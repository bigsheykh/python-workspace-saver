{"0.20.0": "- Bug in :class:`SparseFrame` constructor where passing ``None`` as the data would cause ``default_fill_value`` to be ignored (:issue:`16807`)\n- Bug in :class:`SparseDataFrame` when adding a column in which the length of values does not match length of index, ``AssertionError`` is raised instead of raising ``ValueError`` (:issue:`25484`)\n- Introduce a better error message in :meth:`Series.sparse.from_coo` so it returns a ``TypeError`` for inputs that are not coo matrices (:issue:`26554`)\n- Bug in :func:`numpy.modf` on a :class:`SparseArray`. Now a tuple of :class:`SparseArray` is returned (:issue:`26946`).\n\n\nBuild changes\n^^^^^^^^^^^^^\n\n- Fix install error with PyPy on macOS (:issue:`26536`)\n\nExtensionArray\n^^^^^^^^^^^^^^\n\n- Bug in :func:`factorize` when passing an ``ExtensionArray`` with a custom ``na_sentinel`` (:issue:`25696`).\n- :meth:`Series.count` miscounts NA values in ExtensionArrays (:issue:`26835`)\n- Added ``Series.__array_ufunc__`` to better handle NumPy ufuncs applied to Series backed by extension arrays (:issue:`23293`).\n- Keyword argument ``deep`` has been removed from :meth:`ExtensionArray.copy` (:issue:`27083`)\n\nOther\n^^^^^\n\n- Removed unused C functions from vendored UltraJSON implementation (:issue:`26198`)\n- Allow :class:`Index` and :class:`RangeIndex` to be passed to numpy ``min`` and ``max`` functions (:issue:`26125`)\n- Use actual class name in repr of empty objects of a ``Series`` subclass (:issue:`27001`).\n- Bug in :class:`DataFrame` where passing an object array of timezone-aware ``datetime`` objects would incorrectly raise ``ValueError`` (:issue:`13287`)\n\n.. _whatsnew_0.250.contributors:\n\nContributors\n~~~~~~~~~~~~\n\n.. contributors:: v0.24.2..v0.25.0\n\n\n.. _whatsnew_0171:\n\nVersion 0.17.1 (November 21, 2015)\n----------------------------------\n\n{{ header }}\n\n\n.. note::\n\n   We are proud to announce that *pandas* has become a sponsored project of the (`NumFOCUS organization`_). This will help ensure the success of development of *pandas* as a world-class open-source project.\n\n.. _numfocus organization: http://www.numfocus.org/blog/numfocus-announces-new-fiscally-sponsored-project-pandas\n\nThis is a minor bug-fix release from 0.17.0 and includes a large number of\nbug fixes along several new features, enhancements, and performance improvements.\nWe recommend that all users upgrade to this version.\n\nHighlights include:\n\n- Support for Conditional HTML Formatting, see :ref:`here <whatsnew_0171.style>`\n- Releasing the GIL on the csv reader & other ops, see :ref:`here <whatsnew_0171.performance>`\n- Fixed regression in ``DataFrame.drop_duplicates`` from 0.16.2, causing incorrect results on integer values (:issue:`11376`)\n\n.. contents:: What's new in v0.17.1\n    :local:\n    :backlinks: none\n\nNew features\n~~~~~~~~~~~~\n\n.. _whatsnew_0171.style:\n\nConditional HTML formatting\n^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n.. warning::\n    This is a new feature and is under active development.\n    We'll be adding features an  possibly making breaking changes in future\n    releases. Feedback is welcome in :issue:`11610`\n\nWe've added *experimental* support for conditional HTML formatting:\nthe visual styling of a DataFrame based on the data.\nThe styling is accomplished with HTML and CSS.\nAccesses the styler class with the :attr:`pandas.DataFrame.style`, attribute,\nan instance of :class:`.Styler` with your data attached.\n\nHere's a quick example:\n\n  .. ipython:: python\n\n    np.random.seed(123)\n    df = pd.DataFrame(np.random.randn(10, 5), columns=list(\"abcde\"))\n    html = df.style.background_gradient(cmap=\"viridis\", low=0.5)\n\nWe can render the HTML to get the following table.\n\n.. raw:: html\n   :file: whatsnew_0171_html_table.html\n\n:class:`.Styler` interacts nicely with the Jupyter Notebook.\nSee the :ref:`documentation </user_guide/style.ipynb>` for more.\n\n.. _whatsnew_0171.enhancements:\n\nEnhancements\n~~~~~~~~~~~~\n\n- ``DatetimeIndex`` now supports conversion to strings with ``astype(str)`` (:issue:`10442`)\n- Support for ``compression`` (gzip/bz2) in :meth:`pandas.DataFrame.to_csv` (:issue:`7615`)\n- ``pd.read_*`` functions can now also accept :class:`python:pathlib.Path`, or :class:`py:py._path.local.LocalPath`\n  objects for the ``filepath_or_buffer`` argument. (:issue:`11033`)\n  - The ``DataFrame`` and ``Series`` functions ``.to_csv()``, ``.to_html()`` and ``.to_latex()`` can now handle paths beginning with tildes (e.g. ``~/Documents/``) (:issue:`11438`)\n- ``DataFrame`` now uses the fields of a ``namedtuple`` as columns, if columns are not supplied (:issue:`11181`)\n- ``DataFrame.itertuples()`` now returns ``namedtuple`` objects, when possible. (:issue:`11269`, :issue:`11625`)\n- Added ``axvlines_kwds`` to parallel coordinates plot (:issue:`10709`)\n- Option to ``.info()`` and ``.memory_usage()`` to provide for deep introspection of memory consumption. Note that this can be expensive to compute and therefore is an optional parameter. (:issue:`11595`)\n\n  .. ipython:: python\n\n     df = pd.DataFrame({\"A\": [\"foo\"] * 1000})   noqa: F821\n     df[\"B\"] = df[\"A\"].astype(\"category\")\n\n      shows the '+' as we have object dtypes\n     df.info()\n\n      we have an accurate memory assessment (but can be expensive to compute this)\n     df.info(memory_usage=\"deep\")\n\n- ``Index`` now has a ``fillna`` method (:issue:`10089`)\n\n  .. ipython:: python\n\n     pd.Index([1, np.nan, 3]).fillna(2)\n\n- Series of type ``category`` now make ``.str.<...>`` and ``.dt.<...>`` accessor methods / properties available, if the categories are of that type. (:issue:`10661`)\n\n  .. ipython:: python\n\n     s = pd.Series(list(\"aabb\")).astype(\"category\")\n     s\n     s.str.contains(\"a\")\n\n     date = pd.Series(pd.date_range(\"1/1/2015\", periods=5)).astype(\"category\")\n     date\n     date.dt.day\n\n- ``pivot_table`` now has a ``margins_name`` argument so you can use something other than the default of 'All' (:issue:`3335`)\n- Implement export of ``datetime64[ns, tz]`` dtypes with a fixed HDF5 store (:issue:`11411`)\n- Pretty printing sets (e.g. in DataFrame cells) now uses set literal syntax (``{x, y}``) instead of\n  Legacy Python syntax (``set([x, y])``) (:issue:`11215`)\n- Improve the error message in :func:`pandas.io.gbq.to_gbq` when a streaming insert fails (:issue:`11285`)\n  and when the DataFrame does not match the schema of the destination table (:issue:`11359`)\n\n.. _whatsnew_0171.api:\n\nAPI changes\n~~~~~~~~~~~\n\n- raise ``NotImplementedError`` in ``Index.shift`` for non-supported index types (:issue:`8038`)\n- ``min`` and ``max`` reductions on ``datetime64`` and ``timedelta64`` dtyped series now\n  result in ``NaT`` and not ``nan`` (:issue:`11245`).\n- Indexing with a null key will raise a ``TypeError``, instead of a ``ValueError`` (:issue:`11356`)\n- ``Series.ptp`` will now ignore missing values by default (:issue:`11163`)\n\n.. _whatsnew_0171.deprecations:\n\nDeprecations\n^^^^^^^^^^^^\n\n- The ``pandas.io.ga`` module which implements ``google-analytics`` support is deprecated and will be removed in a future version (:issue:`11308`)\n- Deprecate the ``engine`` keyword in ``.to_csv()``, which will be removed in a future version (:issue:`11274`)\n\n.. _whatsnew_0171.performance:\n\nPerformance improvements\n~~~~~~~~~~~~~~~~~~~~~~~~\n\n- Checking monotonic-ness before sorting on an index (:issue:`11080`)\n- ``Series.dropna`` performance improvement when its dtype can't contain ``NaN`` (:issue:`11159`)\n- Release the GIL on most datetime field operations (e.g. ``DatetimeIndex.year``, ``Series.dt.year``), normalization, and conversion to and from ``Period``, ``DatetimeIndex.to_period`` and ``PeriodIndex.to_timestamp`` (:issue:`11263`)\n- Release the GIL on some rolling algos: ``rolling_median``, ``rolling_mean``, ``rolling_max``, ``rolling_min``, ``rolling_var``, ``rolling_kurt``, ``rolling_skew`` (:issue:`11450`)\n- Release the GIL when reading and parsing text files in ``read_csv``, ``read_table`` (:issue:`11272`)\n- Improved performance of ``rolling_median`` (:issue:`11450`)\n- Improved performance of ``to_excel`` (:issue:`11352`)\n- Performance bug in repr of ``Categorical`` categories, which was rendering the strings before chopping them for display (:issue:`11305`)\n- Performance improvement in ``Categorical.remove_unused_categories``, (:issue:`11643`).\n- Improved performance of ``Series`` constructor with no data and ``DatetimeIndex`` (:issue:`11433`)\n- Improved performance of ``shift``, ``cumprod``, and ``cumsum`` with groupby (:issue:`4095`)\n\n.. _whatsnew_0171.bug_fixes:\n\nBug fixes\n~~~~~~~~~\n\n- ``SparseArray.__iter__()`` now does not cause ``PendingDeprecationWarning`` in Python 3.5 (:issue:`11622`)\n- Regression from 0.16.2 for output formatting of long floats/nan, restored in (:issue:`11302`)\n- ``Series.sort_index()`` now correctly handles the ``inplace`` option (:issue:`11402`)\n- Incorrectly distributed .c file in the build on ``PyPi`` when reading a csv of floats and passing ``na_values=<a scalar>`` would show an exception (:issue:`11374`)\n- Bug in ``.to_latex()`` output broken when the index has a name (:issue:`10660`)\n- Bug in ``HDFStore.append`` with strings whose encoded length exceeded the max unencoded length (:issue:`11234`)\n- Bug in merging ``datetime64[ns, tz]`` dtypes (:issue:`11405`)\n- Bug in ``HDFStore.select`` when comparing with a numpy scalar in a where clause (:issue:`11283`)\n- Bug in using ``DataFrame.ix`` with a MultiIndex indexer (:issue:`11372`)\n- Bug in ``date_range`` with ambiguous endpoints (:issue:`11626`)\n- Prevent adding new attributes to the accessors ``.str``, ``.dt`` and ``.cat``. Retrieving such\n  a value was not possible, so error out on setting it. (:issue:`10673`)\n- Bug in tz-conversions with an ambiguous time and ``.dt`` accessors (:issue:`11295`)\n- Bug in output formatting when using an index of ambiguous times (:issue:`11619`)\n- Bug in comparisons of Series vs list-likes (:issue:`11339`)\n- Bug in ``DataFrame.replace`` with a ``datetime64[ns, tz]`` and a non-compat to_replace (:issue:`11326`, :issue:`11153`)\n- Bug in ``isnull`` where ``numpy.datetime64('NaT')`` in a ``numpy.array`` was not determined to be null(:issue:`11206`)\n- Bug in list-like indexing with a mixed-integer Index (:issue:`11320`)\n- Bug in ``pivot_table`` with ``margins=True`` when indexes are of ``Categorical`` dtype (:issue:`10993`)\n- Bug in ``DataFrame.plot`` cannot use hex strings colors (:issue:`10299`)\n- Regression in ``DataFrame.drop_duplicates`` from 0.16.2, causing incorrect results on integer values (:issue:`11376`)\n- Bug in ``pd.eval`` where unary ops in a list error (:issue:`11235`)\n- Bug in ``squeeze()`` with zero length arrays (:issue:`11230`, :issue:`8999`)\n- Bug in ``describe()`` dropping column names for hierarchical indexes (:issue:`11517`)\n- Bug in ``DataFrame.pct_change()`` not propagating ``axis`` keyword on ``.fillna`` method (:issue:`11150`)\n- Bug in ``.to_csv()`` when a mix of integer and string column names are passed as the ``columns`` parameter (:issue:`11637`)\n- Bug in indexing with a ``range``, (:issue:`11652`)\n- Bug in inference of numpy scalars and preserving dtype when setting columns (:issue:`11638`)\n- Bug in ``to_sql`` using unicode column names giving UnicodeEncodeError with (:issue:`11431`).\n- Fix regression in setting of ``xticks`` in ``plot`` (:issue:`11529`).\n- Bug in ``holiday.dates`` where observance rules could not be applied to holiday and doc enhancement (:issue:`11477`, :issue:`11533`)\n- Fix plotting issues when having plain ``Axes`` instances instead of ``SubplotAxes`` (:issue:`11520`, :issue:`11556`).\n- Bug in ``DataFrame.to_latex()`` produces an extra rule when ``header=False`` (:issue:`7124`)\n- Bug in ``df.groupby(...).apply(func)`` when a func returns a ``Series`` containing a new datetimelike column (:issue:`11324`)\n- Bug in ``pandas.json`` when file to load is big (:issue:`11344`)\n- Bugs in ``to_excel`` with duplicate columns (:issue:`11007`, :issue:`10982`, :issue:`10970`)\n- Fixed a bug that prevented the construction of an empty series of dtype ``datetime64[ns, tz]`` (:issue:`11245`).\n- Bug in ``read_excel`` with MultiIndex containing integers (:issue:`11317`)\n- Bug in ``to_excel`` with openpyxl 2.2+ and merging (:issue:`11408`)\n- Bug in ``DataFrame.to_dict()`` produces a ``np.datetime64`` object instead of ``Timestamp`` when only datetime is present in data (:issue:`11327`)\n- Bug in ``DataFrame.corr()`` raises exception when computes Kendall correlation for DataFrames with boolean and not boolean columns (:issue:`11560`)\n- Bug in the link-time error caused by C ``inline`` functions on FreeBSD 10+ (with ``clang``) (:issue:`10510`)\n- Bug in ``DataFrame.to_csv`` in passing through arguments for formatting ``MultiIndexes``, including ``date_format`` (:issue:`7791`)\n- Bug in ``DataFrame.join()`` with ``how='right'`` producing a ``TypeError`` (:issue:`11519`)\n- Bug in ``Series.quantile`` with empty list results has ``Index`` with ``object`` dtype (:issue:`11588`)\n- Bug in ``pd.merge`` results in empty ``Int64Index`` rather than ``Index(dtype=object)`` when the merge result is empty (:issue:`11588`)\n- Bug in ``Categorical.remove_unused_categories`` when having ``NaN`` values (:issue:`11599`)\n- Bug in ``DataFrame.to_sparse()`` loses column names for MultiIndexes (:issue:`11600`)\n- Bug in ``DataFrame.round()`` with non-unique column index producing a Fatal Python error (:issue:`11611`)\n- Bug in ``DataFrame.round()`` with ``decimals`` being a non-unique indexed Series producing extra columns (:issue:`11618`)\n\n\n.. _whatsnew_0.17.1.contributors:\n\nContributors\n~~~~~~~~~~~~\n\n.. contributors:: v0.17.0..v0.17.1\n\n\n.. _whatsnew_113:\n\nWhat's new in 1.1.3 (October 5, 2020)\n-------------------------------------\n\nThese are the changes in pandas 1.1.3. See :ref:`release` for a full changelog\nincluding other versions of pandas.\n\n{{ header }}\n\n.. ---------------------------------------------------------------------------\n\nEnhancements\n~~~~~~~~~~~~\n\nAdded support for new Python version\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\npandas 1.1.3 now supports Python 3.9 (:issue:`36296`).\n\nDevelopment Changes\n^^^^^^^^^^^^^^^^^^^\n\n- The minimum version of Cython is now the most recent bug-fix version (0.29.21) (:issue:`36296`).\n\n.. ---------------------------------------------------------------------------\n\n.. _whatsnew_113.regressions:\n\nFixed regressions\n~~~~~~~~~~~~~~~~~\n- Fixed regression in :meth:`DataFrame.agg`, :meth:`DataFrame.apply`, :meth:`Series.agg`, and :meth:`Series.apply` where internal suffix is exposed to the users when no relabelling is applied (:issue:`36189`)\n- Fixed regression in :class:`IntegerArray` unary plus and minus operations raising a ``TypeError`` (:issue:`36063`)\n- Fixed regression when adding a :meth:`timedelta_range` to a :class:`Timestamp` raised a ``ValueError`` (:issue:`35897`)\n- Fixed regression in :meth:`Series.__getitem__` incorrectly raising when the input was a tuple (:issue:`35534`)\n- Fixed regression in :meth:`Series.__getitem__` incorrectly raising when the input was a frozenset (:issue:`35747`)\n- Fixed regression in modulo of :class:`Index`, :class:`Series` and :class:`DataFrame` using ``numexpr`` using C not Python semantics (:issue:`36047`, :issue:`36526`)\n- Fixed regression in :meth:`read_excel` with ``engine=\"odf\"`` caused ``UnboundLocalError`` in some cases where cells had nested child nodes (:issue:`36122`, :issue:`35802`)\n- Fixed regression in :meth:`DataFrame.replace` inconsistent replace when using a float in the replace method (:issue:`35376`)\n- Fixed regression in :meth:`Series.loc` on a :class:`Series` with a :class:`MultiIndex` containing :class:`Timestamp` raising ``InvalidIndexError`` (:issue:`35858`)\n- Fixed regression in :class:`DataFrame` and :class:`Series` comparisons between numeric arrays and strings (:issue:`35700`, :issue:`36377`)\n- Fixed regression in :meth:`DataFrame.apply` with ``raw=True`` and user-function returning string (:issue:`35940`)\n- Fixed regression when setting empty :class:`DataFrame` column to a :class:`Series` in preserving name of index in frame (:issue:`36527`)\n- Fixed regression in :class:`Period` incorrect value for ordinal over the maximum timestamp (:issue:`36430`)\n- Fixed regression in :func:`read_table` raised ``ValueError`` when ``delim_whitespace`` was set to ``True`` (:issue:`35958`)\n- Fixed regression in :meth:`Series.dt.normalize` when normalizing pre-epoch dates the result was shifted one day (:issue:`36294`)\n\n.. ---------------------------------------------------------------------------\n\n.. _whatsnew_113.bug_fixes:\n\nBug fixes\n~~~~~~~~~\n- Bug in :func:`read_spss` where passing a ``pathlib.Path`` as ``path`` would raise a ``TypeError`` (:issue:`33666`)\n- Bug in :meth:`Series.str.startswith` and :meth:`Series.str.endswith` with ``category`` dtype not propagating ``na`` parameter (:issue:`36241`)\n- Bug in :class:`Series` constructor where integer overflow would occur for sufficiently large scalar inputs when an index was provided (:issue:`36291`)\n- Bug in :meth:`DataFrame.sort_values` raising an ``AttributeError`` when sorting on a key that casts column to categorical dtype (:issue:`36383`)\n- Bug in :meth:`DataFrame.stack` raising a ``ValueError`` when stacking :class:`MultiIndex` columns based on position when the levels had duplicate names (:issue:`36353`)\n- Bug in :meth:`Series.astype` showing too much precision when casting from ``np.float32`` to string dtype (:issue:`36451`)\n- Bug in :meth:`Series.isin` and :meth:`DataFrame.isin` when using ``NaN`` and a row length above 1,000,000 (:issue:`22205`)\n- Bug in :func:`cut` raising a ``ValueError`` when passed a :class:`Series` of labels with ``ordered=False`` (:issue:`36603`)\n\n.. ---------------------------------------------------------------------------\n\n.. _whatsnew_113.other:\n\nOther\n~~~~~\n- Reverted enhancement added in pandas-1.1.0 where :func:`timedelta_range` infers a frequency when passed ``start``, ``stop``, and ``periods`` (:issue:`32377`)\n\n.. ---------------------------------------------------------------------------\n\n.. _whatsnew_113.contributors:\n\nContributors\n~~~~~~~~~~~~\n\n.. contributors:: v1.1.2..v1.1.3\n\n\n.. _whatsnew_0150:\n\nVersion 0.15.0 (October 18, 2014)\n---------------------------------\n\n{{ header }}\n\n\nThis is a major release from 0.14.1 and includes a small number of API changes, several new features,\nenhancements, and performance improvements along with a large number of bug fixes. We recommend that all\nusers upgrade to this version.\n\n.. warning::\n\n   pandas >= 0.15.0 will no longer support compatibility with NumPy versions <\n   1.7.0. If you want to use the latest versions of pandas, please upgrade to\n   NumPy >= 1.7.0 (:issue:`7711`)\n\n- Highlights include:\n\n  - The ``Categorical`` type was integrated as a first-class pandas type, see :ref:`here <whatsnew_0150.cat>`\n  - New scalar type ``Timedelta``, and a new index type ``TimedeltaIndex``, see :ref:`here <whatsnew_0150.timedeltaindex>`\n  - New datetimelike properties accessor ``.dt`` for Series, see :ref:`Datetimelike Properties <whatsnew_0150.dt>`\n  - New DataFrame default display for ``df.info()`` to include memory usage, see :ref:`Memory Usage <whatsnew_0150.memory>`\n  - ``read_csv`` will now by default ignore blank lines when parsing, see :ref:`here <whatsnew_0150.blanklines>`\n  - API change in using Indexes in set operations, see :ref:`here <whatsnew_0150.index_set_ops>`\n  - Enhancements in the handling of timezones, see :ref:`here <whatsnew_0150.tz>`\n  - A lot of improvements to the rolling and expanding moment functions, see :ref:`here <whatsnew_0150.roll>`\n  - Internal refactoring of the ``Index`` class to no longer sub-class ``ndarray``, see :ref:`Internal Refactoring <whatsnew_0150.refactoring>`\n  - dropping support for ``PyTables`` less than version 3.0.0, and ``numexpr`` less than version 2.1 (:issue:`7990`)\n  - Split indexing documentation into :ref:`Indexing and Selecting Data <indexing>` and :ref:`MultiIndex / Advanced Indexing <advanced>`\n  - Split out string methods documentation into :ref:`Working with Text Data <text>`\n\n- Check the :ref:`API Changes <whatsnew_0150.api>` and :ref:`deprecations <whatsnew_0150.deprecations>` before updating\n\n- :ref:`Other Enhancements <whatsnew_0150.enhancements>`\n\n- :ref:`Performance Improvements <whatsnew_0150.performance>`\n\n- :ref:`Bug Fixes <whatsnew_0150.bug_fixes>`\n\n.. warning::\n\n   In 0.15.0 ``Index`` has internally been refactored to no longer sub-class ``ndarray``\n   but instead subclass ``PandasObject``, similarly to the rest of the pandas objects. This change allows very easy sub-classing and creation of new index types. This should be\n   a transparent change with only very limited API implications (See the :ref:`Internal Refactoring <whatsnew_0150.refactoring>`)\n\n.. warning::\n\n   The refactoring in :class:`~pandas.Categorical` changed the two argument constructor from\n   \"codes/labels and levels\" to \"values and levels (now called 'categories')\". This can lead to subtle bugs. If you use\n   :class:`~pandas.Categorical` directly, please audit your code before updating to this pandas\n   version and change it to use the :meth:`~pandas.Categorical.from_codes` constructor. See more on ``Categorical`` :ref:`here <whatsnew_0150.cat>`\n\n\nNew features\n~~~~~~~~~~~~\n\n.. _whatsnew_0150.cat:\n\nCategoricals in Series/DataFrame\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n:class:`~pandas.Categorical` can now be included in ``Series`` and ``DataFrames`` and gained new\nmethods to manipulate. Thanks to Jan Schulz for much of this API/implementation. (:issue:`3943`, :issue:`5313`, :issue:`5314`,\n:issue:`7444`, :issue:`7839`, :issue:`7848`, :issue:`7864`, :issue:`7914`, :issue:`7768`, :issue:`8006`, :issue:`3678`,\n:issue:`8075`, :issue:`8076`, :issue:`8143`, :issue:`8453`, :issue:`8518`).\n\nFor full docs, see the :ref:`categorical introduction <categorical>` and the\n:ref:`API documentation <api.arrays.categorical>`.\n\n.. ipython:: python\n\n    df = pd.DataFrame({\"id\": [1, 2, 3, 4, 5, 6],\n                       \"raw_grade\": ['a', 'b', 'b', 'a', 'a', 'e']})\n\n    df[\"grade\"] = df[\"raw_grade\"].astype(\"category\")\n    df[\"grade\"]\n\n     Rename the categories\n    df[\"grade\"] = df[\"grade\"].cat.rename_categories([\"very good\", \"good\", \"very bad\"])\n\n     Reorder the categories and simultaneously add the missing categories\n    df[\"grade\"] = df[\"grade\"].cat.set_categories([\"very bad\", \"bad\",\n                                                  \"medium\", \"good\", \"very good\"])\n    df[\"grade\"]\n    df.sort_values(\"grade\")\n    df.groupby(\"grade\", observed=False).size()\n\n- ``pandas.core.group_agg`` and ``pandas.core.factor_agg`` were removed. As an alternative, construct\n  a dataframe and use ``df.groupby(<group>).agg(<func>)``.\n\n- Supplying \"codes/labels and levels\" to the :class:`~pandas.Categorical` constructor is not\n  supported anymore. Supplying two arguments to the constructor is now interpreted as\n  \"values and levels (now called 'categories')\". Please change your code to use the :meth:`~pandas.Categorical.from_codes`\n  constructor.\n\n- The ``Categorical.labels`` attribute was renamed to ``Categorical.codes`` and is read\n  only. If you want to manipulate codes, please use one of the\n  :ref:`API methods on Categoricals <api.arrays.categorical>`.\n\n- The ``Categorical.levels`` attribute is renamed to ``Categorical.categories``.\n\n\n.. _whatsnew_0150.timedeltaindex:\n\nTimedeltaIndex/scalar\n^^^^^^^^^^^^^^^^^^^^^\n\nWe introduce a new scalar type ``Timedelta``, which is a subclass of ``datetime.timedelta``, and behaves in a similar manner,\nbut allows compatibility with ``np.timedelta64`` types as well as a host of custom representation, parsing, and attributes.\nThis type is very similar to how ``Timestamp`` works for ``datetimes``. It is a nice-API box for the type. See the :ref:`docs <timedeltas.timedeltas>`.\n(:issue:`3009`, :issue:`4533`, :issue:`8209`, :issue:`8187`, :issue:`8190`, :issue:`7869`, :issue:`7661`, :issue:`8345`, :issue:`8471`)\n\n.. warning::\n\n   ``Timedelta`` scalars (and ``TimedeltaIndex``) component fields are *not the same* as the component fields on a ``datetime.timedelta`` object. For example, ``.seconds`` on a ``datetime.timedelta`` object returns the total number of seconds combined between ``hours``, ``minutes`` and ``seconds``. In contrast, the pandas ``Timedelta`` breaks out hours, minutes, microseconds and nanoseconds separately.\n\n   .. code-block:: ipython\n\n       Timedelta accessor\n      In [9]: tds = pd.Timedelta('31 days 5 min 3 sec')\n\n      In [10]: tds.minutes\n      Out[10]: 5L\n\n      In [11]: tds.seconds\n      Out[11]: 3L\n\n       datetime.timedelta accessor\n       this is 5 minutes * 60 + 3 seconds\n      In [12]: tds.to_pytimedelta().seconds\n      Out[12]: 303\n\n   **Note**: this is no longer true starting from v0.16.0, where full\n   compatibility with ``datetime.timedelta`` is introduced. See the\n   :ref:`0.16.0 whatsnew entry <whatsnew_0160.api_breaking.timedelta>`\n\n.. warning::\n\n       Prior to 0.15.0 ``pd.to_timedelta`` would return a ``Series`` for list-like/Series input, and a ``np.timedelta64`` for scalar input.\n       It will now return a ``TimedeltaIndex`` for list-like input, ``Series`` for Series input, and ``Timedelta`` for scalar input.\n\n       The arguments to ``pd.to_timedelta`` are now ``(arg,unit='ns',box=True,coerce=False)``, previously were ``(arg,box=True,unit='ns')`` as these are more logical.\n\nConstruct a scalar\n\n.. ipython:: python\n\n   pd.Timedelta('1 days 06:05:01.00003')\n   pd.Timedelta('15.5us')\n   pd.Timedelta('1 hour 15.5us')\n\n    negative Timedeltas have this string repr\n    to be more consistent with datetime.timedelta conventions\n   pd.Timedelta('-1us')\n\n    a NaT\n   pd.Timedelta('nan')\n\nAccess fields for a ``Timedelta``\n\n.. ipython:: python\n\n   td = pd.Timedelta('1 hour 3m 15.5us')\n   td.seconds\n   td.microseconds\n   td.nanoseconds\n\nConstruct a ``TimedeltaIndex``\n\n.. ipython:: python\n   :suppress:\n\n   import datetime\n\n.. ipython:: python\n\n   pd.TimedeltaIndex(['1 days', '1 days, 00:00:05',\n                      np.timedelta64(2, 'D'),\n                      datetime.timedelta(days=2, seconds=2)])\n\nConstructing a ``TimedeltaIndex`` with a regular range\n\n.. ipython:: python\n\n   pd.timedelta_range('1 days', periods=5, freq='D')\n\n.. code-block:: python\n\n   In [20]: pd.timedelta_range(start='1 days', end='2 days', freq='30T')\n   Out[20]:\n   TimedeltaIndex(['1 days 00:00:00', '1 days 00:30:00', '1 days 01:00:00',\n                   '1 days 01:30:00', '1 days 02:00:00', '1 days 02:30:00',\n                   '1 days 03:00:00', '1 days 03:30:00', '1 days 04:00:00',\n                   '1 days 04:30:00', '1 days 05:00:00', '1 days 05:30:00',\n                   '1 days 06:00:00', '1 days 06:30:00', '1 days 07:00:00',\n                   '1 days 07:30:00', '1 days 08:00:00', '1 days 08:30:00',\n                   '1 days 09:00:00', '1 days 09:30:00', '1 days 10:00:00',\n                   '1 days 10:30:00', '1 days 11:00:00', '1 days 11:30:00',\n                   '1 days 12:00:00', '1 days 12:30:00', '1 days 13:00:00',\n                   '1 days 13:30:00', '1 days 14:00:00', '1 days 14:30:00',\n                   '1 days 15:00:00', '1 days 15:30:00', '1 days 16:00:00',\n                   '1 days 16:30:00', '1 days 17:00:00', '1 days 17:30:00',\n                   '1 days 18:00:00', '1 days 18:30:00', '1 days 19:00:00',\n                   '1 days 19:30:00', '1 days 20:00:00', '1 days 20:30:00',\n                   '1 days 21:00:00', '1 days 21:30:00', '1 days 22:00:00',\n                   '1 days 22:30:00', '1 days 23:00:00', '1 days 23:30:00',\n                   '2 days 00:00:00'],\n                  dtype='timedelta64[ns]', freq='30T')\n\nYou can now use a ``TimedeltaIndex`` as the index of a pandas object\n\n.. ipython:: python\n\n   s = pd.Series(np.arange(5),\n                 index=pd.timedelta_range('1 days', periods=5, freq='s'))\n   s\n\nYou can select with partial string selections\n\n.. ipython:: python\n\n   s['1 day 00:00:02']\n   s['1 day':'1 day 00:00:02']\n\nFinally, the combination of ``TimedeltaIndex`` with ``DatetimeIndex`` allow certain combination operations that are ``NaT`` preserving:\n\n.. ipython:: python\n\n   tdi = pd.TimedeltaIndex(['1 days', pd.NaT, '2 days'])\n   tdi.tolist()\n   dti = pd.date_range('20130101', periods=3)\n   dti.tolist()\n\n   (dti + tdi).tolist()\n   (dti - tdi).tolist()\n\n- iteration of a ``Series`` e.g. ``list(Series(...))`` of ``timedelta64[ns]`` would prior to v0.15.0 return ``np.timedelta64`` for each element. These will now be wrapped in ``Timedelta``.\n\n\n.. _whatsnew_0150.memory:\n\nMemory usage\n^^^^^^^^^^^^\n\nImplemented methods to find memory usage of a DataFrame. See the :ref:`FAQ <df-memory-usage>` for more. (:issue:`6852`).\n\nA new display option ``display.memory_usage`` (see :ref:`options`) sets the default behavior of the ``memory_usage`` argument in the ``df.info()`` method. By default ``display.memory_usage`` is ``True``.\n\n.. ipython:: python\n\n    dtypes = ['int64', 'float64', 'datetime64[ns]', 'timedelta64[ns]',\n              'complex128', 'object', 'bool']\n    n = 5000\n    data = {t: np.random.randint(100, size=n).astype(t) for t in dtypes}\n    df = pd.DataFrame(data)\n    df['categorical'] = df['object'].astype('category')\n\n    df.info()\n\nAdditionally :meth:`~pandas.DataFrame.memory_usage` is an available method for a dataframe object which returns the memory usage of each column.\n\n.. ipython:: python\n\n    df.memory_usage(index=True)\n\n\n.. _whatsnew_0150.dt:\n\nSeries.dt accessor\n^^^^^^^^^^^^^^^^^^\n\n``Series`` has gained an accessor to succinctly return datetime like properties for the *values* of the Series, if its a datetime/period like Series. (:issue:`7207`)\nThis will return a Series, indexed like the existing Series. See the :ref:`docs <basics.dt_accessors>`\n\n.. ipython:: python\n\n    datetime\n   s = pd.Series(pd.date_range('20130101 09:10:12', periods=4))\n   s\n   s.dt.hour\n   s.dt.second\n   s.dt.day\n   s.dt.freq\n\nThis enables nice expressions like this:\n\n.. ipython:: python\n\n   s[s.dt.day == 2]\n\nYou can easily produce tz aware transformations:\n\n.. ipython:: python\n\n   stz = s.dt.tz_localize('US/Eastern')\n   stz\n   stz.dt.tz\n\nYou can also chain these types of operations:\n\n.. ipython:: python\n\n   s.dt.tz_localize('UTC').dt.tz_convert('US/Eastern')\n\nThe ``.dt`` accessor works for period and timedelta dtypes.\n\n.. ipython:: python\n\n    period\n   s = pd.Series(pd.period_range('20130101', periods=4, freq='D'))\n   s\n   s.dt.year\n   s.dt.day\n\n.. ipython:: python\n\n    timedelta\n   s = pd.Series(pd.timedelta_range('1 day 00:00:05', periods=4, freq='s'))\n   s\n   s.dt.days\n   s.dt.seconds\n   s.dt.components\n\n\n.. _whatsnew_0150.tz:\n\nTimezone handling improvements\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n- ``tz_localize(None)`` for tz-aware ``Timestamp`` and ``DatetimeIndex`` now removes timezone holding local time,\n  previously this resulted in ``Exception`` or ``TypeError`` (:issue:`7812`)\n\n  .. code-block:: ipython\n\n     In [58]: ts = pd.Timestamp('2014-08-01 09:00', tz='US/Eastern')\n\n     In[59]: ts\n     Out[59]: Timestamp('2014-08-01 09:00:00-0400', tz='US/Eastern')\n\n     In [60]: ts.tz_localize(None)\n     Out[60]: Timestamp('2014-08-01 09:00:00')\n\n     In [61]: didx = pd.date_range(start='2014-08-01 09:00', freq='H',\n        ....:                      periods=10, tz='US/Eastern')\n        ....:\n\n     In [62]: didx\n     Out[62]:\n     DatetimeIndex(['2014-08-01 09:00:00-04:00', '2014-08-01 10:00:00-04:00',\n                    '2014-08-01 11:00:00-04:00', '2014-08-01 12:00:00-04:00',\n                    '2014-08-01 13:00:00-04:00', '2014-08-01 14:00:00-04:00',\n                    '2014-08-01 15:00:00-04:00', '2014-08-01 16:00:00-04:00',\n                    '2014-08-01 17:00:00-04:00', '2014-08-01 18:00:00-04:00'],\n                   dtype='datetime64[ns, US/Eastern]', freq='H')\n\n     In [63]: didx.tz_localize(None)\n     Out[63]:\n     DatetimeIndex(['2014-08-01 09:00:00', '2014-08-01 10:00:00',\n                    '2014-08-01 11:00:00', '2014-08-01 12:00:00',\n                    '2014-08-01 13:00:00', '2014-08-01 14:00:00',\n                    '2014-08-01 15:00:00', '2014-08-01 16:00:00',\n                    '2014-08-01 17:00:00', '2014-08-01 18:00:00'],\n                   dtype='datetime64[ns]', freq=None)\n\n- ``tz_localize`` now accepts the ``ambiguous`` keyword which allows for passing an array of bools\n  indicating whether the date belongs in DST or not, 'NaT' for setting transition times to NaT,\n  'infer' for inferring DST/non-DST, and 'raise' (default) for an ``AmbiguousTimeError`` to be raised. See :ref:`the docs<timeseries.timezone_ambiguous>` for more details (:issue:`7943`)\n\n- ``DataFrame.tz_localize`` and ``DataFrame.tz_convert`` now accepts an optional ``level`` argument\n  for localizing a specific level of a MultiIndex (:issue:`7846`)\n\n- ``Timestamp.tz_localize`` and ``Timestamp.tz_convert`` now raise ``TypeError`` in error cases, rather than ``Exception`` (:issue:`8025`)\n\n- a timeseries/index localized to UTC when inserted into a Series/DataFrame will preserve the UTC timezone (rather than being a naive ``datetime64[ns]``) as ``object`` dtype (:issue:`8411`)\n\n- ``Timestamp.__repr__`` displays ``dateutil.tz.tzoffset`` info (:issue:`7907`)\n\n\n.. _whatsnew_0150.roll:\n\nRolling/expanding moments improvements\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n- :func:`rolling_min`, :func:`rolling_max`, :func:`rolling_cov`, and :func:`rolling_corr`\n  now return objects with all ``NaN`` when ``len(arg) < min_periods <= window`` rather\n  than raising. (This makes all rolling functions consistent in this behavior). (:issue:`7766`)\n\n  Prior to 0.15.0\n\n  .. ipython:: python\n\n     s = pd.Series([10, 11, 12, 13])\n\n  .. code-block:: ipython\n\n     In [15]: pd.rolling_min(s, window=10, min_periods=5)\n     ValueError: min_periods (5) must be <= window (4)\n\n  New behavior\n\n  .. code-block:: ipython\n\n     In [4]: pd.rolling_min(s, window=10, min_periods=5)\n     Out[4]:\n     0   NaN\n     1   NaN\n     2   NaN\n     3   NaN\n     dtype: float64\n\n- :func:`rolling_max`, :func:`rolling_min`, :func:`rolling_sum`, :func:`rolling_mean`, :func:`rolling_median`,\n  :func:`rolling_std`, :func:`rolling_var`, :func:`rolling_skew`, :func:`rolling_kurt`, :func:`rolling_quantile`,\n  :func:`rolling_cov`, :func:`rolling_corr`, :func:`rolling_corr_pairwise`,\n  :func:`rolling_window`, and :func:`rolling_apply` with ``center=True`` previously would return a result of the same\n  structure as the input ``arg`` with ``NaN`` in the final ``(window-1)/2`` entries.\n\n  Now the final ``(window-1)/2`` entries of the result are calculated as if the input ``arg`` were followed\n  by ``(window-1)/2`` ``NaN`` values (or with shrinking windows, in the case of :func:`rolling_apply`).\n  (:issue:`7925`, :issue:`8269`)\n\n  Prior behavior (note final value is ``NaN``):\n\n  .. code-block:: ipython\n\n    In [7]: pd.rolling_sum(Series(range(4)), window=3, min_periods=0, center=True)\n    Out[7]:\n    0     1\n    1     3\n    2     6\n    3   NaN\n    dtype: float64\n\n  New behavior (note final value is ``5 = sum([2, 3, NaN])``):\n\n  .. code-block:: ipython\n\n     In [7]: pd.rolling_sum(pd.Series(range(4)), window=3,\n       ....:                min_periods=0, center=True)\n     Out[7]:\n     0    1\n     1    3\n     2    6\n     3    5\n     dtype: float64\n\n- :func:`rolling_window` now normalizes the weights properly in rolling mean mode (`mean=True`) so that\n  the calculated weighted means (e.g. 'triang', 'gaussian') are distributed about the same means as those\n  calculated without weighting (i.e. 'boxcar'). See :ref:`the note on normalization <window.weighted>` for further details. (:issue:`7618`)\n\n  .. ipython:: python\n\n    s = pd.Series([10.5, 8.8, 11.4, 9.7, 9.3])\n\n  Behavior prior to 0.15.0:\n\n  .. code-block:: ipython\n\n     In [39]: pd.rolling_window(s, window=3, win_type='triang', center=True)\n     Out[39]:\n     0         NaN\n     1    6.583333\n     2    6.883333\n     3    6.683333\n     4         NaN\n     dtype: float64\n\n  New behavior\n\n  .. code-block:: ipython\n\n     In [10]: pd.rolling_window(s, window=3, win_type='triang', center=True)\n     Out[10]:\n     0       NaN\n     1     9.875\n     2    10.325\n     3    10.025\n     4       NaN\n     dtype: float64\n\n- Removed ``center`` argument from all :func:`expanding_ <expanding_apply>` functions (see :ref:`list <api.functions_expanding>`),\n  as the results produced when ``center=True`` did not make much sense. (:issue:`7925`)\n\n- Added optional ``ddof`` argument to :func:`expanding_cov` and :func:`rolling_cov`.\n  The default value of ``1`` is backwards-compatible. (:issue:`8279`)\n\n- Documented the ``ddof`` argument to :func:`expanding_var`, :func:`expanding_std`,\n  :func:`rolling_var`, and :func:`rolling_std`. These functions' support of a\n  ``ddof`` argument (with a default value of ``1``) was previously undocumented. (:issue:`8064`)\n\n- :func:`ewma`, :func:`ewmstd`, :func:`ewmvol`, :func:`ewmvar`, :func:`ewmcov`, and :func:`ewmcorr`\n  now interpret ``min_periods`` in the same manner that the :func:`rolling_*()` and :func:`expanding_*()` functions do:\n  a given result entry will be ``NaN`` if the (expanding, in this case) window does not contain\n  at least ``min_periods`` values. The previous behavior was to set to ``NaN`` the ``min_periods`` entries\n  starting with the first non- ``NaN`` value. (:issue:`7977`)\n\n  Prior behavior (note values start at index ``2``, which is ``min_periods`` after index ``0``\n  (the index of the first non-empty value)):\n\n  .. ipython:: python\n\n    s  = pd.Series([1, None, None, None, 2, 3])\n\n  .. code-block:: ipython\n\n        In [51]: pd.ewma(s, com=3., min_periods=2)\n        Out[51]:\n        0         NaN\n        1         NaN\n        2    1.000000\n        3    1.000000\n        4    1.571429\n        5    2.189189\n        dtype: float64\n\n  New behavior (note values start at index ``4``, the location of the 2nd (since ``min_periods=2``) non-empty value):\n\n  .. code-block:: ipython\n\n     In [2]: pd.ewma(s, com=3., min_periods=2)\n     Out[2]:\n     0         NaN\n     1         NaN\n     2         NaN\n     3         NaN\n     4    1.759644\n     5    2.383784\n     dtype: float64\n\n- :func:`ewmstd`, :func:`ewmvol`, :func:`ewmvar`, :func:`ewmcov`, and :func:`ewmcorr`\n  now have an optional ``adjust`` argument, just like :func:`ewma` does,\n  affecting how the weights are calculated.\n  The default value of ``adjust`` is ``True``, which is backwards-compatible.\n  See :ref:`Exponentially weighted moment functions <window.exponentially_weighted>` for details. (:issue:`7911`)\n\n- :func:`ewma`, :func:`ewmstd`, :func:`ewmvol`, :func:`ewmvar`, :func:`ewmcov`, and :func:`ewmcorr`\n  now have an optional ``ignore_na`` argument.\n  When ``ignore_na=False`` (the default), missing values are taken into account in the weights calculation.\n  When ``ignore_na=True`` (which reproduces the pre-0.15.0 behavior), missing values are ignored in the weights calculation.\n  (:issue:`7543`)\n\n  .. code-block:: ipython\n\n     In [7]: pd.ewma(pd.Series([None, 1., 8.]), com=2.)\n     Out[7]:\n     0    NaN\n     1    1.0\n     2    5.2\n     dtype: float64\n\n     In [8]: pd.ewma(pd.Series([1., None, 8.]), com=2.,\n       ....:         ignore_na=True)   pre-0.15.0 behavior\n     Out[8]:\n     0    1.0\n     1    1.0\n     2    5.2\n     dtype: float64\n\n     In [9]: pd.ewma(pd.Series([1., None, 8.]), com=2.,\n       ....:         ignore_na=False)   new default\n     Out[9]:\n     0    1.000000\n     1    1.000000\n     2    5.846154\n     dtype: float64\n\n  .. warning::\n\n     By default (``ignore_na=False``) the :func:`ewm*()` functions' weights calculation\n     in the presence of missing values is different than in pre-0.15.0 versions.\n     To reproduce the pre-0.15.0 calculation of weights in the presence of missing values\n     one must specify explicitly ``ignore_na=True``.\n\n- Bug in :func:`expanding_cov`, :func:`expanding_corr`, :func:`rolling_cov`, :func:`rolling_cor`, :func:`ewmcov`, and :func:`ewmcorr`\n  returning results with columns sorted by name and producing an error for non-unique columns;\n  now handles non-unique columns and returns columns in original order\n  (except for the case of two DataFrames with ``pairwise=False``, where behavior is unchanged) (:issue:`7542`)\n- Bug in :func:`rolling_count` and :func:`expanding_*()` functions unnecessarily producing error message for zero-length data (:issue:`8056`)\n- Bug in :func:`rolling_apply` and :func:`expanding_apply` interpreting ``min_periods=0`` as ``min_periods=1`` (:issue:`8080`)\n- Bug in :func:`expanding_std` and :func:`expanding_var` for a single value producing a confusing error message (:issue:`7900`)\n- Bug in :func:`rolling_std` and :func:`rolling_var` for a single value producing ``0`` rather than ``NaN`` (:issue:`7900`)\n\n- Bug in :func:`ewmstd`, :func:`ewmvol`, :func:`ewmvar`, and :func:`ewmcov`\n  calculation of de-biasing factors when ``bias=False`` (the default).\n  Previously an incorrect constant factor was used, based on ``adjust=True``, ``ignore_na=True``,\n  and an infinite number of observations.\n  Now a different factor is used for each entry, based on the actual weights\n  (analogous to the usual ``N/(N-1)`` factor).\n  In particular, for a single point a value of ``NaN`` is returned when ``bias=False``,\n  whereas previously a value of (approximately) ``0`` was returned.\n\n  For example, consider the following pre-0.15.0 results for ``ewmvar(..., bias=False)``,\n  and the corresponding debiasing factors:\n\n  .. ipython:: python\n\n     s = pd.Series([1., 2., 0., 4.])\n\n  .. code-block:: ipython\n\n         In [89]: pd.ewmvar(s, com=2., bias=False)\n         Out[89]:\n         0   -2.775558e-16\n         1    3.000000e-01\n         2    9.556787e-01\n         3    3.585799e+00\n         dtype: float64\n\n         In [90]: pd.ewmvar(s, com=2., bias=False) / pd.ewmvar(s, com=2., bias=True)\n         Out[90]:\n         0    1.25\n         1    1.25\n         2    1.25\n         3    1.25\n         dtype: float64\n\n  Note that entry ``0`` is approximately 0, and the debiasing factors are a constant 1.25.\n  By comparison, the following 0.15.0 results have a ``NaN`` for entry ``0``,\n  and the debiasing factors are decreasing (towards 1.25):\n\n  .. code-block:: ipython\n\n     In [14]: pd.ewmvar(s, com=2., bias=False)\n     Out[14]:\n     0         NaN\n     1    0.500000\n     2    1.210526\n     3    4.089069\n     dtype: float64\n\n     In [15]: pd.ewmvar(s, com=2., bias=False) / pd.ewmvar(s, com=2., bias=True)\n     Out[15]:\n     0         NaN\n     1    2.083333\n     2    1.583333\n     3    1.425439\n     dtype: float64\n\n  See :ref:`Exponentially weighted moment functions <window.exponentially_weighted>` for details. (:issue:`7912`)\n\n\n.. _whatsnew_0150.sql:\n\nImprovements in the SQL IO module\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n- Added support for a ``chunksize`` parameter to ``to_sql`` function. This allows DataFrame to be written in chunks and avoid packet-size overflow errors (:issue:`8062`).\n- Added support for a ``chunksize`` parameter to ``read_sql`` function. Specifying this argument will return an iterator through chunks of the query result (:issue:`2908`).\n- Added support for writing ``datetime.date`` and ``datetime.time`` object columns with ``to_sql`` (:issue:`6932`).\n- Added support for specifying a ``schema`` to read from/write to with ``read_sql_table`` and ``to_sql`` (:issue:`7441`, :issue:`7952`).\n  For example:\n\n  .. code-block:: python\n\n         df.to_sql('table', engine, schema='other_schema')   noqa F821\n         pd.read_sql_table('table', engine, schema='other_schema')   noqa F821\n\n- Added support for writing ``NaN`` values with ``to_sql`` (:issue:`2754`).\n- Added support for writing datetime64 columns with ``to_sql`` for all database flavors (:issue:`7103`).\n\n\n.. _whatsnew_0150.api:\n\nBackwards incompatible API changes\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\n.. _whatsnew_0150.api_breaking:\n\nBreaking changes\n^^^^^^^^^^^^^^^^\n\nAPI changes related to ``Categorical`` (see :ref:`here <whatsnew_0150.cat>`\nfor more details):\n\n- The ``Categorical`` constructor with two arguments changed from\n  \"codes/labels and levels\" to \"values and levels (now called 'categories')\".\n  This can lead to subtle bugs. If you use :class:`~pandas.Categorical` directly,\n  please audit your code by changing it to use the :meth:`~pandas.Categorical.from_codes`\n  constructor.\n\n  An old function call like (prior to 0.15.0):\n\n  .. code-block:: python\n\n    pd.Categorical([0,1,0,2,1], levels=['a', 'b', 'c'])\n\n  will have to adapted to the following to keep the same behaviour:\n\n  .. code-block:: ipython\n\n    In [2]: pd.Categorical.from_codes([0,1,0,2,1], categories=['a', 'b', 'c'])\n    Out[2]:\n    [a, b, a, c, b]\n    Categories (3, object): [a, b, c]\n\nAPI changes related to the introduction of the ``Timedelta`` scalar (see\n:ref:`above <whatsnew_0150.timedeltaindex>` for more details):\n\n- Prior to 0.15.0 :func:`to_timedelta` would return a ``Series`` for list-like/Series input,\n  and a ``np.timedelta64`` for scalar input. It will now return a ``TimedeltaIndex`` for\n  list-like input, ``Series`` for Series input, and ``Timedelta`` for scalar input.\n\nFor API changes related to the rolling and expanding functions, see detailed overview :ref:`above <whatsnew_0150.roll>`.\n\nOther notable API changes:\n\n- Consistency when indexing with ``.loc`` and a list-like indexer when no values are found.\n\n  .. ipython:: python\n\n     df = pd.DataFrame([['a'], ['b']], index=[1, 2])\n     df\n\n  In prior versions there was a difference in these two constructs:\n\n  - ``df.loc[[3]]`` would return a frame reindexed by 3 (with all ``np.nan`` values)\n  - ``df.loc[[3],:]`` would raise ``KeyError``.\n\n  Both will now raise a ``KeyError``. The rule is that *at least 1* indexer must be found when using a list-like and ``.loc`` (:issue:`7999`)\n\n  Furthermore in prior versions these were also different:\n\n  - ``df.loc[[1,3]]`` would return a frame reindexed by [1,3]\n  - ``df.loc[[1,3],:]`` would raise ``KeyError``.\n\n  Both will now return a frame reindex by [1,3]. E.g.\n\n  .. code-block:: ipython\n\n     In [3]: df.loc[[1, 3]]\n     Out[3]:\n          0\n     1    a\n     3  NaN\n\n     In [4]: df.loc[[1, 3], :]\n     Out[4]:\n          0\n     1    a\n     3  NaN\n\n  This can also be seen in multi-axis indexing with a ``Panel``.\n\n  .. code-block:: python\n\n     >>> p = pd.Panel(np.arange(2 * 3 * 4).reshape(2, 3, 4),\n     ...              items=['ItemA', 'ItemB'],\n     ...              major_axis=[1, 2, 3],\n     ...              minor_axis=['A', 'B', 'C', 'D'])\n     >>> p\n     <class 'pandas.core.panel.Panel'>\n     Dimensions: 2 (items) x 3 (major_axis) x 4 (minor_axis)\n     Items axis: ItemA to ItemB\n     Major_axis axis: 1 to 3\n     Minor_axis axis: A to D\n\n\n  The following would raise ``KeyError`` prior to 0.15.0:\n\n  .. code-block:: ipython\n\n     In [5]:\n     Out[5]:\n        ItemA  ItemD\n     1      3    NaN\n     2      7    NaN\n     3     11    NaN\n\n  Furthermore, ``.loc`` will raise If no values are found in a MultiIndex with a list-like indexer:\n\n  .. ipython:: python\n     :okexcept:\n\n     s = pd.Series(np.arange(3, dtype='int64'),\n                   index=pd.MultiIndex.from_product([['A'],\n                                                    ['foo', 'bar', 'baz']],\n                                                    names=['one', 'two'])\n                   ).sort_index()\n     s\n     try:\n         s.loc[['D']]\n     except KeyError as e:\n         print(\"KeyError: \" + str(e))\n\n- Assigning values to ``None`` now considers the dtype when choosing an 'empty' value (:issue:`7941`).\n\n  Previously, assigning to ``None`` in numeric containers changed the\n  dtype to object (or errored, depending on the call). It now uses\n  ``NaN``:\n\n  .. ipython:: python\n\n     s = pd.Series([1., 2., 3.])\n     s.loc[0] = None\n     s\n\n  ``NaT`` is now used similarly for datetime containers.\n\n  For object containers, we now preserve ``None`` values (previously these\n  were converted to ``NaN`` values).\n\n  .. ipython:: python\n\n     s = pd.Series([\"a\", \"b\", \"c\"])\n     s.loc[0] = None\n     s\n\n  To insert a ``NaN``, you must explicitly use ``np.nan``. See the :ref:`docs <missing.inserting>`.\n\n- In prior versions, updating a pandas object inplace would not reflect in other python references to this object. (:issue:`8511`, :issue:`5104`)\n\n  .. ipython:: python\n\n     s = pd.Series([1, 2, 3])\n     s2 = s\n     s += 1.5\n\n  Behavior prior to v0.15.0\n\n  .. code-block:: ipython\n\n\n      the original object\n     In [5]: s\n     Out[5]:\n     0    2.5\n     1    3.5\n     2    4.5\n     dtype: float64\n\n\n      a reference to the original object\n     In [7]: s2\n     Out[7]:\n     0    1\n     1    2\n     2    3\n     dtype: int64\n\n  This is now the correct behavior\n\n  .. ipython:: python\n\n      the original object\n     s\n\n      a reference to the original object\n     s2\n\n.. _whatsnew_0150.blanklines:\n\n- Made both the C-based and Python engines for ``read_csv`` and ``read_table`` ignore empty lines in input as well as\n  white space-filled lines, as long as ``sep`` is not white space. This is an API change\n  that can be controlled by the keyword parameter ``skip_blank_lines``.  See :ref:`the docs <io.skiplines>` (:issue:`4466`)\n\n- A timeseries/index localized to UTC when inserted into a Series/DataFrame will preserve the UTC timezone\n  and inserted as ``object`` dtype rather than being converted to a naive ``datetime64[ns]`` (:issue:`8411`).\n\n- Bug in passing a ``DatetimeIndex`` with a timezone that was not being retained in DataFrame construction from a dict (:issue:`7822`)\n\n  In prior versions this would drop the timezone, now it retains the timezone,\n  but gives a column of ``object`` dtype:\n\n  .. ipython:: python\n\n        i = pd.date_range('1/1/2011', periods=3, freq='10s', tz='US/Eastern')\n        i\n        df = pd.DataFrame({'a': i})\n        df\n        df.dtypes\n\n  Previously this would have yielded a column of ``datetime64`` dtype, but without timezone info.\n\n  The behaviour of assigning a column to an existing dataframe as ``df['a'] = i``\n  remains unchanged (this already returned an  ``object`` column with a timezone).\n\n- When passing multiple levels to :meth:`~pandas.DataFrame.stack()`, it will now raise a ``ValueError`` when the\n  levels aren't all level names or all level numbers (:issue:`7660`). See\n  :ref:`Reshaping by stacking and unstacking <reshaping.stack_multiple>`.\n\n- Raise a ``ValueError`` in ``df.to_hdf`` with 'fixed' format, if ``df`` has non-unique columns as the resulting file will be broken (:issue:`7761`)\n\n- ``SettingWithCopy`` raise/warnings (according to the option ``mode.chained_assignment``) will now be issued when setting a value on a sliced mixed-dtype DataFrame using chained-assignment. (:issue:`7845`, :issue:`7950`)\n\n  .. code-block:: python\n\n     In [1]: df = pd.DataFrame(np.arange(0, 9), columns=['count'])\n\n     In [2]: df['group'] = 'b'\n\n     In [3]: df.iloc[0:5]['group'] = 'a'\n     /usr/local/bin/ipython:1: SettingWithCopyWarning:\n     A value is trying to be set on a copy of a slice from a DataFrame.\n     Try using .loc[row_indexer,col_indexer] = value instead\n\n     See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n\n- ``merge``, ``DataFrame.merge``, and ``ordered_merge`` now return the same type\n  as the ``left`` argument (:issue:`7737`).\n\n- Previously an enlargement with a mixed-dtype frame would act unlike ``.append`` which will preserve dtypes (related :issue:`2578`, :issue:`8176`):\n\n  .. ipython:: python\n\n     df = pd.DataFrame([[True, 1], [False, 2]],\n                       columns=[\"female\", \"fitness\"])\n     df\n     df.dtypes\n\n      dtypes are now preserved\n     df.loc[2] = df.loc[1]\n     df\n     df.dtypes\n\n- ``Series.to_csv()`` now returns a string when ``path=None``, matching the behaviour of ``DataFrame.to_csv()`` (:issue:`8215`).\n\n- ``read_hdf`` now raises ``IOError`` when a file that doesn't exist is passed in. Previously, a new, empty file was created, and a ``KeyError`` raised (:issue:`7715`).\n\n- ``DataFrame.info()`` now ends its output with a newline character (:issue:`8114`)\n- Concatenating no objects will now raise a ``ValueError`` rather than a bare ``Exception``.\n- Merge errors will now be sub-classes of ``ValueError`` rather than raw ``Exception`` (:issue:`8501`)\n- ``DataFrame.plot`` and ``Series.plot`` keywords are now have consistent orders (:issue:`8037`)\n\n\n.. _whatsnew_0150.refactoring:\n\nInternal refactoring\n^^^^^^^^^^^^^^^^^^^^\n\nIn 0.15.0 ``Index`` has internally been refactored to no longer sub-class ``ndarray``\nbut instead subclass ``PandasObject``, similarly to the rest of the pandas objects. This\nchange allows very easy sub-classing and creation of new index types. This should be\na transparent change with only very limited API implications (:issue:`5080`, :issue:`7439`, :issue:`7796`, :issue:`8024`, :issue:`8367`, :issue:`7997`, :issue:`8522`):\n\n- you may need to unpickle pandas version < 0.15.0 pickles using ``pd.read_pickle`` rather than ``pickle.load``. See :ref:`pickle docs <io.pickle>`\n- when plotting with a ``PeriodIndex``, the matplotlib internal axes will now be arrays of ``Period`` rather than a ``PeriodIndex`` (this is similar to how a ``DatetimeIndex`` passes arrays of ``datetimes`` now)\n- MultiIndexes will now raise similarly to other pandas objects w.r.t. truth testing, see :ref:`here <gotchas.truth>` (:issue:`7897`).\n- When plotting a DatetimeIndex directly with matplotlib's ``plot`` function,\n  the axis labels will no longer be formatted as dates but as integers (the\n  internal representation of a ``datetime64``). **UPDATE** This is fixed\n  in 0.15.1, see :ref:`here <whatsnew_0151.datetime64_plotting>`.\n\n.. _whatsnew_0150.deprecations:\n\nDeprecations\n^^^^^^^^^^^^\n\n- The attributes ``Categorical`` ``labels`` and ``levels`` attributes are\n  deprecated and renamed to ``codes`` and ``categories``.\n- The ``outtype`` argument to ``pd.DataFrame.to_dict`` has been deprecated in favor of ``orient``. (:issue:`7840`)\n- The ``convert_dummies`` method has been deprecated in favor of\n  ``get_dummies`` (:issue:`8140`)\n- The ``infer_dst`` argument in ``tz_localize`` will be deprecated in favor of\n  ``ambiguous`` to allow for more flexibility in dealing with DST transitions.\n  Replace ``infer_dst=True`` with ``ambiguous='infer'`` for the same behavior (:issue:`7943`).\n  See :ref:`the docs<timeseries.timezone_ambiguous>` for more details.\n- The top-level ``pd.value_range`` has been deprecated and can be replaced by ``.describe()`` (:issue:`8481`)\n\n.. _whatsnew_0150.index_set_ops:\n\n- The ``Index`` set operations ``+`` and ``-`` were deprecated in order to provide these for numeric type operations on certain index types. ``+`` can be replaced by ``.union()`` or ``|``, and ``-`` by ``.difference()``. Further the method name ``Index.diff()`` is deprecated and can be replaced by ``Index.difference()`` (:issue:`8226`)\n\n  .. code-block:: python\n\n      +\n     pd.Index(['a', 'b', 'c']) + pd.Index(['b', 'c', 'd'])\n\n      should be replaced by\n     pd.Index(['a', 'b', 'c']).union(pd.Index(['b', 'c', 'd']))\n\n  .. code-block:: python\n\n      -\n     pd.Index(['a', 'b', 'c']) - pd.Index(['b', 'c', 'd'])\n\n      should be replaced by\n     pd.Index(['a', 'b', 'c']).difference(pd.Index(['b', 'c', 'd']))\n\n- The ``infer_types`` argument to :func:`~pandas.read_html` now has no\n  effect and is deprecated (:issue:`7762`, :issue:`7032`).\n\n\n.. _whatsnew_0150.prior_deprecations:\n\nRemoval of prior version deprecations/changes\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n- Remove ``DataFrame.delevel`` method in favor of ``DataFrame.reset_index``\n\n\n\n.. _whatsnew_0150.enhancements:\n\nEnhancements\n~~~~~~~~~~~~\n\nEnhancements in the importing/exporting of Stata files:\n\n- Added support for bool, uint8, uint16 and uint32 data types in ``to_stata`` (:issue:`7097`, :issue:`7365`)\n- Added conversion option when importing Stata files (:issue:`8527`)\n- ``DataFrame.to_stata`` and ``StataWriter`` check string length for\n  compatibility with limitations imposed in dta files where fixed-width\n  strings must contain 244 or fewer characters.  Attempting to write Stata\n  dta files with strings longer than 244 characters raises a ``ValueError``. (:issue:`7858`)\n- ``read_stata`` and ``StataReader`` can import missing data information into a\n  ``DataFrame`` by setting the argument ``convert_missing`` to ``True``. When\n  using this options, missing values are returned as ``StataMissingValue``\n  objects and columns containing missing values have ``object`` data type. (:issue:`8045`)\n\nEnhancements in the plotting functions:\n\n- Added ``layout`` keyword to ``DataFrame.plot``. You can pass a tuple of ``(rows, columns)``, one of which can be ``-1`` to automatically infer (:issue:`6667`, :issue:`8071`).\n- Allow to pass multiple axes to ``DataFrame.plot``, ``hist`` and ``boxplot`` (:issue:`5353`, :issue:`6970`, :issue:`7069`)\n- Added support for ``c``, ``colormap`` and ``colorbar`` arguments for ``DataFrame.plot`` with ``kind='scatter'`` (:issue:`7780`)\n- Histogram from ``DataFrame.plot`` with ``kind='hist'`` (:issue:`7809`), See :ref:`the docs<visualization.hist>`.\n- Boxplot from ``DataFrame.plot`` with ``kind='box'`` (:issue:`7998`), See :ref:`the docs<visualization.box>`.\n\nOther:\n\n- ``read_csv`` now has a keyword parameter ``float_precision`` which specifies which floating-point converter the C engine should use during parsing, see :ref:`here <io.float_precision>` (:issue:`8002`, :issue:`8044`)\n\n- Added ``searchsorted`` method to ``Series`` objects (:issue:`7447`)\n\n- :func:`describe` on mixed-types DataFrames is more flexible. Type-based column filtering is now possible via the ``include``/``exclude`` arguments.\n  See the :ref:`docs <basics.describe>` (:issue:`8164`).\n\n  .. ipython:: python\n\n    df = pd.DataFrame({'catA': ['foo', 'foo', 'bar'] * 8,\n                       'catB': ['a', 'b', 'c', 'd'] * 6,\n                       'numC': np.arange(24),\n                       'numD': np.arange(24.) + .5})\n    df.describe(include=[\"object\"])\n    df.describe(include=[\"number\", \"object\"], exclude=[\"float\"])\n\n  Requesting all columns is possible with the shorthand 'all'\n\n  .. ipython:: python\n\n    df.describe(include='all')\n\n  Without those arguments, ``describe`` will behave as before, including only numerical columns or, if none are, only categorical columns. See also the :ref:`docs <basics.describe>`\n\n- Added ``split`` as an option to the ``orient`` argument in ``pd.DataFrame.to_dict``. (:issue:`7840`)\n\n- The ``get_dummies`` method can now be used on DataFrames. By default only\n  categorical columns are encoded as 0's and 1's, while other columns are\n  left untouched.\n\n  .. ipython:: python\n\n    df = pd.DataFrame({'A': ['a', 'b', 'a'], 'B': ['c', 'c', 'b'],\n                    'C': [1, 2, 3]})\n    pd.get_dummies(df)\n\n- ``PeriodIndex`` supports ``resolution`` as the same as ``DatetimeIndex`` (:issue:`7708`)\n- ``pandas.tseries.holiday`` has added support for additional holidays and ways to observe holidays (:issue:`7070`)\n- ``pandas.tseries.holiday.Holiday`` now supports a list of offsets in Python3 (:issue:`7070`)\n- ``pandas.tseries.holiday.Holiday`` now supports a days_of_week parameter (:issue:`7070`)\n- ``GroupBy.nth()`` now supports selecting multiple nth values (:issue:`7910`)\n\n  .. ipython:: python\n\n    business_dates = pd.date_range(start='4/1/2014', end='6/30/2014', freq='B')\n    df = pd.DataFrame(1, index=business_dates, columns=['a', 'b'])\n     get the first, 4th, and last date index for each month\n    df.groupby([df.index.year, df.index.month]).nth([0, 3, -1])\n\n- ``Period`` and ``PeriodIndex`` supports addition/subtraction with ``timedelta``-likes (:issue:`7966`)\n\n  If ``Period`` freq is ``D``, ``H``, ``T``, ``S``, ``L``, ``U``, ``N``, ``Timedelta``-like can be added if the result can have same freq. Otherwise, only the same ``offsets`` can be added.\n\n  .. code-block:: ipython\n\n     In [104]: idx = pd.period_range('2014-07-01 09:00', periods=5, freq='H')\n\n     In [105]: idx\n     Out[105]:\n     PeriodIndex(['2014-07-01 09:00', '2014-07-01 10:00', '2014-07-01 11:00',\n                  '2014-07-01 12:00', '2014-07-01 13:00'],\n                 dtype='period[H]')\n\n     In [106]: idx + pd.offsets.Hour(2)\n     Out[106]:\n     PeriodIndex(['2014-07-01 11:00', '2014-07-01 12:00', '2014-07-01 13:00',\n                  '2014-07-01 14:00', '2014-07-01 15:00'],\n                 dtype='period[H]')\n\n     In [107]: idx + pd.Timedelta('120m')\n     Out[107]:\n     PeriodIndex(['2014-07-01 11:00', '2014-07-01 12:00', '2014-07-01 13:00',\n                  '2014-07-01 14:00', '2014-07-01 15:00'],\n                 dtype='period[H]')\n\n     In [108]: idx = pd.period_range('2014-07', periods=5, freq='M')\n\n     In [109]: idx\n     Out[109]: PeriodIndex(['2014-07', '2014-08', '2014-09', '2014-10', '2014-11'], dtype='period[M]')\n\n     In [110]: idx + pd.offsets.MonthEnd(3)\n     Out[110]: PeriodIndex(['2014-10', '2014-11', '2014-12', '2015-01', '2015-02'], dtype='period[M]')\n\n- Added experimental compatibility with ``openpyxl`` for versions >= 2.0. The ``DataFrame.to_excel``\n  method ``engine`` keyword now recognizes ``openpyxl1`` and ``openpyxl2``\n  which will explicitly require openpyxl v1 and v2 respectively, failing if\n  the requested version is not available. The ``openpyxl`` engine is a now a\n  meta-engine that automatically uses whichever version of openpyxl is\n  installed. (:issue:`7177`)\n\n- ``DataFrame.fillna`` can now accept a ``DataFrame`` as a fill value (:issue:`8377`)\n\n- Passing multiple levels to :meth:`~pandas.DataFrame.stack()` will now work when multiple level\n  numbers are passed (:issue:`7660`). See\n  :ref:`Reshaping by stacking and unstacking <reshaping.stack_multiple>`.\n\n- :func:`set_names`, :func:`set_labels`, and :func:`set_levels` methods now take an optional ``level`` keyword argument to all modification of specific level(s) of a MultiIndex. Additionally :func:`set_names` now accepts a scalar string value when operating on an ``Index`` or on a specific level of a ``MultiIndex`` (:issue:`7792`)\n\n  .. ipython:: python\n\n      idx = pd.MultiIndex.from_product([['a'], range(3), list(\"pqr\")],\n                                       names=['foo', 'bar', 'baz'])\n      idx.set_names('qux', level=0)\n      idx.set_names(['qux', 'corge'], level=[0, 1])\n      idx.set_levels(['a', 'b', 'c'], level='bar')\n      idx.set_levels([['a', 'b', 'c'], [1, 2, 3]], level=[1, 2])\n\n- ``Index.isin`` now supports a ``level`` argument to specify which index level\n  to use for membership tests (:issue:`7892`, :issue:`7890`)\n\n  .. code-block:: ipython\n\n     In [1]: idx = pd.MultiIndex.from_product([[0, 1], ['a', 'b', 'c']])\n\n     In [2]: idx.values\n     Out[2]: array([(0, 'a'), (0, 'b'), (0, 'c'), (1, 'a'), (1, 'b'), (1, 'c')], dtype=object)\n\n     In [3]: idx.isin(['a', 'c', 'e'], level=1)\n     Out[3]: array([ True, False,  True,  True, False,  True], dtype=bool)\n\n- ``Index`` now supports ``duplicated`` and ``drop_duplicates``. (:issue:`4060`)\n\n  .. ipython:: python\n\n     idx = pd.Index([1, 2, 3, 4, 1, 2])\n     idx\n     idx.duplicated()\n     idx.drop_duplicates()\n\n- add ``copy=True`` argument to ``pd.concat`` to enable pass through of complete blocks (:issue:`8252`)\n\n- Added support for numpy 1.8+ data types (``bool_``, ``int_``, ``float_``, ``string_``) for conversion to R dataframe  (:issue:`8400`)\n\n\n\n.. _whatsnew_0150.performance:\n\nPerformance\n~~~~~~~~~~~\n\n- Performance improvements in ``DatetimeIndex.__iter__`` to allow faster iteration (:issue:`7683`)\n- Performance improvements in ``Period`` creation (and ``PeriodIndex`` setitem) (:issue:`5155`)\n- Improvements in Series.transform for significant performance gains (revised) (:issue:`6496`)\n- Performance improvements in ``StataReader`` when reading large files (:issue:`8040`, :issue:`8073`)\n- Performance improvements in ``StataWriter`` when writing large files (:issue:`8079`)\n- Performance and memory usage improvements in multi-key ``groupby`` (:issue:`8128`)\n- Performance improvements in groupby ``.agg`` and ``.apply`` where builtins max/min were not mapped to numpy/cythonized versions (:issue:`7722`)\n- Performance improvement in writing to sql (``to_sql``) of up to 50% (:issue:`8208`).\n- Performance benchmarking of groupby for large value of ngroups (:issue:`6787`)\n- Performance improvement in ``CustomBusinessDay``, ``CustomBusinessMonth`` (:issue:`8236`)\n- Performance improvement for ``MultiIndex.values`` for multi-level indexes containing datetimes (:issue:`8543`)\n\n\n\n.. _whatsnew_0150.bug_fixes:\n\nBug fixes\n~~~~~~~~~\n\n- Bug in pivot_table, when using margins and a dict aggfunc (:issue:`8349`)\n- Bug in ``read_csv`` where ``squeeze=True`` would return a view (:issue:`8217`)\n- Bug in checking of table name in ``read_sql`` in certain cases (:issue:`7826`).\n- Bug in ``DataFrame.groupby`` where ``Grouper`` does not recognize level when frequency is specified (:issue:`7885`)\n- Bug in multiindexes dtypes getting mixed up when DataFrame is saved to SQL table (:issue:`8021`)\n- Bug in ``Series`` 0-division with a float and integer operand dtypes  (:issue:`7785`)\n- Bug in ``Series.astype(\"unicode\")`` not calling ``unicode`` on the values correctly (:issue:`7758`)\n- Bug in ``DataFrame.as_matrix()`` with mixed ``datetime64[ns]`` and ``timedelta64[ns]`` dtypes (:issue:`7778`)\n- Bug in ``HDFStore.select_column()`` not preserving UTC timezone info when selecting a ``DatetimeIndex`` (:issue:`7777`)\n- Bug in ``to_datetime`` when ``format='%Y%m%d'`` and ``coerce=True`` are specified, where previously an object array was returned (rather than\n  a coerced time-series with ``NaT``), (:issue:`7930`)\n- Bug in ``DatetimeIndex`` and ``PeriodIndex`` in-place addition and subtraction cause different result from normal one (:issue:`6527`)\n- Bug in adding and subtracting ``PeriodIndex`` with ``PeriodIndex`` raise ``TypeError`` (:issue:`7741`)\n- Bug in ``combine_first`` with ``PeriodIndex`` data raises ``TypeError`` (:issue:`3367`)\n- Bug in MultiIndex slicing with missing indexers (:issue:`7866`)\n- Bug in MultiIndex slicing with various edge cases (:issue:`8132`)\n- Regression in MultiIndex indexing with a non-scalar type object (:issue:`7914`)\n- Bug in ``Timestamp`` comparisons with ``==`` and ``int64`` dtype (:issue:`8058`)\n- Bug in pickles contains ``DateOffset`` may raise ``AttributeError`` when ``normalize`` attribute is referred internally (:issue:`7748`)\n- Bug in ``Panel`` when using ``major_xs`` and ``copy=False`` is passed (deprecation warning fails because of missing ``warnings``) (:issue:`8152`).\n- Bug in pickle deserialization that failed for pre-0.14.1 containers with dup items trying to avoid ambiguity\n  when matching block and manager items, when there's only one block there's no ambiguity (:issue:`7794`)\n- Bug in putting a ``PeriodIndex`` into a ``Series`` would convert to ``int64`` dtype, rather than ``object`` of ``Periods`` (:issue:`7932`)\n- Bug in ``HDFStore`` iteration when passing a where (:issue:`8014`)\n- Bug in ``DataFrameGroupby.transform`` when transforming with a passed non-sorted key (:issue:`8046`, :issue:`8430`)\n- Bug in repeated timeseries line and area plot may result in ``ValueError`` or incorrect kind (:issue:`7733`)\n- Bug in inference in a ``MultiIndex`` with ``datetime.date`` inputs (:issue:`7888`)\n- Bug in ``get`` where an ``IndexError`` would not cause the default value to be returned (:issue:`7725`)\n- Bug in ``offsets.apply``, ``rollforward`` and ``rollback`` may reset nanosecond (:issue:`7697`)\n- Bug in ``offsets.apply``, ``rollforward`` and ``rollback`` may raise ``AttributeError`` if ``Timestamp`` has ``dateutil`` tzinfo (:issue:`7697`)\n- Bug in sorting a MultiIndex frame with a ``Float64Index`` (:issue:`8017`)\n- Bug in inconsistent panel setitem with a rhs of a ``DataFrame`` for alignment (:issue:`7763`)\n- Bug in ``is_superperiod`` and ``is_subperiod`` cannot handle higher frequencies than ``S`` (:issue:`7760`, :issue:`7772`, :issue:`7803`)\n- Bug in 32-bit platforms with ``Series.shift`` (:issue:`8129`)\n- Bug in ``PeriodIndex.unique`` returns int64 ``np.ndarray`` (:issue:`7540`)\n- Bug in ``groupby.apply`` with a non-affecting mutation in the function (:issue:`8467`)\n- Bug in ``DataFrame.reset_index`` which has ``MultiIndex`` contains ``PeriodIndex`` or ``DatetimeIndex`` with tz raises ``ValueError`` (:issue:`7746`, :issue:`7793`)\n- Bug in ``DataFrame.plot`` with ``subplots=True`` may draw unnecessary minor xticks and yticks (:issue:`7801`)\n- Bug in ``StataReader`` which did not read variable labels in 117 files due to difference between Stata documentation and implementation (:issue:`7816`)\n- Bug in ``StataReader`` where strings were always converted to 244 characters-fixed width irrespective of underlying string size (:issue:`7858`)\n- Bug in ``DataFrame.plot`` and ``Series.plot`` may ignore ``rot`` and ``fontsize`` keywords (:issue:`7844`)\n- Bug in ``DatetimeIndex.value_counts`` doesn't preserve tz  (:issue:`7735`)\n- Bug in ``PeriodIndex.value_counts`` results in ``Int64Index`` (:issue:`7735`)\n- Bug in ``DataFrame.join`` when doing left join on index and there are multiple matches (:issue:`5391`)\n- Bug in ``GroupBy.transform()`` where int groups with a transform that\n  didn't preserve the index were incorrectly truncated (:issue:`7972`).\n- Bug in ``groupby`` where callable objects without name attributes would take the wrong path,\n  and produce a ``DataFrame`` instead of a ``Series`` (:issue:`7929`)\n- Bug in ``groupby`` error message when a DataFrame grouping column is duplicated (:issue:`7511`)\n- Bug in ``read_html`` where the ``infer_types`` argument forced coercion of\n  date-likes incorrectly (:issue:`7762`, :issue:`7032`).\n- Bug in ``Series.str.cat`` with an index which was filtered as to not include the first item (:issue:`7857`)\n- Bug in ``Timestamp`` cannot parse ``nanosecond`` from string (:issue:`7878`)\n- Bug in ``Timestamp`` with string offset and ``tz`` results incorrect (:issue:`7833`)\n- Bug in ``tslib.tz_convert`` and ``tslib.tz_convert_single`` may return different results (:issue:`7798`)\n- Bug in ``DatetimeIndex.intersection`` of non-overlapping timestamps with tz raises ``IndexError`` (:issue:`7880`)\n- Bug in alignment with TimeOps and non-unique indexes (:issue:`8363`)\n- Bug in ``GroupBy.filter()`` where fast path vs. slow path made the filter\n  return a non scalar value that appeared valid but wasn't (:issue:`7870`).\n- Bug in ``date_range()``/``DatetimeIndex()`` when the timezone was inferred from input dates yet incorrect\n  times were returned when crossing DST boundaries (:issue:`7835`, :issue:`7901`).\n- Bug in ``to_excel()`` where a negative sign was being prepended to positive infinity and was absent for negative infinity (:issue:`7949`)\n- Bug in area plot draws legend with incorrect ``alpha`` when ``stacked=True`` (:issue:`8027`)\n- ``Period`` and ``PeriodIndex`` addition/subtraction with ``np.timedelta64`` results in incorrect internal representations (:issue:`7740`)\n- Bug in ``Holiday`` with no offset or observance (:issue:`7987`)\n- Bug in ``DataFrame.to_latex`` formatting when columns or index is a ``MultiIndex`` (:issue:`7982`).\n- Bug in ``DateOffset`` around Daylight Savings Time produces unexpected results (:issue:`5175`).\n- Bug in ``DataFrame.shift`` where empty columns would throw ``ZeroDivisionError`` on numpy 1.7 (:issue:`8019`)\n- Bug in installation where ``html_encoding/*.html`` wasn't installed and\n  therefore some tests were not running correctly (:issue:`7927`).\n- Bug in ``read_html`` where ``bytes`` objects were not tested for in\n  ``_read`` (:issue:`7927`).\n- Bug in ``DataFrame.stack()`` when one of the column levels was a datelike (:issue:`8039`)\n- Bug in broadcasting numpy scalars with ``DataFrame`` (:issue:`8116`)\n- Bug in ``pivot_table`` performed with nameless ``index`` and ``columns`` raises ``KeyError`` (:issue:`8103`)\n- Bug in ``DataFrame.plot(kind='scatter')`` draws points and errorbars with different colors when the color is specified by ``c`` keyword (:issue:`8081`)\n- Bug in ``Float64Index`` where ``iat`` and ``at`` were not testing and were\n  failing (:issue:`8092`).\n- Bug in ``DataFrame.boxplot()`` where y-limits were not set correctly when\n  producing multiple axes (:issue:`7528`, :issue:`5517`).\n- Bug in ``read_csv`` where line comments were not handled correctly given\n  a custom line terminator or ``delim_whitespace=True`` (:issue:`8122`).\n- Bug in ``read_html`` where empty tables caused a ``StopIteration`` (:issue:`7575`)\n- Bug in casting when setting a column in a same-dtype block (:issue:`7704`)\n- Bug in accessing groups from a ``GroupBy`` when the original grouper\n  was a tuple (:issue:`8121`).\n- Bug in ``.at`` that would accept integer indexers on a non-integer index and do fallback (:issue:`7814`)\n- Bug with kde plot and NaNs (:issue:`8182`)\n- Bug in ``GroupBy.count`` with float32 data type were nan values were not excluded (:issue:`8169`).\n- Bug with stacked barplots and NaNs (:issue:`8175`).\n- Bug in resample with non evenly divisible offsets (e.g. '7s') (:issue:`8371`)\n- Bug in interpolation methods with the ``limit`` keyword when no values needed interpolating (:issue:`7173`).\n- Bug where ``col_space`` was ignored in ``DataFrame.to_string()`` when ``header=False`` (:issue:`8230`).\n- Bug with ``DatetimeIndex.asof`` incorrectly matching partial strings and returning the wrong date (:issue:`8245`).\n- Bug in plotting methods modifying the global matplotlib rcParams (:issue:`8242`).\n- Bug in ``DataFrame.__setitem__`` that caused errors when setting a dataframe column to a sparse array (:issue:`8131`)\n- Bug where ``Dataframe.boxplot()`` failed when entire column was empty (:issue:`8181`).\n- Bug with messed variables in ``radviz`` visualization (:issue:`8199`).\n- Bug in interpolation methods with the ``limit`` keyword when no values needed interpolating (:issue:`7173`).\n- Bug where ``col_space`` was ignored in ``DataFrame.to_string()`` when ``header=False`` (:issue:`8230`).\n- Bug in ``to_clipboard`` that would clip long column data (:issue:`8305`)\n- Bug in ``DataFrame`` terminal display: Setting max_column/max_rows to zero did not trigger auto-resizing of dfs to fit terminal width/height (:issue:`7180`).\n- Bug in OLS where running with \"cluster\" and \"nw_lags\" parameters did not work correctly, but also did not throw an error\n  (:issue:`5884`).\n- Bug in ``DataFrame.dropna`` that interpreted non-existent columns in the subset argument as the 'last column' (:issue:`8303`)\n- Bug in ``Index.intersection`` on non-monotonic non-unique indexes (:issue:`8362`).\n- Bug in masked series assignment where mismatching types would break alignment (:issue:`8387`)\n- Bug in ``NDFrame.equals`` gives false negatives with dtype=object (:issue:`8437`)\n- Bug in assignment with indexer where type diversity would break alignment (:issue:`8258`)\n- Bug in ``NDFrame.loc`` indexing when row/column names were lost when target was a list/ndarray (:issue:`6552`)\n- Regression in ``NDFrame.loc`` indexing when rows/columns were converted to Float64Index if target was an empty list/ndarray (:issue:`7774`)\n- Bug in ``Series`` that allows it to be indexed by a ``DataFrame`` which has unexpected results.  Such indexing is no longer permitted (:issue:`8444`)\n- Bug in item assignment of a ``DataFrame`` with MultiIndex columns where right-hand-side columns were not aligned (:issue:`7655`)\n- Suppress FutureWarning generated by NumPy when comparing object arrays containing NaN for equality (:issue:`7065`)\n- Bug in ``DataFrame.eval()`` where the dtype of the ``not`` operator (``~``)\n  was not correctly inferred as ``bool``.\n\n\n.. _whatsnew_0.15.0.contributors:\n\nContributors\n~~~~~~~~~~~~\n\n.. contributors:: v0.14.1..v0.15.0\n\n\n.. _whatsnew_101:\n\nWhat's new in 1.0.1 (February 5, 2020)\n--------------------------------------\n\nThese are the changes in pandas 1.0.1. See :ref:`release` for a full changelog\nincluding other versions of pandas.\n\n{{ header }}\n\n.. ---------------------------------------------------------------------------\n\n.. _whatsnew_101.regressions:\n\nFixed regressions\n~~~~~~~~~~~~~~~~~\n\n- Fixed regression in :class:`DataFrame` setting values with a slice (e.g. ``df[-4:] = 1``) indexing by label instead of position (:issue:`31469`)\n- Fixed regression when indexing a ``Series`` or ``DataFrame`` indexed by ``DatetimeIndex`` with a slice containing a :class:`datetime.date` (:issue:`31501`)\n- Fixed regression in ``DataFrame.__setitem__`` raising an ``AttributeError`` with a :class:`MultiIndex` and a non-monotonic indexer (:issue:`31449`)\n- Fixed regression in :class:`Series` multiplication when multiplying a numeric :class:`Series` with >10000 elements with a timedelta-like scalar (:issue:`31457`)\n- Fixed regression in ``.groupby().agg()`` raising an ``AssertionError`` for some reductions like ``min`` on object-dtype columns (:issue:`31522`)\n- Fixed regression in ``.groupby()`` aggregations with categorical dtype using Cythonized reduction functions (e.g. ``first``) (:issue:`31450`)\n- Fixed regression in :meth:`.DataFrameGroupBy.apply` and :meth:`.SeriesGroupBy.apply` if called with a function which returned a non-pandas non-scalar object (e.g. a list or numpy array) (:issue:`31441`)\n- Fixed regression in :meth:`DataFrame.groupby` whereby taking the minimum or maximum of a column with period dtype would raise a ``TypeError``. (:issue:`31471`)\n- Fixed regression in :meth:`DataFrame.groupby` with an empty DataFrame grouping by a level of a MultiIndex (:issue:`31670`).\n- Fixed regression in :meth:`DataFrame.apply` with object dtype and non-reducing function (:issue:`31505`)\n- Fixed regression in :meth:`to_datetime` when parsing non-nanosecond resolution datetimes (:issue:`31491`)\n- Fixed regression in :meth:`~DataFrame.to_csv` where specifying an ``na_rep`` might truncate the values written (:issue:`31447`)\n- Fixed regression in :class:`Categorical` construction with ``numpy.str_`` categories (:issue:`31499`)\n- Fixed regression in :meth:`DataFrame.loc` and :meth:`DataFrame.iloc` when selecting a row containing a single ``datetime64`` or ``timedelta64`` column (:issue:`31649`)\n- Fixed regression where setting :attr:`pd.options.display.max_colwidth` was not accepting negative integer. In addition, this behavior has been deprecated in favor of using ``None`` (:issue:`31532`)\n- Fixed regression in objTOJSON.c fix return-type warning (:issue:`31463`)\n- Fixed regression in :meth:`qcut` when passed a nullable integer. (:issue:`31389`)\n- Fixed regression in assigning to a :class:`Series` using a nullable integer dtype (:issue:`31446`)\n- Fixed performance regression when indexing a ``DataFrame`` or ``Series`` with a :class:`MultiIndex` for the index using a list of labels (:issue:`31648`)\n- Fixed regression in :meth:`read_csv` used in file like object ``RawIOBase`` is not recognize ``encoding`` option (:issue:`31575`)\n\n.. ---------------------------------------------------------------------------\n\n.. _whatsnew_101.deprecations:\n\nDeprecations\n~~~~~~~~~~~~\n\n- Support for negative integer for :attr:`pd.options.display.max_colwidth` is deprecated in favor of using ``None`` (:issue:`31532`)\n\n.. ---------------------------------------------------------------------------\n\n.. _whatsnew_101.bug_fixes:\n\nBug fixes\n~~~~~~~~~\n\n**Datetimelike**\n\n- Fixed bug in :meth:`to_datetime` raising when ``cache=True`` and out-of-bound values are present (:issue:`31491`)\n\n**Numeric**\n\n- Bug in dtypes being lost in ``DataFrame.__invert__`` (``~`` operator) with mixed dtypes (:issue:`31183`)\n  and for extension-array backed ``Series`` and ``DataFrame`` (:issue:`23087`)\n\n**Plotting**\n\n- Plotting tz-aware timeseries no longer gives UserWarning (:issue:`31205`)\n\n**Interval**\n\n- Bug in :meth:`Series.shift` with ``interval`` dtype raising a ``TypeError`` when shifting an interval array of integers or datetimes (:issue:`34195`)\n\n.. ---------------------------------------------------------------------------\n\n.. _whatsnew_101.contributors:\n\nContributors\n~~~~~~~~~~~~\n\n.. contributors:: v1.0.0..v1.0.1|HEAD\n\n\n.. _whatsnew_080:\n\nVersion 0.8.0 (June 29, 2012)\n-----------------------------\n\n{{ header }}\n\n\nThis is a major release from 0.7.3 and includes extensive work on the time\nseries handling and processing infrastructure as well as a great deal of new\nfunctionality throughout the library. It includes over 700 commits from more\nthan 20 distinct authors. Most pandas 0.7.3 and earlier users should not\nexperience any issues upgrading, but due to the migration to the NumPy\ndatetime64 dtype, there may be a number of bugs and incompatibilities\nlurking. Lingering incompatibilities will be fixed ASAP in a 0.8.1 release if\nnecessary. See the :ref:`full release notes\n<release>` or issue tracker\non GitHub for a complete list.\n\nSupport for non-unique indexes\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\nAll objects can now work with non-unique indexes. Data alignment / join\noperations work according to SQL join semantics (including, if application,\nindex duplication in many-to-many joins)\n\nNumPy datetime64 dtype and 1.6 dependency\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\nTime series data are now represented using NumPy's datetime64 dtype; thus,\npandas 0.8.0 now requires at least NumPy 1.6. It has been tested and verified\nto work with the development version (1.7+) of NumPy as well which includes\nsome significant user-facing API changes. NumPy 1.6 also has a number of bugs\nhaving to do with nanosecond resolution data, so I recommend that you steer\nclear of NumPy 1.6's datetime64 API functions (though limited as they are) and\nonly interact with this data using the interface that pandas provides.\n\nSee the end of the 0.8.0 section for a \"porting\" guide listing potential issues\nfor users migrating legacy code bases from pandas 0.7 or earlier to 0.8.0.\n\nBug fixes to the 0.7.x series for legacy NumPy < 1.6 users will be provided as\nthey arise. There will be no more further development in 0.7.x beyond bug\nfixes.\n\nTime Series changes and improvements\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\n.. note::\n\n    With this release, legacy scikits.timeseries users should be able to port\n    their code to use pandas.\n\n.. note::\n\n    See :ref:`documentation <timeseries>` for overview of pandas timeseries API.\n\n- New datetime64 representation **speeds up join operations and data\n  alignment**, **reduces memory usage**, and improve serialization /\n  deserialization performance significantly over datetime.datetime\n- High performance and flexible **resample** method for converting from\n  high-to-low and low-to-high frequency. Supports interpolation, user-defined\n  aggregation functions, and control over how the intervals and result labeling\n  are defined. A suite of high performance Cython/C-based resampling functions\n  (including Open-High-Low-Close) have also been implemented.\n- Revamp of :ref:`frequency aliases <timeseries.offset_aliases>` and support for\n  **frequency shortcuts** like '15min', or '1h30min'\n- New :ref:`DatetimeIndex class <timeseries.datetimeindex>` supports both fixed\n  frequency and irregular time\n  series. Replaces now deprecated DateRange class\n- New ``PeriodIndex`` and ``Period`` classes for representing\n  :ref:`time spans <timeseries.periods>` and performing **calendar logic**,\n  including the ``12 fiscal quarterly frequencies <timeseries.quarterly>``.\n  This is a partial port of, and a substantial enhancement to,\n  elements of the scikits.timeseries code base. Support for conversion between\n  PeriodIndex and DatetimeIndex\n- New Timestamp data type subclasses ``datetime.datetime``, providing the same\n  interface while enabling working with nanosecond-resolution data. Also\n  provides :ref:`easy time zone conversions <timeseries.timezone>`.\n- Enhanced support for :ref:`time zones <timeseries.timezone>`. Add\n  ``tz_convert`` and ``tz_localize`` methods to TimeSeries and DataFrame. All\n  timestamps are stored as UTC; Timestamps from DatetimeIndex objects with time\n  zone set will be localized to local time. Time zone conversions are therefore\n  essentially free. User needs to know very little about pytz library now; only\n  time zone names as strings are required. Time zone-aware timestamps are\n  equal if and only if their UTC timestamps match. Operations between time\n  zone-aware time series with different time zones will result in a UTC-indexed\n  time series.\n- Time series **string indexing conveniences** / shortcuts: slice years, year\n  and month, and index values with strings\n- Enhanced time series **plotting**; adaptation of scikits.timeseries\n  matplotlib-based plotting code\n- New ``date_range``, ``bdate_range``, and ``period_range`` :ref:`factory\n  functions <timeseries.daterange>`\n- Robust **frequency inference** function ``infer_freq`` and ``inferred_freq``\n  property of DatetimeIndex, with option to infer frequency on construction of\n  DatetimeIndex\n- to_datetime function efficiently **parses array of strings** to\n  DatetimeIndex. DatetimeIndex will parse array or list of strings to\n  datetime64\n- **Optimized** support for datetime64-dtype data in Series and DataFrame\n  columns\n- New NaT (Not-a-Time) type to represent **NA** in timestamp arrays\n- Optimize Series.asof for looking up **\"as of\" values** for arrays of\n  timestamps\n- Milli, Micro, Nano date offset objects\n- Can index time series with datetime.time objects to select all data at\n  particular **time of day** (``TimeSeries.at_time``) or **between two times**\n  (``TimeSeries.between_time``)\n- Add :ref:`tshift <timeseries.advanced_datetime>` method for leading/lagging\n  using the frequency (if any) of the index, as opposed to a naive lead/lag\n  using shift\n\nOther new features\n~~~~~~~~~~~~~~~~~~\n\n- New :ref:`cut <reshaping.tile.cut>` and ``qcut`` functions (like R's cut\n  function) for computing a categorical variable from a continuous variable by\n  binning values either into value-based (``cut``) or quantile-based (``qcut``)\n  bins\n- Rename ``Factor`` to ``Categorical`` and add a number of usability features\n- Add :ref:`limit <missing_data.fillna.limit>` argument to fillna/reindex\n- More flexible multiple function application in GroupBy, and can pass list\n  (name, function) tuples to get result in particular order with given names\n- Add flexible :ref:`replace <missing_data.replace>` method for efficiently\n  substituting values\n- Enhanced :ref:`read_csv/read_table <io.parse_dates>` for reading time series\n  data and converting multiple columns to dates\n- Add :ref:`comments <io.comments>` option to parser functions: read_csv, etc.\n- Add :ref:`dayfirst <io.dayfirst>` option to parser functions for parsing\n  international DD/MM/YYYY dates\n- Allow the user to specify the CSV reader :ref:`dialect <io.dialect>` to\n  control quoting etc.\n- Handling :ref:`thousands <io.thousands>` separators in read_csv to improve\n  integer parsing.\n- Enable unstacking of multiple levels in one shot. Alleviate ``pivot_table``\n  bugs (empty columns being introduced)\n- Move to klib-based hash tables for indexing; better performance and less\n  memory usage than Python's dict\n- Add first, last, min, max, and prod optimized GroupBy functions\n- New :ref:`ordered_merge <merging.merge_ordered>` function\n- Add flexible :ref:`comparison <basics.binop>` instance methods eq, ne, lt,\n  gt, etc. to DataFrame, Series\n- Improve :ref:`scatter_matrix <visualization.scatter_matrix>` plotting\n  function and add histogram or kernel density estimates to diagonal\n- Add :ref:`'kde' <visualization.kde>` plot option for density plots\n- Support for converting DataFrame to R data.frame through rpy2\n- Improved support for complex numbers in Series and DataFrame\n- Add ``pct_change`` method to all data structures\n- Add max_colwidth configuration option for DataFrame console output\n- :ref:`Interpolate <missing_data.interpolate>` Series values using index values\n- Can select multiple columns from GroupBy\n- Add :ref:`update <merging.combine_first.update>` methods to Series/DataFrame\n  for updating values in place\n- Add ``any`` and ``all`` method to DataFrame\n\nNew plotting methods\n~~~~~~~~~~~~~~~~~~~~\n\n.. code-block:: python\n\n   import pandas as pd\n\n   fx = pd.read_pickle(\"data/fx_prices\")\n   import matplotlib.pyplot as plt\n\n``Series.plot`` now supports a ``secondary_y`` option:\n\n.. code-block:: python\n\n   plt.figure()\n\n   fx[\"FR\"].plot(style=\"g\")\n\n   fx[\"IT\"].plot(style=\"k--\", secondary_y=True)\n\nVytautas Jancauskas, the 2012 GSOC participant, has added many new plot\ntypes. For example, ``'kde'`` is a new option:\n\n.. code-block:: python\n\n   s = pd.Series(\n       np.concatenate((np.random.randn(1000), np.random.randn(1000) * 0.5 + 3))\n   )\n   plt.figure()\n   s.hist(density=True, alpha=0.2)\n   s.plot(kind=\"kde\")\n\nSee :ref:`the plotting page <visualization.other>` for much more.\n\nOther API changes\n~~~~~~~~~~~~~~~~~\n\n- Deprecation of ``offset``, ``time_rule``, and ``timeRule`` arguments names in\n  time series functions. Warnings will be printed until pandas 0.9 or 1.0.\n\nPotential porting issues for pandas <= 0.7.3 users\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\nThe major change that may affect you in pandas 0.8.0 is that time series\nindexes use NumPy's ``datetime64`` data type instead of ``dtype=object`` arrays\nof Python's built-in ``datetime.datetime`` objects. ``DateRange`` has been\nreplaced by ``DatetimeIndex`` but otherwise behaved identically. But, if you\nhave code that converts ``DateRange`` or ``Index`` objects that used to contain\n``datetime.datetime`` values to plain NumPy arrays, you may have bugs lurking\nwith code using scalar values because you are handing control over to NumPy:\n\n.. ipython:: python\n\n   import datetime\n\n   rng = pd.date_range(\"1/1/2000\", periods=10)\n   rng[5]\n   isinstance(rng[5], datetime.datetime)\n   rng_asarray = np.asarray(rng)\n   scalar_val = rng_asarray[5]\n   type(scalar_val)\n\npandas's ``Timestamp`` object is a subclass of ``datetime.datetime`` that has\nnanosecond support (the ``nanosecond`` field store the nanosecond value between\n0 and 999). It should substitute directly into any code that used\n``datetime.datetime`` values before. Thus, I recommend not casting\n``DatetimeIndex`` to regular NumPy arrays.\n\nIf you have code that requires an array of ``datetime.datetime`` objects, you\nhave a couple of options. First, the ``astype(object)`` method of ``DatetimeIndex``\nproduces an array of ``Timestamp`` objects:\n\n.. ipython:: python\n\n   stamp_array = rng.astype(object)\n   stamp_array\n   stamp_array[5]\n\nTo get an array of proper ``datetime.datetime`` objects, use the\n``to_pydatetime`` method:\n\n.. ipython:: python\n\n   dt_array = rng.to_pydatetime()\n   dt_array\n   dt_array[5]\n\nmatplotlib knows how to handle ``datetime.datetime`` but not Timestamp\nobjects. While I recommend that you plot time series using ``TimeSeries.plot``,\nyou can either use ``to_pydatetime`` or register a converter for the Timestamp\ntype. See `matplotlib documentation\n<http://matplotlib.org/api/units_api.html>`__ for more on this.\n\n.. warning::\n\n    There are bugs in the user-facing API with the nanosecond datetime64 unit\n    in NumPy 1.6. In particular, the string version of the array shows garbage\n    values, and conversion to ``dtype=object`` is similarly broken.\n\n    .. ipython:: python\n\n       rng = pd.date_range(\"1/1/2000\", periods=10)\n       rng\n       np.asarray(rng)\n       converted = np.asarray(rng, dtype=object)\n       converted[5]\n\n    **Trust me: don't panic**. If you are using NumPy 1.6 and restrict your\n    interaction with ``datetime64`` values to pandas's API you will be just\n    fine. There is nothing wrong with the data-type (a 64-bit integer\n    internally); all of the important data processing happens in pandas and is\n    heavily tested. I strongly recommend that you **do not work directly with\n    datetime64 arrays in NumPy 1.6** and only use the pandas API.\n\n\n**Support for non-unique indexes**: In the latter case, you may have code\ninside a ``try:... catch:`` block that failed due to the index not being\nunique. In many cases it will no longer fail (some method like ``append`` still\ncheck for uniqueness unless disabled). However, all is not lost: you can\ninspect ``index.is_unique`` and raise an exception explicitly if it is\n``False`` or go to a different code branch.\n\n\n.. _whatsnew_0.8.0.contributors:\n\nContributors\n~~~~~~~~~~~~\n\n.. contributors:: v0.7.3..v0.8.0\n\n\n.. _whatsnew_153:\n\nWhat's new in 1.5.3 (January 18, 2023)\n--------------------------------------\n\nThese are the changes in pandas 1.5.3. See :ref:`release` for a full changelog\nincluding other versions of pandas.\n\n{{ header }}\n\n.. ---------------------------------------------------------------------------\n.. _whatsnew_153.regressions:\n\nFixed regressions\n~~~~~~~~~~~~~~~~~\n- Fixed performance regression in :meth:`Series.isin` when ``values`` is empty (:issue:`49839`)\n- Fixed regression in :meth:`DataFrame.memory_usage` showing unnecessary ``FutureWarning`` when :class:`DataFrame` is empty (:issue:`50066`)\n- Fixed regression in :meth:`.DataFrameGroupBy.transform` when used with ``as_index=False`` (:issue:`49834`)\n- Enforced reversion of ``color`` as an alias for ``c`` and ``size`` as an alias for ``s`` in function :meth:`DataFrame.plot.scatter` (:issue:`49732`)\n- Fixed regression in :meth:`.SeriesGroupBy.apply` setting a ``name`` attribute on the result if the result was a :class:`DataFrame` (:issue:`49907`)\n- Fixed performance regression in setting with the :meth:`~DataFrame.at` indexer (:issue:`49771`)\n- Fixed regression in :func:`to_datetime` raising ``ValueError`` when parsing array of ``float`` containing ``np.nan`` (:issue:`50237`)\n\n.. ---------------------------------------------------------------------------\n.. _whatsnew_153.bug_fixes:\n\nBug fixes\n~~~~~~~~~\n- Bug in the Copy-on-Write implementation losing track of views when indexing a :class:`DataFrame` with another :class:`DataFrame` (:issue:`50630`)\n- Bug in :meth:`.Styler.to_excel` leading to error when unrecognized ``border-style`` (e.g. ``\"hair\"``) provided to Excel writers (:issue:`48649`)\n- Bug in :meth:`Series.quantile` emitting warning from NumPy when :class:`Series` has only ``NA`` values (:issue:`50681`)\n- Bug when chaining several :meth:`.Styler.concat` calls, only the last styler was concatenated (:issue:`49207`)\n- Fixed bug when instantiating a :class:`DataFrame` subclass inheriting from ``typing.Generic`` that triggered a ``UserWarning`` on python 3.11 (:issue:`49649`)\n- Bug in :func:`pivot_table` with NumPy 1.24 or greater when the :class:`DataFrame` columns has nested elements (:issue:`50342`)\n- Bug in :func:`pandas.testing.assert_series_equal` (and equivalent ``assert_`` functions) when having nested data and using numpy >= 1.25 (:issue:`50360`)\n\n.. ---------------------------------------------------------------------------\n.. _whatsnew_153.other:\n\nOther\n~~~~~\n\n.. note::\n\n    If you are using :meth:`DataFrame.to_sql`, :func:`read_sql`, :func:`read_sql_table`, or :func:`read_sql_query` with SQLAlchemy 1.4.46 or greater,\n    you may see a ``sqlalchemy.exc.RemovedIn20Warning``. These warnings can be safely ignored for the SQLAlchemy 1.4.x releases\n    as pandas works toward compatibility with SQLAlchemy 2.0.\n\n- Reverted deprecation (:issue:`45324`) of behavior of :meth:`Series.__getitem__` and :meth:`Series.__setitem__` slicing with an integer :class:`Index`; this will remain positional (:issue:`49612`)\n- A ``FutureWarning`` raised when attempting to set values inplace with :meth:`DataFrame.loc` or :meth:`DataFrame.iloc` has been changed to a ``DeprecationWarning`` (:issue:`48673`)\n\n.. ---------------------------------------------------------------------------\n.. _whatsnew_153.contributors:\n\nContributors\n~~~~~~~~~~~~\n\n.. contributors:: v1.5.2..v1.5.3\n\n\n.. _whatsnew_0101:\n\nVersion 0.10.1 (January 22, 2013)\n---------------------------------\n\n{{ header }}\n\n\nThis is a minor release from 0.10.0 and includes new features, enhancements,\nand bug fixes. In particular, there is substantial new HDFStore functionality\ncontributed by Jeff Reback.\n\nAn undesired API breakage with functions taking the ``inplace`` option has been\nreverted and deprecation warnings added.\n\nAPI changes\n~~~~~~~~~~~\n\n- Functions taking an ``inplace`` option return the calling object as before. A\n  deprecation message has been added\n- Groupby aggregations Max/Min no longer exclude non-numeric data (:issue:`2700`)\n- Resampling an empty DataFrame now returns an empty DataFrame instead of\n  raising an exception (:issue:`2640`)\n- The file reader will now raise an exception when NA values are found in an\n  explicitly specified integer column instead of converting the column to float\n  (:issue:`2631`)\n- DatetimeIndex.unique now returns a DatetimeIndex with the same name and\n- timezone instead of an array (:issue:`2563`)\n\nNew features\n~~~~~~~~~~~~\n\n- MySQL support for database (contribution from Dan Allan)\n\nHDFStore\n~~~~~~~~\n\nYou may need to upgrade your existing data files. Please visit the\n**compatibility** section in the main docs.\n\n\n.. ipython:: python\n   :suppress:\n   :okexcept:\n\n   import os\n\n   os.remove(\"store.h5\")\n\nYou can designate (and index) certain columns that you want to be able to\nperform queries on a table, by passing a list to ``data_columns``\n\n.. ipython:: python\n\n   store = pd.HDFStore(\"store.h5\")\n   df = pd.DataFrame(\n       np.random.randn(8, 3),\n       index=pd.date_range(\"1/1/2000\", periods=8),\n       columns=[\"A\", \"B\", \"C\"],\n   )\n   df[\"string\"] = \"foo\"\n   df.loc[df.index[4:6], \"string\"] = np.nan\n   df.loc[df.index[7:9], \"string\"] = \"bar\"\n   df[\"string2\"] = \"cool\"\n   df\n\n    on-disk operations\n   store.append(\"df\", df, data_columns=[\"B\", \"C\", \"string\", \"string2\"])\n   store.select(\"df\", \"B>0 and string=='foo'\")\n\n    this is in-memory version of this type of selection\n   df[(df.B > 0) & (df.string == \"foo\")]\n\nRetrieving unique values in an indexable or data column.\n\n.. code-block:: python\n\n    note that this is deprecated as of 0.14.0\n    can be replicated by: store.select_column('df','index').unique()\n   store.unique(\"df\", \"index\")\n   store.unique(\"df\", \"string\")\n\nYou can now store ``datetime64`` in data columns\n\n.. ipython:: python\n\n    df_mixed = df.copy()\n    df_mixed[\"datetime64\"] = pd.Timestamp(\"20010102\")\n    df_mixed.loc[df_mixed.index[3:4], [\"A\", \"B\"]] = np.nan\n\n    store.append(\"df_mixed\", df_mixed)\n    df_mixed1 = store.select(\"df_mixed\")\n    df_mixed1\n    df_mixed1.dtypes.value_counts()\n\nYou can pass ``columns`` keyword to select to filter a list of the return\ncolumns, this is equivalent to passing a\n``Term('columns',list_of_columns_to_filter)``\n\n.. ipython:: python\n\n   store.select(\"df\", columns=[\"A\", \"B\"])\n\n``HDFStore`` now serializes MultiIndex dataframes when appending tables.\n\n.. code-block:: ipython\n\n    In [19]: index = pd.MultiIndex(levels=[['foo', 'bar', 'baz', 'qux'],\n       ....:                               ['one', 'two', 'three']],\n       ....:                       labels=[[0, 0, 0, 1, 1, 2, 2, 3, 3, 3],\n       ....:                               [0, 1, 2, 0, 1, 1, 2, 0, 1, 2]],\n       ....:                       names=['foo', 'bar'])\n       ....:\n\n    In [20]: df = pd.DataFrame(np.random.randn(10, 3), index=index,\n       ....:                   columns=['A', 'B', 'C'])\n       ....:\n\n    In [21]: df\n    Out[21]:\n                      A         B         C\n    foo bar\n    foo one   -0.116619  0.295575 -1.047704\n        two    1.640556  1.905836  2.772115\n        three  0.088787 -1.144197 -0.633372\n    bar one    0.925372 -0.006438 -0.820408\n        two   -0.600874 -1.039266  0.824758\n    baz two   -0.824095 -0.337730 -0.927764\n        three -0.840123  0.248505 -0.109250\n    qux one    0.431977 -0.460710  0.336505\n        two   -3.207595 -1.535854  0.409769\n        three -0.673145 -0.741113 -0.110891\n\n    In [22]: store.append('mi', df)\n\n    In [23]: store.select('mi')\n    Out[23]:\n                      A         B         C\n    foo bar\n    foo one   -0.116619  0.295575 -1.047704\n        two    1.640556  1.905836  2.772115\n        three  0.088787 -1.144197 -0.633372\n    bar one    0.925372 -0.006438 -0.820408\n        two   -0.600874 -1.039266  0.824758\n    baz two   -0.824095 -0.337730 -0.927764\n        three -0.840123  0.248505 -0.109250\n    qux one    0.431977 -0.460710  0.336505\n        two   -3.207595 -1.535854  0.409769\n        three -0.673145 -0.741113 -0.110891\n\n     the levels are automatically included as data columns\n    In [24]: store.select('mi', \"foo='bar'\")\n    Out[24]:\n                    A         B         C\n    foo bar\n    bar one  0.925372 -0.006438 -0.820408\n        two -0.600874 -1.039266  0.824758\n\nMulti-table creation via ``append_to_multiple`` and selection via\n``select_as_multiple`` can create/select from multiple tables and return a\ncombined result, by using ``where`` on a selector table.\n\n.. ipython:: python\n\n   df_mt = pd.DataFrame(\n       np.random.randn(8, 6),\n       index=pd.date_range(\"1/1/2000\", periods=8),\n       columns=[\"A\", \"B\", \"C\", \"D\", \"E\", \"F\"],\n   )\n   df_mt[\"foo\"] = \"bar\"\n\n    you can also create the tables individually\n   store.append_to_multiple(\n       {\"df1_mt\": [\"A\", \"B\"], \"df2_mt\": None}, df_mt, selector=\"df1_mt\"\n   )\n   store\n\n    individual tables were created\n   store.select(\"df1_mt\")\n   store.select(\"df2_mt\")\n\n    as a multiple\n   store.select_as_multiple(\n       [\"df1_mt\", \"df2_mt\"], where=[\"A>0\", \"B>0\"], selector=\"df1_mt\"\n   )\n\n.. ipython:: python\n   :suppress:\n\n   store.close()\n   os.remove(\"store.h5\")\n\n**Enhancements**\n\n- ``HDFStore`` now can read native PyTables table format tables\n\n- You can pass ``nan_rep = 'my_nan_rep'`` to append, to change the default nan\n  representation on disk (which converts to/from ``np.nan``), this defaults to\n  ``nan``.\n\n- You can pass ``index`` to ``append``. This defaults to ``True``. This will\n  automagically create indices on the *indexables* and *data columns* of the\n  table\n\n- You can pass ``chunksize=an integer`` to ``append``, to change the writing\n  chunksize (default is 50000). This will significantly lower your memory usage\n  on writing.\n\n- You can pass ``expectedrows=an integer`` to the first ``append``, to set the\n  TOTAL number of expected rows that ``PyTables`` will expected. This will\n  optimize read/write performance.\n\n- ``Select`` now supports passing ``start`` and ``stop`` to provide selection\n  space limiting in selection.\n\n- Greatly improved ISO8601 (e.g., yyyy-mm-dd) date parsing for file parsers (:issue:`2698`)\n- Allow ``DataFrame.merge`` to handle combinatorial sizes too large for 64-bit\n  integer (:issue:`2690`)\n- Series now has unary negation (-series) and inversion (~series) operators (:issue:`2686`)\n- DataFrame.plot now includes a ``logx`` parameter to change the x-axis to log scale (:issue:`2327`)\n- Series arithmetic operators can now handle constant and ndarray input (:issue:`2574`)\n- ExcelFile now takes a ``kind`` argument to specify the file type (:issue:`2613`)\n- A faster implementation for Series.str methods (:issue:`2602`)\n\n**Bug Fixes**\n\n- ``HDFStore`` tables can now store ``float32`` types correctly (cannot be\n  mixed with ``float64`` however)\n- Fixed Google Analytics prefix when specifying request segment (:issue:`2713`).\n- Function to reset Google Analytics token store so users can recover from\n  improperly setup client secrets (:issue:`2687`).\n- Fixed groupby bug resulting in segfault when passing in MultiIndex (:issue:`2706`)\n- Fixed bug where passing a Series with datetime64 values into ``to_datetime``\n  results in bogus output values (:issue:`2699`)\n- Fixed bug in ``pattern in HDFStore`` expressions when pattern is not a valid\n  regex (:issue:`2694`)\n- Fixed performance issues while aggregating boolean data (:issue:`2692`)\n- When given a boolean mask key and a Series of new values, Series __setitem__\n  will now align the incoming values with the original Series (:issue:`2686`)\n- Fixed MemoryError caused by performing counting sort on sorting MultiIndex\n  levels with a very large number of combinatorial values (:issue:`2684`)\n- Fixed bug that causes plotting to fail when the index is a DatetimeIndex with\n  a fixed-offset timezone (:issue:`2683`)\n- Corrected business day subtraction logic when the offset is more than 5 bdays\n  and the starting date is on a weekend (:issue:`2680`)\n- Fixed C file parser behavior when the file has more columns than data\n  (:issue:`2668`)\n- Fixed file reader bug that misaligned columns with data in the presence of an\n  implicit column and a specified ``usecols`` value\n- DataFrames with numerical or datetime indices are now sorted prior to\n  plotting (:issue:`2609`)\n- Fixed DataFrame.from_records error when passed columns, index, but empty\n  records (:issue:`2633`)\n- Several bug fixed for Series operations when dtype is datetime64 (:issue:`2689`,\n  :issue:`2629`, :issue:`2626`)\n\n\nSee the :ref:`full release notes\n<release>` or issue tracker\non GitHub for a complete list.\n\n\n.. _whatsnew_0.10.1.contributors:\n\nContributors\n~~~~~~~~~~~~\n\n.. contributors:: v0.10.0..v0.10.1\n\n\n.. _whatsnew_212:\n\nWhat's new in 2.1.2 (October 26, 2023)\n---------------------------------------\n\nThese are the changes in pandas 2.1.2. See :ref:`release` for a full changelog\nincluding other versions of pandas.\n\n{{ header }}\n\n.. ---------------------------------------------------------------------------\n.. _whatsnew_212.deprecations:\n\nDeprecations\n~~~~~~~~~~~~\n\n- Reverted deprecation of ``fill_method=None`` in :meth:`DataFrame.pct_change`, :meth:`Series.pct_change`, :meth:`DataFrameGroupBy.pct_change`, and :meth:`SeriesGroupBy.pct_change`; the values ``'backfill'``, ``'bfill'``, ``'pad'``, and ``'ffill'`` are still deprecated (:issue:`53491`)\n\n.. ---------------------------------------------------------------------------\n.. _whatsnew_212.regressions:\n\nFixed regressions\n~~~~~~~~~~~~~~~~~\n- Fixed regression in :meth:`DataFrame.join` where result has missing values and dtype is arrow backed string (:issue:`55348`)\n- Fixed regression in :meth:`~DataFrame.rolling` where non-nanosecond index or ``on`` column would produce incorrect results (:issue:`55026`, :issue:`55106`, :issue:`55299`)\n- Fixed regression in :meth:`DataFrame.resample` which was extrapolating back to ``origin`` when ``origin`` was outside its bounds (:issue:`55064`)\n- Fixed regression in :meth:`DataFrame.sort_index` which was not sorting correctly when the index was a sliced :class:`MultiIndex` (:issue:`55379`)\n- Fixed regression in :meth:`DataFrameGroupBy.agg` and :meth:`SeriesGroupBy.agg` where if the option ``compute.use_numba`` was set to True, groupby methods not supported by the numba engine would raise a ``TypeError`` (:issue:`55520`)\n- Fixed performance regression with wide DataFrames, typically involving methods where all columns were accessed individually (:issue:`55256`, :issue:`55245`)\n- Fixed regression in :func:`merge_asof` raising ``TypeError`` for ``by`` with datetime and timedelta dtypes (:issue:`55453`)\n- Fixed regression in :func:`read_parquet` when reading a file with a string column consisting of more than 2 GB of string data and using the ``\"string\"`` dtype (:issue:`55606`)\n- Fixed regression in :meth:`DataFrame.to_sql` not roundtripping datetime columns correctly for sqlite when using ``detect_types`` (:issue:`55554`)\n- Fixed regression in construction of certain DataFrame or Series subclasses (:issue:`54922`)\n\n.. ---------------------------------------------------------------------------\n.. _whatsnew_212.bug_fixes:\n\nBug fixes\n~~~~~~~~~\n- Fixed bug in :class:`.DataFrameGroupBy` reductions not preserving object dtype when ``infer_string`` is set (:issue:`55620`)\n- Fixed bug in :meth:`.SeriesGroupBy.value_counts` returning incorrect dtype for string columns (:issue:`55627`)\n- Fixed bug in :meth:`Categorical.equals` if other has arrow backed string dtype (:issue:`55364`)\n- Fixed bug in :meth:`DataFrame.__setitem__` not inferring string dtype for zero-dimensional array with ``infer_string=True`` (:issue:`55366`)\n- Fixed bug in :meth:`DataFrame.idxmin` and :meth:`DataFrame.idxmax` raising for arrow dtypes (:issue:`55368`)\n- Fixed bug in :meth:`DataFrame.interpolate` raising incorrect error message (:issue:`55347`)\n- Fixed bug in :meth:`Index.insert` raising when inserting ``None`` into :class:`Index` with ``dtype=\"string[pyarrow_numpy]\"`` (:issue:`55365`)\n- Fixed bug in :meth:`Series.all`  and :meth:`Series.any` not treating missing values correctly for ``dtype=\"string[pyarrow_numpy]\"`` (:issue:`55367`)\n- Fixed bug in :meth:`Series.floordiv` for :class:`ArrowDtype` (:issue:`55561`)\n- Fixed bug in :meth:`Series.mode` not sorting values for arrow backed string dtype (:issue:`55621`)\n- Fixed bug in :meth:`Series.rank` for ``string[pyarrow_numpy]`` dtype (:issue:`55362`)\n- Fixed bug in :meth:`Series.str.extractall` for :class:`ArrowDtype` dtype being converted to object (:issue:`53846`)\n- Fixed bug where PDEP-6 warning about setting an item of an incompatible dtype was being shown when creating a new conditional column (:issue:`55025`)\n- Silence ``Period[B]`` warnings introduced by :issue:`53446` during normal plotting activity (:issue:`55138`)\n- Fixed bug in :class:`Series` constructor not inferring string dtype when ``NA`` is the first value and ``infer_string`` is set (:issue:` 55655`)\n\n.. ---------------------------------------------------------------------------\n.. _whatsnew_212.other:\n\nOther\n~~~~~\n- Fixed non-working installation of optional dependency group ``output_formatting``. Replacing underscore ``_`` with a dash ``-`` fixes broken dependency resolution. A correct way to use now is ``pip install pandas[output-formatting]``.\n-\n\n.. ---------------------------------------------------------------------------\n.. _whatsnew_212.contributors:\n\nContributors\n~~~~~~~~~~~~\n\n.. contributors:: v2.1.1..v2.1.2\n\n\n.. _whatsnew_0200:\n\nVersion 0.20.1 (May 5, 2017)\n----------------------------\n\n{{ header }}\n\nThis is a major release from 0.19.2 and includes a number of API changes, deprecations, new features,\nenhancements, and performance improvements along with a large number of bug fixes. We recommend that all\nusers upgrade to this version.\n\nHighlights include:\n\n- New ``.agg()`` API for Series/DataFrame similar to the groupby-rolling-resample API's, see :ref:`here <whatsnew_0200.enhancements.agg>`\n- Integration with the ``feather-format``, including a new top-level ``pd.read_feather()`` and ``DataFrame.to_feather()`` method, see :ref:`here <io.feather>`.\n- The ``.ix`` indexer has been deprecated, see :ref:`here <whatsnew_0200.api_breaking.deprecate_ix>`\n- ``Panel`` has been deprecated, see :ref:`here <whatsnew_0200.api_breaking.deprecate_panel>`\n- Addition of an ``IntervalIndex`` and ``Interval`` scalar type, see :ref:`here <whatsnew_0200.enhancements.intervalindex>`\n- Improved user API when grouping by index levels in ``.groupby()``, see :ref:`here <whatsnew_0200.enhancements.groupby_access>`\n- Improved support for ``UInt64`` dtypes, see :ref:`here <whatsnew_0200.enhancements.uint64_support>`\n- A new orient for JSON serialization, ``orient='table'``, that uses the Table Schema spec and that gives the possibility for a more interactive repr in the Jupyter Notebook, see :ref:`here <whatsnew_0200.enhancements.table_schema>`\n- Experimental support for exporting styled DataFrames (``DataFrame.style``) to Excel, see :ref:`here <whatsnew_0200.enhancements.style_excel>`\n- Window binary corr/cov operations now return a MultiIndexed ``DataFrame`` rather than a ``Panel``, as ``Panel`` is now deprecated, see :ref:`here <whatsnew_0200.api_breaking.rolling_pairwise>`\n- Support for S3 handling now uses ``s3fs``, see :ref:`here <whatsnew_0200.api_breaking.s3>`\n- Google BigQuery support now uses the ``pandas-gbq`` library, see :ref:`here <whatsnew_0200.api_breaking.gbq>`\n\n.. warning::\n\n  pandas has changed the internal structure and layout of the code base.\n  This can affect imports that are not from the top-level ``pandas.*`` namespace, please see the changes :ref:`here <whatsnew_0200.privacy>`.\n\nCheck the :ref:`API Changes <whatsnew_0200.api_breaking>` and :ref:`deprecations <whatsnew_0200.deprecations>` before updating.\n\n.. note::\n\n   This is a combined release for 0.20.0 and 0.20.1.\n   Version 0.20.1 contains one additional change for backwards-compatibility with downstream projects using pandas' ``utils`` routines. (:issue:`16250`)\n\n.. contents:: What's new in v0.20.0\n    :local:\n    :backlinks: none\n\n.. _whatsnew_0200.enhancements:\n\nNew features\n~~~~~~~~~~~~\n\n.. _whatsnew_0200.enhancements.agg:\n\nMethod ``agg`` API for DataFrame/Series\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nSeries & DataFrame have been enhanced to support the aggregation API. This is a familiar API\nfrom groupby, window operations, and resampling. This allows aggregation operations in a concise way\nby using :meth:`~DataFrame.agg` and :meth:`~DataFrame.transform`. The full documentation\nis :ref:`here <basics.aggregate>` (:issue:`1623`).\n\nHere is a sample\n\n.. ipython:: python\n\n   df = pd.DataFrame(np.random.randn(10, 3), columns=['A', 'B', 'C'],\n                     index=pd.date_range('1/1/2000', periods=10))\n   df.iloc[3:7] = np.nan\n   df\n\nOne can operate using string function names, callables, lists, or dictionaries of these.\n\nUsing a single function is equivalent to ``.apply``.\n\n.. ipython:: python\n\n   df.agg('sum')\n\nMultiple aggregations with a list of functions.\n\n.. ipython:: python\n\n   df.agg(['sum', 'min'])\n\nUsing a dict provides the ability to apply specific aggregations per column.\nYou will get a matrix-like output of all of the aggregators. The output has one column\nper unique function. Those functions applied to a particular column will be ``NaN``:\n\n.. ipython:: python\n\n   df.agg({'A': ['sum', 'min'], 'B': ['min', 'max']})\n\nThe API also supports a ``.transform()`` function for broadcasting results.\n\n.. ipython:: python\n   :okwarning:\n\n   df.transform(['abs', lambda x: x - x.min()])\n\nWhen presented with mixed dtypes that cannot be aggregated, ``.agg()`` will only take the valid\naggregations. This is similar to how groupby ``.agg()`` works. (:issue:`15015`)\n\n.. ipython:: python\n\n   df = pd.DataFrame({'A': [1, 2, 3],\n                      'B': [1., 2., 3.],\n                      'C': ['foo', 'bar', 'baz'],\n                      'D': pd.date_range('20130101', periods=3)})\n   df.dtypes\n\n.. code-block:: python\n\n   In [10]: df.agg(['min', 'sum'])\n   Out[10]:\n        A    B          C          D\n   min  1  1.0        bar 2013-01-01\n   sum  6  6.0  foobarbaz        NaT\n\n.. _whatsnew_0200.enhancements.dataio_dtype:\n\nKeyword argument ``dtype`` for data IO\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nThe ``'python'`` engine for :func:`read_csv`, as well as the :func:`read_fwf` function for parsing\nfixed-width text files and :func:`read_excel` for parsing Excel files, now accept the ``dtype`` keyword argument for specifying the types of specific columns (:issue:`14295`). See the :ref:`io docs <io.dtypes>` for more information.\n\n.. ipython:: python\n   :suppress:\n\n   from io import StringIO\n\n.. ipython:: python\n\n   data = \"a  b\\n1  2\\n3  4\"\n   pd.read_fwf(StringIO(data)).dtypes\n   pd.read_fwf(StringIO(data), dtype={'a': 'float64', 'b': 'object'}).dtypes\n\n.. _whatsnew_0120.enhancements.datetime_origin:\n\nMethod ``.to_datetime()`` has gained an ``origin`` parameter\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n:func:`to_datetime` has gained a new parameter, ``origin``, to define a reference date\nfrom where to compute the resulting timestamps when parsing numerical values with a specific ``unit`` specified. (:issue:`11276`, :issue:`11745`)\n\nFor example, with 1960-01-01 as the starting date:\n\n.. ipython:: python\n\n   pd.to_datetime([1, 2, 3], unit='D', origin=pd.Timestamp('1960-01-01'))\n\nThe default is set at ``origin='unix'``, which defaults to ``1970-01-01 00:00:00``, which is\ncommonly called 'unix epoch' or POSIX time. This was the previous default, so this is a backward compatible change.\n\n.. ipython:: python\n\n   pd.to_datetime([1, 2, 3], unit='D')\n\n\n.. _whatsnew_0200.enhancements.groupby_access:\n\nGroupBy enhancements\n^^^^^^^^^^^^^^^^^^^^\n\nStrings passed to ``DataFrame.groupby()`` as the ``by`` parameter may now reference either column names or index level names. Previously, only column names could be referenced. This allows to easily group by a column and index level at the same time. (:issue:`5677`)\n\n.. ipython:: python\n\n   arrays = [['bar', 'bar', 'baz', 'baz', 'foo', 'foo', 'qux', 'qux'],\n             ['one', 'two', 'one', 'two', 'one', 'two', 'one', 'two']]\n\n   index = pd.MultiIndex.from_arrays(arrays, names=['first', 'second'])\n\n   df = pd.DataFrame({'A': [1, 1, 1, 1, 2, 2, 3, 3],\n                      'B': np.arange(8)},\n                     index=index)\n   df\n\n   df.groupby(['second', 'A']).sum()\n\n\n.. _whatsnew_0200.enhancements.compressed_urls:\n\nBetter support for compressed URLs in ``read_csv``\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nThe compression code was refactored (:issue:`12688`). As a result, reading\ndataframes from URLs in :func:`read_csv` or :func:`read_table` now supports\nadditional compression methods: ``xz``, ``bz2``, and ``zip`` (:issue:`14570`).\nPreviously, only ``gzip`` compression was supported. By default, compression of\nURLs and paths are now inferred using their file extensions. Additionally,\nsupport for bz2 compression in the python 2 C-engine improved (:issue:`14874`).\n\n.. ipython:: python\n\n   url = ('https://github.com/{repo}/raw/{branch}/{path}'\n          .format(repo='pandas-dev/pandas',\n                  branch='main',\n                  path='pandas/tests/io/parser/data/salaries.csv.bz2'))\n    default, infer compression\n   df = pd.read_csv(url, sep='\\t', compression='infer')\n    explicitly specify compression\n   df = pd.read_csv(url, sep='\\t', compression='bz2')\n   df.head(2)\n\n.. _whatsnew_0200.enhancements.pickle_compression:\n\nPickle file IO now supports compression\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n:func:`read_pickle`, :meth:`DataFrame.to_pickle` and :meth:`Series.to_pickle`\ncan now read from and write to compressed pickle files. Compression methods\ncan be an explicit parameter or be inferred from the file extension.\nSee :ref:`the docs here. <io.pickle.compression>`\n\n.. ipython:: python\n\n   df = pd.DataFrame({'A': np.random.randn(1000),\n                      'B': 'foo',\n                      'C': pd.date_range('20130101', periods=1000, freq='s')})\n\nUsing an explicit compression type\n\n.. ipython:: python\n\n   df.to_pickle(\"data.pkl.compress\", compression=\"gzip\")\n   rt = pd.read_pickle(\"data.pkl.compress\", compression=\"gzip\")\n   rt.head()\n\nThe default is to infer the compression type from the extension (``compression='infer'``):\n\n.. ipython:: python\n\n   df.to_pickle(\"data.pkl.gz\")\n   rt = pd.read_pickle(\"data.pkl.gz\")\n   rt.head()\n   df[\"A\"].to_pickle(\"s1.pkl.bz2\")\n   rt = pd.read_pickle(\"s1.pkl.bz2\")\n   rt.head()\n\n.. ipython:: python\n   :suppress:\n\n   import os\n   os.remove(\"data.pkl.compress\")\n   os.remove(\"data.pkl.gz\")\n   os.remove(\"s1.pkl.bz2\")\n\n.. _whatsnew_0200.enhancements.uint64_support:\n\nUInt64 support improved\n^^^^^^^^^^^^^^^^^^^^^^^\n\npandas has significantly improved support for operations involving unsigned,\nor purely non-negative, integers. Previously, handling these integers would\nresult in improper rounding or data-type casting, leading to incorrect results.\nNotably, a new numerical index, ``UInt64Index``, has been created (:issue:`14937`)\n\n.. code-block:: ipython\n\n   In [1]: idx = pd.UInt64Index([1, 2, 3])\n   In [2]: df = pd.DataFrame({'A': ['a', 'b', 'c']}, index=idx)\n   In [3]: df.index\n   Out[3]: UInt64Index([1, 2, 3], dtype='uint64')\n\n- Bug in converting object elements of array-like objects to unsigned 64-bit integers (:issue:`4471`, :issue:`14982`)\n- Bug in ``Series.unique()`` in which unsigned 64-bit integers were causing overflow (:issue:`14721`)\n- Bug in ``DataFrame`` construction in which unsigned 64-bit integer elements were being converted to objects (:issue:`14881`)\n- Bug in ``pd.read_csv()`` in which unsigned 64-bit integer elements were being improperly converted to the wrong data types (:issue:`14983`)\n- Bug in ``pd.unique()`` in which unsigned 64-bit integers were causing overflow (:issue:`14915`)\n- Bug in ``pd.value_counts()`` in which unsigned 64-bit integers were being erroneously truncated in the output (:issue:`14934`)\n\n.. _whatsnew_0200.enhancements.groupy_categorical:\n\nGroupBy on categoricals\n^^^^^^^^^^^^^^^^^^^^^^^\n\nIn previous versions, ``.groupby(..., sort=False)`` would fail with a ``ValueError`` when grouping on a categorical series with some categories not appearing in the data. (:issue:`13179`)\n\n.. ipython:: python\n\n   chromosomes = np.r_[np.arange(1, 23).astype(str), ['X', 'Y']]\n   df = pd.DataFrame({\n       'A': np.random.randint(100),\n       'B': np.random.randint(100),\n       'C': np.random.randint(100),\n       'chromosomes': pd.Categorical(np.random.choice(chromosomes, 100),\n                                     categories=chromosomes,\n                                     ordered=True)})\n   df\n\n**Previous behavior**:\n\n.. code-block:: ipython\n\n   In [3]: df[df.chromosomes != '1'].groupby('chromosomes', observed=False, sort=False).sum()\n   ---------------------------------------------------------------------------\n   ValueError: items in new_categories are not the same as in old categories\n\n**New behavior**:\n\n.. ipython:: python\n\n   df[df.chromosomes != '1'].groupby('chromosomes', observed=False, sort=False).sum()\n\n.. _whatsnew_0200.enhancements.table_schema:\n\nTable schema output\n^^^^^^^^^^^^^^^^^^^\n\nThe new orient ``'table'`` for :meth:`DataFrame.to_json`\nwill generate a `Table Schema`_ compatible string representation of\nthe data.\n\n.. ipython:: python\n\n   df = pd.DataFrame(\n       {'A': [1, 2, 3],\n        'B': ['a', 'b', 'c'],\n        'C': pd.date_range('2016-01-01', freq='d', periods=3)},\n       index=pd.Index(range(3), name='idx'))\n   df\n   df.to_json(orient='table')\n\n\nSee :ref:`IO: Table Schema for more information <io.table_schema>`.\n\nAdditionally, the repr for ``DataFrame`` and ``Series`` can now publish\nthis JSON Table schema representation of the Series or DataFrame if you are\nusing IPython (or another frontend like `nteract`_ using the Jupyter messaging\nprotocol).\nThis gives frontends like the Jupyter notebook and `nteract`_\nmore flexibility in how they display pandas objects, since they have\nmore information about the data.\nYou must enable this by setting the ``display.html.table_schema`` option to ``True``.\n\n.. _Table Schema: http://specs.frictionlessdata.io/json-table-schema/\n.. _nteract: https://nteract.io/\n\n.. _whatsnew_0200.enhancements.scipy_sparse:\n\nSciPy sparse matrix from/to SparseDataFrame\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\npandas now supports creating sparse dataframes directly from ``scipy.sparse.spmatrix`` instances.\nSee the :ref:`documentation <sparse.scipysparse>` for more information. (:issue:`4343`)\n\nAll sparse formats are supported, but matrices that are not in :mod:`COOrdinate <scipy.sparse>` format will be converted, copying data as needed.\n\n.. code-block:: python\n\n   from scipy.sparse import csr_matrix\n   arr = np.random.random(size=(1000, 5))\n   arr[arr < .9] = 0\n   sp_arr = csr_matrix(arr)\n   sp_arr\n   sdf = pd.SparseDataFrame(sp_arr)\n   sdf\n\nTo convert a ``SparseDataFrame`` back to sparse SciPy matrix in COO format, you can use:\n\n.. code-block:: python\n\n   sdf.to_coo()\n\n.. _whatsnew_0200.enhancements.style_excel:\n\nExcel output for styled DataFrames\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nExperimental support has been added to export ``DataFrame.style`` formats to Excel using the ``openpyxl`` engine. (:issue:`15530`)\n\nFor example, after running the following, ``styled.xlsx`` renders as below:\n\n.. ipython:: python\n   :okwarning:\n\n   np.random.seed(24)\n   df = pd.DataFrame({'A': np.linspace(1, 10, 10)})\n   df = pd.concat([df, pd.DataFrame(np.random.RandomState(24).randn(10, 4),\n                                    columns=list('BCDE'))],\n                  axis=1)\n   df.iloc[0, 2] = np.nan\n   df\n   styled = (df.style\n             .applymap(lambda val: 'color:red;' if val < 0 else 'color:black;')\n             .highlight_max())\n   styled.to_excel('styled.xlsx', engine='openpyxl')\n\n.. image:: ../_static/style-excel.png\n\n.. ipython:: python\n   :suppress:\n\n   import os\n   os.remove('styled.xlsx')\n\nSee the :ref:`Style documentation </user_guide/style.ipynbExport-to-Excel>` for more detail.\n\n.. _whatsnew_0200.enhancements.intervalindex:\n\nIntervalIndex\n^^^^^^^^^^^^^\n\npandas has gained an ``IntervalIndex`` with its own dtype, ``interval`` as well as the ``Interval`` scalar type. These allow first-class support for interval\nnotation, specifically as a return type for the categories in :func:`cut` and :func:`qcut`. The ``IntervalIndex`` allows some unique indexing, see the\n:ref:`docs <advanced.intervalindex>`. (:issue:`7640`, :issue:`8625`)\n\n.. warning::\n\n   These indexing behaviors of the IntervalIndex are provisional and may change in a future version of pandas. Feedback on usage is welcome.\n\n\nPrevious behavior:\n\nThe returned categories were strings, representing Intervals\n\n.. code-block:: ipython\n\n   In [1]: c = pd.cut(range(4), bins=2)\n\n   In [2]: c\n   Out[2]:\n   [(-0.003, 1.5], (-0.003, 1.5], (1.5, 3], (1.5, 3]]\n   Categories (2, object): [(-0.003, 1.5] < (1.5, 3]]\n\n   In [3]: c.categories\n   Out[3]: Index(['(-0.003, 1.5]', '(1.5, 3]'], dtype='object')\n\nNew behavior:\n\n.. ipython:: python\n\n   c = pd.cut(range(4), bins=2)\n   c\n   c.categories\n\nFurthermore, this allows one to bin *other* data with these same bins, with ``NaN`` representing a missing\nvalue similar to other dtypes.\n\n.. ipython:: python\n\n   pd.cut([0, 3, 5, 1], bins=c.categories)\n\nAn ``IntervalIndex`` can also be used in ``Series`` and ``DataFrame`` as the index.\n\n.. ipython:: python\n\n   df = pd.DataFrame({'A': range(4),\n                      'B': pd.cut([0, 3, 1, 1], bins=c.categories)\n                      }).set_index('B')\n   df\n\nSelecting via a specific interval:\n\n.. ipython:: python\n\n   df.loc[pd.Interval(1.5, 3.0)]\n\nSelecting via a scalar value that is contained *in* the intervals.\n\n.. ipython:: python\n\n   df.loc[0]\n\n.. _whatsnew_0200.enhancements.other:\n\nOther enhancements\n^^^^^^^^^^^^^^^^^^\n\n- ``DataFrame.rolling()`` now accepts the parameter ``closed='right'|'left'|'both'|'neither'`` to choose the rolling window-endpoint closedness. See the :ref:`documentation <window.endpoints>` (:issue:`13965`)\n- Integration with the ``feather-format``, including a new top-level ``pd.read_feather()`` and ``DataFrame.to_feather()`` method, see :ref:`here <io.feather>`.\n- ``Series.str.replace()`` now accepts a callable, as replacement, which is passed to ``re.sub`` (:issue:`15055`)\n- ``Series.str.replace()`` now accepts a compiled regular expression as a pattern (:issue:`15446`)\n- ``Series.sort_index`` accepts parameters ``kind`` and ``na_position`` (:issue:`13589`, :issue:`14444`)\n- ``DataFrame`` and ``DataFrame.groupby()``  have gained a ``nunique()`` method to count the distinct values over an axis (:issue:`14336`, :issue:`15197`).\n- ``DataFrame`` has gained a ``melt()`` method, equivalent to ``pd.melt()``, for unpivoting from a wide to long format (:issue:`12640`).\n- ``pd.read_excel()`` now preserves sheet order when using ``sheetname=None`` (:issue:`9930`)\n- Multiple offset aliases with decimal points are now supported (e.g. ``0.5min`` is parsed as ``30s``) (:issue:`8419`)\n- ``.isnull()`` and ``.notnull()`` have been added to ``Index`` object to make them more consistent with the ``Series`` API (:issue:`15300`)\n- New ``UnsortedIndexError`` (subclass of ``KeyError``) raised when indexing/slicing into an\n  unsorted MultiIndex (:issue:`11897`). This allows differentiation between errors due to lack\n  of sorting or an incorrect key. See :ref:`here <advanced.unsorted>`\n- ``MultiIndex`` has gained a ``.to_frame()`` method to convert to a ``DataFrame`` (:issue:`12397`)\n- ``pd.cut`` and ``pd.qcut`` now support datetime64 and timedelta64 dtypes (:issue:`14714`, :issue:`14798`)\n- ``pd.qcut`` has gained the ``duplicates='raise'|'drop'`` option to control whether to raise on duplicated edges (:issue:`7751`)\n- ``Series`` provides a ``to_excel`` method to output Excel files (:issue:`8825`)\n- The ``usecols`` argument in ``pd.read_csv()`` now accepts a callable function as a value  (:issue:`14154`)\n- The ``skiprows`` argument in ``pd.read_csv()`` now accepts a callable function as a value  (:issue:`10882`)\n- The ``nrows`` and ``chunksize`` arguments in ``pd.read_csv()`` are supported if both are passed (:issue:`6774`, :issue:`15755`)\n- ``DataFrame.plot`` now prints a title above each subplot if ``suplots=True`` and ``title`` is a list of strings (:issue:`14753`)\n- ``DataFrame.plot`` can pass the matplotlib 2.0 default color cycle as a single string as color parameter, see `here <http://matplotlib.org/2.0.0/users/colors.html#cn-color-selection>`__. (:issue:`15516`)\n- ``Series.interpolate()`` now supports timedelta as an index type with ``method='time'`` (:issue:`6424`)\n- Addition of a ``level`` keyword to ``DataFrame/Series.rename`` to rename\n  labels in the specified level of a MultiIndex (:issue:`4160`).\n- ``DataFrame.reset_index()`` will now interpret a tuple ``index.name`` as a key spanning across levels of ``columns``, if this is a ``MultiIndex`` (:issue:`16164`)\n- ``Timedelta.isoformat`` method added for formatting Timedeltas as an `ISO 8601 duration`_. See the :ref:`Timedelta docs <timedeltas.isoformat>` (:issue:`15136`)\n- ``.select_dtypes()`` now allows the string ``datetimetz`` to generically select datetimes with tz (:issue:`14910`)\n- The ``.to_latex()`` method will now accept ``multicolumn`` and ``multirow`` arguments to use the accompanying LaTeX enhancements\n- ``pd.merge_asof()`` gained the option ``direction='backward'|'forward'|'nearest'`` (:issue:`14887`)\n- ``Series/DataFrame.asfreq()`` have gained a ``fill_value`` parameter, to fill missing values (:issue:`3715`).\n- ``Series/DataFrame.resample.asfreq`` have gained a ``fill_value`` parameter, to fill missing values during resampling (:issue:`3715`).\n- :func:`pandas.util.hash_pandas_object` has gained the ability to hash a ``MultiIndex`` (:issue:`15224`)\n- ``Series/DataFrame.squeeze()`` have gained the ``axis`` parameter. (:issue:`15339`)\n- ``DataFrame.to_excel()`` has a new ``freeze_panes`` parameter to turn on Freeze Panes when exporting to Excel (:issue:`15160`)\n- ``pd.read_html()`` will parse multiple header rows, creating a MultiIndex header. (:issue:`13434`).\n- HTML table output skips ``colspan`` or ``rowspan`` attribute if equal to 1. (:issue:`15403`)\n- :class:`pandas.io.formats.style.Styler` template now has blocks for easier extension, see the :ref:`example notebook </user_guide/style.ipynbSubclassing>` (:issue:`15649`)\n- :meth:`Styler.render() <pandas.io.formats.style.Styler.render>` now accepts ``**kwargs`` to allow user-defined variables in the template (:issue:`15649`)\n- Compatibility with Jupyter notebook 5.0; MultiIndex column labels are left-aligned and MultiIndex row-labels are top-aligned (:issue:`15379`)\n- ``TimedeltaIndex`` now has a custom date-tick formatter specifically designed for nanosecond level precision (:issue:`8711`)\n- ``pd.api.types.union_categoricals`` gained the ``ignore_ordered`` argument to allow ignoring the ordered attribute of unioned categoricals (:issue:`13410`). See the :ref:`categorical union docs <categorical.union>` for more information.\n- ``DataFrame.to_latex()`` and ``DataFrame.to_string()`` now allow optional header aliases. (:issue:`15536`)\n- Re-enable the ``parse_dates`` keyword of ``pd.read_excel()`` to parse string columns as dates (:issue:`14326`)\n- Added ``.empty`` property to subclasses of ``Index``. (:issue:`15270`)\n- Enabled floor division for ``Timedelta`` and ``TimedeltaIndex`` (:issue:`15828`)\n- ``pandas.io.json.json_normalize()`` gained the option ``errors='ignore'|'raise'``; the default is ``errors='raise'`` which is backward compatible. (:issue:`14583`)\n- ``pandas.io.json.json_normalize()`` with an empty ``list`` will return an empty ``DataFrame`` (:issue:`15534`)\n- ``pandas.io.json.json_normalize()`` has gained a ``sep`` option that accepts ``str`` to separate joined fields; the default is \".\", which is backward compatible. (:issue:`14883`)\n- :meth:`MultiIndex.remove_unused_levels` has been added to facilitate :ref:`removing unused levels <advanced.shown_levels>`. (:issue:`15694`)\n- ``pd.read_csv()`` will now raise a ``ParserError`` error whenever any parsing error occurs (:issue:`15913`, :issue:`15925`)\n- ``pd.read_csv()`` now supports the ``error_bad_lines`` and ``warn_bad_lines`` arguments for the Python parser (:issue:`15925`)\n- The ``display.show_dimensions`` option can now also be used to specify\n  whether the length of a ``Series`` should be shown in its repr (:issue:`7117`).\n- ``parallel_coordinates()`` has gained a ``sort_labels`` keyword argument that sorts class labels and the colors assigned to them (:issue:`15908`)\n- Options added to allow one to turn on/off using ``bottleneck`` and ``numexpr``, see :ref:`here <basics.accelerate>` (:issue:`16157`)\n- ``DataFrame.style.bar()`` now accepts two more options to further customize the bar chart. Bar alignment is set with ``align='left'|'mid'|'zero'``, the default is \"left\", which is backward compatible; You can now pass a list of ``color=[color_negative, color_positive]``. (:issue:`14757`)\n\n.. _ISO 8601 duration: https://en.wikipedia.org/wiki/ISO_8601#Durations\n\n\n.. _whatsnew_0200.api_breaking:\n\nBackwards incompatible API changes\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\n.. _whatsnew.api_breaking.io_compat:\n\nPossible incompatibility for HDF5 formats created with pandas < 0.13.0\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n``pd.TimeSeries`` was deprecated officially in 0.17.0, though has already been an alias since 0.13.0. It has\nbeen dropped in favor of ``pd.Series``. (:issue:`15098`).\n\nThis *may* cause HDF5 files that were created in prior versions to become unreadable if ``pd.TimeSeries``\nwas used. This is most likely to be for pandas < 0.13.0. If you find yourself in this situation.\nYou can use a recent prior version of pandas to read in your HDF5 files,\nthen write them out again after applying the procedure below.\n\n.. code-block:: ipython\n\n   In [2]: s = pd.TimeSeries([1, 2, 3], index=pd.date_range('20130101', periods=3))\n\n   In [3]: s\n   Out[3]:\n   2013-01-01    1\n   2013-01-02    2\n   2013-01-03    3\n   Freq: D, dtype: int64\n\n   In [4]: type(s)\n   Out[4]: pandas.core.series.TimeSeries\n\n   In [5]: s = pd.Series(s)\n\n   In [6]: s\n   Out[6]:\n   2013-01-01    1\n   2013-01-02    2\n   2013-01-03    3\n   Freq: D, dtype: int64\n\n   In [7]: type(s)\n   Out[7]: pandas.core.series.Series\n\n\n.. _whatsnew_0200.api_breaking.index_map:\n\nMap on Index types now return other Index types\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n``map`` on an ``Index`` now returns an ``Index``, not a numpy array (:issue:`12766`)\n\n.. ipython:: python\n\n   idx = pd.Index([1, 2])\n   idx\n   mi = pd.MultiIndex.from_tuples([(1, 2), (2, 4)])\n   mi\n\nPrevious behavior:\n\n.. code-block:: ipython\n\n   In [5]: idx.map(lambda x: x * 2)\n   Out[5]: array([2, 4])\n\n   In [6]: idx.map(lambda x: (x, x * 2))\n   Out[6]: array([(1, 2), (2, 4)], dtype=object)\n\n   In [7]: mi.map(lambda x: x)\n   Out[7]: array([(1, 2), (2, 4)], dtype=object)\n\n   In [8]: mi.map(lambda x: x[0])\n   Out[8]: array([1, 2])\n\nNew behavior:\n\n.. ipython:: python\n\n   idx.map(lambda x: x * 2)\n   idx.map(lambda x: (x, x * 2))\n\n   mi.map(lambda x: x)\n\n   mi.map(lambda x: x[0])\n\n\n``map`` on a ``Series`` with ``datetime64`` values may return ``int64`` dtypes rather than ``int32``\n\n.. code-block:: ipython\n\n   In [64]: s = pd.Series(pd.date_range('2011-01-02T00:00', '2011-01-02T02:00', freq='H')\n      ....:               .tz_localize('Asia/Tokyo'))\n      ....:\n\n   In [65]: s\n   Out[65]:\n   0   2011-01-02 00:00:00+09:00\n   1   2011-01-02 01:00:00+09:00\n   2   2011-01-02 02:00:00+09:00\n   Length: 3, dtype: datetime64[ns, Asia/Tokyo]\n\nPrevious behavior:\n\n.. code-block:: ipython\n\n   In [9]: s.map(lambda x: x.hour)\n   Out[9]:\n   0    0\n   1    1\n   2    2\n   dtype: int32\n\nNew behavior:\n\n.. code-block:: ipython\n\n   In [66]: s.map(lambda x: x.hour)\n   Out[66]:\n   0    0\n   1    1\n   2    2\n   Length: 3, dtype: int64\n\n\n.. _whatsnew_0200.api_breaking.index_dt_field:\n\nAccessing datetime fields of Index now return Index\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nThe datetime-related attributes (see :ref:`here <timeseries.components>`\nfor an overview) of ``DatetimeIndex``, ``PeriodIndex`` and ``TimedeltaIndex`` previously\nreturned numpy arrays. They will now return a new ``Index`` object, except\nin the case of a boolean field, where the result will still be a boolean ndarray. (:issue:`15022`)\n\nPrevious behaviour:\n\n.. code-block:: ipython\n\n   In [1]: idx = pd.date_range(\"2015-01-01\", periods=5, freq='10H')\n\n   In [2]: idx.hour\n   Out[2]: array([ 0, 10, 20,  6, 16], dtype=int32)\n\nNew behavior:\n\n.. code-block:: ipython\n\n   In [67]: idx = pd.date_range(\"2015-01-01\", periods=5, freq='10H')\n\n   In [68]: idx.hour\n   Out[68]: Index([0, 10, 20, 6, 16], dtype='int32')\n\nThis has the advantage that specific ``Index`` methods are still available on the\nresult. On the other hand, this might have backward incompatibilities: e.g.\ncompared to numpy arrays, ``Index`` objects are not mutable. To get the original\nndarray, you can always convert explicitly using ``np.asarray(idx.hour)``.\n\n.. _whatsnew_0200.api_breaking.unique:\n\npd.unique will now be consistent with extension types\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nIn prior versions, using :meth:`Series.unique` and :func:`pandas.unique` on ``Categorical`` and tz-aware\ndata-types would yield different return types. These are now made consistent. (:issue:`15903`)\n\n- Datetime tz-aware\n\n  Previous behaviour:\n\n  .. code-block:: ipython\n\n      Series\n     In [5]: pd.Series([pd.Timestamp('20160101', tz='US/Eastern'),\n        ...:            pd.Timestamp('20160101', tz='US/Eastern')]).unique()\n     Out[5]: array([Timestamp('2016-01-01 00:00:00-0500', tz='US/Eastern')], dtype=object)\n\n     In [6]: pd.unique(pd.Series([pd.Timestamp('20160101', tz='US/Eastern'),\n        ...:                      pd.Timestamp('20160101', tz='US/Eastern')]))\n     Out[6]: array(['2016-01-01T05:00:00.000000000'], dtype='datetime64[ns]')\n\n      Index\n     In [7]: pd.Index([pd.Timestamp('20160101', tz='US/Eastern'),\n        ...:           pd.Timestamp('20160101', tz='US/Eastern')]).unique()\n     Out[7]: DatetimeIndex(['2016-01-01 00:00:00-05:00'], dtype='datetime64[ns, US/Eastern]', freq=None)\n\n     In [8]: pd.unique([pd.Timestamp('20160101', tz='US/Eastern'),\n        ...:            pd.Timestamp('20160101', tz='US/Eastern')])\n     Out[8]: array(['2016-01-01T05:00:00.000000000'], dtype='datetime64[ns]')\n\n  New behavior:\n\n  .. ipython:: python\n\n      Series, returns an array of Timestamp tz-aware\n     pd.Series([pd.Timestamp(r'20160101', tz=r'US/Eastern'),\n                pd.Timestamp(r'20160101', tz=r'US/Eastern')]).unique()\n     pd.unique(pd.Series([pd.Timestamp('20160101', tz='US/Eastern'),\n               pd.Timestamp('20160101', tz='US/Eastern')]))\n\n      Index, returns a DatetimeIndex\n     pd.Index([pd.Timestamp('20160101', tz='US/Eastern'),\n               pd.Timestamp('20160101', tz='US/Eastern')]).unique()\n     pd.unique(pd.Index([pd.Timestamp('20160101', tz='US/Eastern'),\n                         pd.Timestamp('20160101', tz='US/Eastern')]))\n\n- Categoricals\n\n  Previous behaviour:\n\n  .. code-block:: ipython\n\n     In [1]: pd.Series(list('baabc'), dtype='category').unique()\n     Out[1]:\n     [b, a, c]\n     Categories (3, object): [b, a, c]\n\n     In [2]: pd.unique(pd.Series(list('baabc'), dtype='category'))\n     Out[2]: array(['b', 'a', 'c'], dtype=object)\n\n  New behavior:\n\n  .. ipython:: python\n\n      returns a Categorical\n     pd.Series(list('baabc'), dtype='category').unique()\n     pd.unique(pd.Series(list('baabc'), dtype='category'))\n\n.. _whatsnew_0200.api_breaking.s3:\n\nS3 file handling\n^^^^^^^^^^^^^^^^\n\npandas now uses `s3fs <http://s3fs.readthedocs.io/>`_ for handling S3 connections. This shouldn't break\nany code. However, since ``s3fs`` is not a required dependency, you will need to install it separately, like ``boto``\nin prior versions of pandas. (:issue:`11915`).\n\n.. _whatsnew_0200.api_breaking.partial_string_indexing:\n\nPartial string indexing changes\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n:ref:`DatetimeIndex Partial String Indexing <timeseries.partialindexing>` now works as an exact match, provided that string resolution coincides with index resolution, including a case when both are seconds (:issue:`14826`). See :ref:`Slice vs. Exact Match <timeseries.slice_vs_exact_match>` for details.\n\n.. ipython:: python\n\n   df = pd.DataFrame({'a': [1, 2, 3]}, pd.DatetimeIndex(['2011-12-31 23:59:59',\n                                                         '2012-01-01 00:00:00',\n                                                         '2012-01-01 00:00:01']))\nPrevious behavior:\n\n.. code-block:: ipython\n\n   In [4]: df['2011-12-31 23:59:59']\n   Out[4]:\n                          a\n   2011-12-31 23:59:59  1\n\n   In [5]: df['a']['2011-12-31 23:59:59']\n   Out[5]:\n   2011-12-31 23:59:59    1\n   Name: a, dtype: int64\n\n\nNew behavior:\n\n.. code-block:: ipython\n\n   In [4]: df['2011-12-31 23:59:59']\n   KeyError: '2011-12-31 23:59:59'\n\n   In [5]: df['a']['2011-12-31 23:59:59']\n   Out[5]: 1\n\n.. _whatsnew_0200.api_breaking.concat_dtypes:\n\nConcat of different float dtypes will not automatically upcast\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nPreviously, ``concat`` of multiple objects with different ``float`` dtypes would automatically upcast results to a dtype of ``float64``.\nNow the smallest acceptable dtype will be used (:issue:`13247`)\n\n.. ipython:: python\n\n   df1 = pd.DataFrame(np.array([1.0], dtype=np.float32, ndmin=2))\n   df1.dtypes\n\n   df2 = pd.DataFrame(np.array([np.nan], dtype=np.float32, ndmin=2))\n   df2.dtypes\n\nPrevious behavior:\n\n.. code-block:: ipython\n\n   In [7]: pd.concat([df1, df2]).dtypes\n   Out[7]:\n   0    float64\n   dtype: object\n\nNew behavior:\n\n.. ipython:: python\n\n   pd.concat([df1, df2]).dtypes\n\n.. _whatsnew_0200.api_breaking.gbq:\n\npandas Google BigQuery support has moved\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\npandas has split off Google BigQuery support into a separate package ``pandas-gbq``. You can ``conda install pandas-gbq -c conda-forge`` or\n``pip install pandas-gbq`` to get it. The functionality of :func:`read_gbq` and :meth:`DataFrame.to_gbq` remain the same with the\ncurrently released version of ``pandas-gbq=0.1.4``. Documentation is now hosted `here <https://pandas-gbq.readthedocs.io/>`__  (:issue:`15347`)\n\n.. _whatsnew_0200.api_breaking.memory_usage:\n\nMemory usage for Index is more accurate\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nIn previous versions, showing ``.memory_usage()`` on a pandas structure that has an index, would only include actual index values and not include structures that facilitated fast indexing. This will generally be different for ``Index`` and ``MultiIndex`` and less-so for other index types. (:issue:`15237`)\n\nPrevious behavior:\n\n.. code-block:: ipython\n\n   In [8]: index = pd.Index(['foo', 'bar', 'baz'])\n\n   In [9]: index.memory_usage(deep=True)\n   Out[9]: 180\n\n   In [10]: index.get_loc('foo')\n   Out[10]: 0\n\n   In [11]: index.memory_usage(deep=True)\n   Out[11]: 180\n\nNew behavior:\n\n.. code-block:: ipython\n\n   In [8]: index = pd.Index(['foo', 'bar', 'baz'])\n\n   In [9]: index.memory_usage(deep=True)\n   Out[9]: 180\n\n   In [10]: index.get_loc('foo')\n   Out[10]: 0\n\n   In [11]: index.memory_usage(deep=True)\n   Out[11]: 260\n\n.. _whatsnew_0200.api_breaking.sort_index:\n\nDataFrame.sort_index changes\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nIn certain cases, calling ``.sort_index()`` on a MultiIndexed DataFrame would return the *same* DataFrame without seeming to sort.\nThis would happen with a ``lexsorted``, but non-monotonic levels. (:issue:`15622`, :issue:`15687`, :issue:`14015`, :issue:`13431`, :issue:`15797`)\n\nThis is *unchanged* from prior versions, but shown for illustration purposes:\n\n.. code-block:: python\n\n   In [81]: df = pd.DataFrame(np.arange(6), columns=['value'],\n      ....:                   index=pd.MultiIndex.from_product([list('BA'), range(3)]))\n      ....:\n   In [82]: df\n\n   Out[82]:\n        value\n   B 0      0\n     1      1\n     2      2\n   A 0      3\n     1      4\n     2      5\n\n   [6 rows x 1 columns]\n\n.. code-block:: python\n\n   In [87]: df.index.is_lexsorted()\n   Out[87]: False\n\n   In [88]: df.index.is_monotonic\n   Out[88]: False\n\nSorting works as expected\n\n.. ipython:: python\n\n   df.sort_index()\n\n.. code-block:: python\n\n   In [90]: df.sort_index().index.is_lexsorted()\n   Out[90]: True\n\n   In [91]: df.sort_index().index.is_monotonic\n   Out[91]: True\n\nHowever, this example, which has a non-monotonic 2nd level,\ndoesn't behave as desired.\n\n.. ipython:: python\n\n   df = pd.DataFrame({'value': [1, 2, 3, 4]},\n                     index=pd.MultiIndex([['a', 'b'], ['bb', 'aa']],\n                                         [[0, 0, 1, 1], [0, 1, 0, 1]]))\n   df\n\nPrevious behavior:\n\n.. code-block:: python\n\n   In [11]: df.sort_index()\n   Out[11]:\n         value\n   a bb      1\n     aa      2\n   b bb      3\n     aa      4\n\n   In [14]: df.sort_index().index.is_lexsorted()\n   Out[14]: True\n\n   In [15]: df.sort_index().index.is_monotonic\n   Out[15]: False\n\nNew behavior:\n\n.. code-block:: python\n\n   In [94]: df.sort_index()\n   Out[94]:\n         value\n   a aa      2\n     bb      1\n   b aa      4\n     bb      3\n\n   [4 rows x 1 columns]\n\n   In [95]: df.sort_index().index.is_lexsorted()\n   Out[95]: True\n\n   In [96]: df.sort_index().index.is_monotonic\n   Out[96]: True\n\n\n.. _whatsnew_0200.api_breaking.groupby_describe:\n\nGroupBy describe formatting\n^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nThe output formatting of ``groupby.describe()`` now labels the ``describe()`` metrics in the columns instead of the index.\nThis format is consistent with ``groupby.agg()`` when applying multiple functions at once. (:issue:`4792`)\n\nPrevious behavior:\n\n.. code-block:: ipython\n\n   In [1]: df = pd.DataFrame({'A': [1, 1, 2, 2], 'B': [1, 2, 3, 4]})\n\n   In [2]: df.groupby('A').describe()\n   Out[2]:\n                   B\n   A\n   1 count  2.000000\n     mean   1.500000\n     std    0.707107\n     min    1.000000\n     25%    1.250000\n     50%    1.500000\n     75%    1.750000\n     max    2.000000\n   2 count  2.000000\n     mean   3.500000\n     std    0.707107\n     min    3.000000\n     25%    3.250000\n     50%    3.500000\n     75%    3.750000\n     max    4.000000\n\n   In [3]: df.groupby('A').agg([\"mean\", \"std\", \"min\", \"max\"])\n   Out[3]:\n        B\n     mean       std amin amax\n   A\n   1  1.5  0.707107    1    2\n   2  3.5  0.707107    3    4\n\nNew behavior:\n\n.. ipython:: python\n\n   df = pd.DataFrame({'A': [1, 1, 2, 2], 'B': [1, 2, 3, 4]})\n\n   df.groupby('A').describe()\n\n   df.groupby('A').agg([\"mean\", \"std\", \"min\", \"max\"])\n\n.. _whatsnew_0200.api_breaking.rolling_pairwise:\n\nWindow binary corr/cov operations return a MultiIndex DataFrame\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nA binary window operation, like ``.corr()`` or ``.cov()``, when operating on a ``.rolling(..)``, ``.expanding(..)``, or ``.ewm(..)`` object,\nwill now return a 2-level ``MultiIndexed DataFrame`` rather than a ``Panel``, as ``Panel`` is now deprecated,\nsee :ref:`here <whatsnew_0200.api_breaking.deprecate_panel>`. These are equivalent in function,\nbut a MultiIndexed ``DataFrame`` enjoys more support in pandas.\nSee the section on :ref:`Windowed Binary Operations <window.cov_corr>` for more information. (:issue:`15677`)\n\n.. ipython:: python\n\n   np.random.seed(1234)\n   df = pd.DataFrame(np.random.rand(100, 2),\n                     columns=pd.Index(['A', 'B'], name='bar'),\n                     index=pd.date_range('20160101',\n                                         periods=100, freq='D', name='foo'))\n   df.tail()\n\nPrevious behavior:\n\n.. code-block:: ipython\n\n   In [2]: df.rolling(12).corr()\n   Out[2]:\n   <class 'pandas.core.panel.Panel'>\n   Dimensions: 100 (items) x 2 (major_axis) x 2 (minor_axis)\n   Items axis: 2016-01-01 00:00:00 to 2016-04-09 00:00:00\n   Major_axis axis: A to B\n   Minor_axis axis: A to B\n\nNew behavior:\n\n.. ipython:: python\n\n   res = df.rolling(12).corr()\n   res.tail()\n\nRetrieving a correlation matrix for a cross-section\n\n.. ipython:: python\n\n   df.rolling(12).corr().loc['2016-04-07']\n\n.. _whatsnew_0200.api_breaking.hdfstore_where:\n\nHDFStore where string comparison\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nIn previous versions most types could be compared to string column in a ``HDFStore``\nusually resulting in an invalid comparison, returning an empty result frame. These comparisons will now raise a\n``TypeError`` (:issue:`15492`)\n\n.. ipython:: python\n\n   df = pd.DataFrame({'unparsed_date': ['2014-01-01', '2014-01-01']})\n   df.to_hdf('store.h5', key='key', format='table', data_columns=True)\n   df.dtypes\n\nPrevious behavior:\n\n.. code-block:: ipython\n\n   In [4]: pd.read_hdf('store.h5', 'key', where='unparsed_date > ts')\n   File \"<string>\", line 1\n     (unparsed_date > 1970-01-01 00:00:01.388552400)\n                           ^\n   SyntaxError: invalid token\n\nNew behavior:\n\n.. code-block:: ipython\n\n   In [18]: ts = pd.Timestamp('2014-01-01')\n\n   In [19]: pd.read_hdf('store.h5', 'key', where='unparsed_date > ts')\n   TypeError: Cannot compare 2014-01-01 00:00:00 of\n   type <class 'pandas.tslib.Timestamp'> to string column\n\n.. ipython:: python\n   :suppress:\n\n   import os\n   os.remove('store.h5')\n\n.. _whatsnew_0200.api_breaking.index_order:\n\nIndex.intersection and inner join now preserve the order of the left Index\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n:meth:`Index.intersection` now preserves the order of the calling ``Index`` (left)\ninstead of the other ``Index`` (right) (:issue:`15582`). This affects inner\njoins, :meth:`DataFrame.join` and :func:`merge`, and the ``.align`` method.\n\n- ``Index.intersection``\n\n  .. ipython:: python\n\n     left = pd.Index([2, 1, 0])\n     left\n     right = pd.Index([1, 2, 3])\n     right\n\n  Previous behavior:\n\n  .. code-block:: ipython\n\n     In [4]: left.intersection(right)\n     Out[4]: Int64Index([1, 2], dtype='int64')\n\n  New behavior:\n\n  .. ipython:: python\n\n     left.intersection(right)\n\n- ``DataFrame.join`` and ``pd.merge``\n\n  .. ipython:: python\n\n     left = pd.DataFrame({'a': [20, 10, 0]}, index=[2, 1, 0])\n     left\n     right = pd.DataFrame({'b': [100, 200, 300]}, index=[1, 2, 3])\n     right\n\n  Previous behavior:\n\n  .. code-block:: ipython\n\n     In [4]: left.join(right, how='inner')\n     Out[4]:\n        a    b\n     1  10  100\n     2  20  200\n\n  New behavior:\n\n  .. ipython:: python\n\n     left.join(right, how='inner')\n\n.. _whatsnew_0200.api_breaking.pivot_table:\n\nPivot table always returns a DataFrame\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nThe documentation for :meth:`pivot_table` states that a ``DataFrame`` is *always* returned. Here a bug\nis fixed that allowed this to return a ``Series`` under certain circumstance. (:issue:`4386`)\n\n.. ipython:: python\n\n   df = pd.DataFrame({'col1': [3, 4, 5],\n                      'col2': ['C', 'D', 'E'],\n                      'col3': [1, 3, 9]})\n   df\n\nPrevious behavior:\n\n.. code-block:: ipython\n\n   In [2]: df.pivot_table('col1', index=['col3', 'col2'], aggfunc=\"sum\")\n   Out[2]:\n   col3  col2\n   1     C       3\n   3     D       4\n   9     E       5\n   Name: col1, dtype: int64\n\nNew behavior:\n\n.. ipython:: python\n\n   df.pivot_table('col1', index=['col3', 'col2'], aggfunc=\"sum\")\n\n.. _whatsnew_0200.api:\n\nOther API changes\n^^^^^^^^^^^^^^^^^\n\n- ``numexpr`` version is now required to be >= 2.4.6 and it will not be used at all if this requisite is not fulfilled (:issue:`15213`).\n- ``CParserError`` has been renamed to ``ParserError`` in ``pd.read_csv()`` and will be removed in the future (:issue:`12665`)\n- ``SparseArray.cumsum()`` and ``SparseSeries.cumsum()`` will now always return ``SparseArray`` and ``SparseSeries`` respectively (:issue:`12855`)\n- ``DataFrame.applymap()`` with an empty ``DataFrame`` will return a copy of the empty ``DataFrame`` instead of a ``Series`` (:issue:`8222`)\n- ``Series.map()`` now respects default values of dictionary subclasses with a ``__missing__`` method, such as ``collections.Counter`` (:issue:`15999`)\n- ``.loc`` has compat with ``.ix`` for accepting iterators, and NamedTuples (:issue:`15120`)\n- ``interpolate()`` and ``fillna()`` will raise a ``ValueError`` if the ``limit`` keyword argument is not greater than 0. (:issue:`9217`)\n- ``pd.read_csv()`` will now issue a ``ParserWarning`` whenever there are conflicting values provided by the ``dialect`` parameter and the user (:issue:`14898`)\n- ``pd.read_csv()`` will now raise a ``ValueError`` for the C engine if the quote character is larger than one byte (:issue:`11592`)\n- ``inplace`` arguments now require a boolean value, else a ``ValueError`` is thrown (:issue:`14189`)\n- ``pandas.api.types.is_datetime64_ns_dtype`` will now report ``True`` on a tz-aware dtype, similar to ``pandas.api.types.is_datetime64_any_dtype``\n- ``DataFrame.asof()`` will return a null filled ``Series`` instead the scalar ``NaN`` if a match is not found (:issue:`15118`)\n- Specific support for ``copy.copy()`` and ``copy.deepcopy()`` functions on NDFrame objects (:issue:`15444`)\n- ``Series.sort_values()`` accepts a one element list of bool for consistency with the behavior of ``DataFrame.sort_values()`` (:issue:`15604`)\n- ``.merge()`` and ``.join()`` on ``category`` dtype columns will now preserve the category dtype when possible (:issue:`10409`)\n- ``SparseDataFrame.default_fill_value`` will be 0, previously was ``nan`` in the return from ``pd.get_dummies(..., sparse=True)`` (:issue:`15594`)\n- The default behaviour of ``Series.str.match`` has changed from extracting\n  groups to matching the pattern. The extracting behaviour was deprecated\n  since pandas version 0.13.0 and can be done with the ``Series.str.extract``\n  method (:issue:`5224`). As a consequence, the ``as_indexer`` keyword is\n  ignored (no longer needed to specify the new behaviour) and is deprecated.\n- ``NaT`` will now correctly report ``False`` for datetimelike boolean operations such as ``is_month_start`` (:issue:`15781`)\n- ``NaT`` will now correctly return ``np.nan`` for ``Timedelta`` and ``Period`` accessors such as ``days`` and ``quarter`` (:issue:`15782`)\n- ``NaT`` will now returns ``NaT`` for ``tz_localize`` and ``tz_convert``\n  methods (:issue:`15830`)\n- ``DataFrame`` and ``Panel`` constructors with invalid input will now raise ``ValueError`` rather than ``PandasError``, if called with scalar inputs and not axes (:issue:`15541`)\n- ``DataFrame`` and ``Panel`` constructors with invalid input will now raise ``ValueError`` rather than ``pandas.core.common.PandasError``, if called with scalar inputs and not axes; The exception ``PandasError`` is removed as well. (:issue:`15541`)\n- The exception ``pandas.core.common.AmbiguousIndexError`` is removed as it is not referenced (:issue:`15541`)\n\n\n.. _whatsnew_0200.privacy:\n\nReorganization of the library: privacy changes\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\n.. _whatsnew_0200.privacy.extensions:\n\nModules privacy has changed\n^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nSome formerly public python/c/c++/cython extension modules have been moved and/or renamed. These are all removed from the public API.\nFurthermore, the ``pandas.core``, ``pandas.compat``, and ``pandas.util`` top-level modules are now considered to be PRIVATE.\nIf indicated, a deprecation warning will be issued if you reference these modules. (:issue:`12588`)\n\n.. csv-table::\n    :header: \"Previous Location\", \"New Location\", \"Deprecated\"\n    :widths: 30, 30, 4\n\n    \"pandas.lib\", \"pandas._libs.lib\", \"X\"\n    \"pandas.tslib\", \"pandas._libs.tslib\", \"X\"\n    \"pandas.computation\", \"pandas.core.computation\", \"X\"\n    \"pandas.msgpack\", \"pandas.io.msgpack\", \"\"\n    \"pandas.index\", \"pandas._libs.index\", \"\"\n    \"pandas.algos\", \"pandas._libs.algos\", \"\"\n    \"pandas.hashtable\", \"pandas._libs.hashtable\", \"\"\n    \"pandas.indexes\", \"pandas.core.indexes\", \"\"\n    \"pandas.json\", \"pandas._libs.json / pandas.io.json\", \"X\"\n    \"pandas.parser\", \"pandas._libs.parsers\", \"X\"\n    \"pandas.formats\", \"pandas.io.formats\", \"\"\n    \"pandas.sparse\", \"pandas.core.sparse\", \"\"\n    \"pandas.tools\", \"pandas.core.reshape\", \"X\"\n    \"pandas.types\", \"pandas.core.dtypes\", \"X\"\n    \"pandas.io.sas.saslib\", \"pandas.io.sas._sas\", \"\"\n    \"pandas._join\", \"pandas._libs.join\", \"\"\n    \"pandas._hash\", \"pandas._libs.hashing\", \"\"\n    \"pandas._period\", \"pandas._libs.period\", \"\"\n    \"pandas._sparse\", \"pandas._libs.sparse\", \"\"\n    \"pandas._testing\", \"pandas._libs.testing\", \"\"\n    \"pandas._window\", \"pandas._libs.window\", \"\"\n\n\nSome new subpackages are created with public functionality that is not directly\nexposed in the top-level namespace: ``pandas.errors``, ``pandas.plotting`` and\n``pandas.testing`` (more details below). Together with ``pandas.api.types`` and\ncertain functions in the ``pandas.io`` and ``pandas.tseries`` submodules,\nthese are now the public subpackages.\n\nFurther changes:\n\n- The function :func:`~pandas.api.types.union_categoricals` is now importable from ``pandas.api.types``, formerly from ``pandas.types.concat`` (:issue:`15998`)\n- The type import ``pandas.tslib.NaTType`` is deprecated and can be replaced by using ``type(pandas.NaT)`` (:issue:`16146`)\n- The public functions in ``pandas.tools.hashing`` deprecated from that locations, but are now importable from ``pandas.util`` (:issue:`16223`)\n- The modules in ``pandas.util``: ``decorators``, ``print_versions``, ``doctools``, ``validators``, ``depr_module`` are now private. Only the functions exposed in ``pandas.util`` itself are public (:issue:`16223`)\n\n.. _whatsnew_0200.privacy.errors:\n\n``pandas.errors``\n^^^^^^^^^^^^^^^^^\n\nWe are adding a standard public module for all pandas exceptions & warnings ``pandas.errors``. (:issue:`14800`). Previously\nthese exceptions & warnings could be imported from ``pandas.core.common`` or ``pandas.io.common``. These exceptions and warnings\nwill be removed from the ``*.common`` locations in a future release. (:issue:`15541`)\n\nThe following are now part of this API:\n\n.. code-block:: python\n\n   ['DtypeWarning',\n    'EmptyDataError',\n    'OutOfBoundsDatetime',\n    'ParserError',\n    'ParserWarning',\n    'PerformanceWarning',\n    'UnsortedIndexError',\n    'UnsupportedFunctionCall']\n\n\n.. _whatsnew_0200.privacy.testing:\n\n``pandas.testing``\n^^^^^^^^^^^^^^^^^^\n\nWe are adding a standard module that exposes the public testing functions in ``pandas.testing`` (:issue:`9895`). Those functions can be used when writing tests for functionality using pandas objects.\n\nThe following testing functions are now part of this API:\n\n- :func:`testing.assert_frame_equal`\n- :func:`testing.assert_series_equal`\n- :func:`testing.assert_index_equal`\n\n\n.. _whatsnew_0200.privacy.plotting:\n\n``pandas.plotting``\n^^^^^^^^^^^^^^^^^^^\n\nA new public ``pandas.plotting`` module has been added that holds plotting functionality that was previously in either ``pandas.tools.plotting`` or in the top-level namespace. See the :ref:`deprecations sections <whatsnew_0200.privacy.deprecate_plotting>` for more details.\n\n.. _whatsnew_0200.privacy.development:\n\nOther development changes\n^^^^^^^^^^^^^^^^^^^^^^^^^\n\n- Building pandas for development now requires ``cython >= 0.23`` (:issue:`14831`)\n- Require at least 0.23 version of cython to avoid problems with character encodings (:issue:`14699`)\n- Switched the test framework to use `pytest <http://doc.pytest.org/en/latest>`__ (:issue:`13097`)\n- Reorganization of tests directory layout (:issue:`14854`, :issue:`15707`).\n\n\n.. _whatsnew_0200.deprecations:\n\nDeprecations\n~~~~~~~~~~~~\n\n.. _whatsnew_0200.api_breaking.deprecate_ix:\n\nDeprecate ``.ix``\n^^^^^^^^^^^^^^^^^\n\nThe ``.ix`` indexer is deprecated, in favor of the more strict ``.iloc`` and ``.loc`` indexers. ``.ix`` offers a lot of magic on the inference of what the user wants to do. More specifically, ``.ix`` can decide to index *positionally* OR via *labels*, depending on the data type of the index. This has caused quite a bit of user confusion over the years. The full indexing documentation is :ref:`here <indexing>`. (:issue:`14218`)\n\nThe recommended methods of indexing are:\n\n- ``.loc`` if you want to *label* index\n- ``.iloc`` if you want to *positionally* index.\n\nUsing ``.ix`` will now show a ``DeprecationWarning`` with a link to some examples of how to convert code `here <https://pandas.pydata.org/pandas-docs/version/1.0/user_guide/indexing.html#ix-indexer-is-deprecated>`__.\n\n\n.. ipython:: python\n\n   df = pd.DataFrame({'A': [1, 2, 3],\n                      'B': [4, 5, 6]},\n                     index=list('abc'))\n\n   df\n\nPrevious behavior, where you wish to get the 0th and the 2nd elements from the index in the 'A' column.\n\n.. code-block:: ipython\n\n   In [3]: df.ix[[0, 2], 'A']\n   Out[3]:\n   a    1\n   c    3\n   Name: A, dtype: int64\n\nUsing ``.loc``. Here we will select the appropriate indexes from the index, then use *label* indexing.\n\n.. ipython:: python\n\n   df.loc[df.index[[0, 2]], 'A']\n\nUsing ``.iloc``. Here we will get the location of the 'A' column, then use *positional* indexing to select things.\n\n.. ipython:: python\n\n   df.iloc[[0, 2], df.columns.get_loc('A')]\n\n\n.. _whatsnew_0200.api_breaking.deprecate_panel:\n\nDeprecate Panel\n^^^^^^^^^^^^^^^\n\n``Panel`` is deprecated and will be removed in a future version. The recommended way to represent 3-D data are\nwith a ``MultiIndex`` on a ``DataFrame`` via the :meth:`~Panel.to_frame` or with the `xarray package <http://xarray.pydata.org/en/stable/>`__. pandas\nprovides a :meth:`~Panel.to_xarray` method to automate this conversion (:issue:`13563`).\n\n.. code-block:: ipython\n\n    In [133]: import pandas._testing as tm\n\n    In [134]: p = tm.makePanel()\n\n    In [135]: p\n    Out[135]:\n    <class 'pandas.core.panel.Panel'>\n    Dimensions: 3 (items) x 3 (major_axis) x 4 (minor_axis)\n    Items axis: ItemA to ItemC\n    Major_axis axis: 2000-01-03 00:00:00 to 2000-01-05 00:00:00\n    Minor_axis axis: A to D\n\nConvert to a MultiIndex DataFrame\n\n.. code-block:: ipython\n\n    In [136]: p.to_frame()\n    Out[136]:\n                         ItemA     ItemB     ItemC\n    major      minor\n    2000-01-03 A      0.628776 -1.409432  0.209395\n               B      0.988138 -1.347533 -0.896581\n               C     -0.938153  1.272395 -0.161137\n               D     -0.223019 -0.591863 -1.051539\n    2000-01-04 A      0.186494  1.422986 -0.592886\n               B     -0.072608  0.363565  1.104352\n               C     -1.239072 -1.449567  0.889157\n               D      2.123692 -0.414505 -0.319561\n    2000-01-05 A      0.952478 -2.147855 -1.473116\n               B     -0.550603 -0.014752 -0.431550\n               C      0.139683 -1.195524  0.288377\n               D      0.122273 -1.425795 -0.619993\n\n    [12 rows x 3 columns]\n\nConvert to an xarray DataArray\n\n.. code-block:: ipython\n\n    In [137]: p.to_xarray()\n    Out[137]:\n    <xarray.DataArray (items: 3, major_axis: 3, minor_axis: 4)>\n    array([[[ 0.628776,  0.988138, -0.938153, -0.223019],\n            [ 0.186494, -0.072608, -1.239072,  2.123692],\n            [ 0.952478, -0.550603,  0.139683,  0.122273]],\n\n           [[-1.409432, -1.347533,  1.272395, -0.591863],\n            [ 1.422986,  0.363565, -1.449567, -0.414505],\n            [-2.147855, -0.014752, -1.195524, -1.425795]],\n\n           [[ 0.209395, -0.896581, -0.161137, -1.051539],\n            [-0.592886,  1.104352,  0.889157, -0.319561],\n            [-1.473116, -0.43155 ,  0.288377, -0.619993]]])\n    Coordinates:\n      * items       (items) object 'ItemA' 'ItemB' 'ItemC'\n      * major_axis  (major_axis) datetime64[ns] 2000-01-03 2000-01-04 2000-01-05\n      * minor_axis  (minor_axis) object 'A' 'B' 'C' 'D'\n\n.. _whatsnew_0200.api_breaking.deprecate_group_agg_dict:\n\nDeprecate groupby.agg() with a dictionary when renaming\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nThe ``.groupby(..).agg(..)``, ``.rolling(..).agg(..)``, and ``.resample(..).agg(..)``  syntax can accept a variable of inputs, including scalars,\nlist, and a dict of column names to scalars or lists. This provides a useful syntax for constructing multiple\n(potentially different) aggregations.\n\nHowever, ``.agg(..)`` can *also* accept a dict that allows 'renaming' of the result columns. This is a complicated and confusing syntax, as well as not consistent\nbetween ``Series`` and ``DataFrame``. We are deprecating this 'renaming' functionality.\n\n- We are deprecating passing a dict to a grouped/rolled/resampled ``Series``. This allowed\n  one to ``rename`` the resulting aggregation, but this had a completely different\n  meaning than passing a dictionary to a grouped ``DataFrame``, which accepts column-to-aggregations.\n- We are deprecating passing a dict-of-dicts to a grouped/rolled/resampled ``DataFrame`` in a similar manner.\n\nThis is an illustrative example:\n\n.. ipython:: python\n\n   df = pd.DataFrame({'A': [1, 1, 1, 2, 2],\n                      'B': range(5),\n                      'C': range(5)})\n   df\n\nHere is a typical useful syntax for computing different aggregations for different columns. This\nis a natural, and useful syntax. We aggregate from the dict-to-list by taking the specified\ncolumns and applying the list of functions. This returns a ``MultiIndex`` for the columns (this is *not* deprecated).\n\n.. ipython:: python\n\n   df.groupby('A').agg({'B': 'sum', 'C': 'min'})\n\nHere's an example of the first deprecation, passing a dict to a grouped ``Series``. This\nis a combination aggregation & renaming:\n\n.. code-block:: ipython\n\n   In [6]: df.groupby('A').B.agg({'foo': 'count'})\n   FutureWarning: using a dict on a Series for aggregation\n   is deprecated and will be removed in a future version\n\n   Out[6]:\n      foo\n   A\n   1    3\n   2    2\n\nYou can accomplish the same operation, more idiomatically by:\n\n.. ipython:: python\n\n   df.groupby('A').B.agg(['count']).rename(columns={'count': 'foo'})\n\n\nHere's an example of the second deprecation, passing a dict-of-dict to a grouped ``DataFrame``:\n\n.. code-block:: python\n\n   In [23]: (df.groupby('A')\n       ...:    .agg({'B': {'foo': 'sum'}, 'C': {'bar': 'min'}})\n       ...:  )\n   FutureWarning: using a dict with renaming is deprecated and\n   will be removed in a future version\n\n   Out[23]:\n        B   C\n      foo bar\n   A\n   1   3   0\n   2   7   3\n\n\nYou can accomplish nearly the same by:\n\n.. ipython:: python\n\n   (df.groupby('A')\n      .agg({'B': 'sum', 'C': 'min'})\n      .rename(columns={'B': 'foo', 'C': 'bar'})\n    )\n\n\n\n.. _whatsnew_0200.privacy.deprecate_plotting:\n\nDeprecate .plotting\n^^^^^^^^^^^^^^^^^^^\n\nThe ``pandas.tools.plotting`` module has been deprecated,  in favor of the top level ``pandas.plotting`` module. All the public plotting functions are now available\nfrom ``pandas.plotting`` (:issue:`12548`).\n\nFurthermore, the top-level ``pandas.scatter_matrix`` and ``pandas.plot_params`` are deprecated.\nUsers can import these from ``pandas.plotting`` as well.\n\nPrevious script:\n\n.. code-block:: python\n\n   pd.tools.plotting.scatter_matrix(df)\n   pd.scatter_matrix(df)\n\nShould be changed to:\n\n.. code-block:: python\n\n   pd.plotting.scatter_matrix(df)\n\n\n\n.. _whatsnew_0200.deprecations.other:\n\nOther deprecations\n^^^^^^^^^^^^^^^^^^\n\n- ``SparseArray.to_dense()`` has deprecated the ``fill`` parameter, as that parameter was not being respected (:issue:`14647`)\n- ``SparseSeries.to_dense()`` has deprecated the ``sparse_only`` parameter (:issue:`14647`)\n- ``Series.repeat()`` has deprecated the ``reps`` parameter in favor of ``repeats`` (:issue:`12662`)\n- The ``Series`` constructor and ``.astype`` method have deprecated accepting timestamp dtypes without a frequency (e.g. ``np.datetime64``) for the ``dtype`` parameter (:issue:`15524`)\n- ``Index.repeat()`` and ``MultiIndex.repeat()`` have deprecated the ``n`` parameter in favor of ``repeats`` (:issue:`12662`)\n- ``Categorical.searchsorted()`` and ``Series.searchsorted()`` have deprecated the ``v`` parameter in favor of ``value`` (:issue:`12662`)\n- ``TimedeltaIndex.searchsorted()``, ``DatetimeIndex.searchsorted()``, and ``PeriodIndex.searchsorted()`` have deprecated the ``key`` parameter in favor of ``value`` (:issue:`12662`)\n- ``DataFrame.astype()`` has deprecated the ``raise_on_error`` parameter in favor of ``errors`` (:issue:`14878`)\n- ``Series.sortlevel`` and ``DataFrame.sortlevel`` have been deprecated in favor of ``Series.sort_index`` and ``DataFrame.sort_index`` (:issue:`15099`)\n- importing ``concat`` from ``pandas.tools.merge`` has been deprecated in favor of imports from the ``pandas`` namespace. This should only affect explicit imports (:issue:`15358`)\n- ``Series/DataFrame/Panel.consolidate()`` been deprecated as a public method. (:issue:`15483`)\n- The ``as_indexer`` keyword of ``Series.str.match()`` has been deprecated (ignored keyword) (:issue:`15257`).\n- The following top-level pandas functions have been deprecated and will be removed in a future version (:issue:`13790`, :issue:`15940`)\n\n  * ``pd.pnow()``, replaced by ``Period.now()``\n  * ``pd.Term``, is removed, as it is not applicable to user code. Instead use in-line string expressions in the where clause when searching in HDFStore\n  * ``pd.Expr``, is removed, as it is not applicable to user code.\n  * ``pd.match()``, is removed.\n  * ``pd.groupby()``, replaced by using the ``.groupby()`` method directly on a ``Series/DataFrame``\n  * ``pd.get_store()``, replaced by a direct call to ``pd.HDFStore(...)``\n- ``is_any_int_dtype``, ``is_floating_dtype``, and ``is_sequence`` are deprecated from ``pandas.api.types`` (:issue:`16042`)\n\n.. _whatsnew_0200.prior_deprecations:\n\nRemoval of prior version deprecations/changes\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\n- The ``pandas.rpy`` module is removed. Similar functionality can be accessed\n  through the `rpy2 <https://rpy2.readthedocs.io/>`__ project.\n  See the `R interfacing docs <https://pandas.pydata.org/pandas-docs/version/0.20/r_interface.html>`__ for more details.\n- The ``pandas.io.ga`` module with a ``google-analytics`` interface is removed (:issue:`11308`).\n  Similar functionality can be found in the `Google2Pandas <https://github.com/panalysis/Google2Pandas>`__ package.\n- ``pd.to_datetime`` and ``pd.to_timedelta`` have dropped the ``coerce`` parameter in favor of ``errors`` (:issue:`13602`)\n- ``pandas.stats.fama_macbeth``, ``pandas.stats.ols``, ``pandas.stats.plm`` and ``pandas.stats.var``, as well as the top-level ``pandas.fama_macbeth`` and ``pandas.ols`` routines are removed. Similar functionality can be found in the `statsmodels <https://www.statsmodels.org/dev/>`__ package. (:issue:`11898`)\n- The ``TimeSeries`` and ``SparseTimeSeries`` classes, aliases of ``Series``\n  and ``SparseSeries``, are removed (:issue:`10890`, :issue:`15098`).\n- ``Series.is_time_series`` is dropped in favor of ``Series.index.is_all_dates`` (:issue:`15098`)\n- The deprecated ``irow``, ``icol``, ``iget`` and ``iget_value`` methods are removed\n  in favor of ``iloc`` and ``iat`` as explained :ref:`here <whatsnew_0170.deprecations>` (:issue:`10711`).\n- The deprecated ``DataFrame.iterkv()`` has been removed in favor of ``DataFrame.iteritems()`` (:issue:`10711`)\n- The ``Categorical`` constructor has dropped the ``name`` parameter (:issue:`10632`)\n- ``Categorical`` has dropped support for ``NaN`` categories (:issue:`10748`)\n- The ``take_last`` parameter has been dropped from ``duplicated()``, ``drop_duplicates()``, ``nlargest()``, and ``nsmallest()`` methods (:issue:`10236`, :issue:`10792`, :issue:`10920`)\n- ``Series``, ``Index``, and ``DataFrame`` have dropped the ``sort`` and ``order`` methods (:issue:`10726`)\n- Where clauses in ``pytables`` are only accepted as strings and expressions types and not other data-types (:issue:`12027`)\n- ``DataFrame`` has dropped the ``combineAdd`` and ``combineMult`` methods in favor of ``add`` and ``mul`` respectively (:issue:`10735`)\n\n.. _whatsnew_0200.performance:\n\nPerformance improvements\n~~~~~~~~~~~~~~~~~~~~~~~~\n\n- Improved performance of ``pd.wide_to_long()`` (:issue:`14779`)\n- Improved performance of ``pd.factorize()`` by releasing the GIL with ``object`` dtype when inferred as strings (:issue:`14859`, :issue:`16057`)\n- Improved performance of timeseries plotting with an irregular DatetimeIndex\n  (or with ``compat_x=True``) (:issue:`15073`).\n- Improved performance of ``groupby().cummin()`` and ``groupby().cummax()`` (:issue:`15048`, :issue:`15109`, :issue:`15561`, :issue:`15635`)\n- Improved performance and reduced memory when indexing with a ``MultiIndex`` (:issue:`15245`)\n- When reading buffer object in ``read_sas()`` method without specified format, filepath string is inferred rather than buffer object. (:issue:`14947`)\n- Improved performance of ``.rank()`` for categorical data (:issue:`15498`)\n- Improved performance when using ``.unstack()`` (:issue:`15503`)\n- Improved performance of merge/join on ``category`` columns (:issue:`10409`)\n- Improved performance of ``drop_duplicates()`` on ``bool`` columns (:issue:`12963`)\n- Improve performance of ``pd.core.groupby.GroupBy.apply`` when the applied\n  function used the ``.name`` attribute of the group DataFrame (:issue:`15062`).\n- Improved performance of ``iloc`` indexing with a list or array (:issue:`15504`).\n- Improved performance of ``Series.sort_index()`` with a monotonic index (:issue:`15694`)\n- Improved performance in ``pd.read_csv()`` on some platforms with buffered reads (:issue:`16039`)\n\n.. _whatsnew_0200.bug_fixes:\n\nBug fixes\n~~~~~~~~~\n\nConversion\n^^^^^^^^^^\n\n- Bug in ``Timestamp.replace`` now raises ``TypeError`` when incorrect argument names are given; previously this raised ``ValueError`` (:issue:`15240`)\n- Bug in ``Timestamp.replace`` with compat for passing long integers (:issue:`15030`)\n- Bug in ``Timestamp`` returning UTC based time/date attributes when a timezone was provided (:issue:`13303`, :issue:`6538`)\n- Bug in ``Timestamp`` incorrectly localizing timezones during construction (:issue:`11481`, :issue:`15777`)\n- Bug in ``TimedeltaIndex`` addition where overflow was being allowed without error (:issue:`14816`)\n- Bug in ``TimedeltaIndex`` raising a ``ValueError`` when boolean indexing with ``loc`` (:issue:`14946`)\n- Bug in catching an overflow in ``Timestamp`` + ``Timedelta/Offset`` operations (:issue:`15126`)\n- Bug in ``DatetimeIndex.round()`` and ``Timestamp.round()`` floating point accuracy when rounding by milliseconds or less (:issue:`14440`, :issue:`15578`)\n- Bug in ``astype()`` where ``inf`` values were incorrectly converted to integers. Now raises error now with ``astype()`` for Series and DataFrames (:issue:`14265`)\n- Bug in ``DataFrame(..).apply(to_numeric)`` when values are of type decimal.Decimal. (:issue:`14827`)\n- Bug in ``describe()`` when passing a numpy array which does not contain the median to the ``percentiles`` keyword argument (:issue:`14908`)\n- Cleaned up ``PeriodIndex`` constructor, including raising on floats more consistently (:issue:`13277`)\n- Bug in using ``__deepcopy__`` on empty NDFrame objects (:issue:`15370`)\n- Bug in ``.replace()`` may result in incorrect dtypes. (:issue:`12747`, :issue:`15765`)\n- Bug in ``Series.replace`` and ``DataFrame.replace`` which failed on empty replacement dicts (:issue:`15289`)\n- Bug in ``Series.replace`` which replaced a numeric by string (:issue:`15743`)\n- Bug in ``Index`` construction with ``NaN`` elements and integer dtype specified (:issue:`15187`)\n- Bug in ``Series`` construction with a datetimetz (:issue:`14928`)\n- Bug in ``Series.dt.round()`` inconsistent behaviour on ``NaT`` 's with different arguments (:issue:`14940`)\n- Bug in ``Series`` constructor when both ``copy=True`` and ``dtype`` arguments are provided (:issue:`15125`)\n- Incorrect dtyped ``Series`` was returned by comparison methods (e.g., ``lt``, ``gt``, ...) against a constant for an empty ``DataFrame`` (:issue:`15077`)\n- Bug in ``Series.ffill()`` with mixed dtypes containing tz-aware datetimes. (:issue:`14956`)\n- Bug in ``DataFrame.fillna()`` where the argument ``downcast`` was ignored when fillna value was of type ``dict`` (:issue:`15277`)\n- Bug in ``.asfreq()``, where frequency was not set for empty ``Series`` (:issue:`14320`)\n- Bug in ``DataFrame`` construction with nulls and datetimes in a list-like (:issue:`15869`)\n- Bug in ``DataFrame.fillna()`` with tz-aware datetimes (:issue:`15855`)\n- Bug in ``is_string_dtype``, ``is_timedelta64_ns_dtype``, and ``is_string_like_dtype`` in which an error was raised when ``None`` was passed in (:issue:`15941`)\n- Bug in the return type of ``pd.unique`` on a ``Categorical``, which was returning an ndarray and not a ``Categorical`` (:issue:`15903`)\n- Bug in ``Index.to_series()`` where the index was not copied (and so mutating later would change the original), (:issue:`15949`)\n- Bug in indexing with partial string indexing with a len-1 DataFrame (:issue:`16071`)\n- Bug in ``Series`` construction where passing invalid dtype didn't raise an error. (:issue:`15520`)\n\nIndexing\n^^^^^^^^\n\n- Bug in ``Index`` power operations with reversed operands (:issue:`14973`)\n- Bug in ``DataFrame.sort_values()`` when sorting by multiple columns where one column is of type ``int64`` and contains ``NaT`` (:issue:`14922`)\n- Bug in ``DataFrame.reindex()`` in which ``method`` was ignored when passing ``columns`` (:issue:`14992`)\n- Bug in ``DataFrame.loc`` with indexing a ``MultiIndex`` with a ``Series`` indexer (:issue:`14730`, :issue:`15424`)\n- Bug in ``DataFrame.loc`` with indexing a ``MultiIndex`` with a numpy array (:issue:`15434`)\n- Bug in ``Series.asof`` which raised if the series contained all ``np.nan`` (:issue:`15713`)\n- Bug in ``.at`` when selecting from a tz-aware column (:issue:`15822`)\n- Bug in ``Series.where()`` and ``DataFrame.where()`` where array-like conditionals were being rejected (:issue:`15414`)\n- Bug in ``Series.where()`` where TZ-aware data was converted to float representation (:issue:`15701`)\n- Bug in ``.loc`` that would not return the correct dtype for scalar access for a DataFrame (:issue:`11617`)\n- Bug in output formatting of a ``MultiIndex`` when names are integers (:issue:`12223`, :issue:`15262`)\n- Bug in ``Categorical.searchsorted()`` where alphabetical instead of the provided categorical order was used (:issue:`14522`)\n- Bug in ``Series.iloc`` where a ``Categorical`` object for list-like indexes input was returned, where a ``Series`` was expected. (:issue:`14580`)\n- Bug in ``DataFrame.isin`` comparing datetimelike to empty frame (:issue:`15473`)\n- Bug in ``.reset_index()`` when an all ``NaN`` level of a ``MultiIndex`` would fail (:issue:`6322`)\n- Bug in ``.reset_index()`` when raising error for index name already present in ``MultiIndex`` columns (:issue:`16120`)\n- Bug in creating a ``MultiIndex`` with tuples and not passing a list of names; this will now raise ``ValueError`` (:issue:`15110`)\n- Bug in the HTML display with a ``MultiIndex`` and truncation (:issue:`14882`)\n- Bug in the display of ``.info()`` where a qualifier (+) would always be displayed with a ``MultiIndex`` that contains only non-strings (:issue:`15245`)\n- Bug in ``pd.concat()`` where the names of ``MultiIndex`` of resulting ``DataFrame`` are not handled correctly when ``None`` is presented in the names of ``MultiIndex`` of input ``DataFrame`` (:issue:`15787`)\n- Bug in ``DataFrame.sort_index()`` and ``Series.sort_index()`` where ``na_position`` doesn't work with a ``MultiIndex`` (:issue:`14784`, :issue:`16604`)\n- Bug in ``pd.concat()`` when combining objects with a ``CategoricalIndex`` (:issue:`16111`)\n- Bug in indexing with a scalar and a ``CategoricalIndex`` (:issue:`16123`)\n\nIO\n^^\n\n- Bug in ``pd.to_numeric()`` in which float and unsigned integer elements were being improperly casted (:issue:`14941`, :issue:`15005`)\n- Bug in ``pd.read_fwf()`` where the skiprows parameter was not being respected during column width inference (:issue:`11256`)\n- Bug in ``pd.read_csv()`` in which the ``dialect`` parameter was not being verified before processing (:issue:`14898`)\n- Bug in ``pd.read_csv()`` in which missing data was being improperly handled with ``usecols`` (:issue:`6710`)\n- Bug in ``pd.read_csv()`` in which a file containing a row with many columns followed by rows with fewer columns would cause a crash (:issue:`14125`)\n- Bug in ``pd.read_csv()`` for the C engine where ``usecols`` were being indexed incorrectly with ``parse_dates`` (:issue:`14792`)\n- Bug in ``pd.read_csv()`` with ``parse_dates`` when multi-line headers are specified (:issue:`15376`)\n- Bug in ``pd.read_csv()`` with ``float_precision='round_trip'`` which caused a segfault when a text entry is parsed (:issue:`15140`)\n- Bug in ``pd.read_csv()`` when an index was specified and no values were specified as null values (:issue:`15835`)\n- Bug in ``pd.read_csv()`` in which certain invalid file objects caused the Python interpreter to crash (:issue:`15337`)\n- Bug in ``pd.read_csv()`` in which invalid values for ``nrows`` and ``chunksize`` were allowed (:issue:`15767`)\n- Bug in ``pd.read_csv()`` for the Python engine in which unhelpful error messages were being raised when parsing errors occurred (:issue:`15910`)\n- Bug in ``pd.read_csv()`` in which the ``skipfooter`` parameter was not being properly validated (:issue:`15925`)\n- Bug in ``pd.to_csv()`` in which there was numeric overflow when a timestamp index was being written (:issue:`15982`)\n- Bug in ``pd.util.hashing.hash_pandas_object()`` in which hashing of categoricals depended on the ordering of categories, instead of just their values. (:issue:`15143`)\n- Bug in ``.to_json()`` where ``lines=True`` and contents (keys or values) contain escaped characters (:issue:`15096`)\n- Bug in ``.to_json()`` causing single byte ascii characters to be expanded to four byte unicode (:issue:`15344`)\n- Bug in ``.to_json()`` for the C engine where rollover was not correctly handled for case where frac is odd and diff is exactly 0.5 (:issue:`15716`, :issue:`15864`)\n- Bug in ``pd.read_json()`` for Python 2 where ``lines=True`` and contents contain non-ascii unicode characters (:issue:`15132`)\n- Bug in ``pd.read_msgpack()`` in which ``Series`` categoricals were being improperly processed (:issue:`14901`)\n- Bug in ``pd.read_msgpack()`` which did not allow loading of a dataframe with an index of type ``CategoricalIndex`` (:issue:`15487`)\n- Bug in ``pd.read_msgpack()`` when deserializing a ``CategoricalIndex`` (:issue:`15487`)\n- Bug in ``DataFrame.to_records()`` with converting a ``DatetimeIndex`` with a timezone (:issue:`13937`)\n- Bug in ``DataFrame.to_records()`` which failed with unicode characters in column names (:issue:`11879`)\n- Bug in ``.to_sql()`` when writing a DataFrame with numeric index names (:issue:`15404`).\n- Bug in ``DataFrame.to_html()`` with ``index=False`` and ``max_rows`` raising in ``IndexError`` (:issue:`14998`)\n- Bug in ``pd.read_hdf()`` passing a ``Timestamp`` to the ``where`` parameter with a non date column (:issue:`15492`)\n- Bug in ``DataFrame.to_stata()`` and ``StataWriter`` which produces incorrectly formatted files to be produced for some locales (:issue:`13856`)\n- Bug in ``StataReader`` and ``StataWriter`` which allows invalid encodings (:issue:`15723`)\n- Bug in the ``Series`` repr not showing the length when the output was truncated (:issue:`15962`).\n\nPlotting\n^^^^^^^^\n\n- Bug in ``DataFrame.hist`` where ``plt.tight_layout`` caused an ``AttributeError``  (use ``matplotlib >= 2.0.1``) (:issue:`9351`)\n- Bug in ``DataFrame.boxplot`` where ``fontsize`` was not applied to the tick labels on both axes (:issue:`15108`)\n- Bug in the date and time converters pandas registers with matplotlib not handling multiple dimensions (:issue:`16026`)\n- Bug in ``pd.scatter_matrix()`` could accept either ``color`` or ``c``, but not both (:issue:`14855`)\n\nGroupBy/resample/rolling\n^^^^^^^^^^^^^^^^^^^^^^^^\n\n- Bug in ``.groupby(..).resample()`` when passed the ``on=`` kwarg. (:issue:`15021`)\n- Properly set ``__name__`` and ``__qualname__`` for ``Groupby.*`` functions (:issue:`14620`)\n- Bug in ``GroupBy.get_group()`` failing with a categorical grouper (:issue:`15155`)\n- Bug in ``.groupby(...).rolling(...)`` when ``on`` is specified and using a ``DatetimeIndex`` (:issue:`15130`, :issue:`13966`)\n- Bug in groupby operations with ``timedelta64`` when passing ``numeric_only=False`` (:issue:`5724`)\n- Bug in ``groupby.apply()`` coercing ``object`` dtypes to numeric types, when not all values were numeric (:issue:`14423`, :issue:`15421`, :issue:`15670`)\n- Bug in ``resample``, where a non-string ``loffset`` argument would not be applied when resampling a timeseries (:issue:`13218`)\n- Bug in ``DataFrame.groupby().describe()`` when grouping on ``Index`` containing tuples (:issue:`14848`)\n- Bug in ``groupby().nunique()`` with a datetimelike-grouper where bins counts were incorrect (:issue:`13453`)\n- Bug in ``groupby.transform()`` that would coerce the resultant dtypes back to the original (:issue:`10972`, :issue:`11444`)\n- Bug in ``groupby.agg()`` incorrectly localizing timezone on ``datetime`` (:issue:`15426`, :issue:`10668`, :issue:`13046`)\n- Bug in ``.rolling/expanding()`` functions where ``count()`` was not counting ``np.Inf``, nor handling ``object`` dtypes (:issue:`12541`)\n- Bug in ``.rolling()`` where ``pd.Timedelta`` or ``datetime.timedelta`` was not accepted as a ``window`` argument (:issue:`15440`)\n- Bug in ``Rolling.quantile`` function that caused a segmentation fault when called with a quantile value outside of the range [0, 1] (:issue:`15463`)\n- Bug in ``DataFrame.resample().median()`` if duplicate column names are present (:issue:`14233`)\n\nSparse\n^^^^^^\n\n- Bug in ``SparseSeries.reindex`` on single level with list of length 1 (:issue:`15447`)\n- Bug in repr-formatting a ``SparseDataFrame`` after a value was set on (a copy of) one of its series (:issue:`15488`)\n- Bug in ``SparseDataFrame`` construction with lists not coercing to dtype (:issue:`15682`)\n- Bug in sparse array indexing in which indices were not being validated (:issue:`15863`)\n\nReshaping\n^^^^^^^^^\n\n- Bug in ``pd.merge_asof()`` where ``left_index`` or ``right_index`` caused a failure when multiple ``by`` was specified (:issue:`15676`)\n- Bug in ``pd.merge_asof()`` where ``left_index``/``right_index`` together caused a failure when ``tolerance`` was specified (:issue:`15135`)\n- Bug in ``DataFrame.pivot_table()`` where ``dropna=True`` would not drop all-NaN columns when the columns was a ``category`` dtype (:issue:`15193`)\n- Bug in ``pd.melt()`` where passing a tuple value for ``value_vars`` caused a ``TypeError`` (:issue:`15348`)\n- Bug in ``pd.pivot_table()`` where no error was raised when values argument was not in the columns (:issue:`14938`)\n- Bug in ``pd.concat()`` in which concatenating with an empty dataframe with ``join='inner'`` was being improperly handled (:issue:`15328`)\n- Bug with ``sort=True`` in ``DataFrame.join`` and ``pd.merge`` when joining on indexes (:issue:`15582`)\n- Bug in ``DataFrame.nsmallest`` and ``DataFrame.nlargest`` where identical values resulted in duplicated rows (:issue:`15297`)\n- Bug in :func:`pandas.pivot_table` incorrectly raising ``UnicodeError`` when passing unicode input for ``margins`` keyword (:issue:`13292`)\n\nNumeric\n^^^^^^^\n\n- Bug in ``.rank()`` which incorrectly ranks ordered categories (:issue:`15420`)\n- Bug in ``.corr()`` and ``.cov()`` where the column and index were the same object (:issue:`14617`)\n- Bug in ``.mode()`` where ``mode`` was not returned if was only a single value (:issue:`15714`)\n- Bug in ``pd.cut()`` with a single bin on an all 0s array (:issue:`15428`)\n- Bug in ``pd.qcut()`` with a single quantile and an array with identical values (:issue:`15431`)\n- Bug in ``pandas.tools.utils.cartesian_product()`` with large input can cause overflow on windows (:issue:`15265`)\n- Bug in ``.eval()`` which caused multi-line evals to fail with local variables not on the first line (:issue:`15342`)\n\nOther\n^^^^^\n\n- Compat with SciPy 0.19.0 for testing on ``.interpolate()`` (:issue:`15662`)\n- Compat for 32-bit platforms for ``.qcut/cut``; bins will now be ``int64`` dtype (:issue:`14866`)\n- Bug in interactions with ``Qt`` when a ``QtApplication`` already exists (:issue:`14372`)\n- Avoid use of ``np.finfo()`` during ``import pandas`` removed to mitigate deadlock on Python GIL misuse (:issue:`14641`)\n\n\n.. _whatsnew_0.20.0.contributors:\n\nContributors\n~~~~~~~~~~~~\n\n.. contributors:: v0.19.2..v0.20.0\n\n\n.. _whatsnew_214:\n\nWhat's new in 2.1.4 (December 8, 2023)\n---------------------------------------\n\nThese are the changes in pandas 2.1.4. See :ref:`release` for a full changelog\nincluding other versions of pandas.\n\n{{ header }}\n\n.. ---------------------------------------------------------------------------\n.. _whatsnew_214.regressions:\n\nFixed regressions\n~~~~~~~~~~~~~~~~~\n- Fixed regression when trying to read a pickled pandas :class:`DataFrame` from pandas 1.3 (:issue:`55137`)\n\n.. ---------------------------------------------------------------------------\n.. _whatsnew_214.bug_fixes:\n\nBug fixes\n~~~~~~~~~\n- Bug in :class:`Series` constructor raising DeprecationWarning when ``index`` is a list of :class:`Series` (:issue:`55228`)\n- Bug in :class:`Series` when trying to cast date-like string inputs to :class:`ArrowDtype` of ``pyarrow.timestamp`` (:issue:`56266`)\n- Bug in :class:`Timestamp` construction with ``ts_input=\"now\"`` or ``ts_input=\"today\"`` giving a different unit from :meth:`Timestamp.now` or :meth:`Timestamp.today` (:issue:`55879`)\n- Bug in :meth:`Index.__getitem__` returning wrong result for Arrow dtypes and negative stepsize (:issue:`55832`)\n- Fixed bug in :func:`read_csv` not respecting object dtype when ``infer_string`` option is set (:issue:`56047`)\n- Fixed bug in :func:`to_numeric` converting to extension dtype for ``string[pyarrow_numpy]`` dtype (:issue:`56179`)\n- Fixed bug in :meth:`.DataFrameGroupBy.min` and :meth:`.DataFrameGroupBy.max` not preserving extension dtype for empty object (:issue:`55619`)\n- Fixed bug in :meth:`DataFrame.__setitem__` casting :class:`Index` with object-dtype to PyArrow backed strings when ``infer_string`` option is set (:issue:`55638`)\n- Fixed bug in :meth:`DataFrame.to_hdf` raising when columns have ``StringDtype`` (:issue:`55088`)\n- Fixed bug in :meth:`Index.insert` casting object-dtype to PyArrow backed strings when ``infer_string`` option is set (:issue:`55638`)\n- Fixed bug in :meth:`Series.__ne__` resulting in False for comparison between ``NA`` and string value for ``dtype=\"string[pyarrow_numpy]\"`` (:issue:`56122`)\n- Fixed bug in :meth:`Series.mode` not keeping object dtype when ``infer_string`` is set (:issue:`56183`)\n- Fixed bug in :meth:`Series.reset_index` not preserving object dtype when ``infer_string`` is set (:issue:`56160`)\n- Fixed bug in :meth:`Series.str.split` and :meth:`Series.str.rsplit` when ``pat=None`` for :class:`ArrowDtype` with ``pyarrow.string`` (:issue:`56271`)\n- Fixed bug in :meth:`Series.str.translate` losing object dtype when string option is set (:issue:`56152`)\n\n.. ---------------------------------------------------------------------------\n.. _whatsnew_214.contributors:\n\nContributors\n~~~~~~~~~~~~\n\n.. contributors:: v2.1.3..v2.1.4\n\n\n.. _whatsnew_0702:\n\nVersion 0.7.2 (March 16, 2012)\n------------------------------\n\n{{ header }}\n\n\nThis release targets bugs in 0.7.1, and adds a few minor features.\n\nNew features\n~~~~~~~~~~~~\n\n  - Add additional tie-breaking methods in DataFrame.rank (:issue:`874`)\n  - Add ascending parameter to rank in Series, DataFrame (:issue:`875`)\n  - Add coerce_float option to DataFrame.from_records (:issue:`893`)\n  - Add sort_columns parameter to allow unsorted plots (:issue:`918`)\n  - Enable column access via attributes on GroupBy (:issue:`882`)\n  - Can pass dict of values to DataFrame.fillna (:issue:`661`)\n  - Can select multiple hierarchical groups by passing list of values in .ix\n    (:issue:`134`)\n  - Add ``axis`` option to DataFrame.fillna (:issue:`174`)\n  - Add level keyword to ``drop`` for dropping values from a level (:issue:`159`)\n\nPerformance improvements\n~~~~~~~~~~~~~~~~~~~~~~~~\n\n  - Use khash for Series.value_counts, add raw function to algorithms.py (:issue:`861`)\n  - Intercept __builtin__.sum in groupby (:issue:`885`)\n\n\n\n.. _whatsnew_0.7.2.contributors:\n\nContributors\n~~~~~~~~~~~~\n\n.. contributors:: v0.7.1..v0.7.2\n\n\n.. _whatsnew_211:\n\nWhat's new in 2.1.1 (September 20, 2023)\n----------------------------------------\n\nThese are the changes in pandas 2.1.1. See :ref:`release` for a full changelog\nincluding other versions of pandas.\n\n{{ header }}\n\n.. ---------------------------------------------------------------------------\n.. _whatsnew_211.regressions:\n\nFixed regressions\n~~~~~~~~~~~~~~~~~\n- Fixed regression in :func:`concat` when :class:`DataFrame` 's have two different extension dtypes (:issue:`54848`)\n- Fixed regression in :func:`merge` when merging over a PyArrow string index (:issue:`54894`)\n- Fixed regression in :func:`read_csv` when ``usecols`` is given and ``dtypes`` is a dict for ``engine=\"python\"`` (:issue:`54868`)\n- Fixed regression in :func:`read_csv` when ``delim_whitespace`` is True (:issue:`54918`, :issue:`54931`)\n- Fixed regression in :meth:`.GroupBy.get_group` raising for ``axis=1`` (:issue:`54858`)\n- Fixed regression in :meth:`DataFrame.__setitem__` raising ``AssertionError`` when setting a :class:`Series` with a partial :class:`MultiIndex` (:issue:`54875`)\n- Fixed regression in :meth:`DataFrame.filter` not respecting the order of elements for ``filter`` (:issue:`54980`)\n- Fixed regression in :meth:`DataFrame.to_sql` not roundtripping datetime columns correctly for sqlite (:issue:`54877`)\n- Fixed regression in :meth:`DataFrameGroupBy.agg` when aggregating a DataFrame with duplicate column names using a dictionary (:issue:`55006`)\n- Fixed regression in :meth:`MultiIndex.append` raising when appending overlapping :class:`IntervalIndex` levels (:issue:`54934`)\n- Fixed regression in :meth:`Series.drop_duplicates` for PyArrow strings (:issue:`54904`)\n- Fixed regression in :meth:`Series.interpolate` raising when ``fill_value`` was given (:issue:`54920`)\n- Fixed regression in :meth:`Series.value_counts` raising for numeric data if ``bins`` was specified (:issue:`54857`)\n- Fixed regression in comparison operations for PyArrow backed columns not propagating exceptions correctly (:issue:`54944`)\n- Fixed regression when comparing a :class:`Series` with ``datetime64`` dtype with ``None`` (:issue:`54870`)\n\n.. ---------------------------------------------------------------------------\n.. _whatsnew_211.bug_fixes:\n\nBug fixes\n~~~~~~~~~\n- Fixed bug for :class:`ArrowDtype` raising ``NotImplementedError`` for fixed-size list (:issue:`55000`)\n- Fixed bug in :meth:`DataFrame.stack` with ``future_stack=True`` and columns a non-:class:`MultiIndex` consisting of tuples (:issue:`54948`)\n- Fixed bug in :meth:`Series.dt.tz` with :class:`ArrowDtype` where a string was returned instead of a ``tzinfo`` object (:issue:`55003`)\n- Fixed bug in :meth:`Series.pct_change` and :meth:`DataFrame.pct_change` showing unnecessary ``FutureWarning`` (:issue:`54981`)\n\n.. ---------------------------------------------------------------------------\n.. _whatsnew_211.other:\n\nOther\n~~~~~\n- Reverted the deprecation that disallowed :meth:`Series.apply` returning a :class:`DataFrame` when the passed-in callable returns a :class:`Series` object (:issue:`52116`)\n\n.. ---------------------------------------------------------------------------\n.. _whatsnew_211.contributors:\n\nContributors\n~~~~~~~~~~~~\n\n.. contributors:: v2.1.0..v2.1.1\n\n\n.. _whatsnew_150:\n\nWhat's new in 1.5.0 (September 19, 2022)\n----------------------------------------\n\nThese are the changes in pandas 1.5.0. See :ref:`release` for a full changelog\nincluding other versions of pandas.\n\n{{ header }}\n\n.. ---------------------------------------------------------------------------\n.. _whatsnew_150.enhancements:\n\nEnhancements\n~~~~~~~~~~~~\n\n.. _whatsnew_150.enhancements.pandas-stubs:\n\n``pandas-stubs``\n^^^^^^^^^^^^^^^^\n\nThe ``pandas-stubs`` library is now supported by the pandas development team, providing type stubs for the pandas API. Please visit\nhttps://github.com/pandas-dev/pandas-stubs for more information.\n\nWe thank VirtusLab and Microsoft for their initial, significant contributions to ``pandas-stubs``\n\n.. _whatsnew_150.enhancements.arrow:\n\nNative PyArrow-backed ExtensionArray\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nWith `Pyarrow <https://arrow.apache.org/docs/python/index.html>`__ installed, users can now create pandas objects\nthat are backed by a ``pyarrow.ChunkedArray`` and ``pyarrow.DataType``.\n\nThe ``dtype`` argument can accept a string of a `pyarrow data type <https://arrow.apache.org/docs/python/api/datatypes.html>`__\nwith ``pyarrow`` in brackets e.g. ``\"int64[pyarrow]\"`` or, for pyarrow data types that take parameters, a :class:`ArrowDtype`\ninitialized with a ``pyarrow.DataType``.\n\n.. ipython:: python\n\n    import pyarrow as pa\n    ser_float = pd.Series([1.0, 2.0, None], dtype=\"float32[pyarrow]\")\n    ser_float\n\n    list_of_int_type = pd.ArrowDtype(pa.list_(pa.int64()))\n    ser_list = pd.Series([[1, 2], [3, None]], dtype=list_of_int_type)\n    ser_list\n\n    ser_list.take([1, 0])\n    ser_float * 5\n    ser_float.mean()\n    ser_float.dropna()\n\nMost operations are supported and have been implemented using `pyarrow compute <https://arrow.apache.org/docs/python/api/compute.html>`__ functions.\nWe recommend installing the latest version of PyArrow to access the most recently implemented compute functions.\n\n.. warning::\n\n    This feature is experimental, and the API can change in a future release without warning.\n\n.. _whatsnew_150.enhancements.dataframe_interchange:\n\nDataFrame interchange protocol implementation\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nPandas now implement the DataFrame interchange API spec.\nSee the full details on the API at https://data-apis.org/dataframe-protocol/latest/index.html\n\nThe protocol consists of two parts:\n\n- New method :meth:`DataFrame.__dataframe__` which produces the interchange object.\n  It effectively \"exports\" the pandas dataframe as an interchange object so\n  any other library which has the protocol implemented can \"import\" that dataframe\n  without knowing anything about the producer except that it makes an interchange object.\n- New function :func:`pandas.api.interchange.from_dataframe` which can take\n  an arbitrary interchange object from any conformant library and construct a\n  pandas DataFrame out of it.\n\n.. _whatsnew_150.enhancements.styler:\n\nStyler\n^^^^^^\n\nThe most notable development is the new method :meth:`.Styler.concat` which\nallows adding customised footer rows to visualise additional calculations on the data,\ne.g. totals and counts etc. (:issue:`43875`, :issue:`46186`)\n\nAdditionally there is an alternative output method :meth:`.Styler.to_string`,\nwhich allows using the Styler's formatting methods to create, for example, CSVs (:issue:`44502`).\n\nA new feature :meth:`.Styler.relabel_index` is also made available to provide full customisation of the display of\nindex or column headers (:issue:`47864`)\n\nMinor feature improvements are:\n\n  - Adding the ability to render ``border`` and ``border-{side}`` CSS properties in Excel (:issue:`42276`)\n  - Making keyword arguments consist: :meth:`.Styler.highlight_null` now accepts ``color`` and deprecates ``null_color`` although this remains backwards compatible (:issue:`45907`)\n\n.. _whatsnew_150.enhancements.resample_group_keys:\n\nControl of index with ``group_keys`` in :meth:`DataFrame.resample`\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nThe argument ``group_keys`` has been added to the method :meth:`DataFrame.resample`.\nAs with :meth:`DataFrame.groupby`, this argument controls the whether each group is added\nto the index in the resample when :meth:`.Resampler.apply` is used.\n\n.. warning::\n   Not specifying the ``group_keys`` argument will retain the\n   previous behavior and emit a warning if the result will change\n   by specifying ``group_keys=False``. In a future version\n   of pandas, not specifying ``group_keys`` will default to\n   the same behavior as ``group_keys=False``.\n\n.. code-block:: ipython\n\n    In [11]: df = pd.DataFrame(\n       ....:     {'a': range(6)},\n       ....:     index=pd.date_range(\"2021-01-01\", periods=6, freq=\"8H\")\n       ....: )\n       ....:\n\n    In [12]: df.resample(\"D\", group_keys=True).apply(lambda x: x)\n    Out[12]:\n                                    a\n    2021-01-01 2021-01-01 00:00:00  0\n               2021-01-01 08:00:00  1\n               2021-01-01 16:00:00  2\n    2021-01-02 2021-01-02 00:00:00  3\n               2021-01-02 08:00:00  4\n               2021-01-02 16:00:00  5\n\n    In [13]: df.resample(\"D\", group_keys=False).apply(lambda x: x)\n    Out[13]:\n                         a\n    2021-01-01 00:00:00  0\n    2021-01-01 08:00:00  1\n    2021-01-01 16:00:00  2\n    2021-01-02 00:00:00  3\n    2021-01-02 08:00:00  4\n    2021-01-02 16:00:00  5\n\nPreviously, the resulting index would depend upon the values returned by ``apply``,\nas seen in the following example.\n\n.. code-block:: ipython\n\n    In [1]:  pandas 1.3\n    In [2]: df.resample(\"D\").apply(lambda x: x)\n    Out[2]:\n                         a\n    2021-01-01 00:00:00  0\n    2021-01-01 08:00:00  1\n    2021-01-01 16:00:00  2\n    2021-01-02 00:00:00  3\n    2021-01-02 08:00:00  4\n    2021-01-02 16:00:00  5\n\n    In [3]: df.resample(\"D\").apply(lambda x: x.reset_index())\n    Out[3]:\n                               index  a\n    2021-01-01 0 2021-01-01 00:00:00  0\n               1 2021-01-01 08:00:00  1\n               2 2021-01-01 16:00:00  2\n    2021-01-02 0 2021-01-02 00:00:00  3\n               1 2021-01-02 08:00:00  4\n               2 2021-01-02 16:00:00  5\n\n.. _whatsnew_150.enhancements.from_dummies:\n\nfrom_dummies\n^^^^^^^^^^^^\n\nAdded new function :func:`~pandas.from_dummies` to convert a dummy coded :class:`DataFrame` into a categorical :class:`DataFrame`.\n\n.. ipython:: python\n\n    import pandas as pd\n\n    df = pd.DataFrame({\"col1_a\": [1, 0, 1], \"col1_b\": [0, 1, 0],\n                       \"col2_a\": [0, 1, 0], \"col2_b\": [1, 0, 0],\n                       \"col2_c\": [0, 0, 1]})\n\n    pd.from_dummies(df, sep=\"_\")\n\n.. _whatsnew_150.enhancements.orc:\n\nWriting to ORC files\n^^^^^^^^^^^^^^^^^^^^\n\nThe new method :meth:`DataFrame.to_orc` allows writing to ORC files (:issue:`43864`).\n\nThis functionality depends the `pyarrow <http://arrow.apache.org/docs/python/>`__ library. For more details, see :ref:`the IO docs on ORC <io.orc>`.\n\n.. warning::\n\n   * It is *highly recommended* to install pyarrow using conda due to some issues occurred by pyarrow.\n   * :func:`~pandas.DataFrame.to_orc` requires pyarrow>=7.0.0.\n   * :func:`~pandas.DataFrame.to_orc` is not supported on Windows yet, you can find valid environments on :ref:`install optional dependencies <install.warn_orc>`.\n   * For supported dtypes please refer to `supported ORC features in Arrow <https://arrow.apache.org/docs/cpp/orc.html#data-types>`__.\n   * Currently timezones in datetime columns are not preserved when a dataframe is converted into ORC files.\n\n.. code-block:: python\n\n    df = pd.DataFrame(data={\"col1\": [1, 2], \"col2\": [3, 4]})\n    df.to_orc(\"./out.orc\")\n\n.. _whatsnew_150.enhancements.tar:\n\nReading directly from TAR archives\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nI/O methods like :func:`read_csv` or :meth:`DataFrame.to_json` now allow reading and writing\ndirectly on TAR archives (:issue:`44787`).\n\n.. code-block:: python\n\n   df = pd.read_csv(\"./movement.tar.gz\")\n    ...\n   df.to_csv(\"./out.tar.gz\")\n\nThis supports ``.tar``, ``.tar.gz``, ``.tar.bz`` and ``.tar.xz2`` archives.\nThe used compression method is inferred from the filename.\nIf the compression method cannot be inferred, use the ``compression`` argument:\n\n.. code-block:: python\n\n   df = pd.read_csv(some_file_obj, compression={\"method\": \"tar\", \"mode\": \"r:gz\"})  noqa F821\n\n(``mode`` being one of ``tarfile.open``'s modes: https://docs.python.org/3/library/tarfile.html#tarfile.open)\n\n\n.. _whatsnew_150.enhancements.read_xml_dtypes:\n\nread_xml now supports ``dtype``, ``converters``, and ``parse_dates``\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nSimilar to other IO methods, :func:`pandas.read_xml` now supports assigning specific dtypes to columns,\napply converter methods, and parse dates (:issue:`43567`).\n\n.. ipython:: python\n\n    from io import StringIO\n    xml_dates = \"\"\"<?xml version='1.0' encoding='utf-8'?>\n    <data>\n      <row>\n        <shape>square</shape>\n        <degrees>00360</degrees>\n        <sides>4.0</sides>\n        <date>2020-01-01</date>\n       </row>\n      <row>\n        <shape>circle</shape>\n        <degrees>00360</degrees>\n        <sides/>\n        <date>2021-01-01</date>\n      </row>\n      <row>\n        <shape>triangle</shape>\n        <degrees>00180</degrees>\n        <sides>3.0</sides>\n        <date>2022-01-01</date>\n      </row>\n    </data>\"\"\"\n\n    df = pd.read_xml(\n        StringIO(xml_dates),\n        dtype={'sides': 'Int64'},\n        converters={'degrees': str},\n        parse_dates=['date']\n    )\n    df\n    df.dtypes\n\n\n.. _whatsnew_150.enhancements.read_xml_iterparse:\n\nread_xml now supports large XML using ``iterparse``\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nFor very large XML files that can range in hundreds of megabytes to gigabytes, :func:`pandas.read_xml`\nnow supports parsing such sizeable files using `lxml's iterparse`_ and `etree's iterparse`_\nwhich are memory-efficient methods to iterate through XML trees and extract specific elements\nand attributes without holding entire tree in memory (:issue:`45442`).\n\n.. code-block:: ipython\n\n    In [1]: df = pd.read_xml(\n    ...      \"/path/to/downloaded/enwikisource-latest-pages-articles.xml\",\n    ...      iterparse = {\"page\": [\"title\", \"ns\", \"id\"]})\n    ...  )\n    df\n    Out[2]:\n                                                         title   ns        id\n    0                                       Gettysburg Address    0     21450\n    1                                                Main Page    0     42950\n    2                            Declaration by United Nations    0      8435\n    3             Constitution of the United States of America    0      8435\n    4                     Declaration of Independence (Israel)    0     17858\n    ...                                                    ...  ...       ...\n    3578760               Page:Black cat 1897 07 v2 n10.pdf/17  104    219649\n    3578761               Page:Black cat 1897 07 v2 n10.pdf/43  104    219649\n    3578762               Page:Black cat 1897 07 v2 n10.pdf/44  104    219649\n    3578763      The History of Tom Jones, a Foundling/Book IX    0  12084291\n    3578764  Page:Shakespeare of Stratford (1926) Yale.djvu/91  104     21450\n\n    [3578765 rows x 3 columns]\n\n\n.. _`lxml's iterparse`: https://lxml.de/3.2/parsing.html#iterparse-and-iterwalk\n.. _`etree's iterparse`: https://docs.python.org/3/library/xml.etree.elementtree.html#xml.etree.ElementTree.iterparse\n\n.. _whatsnew_150.enhancements.copy_on_write:\n\nCopy on Write\n^^^^^^^^^^^^^\n\nA new feature ``copy_on_write`` was added (:issue:`46958`). Copy on write ensures that\nany DataFrame or Series derived from another in any way always behaves as a copy.\nCopy on write disallows updating any other object than the object the method\nwas applied to.\n\nCopy on write can be enabled through:\n\n.. code-block:: python\n\n    pd.set_option(\"mode.copy_on_write\", True)\n    pd.options.mode.copy_on_write = True\n\nAlternatively, copy on write can be enabled locally through:\n\n.. code-block:: python\n\n    with pd.option_context(\"mode.copy_on_write\", True):\n        ...\n\nWithout copy on write, the parent :class:`DataFrame` is updated when updating a child\n:class:`DataFrame` that was derived from this :class:`DataFrame`.\n\n.. ipython:: python\n\n    df = pd.DataFrame({\"foo\": [1, 2, 3], \"bar\": 1})\n    view = df[\"foo\"]\n    view.iloc[0]\n    df\n\nWith copy on write enabled, df won't be updated anymore:\n\n.. ipython:: python\n\n    with pd.option_context(\"mode.copy_on_write\", True):\n        df = pd.DataFrame({\"foo\": [1, 2, 3], \"bar\": 1})\n        view = df[\"foo\"]\n        view.iloc[0]\n        df\n\nA more detailed explanation can be found `here <https://phofl.github.io/cow-introduction.html>`_.\n\n.. _whatsnew_150.enhancements.other:\n\nOther enhancements\n^^^^^^^^^^^^^^^^^^\n- :meth:`Series.map` now raises when ``arg`` is dict but ``na_action`` is not either ``None`` or ``'ignore'`` (:issue:`46588`)\n- :meth:`MultiIndex.to_frame` now supports the argument ``allow_duplicates`` and raises on duplicate labels if it is missing or False (:issue:`45245`)\n- :class:`.StringArray` now accepts array-likes containing nan-likes (``None``, ``np.nan``) for the ``values`` parameter in its constructor in addition to strings and :attr:`pandas.NA`. (:issue:`40839`)\n- Improved the rendering of ``categories`` in :class:`CategoricalIndex` (:issue:`45218`)\n- :meth:`DataFrame.plot` will now allow the ``subplots`` parameter to be a list of iterables specifying column groups, so that columns may be grouped together in the same subplot (:issue:`29688`).\n- :meth:`to_numeric` now preserves float64 arrays when downcasting would generate values not representable in float32 (:issue:`43693`)\n- :meth:`Series.reset_index` and :meth:`DataFrame.reset_index` now support the argument ``allow_duplicates`` (:issue:`44410`)\n- :meth:`.DataFrameGroupBy.min`, :meth:`.SeriesGroupBy.min`, :meth:`.DataFrameGroupBy.max`, and :meth:`.SeriesGroupBy.max` now supports `Numba <https://numba.pydata.org/>`_ execution with the ``engine`` keyword (:issue:`45428`)\n- :func:`read_csv` now supports ``defaultdict`` as a ``dtype`` parameter (:issue:`41574`)\n- :meth:`DataFrame.rolling` and :meth:`Series.rolling` now support a ``step`` parameter with fixed-length windows (:issue:`15354`)\n- Implemented a ``bool``-dtype :class:`Index`, passing a bool-dtype array-like to ``pd.Index`` will now retain ``bool`` dtype instead of casting to ``object`` (:issue:`45061`)\n- Implemented a complex-dtype :class:`Index`, passing a complex-dtype array-like to ``pd.Index`` will now retain complex dtype instead of casting to ``object`` (:issue:`45845`)\n- :class:`Series` and :class:`DataFrame` with :class:`IntegerDtype` now supports bitwise operations (:issue:`34463`)\n- Add ``milliseconds`` field support for :class:`.DateOffset` (:issue:`43371`)\n- :meth:`DataFrame.where` tries to maintain dtype of :class:`DataFrame` if fill value can be cast without loss of precision (:issue:`45582`)\n- :meth:`DataFrame.reset_index` now accepts a ``names`` argument which renames the index names (:issue:`6878`)\n- :func:`concat` now raises when ``levels`` is given but ``keys`` is None (:issue:`46653`)\n- :func:`concat` now raises when ``levels`` contains duplicate values (:issue:`46653`)\n- Added ``numeric_only`` argument to :meth:`DataFrame.corr`, :meth:`DataFrame.corrwith`, :meth:`DataFrame.cov`, :meth:`DataFrame.idxmin`, :meth:`DataFrame.idxmax`, :meth:`.DataFrameGroupBy.idxmin`, :meth:`.DataFrameGroupBy.idxmax`, :meth:`.DataFrameGroupBy.var`, :meth:`.SeriesGroupBy.var`, :meth:`.DataFrameGroupBy.std`, :meth:`.SeriesGroupBy.std`, :meth:`.DataFrameGroupBy.sem`, :meth:`.SeriesGroupBy.sem`, and :meth:`.DataFrameGroupBy.quantile` (:issue:`46560`)\n- A :class:`errors.PerformanceWarning` is now thrown when using ``string[pyarrow]`` dtype with methods that don't dispatch to ``pyarrow.compute`` methods (:issue:`42613`, :issue:`46725`)\n- Added ``validate`` argument to :meth:`DataFrame.join` (:issue:`46622`)\n- Added ``numeric_only`` argument to :meth:`.Resampler.sum`, :meth:`.Resampler.prod`, :meth:`.Resampler.min`, :meth:`.Resampler.max`, :meth:`.Resampler.first`, and :meth:`.Resampler.last` (:issue:`46442`)\n- ``times`` argument in :class:`.ExponentialMovingWindow` now accepts ``np.timedelta64`` (:issue:`47003`)\n- :class:`.DataError`, :class:`.SpecificationError`, :class:`.SettingWithCopyError`, :class:`.SettingWithCopyWarning`, :class:`.NumExprClobberingError`, :class:`.UndefinedVariableError`, :class:`.IndexingError`, :class:`.PyperclipException`, :class:`.PyperclipWindowsException`, :class:`.CSSWarning`, :class:`.PossibleDataLossError`, :class:`.ClosedFileError`, :class:`.IncompatibilityWarning`, :class:`.AttributeConflictWarning`, :class:`.DatabaseError`, :class:`.PossiblePrecisionLoss`, :class:`.ValueLabelTypeMismatch`, :class:`.InvalidColumnName`, and :class:`.CategoricalConversionWarning` are now exposed in ``pandas.errors`` (:issue:`27656`)\n- Added ``check_like`` argument to :func:`testing.assert_series_equal` (:issue:`47247`)\n- Add support for :meth:`.DataFrameGroupBy.ohlc` and :meth:`.SeriesGroupBy.ohlc` for extension array dtypes (:issue:`37493`)\n- Allow reading compressed SAS files with :func:`read_sas` (e.g., ``.sas7bdat.gz`` files)\n- :func:`pandas.read_html` now supports extracting links from table cells (:issue:`13141`)\n- :meth:`DatetimeIndex.astype` now supports casting timezone-naive indexes to ``datetime64[s]``, ``datetime64[ms]``, and ``datetime64[us]``, and timezone-aware indexes to the corresponding ``datetime64[unit, tzname]`` dtypes (:issue:`47579`)\n- :class:`Series` reducers (e.g. ``min``, ``max``, ``sum``, ``mean``) will now successfully operate when the dtype is numeric and ``numeric_only=True`` is provided; previously this would raise a ``NotImplementedError`` (:issue:`47500`)\n- :meth:`RangeIndex.union` now can return a :class:`RangeIndex` instead of a :class:`Int64Index` if the resulting values are equally spaced (:issue:`47557`, :issue:`43885`)\n- :meth:`DataFrame.compare` now accepts an argument ``result_names`` to allow the user to specify the result's names of both left and right DataFrame which are being compared. This is by default ``'self'`` and ``'other'`` (:issue:`44354`)\n- :meth:`DataFrame.quantile` gained a ``method`` argument that can accept ``table`` to evaluate multi-column quantiles (:issue:`43881`)\n- :class:`Interval` now supports checking whether one interval is contained by another interval (:issue:`46613`)\n- Added ``copy`` keyword to :meth:`Series.set_axis` and :meth:`DataFrame.set_axis` to allow user to set axis on a new object without necessarily copying the underlying data (:issue:`47932`)\n- The method :meth:`.ExtensionArray.factorize` accepts ``use_na_sentinel=False`` for determining how null values are to be treated (:issue:`46601`)\n- The ``Dockerfile`` now installs a dedicated ``pandas-dev`` virtual environment for pandas development instead of using the ``base`` environment (:issue:`48427`)\n\n.. ---------------------------------------------------------------------------\n.. _whatsnew_150.notable_bug_fixes:\n\nNotable bug fixes\n~~~~~~~~~~~~~~~~~\n\nThese are bug fixes that might have notable behavior changes.\n\n.. _whatsnew_150.notable_bug_fixes.groupby_transform_dropna:\n\nUsing ``dropna=True`` with ``groupby`` transforms\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nA transform is an operation whose result has the same size as its input. When the\nresult is a :class:`DataFrame` or :class:`Series`, it is also required that the\nindex of the result matches that of the input. In pandas 1.4, using\n:meth:`.DataFrameGroupBy.transform` or :meth:`.SeriesGroupBy.transform` with null\nvalues in the groups and ``dropna=True`` gave incorrect results. Demonstrated by the\nexamples below, the incorrect results either contained incorrect values, or the result\ndid not have the same index as the input.\n\n.. ipython:: python\n\n    df = pd.DataFrame({'a': [1, 1, np.nan], 'b': [2, 3, 4]})\n\n*Old behavior*:\n\n.. code-block:: ipython\n\n    In [3]:  Value in the last row should be np.nan\n            df.groupby('a', dropna=True).transform('sum')\n    Out[3]:\n       b\n    0  5\n    1  5\n    2  5\n\n    In [3]:  Should have one additional row with the value np.nan\n            df.groupby('a', dropna=True).transform(lambda x: x.sum())\n    Out[3]:\n       b\n    0  5\n    1  5\n\n    In [3]:  The value in the last row is np.nan interpreted as an integer\n            df.groupby('a', dropna=True).transform('ffill')\n    Out[3]:\n                         b\n    0                    2\n    1                    3\n    2 -9223372036854775808\n\n    In [3]:  Should have one additional row with the value np.nan\n            df.groupby('a', dropna=True).transform(lambda x: x)\n    Out[3]:\n       b\n    0  2\n    1  3\n\n*New behavior*:\n\n.. ipython:: python\n\n    df.groupby('a', dropna=True).transform('sum')\n    df.groupby('a', dropna=True).transform(lambda x: x.sum())\n    df.groupby('a', dropna=True).transform('ffill')\n    df.groupby('a', dropna=True).transform(lambda x: x)\n\n.. _whatsnew_150.notable_bug_fixes.to_json_incorrectly_localizing_naive_timestamps:\n\nSerializing tz-naive Timestamps with to_json() with ``iso_dates=True``\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n:meth:`DataFrame.to_json`, :meth:`Series.to_json`, and :meth:`Index.to_json`\nwould incorrectly localize DatetimeArrays/DatetimeIndexes with tz-naive Timestamps\nto UTC. (:issue:`38760`)\n\nNote that this patch does not fix the localization of tz-aware Timestamps to UTC\nupon serialization. (Related issue :issue:`12997`)\n\n*Old Behavior*\n\n.. code-block:: ipython\n\n    In [32]: index = pd.date_range(\n       ....:     start='2020-12-28 00:00:00',\n       ....:     end='2020-12-28 02:00:00',\n       ....:     freq='1H',\n       ....: )\n       ....:\n\n    In [33]: a = pd.Series(\n       ....:     data=range(3),\n       ....:     index=index,\n       ....: )\n       ....:\n\n    In [4]: from io import StringIO\n\n    In [5]: a.to_json(date_format='iso')\n    Out[5]: '{\"2020-12-28T00:00:00.000Z\":0,\"2020-12-28T01:00:00.000Z\":1,\"2020-12-28T02:00:00.000Z\":2}'\n\n    In [6]: pd.read_json(StringIO(a.to_json(date_format='iso')), typ=\"series\").index == a.index\n    Out[6]: array([False, False, False])\n\n*New Behavior*\n\n.. code-block:: ipython\n\n    In [34]: from io import StringIO\n\n    In [35]: a.to_json(date_format='iso')\n    Out[35]: '{\"2020-12-28T00:00:00.000Z\":0,\"2020-12-28T01:00:00.000Z\":1,\"2020-12-28T02:00:00.000Z\":2}'\n\n     Roundtripping now works\n    In [36]: pd.read_json(StringIO(a.to_json(date_format='iso')), typ=\"series\").index == a.index\n    Out[36]: array([ True,  True,  True])\n\n.. _whatsnew_150.notable_bug_fixes.groupby_value_counts_categorical:\n\nDataFrameGroupBy.value_counts with non-grouping categorical columns and ``observed=True``\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nCalling :meth:`.DataFrameGroupBy.value_counts` with ``observed=True`` would incorrectly drop non-observed categories of non-grouping columns (:issue:`46357`).\n\n.. code-block:: ipython\n\n    In [6]: df = pd.DataFrame([\"a\", \"b\", \"c\"], dtype=\"category\").iloc[0:2]\n    In [7]: df\n    Out[7]:\n       0\n    0  a\n    1  b\n\n*Old Behavior*\n\n.. code-block:: ipython\n\n    In [8]: df.groupby(level=0, observed=True).value_counts()\n    Out[8]:\n    0  a    1\n    1  b    1\n    dtype: int64\n\n\n*New Behavior*\n\n.. code-block:: ipython\n\n    In [9]: df.groupby(level=0, observed=True).value_counts()\n    Out[9]:\n    0  a    1\n    1  a    0\n       b    1\n    0  b    0\n       c    0\n    1  c    0\n    dtype: int64\n\n.. ---------------------------------------------------------------------------\n.. _whatsnew_150.api_breaking:\n\nBackwards incompatible API changes\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\n.. _whatsnew_150.api_breaking.deps:\n\nIncreased minimum versions for dependencies\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nSome minimum supported versions of dependencies were updated.\nIf installed, we now require:\n\n+-----------------+-----------------+----------+---------+\n| Package         | Minimum Version | Required | Changed |\n+=================+=================+==========+=========+\n| numpy           | 1.20.3          |    X     |    X    |\n+-----------------+-----------------+----------+---------+\n| mypy (dev)      | 0.971           |          |    X    |\n+-----------------+-----------------+----------+---------+\n| beautifulsoup4  | 4.9.3           |          |    X    |\n+-----------------+-----------------+----------+---------+\n| blosc           | 1.21.0          |          |    X    |\n+-----------------+-----------------+----------+---------+\n| bottleneck      | 1.3.2           |          |    X    |\n+-----------------+-----------------+----------+---------+\n| fsspec          | 2021.07.0       |          |    X    |\n+-----------------+-----------------+----------+---------+\n| hypothesis      | 6.13.0          |          |    X    |\n+-----------------+-----------------+----------+---------+\n| gcsfs           | 2021.07.0       |          |    X    |\n+-----------------+-----------------+----------+---------+\n| jinja2          | 3.0.0           |          |    X    |\n+-----------------+-----------------+----------+---------+\n| lxml            | 4.6.3           |          |    X    |\n+-----------------+-----------------+----------+---------+\n| numba           | 0.53.1          |          |    X    |\n+-----------------+-----------------+----------+---------+\n| numexpr         | 2.7.3           |          |    X    |\n+-----------------+-----------------+----------+---------+\n| openpyxl        | 3.0.7           |          |    X    |\n+-----------------+-----------------+----------+---------+\n| pandas-gbq      | 0.15.0          |          |    X    |\n+-----------------+-----------------+----------+---------+\n| psycopg2        | 2.8.6           |          |    X    |\n+-----------------+-----------------+----------+---------+\n| pymysql         | 1.0.2           |          |    X    |\n+-----------------+-----------------+----------+---------+\n| pyreadstat      | 1.1.2           |          |    X    |\n+-----------------+-----------------+----------+---------+\n| pyxlsb          | 1.0.8           |          |    X    |\n+-----------------+-----------------+----------+---------+\n| s3fs            | 2021.08.0       |          |    X    |\n+-----------------+-----------------+----------+---------+\n| scipy           | 1.7.1           |          |    X    |\n+-----------------+-----------------+----------+---------+\n| sqlalchemy      | 1.4.16          |          |    X    |\n+-----------------+-----------------+----------+---------+\n| tabulate        | 0.8.9           |          |    X    |\n+-----------------+-----------------+----------+---------+\n| xarray          | 0.19.0          |          |    X    |\n+-----------------+-----------------+----------+---------+\n| xlsxwriter      | 1.4.3           |          |    X    |\n+-----------------+-----------------+----------+---------+\n\nFor `optional libraries <https://pandas.pydata.org/docs/getting_started/install.html>`_ the general recommendation is to use the latest version.\nThe following table lists the lowest version per library that is currently being tested throughout the development of pandas.\nOptional libraries below the lowest tested version may still work, but are not considered supported.\n\n+-----------------+-----------------+---------+\n| Package         | Minimum Version | Changed |\n+=================+=================+=========+\n| beautifulsoup4  |4.9.3            |    X    |\n+-----------------+-----------------+---------+\n| blosc           |1.21.0           |    X    |\n+-----------------+-----------------+---------+\n| bottleneck      |1.3.2            |    X    |\n+-----------------+-----------------+---------+\n| brotlipy        |0.7.0            |         |\n+-----------------+-----------------+---------+\n| fastparquet     |0.4.0            |         |\n+-----------------+-----------------+---------+\n| fsspec          |2021.08.0        |    X    |\n+-----------------+-----------------+---------+\n| html5lib        |1.1              |         |\n+-----------------+-----------------+---------+\n| hypothesis      |6.13.0           |    X    |\n+-----------------+-----------------+---------+\n| gcsfs           |2021.08.0        |    X    |\n+-----------------+-----------------+---------+\n| jinja2          |3.0.0            |    X    |\n+-----------------+-----------------+---------+\n| lxml            |4.6.3            |    X    |\n+-----------------+-----------------+---------+\n| matplotlib      |3.3.2            |         |\n+-----------------+-----------------+---------+\n| numba           |0.53.1           |    X    |\n+-----------------+-----------------+---------+\n| numexpr         |2.7.3            |    X    |\n+-----------------+-----------------+---------+\n| odfpy           |1.4.1            |         |\n+-----------------+-----------------+---------+\n| openpyxl        |3.0.7            |    X    |\n+-----------------+-----------------+---------+\n| pandas-gbq      |0.15.0           |    X    |\n+-----------------+-----------------+---------+\n| psycopg2        |2.8.6            |    X    |\n+-----------------+-----------------+---------+\n| pyarrow         |1.0.1            |         |\n+-----------------+-----------------+---------+\n| pymysql         |1.0.2            |    X    |\n+-----------------+-----------------+---------+\n| pyreadstat      |1.1.2            |    X    |\n+-----------------+-----------------+---------+\n| pytables        |3.6.1            |         |\n+-----------------+-----------------+---------+\n| python-snappy   |0.6.0            |         |\n+-----------------+-----------------+---------+\n| pyxlsb          |1.0.8            |    X    |\n+-----------------+-----------------+---------+\n| s3fs            |2021.08.0        |    X    |\n+-----------------+-----------------+---------+\n| scipy           |1.7.1            |    X    |\n+-----------------+-----------------+---------+\n| sqlalchemy      |1.4.16           |    X    |\n+-----------------+-----------------+---------+\n| tabulate        |0.8.9            |    X    |\n+-----------------+-----------------+---------+\n| tzdata          |2022a            |         |\n+-----------------+-----------------+---------+\n| xarray          |0.19.0           |    X    |\n+-----------------+-----------------+---------+\n| xlrd            |2.0.1            |         |\n+-----------------+-----------------+---------+\n| xlsxwriter      |1.4.3            |    X    |\n+-----------------+-----------------+---------+\n| xlwt            |1.3.0            |         |\n+-----------------+-----------------+---------+\n| zstandard       |0.15.2           |         |\n+-----------------+-----------------+---------+\n\nSee :ref:`install.dependencies` and :ref:`install.optional_dependencies` for more.\n\n.. _whatsnew_150.api_breaking.other:\n\nOther API changes\n^^^^^^^^^^^^^^^^^\n\n- BigQuery I/O methods :func:`read_gbq` and :meth:`DataFrame.to_gbq` default to\n  ``auth_local_webserver = True``. Google has deprecated the\n  ``auth_local_webserver = False`` `\"out of band\" (copy-paste) flow\n  <https://developers.googleblog.com/2022/02/making-oauth-flows-safer.html?m=1#disallowed-oob>`_.\n  The ``auth_local_webserver = False`` option is planned to stop working in\n  October 2022. (:issue:`46312`)\n- :func:`read_json` now raises ``FileNotFoundError`` (previously ``ValueError``) when input is a string ending in ``.json``, ``.json.gz``, ``.json.bz2``, etc. but no such file exists. (:issue:`29102`)\n- Operations with :class:`Timestamp` or :class:`Timedelta` that would previously raise ``OverflowError`` instead raise ``OutOfBoundsDatetime`` or ``OutOfBoundsTimedelta`` where appropriate (:issue:`47268`)\n- When :func:`read_sas` previously returned ``None``, it now returns an empty :class:`DataFrame` (:issue:`47410`)\n- :class:`DataFrame` constructor raises if ``index`` or ``columns`` arguments are sets (:issue:`47215`)\n\n.. ---------------------------------------------------------------------------\n.. _whatsnew_150.deprecations:\n\nDeprecations\n~~~~~~~~~~~~\n\n.. warning::\n\n    In the next major version release, 2.0, several larger API changes are being considered without a formal deprecation such as\n    making the standard library `zoneinfo <https://docs.python.org/3/library/zoneinfo.html>`_ the default timezone implementation instead of ``pytz``,\n    having the :class:`Index` support all data types instead of having multiple subclasses (:class:`CategoricalIndex`, :class:`Int64Index`, etc.), and more.\n    The changes under consideration are logged in `this GitHub issue <https://github.com/pandas-dev/pandas/issues/44823>`_, and any\n    feedback or concerns are welcome.\n\n.. _whatsnew_150.deprecations.int_slicing_series:\n\nLabel-based integer slicing on a Series with an Int64Index or RangeIndex\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nIn a future version, integer slicing on a :class:`Series` with a :class:`Int64Index` or :class:`RangeIndex` will be treated as *label-based*, not positional. This will make the behavior consistent with other :meth:`Series.__getitem__` and :meth:`Series.__setitem__` behaviors (:issue:`45162`).\n\nFor example:\n\n.. ipython:: python\n\n   ser = pd.Series([1, 2, 3, 4, 5], index=[2, 3, 5, 7, 11])\n\nIn the old behavior, ``ser[2:4]`` treats the slice as positional:\n\n*Old behavior*:\n\n.. code-block:: ipython\n\n    In [3]: ser[2:4]\n    Out[3]:\n    5    3\n    7    4\n    dtype: int64\n\nIn a future version, this will be treated as label-based:\n\n*Future behavior*:\n\n.. code-block:: ipython\n\n    In [4]: ser.loc[2:4]\n    Out[4]:\n    2    1\n    3    2\n    dtype: int64\n\nTo retain the old behavior, use ``series.iloc[i:j]``. To get the future behavior,\nuse ``series.loc[i:j]``.\n\nSlicing on a :class:`DataFrame` will not be affected.\n\n.. _whatsnew_150.deprecations.excel_writer_attributes:\n\n:class:`ExcelWriter` attributes\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nAll attributes of :class:`ExcelWriter` were previously documented as not\npublic. However some third party Excel engines documented accessing\n``ExcelWriter.book`` or ``ExcelWriter.sheets``, and users were utilizing these\nand possibly other attributes. Previously these attributes were not safe to use;\ne.g. modifications to ``ExcelWriter.book`` would not update ``ExcelWriter.sheets``\nand conversely. In order to support this, pandas has made some attributes public\nand improved their implementations so that they may now be safely used. (:issue:`45572`)\n\nThe following attributes are now public and considered safe to access.\n\n - ``book``\n - ``check_extension``\n - ``close``\n - ``date_format``\n - ``datetime_format``\n - ``engine``\n - ``if_sheet_exists``\n - ``sheets``\n - ``supported_extensions``\n\nThe following attributes have been deprecated. They now raise a ``FutureWarning``\nwhen accessed and will be removed in a future version. Users should be aware\nthat their usage is considered unsafe, and can lead to unexpected results.\n\n - ``cur_sheet``\n - ``handles``\n - ``path``\n - ``save``\n - ``write_cells``\n\nSee the documentation of :class:`ExcelWriter` for further details.\n\n.. _whatsnew_150.deprecations.group_keys_in_apply:\n\nUsing ``group_keys`` with transformers in :meth:`.DataFrameGroupBy.apply` and :meth:`.SeriesGroupBy.apply`\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nIn previous versions of pandas, if it was inferred that the function passed to\n:meth:`.DataFrameGroupBy.apply` or :meth:`.SeriesGroupBy.apply` was a transformer (i.e. the resulting index was equal to\nthe input index), the ``group_keys`` argument of :meth:`DataFrame.groupby` and\n:meth:`Series.groupby` was ignored and the group keys would never be added to\nthe index of the result. In the future, the group keys will be added to the index\nwhen the user specifies ``group_keys=True``.\n\nAs ``group_keys=True`` is the default value of :meth:`DataFrame.groupby` and\n:meth:`Series.groupby`, not specifying ``group_keys`` with a transformer will\nraise a ``FutureWarning``. This can be silenced and the previous behavior\nretained by specifying ``group_keys=False``.\n\n.. _whatsnew_150.deprecations.setitem_column_try_inplace:\n   _ see also _whatsnew_130.notable_bug_fixes.setitem_column_try_inplace\n\nInplace operation when setting values with ``loc`` and ``iloc``\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nMost of the time setting values with :meth:`DataFrame.iloc` attempts to set values\ninplace, only falling back to inserting a new array if necessary. There are\nsome cases where this rule is not followed, for example when setting an entire\ncolumn from an array with different dtype:\n\n.. ipython:: python\n\n   df = pd.DataFrame({'price': [11.1, 12.2]}, index=['book1', 'book2'])\n   original_prices = df['price']\n   new_prices = np.array([98, 99])\n\n*Old behavior*:\n\n.. code-block:: ipython\n\n    In [3]: df.iloc[:, 0] = new_prices\n    In [4]: df.iloc[:, 0]\n    Out[4]:\n    book1    98\n    book2    99\n    Name: price, dtype: int64\n    In [5]: original_prices\n    Out[5]:\n    book1    11.1\n    book2    12.2\n    Name: price, float: 64\n\nThis behavior is deprecated. In a future version, setting an entire column with\niloc will attempt to operate inplace.\n\n*Future behavior*:\n\n.. code-block:: ipython\n\n    In [3]: df.iloc[:, 0] = new_prices\n    In [4]: df.iloc[:, 0]\n    Out[4]:\n    book1    98.0\n    book2    99.0\n    Name: price, dtype: float64\n    In [5]: original_prices\n    Out[5]:\n    book1    98.0\n    book2    99.0\n    Name: price, dtype: float64\n\nTo get the old behavior, use :meth:`DataFrame.__setitem__` directly:\n\n.. code-block:: ipython\n\n    In [3]: df[df.columns[0]] = new_prices\n    In [4]: df.iloc[:, 0]\n    Out[4]\n    book1    98\n    book2    99\n    Name: price, dtype: int64\n    In [5]: original_prices\n    Out[5]:\n    book1    11.1\n    book2    12.2\n    Name: price, dtype: float64\n\nTo get the old behaviour when ``df.columns`` is not unique and you want to\nchange a single column by index, you can use :meth:`DataFrame.isetitem`, which\nhas been added in pandas 1.5:\n\n.. code-block:: ipython\n\n    In [3]: df_with_duplicated_cols = pd.concat([df, df], axis='columns')\n    In [3]: df_with_duplicated_cols.isetitem(0, new_prices)\n    In [4]: df_with_duplicated_cols.iloc[:, 0]\n    Out[4]:\n    book1    98\n    book2    99\n    Name: price, dtype: int64\n    In [5]: original_prices\n    Out[5]:\n    book1    11.1\n    book2    12.2\n    Name: 0, dtype: float64\n\n.. _whatsnew_150.deprecations.numeric_only_default:\n\n``numeric_only`` default value\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nAcross the :class:`DataFrame`, :class:`.DataFrameGroupBy`, and :class:`.Resampler` operations such as\n``min``, ``sum``, and ``idxmax``, the default\nvalue of the ``numeric_only`` argument, if it exists at all, was inconsistent.\nFurthermore, operations with the default value ``None`` can lead to surprising\nresults. (:issue:`46560`)\n\n.. code-block:: ipython\n\n    In [1]: df = pd.DataFrame({\"a\": [1, 2], \"b\": [\"x\", \"y\"]})\n\n    In [2]:  Reading the next line without knowing the contents of df, one would\n             expect the result to contain the products for both columns a and b.\n            df[[\"a\", \"b\"]].prod()\n    Out[2]:\n    a    2\n    dtype: int64\n\nTo avoid this behavior, the specifying the value ``numeric_only=None`` has been\ndeprecated, and will be removed in a future version of pandas. In the future,\nall operations with a ``numeric_only`` argument will default to ``False``. Users\nshould either call the operation only with columns that can be operated on, or\nspecify ``numeric_only=True`` to operate only on Boolean, integer, and float columns.\n\nIn order to support the transition to the new behavior, the following methods have\ngained the ``numeric_only`` argument.\n\n- :meth:`DataFrame.corr`\n- :meth:`DataFrame.corrwith`\n- :meth:`DataFrame.cov`\n- :meth:`DataFrame.idxmin`\n- :meth:`DataFrame.idxmax`\n- :meth:`.DataFrameGroupBy.cummin`\n- :meth:`.DataFrameGroupBy.cummax`\n- :meth:`.DataFrameGroupBy.idxmin`\n- :meth:`.DataFrameGroupBy.idxmax`\n- :meth:`.DataFrameGroupBy.var`\n- :meth:`.DataFrameGroupBy.std`\n- :meth:`.DataFrameGroupBy.sem`\n- :meth:`.DataFrameGroupBy.quantile`\n- :meth:`.Resampler.mean`\n- :meth:`.Resampler.median`\n- :meth:`.Resampler.sem`\n- :meth:`.Resampler.std`\n- :meth:`.Resampler.var`\n- :meth:`DataFrame.rolling` operations\n- :meth:`DataFrame.expanding` operations\n- :meth:`DataFrame.ewm` operations\n\n.. _whatsnew_150.deprecations.other:\n\nOther Deprecations\n^^^^^^^^^^^^^^^^^^\n- Deprecated the keyword ``line_terminator`` in :meth:`DataFrame.to_csv` and :meth:`Series.to_csv`, use ``lineterminator`` instead; this is for consistency with :func:`read_csv` and the standard library 'csv' module (:issue:`9568`)\n- Deprecated behavior of :meth:`SparseArray.astype`, :meth:`Series.astype`, and :meth:`DataFrame.astype` with :class:`SparseDtype` when passing a non-sparse ``dtype``. In a future version, this will cast to that non-sparse dtype instead of wrapping it in a :class:`SparseDtype` (:issue:`34457`)\n- Deprecated behavior of :meth:`DatetimeIndex.intersection` and :meth:`DatetimeIndex.symmetric_difference` (``union`` behavior was already deprecated in version 1.3.0) with mixed time zones; in a future version both will be cast to UTC instead of object dtype (:issue:`39328`, :issue:`45357`)\n- Deprecated :meth:`DataFrame.iteritems`, :meth:`Series.iteritems`, :meth:`HDFStore.iteritems` in favor of :meth:`DataFrame.items`, :meth:`Series.items`, :meth:`HDFStore.items`  (:issue:`45321`)\n- Deprecated :meth:`Series.is_monotonic` and :meth:`Index.is_monotonic` in favor of :meth:`Series.is_monotonic_increasing` and :meth:`Index.is_monotonic_increasing` (:issue:`45422`, :issue:`21335`)\n- Deprecated behavior of :meth:`DatetimeIndex.astype`, :meth:`TimedeltaIndex.astype`, :meth:`PeriodIndex.astype` when converting to an integer dtype other than ``int64``. In a future version, these will convert to exactly the specified dtype (instead of always ``int64``) and will raise if the conversion overflows (:issue:`45034`)\n- Deprecated the ``__array_wrap__`` method of DataFrame and Series, rely on standard numpy ufuncs instead (:issue:`45451`)\n- Deprecated treating float-dtype data as wall-times when passed with a timezone to :class:`Series` or :class:`DatetimeIndex` (:issue:`45573`)\n- Deprecated the behavior of :meth:`Series.fillna` and :meth:`DataFrame.fillna` with ``timedelta64[ns]`` dtype and incompatible fill value; in a future version this will cast to a common dtype (usually object) instead of raising, matching the behavior of other dtypes (:issue:`45746`)\n- Deprecated the ``warn`` parameter in :func:`infer_freq` (:issue:`45947`)\n- Deprecated allowing non-keyword arguments in :meth:`.ExtensionArray.argsort` (:issue:`46134`)\n- Deprecated treating all-bool ``object``-dtype columns as bool-like in :meth:`DataFrame.any` and :meth:`DataFrame.all` with ``bool_only=True``, explicitly cast to bool instead (:issue:`46188`)\n- Deprecated behavior of method :meth:`DataFrame.quantile`, attribute ``numeric_only`` will default False. Including datetime/timedelta columns in the result (:issue:`7308`).\n- Deprecated :attr:`Timedelta.freq` and :attr:`Timedelta.is_populated` (:issue:`46430`)\n- Deprecated :attr:`Timedelta.delta` (:issue:`46476`)\n- Deprecated passing arguments as positional in :meth:`DataFrame.any` and :meth:`Series.any` (:issue:`44802`)\n- Deprecated passing positional arguments to :meth:`DataFrame.pivot` and :func:`pivot` except ``data`` (:issue:`30228`)\n- Deprecated the methods :meth:`DataFrame.mad`, :meth:`Series.mad`, and the corresponding groupby methods (:issue:`11787`)\n- Deprecated positional arguments to :meth:`Index.join` except for ``other``, use keyword-only arguments instead of positional arguments (:issue:`46518`)\n- Deprecated positional arguments to :meth:`StringMethods.rsplit` and :meth:`StringMethods.split` except for ``pat``, use keyword-only arguments instead of positional arguments (:issue:`47423`)\n- Deprecated indexing on a timezone-naive :class:`DatetimeIndex` using a string representing a timezone-aware datetime (:issue:`46903`, :issue:`36148`)\n- Deprecated allowing ``unit=\"M\"`` or ``unit=\"Y\"`` in :class:`Timestamp` constructor with a non-round float value (:issue:`47267`)\n- Deprecated the ``display.column_space`` global configuration option (:issue:`7576`)\n- Deprecated the argument ``na_sentinel`` in :func:`factorize`, :meth:`Index.factorize`, and :meth:`.ExtensionArray.factorize`; pass ``use_na_sentinel=True`` instead to use the sentinel ``-1`` for NaN values and ``use_na_sentinel=False`` instead of ``na_sentinel=None`` to encode NaN values (:issue:`46910`)\n- Deprecated :meth:`.DataFrameGroupBy.transform` not aligning the result when the UDF returned DataFrame (:issue:`45648`)\n- Clarified warning from :func:`to_datetime` when delimited dates can't be parsed in accordance to specified ``dayfirst`` argument (:issue:`46210`)\n- Emit warning from :func:`to_datetime` when delimited dates can't be parsed in accordance to specified ``dayfirst`` argument even for dates where leading zero is omitted (e.g. ``31/1/2001``) (:issue:`47880`)\n- Deprecated :class:`Series` and :class:`Resampler` reducers (e.g. ``min``, ``max``, ``sum``, ``mean``) raising a ``NotImplementedError`` when the dtype is non-numric and ``numeric_only=True`` is provided; this will raise a ``TypeError`` in a future version (:issue:`47500`)\n- Deprecated :meth:`Series.rank` returning an empty result when the dtype is non-numeric and ``numeric_only=True`` is provided; this will raise a ``TypeError`` in a future version (:issue:`47500`)\n- Deprecated argument ``errors`` for :meth:`Series.mask`, :meth:`Series.where`, :meth:`DataFrame.mask`, and :meth:`DataFrame.where` as ``errors`` had no effect on this methods (:issue:`47728`)\n- Deprecated arguments ``*args`` and ``**kwargs`` in :class:`Rolling`, :class:`Expanding`, and :class:`ExponentialMovingWindow` ops. (:issue:`47836`)\n- Deprecated the ``inplace`` keyword in :meth:`Categorical.set_ordered`, :meth:`Categorical.as_ordered`, and :meth:`Categorical.as_unordered` (:issue:`37643`)\n- Deprecated setting a categorical's categories with ``cat.categories = ['a', 'b', 'c']``, use :meth:`Categorical.rename_categories` instead (:issue:`37643`)\n- Deprecated unused arguments ``encoding`` and ``verbose`` in :meth:`Series.to_excel` and :meth:`DataFrame.to_excel` (:issue:`47912`)\n- Deprecated the ``inplace`` keyword in :meth:`DataFrame.set_axis` and :meth:`Series.set_axis`, use ``obj = obj.set_axis(..., copy=False)`` instead (:issue:`48130`)\n- Deprecated producing a single element when iterating over a :class:`DataFrameGroupBy` or a :class:`SeriesGroupBy` that has been grouped by a list of length 1; A tuple of length one will be returned instead (:issue:`42795`)\n- Fixed up warning message of deprecation of :meth:`MultiIndex.lesort_depth` as public method, as the message previously referred to :meth:`MultiIndex.is_lexsorted` instead (:issue:`38701`)\n- Deprecated the ``sort_columns`` argument in :meth:`DataFrame.plot` and :meth:`Series.plot` (:issue:`47563`).\n- Deprecated positional arguments for all but the first argument of :meth:`DataFrame.to_stata` and :func:`read_stata`, use keyword arguments instead (:issue:`48128`).\n- Deprecated the ``mangle_dupe_cols`` argument in :func:`read_csv`, :func:`read_fwf`, :func:`read_table` and :func:`read_excel`. The argument was never implemented, and a new argument where the renaming pattern can be specified will be added instead (:issue:`47718`)\n- Deprecated allowing ``dtype='datetime64'`` or ``dtype=np.datetime64`` in :meth:`Series.astype`, use \"datetime64[ns]\" instead (:issue:`47844`)\n\n.. ---------------------------------------------------------------------------\n.. _whatsnew_150.performance:\n\nPerformance improvements\n~~~~~~~~~~~~~~~~~~~~~~~~\n- Performance improvement in :meth:`DataFrame.corrwith` for column-wise (axis=0) Pearson and Spearman correlation when other is a :class:`Series` (:issue:`46174`)\n- Performance improvement in :meth:`.DataFrameGroupBy.transform` and :meth:`.SeriesGroupBy.transform` for some user-defined DataFrame -> Series functions (:issue:`45387`)\n- Performance improvement in :meth:`DataFrame.duplicated` when subset consists of only one column (:issue:`45236`)\n- Performance improvement in :meth:`.DataFrameGroupBy.diff` and :meth:`.SeriesGroupBy.diff` (:issue:`16706`)\n- Performance improvement in :meth:`.DataFrameGroupBy.transform` and :meth:`.SeriesGroupBy.transform` when broadcasting values for user-defined functions (:issue:`45708`)\n- Performance improvement in :meth:`.DataFrameGroupBy.transform` and :meth:`.SeriesGroupBy.transform` for user-defined functions when only a single group exists (:issue:`44977`)\n- Performance improvement in :meth:`.DataFrameGroupBy.apply` and :meth:`.SeriesGroupBy.apply` when grouping on a non-unique unsorted index (:issue:`46527`)\n- Performance improvement in :meth:`DataFrame.loc` and :meth:`Series.loc` for tuple-based indexing of a :class:`MultiIndex` (:issue:`45681`, :issue:`46040`, :issue:`46330`)\n- Performance improvement in :meth:`.DataFrameGroupBy.var` and :meth:`.SeriesGroupBy.var` with ``ddof`` other than one (:issue:`48152`)\n- Performance improvement in :meth:`DataFrame.to_records` when the index is a :class:`MultiIndex` (:issue:`47263`)\n- Performance improvement in :attr:`MultiIndex.values` when the MultiIndex contains levels of type DatetimeIndex, TimedeltaIndex or ExtensionDtypes (:issue:`46288`)\n- Performance improvement in :func:`merge` when left and/or right are empty (:issue:`45838`)\n- Performance improvement in :meth:`DataFrame.join` when left and/or right are empty (:issue:`46015`)\n- Performance improvement in :meth:`DataFrame.reindex` and :meth:`Series.reindex` when target is a :class:`MultiIndex` (:issue:`46235`)\n- Performance improvement when setting values in a pyarrow backed string array (:issue:`46400`)\n- Performance improvement in :func:`factorize` (:issue:`46109`)\n- Performance improvement in :class:`DataFrame` and :class:`Series` constructors for extension dtype scalars (:issue:`45854`)\n- Performance improvement in :func:`read_excel` when ``nrows`` argument provided (:issue:`32727`)\n- Performance improvement in :meth:`.Styler.to_excel` when applying repeated CSS formats (:issue:`47371`)\n- Performance improvement in :meth:`MultiIndex.is_monotonic_increasing`  (:issue:`47458`)\n- Performance improvement in :class:`BusinessHour` ``str`` and ``repr`` (:issue:`44764`)\n- Performance improvement in datetime arrays string formatting when one of the default strftime formats ``\"%Y-%m-%d %H:%M:%S\"`` or ``\"%Y-%m-%d %H:%M:%S.%f\"`` is used. (:issue:`44764`)\n- Performance improvement in :meth:`Series.to_sql` and :meth:`DataFrame.to_sql` (:class:`SQLiteTable`) when processing time arrays. (:issue:`44764`)\n- Performance improvement to :func:`read_sas` (:issue:`47404`)\n- Performance improvement in ``argmax`` and ``argmin`` for :class:`arrays.SparseArray` (:issue:`34197`)\n\n.. ---------------------------------------------------------------------------\n.. _whatsnew_150.bug_fixes:\n\nBug fixes\n~~~~~~~~~\n\nCategorical\n^^^^^^^^^^^\n- Bug in :meth:`.Categorical.view` not accepting integer dtypes (:issue:`25464`)\n- Bug in :meth:`.CategoricalIndex.union` when the index's categories are integer-dtype and the index contains ``NaN`` values incorrectly raising instead of casting to ``float64`` (:issue:`45362`)\n- Bug in :meth:`concat` when concatenating two (or more) unordered :class:`CategoricalIndex` variables, whose categories are permutations, yields incorrect index values (:issue:`24845`)\n\nDatetimelike\n^^^^^^^^^^^^\n- Bug in :meth:`DataFrame.quantile` with datetime-like dtypes and no rows incorrectly returning ``float64`` dtype instead of retaining datetime-like dtype (:issue:`41544`)\n- Bug in :func:`to_datetime` with sequences of ``np.str_`` objects incorrectly raising (:issue:`32264`)\n- Bug in :class:`Timestamp` construction when passing datetime components as positional arguments and ``tzinfo`` as a keyword argument incorrectly raising (:issue:`31929`)\n- Bug in :meth:`Index.astype` when casting from object dtype to ``timedelta64[ns]`` dtype incorrectly casting ``np.datetime64(\"NaT\")`` values to ``np.timedelta64(\"NaT\")`` instead of raising (:issue:`45722`)\n- Bug in :meth:`.SeriesGroupBy.value_counts` index when passing categorical column (:issue:`44324`)\n- Bug in :meth:`DatetimeIndex.tz_localize` localizing to UTC failing to make a copy of the underlying data (:issue:`46460`)\n- Bug in :meth:`DatetimeIndex.resolution` incorrectly returning \"day\" instead of \"nanosecond\" for nanosecond-resolution indexes (:issue:`46903`)\n- Bug in :class:`Timestamp` with an integer or float value and ``unit=\"Y\"`` or ``unit=\"M\"`` giving slightly-wrong results (:issue:`47266`)\n- Bug in :class:`.DatetimeArray` construction when passed another :class:`.DatetimeArray` and ``freq=None`` incorrectly inferring the freq from the given array (:issue:`47296`)\n- Bug in :func:`to_datetime` where ``OutOfBoundsDatetime`` would be thrown even if ``errors=coerce`` if there were more than 50 rows (:issue:`45319`)\n- Bug when adding a :class:`DateOffset` to a :class:`Series` would not add the ``nanoseconds`` field (:issue:`47856`)\n\nTimedelta\n^^^^^^^^^\n- Bug in :func:`astype_nansafe` astype(\"timedelta64[ns]\") fails when np.nan is included (:issue:`45798`)\n- Bug in constructing a :class:`Timedelta` with a ``np.timedelta64`` object and a ``unit`` sometimes silently overflowing and returning incorrect results instead of raising ``OutOfBoundsTimedelta`` (:issue:`46827`)\n- Bug in constructing a :class:`Timedelta` from a large integer or float with ``unit=\"W\"`` silently overflowing and returning incorrect results instead of raising ``OutOfBoundsTimedelta`` (:issue:`47268`)\n\nTime Zones\n^^^^^^^^^^\n- Bug in :class:`Timestamp` constructor raising when passed a ``ZoneInfo`` tzinfo object (:issue:`46425`)\n\nNumeric\n^^^^^^^\n- Bug in operations with array-likes with ``dtype=\"boolean\"`` and :attr:`NA` incorrectly altering the array in-place (:issue:`45421`)\n- Bug in arithmetic operations with nullable types without :attr:`NA` values not matching the same operation with non-nullable types (:issue:`48223`)\n- Bug in ``floordiv`` when dividing by ``IntegerDtype`` ``0`` would return ``0`` instead of ``inf`` (:issue:`48223`)\n- Bug in division, ``pow`` and ``mod`` operations on array-likes with ``dtype=\"boolean\"`` not being like their ``np.bool_`` counterparts (:issue:`46063`)\n- Bug in multiplying a :class:`Series` with ``IntegerDtype`` or ``FloatingDtype`` by an array-like with ``timedelta64[ns]`` dtype incorrectly raising (:issue:`45622`)\n- Bug in :meth:`mean` where the optional dependency ``bottleneck`` causes precision loss linear in the length of the array. ``bottleneck`` has been disabled for :meth:`mean` improving the loss to log-linear but may result in a performance decrease. (:issue:`42878`)\n\nConversion\n^^^^^^^^^^\n- Bug in :meth:`DataFrame.astype` not preserving subclasses (:issue:`40810`)\n- Bug in constructing a :class:`Series` from a float-containing list or a floating-dtype ndarray-like (e.g. ``dask.Array``) and an integer dtype raising instead of casting like we would with an ``np.ndarray`` (:issue:`40110`)\n- Bug in :meth:`Float64Index.astype` to unsigned integer dtype incorrectly casting to ``np.int64`` dtype (:issue:`45309`)\n- Bug in :meth:`Series.astype` and :meth:`DataFrame.astype` from floating dtype to unsigned integer dtype failing to raise in the presence of negative values (:issue:`45151`)\n- Bug in :func:`array` with ``FloatingDtype`` and values containing float-castable strings incorrectly raising (:issue:`45424`)\n- Bug when comparing string and datetime64ns objects causing ``OverflowError`` exception. (:issue:`45506`)\n- Bug in metaclass of generic abstract dtypes causing :meth:`DataFrame.apply` and :meth:`Series.apply` to raise for the built-in function ``type`` (:issue:`46684`)\n- Bug in :meth:`DataFrame.to_records` returning inconsistent numpy types if the index was a :class:`MultiIndex` (:issue:`47263`)\n- Bug in :meth:`DataFrame.to_dict` for ``orient=\"list\"`` or ``orient=\"index\"`` was not returning native types (:issue:`46751`)\n- Bug in :meth:`DataFrame.apply` that returns a :class:`DataFrame` instead of a :class:`Series` when applied to an empty :class:`DataFrame` and ``axis=1`` (:issue:`39111`)\n- Bug when inferring the dtype from an iterable that is *not* a NumPy ``ndarray`` consisting of all NumPy unsigned integer scalars did not result in an unsigned integer dtype (:issue:`47294`)\n- Bug in :meth:`DataFrame.eval` when pandas objects (e.g. ``'Timestamp'``) were column names (:issue:`44603`)\n\nStrings\n^^^^^^^\n- Bug in :meth:`str.startswith` and :meth:`str.endswith` when using other series as parameter _pat_. Now raises ``TypeError`` (:issue:`3485`)\n- Bug in :meth:`Series.str.zfill` when strings contain leading signs, padding '0' before the sign character rather than after as ``str.zfill`` from standard library (:issue:`20868`)\n\nInterval\n^^^^^^^^\n- Bug in :meth:`IntervalArray.__setitem__` when setting ``np.nan`` into an integer-backed array raising ``ValueError`` instead of ``TypeError`` (:issue:`45484`)\n- Bug in :class:`IntervalDtype` when using datetime64[ns, tz] as a dtype string (:issue:`46999`)\n\nIndexing\n^^^^^^^^\n- Bug in :meth:`DataFrame.iloc` where indexing a single row on a :class:`DataFrame` with a single ExtensionDtype column gave a copy instead of a view on the underlying data (:issue:`45241`)\n- Bug in :meth:`DataFrame.__getitem__` returning copy when :class:`DataFrame` has duplicated columns even if a unique column is selected (:issue:`45316`, :issue:`41062`)\n- Bug in :meth:`Series.align` does not create :class:`MultiIndex` with union of levels when both MultiIndexes intersections are identical (:issue:`45224`)\n- Bug in setting a NA value (``None`` or ``np.nan``) into a :class:`Series` with int-based :class:`IntervalDtype` incorrectly casting to object dtype instead of a float-based :class:`IntervalDtype` (:issue:`45568`)\n- Bug in indexing setting values into an ``ExtensionDtype`` column with ``df.iloc[:, i] = values`` with ``values`` having the same dtype as ``df.iloc[:, i]`` incorrectly inserting a new array instead of setting in-place (:issue:`33457`)\n- Bug in :meth:`Series.__setitem__` with a non-integer :class:`Index` when using an integer key to set a value that cannot be set inplace where a ``ValueError`` was raised instead of casting to a common dtype (:issue:`45070`)\n- Bug in :meth:`DataFrame.loc` not casting ``None`` to ``NA`` when setting value as a list into :class:`DataFrame` (:issue:`47987`)\n- Bug in :meth:`Series.__setitem__` when setting incompatible values into a ``PeriodDtype`` or ``IntervalDtype`` :class:`Series` raising when indexing with a boolean mask but coercing when indexing with otherwise-equivalent indexers; these now consistently coerce, along with :meth:`Series.mask` and :meth:`Series.where` (:issue:`45768`)\n- Bug in :meth:`DataFrame.where` with multiple columns with datetime-like dtypes failing to downcast results consistent with other dtypes (:issue:`45837`)\n- Bug in :func:`isin` upcasting to ``float64`` with unsigned integer dtype and list-like argument without a dtype (:issue:`46485`)\n- Bug in :meth:`Series.loc.__setitem__` and :meth:`Series.loc.__getitem__` not raising when using multiple keys without using a :class:`MultiIndex` (:issue:`13831`)\n- Bug in :meth:`Index.reindex` raising ``AssertionError`` when ``level`` was specified but no :class:`MultiIndex` was given; level is ignored now (:issue:`35132`)\n- Bug when setting a value too large for a :class:`Series` dtype failing to coerce to a common type (:issue:`26049`, :issue:`32878`)\n- Bug in :meth:`loc.__setitem__` treating ``range`` keys as positional instead of label-based (:issue:`45479`)\n- Bug in :meth:`DataFrame.__setitem__` casting extension array dtypes to object when setting with a scalar key and :class:`DataFrame` as value (:issue:`46896`)\n- Bug in :meth:`Series.__setitem__` when setting a scalar to a nullable pandas dtype would not raise a ``TypeError`` if the scalar could not be cast (losslessly) to the nullable type (:issue:`45404`)\n- Bug in :meth:`Series.__setitem__` when setting ``boolean`` dtype values containing ``NA`` incorrectly raising instead of casting to ``boolean`` dtype (:issue:`45462`)\n- Bug in :meth:`Series.loc` raising with boolean indexer containing ``NA`` when :class:`Index` did not match (:issue:`46551`)\n- Bug in :meth:`Series.__setitem__` where setting :attr:`NA` into a numeric-dtype :class:`Series` would incorrectly upcast to object-dtype rather than treating the value as ``np.nan`` (:issue:`44199`)\n- Bug in :meth:`DataFrame.loc` when setting values to a column and right hand side is a dictionary (:issue:`47216`)\n- Bug in :meth:`Series.__setitem__` with ``datetime64[ns]`` dtype, an all-``False`` boolean mask, and an incompatible value incorrectly casting to ``object`` instead of retaining ``datetime64[ns]`` dtype (:issue:`45967`)\n- Bug in :meth:`Index.__getitem__`  raising ``ValueError`` when indexer is from boolean dtype with ``NA`` (:issue:`45806`)\n- Bug in :meth:`Series.__setitem__` losing precision when enlarging :class:`Series` with scalar (:issue:`32346`)\n- Bug in :meth:`Series.mask` with ``inplace=True`` or setting values with a boolean mask with small integer dtypes incorrectly raising (:issue:`45750`)\n- Bug in :meth:`DataFrame.mask` with ``inplace=True`` and ``ExtensionDtype`` columns incorrectly raising (:issue:`45577`)\n- Bug in getting a column from a DataFrame with an object-dtype row index with datetime-like values: the resulting Series now preserves the exact object-dtype Index from the parent DataFrame (:issue:`42950`)\n- Bug in :meth:`DataFrame.__getattribute__` raising ``AttributeError`` if columns have ``\"string\"`` dtype (:issue:`46185`)\n- Bug in :meth:`DataFrame.compare` returning all ``NaN`` column when comparing extension array dtype and numpy dtype (:issue:`44014`)\n- Bug in :meth:`DataFrame.where` setting wrong values with ``\"boolean\"`` mask for numpy dtype (:issue:`44014`)\n- Bug in indexing on a :class:`DatetimeIndex` with a ``np.str_`` key incorrectly raising (:issue:`45580`)\n- Bug in :meth:`CategoricalIndex.get_indexer` when index contains ``NaN`` values, resulting in elements that are in target but not present in the index to be mapped to the index of the NaN element, instead of -1 (:issue:`45361`)\n- Bug in setting large integer values into :class:`Series` with ``float32`` or ``float16`` dtype incorrectly altering these values instead of coercing to ``float64`` dtype (:issue:`45844`)\n- Bug in :meth:`Series.asof` and :meth:`DataFrame.asof` incorrectly casting bool-dtype results to ``float64`` dtype (:issue:`16063`)\n- Bug in :meth:`NDFrame.xs`, :meth:`DataFrame.iterrows`, :meth:`DataFrame.loc` and :meth:`DataFrame.iloc` not always propagating metadata (:issue:`28283`)\n- Bug in :meth:`DataFrame.sum` min_count changes dtype if input contains NaNs (:issue:`46947`)\n- Bug in :class:`IntervalTree` that lead to an infinite recursion. (:issue:`46658`)\n- Bug in :class:`PeriodIndex` raising ``AttributeError`` when indexing on ``NA``, rather than putting ``NaT`` in its place. (:issue:`46673`)\n- Bug in :meth:`DataFrame.at` would allow the modification of multiple columns (:issue:`48296`)\n\nMissing\n^^^^^^^\n- Bug in :meth:`Series.fillna` and :meth:`DataFrame.fillna` with ``downcast`` keyword not being respected in some cases where there are no NA values present (:issue:`45423`)\n- Bug in :meth:`Series.fillna` and :meth:`DataFrame.fillna` with :class:`IntervalDtype` and incompatible value raising instead of casting to a common (usually object) dtype (:issue:`45796`)\n- Bug in :meth:`Series.map` not respecting ``na_action`` argument if mapper is a ``dict`` or :class:`Series` (:issue:`47527`)\n- Bug in :meth:`DataFrame.interpolate` with object-dtype column not returning a copy with ``inplace=False`` (:issue:`45791`)\n- Bug in :meth:`DataFrame.dropna` allows to set both ``how`` and ``thresh`` incompatible arguments (:issue:`46575`)\n- Bug in :meth:`DataFrame.fillna` ignored ``axis`` when :class:`DataFrame` is single block (:issue:`47713`)\n\nMultiIndex\n^^^^^^^^^^\n- Bug in :meth:`DataFrame.loc` returning empty result when slicing a :class:`MultiIndex` with a negative step size and non-null start/stop values (:issue:`46156`)\n- Bug in :meth:`DataFrame.loc` raising when slicing a :class:`MultiIndex` with a negative step size other than -1 (:issue:`46156`)\n- Bug in :meth:`DataFrame.loc` raising when slicing a :class:`MultiIndex` with a negative step size and slicing a non-int labeled index level (:issue:`46156`)\n- Bug in :meth:`Series.to_numpy` where multiindexed Series could not be converted to numpy arrays when an ``na_value`` was supplied (:issue:`45774`)\n- Bug in :class:`MultiIndex.equals` not commutative when only one side has extension array dtype (:issue:`46026`)\n- Bug in :meth:`MultiIndex.from_tuples` cannot construct Index of empty tuples (:issue:`45608`)\n\nI/O\n^^^\n- Bug in :meth:`DataFrame.to_stata` where no error is raised if the :class:`DataFrame` contains ``-np.inf`` (:issue:`45350`)\n- Bug in :func:`read_excel` results in an infinite loop with certain ``skiprows`` callables (:issue:`45585`)\n- Bug in :meth:`DataFrame.info` where a new line at the end of the output is omitted when called on an empty :class:`DataFrame` (:issue:`45494`)\n- Bug in :func:`read_csv` not recognizing line break for ``on_bad_lines=\"warn\"`` for ``engine=\"c\"`` (:issue:`41710`)\n- Bug in :meth:`DataFrame.to_csv` not respecting ``float_format`` for ``Float64`` dtype (:issue:`45991`)\n- Bug in :func:`read_csv` not respecting a specified converter to index columns in all cases (:issue:`40589`)\n- Bug in :func:`read_csv` interpreting second row as :class:`Index` names even when ``index_col=False`` (:issue:`46569`)\n- Bug in :func:`read_parquet` when ``engine=\"pyarrow\"`` which caused partial write to disk when column of unsupported datatype was passed (:issue:`44914`)\n- Bug in :func:`DataFrame.to_excel` and :class:`ExcelWriter` would raise when writing an empty DataFrame to a ``.ods`` file (:issue:`45793`)\n- Bug in :func:`read_csv` ignoring non-existing header row for ``engine=\"python\"`` (:issue:`47400`)\n- Bug in :func:`read_excel` raising uncontrolled ``IndexError`` when ``header`` references non-existing rows (:issue:`43143`)\n- Bug in :func:`read_html` where elements surrounding ``<br>`` were joined without a space between them (:issue:`29528`)\n- Bug in :func:`read_csv` when data is longer than header leading to issues with callables in ``usecols`` expecting strings (:issue:`46997`)\n- Bug in Parquet roundtrip for Interval dtype with ``datetime64[ns]`` subtype (:issue:`45881`)\n- Bug in :func:`read_excel` when reading a ``.ods`` file with newlines between xml elements (:issue:`45598`)\n- Bug in :func:`read_parquet` when ``engine=\"fastparquet\"`` where the file was not closed on error (:issue:`46555`)\n- :meth:`DataFrame.to_html` now excludes the ``border`` attribute from ``<table>`` elements when ``border`` keyword is set to ``False``.\n- Bug in :func:`read_sas` with certain types of compressed SAS7BDAT files (:issue:`35545`)\n- Bug in :func:`read_excel` not forward filling :class:`MultiIndex` when no names were given (:issue:`47487`)\n- Bug in :func:`read_sas` returned ``None`` rather than an empty DataFrame for SAS7BDAT files with zero rows (:issue:`18198`)\n- Bug in :meth:`DataFrame.to_string` using wrong missing value with extension arrays in :class:`MultiIndex` (:issue:`47986`)\n- Bug in :class:`StataWriter` where value labels were always written with default encoding (:issue:`46750`)\n- Bug in :class:`StataWriterUTF8` where some valid characters were removed from variable names (:issue:`47276`)\n- Bug in :meth:`DataFrame.to_excel` when writing an empty dataframe with :class:`MultiIndex` (:issue:`19543`)\n- Bug in :func:`read_sas` with RLE-compressed SAS7BDAT files that contain 0x40 control bytes (:issue:`31243`)\n- Bug in :func:`read_sas` that scrambled column names (:issue:`31243`)\n- Bug in :func:`read_sas` with RLE-compressed SAS7BDAT files that contain 0x00 control bytes (:issue:`47099`)\n- Bug in :func:`read_parquet` with ``use_nullable_dtypes=True`` where ``float64`` dtype was returned instead of nullable ``Float64`` dtype (:issue:`45694`)\n- Bug in :meth:`DataFrame.to_json` where ``PeriodDtype`` would not make the serialization roundtrip when read back with :meth:`read_json` (:issue:`44720`)\n- Bug in :func:`read_xml` when reading XML files with Chinese character tags and would raise ``XMLSyntaxError`` (:issue:`47902`)\n\nPeriod\n^^^^^^\n- Bug in subtraction of :class:`Period` from :class:`.PeriodArray` returning wrong results (:issue:`45999`)\n- Bug in :meth:`Period.strftime` and :meth:`PeriodIndex.strftime`, directives ``%l`` and ``%u`` were giving wrong results (:issue:`46252`)\n- Bug in inferring an incorrect ``freq`` when passing a string to :class:`Period` microseconds that are a multiple of 1000 (:issue:`46811`)\n- Bug in constructing a :class:`Period` from a :class:`Timestamp` or ``np.datetime64`` object with non-zero nanoseconds and ``freq=\"ns\"`` incorrectly truncating the nanoseconds (:issue:`46811`)\n- Bug in adding ``np.timedelta64(\"NaT\", \"ns\")`` to a :class:`Period` with a timedelta-like freq incorrectly raising ``IncompatibleFrequency`` instead of returning ``NaT`` (:issue:`47196`)\n- Bug in adding an array of integers to an array with :class:`PeriodDtype` giving incorrect results when ``dtype.freq.n > 1`` (:issue:`47209`)\n- Bug in subtracting a :class:`Period` from an array with :class:`PeriodDtype` returning incorrect results instead of raising ``OverflowError`` when the operation overflows (:issue:`47538`)\n\nPlotting\n^^^^^^^^\n- Bug in :meth:`DataFrame.plot.barh` that prevented labeling the x-axis and ``xlabel`` updating the y-axis label (:issue:`45144`)\n- Bug in :meth:`DataFrame.plot.box` that prevented labeling the x-axis (:issue:`45463`)\n- Bug in :meth:`DataFrame.boxplot` that prevented passing in ``xlabel`` and ``ylabel`` (:issue:`45463`)\n- Bug in :meth:`DataFrame.boxplot` that prevented specifying ``vert=False`` (:issue:`36918`)\n- Bug in :meth:`DataFrame.plot.scatter` that prevented specifying ``norm`` (:issue:`45809`)\n- Fix showing \"None\" as ylabel in :meth:`Series.plot` when not setting ylabel (:issue:`46129`)\n- Bug in :meth:`DataFrame.plot` that led to xticks and vertical grids being improperly placed when plotting a quarterly series (:issue:`47602`)\n- Bug in :meth:`DataFrame.plot` that prevented setting y-axis label, limits and ticks for a secondary y-axis (:issue:`47753`)\n\nGroupby/resample/rolling\n^^^^^^^^^^^^^^^^^^^^^^^^\n- Bug in :meth:`DataFrame.resample` ignoring ``closed=\"right\"`` on :class:`TimedeltaIndex` (:issue:`45414`)\n- Bug in :meth:`.DataFrameGroupBy.transform` fails when ``func=\"size\"`` and the input DataFrame has multiple columns (:issue:`27469`)\n- Bug in :meth:`.DataFrameGroupBy.size` and :meth:`.DataFrameGroupBy.transform` with ``func=\"size\"`` produced incorrect results when ``axis=1`` (:issue:`45715`)\n- Bug in :meth:`.ExponentialMovingWindow.mean` with ``axis=1`` and ``engine='numba'`` when the :class:`DataFrame` has more columns than rows (:issue:`46086`)\n- Bug when using ``engine=\"numba\"`` would return the same jitted function when modifying ``engine_kwargs`` (:issue:`46086`)\n- Bug in :meth:`.DataFrameGroupBy.transform` fails when ``axis=1`` and ``func`` is ``\"first\"`` or ``\"last\"`` (:issue:`45986`)\n- Bug in :meth:`.DataFrameGroupBy.cumsum` with ``skipna=False`` giving incorrect results (:issue:`46216`)\n- Bug in :meth:`.DataFrameGroupBy.sum`, :meth:`.SeriesGroupBy.sum`, :meth:`.DataFrameGroupBy.prod`, :meth:`.SeriesGroupBy.prod, :meth:`.DataFrameGroupBy.cumsum`, and :meth:`.SeriesGroupBy.cumsum` with integer dtypes losing precision (:issue:`37493`)\n- Bug in :meth:`.DataFrameGroupBy.cumsum` and :meth:`.SeriesGroupBy.cumsum` with ``timedelta64[ns]`` dtype failing to recognize ``NaT`` as a null value (:issue:`46216`)\n- Bug in :meth:`.DataFrameGroupBy.cumsum` and :meth:`.SeriesGroupBy.cumsum` with integer dtypes causing overflows when sum was bigger than maximum of dtype (:issue:`37493`)\n- Bug in :meth:`.DataFrameGroupBy.cummin`, :meth:`.SeriesGroupBy.cummin`, :meth:`.DataFrameGroupBy.cummax` and :meth:`.SeriesGroupBy.cummax` with nullable dtypes incorrectly altering the original data in place (:issue:`46220`)\n- Bug in :meth:`DataFrame.groupby` raising error when ``None`` is in first level of :class:`MultiIndex` (:issue:`47348`)\n- Bug in :meth:`.DataFrameGroupBy.cummax` and :meth:`.SeriesGroupBy.cummax` with ``int64`` dtype with leading value being the smallest possible int64 (:issue:`46382`)\n- Bug in :meth:`.DataFrameGroupBy.cumprod` and :meth:`.SeriesGroupBy.cumprod` ``NaN`` influences calculation in different columns with ``skipna=False`` (:issue:`48064`)\n- Bug in :meth:`.DataFrameGroupBy.max` and :meth:`.SeriesGroupBy.max` with empty groups and ``uint64`` dtype incorrectly raising ``RuntimeError`` (:issue:`46408`)\n- Bug in :meth:`.DataFrameGroupBy.apply` and :meth:`.SeriesGroupBy.apply` would fail when ``func`` was a string and args or kwargs were supplied (:issue:`46479`)\n- Bug in :meth:`SeriesGroupBy.apply` would incorrectly name its result when there was a unique group (:issue:`46369`)\n- Bug in :meth:`.Rolling.sum` and :meth:`.Rolling.mean` would give incorrect result with window of same values (:issue:`42064`, :issue:`46431`)\n- Bug in :meth:`.Rolling.var` and :meth:`.Rolling.std` would give non-zero result with window of same values (:issue:`42064`)\n- Bug in :meth:`.Rolling.skew` and :meth:`.Rolling.kurt` would give NaN with window of same values (:issue:`30993`)\n- Bug in :meth:`.Rolling.var` would segfault calculating weighted variance when window size was larger than data size (:issue:`46760`)\n- Bug in :meth:`Grouper.__repr__` where ``dropna`` was not included. Now it is (:issue:`46754`)\n- Bug in :meth:`DataFrame.rolling` gives ValueError when center=True, axis=1 and win_type is specified (:issue:`46135`)\n- Bug in :meth:`.DataFrameGroupBy.describe` and :meth:`.SeriesGroupBy.describe` produces inconsistent results for empty datasets (:issue:`41575`)\n- Bug in :meth:`DataFrame.resample` reduction methods when used with ``on`` would attempt to aggregate the provided column (:issue:`47079`)\n- Bug in :meth:`DataFrame.groupby` and :meth:`Series.groupby` would not respect ``dropna=False`` when the input DataFrame/Series had a NaN values in a :class:`MultiIndex` (:issue:`46783`)\n- Bug in :meth:`DataFrameGroupBy.resample` raises ``KeyError`` when getting the result from a key list which misses the resample key (:issue:`47362`)\n- Bug in :meth:`DataFrame.groupby` would lose index columns when the DataFrame is empty for transforms, like fillna (:issue:`47787`)\n- Bug in :meth:`DataFrame.groupby` and :meth:`Series.groupby` with ``dropna=False`` and ``sort=False`` would put any null groups at the end instead the order that they are encountered (:issue:`46584`)\n\nReshaping\n^^^^^^^^^\n- Bug in :func:`concat` between a :class:`Series` with integer dtype and another with :class:`CategoricalDtype` with integer categories and containing ``NaN`` values casting to object dtype instead of ``float64`` (:issue:`45359`)\n- Bug in :func:`get_dummies` that selected object and categorical dtypes but not string (:issue:`44965`)\n- Bug in :meth:`DataFrame.align` when aligning a :class:`MultiIndex` to a :class:`Series` with another :class:`MultiIndex` (:issue:`46001`)\n- Bug in concatenation with ``IntegerDtype``, or ``FloatingDtype`` arrays where the resulting dtype did not mirror the behavior of the non-nullable dtypes (:issue:`46379`)\n- Bug in :func:`concat` losing dtype of columns when ``join=\"outer\"`` and ``sort=True`` (:issue:`47329`)\n- Bug in :func:`concat` not sorting the column names when ``None`` is included (:issue:`47331`)\n- Bug in :func:`concat` with identical key leads to error when indexing :class:`MultiIndex` (:issue:`46519`)\n- Bug in :func:`pivot_table` raising ``TypeError`` when ``dropna=True`` and aggregation column has extension array dtype (:issue:`47477`)\n- Bug in :func:`merge` raising error for ``how=\"cross\"`` when using ``FIPS`` mode in ssl library (:issue:`48024`)\n- Bug in :meth:`DataFrame.join` with a list when using suffixes to join DataFrames with duplicate column names (:issue:`46396`)\n- Bug in :meth:`DataFrame.pivot_table` with ``sort=False`` results in sorted index (:issue:`17041`)\n- Bug in :meth:`concat` when ``axis=1`` and ``sort=False`` where the resulting Index was a :class:`Int64Index` instead of a :class:`RangeIndex` (:issue:`46675`)\n- Bug in :meth:`wide_to_long` raises when ``stubnames`` is missing in columns and ``i`` contains string dtype column (:issue:`46044`)\n- Bug in :meth:`DataFrame.join` with categorical index results in unexpected reordering (:issue:`47812`)\n\nSparse\n^^^^^^\n- Bug in :meth:`Series.where` and :meth:`DataFrame.where` with ``SparseDtype`` failing to retain the array's ``fill_value`` (:issue:`45691`)\n- Bug in :meth:`SparseArray.unique` fails to keep original elements order (:issue:`47809`)\n\nExtensionArray\n^^^^^^^^^^^^^^\n- Bug in :meth:`IntegerArray.searchsorted` and :meth:`FloatingArray.searchsorted` returning inconsistent results when acting on ``np.nan`` (:issue:`45255`)\n\nStyler\n^^^^^^\n- Bug when attempting to apply styling functions to an empty DataFrame subset (:issue:`45313`)\n- Bug in :class:`CSSToExcelConverter` leading to ``TypeError`` when border color provided without border style for ``xlsxwriter`` engine (:issue:`42276`)\n- Bug in :meth:`Styler.set_sticky` leading to white text on white background in dark mode (:issue:`46984`)\n- Bug in :meth:`Styler.to_latex` causing ``UnboundLocalError`` when ``clines=\"all;data\"`` and the ``DataFrame`` has no rows. (:issue:`47203`)\n- Bug in :meth:`Styler.to_excel` when using ``vertical-align: middle;`` with ``xlsxwriter`` engine (:issue:`30107`)\n- Bug when applying styles to a DataFrame with boolean column labels (:issue:`47838`)\n\nMetadata\n^^^^^^^^\n- Fixed metadata propagation in :meth:`DataFrame.melt` (:issue:`28283`)\n- Fixed metadata propagation in :meth:`DataFrame.explode` (:issue:`28283`)\n\nOther\n^^^^^\n\n.. ***DO NOT USE THIS SECTION***\n\n- Bug in :func:`.assert_index_equal` with ``names=True`` and ``check_order=False`` not checking names (:issue:`47328`)\n\n.. ---------------------------------------------------------------------------\n.. _whatsnew_150.contributors:\n\nContributors\n~~~~~~~~~~~~\n\n.. contributors:: v1.4.4..v1.5.0\n\n\n.. _whatsnew_0152:\n\nVersion 0.15.2 (December 12, 2014)\n----------------------------------\n\n{{ header }}\n\n\nThis is a minor release from 0.15.1 and includes a large number of bug fixes\nalong with several new features, enhancements, and performance improvements.\nA small number of API changes were necessary to fix existing bugs.\nWe recommend that all users upgrade to this version.\n\n- :ref:`Enhancements <whatsnew_0152.enhancements>`\n- :ref:`API Changes <whatsnew_0152.api>`\n- :ref:`Performance Improvements <whatsnew_0152.performance>`\n- :ref:`Bug Fixes <whatsnew_0152.bug_fixes>`\n\n.. _whatsnew_0152.api:\n\nAPI changes\n~~~~~~~~~~~\n\n- Indexing in ``MultiIndex`` beyond lex-sort depth is now supported, though\n  a lexically sorted index will have a better performance. (:issue:`2646`)\n\n  .. code-block:: ipython\n\n    In [1]: df = pd.DataFrame({'jim':[0, 0, 1, 1],\n       ...:                    'joe':['x', 'x', 'z', 'y'],\n       ...:                    'jolie':np.random.rand(4)}).set_index(['jim', 'joe'])\n       ...:\n\n    In [2]: df\n    Out[2]:\n                jolie\n    jim joe\n    0   x    0.126970\n        x    0.966718\n    1   z    0.260476\n        y    0.897237\n\n    [4 rows x 1 columns]\n\n    In [3]: df.index.lexsort_depth\n    Out[3]: 1\n\n     in prior versions this would raise a KeyError\n     will now show a PerformanceWarning\n    In [4]: df.loc[(1, 'z')]\n    Out[4]:\n                jolie\n    jim joe\n    1   z    0.260476\n\n    [1 rows x 1 columns]\n\n     lexically sorting\n    In [5]: df2 = df.sort_index()\n\n    In [6]: df2\n    Out[6]:\n                jolie\n    jim joe\n    0   x    0.126970\n        x    0.966718\n    1   y    0.897237\n        z    0.260476\n\n    [4 rows x 1 columns]\n\n    In [7]: df2.index.lexsort_depth\n    Out[7]: 2\n\n    In [8]: df2.loc[(1,'z')]\n    Out[8]:\n                jolie\n    jim joe\n    1   z    0.260476\n\n    [1 rows x 1 columns]\n\n- Bug in unique of Series with ``category`` dtype, which returned all categories regardless\n  whether they were \"used\" or not (see :issue:`8559` for the discussion).\n  Previous behaviour was to return all categories:\n\n  .. code-block:: ipython\n\n    In [3]: cat = pd.Categorical(['a', 'b', 'a'], categories=['a', 'b', 'c'])\n\n    In [4]: cat\n    Out[4]:\n    [a, b, a]\n    Categories (3, object): [a < b < c]\n\n    In [5]: cat.unique()\n    Out[5]: array(['a', 'b', 'c'], dtype=object)\n\n  Now, only the categories that do effectively occur in the array are returned:\n\n  .. ipython:: python\n\n    cat = pd.Categorical(['a', 'b', 'a'], categories=['a', 'b', 'c'])\n    cat.unique()\n\n- ``Series.all`` and ``Series.any`` now support the ``level`` and ``skipna`` parameters. ``Series.all``, ``Series.any``, ``Index.all``, and ``Index.any`` no longer support the ``out`` and ``keepdims`` parameters, which existed for compatibility with ndarray. Various index types no longer support the ``all`` and ``any`` aggregation functions and will now raise ``TypeError``. (:issue:`8302`).\n\n- Allow equality comparisons of Series with a categorical dtype and object dtype; previously these would raise ``TypeError`` (:issue:`8938`)\n\n- Bug in ``NDFrame``: conflicting attribute/column names now behave consistently between getting and setting. Previously, when both a column and attribute named ``y`` existed, ``data.y`` would return the attribute, while ``data.y = z`` would update the column (:issue:`8994`)\n\n  .. ipython:: python\n\n     data = pd.DataFrame({'x': [1, 2, 3]})\n     data.y = 2\n     data['y'] = [2, 4, 6]\n     data\n\n      this assignment was inconsistent\n     data.y = 5\n\n  Old behavior:\n\n  .. code-block:: ipython\n\n     In [6]: data.y\n     Out[6]: 2\n\n     In [7]: data['y'].values\n     Out[7]: array([5, 5, 5])\n\n  New behavior:\n\n  .. ipython:: python\n\n     data.y\n     data['y'].values\n\n- ``Timestamp('now')`` is now equivalent to ``Timestamp.now()`` in that it returns the local time rather than UTC. Also, ``Timestamp('today')`` is now equivalent to ``Timestamp.today()`` and both have ``tz`` as a possible argument. (:issue:`9000`)\n\n- Fix negative step support for label-based slices (:issue:`8753`)\n\n  Old behavior:\n\n  .. code-block:: ipython\n\n     In [1]: s = pd.Series(np.arange(3), ['a', 'b', 'c'])\n     Out[1]:\n     a    0\n     b    1\n     c    2\n     dtype: int64\n\n     In [2]: s.loc['c':'a':-1]\n     Out[2]:\n     c    2\n     dtype: int64\n\n  New behavior:\n\n  .. ipython:: python\n\n     s = pd.Series(np.arange(3), ['a', 'b', 'c'])\n     s.loc['c':'a':-1]\n\n\n.. _whatsnew_0152.enhancements:\n\nEnhancements\n~~~~~~~~~~~~\n\n``Categorical`` enhancements:\n\n- Added ability to export Categorical data to Stata (:issue:`8633`).  See :ref:`here <io.stata-categorical>` for limitations of categorical variables exported to Stata data files.\n- Added flag ``order_categoricals`` to ``StataReader`` and ``read_stata`` to select whether to order imported categorical data (:issue:`8836`).  See :ref:`here <io.stata-categorical>` for more information on importing categorical variables from Stata data files.\n- Added ability to export Categorical data to/from HDF5 (:issue:`7621`). Queries work the same as if it was an object array. However, the ``category`` dtyped data is stored in a more efficient manner. See :ref:`here <io.hdf5-categorical>` for an example and caveats w.r.t. prior versions of pandas.\n- Added support for ``searchsorted()`` on ``Categorical`` class (:issue:`8420`).\n\nOther enhancements:\n\n- Added the ability to specify the SQL type of columns when writing a DataFrame\n  to a database (:issue:`8778`).\n  For example, specifying to use the sqlalchemy ``String`` type instead of the\n  default ``Text`` type for string columns:\n\n  .. code-block:: python\n\n     from sqlalchemy.types import String\n     data.to_sql('data_dtype', engine, dtype={'Col_1': String})   noqa F821\n\n- ``Series.all`` and ``Series.any`` now support the ``level`` and ``skipna`` parameters (:issue:`8302`):\n\n  .. code-block:: python\n\n     >>> s = pd.Series([False, True, False], index=[0, 0, 1])\n     >>> s.any(level=0)\n     0     True\n     1    False\n     dtype: bool\n\n- ``Panel`` now supports the ``all`` and ``any`` aggregation functions. (:issue:`8302`):\n\n  .. code-block:: python\n\n     >>> p = pd.Panel(np.random.rand(2, 5, 4) > 0.1)\n     >>> p.all()\n            0      1      2     3\n     0   True   True   True  True\n     1   True  False   True  True\n     2   True   True   True  True\n     3  False   True  False  True\n     4   True   True   True  True\n\n- Added support for ``utcfromtimestamp()``, ``fromtimestamp()``, and ``combine()`` on ``Timestamp`` class (:issue:`5351`).\n- Added Google Analytics (`pandas.io.ga`) basic documentation (:issue:`8835`). See `here <https://pandas.pydata.org/pandas-docs/version/0.15.2/remote_data.html#remote-data-ga>`__.\n- ``Timedelta`` arithmetic returns ``NotImplemented`` in unknown cases, allowing extensions by custom classes (:issue:`8813`).\n- ``Timedelta`` now supports arithmetic with ``numpy.ndarray`` objects of the appropriate dtype (numpy 1.8 or newer only) (:issue:`8884`).\n- Added ``Timedelta.to_timedelta64()`` method to the public API (:issue:`8884`).\n- Added ``gbq.generate_bq_schema()`` function to the gbq module (:issue:`8325`).\n- ``Series`` now works with map objects the same way as generators (:issue:`8909`).\n- Added context manager to ``HDFStore`` for automatic closing (:issue:`8791`).\n- ``to_datetime`` gains an ``exact`` keyword to allow for a format to not require an exact match for a provided format string (if its ``False``). ``exact`` defaults to ``True`` (meaning that exact matching is still the default)  (:issue:`8904`)\n- Added ``axvlines`` boolean option to parallel_coordinates plot function, determines whether vertical lines will be printed, default is True\n- Added ability to read table footers to read_html (:issue:`8552`)\n- ``to_sql`` now infers data types of non-NA values for columns that contain NA values and have dtype ``object`` (:issue:`8778`).\n\n\n.. _whatsnew_0152.performance:\n\nPerformance\n~~~~~~~~~~~\n\n- Reduce memory usage when skiprows is an integer in read_csv (:issue:`8681`)\n- Performance boost for ``to_datetime`` conversions with a passed ``format=``, and the ``exact=False`` (:issue:`8904`)\n\n\n.. _whatsnew_0152.bug_fixes:\n\nBug fixes\n~~~~~~~~~\n\n- Bug in concat of Series with ``category`` dtype which were coercing to ``object``. (:issue:`8641`)\n- Bug in Timestamp-Timestamp not returning a Timedelta type and datelike-datelike ops with timezones (:issue:`8865`)\n- Made consistent a timezone mismatch exception (either tz operated with None or incompatible timezone), will now return ``TypeError`` rather than ``ValueError`` (a couple of edge cases only), (:issue:`8865`)\n- Bug in using a ``pd.Grouper(key=...)`` with no level/axis or level only (:issue:`8795`, :issue:`8866`)\n- Report a ``TypeError`` when invalid/no parameters are passed in a groupby (:issue:`8015`)\n- Bug in packaging pandas with ``py2app/cx_Freeze`` (:issue:`8602`, :issue:`8831`)\n- Bug in ``groupby`` signatures that didn't include \\*args or \\*\\*kwargs (:issue:`8733`).\n- ``io.data.Options`` now raises ``RemoteDataError`` when no expiry dates are available from Yahoo and when it receives no data from Yahoo (:issue:`8761`), (:issue:`8783`).\n- Unclear error message in csv parsing when passing dtype and names and the parsed data is a different data type (:issue:`8833`)\n- Bug in slicing a MultiIndex with an empty list and at least one boolean indexer (:issue:`8781`)\n- ``io.data.Options`` now raises ``RemoteDataError`` when no expiry dates are available from Yahoo (:issue:`8761`).\n- ``Timedelta`` kwargs may now be numpy ints and floats (:issue:`8757`).\n- Fixed several outstanding bugs for ``Timedelta`` arithmetic and comparisons (:issue:`8813`, :issue:`5963`, :issue:`5436`).\n- ``sql_schema`` now generates dialect appropriate ``CREATE TABLE`` statements (:issue:`8697`)\n- ``slice`` string method now takes step into account (:issue:`8754`)\n- Bug in ``BlockManager`` where setting values with different type would break block integrity (:issue:`8850`)\n- Bug in ``DatetimeIndex`` when using ``time`` object as key (:issue:`8667`)\n- Bug in ``merge`` where ``how='left'`` and ``sort=False`` would not preserve left frame order (:issue:`7331`)\n- Bug in ``MultiIndex.reindex`` where reindexing at level would not reorder labels (:issue:`4088`)\n- Bug in certain operations with dateutil timezones, manifesting with dateutil 2.3 (:issue:`8639`)\n- Regression in DatetimeIndex iteration with a Fixed/Local offset timezone (:issue:`8890`)\n- Bug in ``to_datetime`` when parsing a nanoseconds using the ``%f`` format (:issue:`8989`)\n- ``io.data.Options`` now raises ``RemoteDataError`` when no expiry dates are available from Yahoo and when it receives no data from Yahoo (:issue:`8761`), (:issue:`8783`).\n- Fix: The font size was only set on x axis if vertical or the y axis if horizontal. (:issue:`8765`)\n- Fixed division by 0 when reading big csv files in python 3 (:issue:`8621`)\n- Bug in outputting a MultiIndex with ``to_html,index=False`` which would add an extra column (:issue:`8452`)\n- Imported categorical variables from Stata files retain the ordinal information in the underlying data (:issue:`8836`).\n- Defined ``.size`` attribute across ``NDFrame`` objects to provide compat with numpy >= 1.9.1; buggy with ``np.array_split`` (:issue:`8846`)\n- Skip testing of histogram plots for matplotlib <= 1.2 (:issue:`8648`).\n- Bug where ``get_data_google`` returned object dtypes (:issue:`3995`)\n- Bug in ``DataFrame.stack(..., dropna=False)`` when the DataFrame's ``columns`` is a ``MultiIndex``\n  whose ``labels`` do not reference all its ``levels``. (:issue:`8844`)\n- Bug in that Option context applied on ``__enter__`` (:issue:`8514`)\n- Bug in resample that causes a ValueError when resampling across multiple days\n  and the last offset is not calculated from the start of the range (:issue:`8683`)\n- Bug where ``DataFrame.plot(kind='scatter')`` fails when checking if an np.array is in the DataFrame (:issue:`8852`)\n- Bug in ``pd.infer_freq/DataFrame.inferred_freq`` that prevented proper sub-daily frequency inference when the index contained DST days (:issue:`8772`).\n- Bug where index name was still used when plotting a series with ``use_index=False`` (:issue:`8558`).\n- Bugs when trying to stack multiple columns, when some (or all) of the level names are numbers (:issue:`8584`).\n- Bug in ``MultiIndex`` where ``__contains__`` returns wrong result if index is not lexically sorted or unique (:issue:`7724`)\n- BUG CSV: fix problem with trailing white space in skipped rows, (:issue:`8679`), (:issue:`8661`), (:issue:`8983`)\n- Regression in ``Timestamp`` does not parse 'Z' zone designator for UTC (:issue:`8771`)\n- Bug in ``StataWriter`` the produces writes strings with 244 characters irrespective of actual size (:issue:`8969`)\n- Fixed ValueError raised by cummin/cummax when datetime64 Series contains NaT. (:issue:`8965`)\n- Bug in DataReader returns object dtype if there are missing values (:issue:`8980`)\n- Bug in plotting if sharex was enabled and index was a timeseries, would show labels on multiple axes (:issue:`3964`).\n- Bug where passing a unit to the TimedeltaIndex constructor applied the to nano-second conversion twice. (:issue:`9011`).\n- Bug in plotting of a period-like array (:issue:`9012`)\n\n\n.. _whatsnew_0.15.2.contributors:\n\nContributors\n~~~~~~~~~~~~\n\n.. contributors:: v0.15.1..v0.15.2\n\n\n.. _whatsnew_0192:\n\nVersion 0.19.2 (December 24, 2016)\n----------------------------------\n\n{{ header }}\n\n.. ipython:: python\n   :suppress:\n\n   from pandas import *   noqa F401, F403\n\n\nThis is a minor bug-fix release in the 0.19.x series and includes some small regression fixes,\nbug fixes and performance improvements.\nWe recommend that all users upgrade to this version.\n\nHighlights include:\n\n- Compatibility with Python 3.6\n- Added a `Pandas Cheat Sheet <https://github.com/pandas-dev/pandas/tree/main/doc/cheatsheet/Pandas_Cheat_Sheet.pdf>`__. (:issue:`13202`).\n\n\n.. contents:: What's new in v0.19.2\n    :local:\n    :backlinks: none\n\n\n.. _whatsnew_0192.enhancements:\n\nEnhancements\n~~~~~~~~~~~~\n\nThe ``pd.merge_asof()``, added in 0.19.0, gained some improvements:\n\n- ``pd.merge_asof()`` gained ``left_index``/``right_index`` and ``left_by``/``right_by`` arguments (:issue:`14253`)\n- ``pd.merge_asof()`` can take multiple columns in ``by`` parameter and has specialized dtypes for better performance (:issue:`13936`)\n\n\n.. _whatsnew_0192.performance:\n\nPerformance improvements\n~~~~~~~~~~~~~~~~~~~~~~~~\n\n- Performance regression with ``PeriodIndex`` (:issue:`14822`)\n- Performance regression in indexing with getitem (:issue:`14930`)\n- Improved performance of ``.replace()`` (:issue:`12745`)\n- Improved performance ``Series`` creation with a datetime index and dictionary data (:issue:`14894`)\n\n\n.. _whatsnew_0192.bug_fixes:\n\nBug fixes\n~~~~~~~~~\n- Compat with python 3.6 for pickling of some offsets (:issue:`14685`)\n- Compat with python 3.6 for some indexing exception types (:issue:`14684`, :issue:`14689`)\n- Compat with python 3.6 for deprecation warnings in the test suite (:issue:`14681`)\n- Compat with python 3.6 for Timestamp pickles (:issue:`14689`)\n- Compat with ``dateutil==2.6.0``; segfault reported in the testing suite (:issue:`14621`)\n- Allow ``nanoseconds`` in ``Timestamp.replace`` as a kwarg (:issue:`14621`)\n- Bug in ``pd.read_csv`` in which aliasing was being done for ``na_values`` when passed in as a dictionary (:issue:`14203`)\n- Bug in ``pd.read_csv`` in which column indices for a dict-like ``na_values`` were not being respected (:issue:`14203`)\n- Bug in ``pd.read_csv`` where reading files fails, if the number of headers is equal to the number of lines in the file (:issue:`14515`)\n- Bug in ``pd.read_csv`` for the Python engine in which an unhelpful error message was being raised when multi-char delimiters were not being respected with quotes (:issue:`14582`)\n- Fix bugs (:issue:`14734`, :issue:`13654`) in ``pd.read_sas`` and ``pandas.io.sas.sas7bdat.SAS7BDATReader`` that caused problems when reading a SAS file incrementally.\n- Bug in ``pd.read_csv`` for the Python engine in which an unhelpful error message was being raised when ``skipfooter`` was not being respected by Python's CSV library (:issue:`13879`)\n- Bug in ``.fillna()`` in which timezone aware datetime64 values were incorrectly rounded (:issue:`14872`)\n- Bug in ``.groupby(..., sort=True)`` of a non-lexsorted MultiIndex when grouping with multiple levels (:issue:`14776`)\n- Bug in ``pd.cut`` with negative values and a single bin (:issue:`14652`)\n- Bug in ``pd.to_numeric`` where a 0 was not unsigned on a ``downcast='unsigned'`` argument (:issue:`14401`)\n- Bug in plotting regular and irregular timeseries using shared axes\n  (``sharex=True`` or ``ax.twinx()``) (:issue:`13341`, :issue:`14322`).\n- Bug in not propagating exceptions in parsing invalid datetimes, noted in python 3.6 (:issue:`14561`)\n- Bug in resampling a ``DatetimeIndex`` in local TZ, covering a DST change, which would raise ``AmbiguousTimeError`` (:issue:`14682`)\n- Bug in indexing that transformed ``RecursionError`` into ``KeyError`` or ``IndexingError`` (:issue:`14554`)\n- Bug in ``HDFStore`` when writing a ``MultiIndex`` when using ``data_columns=True`` (:issue:`14435`)\n- Bug in ``HDFStore.append()`` when writing a ``Series`` and passing a ``min_itemsize`` argument containing a value for the ``index`` (:issue:`11412`)\n- Bug when writing to a ``HDFStore`` in ``table`` format with a ``min_itemsize`` value for the ``index`` and without asking to append (:issue:`10381`)\n- Bug in ``Series.groupby.nunique()`` raising an ``IndexError`` for an empty ``Series`` (:issue:`12553`)\n- Bug in ``DataFrame.nlargest`` and ``DataFrame.nsmallest`` when the index had duplicate values (:issue:`13412`)\n- Bug in clipboard functions on linux with python2 with unicode and separators (:issue:`13747`)\n- Bug in clipboard functions on Windows 10 and python 3 (:issue:`14362`, :issue:`12807`)\n- Bug in ``.to_clipboard()`` and Excel compat (:issue:`12529`)\n- Bug in ``DataFrame.combine_first()`` for integer columns (:issue:`14687`).\n- Bug in ``pd.read_csv()`` in which the ``dtype`` parameter was not being respected for empty data (:issue:`14712`)\n- Bug in ``pd.read_csv()`` in which the ``nrows`` parameter was not being respected for large input when using the C engine for parsing (:issue:`7626`)\n- Bug in ``pd.merge_asof()`` could not handle timezone-aware DatetimeIndex when a tolerance was specified (:issue:`14844`)\n- Explicit check in ``to_stata`` and ``StataWriter`` for out-of-range values when writing doubles (:issue:`14618`)\n- Bug in ``.plot(kind='kde')`` which did not drop missing values to generate the KDE Plot, instead generating an empty plot. (:issue:`14821`)\n- Bug in ``unstack()`` if called with a list of column(s) as an argument, regardless of the dtypes of all columns, they get coerced to ``object`` (:issue:`11847`)\n\n\n.. _whatsnew_0.19.2.contributors:\n\nContributors\n~~~~~~~~~~~~\n\n.. contributors:: v0.19.1..v0.19.2\n\n\n.. _whatsnew_110:\n\nWhat's new in 1.1.0 (July 28, 2020)\n-----------------------------------\n\nThese are the changes in pandas 1.1.0. See :ref:`release` for a full changelog\nincluding other versions of pandas.\n\n{{ header }}\n\n.. ---------------------------------------------------------------------------\n\nEnhancements\n~~~~~~~~~~~~\n\n.. _whatsnew_110.specify_missing_labels:\n\nKeyErrors raised by loc specify missing labels\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nPreviously, if labels were missing for a ``.loc`` call, a KeyError was raised stating that this was no longer supported.\n\nNow the error message also includes a list of the missing labels (max 10 items, display width 80 characters). See :issue:`34272`.\n\n\n.. _whatsnew_110.astype_string:\n\nAll dtypes can now be converted to ``StringDtype``\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nPreviously, declaring or converting to :class:`StringDtype` was in general only possible if the data was already only ``str`` or nan-like (:issue:`31204`).\n:class:`StringDtype` now works in all situations where ``astype(str)`` or ``dtype=str`` work:\n\nFor example, the below now works:\n\n.. ipython:: python\n\n   ser = pd.Series([1, \"abc\", np.nan], dtype=\"string\")\n   ser\n   ser[0]\n   pd.Series([1, 2, np.nan], dtype=\"Int64\").astype(\"string\")\n\n\n.. _whatsnew_110.period_index_partial_string_slicing:\n\nNon-monotonic PeriodIndex partial string slicing\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n:class:`PeriodIndex` now supports partial string slicing for non-monotonic indexes, mirroring :class:`DatetimeIndex` behavior (:issue:`31096`)\n\nFor example:\n\n.. ipython:: python\n\n   dti = pd.date_range(\"2014-01-01\", periods=30, freq=\"30D\")\n   pi = dti.to_period(\"D\")\n   ser_monotonic = pd.Series(np.arange(30), index=pi)\n   shuffler = list(range(0, 30, 2)) + list(range(1, 31, 2))\n   ser = ser_monotonic.iloc[shuffler]\n   ser\n\n.. ipython:: python\n\n   ser[\"2014\"]\n   ser.loc[\"May 2015\"]\n\n\n.. _whatsnew_110.dataframe_or_series_comparing:\n\nComparing two ``DataFrame`` or two ``Series`` and summarizing the differences\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nWe've added :meth:`DataFrame.compare` and :meth:`Series.compare` for comparing two ``DataFrame`` or two ``Series`` (:issue:`30429`)\n\n.. ipython:: python\n\n   df = pd.DataFrame(\n       {\n           \"col1\": [\"a\", \"a\", \"b\", \"b\", \"a\"],\n           \"col2\": [1.0, 2.0, 3.0, np.nan, 5.0],\n           \"col3\": [1.0, 2.0, 3.0, 4.0, 5.0]\n       },\n       columns=[\"col1\", \"col2\", \"col3\"],\n   )\n   df\n\n.. ipython:: python\n\n   df2 = df.copy()\n   df2.loc[0, 'col1'] = 'c'\n   df2.loc[2, 'col3'] = 4.0\n   df2\n\n.. ipython:: python\n\n   df.compare(df2)\n\nSee :ref:`User Guide <merging.compare>` for more details.\n\n\n.. _whatsnew_110.groupby_key:\n\nAllow NA in groupby key\n^^^^^^^^^^^^^^^^^^^^^^^^\n\nWith :ref:`groupby <groupby.dropna>` , we've added a ``dropna`` keyword to :meth:`DataFrame.groupby` and :meth:`Series.groupby` in order to\nallow ``NA`` values in group keys. Users can define ``dropna`` to ``False`` if they want to include\n``NA`` values in groupby keys. The default is set to ``True`` for ``dropna`` to keep backwards\ncompatibility (:issue:`3729`)\n\n.. ipython:: python\n\n    df_list = [[1, 2, 3], [1, None, 4], [2, 1, 3], [1, 2, 2]]\n    df_dropna = pd.DataFrame(df_list, columns=[\"a\", \"b\", \"c\"])\n\n    df_dropna\n\n.. ipython:: python\n\n     Default ``dropna`` is set to True, which will exclude NaNs in keys\n    df_dropna.groupby(by=[\"b\"], dropna=True).sum()\n\n     In order to allow NaN in keys, set ``dropna`` to False\n    df_dropna.groupby(by=[\"b\"], dropna=False).sum()\n\nThe default setting of ``dropna`` argument is ``True`` which means ``NA`` are not included in group keys.\n\n\n.. _whatsnew_110.key_sorting:\n\nSorting with keys\n^^^^^^^^^^^^^^^^^\n\nWe've added a ``key`` argument to the :class:`DataFrame` and :class:`Series` sorting methods, including\n:meth:`DataFrame.sort_values`, :meth:`DataFrame.sort_index`, :meth:`Series.sort_values`,\nand :meth:`Series.sort_index`. The ``key`` can be any callable function which is applied\ncolumn-by-column to each column used for sorting, before sorting is performed (:issue:`27237`).\nSee :ref:`sort_values with keys <basics.sort_value_key>` and :ref:`sort_index with keys\n<basics.sort_index_key>` for more information.\n\n.. ipython:: python\n\n   s = pd.Series(['C', 'a', 'B'])\n   s\n\n.. ipython:: python\n\n   s.sort_values()\n\n\nNote how this is sorted with capital letters first. If we apply the :meth:`Series.str.lower`\nmethod, we get\n\n.. ipython:: python\n\n   s.sort_values(key=lambda x: x.str.lower())\n\n\nWhen applied to a ``DataFrame``, they key is applied per-column to all columns or a subset if\n``by`` is specified, e.g.\n\n.. ipython:: python\n\n   df = pd.DataFrame({'a': ['C', 'C', 'a', 'a', 'B', 'B'],\n                      'b': [1, 2, 3, 4, 5, 6]})\n   df\n\n.. ipython:: python\n\n   df.sort_values(by=['a'], key=lambda col: col.str.lower())\n\n\nFor more details, see examples and documentation in :meth:`DataFrame.sort_values`,\n:meth:`Series.sort_values`, and :meth:`~DataFrame.sort_index`.\n\n.. _whatsnew_110.timestamp_fold_support:\n\nFold argument support in Timestamp constructor\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n:class:`Timestamp:` now supports the keyword-only fold argument according to `PEP 495 <https://www.python.org/dev/peps/pep-0495/#the-fold-attribute>`_ similar to parent ``datetime.datetime`` class. It supports both accepting fold as an initialization argument and inferring fold from other constructor arguments (:issue:`25057`, :issue:`31338`). Support is limited to ``dateutil`` timezones as ``pytz`` doesn't support fold.\n\nFor example:\n\n.. ipython:: python\n\n    ts = pd.Timestamp(\"2019-10-27 01:30:00+00:00\")\n    ts.fold\n\n.. ipython:: python\n\n    ts = pd.Timestamp(year=2019, month=10, day=27, hour=1, minute=30,\n                      tz=\"dateutil/Europe/London\", fold=1)\n    ts\n\nFor more on working with fold, see :ref:`Fold subsection <timeseries.fold>` in the user guide.\n\n.. _whatsnew_110.to_datetime_multiple_tzname_tzoffset_support:\n\nParsing timezone-aware format with different timezones in to_datetime\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n:func:`to_datetime` now supports parsing formats containing timezone names (``%Z``) and UTC offsets (``%z``) from different timezones then converting them to UTC by setting ``utc=True``. This would return a :class:`DatetimeIndex` with timezone at UTC as opposed to an :class:`Index` with ``object`` dtype if ``utc=True`` is not set (:issue:`32792`).\n\nFor example:\n\n.. ipython:: python\n\n    tz_strs = [\"2010-01-01 12:00:00 +0100\", \"2010-01-01 12:00:00 -0100\",\n               \"2010-01-01 12:00:00 +0300\", \"2010-01-01 12:00:00 +0400\"]\n    pd.to_datetime(tz_strs, format='%Y-%m-%d %H:%M:%S %z', utc=True)\n\n.. code-block:: ipython\n\n   In[37]: pd.to_datetime(tz_strs, format='%Y-%m-%d %H:%M:%S %z')\n   Out[37]:\n   Index([2010-01-01 12:00:00+01:00, 2010-01-01 12:00:00-01:00,\n          2010-01-01 12:00:00+03:00, 2010-01-01 12:00:00+04:00],\n         dtype='object')\n\n.. _whatsnew_110.grouper_resample_origin:\n\nGrouper and resample now supports the arguments origin and offset\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n:class:`Grouper` and :meth:`DataFrame.resample` now supports the arguments ``origin`` and ``offset``. It let the user control the timestamp on which to adjust the grouping. (:issue:`31809`)\n\nThe bins of the grouping are adjusted based on the beginning of the day of the time series starting point. This works well with frequencies that are multiples of a day (like ``30D``) or that divides a day (like ``90s`` or ``1min``). But it can create inconsistencies with some frequencies that do not meet this criteria. To change this behavior you can now specify a fixed timestamp with the argument ``origin``.\n\nTwo arguments are now deprecated (more information in the documentation of :meth:`DataFrame.resample`):\n\n- ``base`` should be replaced by ``offset``.\n- ``loffset`` should be replaced by directly adding an offset to the index :class:`DataFrame` after being resampled.\n\nSmall example of the use of ``origin``:\n\n.. ipython:: python\n\n    start, end = '2000-10-01 23:30:00', '2000-10-02 00:30:00'\n    middle = '2000-10-02 00:00:00'\n    rng = pd.date_range(start, end, freq='7min')\n    ts = pd.Series(np.arange(len(rng)) * 3, index=rng)\n    ts\n\nResample with the default behavior ``'start_day'`` (origin is ``2000-10-01 00:00:00``):\n\n.. ipython:: python\n\n    ts.resample('17min').sum()\n    ts.resample('17min', origin='start_day').sum()\n\nResample using a fixed origin:\n\n.. ipython:: python\n\n    ts.resample('17min', origin='epoch').sum()\n    ts.resample('17min', origin='2000-01-01').sum()\n\nIf needed you can adjust the bins with the argument ``offset`` (a :class:`Timedelta`) that would be added to the default ``origin``.\n\nFor a full example, see: :ref:`timeseries.adjust-the-start-of-the-bins`.\n\nfsspec now used for filesystem handling\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nFor reading and writing to filesystems other than local and reading from HTTP(S),\nthe optional dependency ``fsspec`` will be used to dispatch operations (:issue:`33452`).\nThis will give unchanged\nfunctionality for S3 and GCS storage, which were already supported, but also add\nsupport for several other storage implementations such as `Azure Datalake and Blob`_,\nSSH, FTP, dropbox and github. For docs and capabilities, see the `fsspec docs`_.\n\nThe existing capability to interface with S3 and GCS will be unaffected by this\nchange, as ``fsspec`` will still bring in the same packages as before.\n\n.. _Azure Datalake and Blob: https://github.com/fsspec/adlfs\n\n.. _fsspec docs: https://filesystem-spec.readthedocs.io/en/latest/\n\n.. _whatsnew_110.enhancements.other:\n\nOther enhancements\n^^^^^^^^^^^^^^^^^^\n\n- Compatibility with matplotlib 3.3.0 (:issue:`34850`)\n- :meth:`IntegerArray.astype` now supports ``datetime64`` dtype (:issue:`32538`)\n- :class:`IntegerArray` now implements the ``sum`` operation (:issue:`33172`)\n- Added :class:`pandas.errors.InvalidIndexError` (:issue:`34570`).\n- Added :meth:`DataFrame.value_counts` (:issue:`5377`)\n- Added a :func:`pandas.api.indexers.FixedForwardWindowIndexer` class to support forward-looking windows during ``rolling`` operations.\n- Added a :func:`pandas.api.indexers.VariableOffsetWindowIndexer` class to support ``rolling`` operations with non-fixed offsets (:issue:`34994`)\n- :meth:`~DataFrame.describe` now includes a ``datetime_is_numeric`` keyword to control how datetime columns are summarized (:issue:`30164`, :issue:`34798`)\n- :class:`~pandas.io.formats.style.Styler` may now render CSS more efficiently where multiple cells have the same styling (:issue:`30876`)\n- :meth:`~pandas.io.formats.style.Styler.highlight_null` now accepts ``subset`` argument (:issue:`31345`)\n- When writing directly to a sqlite connection :meth:`DataFrame.to_sql` now supports the ``multi`` method (:issue:`29921`)\n- :class:`pandas.errors.OptionError` is now exposed in ``pandas.errors`` (:issue:`27553`)\n- Added :meth:`api.extensions.ExtensionArray.argmax` and :meth:`api.extensions.ExtensionArray.argmin` (:issue:`24382`)\n- :func:`timedelta_range` will now infer a frequency when passed ``start``, ``stop``, and ``periods`` (:issue:`32377`)\n- Positional slicing on a :class:`IntervalIndex` now supports slices with ``step > 1`` (:issue:`31658`)\n- :class:`Series.str` now has a ``fullmatch`` method that matches a regular expression against the entire string in each row of the :class:`Series`, similar to ``re.fullmatch`` (:issue:`32806`).\n- :meth:`DataFrame.sample` will now also allow array-like and BitGenerator objects to be passed to ``random_state`` as seeds (:issue:`32503`)\n- :meth:`Index.union` will now raise ``RuntimeWarning`` for :class:`MultiIndex` objects if the object inside are unsortable. Pass ``sort=False`` to suppress this warning (:issue:`33015`)\n- Added :meth:`Series.dt.isocalendar` and :meth:`DatetimeIndex.isocalendar` that returns a :class:`DataFrame` with year, week, and day calculated according to the ISO 8601 calendar (:issue:`33206`, :issue:`34392`).\n- The :meth:`DataFrame.to_feather` method now supports additional keyword\n  arguments (e.g. to set the compression) that are added in pyarrow 0.17\n  (:issue:`33422`).\n- The :func:`cut` will now accept parameter ``ordered`` with default ``ordered=True``. If ``ordered=False`` and no labels are provided, an error will be raised (:issue:`33141`)\n- :meth:`DataFrame.to_csv`, :meth:`DataFrame.to_pickle`,\n  and :meth:`DataFrame.to_json` now support passing a dict of\n  compression arguments when using the ``gzip`` and ``bz2`` protocols.\n  This can be used to set a custom compression level, e.g.,\n  ``df.to_csv(path, compression={'method': 'gzip', 'compresslevel': 1}``\n  (:issue:`33196`)\n- :meth:`melt` has gained an ``ignore_index`` (default ``True``) argument that, if set to ``False``, prevents the method from dropping the index (:issue:`17440`).\n- :meth:`Series.update` now accepts objects that can be coerced to a :class:`Series`,\n  such as ``dict`` and ``list``, mirroring the behavior of :meth:`DataFrame.update` (:issue:`33215`)\n- :meth:`.DataFrameGroupBy.transform` and :meth:`.DataFrameGroupBy.aggregate` have gained ``engine`` and ``engine_kwargs`` arguments that support executing functions with ``Numba`` (:issue:`32854`, :issue:`33388`)\n- :meth:`.Resampler.interpolate` now supports SciPy interpolation method :class:`scipy.interpolate.CubicSpline` as method ``cubicspline`` (:issue:`33670`)\n- :class:`.DataFrameGroupBy` and :class:`.SeriesGroupBy` now implement the ``sample`` method for doing random sampling within groups (:issue:`31775`)\n- :meth:`DataFrame.to_numpy` now supports the ``na_value`` keyword to control the NA sentinel in the output array (:issue:`33820`)\n- Added :class:`api.extension.ExtensionArray.equals` to the extension array interface, similar to :meth:`Series.equals` (:issue:`27081`)\n- The minimum supported dta version has increased to 105 in :func:`read_stata` and :class:`~pandas.io.stata.StataReader`  (:issue:`26667`).\n- :meth:`~DataFrame.to_stata` supports compression using the ``compression``\n  keyword argument. Compression can either be inferred or explicitly set using a string or a\n  dictionary containing both the method and any additional arguments that are passed to the\n  compression library. Compression was also added to the low-level Stata-file writers\n  :class:`~pandas.io.stata.StataWriter`, :class:`~pandas.io.stata.StataWriter117`,\n  and :class:`~pandas.io.stata.StataWriterUTF8` (:issue:`26599`).\n- :meth:`HDFStore.put` now accepts a ``track_times`` parameter. This parameter is passed to the ``create_table`` method of ``PyTables`` (:issue:`32682`).\n- :meth:`Series.plot` and :meth:`DataFrame.plot` now accepts ``xlabel`` and ``ylabel`` parameters to present labels on x and y axis (:issue:`9093`).\n- Made :class:`.Rolling` and :class:`.Expanding` iterable\u00ef\u00bc\u0088:issue:`11704`)\n- Made ``option_context`` a :class:`contextlib.ContextDecorator`, which allows it to be used as a decorator over an entire function (:issue:`34253`).\n- :meth:`DataFrame.to_csv` and :meth:`Series.to_csv` now accept an ``errors`` argument (:issue:`22610`)\n- :meth:`.DataFrameGroupBy.groupby.transform` now allows ``func`` to be ``pad``, ``backfill`` and ``cumcount`` (:issue:`31269`).\n- :func:`read_json` now accepts an ``nrows`` parameter. (:issue:`33916`).\n- :meth:`DataFrame.hist`, :meth:`Series.hist`, :meth:`core.groupby.DataFrameGroupBy.hist`, and :meth:`core.groupby.SeriesGroupBy.hist` have gained the ``legend`` argument. Set to True to show a legend in the histogram. (:issue:`6279`)\n- :func:`concat` and :meth:`~DataFrame.append` now preserve extension dtypes, for example\n  combining a nullable integer column with a numpy integer column will no longer\n  result in object dtype but preserve the integer dtype (:issue:`33607`, :issue:`34339`, :issue:`34095`).\n- :func:`read_gbq` now allows to disable progress bar (:issue:`33360`).\n- :func:`read_gbq` now supports the ``max_results`` kwarg from ``pandas-gbq`` (:issue:`34639`).\n- :meth:`DataFrame.cov` and :meth:`Series.cov` now support a new parameter ``ddof`` to support delta degrees of freedom as in the corresponding numpy methods (:issue:`34611`).\n- :meth:`DataFrame.to_html` and :meth:`DataFrame.to_string`'s ``col_space`` parameter now accepts a list or dict to change only some specific columns' width (:issue:`28917`).\n- :meth:`DataFrame.to_excel` can now also write OpenOffice spreadsheet (.ods) files (:issue:`27222`)\n- :meth:`~Series.explode` now accepts ``ignore_index`` to reset the index, similar to :meth:`pd.concat` or :meth:`DataFrame.sort_values` (:issue:`34932`).\n- :meth:`DataFrame.to_markdown` and :meth:`Series.to_markdown` now accept ``index`` argument as an alias for tabulate's ``showindex`` (:issue:`32667`)\n- :meth:`read_csv` now accepts string values like \"0\", \"0.0\", \"1\", \"1.0\" as convertible to the nullable Boolean dtype (:issue:`34859`)\n- :class:`.ExponentialMovingWindow` now supports a ``times`` argument that allows ``mean`` to be calculated with observations spaced by the timestamps in ``times`` (:issue:`34839`)\n- :meth:`DataFrame.agg` and :meth:`Series.agg` now accept named aggregation for renaming the output columns/indexes. (:issue:`26513`)\n- ``compute.use_numba`` now exists as a configuration option that utilizes the numba engine when available (:issue:`33966`, :issue:`35374`)\n- :meth:`Series.plot` now supports asymmetric error bars. Previously, if :meth:`Series.plot` received a \"2xN\" array with error values for ``yerr`` and/or ``xerr``, the left/lower values (first row) were mirrored, while the right/upper values (second row) were ignored. Now, the first row represents the left/lower error values and the second row the right/upper error values. (:issue:`9536`)\n\n.. ---------------------------------------------------------------------------\n\n.. _whatsnew_110.notable_bug_fixes:\n\nNotable bug fixes\n~~~~~~~~~~~~~~~~~\n\nThese are bug fixes that might have notable behavior changes.\n\n``MultiIndex.get_indexer`` interprets ``method`` argument correctly\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nThis restores the behavior of :meth:`MultiIndex.get_indexer` with ``method='backfill'`` or ``method='pad'`` to the behavior before pandas 0.23.0. In particular, MultiIndexes are treated as a list of tuples and padding or backfilling is done with respect to the ordering of these lists of tuples (:issue:`29896`).\n\nAs an example of this, given:\n\n.. ipython:: python\n\n        df = pd.DataFrame({\n            'a': [0, 0, 0, 0],\n            'b': [0, 2, 3, 4],\n            'c': ['A', 'B', 'C', 'D'],\n        }).set_index(['a', 'b'])\n        mi_2 = pd.MultiIndex.from_product([[0], [-1, 0, 1, 3, 4, 5]])\n\nThe differences in reindexing ``df`` with ``mi_2`` and using ``method='backfill'`` can be seen here:\n\n*pandas >= 0.23, < 1.1.0*:\n\n.. code-block:: ipython\n\n    In [1]: df.reindex(mi_2, method='backfill')\n    Out[1]:\n          c\n    0 -1  A\n       0  A\n       1  D\n       3  A\n       4  A\n       5  C\n\n*pandas <0.23, >= 1.1.0*\n\n.. ipython:: python\n\n        df.reindex(mi_2, method='backfill')\n\nAnd the differences in reindexing ``df`` with ``mi_2`` and using ``method='pad'`` can be seen here:\n\n*pandas >= 0.23, < 1.1.0*\n\n.. code-block:: ipython\n\n    In [1]: df.reindex(mi_2, method='pad')\n    Out[1]:\n            c\n    0 -1  NaN\n       0  NaN\n       1    D\n       3  NaN\n       4    A\n       5    C\n\n*pandas < 0.23, >= 1.1.0*\n\n.. ipython:: python\n\n        df.reindex(mi_2, method='pad')\n\n.. _whatsnew_110.notable_bug_fixes.indexing_raises_key_errors:\n\nFailed label-based lookups always raise KeyError\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nLabel lookups ``series[key]``, ``series.loc[key]`` and ``frame.loc[key]``\nused to raise either ``KeyError`` or ``TypeError`` depending on the type of\nkey and type of :class:`Index`.  These now consistently raise ``KeyError`` (:issue:`31867`)\n\n.. ipython:: python\n\n    ser1 = pd.Series(range(3), index=[0, 1, 2])\n    ser2 = pd.Series(range(3), index=pd.date_range(\"2020-02-01\", periods=3))\n\n*Previous behavior*:\n\n.. code-block:: ipython\n\n    In [3]: ser1[1.5]\n    ...\n    TypeError: cannot do label indexing on Int64Index with these indexers [1.5] of type float\n\n    In [4] ser1[\"foo\"]\n    ...\n    KeyError: 'foo'\n\n    In [5]: ser1.loc[1.5]\n    ...\n    TypeError: cannot do label indexing on Int64Index with these indexers [1.5] of type float\n\n    In [6]: ser1.loc[\"foo\"]\n    ...\n    KeyError: 'foo'\n\n    In [7]: ser2.loc[1]\n    ...\n    TypeError: cannot do label indexing on DatetimeIndex with these indexers [1] of type int\n\n    In [8]: ser2.loc[pd.Timestamp(0)]\n    ...\n    KeyError: Timestamp('1970-01-01 00:00:00')\n\n*New behavior*:\n\n.. code-block:: ipython\n\n    In [3]: ser1[1.5]\n    ...\n    KeyError: 1.5\n\n    In [4] ser1[\"foo\"]\n    ...\n    KeyError: 'foo'\n\n    In [5]: ser1.loc[1.5]\n    ...\n    KeyError: 1.5\n\n    In [6]: ser1.loc[\"foo\"]\n    ...\n    KeyError: 'foo'\n\n    In [7]: ser2.loc[1]\n    ...\n    KeyError: 1\n\n    In [8]: ser2.loc[pd.Timestamp(0)]\n    ...\n    KeyError: Timestamp('1970-01-01 00:00:00')\n\n\nSimilarly, :meth:`DataFrame.at` and :meth:`Series.at` will raise a ``TypeError`` instead of a ``ValueError`` if an incompatible key is passed, and ``KeyError`` if a missing key is passed, matching the behavior of ``.loc[]`` (:issue:`31722`)\n\n.. _whatsnew_110.notable_bug_fixes.indexing_int_multiindex_raises_key_errors:\n\nFailed Integer Lookups on MultiIndex Raise KeyError\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nIndexing with integers with a :class:`MultiIndex` that has an integer-dtype\nfirst level incorrectly failed to raise ``KeyError`` when one or more of\nthose integer keys is not present in the first level of the index (:issue:`33539`)\n\n.. ipython:: python\n\n    idx = pd.Index(range(4))\n    dti = pd.date_range(\"2000-01-03\", periods=3)\n    mi = pd.MultiIndex.from_product([idx, dti])\n    ser = pd.Series(range(len(mi)), index=mi)\n\n*Previous behavior*:\n\n.. code-block:: ipython\n\n    In [5]: ser[[5]]\n    Out[5]: Series([], dtype: int64)\n\n*New behavior*:\n\n.. code-block:: ipython\n\n    In [5]: ser[[5]]\n    ...\n    KeyError: '[5] not in index'\n\n:meth:`DataFrame.merge` preserves right frame's row order\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n:meth:`DataFrame.merge` now preserves the right frame's row order when executing a right merge (:issue:`27453`)\n\n.. ipython:: python\n\n    left_df = pd.DataFrame({'animal': ['dog', 'pig'],\n                           'max_speed': [40, 11]})\n    right_df = pd.DataFrame({'animal': ['quetzal', 'pig'],\n                            'max_speed': [80, 11]})\n    left_df\n    right_df\n\n*Previous behavior*:\n\n.. code-block:: python\n\n    >>> left_df.merge(right_df, on=['animal', 'max_speed'], how=\"right\")\n        animal  max_speed\n    0      pig         11\n    1  quetzal         80\n\n*New behavior*:\n\n.. ipython:: python\n\n    left_df.merge(right_df, on=['animal', 'max_speed'], how=\"right\")\n\n.. ---------------------------------------------------------------------------\n\n.. _whatsnew_110.notable_bug_fixes.assignment_to_multiple_columns:\n\nAssignment to multiple columns of a DataFrame when some columns do not exist\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nAssignment to multiple columns of a :class:`DataFrame` when some of the columns do not exist would previously assign the values to the last column. Now, new columns will be constructed with the right values. (:issue:`13658`)\n\n.. ipython:: python\n\n   df = pd.DataFrame({'a': [0, 1, 2], 'b': [3, 4, 5]})\n   df\n\n*Previous behavior*:\n\n.. code-block:: ipython\n\n   In [3]: df[['a', 'c']] = 1\n   In [4]: df\n   Out[4]:\n      a  b\n   0  1  1\n   1  1  1\n   2  1  1\n\n*New behavior*:\n\n.. ipython:: python\n\n   df[['a', 'c']] = 1\n   df\n\n.. _whatsnew_110.notable_bug_fixes.groupby_consistency:\n\nConsistency across groupby reductions\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nUsing :meth:`DataFrame.groupby` with ``as_index=True`` and the aggregation ``nunique`` would include the grouping column(s) in the columns of the result. Now the grouping column(s) only appear in the index, consistent with other reductions. (:issue:`32579`)\n\n.. ipython:: python\n\n   df = pd.DataFrame({\"a\": [\"x\", \"x\", \"y\", \"y\"], \"b\": [1, 1, 2, 3]})\n   df\n\n*Previous behavior*:\n\n.. code-block:: ipython\n\n   In [3]: df.groupby(\"a\", as_index=True).nunique()\n   Out[4]:\n      a  b\n   a\n   x  1  1\n   y  1  2\n\n*New behavior*:\n\n.. ipython:: python\n\n   df.groupby(\"a\", as_index=True).nunique()\n\nUsing :meth:`DataFrame.groupby` with ``as_index=False`` and the function ``idxmax``, ``idxmin``, ``mad``, ``nunique``, ``sem``, ``skew``, or ``std`` would modify the grouping column. Now the grouping column remains unchanged, consistent with other reductions. (:issue:`21090`, :issue:`10355`)\n\n*Previous behavior*:\n\n.. code-block:: ipython\n\n   In [3]: df.groupby(\"a\", as_index=False).nunique()\n   Out[4]:\n      a  b\n   0  1  1\n   1  1  2\n\n*New behavior*:\n\n.. ipython:: python\n\n   df.groupby(\"a\", as_index=False).nunique()\n\nThe method :meth:`.DataFrameGroupBy.size` would previously ignore ``as_index=False``. Now the grouping columns are returned as columns, making the result a :class:`DataFrame` instead of a :class:`Series`. (:issue:`32599`)\n\n*Previous behavior*:\n\n.. code-block:: ipython\n\n   In [3]: df.groupby(\"a\", as_index=False).size()\n   Out[4]:\n   a\n   x    2\n   y    2\n   dtype: int64\n\n*New behavior*:\n\n.. ipython:: python\n\n   df.groupby(\"a\", as_index=False).size()\n\n.. _whatsnew_110.api_breaking.groupby_results_lost_as_index_false:\n\n:meth:`.DataFrameGroupby.agg` lost results with ``as_index=False`` when relabeling columns\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nPreviously :meth:`.DataFrameGroupby.agg` lost the result columns, when the ``as_index`` option was\nset to ``False`` and the result columns were relabeled. In this case the result values were replaced with\nthe previous index (:issue:`32240`).\n\n.. ipython:: python\n\n   df = pd.DataFrame({\"key\": [\"x\", \"y\", \"z\", \"x\", \"y\", \"z\"],\n                      \"val\": [1.0, 0.8, 2.0, 3.0, 3.6, 0.75]})\n   df\n\n*Previous behavior*:\n\n.. code-block:: ipython\n\n   In [2]: grouped = df.groupby(\"key\", as_index=False)\n   In [3]: result = grouped.agg(min_val=pd.NamedAgg(column=\"val\", aggfunc=\"min\"))\n   In [4]: result\n   Out[4]:\n        min_val\n    0   x\n    1   y\n    2   z\n\n*New behavior*:\n\n.. ipython:: python\n\n   grouped = df.groupby(\"key\", as_index=False)\n   result = grouped.agg(min_val=pd.NamedAgg(column=\"val\", aggfunc=\"min\"))\n   result\n\n\n.. _whatsnew_110.notable_bug_fixes.apply_applymap_first_once:\n\napply and applymap on ``DataFrame`` evaluates first row/column only once\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n.. ipython:: python\n\n    df = pd.DataFrame({'a': [1, 2], 'b': [3, 6]})\n\n    def func(row):\n        print(row)\n        return row\n\n*Previous behavior*:\n\n.. code-block:: ipython\n\n    In [4]: df.apply(func, axis=1)\n    a    1\n    b    3\n    Name: 0, dtype: int64\n    a    1\n    b    3\n    Name: 0, dtype: int64\n    a    2\n    b    6\n    Name: 1, dtype: int64\n    Out[4]:\n       a  b\n    0  1  3\n    1  2  6\n\n*New behavior*:\n\n.. ipython:: python\n\n    df.apply(func, axis=1)\n\n.. _whatsnew_110.api_breaking:\n\nBackwards incompatible API changes\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\n.. _whatsnew_110.api_breaking.testing.check_freq:\n\nAdded ``check_freq`` argument to ``testing.assert_frame_equal`` and ``testing.assert_series_equal``\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nThe ``check_freq`` argument was added to :func:`testing.assert_frame_equal` and :func:`testing.assert_series_equal` in pandas 1.1.0 and defaults to ``True``. :func:`testing.assert_frame_equal` and :func:`testing.assert_series_equal` now raise ``AssertionError`` if the indexes do not have the same frequency. Before pandas 1.1.0, the index frequency was not checked.\n\n\nIncreased minimum versions for dependencies\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nSome minimum supported versions of dependencies were updated (:issue:`33718`, :issue:`29766`, :issue:`29723`, pytables >= 3.4.3).\nIf installed, we now require:\n\n+-----------------+-----------------+----------+---------+\n| Package         | Minimum Version | Required | Changed |\n+=================+=================+==========+=========+\n| numpy           | 1.15.4          |    X     |    X    |\n+-----------------+-----------------+----------+---------+\n| pytz            | 2015.4          |    X     |         |\n+-----------------+-----------------+----------+---------+\n| python-dateutil | 2.7.3           |    X     |    X    |\n+-----------------+-----------------+----------+---------+\n| bottleneck      | 1.2.1           |          |         |\n+-----------------+-----------------+----------+---------+\n| numexpr         | 2.6.2           |          |         |\n+-----------------+-----------------+----------+---------+\n| pytest (dev)    | 4.0.2           |          |         |\n+-----------------+-----------------+----------+---------+\n\nFor `optional libraries <https://pandas.pydata.org/docs/getting_started/install.html>`_ the general recommendation is to use the latest version.\nThe following table lists the lowest version per library that is currently being tested throughout the development of pandas.\nOptional libraries below the lowest tested version may still work, but are not considered supported.\n\n+-----------------+-----------------+---------+\n| Package         | Minimum Version | Changed |\n+=================+=================+=========+\n| beautifulsoup4  | 4.6.0           |         |\n+-----------------+-----------------+---------+\n| fastparquet     | 0.3.2           |         |\n+-----------------+-----------------+---------+\n| fsspec          | 0.7.4           |         |\n+-----------------+-----------------+---------+\n| gcsfs           | 0.6.0           |    X    |\n+-----------------+-----------------+---------+\n| lxml            | 3.8.0           |         |\n+-----------------+-----------------+---------+\n| matplotlib      | 2.2.2           |         |\n+-----------------+-----------------+---------+\n| numba           | 0.46.0          |         |\n+-----------------+-----------------+---------+\n| openpyxl        | 2.5.7           |         |\n+-----------------+-----------------+---------+\n| pyarrow         | 0.13.0          |         |\n+-----------------+-----------------+---------+\n| pymysql         | 0.7.1           |         |\n+-----------------+-----------------+---------+\n| pytables        | 3.4.3           |    X    |\n+-----------------+-----------------+---------+\n| s3fs            | 0.4.0           |    X    |\n+-----------------+-----------------+---------+\n| scipy           | 1.2.0           |    X    |\n+-----------------+-----------------+---------+\n| sqlalchemy      | 1.1.4           |         |\n+-----------------+-----------------+---------+\n| xarray          | 0.8.2           |         |\n+-----------------+-----------------+---------+\n| xlrd            | 1.1.0           |         |\n+-----------------+-----------------+---------+\n| xlsxwriter      | 0.9.8           |         |\n+-----------------+-----------------+---------+\n| xlwt            | 1.2.0           |         |\n+-----------------+-----------------+---------+\n| pandas-gbq      | 1.2.0           |    X    |\n+-----------------+-----------------+---------+\n\nSee :ref:`install.dependencies` and :ref:`install.optional_dependencies` for more.\n\nDevelopment changes\n^^^^^^^^^^^^^^^^^^^\n\n- The minimum version of Cython is now the most recent bug-fix version (0.29.16) (:issue:`33334`).\n\n\n.. _whatsnew_110.deprecations:\n\nDeprecations\n~~~~~~~~~~~~\n\n- Lookups on a :class:`Series` with a single-item list containing a slice (e.g. ``ser[[slice(0, 4)]]``) are deprecated and will raise in a future version.  Either convert the list to a tuple, or pass the slice directly instead (:issue:`31333`)\n\n- :meth:`DataFrame.mean` and :meth:`DataFrame.median` with ``numeric_only=None`` will include ``datetime64`` and ``datetime64tz`` columns in a future version (:issue:`29941`)\n- Setting values with ``.loc`` using a positional slice is deprecated and will raise in a future version.  Use ``.loc`` with labels or ``.iloc`` with positions instead (:issue:`31840`)\n- :meth:`DataFrame.to_dict` has deprecated accepting short names for ``orient`` and will raise in a future version (:issue:`32515`)\n- :meth:`Categorical.to_dense` is deprecated and will be removed in a future version, use ``np.asarray(cat)`` instead (:issue:`32639`)\n- The ``fastpath`` keyword in the ``SingleBlockManager`` constructor is deprecated and will be removed in a future version (:issue:`33092`)\n- Providing ``suffixes`` as a ``set`` in :func:`pandas.merge` is deprecated. Provide a tuple instead (:issue:`33740`, :issue:`34741`).\n- Indexing a :class:`Series` with a multi-dimensional indexer like ``[:, None]`` to return an ``ndarray`` now raises a ``FutureWarning``. Convert to a NumPy array before indexing instead (:issue:`27837`)\n- :meth:`Index.is_mixed` is deprecated and will be removed in a future version, check ``index.inferred_type`` directly instead (:issue:`32922`)\n\n- Passing any arguments but the first one to :func:`read_html` as\n  positional arguments is deprecated. All other\n  arguments should be given as keyword arguments (:issue:`27573`).\n\n- Passing any arguments but ``path_or_buf`` (the first one) to\n  :func:`read_json` as positional arguments is deprecated. All\n  other arguments should be given as keyword arguments (:issue:`27573`).\n\n- Passing any arguments but the first two to :func:`read_excel` as\n  positional arguments is deprecated. All other\n  arguments should be given as keyword arguments (:issue:`27573`).\n\n- :func:`pandas.api.types.is_categorical` is deprecated and will be removed in a future version; use :func:`pandas.api.types.is_categorical_dtype` instead (:issue:`33385`)\n- :meth:`Index.get_value` is deprecated and will be removed in a future version (:issue:`19728`)\n- :meth:`Series.dt.week` and :meth:`Series.dt.weekofyear` are deprecated and will be removed in a future version, use :meth:`Series.dt.isocalendar().week` instead (:issue:`33595`)\n- :meth:`DatetimeIndex.week` and ``DatetimeIndex.weekofyear`` are deprecated and will be removed in a future version, use ``DatetimeIndex.isocalendar().week`` instead (:issue:`33595`)\n- :meth:`DatetimeArray.week` and ``DatetimeArray.weekofyear`` are deprecated and will be removed in a future version, use ``DatetimeArray.isocalendar().week`` instead (:issue:`33595`)\n- :meth:`DateOffset.__call__` is deprecated and will be removed in a future version, use ``offset + other`` instead (:issue:`34171`)\n- :meth:`~pandas.tseries.offsets.BusinessDay.apply_index` is deprecated and will be removed in a future version. Use ``offset + other`` instead (:issue:`34580`)\n- :meth:`DataFrame.tshift` and :meth:`Series.tshift` are deprecated and will be removed in a future version, use :meth:`DataFrame.shift` and :meth:`Series.shift` instead (:issue:`11631`)\n- Indexing an :class:`Index` object with a float key is deprecated, and will\n  raise an ``IndexError`` in the future. You can manually convert to an integer key\n  instead (:issue:`34191`).\n- The ``squeeze`` keyword in :meth:`~DataFrame.groupby` is deprecated and will be removed in a future version (:issue:`32380`)\n- The ``tz`` keyword in :meth:`Period.to_timestamp` is deprecated and will be removed in a future version; use ``per.to_timestamp(...).tz_localize(tz)`` instead (:issue:`34522`)\n- :meth:`DatetimeIndex.to_perioddelta` is deprecated and will be removed in a future version.  Use ``index - index.to_period(freq).to_timestamp()`` instead (:issue:`34853`)\n- :meth:`DataFrame.melt` accepting a ``value_name`` that already exists is deprecated, and will be removed in a future version (:issue:`34731`)\n- The ``center`` keyword in the :meth:`DataFrame.expanding` function is deprecated and will be removed in a future version (:issue:`20647`)\n\n\n\n.. ---------------------------------------------------------------------------\n\n\n.. _whatsnew_110.performance:\n\nPerformance improvements\n~~~~~~~~~~~~~~~~~~~~~~~~\n\n- Performance improvement in :class:`Timedelta` constructor (:issue:`30543`)\n- Performance improvement in :class:`Timestamp` constructor (:issue:`30543`)\n- Performance improvement in flex arithmetic ops between :class:`DataFrame` and :class:`Series` with ``axis=0`` (:issue:`31296`)\n- Performance improvement in arithmetic ops between :class:`DataFrame` and :class:`Series` with ``axis=1`` (:issue:`33600`)\n- The internal index method :meth:`~Index._shallow_copy` now copies cached attributes over to the new index,\n  avoiding creating these again on the new index. This can speed up many operations that depend on creating copies of\n  existing indexes (:issue:`28584`, :issue:`32640`, :issue:`32669`)\n- Significant performance improvement when creating a :class:`DataFrame` with\n  sparse values from ``scipy.sparse`` matrices using the\n  :meth:`DataFrame.sparse.from_spmatrix` constructor (:issue:`32821`,\n  :issue:`32825`,  :issue:`32826`, :issue:`32856`, :issue:`32858`).\n- Performance improvement for groupby methods :meth:`.Groupby.first`\n  and :meth:`.Groupby.last` (:issue:`34178`)\n- Performance improvement in :func:`factorize` for nullable (integer and Boolean) dtypes (:issue:`33064`).\n- Performance improvement when constructing :class:`Categorical` objects (:issue:`33921`)\n- Fixed performance regression in :func:`pandas.qcut` and :func:`pandas.cut` (:issue:`33921`)\n- Performance improvement in reductions (``sum``, ``prod``, ``min``, ``max``) for nullable (integer and Boolean) dtypes (:issue:`30982`, :issue:`33261`, :issue:`33442`).\n- Performance improvement in arithmetic operations between two :class:`DataFrame` objects (:issue:`32779`)\n- Performance improvement in :class:`.RollingGroupby` (:issue:`34052`)\n- Performance improvement in arithmetic operations (``sub``, ``add``, ``mul``, ``div``) for :class:`MultiIndex` (:issue:`34297`)\n- Performance improvement in ``DataFrame[bool_indexer]`` when ``bool_indexer`` is a ``list`` (:issue:`33924`)\n- Significant performance improvement of :meth:`io.formats.style.Styler.render` with styles added with various ways such as :meth:`io.formats.style.Styler.apply`, :meth:`io.formats.style.Styler.applymap` or :meth:`io.formats.style.Styler.bar` (:issue:`19917`)\n\n.. ---------------------------------------------------------------------------\n\n.. _whatsnew_110.bug_fixes:\n\nBug fixes\n~~~~~~~~~\n\n\nCategorical\n^^^^^^^^^^^\n\n- Passing an invalid ``fill_value`` to :meth:`Categorical.take` raises a ``ValueError`` instead of ``TypeError`` (:issue:`33660`)\n- Combining a :class:`Categorical` with integer categories and which contains missing values with a float dtype column in operations such as :func:`concat` or :meth:`~DataFrame.append` will now result in a float column instead of an object dtype column (:issue:`33607`)\n- Bug where :func:`merge` was unable to join on non-unique categorical indices (:issue:`28189`)\n- Bug when passing categorical data to :class:`Index` constructor along with ``dtype=object`` incorrectly returning a :class:`CategoricalIndex` instead of object-dtype :class:`Index` (:issue:`32167`)\n- Bug where :class:`Categorical` comparison operator ``__ne__`` would incorrectly evaluate to ``False`` when either element was missing (:issue:`32276`)\n- :meth:`Categorical.fillna` now accepts :class:`Categorical` ``other`` argument (:issue:`32420`)\n- Repr of :class:`Categorical` was not distinguishing between ``int`` and ``str`` (:issue:`33676`)\n\nDatetimelike\n^^^^^^^^^^^^\n\n- Passing an integer dtype other than ``int64`` to ``np.array(period_index, dtype=...)`` will now raise ``TypeError`` instead of incorrectly using ``int64`` (:issue:`32255`)\n- :meth:`Series.to_timestamp` now raises a ``TypeError`` if the axis is not a :class:`PeriodIndex`. Previously an ``AttributeError`` was raised (:issue:`33327`)\n- :meth:`Series.to_period` now raises a ``TypeError`` if the axis is not a :class:`DatetimeIndex`. Previously an ``AttributeError`` was raised (:issue:`33327`)\n- :class:`Period` no longer accepts tuples for the ``freq`` argument (:issue:`34658`)\n- Bug in :class:`Timestamp` where constructing a :class:`Timestamp` from ambiguous epoch time and calling constructor again changed the :meth:`Timestamp.value` property (:issue:`24329`)\n- :meth:`DatetimeArray.searchsorted`, :meth:`TimedeltaArray.searchsorted`, :meth:`PeriodArray.searchsorted` not recognizing non-pandas scalars and incorrectly raising ``ValueError`` instead of ``TypeError`` (:issue:`30950`)\n- Bug in :class:`Timestamp` where constructing :class:`Timestamp` with dateutil timezone less than 128 nanoseconds before daylight saving time switch from winter to summer would result in nonexistent time (:issue:`31043`)\n- Bug in :meth:`Period.to_timestamp`, :meth:`Period.start_time` with microsecond frequency returning a timestamp one nanosecond earlier than the correct time (:issue:`31475`)\n- :class:`Timestamp` raised a confusing error message when year, month or day is missing (:issue:`31200`)\n- Bug in :class:`DatetimeIndex` constructor incorrectly accepting ``bool``-dtype inputs (:issue:`32668`)\n- Bug in :meth:`DatetimeIndex.searchsorted` not accepting a ``list`` or :class:`Series` as its argument (:issue:`32762`)\n- Bug where :meth:`PeriodIndex` raised when passed a :class:`Series` of strings (:issue:`26109`)\n- Bug in :class:`Timestamp` arithmetic when adding or subtracting an ``np.ndarray`` with ``timedelta64`` dtype (:issue:`33296`)\n- Bug in :meth:`DatetimeIndex.to_period` not inferring the frequency when called with no arguments (:issue:`33358`)\n- Bug in :meth:`DatetimeIndex.tz_localize` incorrectly retaining ``freq`` in some cases where the original ``freq`` is no longer valid (:issue:`30511`)\n- Bug in :meth:`DatetimeIndex.intersection` losing ``freq`` and timezone in some cases (:issue:`33604`)\n- Bug in :meth:`DatetimeIndex.get_indexer` where incorrect output would be returned for mixed datetime-like targets (:issue:`33741`)\n- Bug in :class:`DatetimeIndex` addition and subtraction with some types of :class:`DateOffset` objects incorrectly retaining an invalid ``freq`` attribute (:issue:`33779`)\n- Bug in :class:`DatetimeIndex` where setting the ``freq`` attribute on an index could silently change the ``freq`` attribute on another index viewing the same data (:issue:`33552`)\n- :meth:`DataFrame.min` and :meth:`DataFrame.max` were not returning consistent results with :meth:`Series.min` and :meth:`Series.max` when called on objects initialized with empty :func:`pd.to_datetime`\n- Bug in :meth:`DatetimeIndex.intersection` and :meth:`TimedeltaIndex.intersection` with results not having the correct ``name`` attribute (:issue:`33904`)\n- Bug in :meth:`DatetimeArray.__setitem__`, :meth:`TimedeltaArray.__setitem__`, :meth:`PeriodArray.__setitem__` incorrectly allowing values with ``int64`` dtype to be silently cast (:issue:`33717`)\n- Bug in subtracting :class:`TimedeltaIndex` from :class:`Period` incorrectly raising ``TypeError`` in some cases where it should succeed and ``IncompatibleFrequency`` in some cases where it should raise ``TypeError`` (:issue:`33883`)\n- Bug in constructing a :class:`Series` or :class:`Index` from a read-only NumPy array with non-ns\n  resolution which converted to object dtype instead of coercing to ``datetime64[ns]``\n  dtype when within the timestamp bounds (:issue:`34843`).\n- The ``freq`` keyword in :class:`Period`, :func:`date_range`, :func:`period_range`, :func:`pd.tseries.frequencies.to_offset` no longer allows tuples, pass as string instead (:issue:`34703`)\n- Bug in :meth:`DataFrame.append` when appending a :class:`Series` containing a scalar tz-aware :class:`Timestamp` to an empty :class:`DataFrame` resulted in an object column instead of ``datetime64[ns, tz]`` dtype (:issue:`35038`)\n- ``OutOfBoundsDatetime`` issues an improved error message when timestamp is out of implementation bounds. (:issue:`32967`)\n- Bug in :meth:`AbstractHolidayCalendar.holidays` when no rules were defined (:issue:`31415`)\n- Bug in :class:`Tick` comparisons raising ``TypeError`` when comparing against timedelta-like objects (:issue:`34088`)\n- Bug in :class:`Tick` multiplication raising ``TypeError`` when multiplying by a float (:issue:`34486`)\n\nTimedelta\n^^^^^^^^^\n\n- Bug in constructing a :class:`Timedelta` with a high precision integer that would round the :class:`Timedelta` components (:issue:`31354`)\n- Bug in dividing ``np.nan`` or ``None`` by :class:`Timedelta` incorrectly returning ``NaT`` (:issue:`31869`)\n- :class:`Timedelta` now understands ``\u00c2\u00b5s`` as an identifier for microsecond (:issue:`32899`)\n- :class:`Timedelta` string representation now includes nanoseconds, when nanoseconds are non-zero (:issue:`9309`)\n- Bug in comparing a :class:`Timedelta` object against an ``np.ndarray`` with ``timedelta64`` dtype incorrectly viewing all entries as unequal (:issue:`33441`)\n- Bug in :func:`timedelta_range` that produced an extra point on a edge case (:issue:`30353`, :issue:`33498`)\n- Bug in :meth:`DataFrame.resample` that produced an extra point on a edge case (:issue:`30353`, :issue:`13022`, :issue:`33498`)\n- Bug in :meth:`DataFrame.resample` that ignored the ``loffset`` argument when dealing with timedelta (:issue:`7687`, :issue:`33498`)\n- Bug in :class:`Timedelta` and :func:`pandas.to_timedelta` that ignored the ``unit`` argument for string input (:issue:`12136`)\n\nTimezones\n^^^^^^^^^\n\n- Bug in :func:`to_datetime` with ``infer_datetime_format=True`` where timezone names (e.g. ``UTC``) would not be parsed correctly (:issue:`33133`)\n\n\nNumeric\n^^^^^^^\n- Bug in :meth:`DataFrame.floordiv` with ``axis=0`` not treating division-by-zero like :meth:`Series.floordiv` (:issue:`31271`)\n- Bug in :func:`to_numeric` with string argument ``\"uint64\"`` and ``errors=\"coerce\"`` silently fails (:issue:`32394`)\n- Bug in :func:`to_numeric` with ``downcast=\"unsigned\"`` fails for empty data (:issue:`32493`)\n- Bug in :meth:`DataFrame.mean` with ``numeric_only=False`` and either ``datetime64`` dtype or ``PeriodDtype`` column incorrectly raising ``TypeError`` (:issue:`32426`)\n- Bug in :meth:`DataFrame.count` with ``level=\"foo\"`` and index level ``\"foo\"`` containing NaNs causes segmentation fault (:issue:`21824`)\n- Bug in :meth:`DataFrame.diff` with ``axis=1`` returning incorrect results with mixed dtypes (:issue:`32995`)\n- Bug in :meth:`DataFrame.corr` and :meth:`DataFrame.cov` raising when handling nullable integer columns with ``pandas.NA`` (:issue:`33803`)\n- Bug in arithmetic operations between :class:`DataFrame` objects with non-overlapping columns with duplicate labels causing an infinite loop (:issue:`35194`)\n- Bug in :class:`DataFrame` and :class:`Series` addition and subtraction between object-dtype objects and ``datetime64`` dtype objects (:issue:`33824`)\n- Bug in :meth:`Index.difference` giving incorrect results when comparing a :class:`Float64Index` and object :class:`Index` (:issue:`35217`)\n- Bug in :class:`DataFrame` reductions (e.g. ``df.min()``, ``df.max()``) with ``ExtensionArray`` dtypes (:issue:`34520`, :issue:`32651`)\n- :meth:`Series.interpolate` and :meth:`DataFrame.interpolate` now raise a ValueError if ``limit_direction`` is ``'forward'`` or ``'both'`` and ``method`` is ``'backfill'`` or ``'bfill'`` or ``limit_direction`` is ``'backward'`` or ``'both'`` and ``method`` is ``'pad'`` or ``'ffill'`` (:issue:`34746`)\n\nConversion\n^^^^^^^^^^\n- Bug in :class:`Series` construction from NumPy array with big-endian ``datetime64`` dtype (:issue:`29684`)\n- Bug in :class:`Timedelta` construction with large nanoseconds keyword value (:issue:`32402`)\n- Bug in :class:`DataFrame` construction where sets would be duplicated rather than raising (:issue:`32582`)\n- The :class:`DataFrame` constructor no longer accepts a list of :class:`DataFrame` objects. Because of changes to NumPy, :class:`DataFrame` objects are now consistently treated as 2D objects, so a list of :class:`DataFrame` objects is considered 3D, and no longer acceptable for the :class:`DataFrame` constructor (:issue:`32289`).\n- Bug in :class:`DataFrame` when initiating a frame with lists and assign ``columns`` with nested list for ``MultiIndex`` (:issue:`32173`)\n- Improved error message for invalid construction of list when creating a new index (:issue:`35190`)\n\n\nStrings\n^^^^^^^\n\n- Bug in the :meth:`~Series.astype` method when converting \"string\" dtype data to nullable integer dtype (:issue:`32450`).\n- Fixed issue where taking ``min`` or ``max`` of a ``StringArray`` or ``Series`` with ``StringDtype`` type would raise. (:issue:`31746`)\n- Bug in :meth:`Series.str.cat` returning ``NaN`` output when other had :class:`Index` type (:issue:`33425`)\n- :func:`pandas.api.dtypes.is_string_dtype` no longer incorrectly identifies categorical series as string.\n\nInterval\n^^^^^^^^\n- Bug in :class:`IntervalArray` incorrectly allowing the underlying data to be changed when setting values (:issue:`32782`)\n\nIndexing\n^^^^^^^^\n\n- :meth:`DataFrame.xs` now raises a  ``TypeError`` if a ``level`` keyword is supplied and the axis is not a :class:`MultiIndex`. Previously an ``AttributeError`` was raised (:issue:`33610`)\n- Bug in slicing on a :class:`DatetimeIndex` with a partial-timestamp dropping high-resolution indices near the end of a year, quarter, or month (:issue:`31064`)\n- Bug in :meth:`PeriodIndex.get_loc` treating higher-resolution strings differently from :meth:`PeriodIndex.get_value` (:issue:`31172`)\n- Bug in :meth:`Series.at` and :meth:`DataFrame.at` not matching ``.loc`` behavior when looking up an integer in a :class:`Float64Index` (:issue:`31329`)\n- Bug in :meth:`PeriodIndex.is_monotonic` incorrectly returning ``True`` when containing leading ``NaT`` entries (:issue:`31437`)\n- Bug in :meth:`DatetimeIndex.get_loc` raising ``KeyError`` with converted-integer key instead of the user-passed key (:issue:`31425`)\n- Bug in :meth:`Series.xs` incorrectly returning ``Timestamp`` instead of ``datetime64`` in some object-dtype cases (:issue:`31630`)\n- Bug in :meth:`DataFrame.iat` incorrectly returning ``Timestamp`` instead of ``datetime`` in some object-dtype cases (:issue:`32809`)\n- Bug in :meth:`DataFrame.at` when either columns or index is non-unique (:issue:`33041`)\n- Bug in :meth:`Series.loc` and :meth:`DataFrame.loc` when indexing with an integer key on a object-dtype :class:`Index` that is not all-integers (:issue:`31905`)\n- Bug in :meth:`DataFrame.iloc.__setitem__` on a :class:`DataFrame` with duplicate columns incorrectly setting values for all matching columns (:issue:`15686`, :issue:`22036`)\n- Bug in :meth:`DataFrame.loc` and :meth:`Series.loc` with a :class:`DatetimeIndex`, :class:`TimedeltaIndex`, or :class:`PeriodIndex` incorrectly allowing lookups of non-matching datetime-like dtypes (:issue:`32650`)\n- Bug in :meth:`Series.__getitem__` indexing with non-standard scalars, e.g. ``np.dtype`` (:issue:`32684`)\n- Bug in :class:`Index` constructor where an unhelpful error message was raised for NumPy scalars (:issue:`33017`)\n- Bug in :meth:`DataFrame.lookup` incorrectly raising an ``AttributeError`` when ``frame.index`` or ``frame.columns`` is not unique; this will now raise a ``ValueError`` with a helpful error message (:issue:`33041`)\n- Bug in :class:`Interval` where a :class:`Timedelta` could not be added or subtracted from a :class:`Timestamp` interval (:issue:`32023`)\n- Bug in :meth:`DataFrame.copy` not invalidating _item_cache after copy caused post-copy value updates to not be reflected (:issue:`31784`)\n- Fixed regression in :meth:`DataFrame.loc` and :meth:`Series.loc` throwing an error when a ``datetime64[ns, tz]`` value is provided (:issue:`32395`)\n- Bug in :meth:`Series.__getitem__` with an integer key and a :class:`MultiIndex` with leading integer level failing to raise ``KeyError`` if the key is not present in the first level (:issue:`33355`)\n- Bug in :meth:`DataFrame.iloc` when slicing a single column :class:`DataFrame` with ``ExtensionDtype`` (e.g. ``df.iloc[:, :1]``) returning an invalid result (:issue:`32957`)\n- Bug in :meth:`DatetimeIndex.insert` and :meth:`TimedeltaIndex.insert` causing index ``freq`` to be lost when setting an element into an empty :class:`Series` (:issue:`33573`)\n- Bug in :meth:`Series.__setitem__` with an :class:`IntervalIndex` and a list-like key of integers (:issue:`33473`)\n- Bug in :meth:`Series.__getitem__` allowing missing labels with ``np.ndarray``, :class:`Index`, :class:`Series` indexers but not ``list``, these now all raise ``KeyError`` (:issue:`33646`)\n- Bug in :meth:`DataFrame.truncate` and :meth:`Series.truncate` where index was assumed to be monotone increasing (:issue:`33756`)\n- Indexing with a list of strings representing datetimes failed on :class:`DatetimeIndex` or :class:`PeriodIndex` (:issue:`11278`)\n- Bug in :meth:`Series.at` when used with a :class:`MultiIndex` would raise an exception on valid inputs (:issue:`26989`)\n- Bug in :meth:`DataFrame.loc` with dictionary of values changes columns with dtype of ``int`` to ``float`` (:issue:`34573`)\n- Bug in :meth:`Series.loc` when used with a :class:`MultiIndex` would raise an ``IndexingError`` when accessing a ``None`` value (:issue:`34318`)\n- Bug in :meth:`DataFrame.reset_index` and :meth:`Series.reset_index` would not preserve data types on an empty :class:`DataFrame` or :class:`Series` with a :class:`MultiIndex` (:issue:`19602`)\n- Bug in :class:`Series` and :class:`DataFrame` indexing with a ``time`` key on a :class:`DatetimeIndex` with ``NaT`` entries (:issue:`35114`)\n\nMissing\n^^^^^^^\n- Calling :meth:`fillna` on an empty :class:`Series` now correctly returns a shallow copied object. The behaviour is now consistent with :class:`Index`, :class:`DataFrame` and a non-empty :class:`Series` (:issue:`32543`).\n- Bug in :meth:`Series.replace` when argument ``to_replace`` is of type dict/list and is used on a :class:`Series` containing ``<NA>`` was raising a ``TypeError``. The method now handles this by ignoring ``<NA>`` values when doing the comparison for the replacement (:issue:`32621`)\n- Bug in :meth:`~Series.any` and :meth:`~Series.all` incorrectly returning ``<NA>`` for all ``False`` or all ``True`` values using the nulllable Boolean dtype and with ``skipna=False`` (:issue:`33253`)\n- Clarified documentation on interpolate with ``method=akima``. The ``der`` parameter must be scalar or ``None`` (:issue:`33426`)\n- :meth:`DataFrame.interpolate` uses the correct axis convention now. Previously interpolating along columns lead to interpolation along indices and vice versa. Furthermore interpolating with methods ``pad``, ``ffill``, ``bfill`` and ``backfill`` are identical to using these methods with :meth:`DataFrame.fillna` (:issue:`12918`, :issue:`29146`)\n- Bug in :meth:`DataFrame.interpolate` when called on a :class:`DataFrame` with column names of string type was throwing a ValueError. The method is now independent of the type of the column names (:issue:`33956`)\n- Passing :class:`NA` into a format string using format specs will now work. For example ``\"{:.1f}\".format(pd.NA)`` would previously raise a ``ValueError``, but will now return the string ``\"<NA>\"`` (:issue:`34740`)\n- Bug in :meth:`Series.map` not raising on invalid ``na_action`` (:issue:`32815`)\n\nMultiIndex\n^^^^^^^^^^\n\n- :meth:`DataFrame.swaplevels` now raises a ``TypeError`` if the axis is not a :class:`MultiIndex`. Previously an ``AttributeError`` was raised (:issue:`31126`)\n- Bug in :meth:`Dataframe.loc` when used with a :class:`MultiIndex`. The returned values were not in the same order as the given inputs (:issue:`22797`)\n\n.. ipython:: python\n\n        df = pd.DataFrame(np.arange(4),\n                          index=[[\"a\", \"a\", \"b\", \"b\"], [1, 2, 1, 2]])\n         Rows are now ordered as the requested keys\n        df.loc[(['b', 'a'], [2, 1]), :]\n\n- Bug in :meth:`MultiIndex.intersection` was not guaranteed to preserve order when ``sort=False``. (:issue:`31325`)\n- Bug in :meth:`DataFrame.truncate` was dropping :class:`MultiIndex` names. (:issue:`34564`)\n\n.. ipython:: python\n\n        left = pd.MultiIndex.from_arrays([[\"b\", \"a\"], [2, 1]])\n        right = pd.MultiIndex.from_arrays([[\"a\", \"b\", \"c\"], [1, 2, 3]])\n         Common elements are now guaranteed to be ordered by the left side\n        left.intersection(right, sort=False)\n\n- Bug when joining two :class:`MultiIndex` without specifying level with different columns. Return-indexers parameter was ignored. (:issue:`34074`)\n\nIO\n^^\n- Passing a ``set`` as ``names`` argument to :func:`pandas.read_csv`, :func:`pandas.read_table`, or :func:`pandas.read_fwf` will raise ``ValueError: Names should be an ordered collection.`` (:issue:`34946`)\n- Bug in print-out when ``display.precision`` is zero. (:issue:`20359`)\n- Bug in :func:`read_json` where integer overflow was occurring when json contains big number strings. (:issue:`30320`)\n- :func:`read_csv` will now raise a ``ValueError`` when the arguments ``header`` and ``prefix`` both are not ``None``. (:issue:`27394`)\n- Bug in :meth:`DataFrame.to_json` was raising ``NotFoundError`` when ``path_or_buf`` was an S3 URI (:issue:`28375`)\n- Bug in :meth:`DataFrame.to_parquet` overwriting pyarrow's default for\n  ``coerce_timestamps``; following pyarrow's default allows writing nanosecond\n  timestamps with ``version=\"2.0\"`` (:issue:`31652`).\n- Bug in :func:`read_csv` was raising ``TypeError`` when ``sep=None`` was used in combination with ``comment`` keyword (:issue:`31396`)\n- Bug in :class:`HDFStore` that caused it to set to ``int64`` the dtype of a ``datetime64`` column when reading a :class:`DataFrame` in Python 3 from fixed format written in Python 2 (:issue:`31750`)\n- :func:`read_sas()` now handles dates and datetimes larger than :attr:`Timestamp.max` returning them as :class:`datetime.datetime` objects (:issue:`20927`)\n- Bug in :meth:`DataFrame.to_json` where ``Timedelta`` objects would not be serialized correctly with ``date_format=\"iso\"`` (:issue:`28256`)\n- :func:`read_csv` will raise a ``ValueError`` when the column names passed in ``parse_dates`` are missing in the :class:`Dataframe` (:issue:`31251`)\n- Bug in :func:`read_excel` where a UTF-8 string with a high surrogate would cause a segmentation violation (:issue:`23809`)\n- Bug in :func:`read_csv` was causing a file descriptor leak on an empty file (:issue:`31488`)\n- Bug in :func:`read_csv` was causing a segfault when there were blank lines between the header and data rows (:issue:`28071`)\n- Bug in :func:`read_csv` was raising a misleading exception on a permissions issue (:issue:`23784`)\n- Bug in :func:`read_csv` was raising an ``IndexError`` when ``header=None`` and two extra data columns\n- Bug in :func:`read_sas` was raising an ``AttributeError`` when reading files from Google Cloud Storage (:issue:`33069`)\n- Bug in :meth:`DataFrame.to_sql` where an ``AttributeError`` was raised when saving an out of bounds date (:issue:`26761`)\n- Bug in :func:`read_excel` did not correctly handle multiple embedded spaces in OpenDocument text cells. (:issue:`32207`)\n- Bug in :func:`read_json` was raising ``TypeError`` when reading a ``list`` of Booleans into a :class:`Series`. (:issue:`31464`)\n- Bug in :func:`pandas.io.json.json_normalize` where location specified by ``record_path`` doesn't point to an array. (:issue:`26284`)\n- :func:`pandas.read_hdf` has a more explicit error message when loading an\n  unsupported HDF file (:issue:`9539`)\n- Bug in :meth:`~DataFrame.read_feather` was raising an ``ArrowIOError`` when reading an s3 or http file path (:issue:`29055`)\n- Bug in :meth:`~DataFrame.to_excel` could not handle the column name ``render`` and was raising an ``KeyError`` (:issue:`34331`)\n- Bug in :meth:`~SQLDatabase.execute` was raising a ``ProgrammingError`` for some DB-API drivers when the SQL statement contained the ``%`` character and no parameters were present (:issue:`34211`)\n- Bug in :meth:`~pandas.io.stata.StataReader` which resulted in categorical variables with different dtypes when reading data using an iterator. (:issue:`31544`)\n- :meth:`HDFStore.keys` has now an optional ``include`` parameter that allows the retrieval of all native HDF5 table names (:issue:`29916`)\n- ``TypeError`` exceptions raised by :func:`read_csv` and :func:`read_table` were showing as ``parser_f`` when an unexpected keyword argument was passed (:issue:`25648`)\n- Bug in :func:`read_excel` for ODS files removes 0.0 values (:issue:`27222`)\n- Bug in :func:`ujson.encode` was raising an ``OverflowError`` with numbers larger than ``sys.maxsize`` (:issue:`34395`)\n- Bug in :meth:`HDFStore.append_to_multiple` was raising a ``ValueError`` when the ``min_itemsize`` parameter is set (:issue:`11238`)\n- Bug in :meth:`~HDFStore.create_table` now raises an error when ``column`` argument was not specified in ``data_columns`` on input (:issue:`28156`)\n- :func:`read_json` now could read line-delimited json file from a file url while ``lines`` and ``chunksize`` are set.\n- Bug in :meth:`DataFrame.to_sql` when reading DataFrames with ``-np.inf`` entries with MySQL now has a more explicit ``ValueError`` (:issue:`34431`)\n- Bug where capitalised files extensions were not decompressed by read_* functions (:issue:`35164`)\n- Bug in :meth:`read_excel` that was raising a ``TypeError`` when ``header=None`` and ``index_col`` is given as a ``list`` (:issue:`31783`)\n- Bug in :func:`read_excel` where datetime values are used in the header in a :class:`MultiIndex` (:issue:`34748`)\n- :func:`read_excel` no longer takes ``**kwds`` arguments. This means that passing in the keyword argument ``chunksize`` now raises a ``TypeError`` (previously raised a ``NotImplementedError``), while passing in the keyword argument ``encoding`` now raises a ``TypeError`` (:issue:`34464`)\n- Bug in :meth:`DataFrame.to_records` was incorrectly losing timezone information in timezone-aware ``datetime64`` columns (:issue:`32535`)\n\nPlotting\n^^^^^^^^\n\n- :meth:`DataFrame.plot` for line/bar now accepts color by dictionary (:issue:`8193`).\n- Bug in :meth:`DataFrame.plot.hist` where weights are not working for multiple columns (:issue:`33173`)\n- Bug in :meth:`DataFrame.boxplot` and :meth:`DataFrame.plot.boxplot` lost color attributes of ``medianprops``, ``whiskerprops``, ``capprops`` and ``boxprops`` (:issue:`30346`)\n- Bug in :meth:`DataFrame.hist` where the order of ``column`` argument was ignored (:issue:`29235`)\n- Bug in :meth:`DataFrame.plot.scatter` that when adding multiple plots with different ``cmap``, colorbars always use the first ``cmap`` (:issue:`33389`)\n- Bug in :meth:`DataFrame.plot.scatter` was adding a colorbar to the plot even if the argument ``c`` was assigned to a column containing color names (:issue:`34316`)\n- Bug in :meth:`pandas.plotting.bootstrap_plot` was causing cluttered axes and overlapping labels (:issue:`34905`)\n- Bug in :meth:`DataFrame.plot.scatter` caused an error when plotting variable marker sizes (:issue:`32904`)\n\nGroupBy/resample/rolling\n^^^^^^^^^^^^^^^^^^^^^^^^\n\n- Using a :class:`pandas.api.indexers.BaseIndexer` with ``count``, ``min``, ``max``, ``median``, ``skew``,  ``cov``, ``corr`` will now return correct results for any monotonic :class:`pandas.api.indexers.BaseIndexer` descendant (:issue:`32865`)\n- :meth:`DataFrameGroupby.mean` and :meth:`SeriesGroupby.mean` (and similarly for :meth:`~DataFrameGroupby.median`, :meth:`~DataFrameGroupby.std` and :meth:`~DataFrameGroupby.var`) now raise a ``TypeError`` if a non-accepted keyword argument is passed into it. Previously an ``UnsupportedFunctionCall`` was raised (``AssertionError`` if ``min_count`` passed into :meth:`~DataFrameGroupby.median`) (:issue:`31485`)\n- Bug in :meth:`.DataFrameGroupBy.apply` and :meth:`.SeriesGroupBy.apply` raising ``ValueError`` when the ``by`` axis is not sorted, has duplicates, and the applied ``func`` does not mutate passed in objects (:issue:`30667`)\n- Bug in :meth:`DataFrameGroupBy.transform` produces an incorrect result with transformation functions (:issue:`30918`)\n- Bug in :meth:`.DataFrameGroupBy.transform` and :meth:`.SeriesGroupBy.transform` were returning the wrong result when grouping by multiple keys of which some were categorical and others not (:issue:`32494`)\n- Bug in :meth:`.DataFrameGroupBy.count` and :meth:`.SeriesGroupBy.count` causing segmentation fault when grouped-by columns contain NaNs (:issue:`32841`)\n- Bug in :meth:`DataFrame.groupby` and :meth:`Series.groupby` produces inconsistent type when aggregating Boolean :class:`Series` (:issue:`32894`)\n- Bug in :meth:`DataFrameGroupBy.sum` and :meth:`SeriesGroupBy.sum` where a large negative number would be returned when the number of non-null values was below ``min_count`` for nullable integer dtypes (:issue:`32861`)\n- Bug in :meth:`SeriesGroupBy.quantile` was raising on nullable integers (:issue:`33136`)\n- Bug in :meth:`DataFrame.resample` where an ``AmbiguousTimeError`` would be raised when the resulting timezone aware :class:`DatetimeIndex` had a DST transition at midnight (:issue:`25758`)\n- Bug in :meth:`DataFrame.groupby` where a ``ValueError`` would be raised when grouping by a categorical column with read-only categories and ``sort=False`` (:issue:`33410`)\n- Bug in :meth:`.DataFrameGroupBy.agg`, :meth:`.SeriesGroupBy.agg`, :meth:`.DataFrameGroupBy.transform`, :meth:`.SeriesGroupBy.transform`, :meth:`.DataFrameGroupBy.resample`, and :meth:`.SeriesGroupBy.resample` where subclasses are not preserved (:issue:`28330`)\n- Bug in :meth:`SeriesGroupBy.agg` where any column name was accepted in the named aggregation of :class:`SeriesGroupBy` previously. The behaviour now allows only ``str`` and callables else would raise ``TypeError``. (:issue:`34422`)\n- Bug in :meth:`DataFrame.groupby` lost the name of the :class:`Index` when one of the ``agg`` keys referenced an empty list (:issue:`32580`)\n- Bug in :meth:`Rolling.apply` where ``center=True`` was ignored when ``engine='numba'`` was specified (:issue:`34784`)\n- Bug in :meth:`DataFrame.ewm.cov` was throwing ``AssertionError`` for :class:`MultiIndex` inputs (:issue:`34440`)\n- Bug in :meth:`core.groupby.DataFrameGroupBy.quantile` raised ``TypeError`` for non-numeric types rather than dropping the columns (:issue:`27892`)\n- Bug in :meth:`core.groupby.DataFrameGroupBy.transform` when ``func='nunique'`` and columns are of type ``datetime64``, the result would also be of type ``datetime64`` instead of ``int64`` (:issue:`35109`)\n- Bug in :meth:`DataFrame.groupby` raising an ``AttributeError`` when selecting a column and aggregating with ``as_index=False`` (:issue:`35246`).\n- Bug in :meth:`DataFrameGroupBy.first` and :meth:`DataFrameGroupBy.last` that would raise an unnecessary ``ValueError`` when grouping on multiple ``Categoricals`` (:issue:`34951`)\n\nReshaping\n^^^^^^^^^\n\n- Bug effecting all numeric and Boolean reduction methods not returning subclassed data type. (:issue:`25596`)\n- Bug in :meth:`DataFrame.pivot_table` when only :class:`MultiIndexed` columns is set (:issue:`17038`)\n- Bug in :meth:`DataFrame.unstack` and :meth:`Series.unstack` can take tuple names in :class:`MultiIndexed` data (:issue:`19966`)\n- Bug in :meth:`DataFrame.pivot_table` when ``margin`` is ``True`` and only ``column`` is defined (:issue:`31016`)\n- Fixed incorrect error message in :meth:`DataFrame.pivot` when ``columns`` is set to ``None``. (:issue:`30924`)\n- Bug in :func:`crosstab` when inputs are two :class:`Series` and have tuple names, the output will keep a dummy :class:`MultiIndex` as columns. (:issue:`18321`)\n- :meth:`DataFrame.pivot` can now take lists for ``index`` and ``columns`` arguments (:issue:`21425`)\n- Bug in :func:`concat` where the resulting indices are not copied when ``copy=True`` (:issue:`29879`)\n- Bug in :meth:`SeriesGroupBy.aggregate` was resulting in aggregations being overwritten when they shared the same name (:issue:`30880`)\n- Bug where :meth:`Index.astype` would lose the :attr:`name` attribute when converting from ``Float64Index`` to ``Int64Index``, or when casting to an ``ExtensionArray`` dtype (:issue:`32013`)\n- :meth:`Series.append` will now raise a ``TypeError`` when passed a :class:`DataFrame` or a sequence containing :class:`DataFrame` (:issue:`31413`)\n- :meth:`DataFrame.replace` and :meth:`Series.replace` will raise a ``TypeError`` if ``to_replace`` is not an expected type. Previously the ``replace`` would fail silently (:issue:`18634`)\n- Bug on inplace operation of a :class:`Series` that was adding a column to the :class:`DataFrame` from where it was originally dropped from (using ``inplace=True``) (:issue:`30484`)\n- Bug in :meth:`DataFrame.apply` where callback was called with :class:`Series` parameter even though ``raw=True`` requested. (:issue:`32423`)\n- Bug in :meth:`DataFrame.pivot_table` losing timezone information when creating a :class:`MultiIndex` level from a column with timezone-aware dtype (:issue:`32558`)\n- Bug in :func:`concat` where when passing a non-dict mapping as ``objs`` would raise a ``TypeError`` (:issue:`32863`)\n- :meth:`DataFrame.agg` now provides more descriptive ``SpecificationError`` message when attempting to aggregate a non-existent column (:issue:`32755`)\n- Bug in :meth:`DataFrame.unstack` when :class:`MultiIndex` columns and :class:`MultiIndex` rows were used (:issue:`32624`, :issue:`24729` and :issue:`28306`)\n- Appending a dictionary to a :class:`DataFrame` without passing ``ignore_index=True`` will raise ``TypeError: Can only append a dict if ignore_index=True`` instead of ``TypeError: Can only append a :class:`Series` if ignore_index=True or if the :class:`Series` has a name`` (:issue:`30871`)\n- Bug in :meth:`DataFrame.corrwith()`, :meth:`DataFrame.memory_usage()`, :meth:`DataFrame.dot()`,\n  :meth:`DataFrame.idxmin()`, :meth:`DataFrame.idxmax()`, :meth:`DataFrame.duplicated()`, :meth:`DataFrame.isin()`,\n  :meth:`DataFrame.count()`, :meth:`Series.explode()`, :meth:`Series.asof()` and :meth:`DataFrame.asof()` not\n  returning subclassed types. (:issue:`31331`)\n- Bug in :func:`concat` was not allowing for concatenation of :class:`DataFrame` and :class:`Series` with duplicate keys (:issue:`33654`)\n- Bug in :func:`cut` raised an error when the argument ``labels`` contains duplicates (:issue:`33141`)\n- Ensure only named functions can be used in :func:`eval()` (:issue:`32460`)\n- Bug in :meth:`Dataframe.aggregate` and :meth:`Series.aggregate` was causing a recursive loop in some cases (:issue:`34224`)\n- Fixed bug in :func:`melt` where melting :class:`MultiIndex` columns with ``col_level > 0`` would raise a ``KeyError`` on ``id_vars`` (:issue:`34129`)\n- Bug in :meth:`Series.where` with an empty :class:`Series` and empty ``cond`` having non-bool dtype (:issue:`34592`)\n- Fixed regression where :meth:`DataFrame.apply` would raise ``ValueError`` for elements with ``S`` dtype (:issue:`34529`)\n\nSparse\n^^^^^^\n- Creating a :class:`SparseArray` from timezone-aware dtype will issue a warning before dropping timezone information, instead of doing so silently (:issue:`32501`)\n- Bug in :meth:`arrays.SparseArray.from_spmatrix` wrongly read scipy sparse matrix (:issue:`31991`)\n- Bug in :meth:`Series.sum` with ``SparseArray`` raised a ``TypeError`` (:issue:`25777`)\n- Bug where :class:`DataFrame` containing an all-sparse :class:`SparseArray` filled with ``NaN`` when indexed by a list-like (:issue:`27781`, :issue:`29563`)\n- The repr of :class:`SparseDtype` now includes the repr of its ``fill_value`` attribute. Previously it used ``fill_value``'s  string representation (:issue:`34352`)\n- Bug where empty :class:`DataFrame` could not be cast to :class:`SparseDtype` (:issue:`33113`)\n- Bug in :meth:`arrays.SparseArray` was returning the incorrect type when indexing a sparse dataframe with an iterable (:issue:`34526`, :issue:`34540`)\n\nExtensionArray\n^^^^^^^^^^^^^^\n\n- Fixed bug where :meth:`Series.value_counts` would raise on empty input of ``Int64`` dtype (:issue:`33317`)\n- Fixed bug in :func:`concat` when concatenating :class:`DataFrame` objects with non-overlapping columns resulting in object-dtype columns rather than preserving the extension dtype (:issue:`27692`, :issue:`33027`)\n- Fixed bug where :meth:`StringArray.isna` would return ``False`` for NA values when ``pandas.options.mode.use_inf_as_na`` was set to ``True`` (:issue:`33655`)\n- Fixed bug in :class:`Series` construction with EA dtype and index but no data or scalar data fails (:issue:`26469`)\n- Fixed bug that caused :meth:`Series.__repr__()` to crash for extension types whose elements are multidimensional arrays (:issue:`33770`).\n- Fixed bug where :meth:`Series.update` would raise a ``ValueError`` for ``ExtensionArray`` dtypes with missing values (:issue:`33980`)\n- Fixed bug where :meth:`StringArray.memory_usage` was not implemented (:issue:`33963`)\n- Fixed bug where :meth:`DataFrameGroupBy` would ignore the ``min_count`` argument for aggregations on nullable Boolean dtypes (:issue:`34051`)\n- Fixed bug where the constructor of :class:`DataFrame` with ``dtype='string'`` would fail (:issue:`27953`, :issue:`33623`)\n- Bug where :class:`DataFrame` column set to scalar extension type was considered an object type rather than the extension type (:issue:`34832`)\n- Fixed bug in :meth:`IntegerArray.astype` to correctly copy the mask as well (:issue:`34931`).\n\nOther\n^^^^^\n\n- Set operations on an object-dtype :class:`Index` now always return object-dtype results (:issue:`31401`)\n- Fixed :func:`pandas.testing.assert_series_equal` to correctly raise if the ``left`` argument is a different subclass with ``check_series_type=True`` (:issue:`32670`).\n- Getting a missing attribute in a :meth:`DataFrame.query` or :meth:`DataFrame.eval` string raises the correct ``AttributeError`` (:issue:`32408`)\n- Fixed bug in :func:`pandas.testing.assert_series_equal` where dtypes were checked for ``Interval`` and ``ExtensionArray`` operands when ``check_dtype`` was ``False`` (:issue:`32747`)\n- Bug in :meth:`DataFrame.__dir__` caused a segfault when using unicode surrogates in a column name (:issue:`25509`)\n- Bug in :meth:`DataFrame.equals` and :meth:`Series.equals` in allowing subclasses to be equal (:issue:`34402`).\n\n.. ---------------------------------------------------------------------------\n\n.. _whatsnew_110.contributors:\n\nContributors\n~~~~~~~~~~~~\n\n.. contributors:: v1.0.5..v1.1.0|HEAD\n\n\n.. _whatsnew_102:\n\nWhat's new in 1.0.2 (March 12, 2020)\n------------------------------------\n\nThese are the changes in pandas 1.0.2. See :ref:`release` for a full changelog\nincluding other versions of pandas.\n\n{{ header }}\n\n.. ---------------------------------------------------------------------------\n\n.. _whatsnew_102.regressions:\n\nFixed regressions\n~~~~~~~~~~~~~~~~~\n\n**Groupby**\n\n- Fixed regression in :meth:`.DataFrameGroupBy.agg` and :meth:`.SeriesGroupBy.agg` which were failing on frames with :class:`MultiIndex` columns and a custom function (:issue:`31777`)\n- Fixed regression in ``groupby(..).rolling(..).apply()`` (``RollingGroupby``) where the ``raw`` parameter was ignored (:issue:`31754`)\n- Fixed regression in :meth:`rolling(..).corr() <.Rolling.corr>` when using a time offset (:issue:`31789`)\n- Fixed regression in :meth:`groupby(..).nunique() <.DataFrameGroupBy.nunique>` which was modifying the original values if ``NaN`` values were present (:issue:`31950`)\n- Fixed regression in ``DataFrame.groupby`` raising a ``ValueError`` from an internal operation (:issue:`31802`)\n- Fixed regression in :meth:`.DataFrameGroupBy.agg` and :meth:`.SeriesGroupBy.agg` calling a user-provided function an extra time on an empty input (:issue:`31760`)\n\n**I/O**\n\n- Fixed regression in :meth:`read_csv` in which the ``encoding`` option was not recognized with certain file-like objects (:issue:`31819`)\n- Fixed regression in :meth:`DataFrame.to_excel` when the ``columns`` keyword argument is passed (:issue:`31677`)\n- Fixed regression in :class:`ExcelFile` where the stream passed into the function was closed by the destructor. (:issue:`31467`)\n- Fixed regression where :func:`read_pickle` raised a ``UnicodeDecodeError`` when reading a py27 pickle with :class:`MultiIndex` column (:issue:`31988`).\n\n**Reindexing/alignment**\n\n- Fixed regression in :meth:`Series.align` when ``other`` is a :class:`DataFrame` and ``method`` is not ``None`` (:issue:`31785`)\n- Fixed regression in :meth:`DataFrame.reindex` and :meth:`Series.reindex` when reindexing with (tz-aware) index and ``method=nearest`` (:issue:`26683`)\n- Fixed regression in :meth:`DataFrame.reindex_like` on a :class:`DataFrame` subclass raised an  ``AssertionError`` (:issue:`31925`)\n- Fixed regression in :class:`DataFrame` arithmetic operations with mis-matched columns (:issue:`31623`)\n\n**Other**\n\n- Fixed regression in joining on :class:`DatetimeIndex` or :class:`TimedeltaIndex` to preserve ``freq`` in simple cases (:issue:`32166`)\n- Fixed regression in :meth:`Series.shift` with ``datetime64`` dtype when passing an integer ``fill_value`` (:issue:`32591`)\n- Fixed regression in the repr of an object-dtype :class:`Index` with bools and missing values (:issue:`32146`)\n\n\n.. ---------------------------------------------------------------------------\n\nIndexing with nullable boolean arrays\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\nPreviously indexing with a nullable Boolean array containing ``NA`` would raise a ``ValueError``, however this is now permitted with ``NA`` being treated as ``False``. (:issue:`31503`)\n\n.. ipython:: python\n\n    s = pd.Series([1, 2, 3, 4])\n    mask = pd.array([True, True, False, None], dtype=\"boolean\")\n    s\n    mask\n\n*pandas 1.0.0-1.0.1*\n\n.. code-block:: python\n\n    >>> s[mask]\n    Traceback (most recent call last):\n    ...\n    ValueError: cannot mask with array containing NA / NaN values\n\n*pandas 1.0.2*\n\n.. ipython:: python\n\n    s[mask]\n\n.. _whatsnew_102.bug_fixes:\n\nBug fixes\n~~~~~~~~~\n\n**Datetimelike**\n\n- Bug in :meth:`Series.astype` not copying for tz-naive and tz-aware ``datetime64`` dtype (:issue:`32490`)\n- Bug where :func:`to_datetime` would raise when passed ``pd.NA`` (:issue:`32213`)\n- Improved error message when subtracting two :class:`Timestamp` that result in an out-of-bounds :class:`Timedelta` (:issue:`31774`)\n\n**Categorical**\n\n- Fixed bug where :meth:`Categorical.from_codes` improperly raised a ``ValueError`` when passed nullable integer codes. (:issue:`31779`)\n- Fixed bug where :meth:`Categorical` constructor would raise a ``TypeError`` when given a numpy array containing ``pd.NA``. (:issue:`31927`)\n- Bug in :class:`Categorical` that would ignore or crash when calling :meth:`Series.replace` with a list-like ``to_replace`` (:issue:`31720`)\n\n**I/O**\n\n- Using ``pd.NA`` with :meth:`DataFrame.to_json` now correctly outputs a null value instead of an empty object (:issue:`31615`)\n- Bug in :meth:`pandas.json_normalize` when value in meta path is not iterable (:issue:`31507`)\n- Fixed pickling of ``pandas.NA``. Previously a new object was returned, which broke computations relying on ``NA`` being a singleton (:issue:`31847`)\n- Fixed bug in parquet roundtrip with nullable unsigned integer dtypes (:issue:`31896`).\n\n**Experimental dtypes**\n\n- Fixed bug in :meth:`DataFrame.convert_dtypes` for columns that were already using the ``\"string\"`` dtype (:issue:`31731`).\n- Fixed bug in :meth:`DataFrame.convert_dtypes` for series with mix of integers and strings (:issue:`32117`)\n- Fixed bug in :meth:`DataFrame.convert_dtypes` where ``BooleanDtype`` columns were converted to ``Int64`` (:issue:`32287`)\n- Fixed bug in setting values using a slice indexer with string dtype (:issue:`31772`)\n- Fixed bug where :meth:`.DataFrameGroupBy.first`, :meth:`.SeriesGroupBy.first`, :meth:`.DataFrameGroupBy.last`, and :meth:`.SeriesGroupBy.last` would raise a ``TypeError`` when groups contained ``pd.NA`` in a column of object dtype (:issue:`32123`)\n- Fixed bug where :meth:`DataFrameGroupBy.mean`, :meth:`DataFrameGroupBy.median`, :meth:`DataFrameGroupBy.var`, and :meth:`DataFrameGroupBy.std` would raise a ``TypeError`` on ``Int64`` dtype columns (:issue:`32219`)\n\n**Strings**\n\n- Using ``pd.NA`` with :meth:`Series.str.repeat` now correctly outputs a null value instead of raising error for vector inputs (:issue:`31632`)\n\n**Rolling**\n\n- Fixed rolling operations with variable window (defined by time duration) on decreasing time index (:issue:`32385`).\n\n.. ---------------------------------------------------------------------------\n\n.. _whatsnew_102.contributors:\n\nContributors\n~~~~~~~~~~~~\n\n.. contributors:: v1.0.1..v1.0.2\n\n\n.. _whatsnew_0232:\n\nWhat's new in 0.23.2 (July 5, 2018)\n-----------------------------------\n\n{{ header }}\n\n\nThis is a minor bug-fix release in the 0.23.x series and includes some small regression fixes\nand bug fixes. We recommend that all users upgrade to this version.\n\n.. note::\n\n   pandas 0.23.2 is first pandas release that's compatible with\n   Python 3.7 (:issue:`20552`)\n\n.. warning::\n\n   Starting January 1, 2019, pandas feature releases will support Python 3 only.\n   See `Dropping Python 2.7 <https://pandas.pydata.org/pandas-docs/version/0.24/install.html#install-dropping-27>`_ for more.\n\n.. contents:: What's new in v0.23.2\n    :local:\n    :backlinks: none\n\n.. _whatsnew_0232.enhancements:\n\nLogical reductions over entire DataFrame\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\n:meth:`DataFrame.all` and :meth:`DataFrame.any` now accept ``axis=None`` to reduce over all axes to a scalar (:issue:`19976`)\n\n.. ipython:: python\n\n   df = pd.DataFrame({\"A\": [1, 2], \"B\": [True, False]})\n   df.all(axis=None)\n\n\nThis also provides compatibility with NumPy 1.15, which now dispatches to ``DataFrame.all``.\nWith NumPy 1.15 and pandas 0.23.1 or earlier, :func:`numpy.all` will no longer reduce over every axis:\n\n.. code-block:: python\n\n   >>>  NumPy 1.15, pandas 0.23.1\n   >>> np.any(pd.DataFrame({\"A\": [False], \"B\": [False]}))\n   A    False\n   B    False\n   dtype: bool\n\nWith pandas 0.23.2, that will correctly return False, as it did with NumPy < 1.15.\n\n.. ipython:: python\n\n   np.any(pd.DataFrame({\"A\": [False], \"B\": [False]}))\n\n\n.. _whatsnew_0232.fixed_regressions:\n\nFixed regressions\n~~~~~~~~~~~~~~~~~\n\n- Fixed regression in :meth:`to_csv` when handling file-like object incorrectly (:issue:`21471`)\n- Re-allowed duplicate level names of a ``MultiIndex``. Accessing a level that has a duplicate name by name still raises an error (:issue:`19029`).\n- Bug in both :meth:`DataFrame.first_valid_index` and :meth:`Series.first_valid_index` raised for a row index having duplicate values (:issue:`21441`)\n- Fixed printing of DataFrames with hierarchical columns with long names (:issue:`21180`)\n- Fixed regression in :meth:`~DataFrame.reindex` and :meth:`~DataFrame.groupby`\n  with a MultiIndex or multiple keys that contains categorical datetime-like values (:issue:`21390`).\n- Fixed regression in unary negative operations with object dtype (:issue:`21380`)\n- Bug in :meth:`Timestamp.ceil` and :meth:`Timestamp.floor` when timestamp is a multiple of the rounding frequency (:issue:`21262`)\n- Fixed regression in :func:`to_clipboard` that defaulted to copying dataframes with space delimited instead of tab delimited (:issue:`21104`)\n\n\nBuild changes\n~~~~~~~~~~~~~\n\n- The source and binary distributions no longer include test data files, resulting in smaller download sizes. Tests relying on these data files will be skipped when using ``pandas.test()``. (:issue:`19320`)\n\n.. _whatsnew_0232.bug_fixes:\n\nBug fixes\n~~~~~~~~~\n\n**Conversion**\n\n- Bug in constructing :class:`Index` with an iterator or generator (:issue:`21470`)\n- Bug in :meth:`Series.nlargest` for signed and unsigned integer dtypes when the minimum value is present (:issue:`21426`)\n\n**Indexing**\n\n- Bug in :meth:`Index.get_indexer_non_unique` with categorical key (:issue:`21448`)\n- Bug in comparison operations for :class:`MultiIndex` where error was raised on equality / inequality comparison involving a MultiIndex with ``nlevels == 1`` (:issue:`21149`)\n- Bug in :meth:`DataFrame.drop` behaviour is not consistent for unique and non-unique indexes (:issue:`21494`)\n- Bug in :func:`DataFrame.duplicated` with a large number of columns causing a 'maximum recursion depth exceeded' (:issue:`21524`).\n\n**I/O**\n\n- Bug in :func:`read_csv` that caused it to incorrectly raise an error when ``nrows=0``, ``low_memory=True``, and ``index_col`` was not ``None`` (:issue:`21141`)\n- Bug in :func:`json_normalize` when formatting the ``record_prefix`` with integer columns (:issue:`21536`)\n\n**Categorical**\n\n- Bug in rendering :class:`Series` with ``Categorical`` dtype in rare conditions under Python 2.7 (:issue:`21002`)\n\n**Timezones**\n\n- Bug in :class:`Timestamp` and :class:`DatetimeIndex` where passing a :class:`Timestamp` localized after a DST transition would return a datetime before the DST transition (:issue:`20854`)\n- Bug in comparing :class:`DataFrame` with tz-aware :class:`DatetimeIndex` columns with a DST transition that raised a ``KeyError`` (:issue:`19970`)\n- Bug in :meth:`DatetimeIndex.shift` where an ``AssertionError`` would raise when shifting across DST (:issue:`8616`)\n- Bug in :class:`Timestamp` constructor where passing an invalid timezone offset designator (``Z``) would not raise a ``ValueError`` (:issue:`8910`)\n- Bug in :meth:`Timestamp.replace` where replacing at a DST boundary would retain an incorrect offset (:issue:`7825`)\n- Bug in :meth:`DatetimeIndex.reindex` when reindexing a tz-naive and tz-aware :class:`DatetimeIndex` (:issue:`8306`)\n- Bug in :meth:`DatetimeIndex.resample` when downsampling across a DST boundary (:issue:`8531`)\n\n**Timedelta**\n\n- Bug in :class:`Timedelta` where non-zero timedeltas shorter than 1 microsecond were considered False (:issue:`21484`)\n\n.. _whatsnew_0.23.2.contributors:\n\nContributors\n~~~~~~~~~~~~\n\n.. contributors:: v0.23.1..v0.23.2\n\n\n.. _whatsnew_115:\n\nWhat's new in 1.1.5 (December 07, 2020)\n---------------------------------------\n\nThese are the changes in pandas 1.1.5. See :ref:`release` for a full changelog\nincluding other versions of pandas.\n\n{{ header }}\n\n.. ---------------------------------------------------------------------------\n\n.. _whatsnew_115.regressions:\n\nFixed regressions\n~~~~~~~~~~~~~~~~~\n- Fixed regression in addition of a timedelta-like scalar to a :class:`DatetimeIndex` raising incorrectly (:issue:`37295`)\n- Fixed regression in :meth:`Series.groupby` raising when the :class:`Index` of the :class:`Series` had a tuple as its name (:issue:`37755`)\n- Fixed regression in :meth:`DataFrame.loc` and :meth:`Series.loc` for ``__setitem__`` when one-dimensional tuple was given to select from :class:`MultiIndex` (:issue:`37711`)\n- Fixed regression in inplace operations on :class:`Series` with ``ExtensionDtype`` with NumPy dtyped operand (:issue:`37910`)\n- Fixed regression in metadata propagation for ``groupby`` iterator (:issue:`37343`)\n- Fixed regression in :class:`MultiIndex` constructed from a :class:`DatetimeIndex` not retaining frequency (:issue:`35563`)\n- Fixed regression in :class:`Index` constructor raising a ``AttributeError`` when passed a :class:`SparseArray` with datetime64 values (:issue:`35843`)\n- Fixed regression in :meth:`DataFrame.unstack` with columns with integer dtype (:issue:`37115`)\n- Fixed regression in indexing on a :class:`Series` with ``CategoricalDtype`` after unpickling (:issue:`37631`)\n- Fixed regression in :meth:`DataFrame.groupby` aggregation with out-of-bounds datetime objects in an object-dtype column (:issue:`36003`)\n- Fixed regression in ``df.groupby(..).rolling(..)`` with the resulting :class:`MultiIndex` when grouping by a label that is in the index (:issue:`37641`)\n- Fixed regression in :meth:`DataFrame.fillna` not filling ``NaN`` after other operations such as :meth:`DataFrame.pivot` (:issue:`36495`).\n- Fixed performance regression in ``df.groupby(..).rolling(..)`` (:issue:`38038`)\n- Fixed regression in :meth:`MultiIndex.intersection` returning duplicates when at least one of the indexes had duplicates (:issue:`36915`)\n- Fixed regression in :meth:`.DataFrameGroupBy.first`, :meth:`.SeriesGroupBy.first`, :meth:`.DataFrameGroupBy.last`, and :meth:`.SeriesGroupBy.last` where ``None`` was considered a non-NA value (:issue:`38286`)\n\n.. ---------------------------------------------------------------------------\n\n.. _whatsnew_115.bug_fixes:\n\nBug fixes\n~~~~~~~~~\n- Bug in pytables methods in python 3.9 (:issue:`38041`)\n\n.. ---------------------------------------------------------------------------\n\n.. _whatsnew_115.other:\n\nOther\n~~~~~\n- Only set ``-Werror`` as a compiler flag in the CI jobs (:issue:`33315`, :issue:`33314`)\n\n.. ---------------------------------------------------------------------------\n\n.. _whatsnew_115.contributors:\n\nContributors\n~~~~~~~~~~~~\n\n.. contributors:: v1.1.4..v1.1.5|HEAD\n\n\n\n.. _whatsnew_103:\n\nWhat's new in 1.0.3 (March 17, 2020)\n------------------------------------\n\nThese are the changes in pandas 1.0.3. See :ref:`release` for a full changelog\nincluding other versions of pandas.\n\n{{ header }}\n\n.. ---------------------------------------------------------------------------\n\n.. _whatsnew_103.regressions:\n\nFixed regressions\n~~~~~~~~~~~~~~~~~\n- Fixed regression in ``resample.agg`` when the underlying data is non-writeable (:issue:`31710`)\n- Fixed regression in :class:`DataFrame` exponentiation with reindexing (:issue:`32685`)\n\n.. _whatsnew_103.bug_fixes:\n\nBug fixes\n~~~~~~~~~\n\nContributors\n~~~~~~~~~~~~\n\n.. contributors:: v1.0.2..v1.0.3\n\n\n.. _whatsnew_0231:\n\nWhat's new in 0.23.1 (June 12, 2018)\n------------------------------------\n\n{{ header }}\n\n\nThis is a minor bug-fix release in the 0.23.x series and includes some small regression fixes\nand bug fixes. We recommend that all users upgrade to this version.\n\n.. warning::\n\n   Starting January 1, 2019, pandas feature releases will support Python 3 only.\n   See `Dropping Python 2.7 <https://pandas.pydata.org/pandas-docs/version/0.24/install.html#install-dropping-27>`_ for more.\n\n.. contents:: What's new in v0.23.1\n    :local:\n    :backlinks: none\n\n.. _whatsnew_0231.fixed_regressions:\n\nFixed regressions\n~~~~~~~~~~~~~~~~~\n\n**Comparing Series with datetime.date**\n\nWe've reverted a 0.23.0 change to comparing a :class:`Series` holding datetimes and a ``datetime.date`` object (:issue:`21152`).\nIn pandas 0.22 and earlier, comparing a Series holding datetimes and ``datetime.date`` objects would coerce the ``datetime.date`` to a datetime before comparing.\nThis was inconsistent with Python, NumPy, and :class:`DatetimeIndex`, which never consider a datetime and ``datetime.date`` equal.\n\nIn 0.23.0, we unified operations between DatetimeIndex and Series, and in the process changed comparisons between a Series of datetimes and ``datetime.date`` without warning.\n\nWe've temporarily restored the 0.22.0 behavior, so datetimes and dates may again compare equal, but restore the 0.23.0 behavior in a future release.\n\nTo summarize, here's the behavior in 0.22.0, 0.23.0, 0.23.1:\n\n.. code-block:: python\n\n    0.22.0... Silently coerce the datetime.date\n   >>> import datetime\n   >>> pd.Series(pd.date_range('2017', periods=2)) == datetime.date(2017, 1, 1)\n   0     True\n   1    False\n   dtype: bool\n\n    0.23.0... Do not coerce the datetime.date\n   >>> pd.Series(pd.date_range('2017', periods=2)) == datetime.date(2017, 1, 1)\n   0    False\n   1    False\n   dtype: bool\n\n    0.23.1... Coerce the datetime.date with a warning\n   >>> pd.Series(pd.date_range('2017', periods=2)) == datetime.date(2017, 1, 1)\n   /bin/python:1: FutureWarning: Comparing Series of datetimes with 'datetime.date'.  Currently, the\n   'datetime.date' is coerced to a datetime. In the future pandas will\n   not coerce, and the values not compare equal to the 'datetime.date'.\n   To retain the current behavior, convert the 'datetime.date' to a\n   datetime with 'pd.Timestamp'.\n     !/bin/python3\n   0     True\n   1    False\n   dtype: bool\n\nIn addition, ordering comparisons will raise a ``TypeError`` in the future.\n\n**Other fixes**\n\n- Reverted the ability of :func:`~DataFrame.to_sql` to perform multivalue\n  inserts as this caused regression in certain cases (:issue:`21103`).\n  In the future this will be made configurable.\n- Fixed regression in the :attr:`DatetimeIndex.date` and :attr:`DatetimeIndex.time`\n  attributes in case of timezone-aware data: :attr:`DatetimeIndex.time` returned\n  a tz-aware time instead of tz-naive (:issue:`21267`) and :attr:`DatetimeIndex.date`\n  returned incorrect date when the input date has a non-UTC timezone (:issue:`21230`).\n- Fixed regression in :meth:`pandas.io.json.json_normalize` when called with ``None`` values\n  in nested levels in JSON, and to not drop keys with value as ``None`` (:issue:`21158`, :issue:`21356`).\n- Bug in :meth:`~DataFrame.to_csv` causes encoding error when compression and encoding are specified (:issue:`21241`, :issue:`21118`)\n- Bug preventing pandas from being importable with -OO optimization (:issue:`21071`)\n- Bug in :meth:`Categorical.fillna` incorrectly raising a ``TypeError`` when ``value`` the individual categories are iterable and ``value`` is an iterable (:issue:`21097`, :issue:`19788`)\n- Fixed regression in constructors coercing NA values like ``None`` to strings when passing ``dtype=str`` (:issue:`21083`)\n- Regression in :func:`pivot_table` where an ordered ``Categorical`` with missing\n  values for the pivot's ``index`` would give a mis-aligned result (:issue:`21133`)\n- Fixed regression in merging on boolean index/columns (:issue:`21119`).\n\n.. _whatsnew_0231.performance:\n\nPerformance improvements\n~~~~~~~~~~~~~~~~~~~~~~~~\n\n- Improved performance of :meth:`CategoricalIndex.is_monotonic_increasing`, :meth:`CategoricalIndex.is_monotonic_decreasing` and :meth:`CategoricalIndex.is_monotonic` (:issue:`21025`)\n- Improved performance of :meth:`CategoricalIndex.is_unique` (:issue:`21107`)\n\n\n.. _whatsnew_0231.bug_fixes:\n\nBug fixes\n~~~~~~~~~\n\n**Groupby/resample/rolling**\n\n- Bug in :func:`DataFrame.agg` where applying multiple aggregation functions to a :class:`DataFrame` with duplicated column names would cause a stack overflow (:issue:`21063`)\n- Bug in :func:`.GroupBy.ffill` and :func:`.GroupBy.bfill` where the fill within a grouping would not always be applied as intended due to the implementations' use of a non-stable sort (:issue:`21207`)\n- Bug in :func:`.GroupBy.rank` where results did not scale to 100% when specifying ``method='dense'`` and ``pct=True``\n- Bug in :func:`pandas.DataFrame.rolling` and :func:`pandas.Series.rolling` which incorrectly accepted a 0 window size rather than raising (:issue:`21286`)\n\n**Data-type specific**\n\n- Bug in :meth:`Series.str.replace()` where the method throws ``TypeError`` on Python 3.5.2 (:issue:`21078`)\n- Bug in :class:`Timedelta` where passing a float with a unit would prematurely round the float precision (:issue:`14156`)\n- Bug in :func:`pandas.testing.assert_index_equal` which raised ``AssertionError`` incorrectly, when comparing two :class:`CategoricalIndex` objects with param ``check_categorical=False`` (:issue:`19776`)\n\n**Sparse**\n\n- Bug in :attr:`SparseArray.shape` which previously only returned the shape :attr:`SparseArray.sp_values` (:issue:`21126`)\n\n**Indexing**\n\n- Bug in :meth:`Series.reset_index` where appropriate error was not raised with an invalid level name (:issue:`20925`)\n- Bug in :func:`interval_range` when ``start``/``periods`` or ``end``/``periods`` are specified with float ``start`` or ``end`` (:issue:`21161`)\n- Bug in :meth:`MultiIndex.set_names` where error raised for a ``MultiIndex`` with ``nlevels == 1`` (:issue:`21149`)\n- Bug in :class:`IntervalIndex` constructors where creating an ``IntervalIndex`` from categorical data was not fully supported (:issue:`21243`, :issue:`21253`)\n- Bug in :meth:`MultiIndex.sort_index` which was not guaranteed to sort correctly with ``level=1``; this was also causing data misalignment in particular :meth:`DataFrame.stack` operations (:issue:`20994`, :issue:`20945`, :issue:`21052`)\n\n**Plotting**\n\n- New keywords (sharex, sharey) to turn on/off sharing of x/y-axis by subplots generated with pandas.DataFrame().groupby().boxplot() (:issue:`20968`)\n\n**I/O**\n\n- Bug in IO methods specifying ``compression='zip'`` which produced uncompressed zip archives (:issue:`17778`, :issue:`21144`)\n- Bug in :meth:`DataFrame.to_stata` which prevented exporting DataFrames to buffers and most file-like objects (:issue:`21041`)\n- Bug in :meth:`read_stata` and :class:`StataReader` which did not correctly decode utf-8 strings on Python 3 from Stata 14 files (dta version 118) (:issue:`21244`)\n- Bug in IO JSON :func:`read_json` reading empty JSON schema with ``orient='table'`` back to :class:`DataFrame` caused an error (:issue:`21287`)\n\n**Reshaping**\n\n- Bug in :func:`concat` where error was raised in concatenating :class:`Series` with numpy scalar and tuple names (:issue:`21015`)\n- Bug in :func:`concat` warning message providing the wrong guidance for future behavior (:issue:`21101`)\n\n**Other**\n\n- Tab completion on :class:`Index` in IPython no longer outputs deprecation warnings (:issue:`21125`)\n- Bug preventing pandas being used on Windows without C++ redistributable installed (:issue:`21106`)\n\n.. _whatsnew_0.23.1.contributors:\n\nContributors\n~~~~~~~~~~~~\n\n.. contributors:: v0.23.0..v0.23.1\n\n\n.. _whatsnew_140:\n\nWhat's new in 1.4.0 (January 22, 2022)\n--------------------------------------\n\nThese are the changes in pandas 1.4.0. See :ref:`release` for a full changelog\nincluding other versions of pandas.\n\n{{ header }}\n\n.. ---------------------------------------------------------------------------\n\n.. _whatsnew_140.enhancements:\n\nEnhancements\n~~~~~~~~~~~~\n\n.. _whatsnew_140.enhancements.warning_lineno:\n\nImproved warning messages\n^^^^^^^^^^^^^^^^^^^^^^^^^\n\nPreviously, warning messages may have pointed to lines within the pandas\nlibrary. Running the script ``setting_with_copy_warning.py``\n\n.. code-block:: python\n\n    import pandas as pd\n\n    df = pd.DataFrame({'a': [1, 2, 3]})\n    df[:2].loc[:, 'a'] = 5\n\nwith pandas 1.3 resulted in::\n\n    .../site-packages/pandas/core/indexing.py:1951: SettingWithCopyWarning:\n    A value is trying to be set on a copy of a slice from a DataFrame.\n\nThis made it difficult to determine where the warning was being generated from.\nNow pandas will inspect the call stack, reporting the first line outside of the\npandas library that gave rise to the warning. The output of the above script is\nnow::\n\n    setting_with_copy_warning.py:4: SettingWithCopyWarning:\n    A value is trying to be set on a copy of a slice from a DataFrame.\n\n\n\n\n.. _whatsnew_140.enhancements.ExtensionIndex:\n\nIndex can hold arbitrary ExtensionArrays\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nUntil now, passing a custom :class:`ExtensionArray` to ``pd.Index`` would cast\nthe array to ``object`` dtype. Now :class:`Index` can directly hold arbitrary\nExtensionArrays (:issue:`43930`).\n\n*Previous behavior*:\n\n.. ipython:: python\n\n   arr = pd.array([1, 2, pd.NA])\n   idx = pd.Index(arr)\n\nIn the old behavior, ``idx`` would be object-dtype:\n\n*Previous behavior*:\n\n.. code-block:: ipython\n\n   In [1]: idx\n   Out[1]: Index([1, 2, <NA>], dtype='object')\n\nWith the new behavior, we keep the original dtype:\n\n*New behavior*:\n\n.. ipython:: python\n\n   idx\n\nOne exception to this is ``SparseArray``, which will continue to cast to numpy\ndtype until pandas 2.0. At that point it will retain its dtype like other\nExtensionArrays.\n\n.. _whatsnew_140.enhancements.styler:\n\nStyler\n^^^^^^\n\n:class:`.Styler` has been further developed in 1.4.0. The following general enhancements have been made:\n\n  - Styling and formatting of indexes has been added, with :meth:`.Styler.apply_index`, :meth:`.Styler.applymap_index` and :meth:`.Styler.format_index`. These mirror the signature of the methods already used to style and format data values, and work with both HTML, LaTeX and Excel format (:issue:`41893`, :issue:`43101`, :issue:`41993`, :issue:`41995`)\n  - The new method :meth:`.Styler.hide` deprecates :meth:`.Styler.hide_index` and :meth:`.Styler.hide_columns` (:issue:`43758`)\n  - The keyword arguments ``level`` and ``names`` have been added to :meth:`.Styler.hide` (and implicitly to the deprecated methods :meth:`.Styler.hide_index` and :meth:`.Styler.hide_columns`) for additional control of visibility of MultiIndexes and of Index names (:issue:`25475`, :issue:`43404`, :issue:`43346`)\n", "1.3.0": "  - Global options under the category ``pd.options.styler`` have been extended to configure default ``Styler`` properties which address formatting, encoding, and HTML and LaTeX rendering. Note that formerly ``Styler`` relied on ``display.html.use_mathjax``, which has now been replaced by ``styler.html.mathjax`` (:issue:`41395`)\n  - Validation of certain keyword arguments, e.g. ``caption`` (:issue:`43368`)\n  - Various bug fixes as recorded below\n\nAdditionally there are specific enhancements to the HTML specific rendering:\n\n  - :meth:`.Styler.bar` introduces additional arguments to control alignment and display (:issue:`26070`, :issue:`36419`), and it also validates the input arguments ``width`` and ``height`` (:issue:`42511`)\n  - :meth:`.Styler.to_html` introduces keyword arguments ``sparse_index``, ``sparse_columns``, ``bold_headers``, ``caption``, ``max_rows`` and ``max_columns`` (:issue:`41946`, :issue:`43149`, :issue:`42972`)\n  - :meth:`.Styler.to_html` omits CSSStyle rules for hidden table elements as a performance enhancement (:issue:`43619`)\n  - Custom CSS classes can now be directly specified without string replacement (:issue:`43686`)\n  - Ability to render hyperlinks automatically via a new ``hyperlinks`` formatting keyword argument (:issue:`45058`)\n\nThere are also some LaTeX specific enhancements:\n\n  - :meth:`.Styler.to_latex` introduces keyword argument ``environment``, which also allows a specific \"longtable\" entry through a separate jinja2 template (:issue:`41866`)\n  - Naive sparsification is now possible for LaTeX without the necessity of including the multirow package (:issue:`43369`)\n  - *cline* support has been added for :class:`MultiIndex` row sparsification through a keyword argument (:issue:`45138`)\n\n.. _whatsnew_140.enhancements.pyarrow_csv_engine:\n\nMulti-threaded CSV reading with a new CSV Engine based on pyarrow\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n:func:`pandas.read_csv` now accepts ``engine=\"pyarrow\"`` (requires at least\n``pyarrow`` 1.0.1) as an argument, allowing for faster csv parsing on multicore\nmachines with pyarrow installed. See the :doc:`I/O docs </user_guide/io>` for\nmore info. (:issue:`23697`, :issue:`43706`)\n\n.. _whatsnew_140.enhancements.window_rank:\n\nRank function for rolling and expanding windows\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nAdded ``rank`` function to :class:`Rolling` and :class:`Expanding`. The new\nfunction supports the ``method``, ``ascending``, and ``pct`` flags of\n:meth:`DataFrame.rank`. The ``method`` argument supports ``min``, ``max``, and\n``average`` ranking methods.\nExample:\n\n.. ipython:: python\n\n    s = pd.Series([1, 4, 2, 3, 5, 3])\n    s.rolling(3).rank()\n\n    s.rolling(3).rank(method=\"max\")\n\n.. _whatsnew_140.enhancements.groupby_indexing:\n\nGroupby positional indexing\n^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nIt is now possible to specify positional ranges relative to the ends of each\ngroup.\n\nNegative arguments for :meth:`.DataFrameGroupBy.head`, :meth:`.SeriesGroupBy.head`, :meth:`.DataFrameGroupBy.tail`, and :meth:`.SeriesGroupBy.tail` now work\ncorrectly and result in ranges relative to the end and start of each group,\nrespectively. Previously, negative arguments returned empty frames.\n\n.. ipython:: python\n\n    df = pd.DataFrame([[\"g\", \"g0\"], [\"g\", \"g1\"], [\"g\", \"g2\"], [\"g\", \"g3\"],\n                       [\"h\", \"h0\"], [\"h\", \"h1\"]], columns=[\"A\", \"B\"])\n    df.groupby(\"A\").head(-1)\n\n\n:meth:`.DataFrameGroupBy.nth` and :meth:`.SeriesGroupBy.nth` now accept a slice or list of integers and slices.\n\n.. ipython:: python\n\n    df.groupby(\"A\").nth(slice(1, -1))\n    df.groupby(\"A\").nth([slice(None, 1), slice(-1, None)])\n\n:meth:`.DataFrameGroupBy.nth` and :meth:`.SeriesGroupBy.nth` now accept index notation.\n\n.. ipython:: python\n\n    df.groupby(\"A\").nth[1, -1]\n    df.groupby(\"A\").nth[1:-1]\n    df.groupby(\"A\").nth[:1, -1:]\n\n.. _whatsnew_140.dict_tight:\n\nDataFrame.from_dict and DataFrame.to_dict have new ``'tight'`` option\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nA new ``'tight'`` dictionary format that preserves :class:`MultiIndex` entries\nand names is now available with the :meth:`DataFrame.from_dict` and\n:meth:`DataFrame.to_dict` methods and can be used with the standard ``json``\nlibrary to produce a tight representation of :class:`DataFrame` objects\n(:issue:`4889`).\n\n.. ipython:: python\n\n    df = pd.DataFrame.from_records(\n        [[1, 3], [2, 4]],\n        index=pd.MultiIndex.from_tuples([(\"a\", \"b\"), (\"a\", \"c\")],\n                                        names=[\"n1\", \"n2\"]),\n        columns=pd.MultiIndex.from_tuples([(\"x\", 1), (\"y\", 2)],\n                                          names=[\"z1\", \"z2\"]),\n    )\n    df\n    df.to_dict(orient='tight')\n\n.. _whatsnew_140.enhancements.other:\n\nOther enhancements\n^^^^^^^^^^^^^^^^^^\n- :meth:`concat` will preserve the ``attrs`` when it is the same for all objects and discard the ``attrs`` when they are different (:issue:`41828`)\n- :class:`DataFrameGroupBy` operations with ``as_index=False`` now correctly retain ``ExtensionDtype`` dtypes for columns being grouped on (:issue:`41373`)\n- Add support for assigning values to ``by`` argument in :meth:`DataFrame.plot.hist` and :meth:`DataFrame.plot.box` (:issue:`15079`)\n- :meth:`Series.sample`, :meth:`DataFrame.sample`, :meth:`.DataFrameGroupBy.sample`, and :meth:`.SeriesGroupBy.sample` now accept a ``np.random.Generator`` as input to ``random_state``. A generator will be more performant, especially with ``replace=False`` (:issue:`38100`)\n- :meth:`Series.ewm` and :meth:`DataFrame.ewm` now support a ``method`` argument with a ``'table'`` option that performs the windowing operation over an entire :class:`DataFrame`. See :ref:`Window Overview <window.overview>` for performance and functional benefits (:issue:`42273`)\n- :meth:`.DataFrameGroupBy.cummin`, :meth:`.SeriesGroupBy.cummin`, :meth:`.DataFrameGroupBy.cummax`, and :meth:`.SeriesGroupBy.cummax` now support the argument ``skipna`` (:issue:`34047`)\n- :meth:`read_table` now supports the argument ``storage_options`` (:issue:`39167`)\n- :meth:`DataFrame.to_stata` and :meth:`StataWriter` now accept the keyword only argument ``value_labels`` to save labels for non-categorical columns (:issue:`38454`)\n- Methods that relied on hashmap based algos such as :meth:`DataFrameGroupBy.value_counts`, :meth:`DataFrameGroupBy.count` and :func:`factorize` ignored imaginary component for complex numbers (:issue:`17927`)\n- Add :meth:`Series.str.removeprefix` and :meth:`Series.str.removesuffix` introduced in Python 3.9 to remove pre-/suffixes from string-type :class:`Series` (:issue:`36944`)\n- Attempting to write into a file in missing parent directory with :meth:`DataFrame.to_csv`, :meth:`DataFrame.to_html`, :meth:`DataFrame.to_excel`, :meth:`DataFrame.to_feather`, :meth:`DataFrame.to_parquet`, :meth:`DataFrame.to_stata`, :meth:`DataFrame.to_json`, :meth:`DataFrame.to_pickle`, and :meth:`DataFrame.to_xml` now explicitly mentions missing parent directory, the same is true for :class:`Series` counterparts (:issue:`24306`)\n- Indexing with ``.loc`` and ``.iloc`` now supports ``Ellipsis`` (:issue:`37750`)\n- :meth:`IntegerArray.all` , :meth:`IntegerArray.any`, :meth:`FloatingArray.any`, and :meth:`FloatingArray.all` use Kleene logic (:issue:`41967`)\n- Added support for nullable boolean and integer types in :meth:`DataFrame.to_stata`, :class:`~pandas.io.stata.StataWriter`, :class:`~pandas.io.stata.StataWriter117`, and :class:`~pandas.io.stata.StataWriterUTF8` (:issue:`40855`)\n- :meth:`DataFrame.__pos__` and :meth:`DataFrame.__neg__` now retain ``ExtensionDtype`` dtypes (:issue:`43883`)\n- The error raised when an optional dependency can't be imported now includes the original exception, for easier investigation (:issue:`43882`)\n- Added :meth:`.ExponentialMovingWindow.sum` (:issue:`13297`)\n- :meth:`Series.str.split` now supports a ``regex`` argument that explicitly specifies whether the pattern is a regular expression. Default is ``None`` (:issue:`43563`, :issue:`32835`, :issue:`25549`)\n- :meth:`DataFrame.dropna` now accepts a single label as ``subset`` along with array-like (:issue:`41021`)\n- Added :meth:`DataFrameGroupBy.value_counts` (:issue:`43564`)\n- :func:`read_csv` now accepts a ``callable`` function in ``on_bad_lines`` when ``engine=\"python\"`` for custom handling of bad lines (:issue:`5686`)\n- :class:`ExcelWriter` argument ``if_sheet_exists=\"overlay\"`` option added (:issue:`40231`)\n- :meth:`read_excel` now accepts a ``decimal`` argument that allow the user to specify the decimal point when parsing string columns to numeric (:issue:`14403`)\n- :meth:`.DataFrameGroupBy.mean`, :meth:`.SeriesGroupBy.mean`, :meth:`.DataFrameGroupBy.std`, :meth:`.SeriesGroupBy.std`, :meth:`.DataFrameGroupBy.var`, :meth:`.SeriesGroupBy.var`, :meth:`.DataFrameGroupBy.sum`, and :meth:`.SeriesGroupBy.sum` now support `Numba <http://numba.pydata.org/>`_ execution with the ``engine`` keyword (:issue:`43731`, :issue:`44862`, :issue:`44939`)\n- :meth:`Timestamp.isoformat` now handles the ``timespec`` argument from the base ``datetime`` class (:issue:`26131`)\n- :meth:`NaT.to_numpy` ``dtype`` argument is now respected, so ``np.timedelta64`` can be returned (:issue:`44460`)\n- New option ``display.max_dir_items`` customizes the number of columns added to :meth:`Dataframe.__dir__` and suggested for tab completion (:issue:`37996`)\n- Added \"Juneteenth National Independence Day\" to ``USFederalHolidayCalendar`` (:issue:`44574`)\n- :meth:`.Rolling.var`, :meth:`.Expanding.var`, :meth:`.Rolling.std`, and :meth:`.Expanding.std` now support `Numba <http://numba.pydata.org/>`_ execution with the ``engine`` keyword (:issue:`44461`)\n- :meth:`Series.info` has been added, for compatibility with :meth:`DataFrame.info` (:issue:`5167`)\n- Implemented :meth:`IntervalArray.min` and :meth:`IntervalArray.max`, as a result of which ``min`` and ``max`` now work for :class:`IntervalIndex`, :class:`Series` and :class:`DataFrame` with ``IntervalDtype`` (:issue:`44746`)\n- :meth:`UInt64Index.map` now retains ``dtype`` where possible (:issue:`44609`)\n- :meth:`read_json` can now parse unsigned long long integers (:issue:`26068`)\n- :meth:`DataFrame.take` now raises a ``TypeError`` when passed a scalar for the indexer (:issue:`42875`)\n- :meth:`is_list_like` now identifies duck-arrays as list-like unless ``.ndim == 0`` (:issue:`35131`)\n- :class:`ExtensionDtype` and :class:`ExtensionArray` are now (de)serialized when exporting a :class:`DataFrame` with :meth:`DataFrame.to_json` using ``orient='table'`` (:issue:`20612`, :issue:`44705`)\n- Add support for `Zstandard <http://facebook.github.io/zstd/>`_ compression to :meth:`DataFrame.to_pickle`/:meth:`read_pickle` and friends (:issue:`43925`)\n- :meth:`DataFrame.to_sql` now returns an ``int`` of the number of written rows (:issue:`23998`)\n\n.. ---------------------------------------------------------------------------\n\n.. _whatsnew_140.notable_bug_fixes:\n\nNotable bug fixes\n~~~~~~~~~~~~~~~~~\n\nThese are bug fixes that might have notable behavior changes.\n\n.. _whatsnew_140.notable_bug_fixes.inconsistent_date_string_parsing:\n\nInconsistent date string parsing\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nThe ``dayfirst`` option of :func:`to_datetime` isn't strict, and this can lead\nto surprising behavior:\n\n.. ipython:: python\n    :okwarning:\n\n    pd.to_datetime([\"31-12-2021\"], dayfirst=False)\n\nNow, a warning will be raised if a date string cannot be parsed accordance to\nthe given ``dayfirst`` value when the value is a delimited date string (e.g.\n``31-12-2012``).\n\n.. _whatsnew_140.notable_bug_fixes.concat_with_empty_or_all_na:\n\nIgnoring dtypes in concat with empty or all-NA columns\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n.. note::\n    This behaviour change has been reverted in pandas 1.4.3.\n\nWhen using :func:`concat` to concatenate two or more :class:`DataFrame` objects,\nif one of the DataFrames was empty or had all-NA values, its dtype was\n*sometimes* ignored when finding the concatenated dtype.  These are now\nconsistently *not* ignored (:issue:`43507`).\n\n.. code-block:: ipython\n\n    In [3]: df1 = pd.DataFrame({\"bar\": [pd.Timestamp(\"2013-01-01\")]}, index=range(1))\n    In [4]: df2 = pd.DataFrame({\"bar\": np.nan}, index=range(1, 2))\n    In [5]: res = pd.concat([df1, df2])\n\nPreviously, the float-dtype in ``df2`` would be ignored so the result dtype\nwould be ``datetime64[ns]``. As a result, the ``np.nan`` would be cast to\n``NaT``.\n\n*Previous behavior*:\n\n.. code-block:: ipython\n\n    In [6]: res\n    Out[6]:\n             bar\n    0 2013-01-01\n    1        NaT\n\nNow the float-dtype is respected. Since the common dtype for these DataFrames is\nobject, the ``np.nan`` is retained.\n\n*New behavior*:\n\n.. code-block:: ipython\n\n    In [6]: res\n    Out[6]:\n                       bar\n    0  2013-01-01 00:00:00\n    1                  NaN\n\n\n\n.. _whatsnew_140.notable_bug_fixes.value_counts_and_mode_do_not_coerce_to_nan:\n\nNull-values are no longer coerced to NaN-value in value_counts and mode\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n:meth:`Series.value_counts` and :meth:`Series.mode` no longer coerce ``None``,\n``NaT`` and other null-values to a NaN-value for ``np.object_``-dtype. This\nbehavior is now consistent with ``unique``, ``isin`` and others\n(:issue:`42688`).\n\n.. ipython:: python\n\n    s = pd.Series([True, None, pd.NaT, None, pd.NaT, None])\n    res = s.value_counts(dropna=False)\n\nPreviously, all null-values were replaced by a NaN-value.\n\n*Previous behavior*:\n\n.. code-block:: ipython\n\n    In [3]: res\n    Out[3]:\n    NaN     5\n    True    1\n    dtype: int64\n\nNow null-values are no longer mangled.\n\n*New behavior*:\n\n.. ipython:: python\n\n    res\n\n.. _whatsnew_140.notable_bug_fixes.read_csv_mangle_dup_cols:\n\nmangle_dupe_cols in read_csv no longer renames unique columns conflicting with target names\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n:func:`read_csv` no longer renames unique column labels which conflict with the target\nnames of duplicated columns. Already existing columns are skipped, i.e. the next\navailable index is used for the target column name (:issue:`14704`).\n\n.. ipython:: python\n\n    import io\n\n    data = \"a,a,a.1\\n1,2,3\"\n    res = pd.read_csv(io.StringIO(data))\n\nPreviously, the second column was called ``a.1``, while the third column was\nalso renamed to ``a.1.1``.\n\n*Previous behavior*:\n\n.. code-block:: ipython\n\n    In [3]: res\n    Out[3]:\n        a  a.1  a.1.1\n    0   1    2      3\n\nNow the renaming checks if ``a.1`` already exists when changing the name of the\nsecond column and jumps this index. The second column is instead renamed to\n``a.2``.\n\n*New behavior*:\n\n.. ipython:: python\n\n    res\n\n.. _whatsnew_140.notable_bug_fixes.unstack_pivot_int32_limit:\n\nunstack and pivot_table no longer raises ValueError for result that would exceed int32 limit\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nPreviously :meth:`DataFrame.pivot_table` and :meth:`DataFrame.unstack` would\nraise a ``ValueError`` if the operation could produce a result with more than\n``2**31 - 1`` elements. This operation now raises a\n:class:`errors.PerformanceWarning` instead (:issue:`26314`).\n\n*Previous behavior*:\n\n.. code-block:: ipython\n\n    In [3]: df = DataFrame({\"ind1\": np.arange(2 ** 16), \"ind2\": np.arange(2 ** 16), \"count\": 0})\n    In [4]: df.pivot_table(index=\"ind1\", columns=\"ind2\", values=\"count\", aggfunc=\"count\")\n    ValueError: Unstacked DataFrame is too big, causing int32 overflow\n\n*New behavior*:\n\n.. code-block:: python\n\n    In [4]: df.pivot_table(index=\"ind1\", columns=\"ind2\", values=\"count\", aggfunc=\"count\")\n    PerformanceWarning: The following operation may generate 4294967296 cells in the resulting pandas object.\n\n.. ---------------------------------------------------------------------------\n\n.. _whatsnew_140.notable_bug_fixes.groupby_apply_mutation:\n\ngroupby.apply consistent transform detection\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n:meth:`.DataFrameGroupBy.apply` and :meth:`.SeriesGroupBy.apply` are designed to be flexible, allowing users to perform\naggregations, transformations, filters, and use it with user-defined functions\nthat might not fall into any of these categories. As part of this, apply will\nattempt to detect when an operation is a transform, and in such a case, the\nresult will have the same index as the input. In order to determine if the\noperation is a transform, pandas compares the input's index to the result's and\ndetermines if it has been mutated. Previously in pandas 1.3, different code\npaths used different definitions of \"mutated\": some would use Python's ``is``\nwhereas others would test only up to equality.\n\nThis inconsistency has been removed, pandas now tests up to equality.\n\n.. ipython:: python\n\n    def func(x):\n        return x.copy()\n\n    df = pd.DataFrame({'a': [1, 2], 'b': [3, 4], 'c': [5, 6]})\n    df\n\n*Previous behavior*:\n\n.. code-block:: ipython\n\n    In [3]: df.groupby(['a']).apply(func)\n    Out[3]:\n         a  b  c\n    a\n    1 0  1  3  5\n    2 1  2  4  6\n\n    In [4]: df.set_index(['a', 'b']).groupby(['a']).apply(func)\n    Out[4]:\n         c\n    a b\n    1 3  5\n    2 4  6\n\nIn the examples above, the first uses a code path where pandas uses ``is`` and\ndetermines that ``func`` is not a transform whereas the second tests up to\nequality and determines that ``func`` is a transform. In the first case, the\nresult's index is not the same as the input's.\n\n*New behavior*:\n\n.. code-block:: ipython\n\n    In [5]: df.groupby(['a']).apply(func)\n    Out[5]:\n       a  b  c\n    0  1  3  5\n    1  2  4  6\n\n    In [6]: df.set_index(['a', 'b']).groupby(['a']).apply(func)\n    Out[6]:\n         c\n    a b\n    1 3  5\n    2 4  6\n\nNow in both cases it is determined that ``func`` is a transform. In each case,\nthe result has the same index as the input.\n\n.. _whatsnew_140.api_breaking:\n\nBackwards incompatible API changes\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\n.. _whatsnew_140.api_breaking.python:\n\nIncreased minimum version for Python\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\npandas 1.4.0 supports Python 3.8 and higher.\n\n.. _whatsnew_140.api_breaking.deps:\n\nIncreased minimum versions for dependencies\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nSome minimum supported versions of dependencies were updated.\nIf installed, we now require:\n\n+-----------------+-----------------+----------+---------+\n| Package         | Minimum Version | Required | Changed |\n+=================+=================+==========+=========+\n| numpy           | 1.18.5          |    X     |    X    |\n+-----------------+-----------------+----------+---------+\n| pytz            | 2020.1          |    X     |    X    |\n+-----------------+-----------------+----------+---------+\n| python-dateutil | 2.8.1           |    X     |    X    |\n+-----------------+-----------------+----------+---------+\n| bottleneck      | 1.3.1           |          |    X    |\n+-----------------+-----------------+----------+---------+\n| numexpr         | 2.7.1           |          |    X    |\n+-----------------+-----------------+----------+---------+\n| pytest (dev)    | 6.0             |          |         |\n+-----------------+-----------------+----------+---------+\n| mypy (dev)      | 0.930           |          |    X    |\n+-----------------+-----------------+----------+---------+\n\nFor `optional libraries\n<https://pandas.pydata.org/docs/getting_started/install.html>`_ the general\nrecommendation is to use the latest version. The following table lists the\nlowest version per library that is currently being tested throughout the\ndevelopment of pandas. Optional libraries below the lowest tested version may\nstill work, but are not considered supported.\n\n+-----------------+-----------------+---------+\n| Package         | Minimum Version | Changed |\n+=================+=================+=========+\n| beautifulsoup4  | 4.8.2           |    X    |\n+-----------------+-----------------+---------+\n| fastparquet     | 0.4.0           |         |\n+-----------------+-----------------+---------+\n| fsspec          | 0.7.4           |         |\n+-----------------+-----------------+---------+\n| gcsfs           | 0.6.0           |         |\n+-----------------+-----------------+---------+\n| lxml            | 4.5.0           |    X    |\n+-----------------+-----------------+---------+\n| matplotlib      | 3.3.2           |    X    |\n+-----------------+-----------------+---------+\n| numba           | 0.50.1          |    X    |\n+-----------------+-----------------+---------+\n| openpyxl        | 3.0.3           |    X    |\n+-----------------+-----------------+---------+\n| pandas-gbq      | 0.14.0          |    X    |\n+-----------------+-----------------+---------+\n| pyarrow         | 1.0.1           |    X    |\n+-----------------+-----------------+---------+\n| pymysql         | 0.10.1          |    X    |\n+-----------------+-----------------+---------+\n| pytables        | 3.6.1           |    X    |\n+-----------------+-----------------+---------+\n| s3fs            | 0.4.0           |         |\n+-----------------+-----------------+---------+\n| scipy           | 1.4.1           |    X    |\n+-----------------+-----------------+---------+\n| sqlalchemy      | 1.4.0           |    X    |\n+-----------------+-----------------+---------+\n| tabulate        | 0.8.7           |         |\n+-----------------+-----------------+---------+\n| xarray          | 0.15.1          |    X    |\n+-----------------+-----------------+---------+\n| xlrd            | 2.0.1           |    X    |\n+-----------------+-----------------+---------+\n| xlsxwriter      | 1.2.2           |    X    |\n+-----------------+-----------------+---------+\n| xlwt            | 1.3.0           |         |\n+-----------------+-----------------+---------+\n\nSee :ref:`install.dependencies` and :ref:`install.optional_dependencies` for more.\n\n.. _whatsnew_140.api_breaking.other:\n\nOther API changes\n^^^^^^^^^^^^^^^^^\n- :meth:`Index.get_indexer_for` no longer accepts keyword arguments (other than ``target``); in the past these would be silently ignored if the index was not unique (:issue:`42310`)\n- Change in the position of the ``min_rows`` argument in :meth:`DataFrame.to_string` due to change in the docstring (:issue:`44304`)\n- Reduction operations for :class:`DataFrame` or :class:`Series` now raising a ``ValueError`` when ``None`` is passed for ``skipna`` (:issue:`44178`)\n- :func:`read_csv` and :func:`read_html` no longer raising an error when one of the header rows consists only of ``Unnamed:`` columns (:issue:`13054`)\n- Changed the ``name`` attribute of several holidays in\n  ``USFederalHolidayCalendar`` to match `official federal holiday\n  names <https://www.opm.gov/policy-data-oversight/pay-leave/federal-holidays/>`_\n  specifically:\n\n   - \"New Year's Day\" gains the possessive apostrophe\n   - \"Presidents Day\" becomes \"Washington's Birthday\"\n   - \"Martin Luther King Jr. Day\" is now \"Birthday of Martin Luther King, Jr.\"\n   - \"July 4th\" is now \"Independence Day\"\n   - \"Thanksgiving\" is now \"Thanksgiving Day\"\n   - \"Christmas\" is now \"Christmas Day\"\n   - Added \"Juneteenth National Independence Day\"\n\n.. ---------------------------------------------------------------------------\n\n.. _whatsnew_140.deprecations:\n\nDeprecations\n~~~~~~~~~~~~\n\n.. _whatsnew_140.deprecations.int64_uint64_float64index:\n\nDeprecated Int64Index, UInt64Index & Float64Index\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n:class:`Int64Index`, :class:`UInt64Index` and :class:`Float64Index` have been\ndeprecated in favor of the base :class:`Index` class and will be removed in\nPandas 2.0 (:issue:`43028`).\n\nFor constructing a numeric index, you can use the base :class:`Index` class\ninstead specifying the data type (which will also work on older pandas\nreleases):\n\n.. code-block:: python\n\n     replace\n    pd.Int64Index([1, 2, 3])\n     with\n    pd.Index([1, 2, 3], dtype=\"int64\")\n\nFor checking the data type of an index object, you can replace ``isinstance``\nchecks with checking the ``dtype``:\n\n.. code-block:: python\n\n     replace\n    isinstance(idx, pd.Int64Index)\n     with\n    idx.dtype == \"int64\"\n\nCurrently, in order to maintain backward compatibility, calls to :class:`Index`\nwill continue to return :class:`Int64Index`, :class:`UInt64Index` and\n:class:`Float64Index` when given numeric data, but in the future, an\n:class:`Index` will be returned.\n\n*Current behavior*:\n\n.. code-block:: ipython\n\n    In [1]: pd.Index([1, 2, 3], dtype=\"int32\")\n    Out [1]: Int64Index([1, 2, 3], dtype='int64')\n    In [1]: pd.Index([1, 2, 3], dtype=\"uint64\")\n    Out [1]: UInt64Index([1, 2, 3], dtype='uint64')\n\n*Future behavior*:\n\n.. code-block:: ipython\n\n    In [3]: pd.Index([1, 2, 3], dtype=\"int32\")\n    Out [3]: Index([1, 2, 3], dtype='int32')\n    In [4]: pd.Index([1, 2, 3], dtype=\"uint64\")\n    Out [4]: Index([1, 2, 3], dtype='uint64')\n\n\n.. _whatsnew_140.deprecations.frame_series_append:\n\nDeprecated DataFrame.append and Series.append\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n:meth:`DataFrame.append` and :meth:`Series.append` have been deprecated and will\nbe removed in a future version. Use :func:`pandas.concat` instead (:issue:`35407`).\n\n*Deprecated syntax*\n\n.. code-block:: ipython\n\n    In [1]: pd.Series([1, 2]).append(pd.Series([3, 4])\n    Out [1]:\n    <stdin>:1: FutureWarning: The series.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n    0    1\n    1    2\n    0    3\n    1    4\n    dtype: int64\n\n    In [2]: df1 = pd.DataFrame([[1, 2], [3, 4]], columns=list('AB'))\n    In [3]: df2 = pd.DataFrame([[5, 6], [7, 8]], columns=list('AB'))\n    In [4]: df1.append(df2)\n    Out [4]:\n    <stdin>:1: FutureWarning: The series.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n       A  B\n    0  1  2\n    1  3  4\n    0  5  6\n    1  7  8\n\n*Recommended syntax*\n\n.. ipython:: python\n\n    pd.concat([pd.Series([1, 2]), pd.Series([3, 4])])\n\n    df1 = pd.DataFrame([[1, 2], [3, 4]], columns=list('AB'))\n    df2 = pd.DataFrame([[5, 6], [7, 8]], columns=list('AB'))\n    pd.concat([df1, df2])\n\n\n.. _whatsnew_140.deprecations.other:\n\nOther Deprecations\n^^^^^^^^^^^^^^^^^^\n- Deprecated :meth:`Index.is_type_compatible` (:issue:`42113`)\n- Deprecated ``method`` argument in :meth:`Index.get_loc`, use ``index.get_indexer([label], method=...)`` instead (:issue:`42269`)\n- Deprecated treating integer keys in :meth:`Series.__setitem__` as positional when the index is a :class:`Float64Index` not containing the key, a :class:`IntervalIndex` with no entries containing the key, or a :class:`MultiIndex` with leading :class:`Float64Index` level not containing the key (:issue:`33469`)\n- Deprecated treating ``numpy.datetime64`` objects as UTC times when passed to the :class:`Timestamp` constructor along with a timezone. In a future version, these will be treated as wall-times. To retain the old behavior, use ``Timestamp(dt64).tz_localize(\"UTC\").tz_convert(tz)`` (:issue:`24559`)\n- Deprecated ignoring missing labels when indexing with a sequence of labels on a level of a :class:`MultiIndex` (:issue:`42351`)\n- Creating an empty :class:`Series` without a ``dtype`` will now raise a more visible ``FutureWarning`` instead of a ``DeprecationWarning`` (:issue:`30017`)\n- Deprecated the ``kind`` argument in :meth:`Index.get_slice_bound`, :meth:`Index.slice_indexer`, and :meth:`Index.slice_locs`; in a future version passing ``kind`` will raise (:issue:`42857`)\n- Deprecated dropping of nuisance columns in :class:`Rolling`, :class:`Expanding`, and :class:`EWM` aggregations (:issue:`42738`)\n- Deprecated :meth:`Index.reindex` with a non-unique :class:`Index` (:issue:`42568`)\n- Deprecated :meth:`.Styler.render` in favor of :meth:`.Styler.to_html` (:issue:`42140`)\n- Deprecated :meth:`.Styler.hide_index` and :meth:`.Styler.hide_columns` in favor of :meth:`.Styler.hide` (:issue:`43758`)\n- Deprecated passing in a string column label into ``times`` in :meth:`DataFrame.ewm` (:issue:`43265`)\n- Deprecated the ``include_start`` and ``include_end`` arguments in :meth:`DataFrame.between_time`; in a future version passing ``include_start`` or ``include_end`` will raise (:issue:`40245`)\n- Deprecated the ``squeeze`` argument to :meth:`read_csv`, :meth:`read_table`, and :meth:`read_excel`. Users should squeeze the :class:`DataFrame` afterwards with ``.squeeze(\"columns\")`` instead (:issue:`43242`)\n- Deprecated the ``index`` argument to :class:`SparseArray` construction (:issue:`23089`)\n- Deprecated the ``closed`` argument in :meth:`date_range` and :meth:`bdate_range` in favor of ``inclusive`` argument; In a future version passing ``closed`` will raise (:issue:`40245`)\n- Deprecated :meth:`.Rolling.validate`, :meth:`.Expanding.validate`, and :meth:`.ExponentialMovingWindow.validate` (:issue:`43665`)\n- Deprecated silent dropping of columns that raised a ``TypeError`` in :class:`Series.transform` and :class:`DataFrame.transform` when used with a dictionary (:issue:`43740`)\n- Deprecated silent dropping of columns that raised a ``TypeError``, ``DataError``, and some cases of ``ValueError`` in :meth:`Series.aggregate`, :meth:`DataFrame.aggregate`, :meth:`Series.groupby.aggregate`, and :meth:`DataFrame.groupby.aggregate` when used with a list (:issue:`43740`)\n- Deprecated casting behavior when setting timezone-aware value(s) into a timezone-aware :class:`Series` or :class:`DataFrame` column when the timezones do not match. Previously this cast to object dtype. In a future version, the values being inserted will be converted to the series or column's existing timezone (:issue:`37605`)\n- Deprecated casting behavior when passing an item with mismatched-timezone to :meth:`DatetimeIndex.insert`, :meth:`DatetimeIndex.putmask`, :meth:`DatetimeIndex.where` :meth:`DatetimeIndex.fillna`, :meth:`Series.mask`, :meth:`Series.where`, :meth:`Series.fillna`, :meth:`Series.shift`, :meth:`Series.replace`, :meth:`Series.reindex` (and :class:`DataFrame` column analogues). In the past this has cast to object ``dtype``. In a future version, these will cast the passed item to the index or series's timezone (:issue:`37605`, :issue:`44940`)\n- Deprecated the ``prefix`` keyword argument in :func:`read_csv` and :func:`read_table`, in a future version the argument will be removed (:issue:`43396`)\n- Deprecated passing non boolean argument to ``sort`` in :func:`concat` (:issue:`41518`)\n- Deprecated passing arguments as positional for :func:`read_fwf` other than ``filepath_or_buffer`` (:issue:`41485`)\n- Deprecated passing arguments as positional for :func:`read_xml` other than ``path_or_buffer`` (:issue:`45133`)\n- Deprecated passing ``skipna=None`` for :meth:`DataFrame.mad` and :meth:`Series.mad`, pass ``skipna=True`` instead (:issue:`44580`)\n- Deprecated the behavior of :func:`to_datetime` with the string \"now\" with ``utc=False``; in a future version this will match ``Timestamp(\"now\")``, which in turn matches :meth:`Timestamp.now` returning the local time (:issue:`18705`)\n- Deprecated :meth:`DateOffset.apply`, use ``offset + other`` instead (:issue:`44522`)\n- Deprecated parameter ``names`` in :meth:`Index.copy` (:issue:`44916`)\n- A deprecation warning is now shown for :meth:`DataFrame.to_latex` indicating the arguments signature may change and emulate more the arguments to :meth:`.Styler.to_latex` in future versions (:issue:`44411`)\n- Deprecated behavior of :func:`concat` between objects with bool-dtype and numeric-dtypes; in a future version these will cast to object dtype instead of coercing bools to numeric values (:issue:`39817`)\n- Deprecated :meth:`Categorical.replace`, use :meth:`Series.replace` instead (:issue:`44929`)\n- Deprecated passing ``set`` or ``dict`` as indexer for :meth:`DataFrame.loc.__setitem__`, :meth:`DataFrame.loc.__getitem__`, :meth:`Series.loc.__setitem__`, :meth:`Series.loc.__getitem__`, :meth:`DataFrame.__getitem__`, :meth:`Series.__getitem__` and :meth:`Series.__setitem__` (:issue:`42825`)\n- Deprecated :meth:`Index.__getitem__` with a bool key; use ``index.values[key]`` to get the old behavior (:issue:`44051`)\n- Deprecated downcasting column-by-column in :meth:`DataFrame.where` with integer-dtypes (:issue:`44597`)\n- Deprecated :meth:`DatetimeIndex.union_many`, use :meth:`DatetimeIndex.union` instead (:issue:`44091`)\n- Deprecated :meth:`.Groupby.pad` in favor of :meth:`.Groupby.ffill` (:issue:`33396`)\n- Deprecated :meth:`.Groupby.backfill` in favor of :meth:`.Groupby.bfill` (:issue:`33396`)\n- Deprecated :meth:`.Resample.pad` in favor of :meth:`.Resample.ffill` (:issue:`33396`)\n- Deprecated :meth:`.Resample.backfill` in favor of :meth:`.Resample.bfill` (:issue:`33396`)\n- Deprecated ``numeric_only=None`` in :meth:`DataFrame.rank`; in a future version ``numeric_only`` must be either ``True`` or ``False`` (the default) (:issue:`45036`)\n- Deprecated the behavior of :meth:`Timestamp.utcfromtimestamp`, in the future it will return a timezone-aware UTC :class:`Timestamp` (:issue:`22451`)\n- Deprecated :meth:`NaT.freq` (:issue:`45071`)\n- Deprecated behavior of :class:`Series` and :class:`DataFrame` construction when passed float-dtype data containing ``NaN`` and an integer dtype ignoring the dtype argument; in a future version this will raise (:issue:`40110`)\n- Deprecated the behaviour of :meth:`Series.to_frame` and :meth:`Index.to_frame` to ignore the ``name`` argument when ``name=None``. Currently, this means to preserve the existing name, but in the future explicitly passing ``name=None`` will set ``None`` as the name of the column in the resulting DataFrame (:issue:`44212`)\n\n.. ---------------------------------------------------------------------------\n\n.. _whatsnew_140.performance:\n\nPerformance improvements\n~~~~~~~~~~~~~~~~~~~~~~~~\n- Performance improvement in :meth:`.DataFrameGroupBy.sample` and :meth:`.SeriesGroupBy.sample`, especially when ``weights`` argument provided (:issue:`34483`)\n- Performance improvement when converting non-string arrays to string arrays (:issue:`34483`)\n- Performance improvement in :meth:`.DataFrameGroupBy.transform` and :meth:`.SeriesGroupBy.transform` for user-defined functions (:issue:`41598`)\n- Performance improvement in constructing :class:`DataFrame` objects (:issue:`42631`, :issue:`43142`, :issue:`43147`, :issue:`43307`, :issue:`43144`, :issue:`44826`)\n- Performance improvement in :meth:`.DataFrameGroupBy.shift` and :meth:`.SeriesGroupBy.shift` when ``fill_value`` argument is provided (:issue:`26615`)\n- Performance improvement in :meth:`DataFrame.corr` for ``method=pearson`` on data without missing values (:issue:`40956`)\n- Performance improvement in some :meth:`.DataFrameGroupBy.apply` and :meth:`.SeriesGroupBy.apply` operations (:issue:`42992`, :issue:`43578`)\n- Performance improvement in :func:`read_stata` (:issue:`43059`, :issue:`43227`)\n- Performance improvement in :func:`read_sas` (:issue:`43333`)\n- Performance improvement in :meth:`to_datetime` with ``uint`` dtypes (:issue:`42606`)\n- Performance improvement in :meth:`to_datetime` with ``infer_datetime_format`` set to ``True`` (:issue:`43901`)\n- Performance improvement in :meth:`Series.sparse.to_coo` (:issue:`42880`)\n- Performance improvement in indexing with a :class:`UInt64Index` (:issue:`43862`)\n- Performance improvement in indexing with a :class:`Float64Index` (:issue:`43705`)\n- Performance improvement in indexing with a non-unique :class:`Index` (:issue:`43792`)\n- Performance improvement in indexing with a listlike indexer on a :class:`MultiIndex` (:issue:`43370`)\n- Performance improvement in indexing with a :class:`MultiIndex` indexer on another :class:`MultiIndex` (:issue:`43370`)\n- Performance improvement in :meth:`.DataFrameGroupBy.quantile` and :meth:`.SeriesGroupBy.quantile` (:issue:`43469`, :issue:`43725`)\n- Performance improvement in :meth:`.DataFrameGroupBy.count` and :meth:`.SeriesGroupBy.count` (:issue:`43730`, :issue:`43694`)\n- Performance improvement in :meth:`.DataFrameGroupBy.any`, :meth:`.SeriesGroupBy.any`, :meth:`.DataFrameGroupBy.all`, and :meth:`.SeriesGroupBy.all` (:issue:`43675`, :issue:`42841`)\n- Performance improvement in :meth:`.DataFrameGroupBy.std` and :meth:`.SeriesGroupBy.std` (:issue:`43115`, :issue:`43576`)\n- Performance improvement in :meth:`.DataFrameGroupBy.cumsum` and :meth:`.SeriesGroupBy.cumsum` (:issue:`43309`)\n- :meth:`SparseArray.min` and :meth:`SparseArray.max` no longer require converting to a dense array (:issue:`43526`)\n- Indexing into a :class:`SparseArray` with a ``slice`` with ``step=1`` no longer requires converting to a dense array (:issue:`43777`)\n- Performance improvement in :meth:`SparseArray.take` with ``allow_fill=False`` (:issue:`43654`)\n- Performance improvement in :meth:`.Rolling.mean`, :meth:`.Expanding.mean`, :meth:`.Rolling.sum`, :meth:`.Expanding.sum`, :meth:`.Rolling.max`, :meth:`.Expanding.max`, :meth:`.Rolling.min` and :meth:`.Expanding.min` with ``engine=\"numba\"`` (:issue:`43612`, :issue:`44176`, :issue:`45170`)\n- Improved performance of :meth:`pandas.read_csv` with ``memory_map=True`` when file encoding is UTF-8 (:issue:`43787`)\n- Performance improvement in :meth:`RangeIndex.sort_values` overriding :meth:`Index.sort_values` (:issue:`43666`)\n- Performance improvement in :meth:`RangeIndex.insert` (:issue:`43988`)\n- Performance improvement in :meth:`Index.insert` (:issue:`43953`)\n- Performance improvement in :meth:`DatetimeIndex.tolist` (:issue:`43823`)\n- Performance improvement in :meth:`DatetimeIndex.union` (:issue:`42353`)\n- Performance improvement in :meth:`Series.nsmallest` (:issue:`43696`)\n- Performance improvement in :meth:`DataFrame.insert` (:issue:`42998`)\n- Performance improvement in :meth:`DataFrame.dropna` (:issue:`43683`)\n- Performance improvement in :meth:`DataFrame.fillna` (:issue:`43316`)\n- Performance improvement in :meth:`DataFrame.values` (:issue:`43160`)\n- Performance improvement in :meth:`DataFrame.select_dtypes` (:issue:`42611`)\n- Performance improvement in :class:`DataFrame` reductions (:issue:`43185`, :issue:`43243`, :issue:`43311`, :issue:`43609`)\n- Performance improvement in :meth:`Series.unstack` and :meth:`DataFrame.unstack` (:issue:`43335`, :issue:`43352`, :issue:`42704`, :issue:`43025`)\n- Performance improvement in :meth:`Series.to_frame` (:issue:`43558`)\n- Performance improvement in :meth:`Series.mad` (:issue:`43010`)\n- Performance improvement in :func:`merge` (:issue:`43332`)\n- Performance improvement in :func:`to_csv` when index column is a datetime and is formatted (:issue:`39413`)\n- Performance improvement in :func:`to_csv` when :class:`MultiIndex` contains a lot of unused levels (:issue:`37484`)\n- Performance improvement in :func:`read_csv` when ``index_col`` was set with a numeric column (:issue:`44158`)\n- Performance improvement in :func:`concat` (:issue:`43354`)\n- Performance improvement in :meth:`SparseArray.__getitem__` (:issue:`23122`)\n- Performance improvement in constructing a :class:`DataFrame` from array-like objects like a ``Pytorch`` tensor (:issue:`44616`)\n\n.. ---------------------------------------------------------------------------\n\n.. _whatsnew_140.bug_fixes:\n\nBug fixes\n~~~~~~~~~\n\nCategorical\n^^^^^^^^^^^\n- Bug in setting dtype-incompatible values into a :class:`Categorical` (or ``Series`` or ``DataFrame`` backed by ``Categorical``) raising ``ValueError`` instead of ``TypeError`` (:issue:`41919`)\n- Bug in :meth:`Categorical.searchsorted` when passing a dtype-incompatible value raising ``KeyError`` instead of ``TypeError`` (:issue:`41919`)\n- Bug in :meth:`Categorical.astype` casting datetimes and :class:`Timestamp` to int for dtype ``object`` (:issue:`44930`)\n- Bug in :meth:`Series.where` with ``CategoricalDtype`` when passing a dtype-incompatible value raising ``ValueError`` instead of ``TypeError`` (:issue:`41919`)\n- Bug in :meth:`Categorical.fillna` when passing a dtype-incompatible value raising ``ValueError`` instead of ``TypeError`` (:issue:`41919`)\n- Bug in :meth:`Categorical.fillna` with a tuple-like category raising ``ValueError`` instead of ``TypeError`` when filling with a non-category tuple (:issue:`41919`)\n\nDatetimelike\n^^^^^^^^^^^^\n- Bug in :class:`DataFrame` constructor unnecessarily copying non-datetimelike 2D object arrays (:issue:`39272`)\n- Bug in :func:`to_datetime` with ``format`` and ``pandas.NA`` was raising ``ValueError`` (:issue:`42957`)\n- :func:`to_datetime` would silently swap ``MM/DD/YYYY`` and ``DD/MM/YYYY`` formats if the given ``dayfirst`` option could not be respected - now, a warning is raised in the case of delimited date strings (e.g. ``31-12-2012``) (:issue:`12585`)\n- Bug in :meth:`date_range` and :meth:`bdate_range` do not return right bound when ``start`` = ``end`` and set is closed on one side (:issue:`43394`)\n- Bug in inplace addition and subtraction of :class:`DatetimeIndex` or :class:`TimedeltaIndex` with :class:`DatetimeArray` or :class:`TimedeltaArray` (:issue:`43904`)\n- Bug in calling ``np.isnan``, ``np.isfinite``, or ``np.isinf`` on a timezone-aware :class:`DatetimeIndex` incorrectly raising ``TypeError`` (:issue:`43917`)\n- Bug in constructing a :class:`Series` from datetime-like strings with mixed timezones incorrectly partially-inferring datetime values (:issue:`40111`)\n- Bug in addition of a :class:`Tick` object and a ``np.timedelta64`` object incorrectly raising instead of returning :class:`Timedelta` (:issue:`44474`)\n- ``np.maximum.reduce`` and ``np.minimum.reduce`` now correctly return :class:`Timestamp` and :class:`Timedelta` objects when operating on :class:`Series`, :class:`DataFrame`, or :class:`Index` with ``datetime64[ns]`` or ``timedelta64[ns]`` dtype (:issue:`43923`)\n- Bug in adding a ``np.timedelta64`` object to a :class:`BusinessDay` or :class:`CustomBusinessDay` object incorrectly raising (:issue:`44532`)\n- Bug in :meth:`Index.insert` for inserting ``np.datetime64``, ``np.timedelta64`` or ``tuple`` into :class:`Index` with ``dtype='object'`` with negative loc adding ``None`` and replacing existing value (:issue:`44509`)\n- Bug in :meth:`Timestamp.to_pydatetime` failing to retain the ``fold`` attribute (:issue:`45087`)\n- Bug in :meth:`Series.mode` with ``DatetimeTZDtype`` incorrectly returning timezone-naive and ``PeriodDtype`` incorrectly raising (:issue:`41927`)\n- Fixed regression in :meth:`~Series.reindex` raising an error when using an incompatible fill value with a datetime-like dtype (or not raising a deprecation warning for using a ``datetime.date`` as fill value) (:issue:`42921`)\n- Bug in :class:`DateOffset` addition with :class:`Timestamp` where ``offset.nanoseconds`` would not be included in the result (:issue:`43968`, :issue:`36589`)\n- Bug in :meth:`Timestamp.fromtimestamp` not supporting the ``tz`` argument (:issue:`45083`)\n- Bug in :class:`DataFrame` construction from dict of :class:`Series` with mismatched index dtypes sometimes raising depending on the ordering of the passed dict (:issue:`44091`)\n- Bug in :class:`Timestamp` hashing during some DST transitions caused a segmentation fault (:issue:`33931` and :issue:`40817`)\n\nTimedelta\n^^^^^^^^^\n- Bug in division of all-``NaT`` :class:`TimeDeltaIndex`, :class:`Series` or :class:`DataFrame` column with object-dtype array like of numbers failing to infer the result as timedelta64-dtype (:issue:`39750`)\n- Bug in floor division of ``timedelta64[ns]`` data with a scalar returning garbage values (:issue:`44466`)\n- Bug in :class:`Timedelta` now properly taking into account any nanoseconds contribution of any kwarg (:issue:`43764`, :issue:`45227`)\n\nTime Zones\n^^^^^^^^^^\n- Bug in :func:`to_datetime` with ``infer_datetime_format=True`` failing to parse zero UTC offset (``Z``) correctly (:issue:`41047`)\n- Bug in :meth:`Series.dt.tz_convert` resetting index in a :class:`Series` with :class:`CategoricalIndex` (:issue:`43080`)\n- Bug in ``Timestamp`` and ``DatetimeIndex`` incorrectly raising a ``TypeError`` when subtracting two timezone-aware objects with mismatched timezones (:issue:`31793`)\n\nNumeric\n^^^^^^^\n- Bug in floor-dividing a list or tuple of integers by a :class:`Series` incorrectly raising (:issue:`44674`)\n- Bug in :meth:`DataFrame.rank` raising ``ValueError`` with ``object`` columns and ``method=\"first\"`` (:issue:`41931`)\n- Bug in :meth:`DataFrame.rank` treating missing values and extreme values as equal (for example ``np.nan`` and ``np.inf``), causing incorrect results when ``na_option=\"bottom\"`` or ``na_option=\"top`` used (:issue:`41931`)\n- Bug in ``numexpr`` engine still being used when the option ``compute.use_numexpr`` is set to ``False`` (:issue:`32556`)\n- Bug in :class:`DataFrame` arithmetic ops with a subclass whose :meth:`_constructor` attribute is a callable other than the subclass itself (:issue:`43201`)\n- Bug in arithmetic operations involving :class:`RangeIndex` where the result would have the incorrect ``name`` (:issue:`43962`)\n- Bug in arithmetic operations involving :class:`Series` where the result could have the incorrect ``name`` when the operands having matching NA or matching tuple names (:issue:`44459`)\n- Bug in division with ``IntegerDtype`` or ``BooleanDtype`` array and NA scalar incorrectly raising (:issue:`44685`)\n- Bug in multiplying a :class:`Series` with ``FloatingDtype`` with a timedelta-like scalar incorrectly raising (:issue:`44772`)\n\nConversion\n^^^^^^^^^^\n- Bug in :class:`UInt64Index` constructor when passing a list containing both positive integers small enough to cast to int64 and integers too large to hold in int64 (:issue:`42201`)\n- Bug in :class:`Series` constructor returning 0 for missing values with dtype ``int64`` and ``False`` for dtype ``bool`` (:issue:`43017`, :issue:`43018`)\n- Bug in constructing a :class:`DataFrame` from a :class:`PandasArray` containing :class:`Series` objects behaving differently than an equivalent ``np.ndarray`` (:issue:`43986`)\n- Bug in :class:`IntegerDtype` not allowing coercion from string dtype (:issue:`25472`)\n- Bug in :func:`to_datetime` with ``arg:xr.DataArray`` and ``unit=\"ns\"`` specified raises ``TypeError`` (:issue:`44053`)\n- Bug in :meth:`DataFrame.convert_dtypes` not returning the correct type when a subclass does not overload :meth:`_constructor_sliced` (:issue:`43201`)\n- Bug in :meth:`DataFrame.astype` not propagating ``attrs`` from the original :class:`DataFrame` (:issue:`44414`)\n- Bug in :meth:`DataFrame.convert_dtypes` result losing ``columns.names`` (:issue:`41435`)\n- Bug in constructing a ``IntegerArray`` from pyarrow data failing to validate dtypes (:issue:`44891`)\n- Bug in :meth:`Series.astype` not allowing converting from a ``PeriodDtype`` to ``datetime64`` dtype, inconsistent with the :class:`PeriodIndex` behavior (:issue:`45038`)\n\nStrings\n^^^^^^^\n- Bug in checking for ``string[pyarrow]`` dtype incorrectly raising an ``ImportError`` when pyarrow is not installed (:issue:`44276`)\n\nInterval\n^^^^^^^^\n- Bug in :meth:`Series.where` with ``IntervalDtype`` incorrectly raising when the ``where`` call should not replace anything (:issue:`44181`)\n\nIndexing\n^^^^^^^^\n- Bug in :meth:`Series.rename` with :class:`MultiIndex` and ``level`` is provided (:issue:`43659`)\n- Bug in :meth:`DataFrame.truncate` and :meth:`Series.truncate` when the object's :class:`Index` has a length greater than one but only one unique value (:issue:`42365`)\n- Bug in :meth:`Series.loc` and :meth:`DataFrame.loc` with a :class:`MultiIndex` when indexing with a tuple in which one of the levels is also a tuple (:issue:`27591`)\n- Bug in :meth:`Series.loc` with a :class:`MultiIndex` whose first level contains only ``np.nan`` values (:issue:`42055`)\n- Bug in indexing on a :class:`Series` or :class:`DataFrame` with a :class:`DatetimeIndex` when passing a string, the return type depended on whether the index was monotonic (:issue:`24892`)\n- Bug in indexing on a :class:`MultiIndex` failing to drop scalar levels when the indexer is a tuple containing a datetime-like string (:issue:`42476`)\n- Bug in :meth:`DataFrame.sort_values` and :meth:`Series.sort_values` when passing an ascending value, failed to raise or incorrectly raising ``ValueError`` (:issue:`41634`)\n- Bug in updating values of :class:`pandas.Series` using boolean index, created by using :meth:`pandas.DataFrame.pop` (:issue:`42530`)\n- Bug in :meth:`Index.get_indexer_non_unique` when index contains multiple ``np.nan`` (:issue:`35392`)\n- Bug in :meth:`DataFrame.query` did not handle the degree sign in a backticked column name, such as \\`Temp(\u00c2\u00b0C)\\`, used in an expression to query a :class:`DataFrame` (:issue:`42826`)\n- Bug in :meth:`DataFrame.drop` where the error message did not show missing labels with commas when raising ``KeyError`` (:issue:`42881`)\n- Bug in :meth:`DataFrame.query` where method calls in query strings led to errors when the ``numexpr`` package was installed (:issue:`22435`)\n- Bug in :meth:`DataFrame.nlargest` and :meth:`Series.nlargest` where sorted result did not count indexes containing ``np.nan`` (:issue:`28984`)\n- Bug in indexing on a non-unique object-dtype :class:`Index` with an NA scalar (e.g. ``np.nan``) (:issue:`43711`)\n- Bug in :meth:`DataFrame.__setitem__` incorrectly writing into an existing column's array rather than setting a new array when the new dtype and the old dtype match (:issue:`43406`)\n- Bug in setting floating-dtype values into a :class:`Series` with integer dtype failing to set inplace when those values can be losslessly converted to integers (:issue:`44316`)\n- Bug in :meth:`Series.__setitem__` with object dtype when setting an array with matching size and dtype='datetime64[ns]' or dtype='timedelta64[ns]' incorrectly converting the datetime/timedeltas to integers (:issue:`43868`)\n- Bug in :meth:`DataFrame.sort_index` where ``ignore_index=True`` was not being respected when the index was already sorted (:issue:`43591`)\n- Bug in :meth:`Index.get_indexer_non_unique` when index contains multiple ``np.datetime64(\"NaT\")`` and ``np.timedelta64(\"NaT\")`` (:issue:`43869`)\n- Bug in setting a scalar :class:`Interval` value into a :class:`Series` with ``IntervalDtype`` when the scalar's sides are floats and the values' sides are integers (:issue:`44201`)\n- Bug when setting string-backed :class:`Categorical` values that can be parsed to datetimes into a :class:`DatetimeArray` or :class:`Series` or :class:`DataFrame` column backed by :class:`DatetimeArray` failing to parse these strings (:issue:`44236`)\n- Bug in :meth:`Series.__setitem__` with an integer dtype other than ``int64`` setting with a ``range`` object unnecessarily upcasting to ``int64`` (:issue:`44261`)\n- Bug in :meth:`Series.__setitem__` with a boolean mask indexer setting a listlike value of length 1 incorrectly broadcasting that value (:issue:`44265`)\n- Bug in :meth:`Series.reset_index` not ignoring ``name`` argument when ``drop`` and ``inplace`` are set to ``True`` (:issue:`44575`)\n- Bug in :meth:`DataFrame.loc.__setitem__` and :meth:`DataFrame.iloc.__setitem__` with mixed dtypes sometimes failing to operate in-place (:issue:`44345`)\n- Bug in :meth:`DataFrame.loc.__getitem__` incorrectly raising ``KeyError`` when selecting a single column with a boolean key (:issue:`44322`).\n- Bug in setting :meth:`DataFrame.iloc` with a single ``ExtensionDtype`` column and setting 2D values e.g. ``df.iloc[:] = df.values`` incorrectly raising (:issue:`44514`)\n- Bug in setting values with :meth:`DataFrame.iloc` with a single ``ExtensionDtype`` column and a tuple of arrays as the indexer (:issue:`44703`)\n- Bug in indexing on columns with ``loc`` or ``iloc`` using a slice with a negative step with ``ExtensionDtype`` columns incorrectly raising (:issue:`44551`)\n- Bug in :meth:`DataFrame.loc.__setitem__` changing dtype when indexer was completely ``False`` (:issue:`37550`)\n- Bug in :meth:`IntervalIndex.get_indexer_non_unique` returning boolean mask instead of array of integers for a non unique and non monotonic index (:issue:`44084`)\n- Bug in :meth:`IntervalIndex.get_indexer_non_unique` not handling targets of ``dtype`` 'object' with NaNs correctly (:issue:`44482`)\n- Fixed regression where a single column ``np.matrix`` was no longer coerced to a 1d ``np.ndarray`` when added to a :class:`DataFrame` (:issue:`42376`)\n- Bug in :meth:`Series.__getitem__` with a :class:`CategoricalIndex` of integers treating lists of integers as positional indexers, inconsistent with the behavior with a single scalar integer (:issue:`15470`, :issue:`14865`)\n- Bug in :meth:`Series.__setitem__` when setting floats or integers into integer-dtype :class:`Series` failing to upcast when necessary to retain precision (:issue:`45121`)\n- Bug in :meth:`DataFrame.iloc.__setitem__` ignores axis argument (:issue:`45032`)\n\nMissing\n^^^^^^^\n- Bug in :meth:`DataFrame.fillna` with ``limit`` and no ``method`` ignores ``axis='columns'`` or ``axis = 1`` (:issue:`40989`, :issue:`17399`)\n- Bug in :meth:`DataFrame.fillna` not replacing missing values when using a dict-like ``value`` and duplicate column names (:issue:`43476`)\n- Bug in constructing a :class:`DataFrame` with a dictionary ``np.datetime64`` as a value and ``dtype='timedelta64[ns]'``, or vice-versa, incorrectly casting instead of raising (:issue:`44428`)\n- Bug in :meth:`Series.interpolate` and :meth:`DataFrame.interpolate` with ``inplace=True`` not writing to the underlying array(s) in-place (:issue:`44749`)\n- Bug in :meth:`Index.fillna` incorrectly returning an unfilled :class:`Index` when NA values are present and ``downcast`` argument is specified. This now raises ``NotImplementedError`` instead; do not pass ``downcast`` argument (:issue:`44873`)\n- Bug in :meth:`DataFrame.dropna` changing :class:`Index` even if no entries were dropped (:issue:`41965`)\n- Bug in :meth:`Series.fillna` with an object-dtype incorrectly ignoring ``downcast=\"infer\"`` (:issue:`44241`)\n\nMultiIndex\n^^^^^^^^^^\n- Bug in :meth:`MultiIndex.get_loc` where the first level is a :class:`DatetimeIndex` and a string key is passed (:issue:`42465`)\n- Bug in :meth:`MultiIndex.reindex` when passing a ``level`` that corresponds to an ``ExtensionDtype`` level (:issue:`42043`)\n- Bug in :meth:`MultiIndex.get_loc` raising ``TypeError`` instead of ``KeyError`` on nested tuple (:issue:`42440`)\n- Bug in :meth:`MultiIndex.union` setting wrong ``sortorder`` causing errors in subsequent indexing operations with slices (:issue:`44752`)\n- Bug in :meth:`MultiIndex.putmask` where the other value was also a :class:`MultiIndex` (:issue:`43212`)\n- Bug in :meth:`MultiIndex.dtypes` duplicate level names returned only one dtype per name (:issue:`45174`)\n\nI/O\n^^^\n- Bug in :func:`read_excel` attempting to read chart sheets from .xlsx files (:issue:`41448`)\n- Bug in :func:`json_normalize` where ``errors=ignore`` could fail to ignore missing values of ``meta`` when ``record_path`` has a length greater than one (:issue:`41876`)\n- Bug in :func:`read_csv` with multi-header input and arguments referencing column names as tuples (:issue:`42446`)\n- Bug in :func:`read_fwf`, where difference in lengths of ``colspecs`` and ``names`` was not raising ``ValueError`` (:issue:`40830`)\n- Bug in :func:`Series.to_json` and :func:`DataFrame.to_json` where some attributes were skipped when serializing plain Python objects to JSON (:issue:`42768`, :issue:`33043`)\n- Column headers are dropped when constructing a :class:`DataFrame` from a sqlalchemy's ``Row`` object (:issue:`40682`)\n- Bug in unpickling an :class:`Index` with object dtype incorrectly inferring numeric dtypes (:issue:`43188`)\n- Bug in :func:`read_csv` where reading multi-header input with unequal lengths incorrectly raised ``IndexError`` (:issue:`43102`)\n- Bug in :func:`read_csv` raising ``ParserError`` when reading file in chunks and some chunk blocks have fewer columns than header for ``engine=\"c\"`` (:issue:`21211`)\n- Bug in :func:`read_csv`, changed exception class when expecting a file path name or file-like object from ``OSError`` to ``TypeError`` (:issue:`43366`)\n- Bug in :func:`read_csv` and :func:`read_fwf` ignoring all ``skiprows`` except first when ``nrows`` is specified for ``engine='python'`` (:issue:`44021`, :issue:`10261`)\n- Bug in :func:`read_csv` keeping the original column in object format when ``keep_date_col=True`` is set (:issue:`13378`)\n- Bug in :func:`read_json` not handling non-numpy dtypes correctly (especially ``category``) (:issue:`21892`, :issue:`33205`)\n- Bug in :func:`json_normalize` where multi-character ``sep`` parameter is incorrectly prefixed to every key (:issue:`43831`)\n- Bug in :func:`json_normalize` where reading data with missing multi-level metadata would not respect ``errors=\"ignore\"`` (:issue:`44312`)\n- Bug in :func:`read_csv` used second row to guess implicit index if ``header`` was set to ``None`` for ``engine=\"python\"`` (:issue:`22144`)\n- Bug in :func:`read_csv` not recognizing bad lines when ``names`` were given for ``engine=\"c\"`` (:issue:`22144`)\n- Bug in :func:`read_csv` with :code:`float_precision=\"round_trip\"` which did not skip initial/trailing whitespace (:issue:`43713`)\n- Bug when Python is built without the lzma module: a warning was raised at the pandas import time, even if the lzma capability isn't used (:issue:`43495`)\n- Bug in :func:`read_csv` not applying dtype for ``index_col`` (:issue:`9435`)\n- Bug in dumping/loading a :class:`DataFrame` with ``yaml.dump(frame)`` (:issue:`42748`)\n- Bug in :func:`read_csv` raising ``ValueError`` when ``names`` was longer than ``header`` but equal to data rows for ``engine=\"python\"`` (:issue:`38453`)\n- Bug in :class:`ExcelWriter`, where ``engine_kwargs`` were not passed through to all engines (:issue:`43442`)\n- Bug in :func:`read_csv` raising ``ValueError`` when ``parse_dates`` was used with :class:`MultiIndex` columns (:issue:`8991`)\n- Bug in :func:`read_csv` not raising an ``ValueError`` when ``\\n`` was specified as ``delimiter`` or ``sep`` which conflicts with ``lineterminator`` (:issue:`43528`)\n- Bug in :func:`to_csv` converting datetimes in categorical :class:`Series` to integers (:issue:`40754`)\n- Bug in :func:`read_csv` converting columns to numeric after date parsing failed (:issue:`11019`)\n- Bug in :func:`read_csv` not replacing ``NaN`` values with ``np.nan`` before attempting date conversion (:issue:`26203`)\n- Bug in :func:`read_csv` raising ``AttributeError`` when attempting to read a .csv file and infer index column dtype from an nullable integer type (:issue:`44079`)\n- Bug in :func:`to_csv` always coercing datetime columns with different formats to the same format (:issue:`21734`)\n- :meth:`DataFrame.to_csv` and :meth:`Series.to_csv` with ``compression`` set to ``'zip'`` no longer create a zip file containing a file ending with \".zip\". Instead, they try to infer the inner file name more smartly (:issue:`39465`)\n- Bug in :func:`read_csv` where reading a mixed column of booleans and missing values to a float type results in the missing values becoming 1.0 rather than NaN (:issue:`42808`, :issue:`34120`)\n- Bug in :func:`to_xml` raising error for ``pd.NA`` with extension array dtype (:issue:`43903`)\n- Bug in :func:`read_csv` when passing simultaneously a parser in ``date_parser`` and ``parse_dates=False``, the parsing was still called (:issue:`44366`)\n- Bug in :func:`read_csv` not setting name of :class:`MultiIndex` columns correctly when ``index_col`` is not the first column (:issue:`38549`)\n- Bug in :func:`read_csv` silently ignoring errors when failing to create a memory-mapped file (:issue:`44766`)\n- Bug in :func:`read_csv` when passing a ``tempfile.SpooledTemporaryFile`` opened in binary mode (:issue:`44748`)\n- Bug in :func:`read_json` raising ``ValueError`` when attempting to parse json strings containing \"://\" (:issue:`36271`)\n- Bug in :func:`read_csv` when ``engine=\"c\"`` and ``encoding_errors=None`` which caused a segfault (:issue:`45180`)\n- Bug in :func:`read_csv` an invalid value of ``usecols`` leading to an unclosed file handle (:issue:`45384`)\n- Bug in :meth:`DataFrame.to_json` fix memory leak (:issue:`43877`)\n\nPeriod\n^^^^^^\n- Bug in adding a :class:`Period` object to a ``np.timedelta64`` object incorrectly raising ``TypeError`` (:issue:`44182`)\n- Bug in :meth:`PeriodIndex.to_timestamp` when the index has ``freq=\"B\"`` inferring ``freq=\"D\"`` for its result instead of ``freq=\"B\"`` (:issue:`44105`)\n- Bug in :class:`Period` constructor incorrectly allowing ``np.timedelta64(\"NaT\")`` (:issue:`44507`)\n- Bug in :meth:`PeriodIndex.to_timestamp` giving incorrect values for indexes with non-contiguous data (:issue:`44100`)\n- Bug in :meth:`Series.where` with ``PeriodDtype`` incorrectly raising when the ``where`` call should not replace anything (:issue:`45135`)\n\nPlotting\n^^^^^^^^\n- When given non-numeric data, :meth:`DataFrame.boxplot` now raises a ``ValueError`` rather than a cryptic ``KeyError`` or ``ZeroDivisionError``, in line with other plotting functions like :meth:`DataFrame.hist` (:issue:`43480`)\n\nGroupby/resample/rolling\n^^^^^^^^^^^^^^^^^^^^^^^^\n- Bug in :meth:`SeriesGroupBy.apply` where passing an unrecognized string argument failed to raise ``TypeError`` when the underlying ``Series`` is empty (:issue:`42021`)\n- Bug in :meth:`Series.rolling.apply`, :meth:`DataFrame.rolling.apply`, :meth:`Series.expanding.apply` and :meth:`DataFrame.expanding.apply` with ``engine=\"numba\"`` where ``*args`` were being cached with the user passed function (:issue:`42287`)\n- Bug in :meth:`.DataFrameGroupBy.max`, :meth:`.SeriesGroupBy.max`, :meth:`.DataFrameGroupBy.min`, and :meth:`.SeriesGroupBy.min` with nullable integer dtypes losing precision (:issue:`41743`)\n- Bug in :meth:`DataFrame.groupby.rolling.var` would calculate the rolling variance only on the first group (:issue:`42442`)\n- Bug in :meth:`.DataFrameGroupBy.shift` and :meth:`.SeriesGroupBy.shift` that would return the grouping columns if ``fill_value`` was not ``None`` (:issue:`41556`)\n- Bug in :meth:`SeriesGroupBy.nlargest` and :meth:`SeriesGroupBy.nsmallest` would have an inconsistent index when the input :class:`Series` was sorted and ``n`` was greater than or equal to all group sizes (:issue:`15272`, :issue:`16345`, :issue:`29129`)\n- Bug in :meth:`pandas.DataFrame.ewm`, where non-float64 dtypes were silently failing (:issue:`42452`)\n- Bug in :meth:`pandas.DataFrame.rolling` operation along rows (``axis=1``) incorrectly omits columns containing ``float16`` and ``float32`` (:issue:`41779`)\n- Bug in :meth:`Resampler.aggregate` did not allow the use of Named Aggregation (:issue:`32803`)\n- Bug in :meth:`Series.rolling` when the :class:`Series` ``dtype`` was ``Int64`` (:issue:`43016`)\n- Bug in :meth:`DataFrame.rolling.corr` when the :class:`DataFrame` columns was a :class:`MultiIndex` (:issue:`21157`)\n- Bug in :meth:`DataFrame.groupby.rolling` when specifying ``on`` and calling ``__getitem__`` would subsequently return incorrect results (:issue:`43355`)\n- Bug in :meth:`.DataFrameGroupBy.apply` and :meth:`.SeriesGroupBy.apply` with time-based :class:`Grouper` objects incorrectly raising ``ValueError`` in corner cases where the grouping vector contains a ``NaT`` (:issue:`43500`, :issue:`43515`)\n- Bug in :meth:`.DataFrameGroupBy.mean` and :meth:`.SeriesGroupBy.mean` failing with ``complex`` dtype (:issue:`43701`)\n- Bug in :meth:`Series.rolling` and :meth:`DataFrame.rolling` not calculating window bounds correctly for the first row when ``center=True`` and index is decreasing (:issue:`43927`)\n- Bug in :meth:`Series.rolling` and :meth:`DataFrame.rolling` for centered datetimelike windows with uneven nanosecond (:issue:`43997`)\n- Bug in :meth:`.DataFrameGroupBy.mean` and :meth:`.SeriesGroupBy.mean` raising ``KeyError`` when column was selected at least twice (:issue:`44924`)\n- Bug in :meth:`.DataFrameGroupBy.nth` and :meth:`.SeriesGroupBy.nth` failing on ``axis=1`` (:issue:`43926`)\n- Bug in :meth:`Series.rolling` and :meth:`DataFrame.rolling` not respecting right bound on centered datetime-like windows, if the index contain duplicates (:issue:`3944`)\n- Bug in :meth:`Series.rolling` and :meth:`DataFrame.rolling` when using a :class:`pandas.api.indexers.BaseIndexer` subclass that returned unequal start and end arrays would segfault instead of raising a ``ValueError`` (:issue:`44470`)\n- Bug in :meth:`Groupby.nunique` not respecting ``observed=True`` for ``categorical`` grouping columns (:issue:`45128`)\n- Bug in :meth:`.DataFrameGroupBy.head`, :meth:`.SeriesGroupBy.head`, :meth:`.DataFrameGroupBy.tail`, and :meth:`.SeriesGroupBy.tail` not dropping groups with ``NaN`` when ``dropna=True`` (:issue:`45089`)\n- Bug in :meth:`GroupBy.__iter__` after selecting a subset of columns in a :class:`GroupBy` object, which returned all columns instead of the chosen subset (:issue:`44821`)\n- Bug in :meth:`Groupby.rolling` when non-monotonic data passed, fails to correctly raise ``ValueError`` (:issue:`43909`)\n- Bug where grouping by a :class:`Series` that has a ``categorical`` data type and length unequal to the axis of grouping raised ``ValueError`` (:issue:`44179`)\n\nReshaping\n^^^^^^^^^\n- Improved error message when creating a :class:`DataFrame` column from a multi-dimensional :class:`numpy.ndarray` (:issue:`42463`)\n- Bug in :func:`concat` creating :class:`MultiIndex` with duplicate level entries when concatenating a :class:`DataFrame` with duplicates in :class:`Index` and multiple keys (:issue:`42651`)\n- Bug in :meth:`pandas.cut` on :class:`Series` with duplicate indices and non-exact :meth:`pandas.CategoricalIndex` (:issue:`42185`, :issue:`42425`)\n- Bug in :meth:`DataFrame.append` failing to retain dtypes when appended columns do not match (:issue:`43392`)\n- Bug in :func:`concat` of ``bool`` and ``boolean`` dtypes resulting in ``object`` dtype instead of ``boolean`` dtype (:issue:`42800`)\n- Bug in :func:`crosstab` when inputs are categorical :class:`Series`, there are categories that are not present in one or both of the :class:`Series`, and ``margins=True``. Previously the margin value for missing categories was ``NaN``. It is now correctly reported as 0 (:issue:`43505`)\n- Bug in :func:`concat` would fail when the ``objs`` argument all had the same index and the ``keys`` argument contained duplicates (:issue:`43595`)\n- Bug in :func:`concat` which ignored the ``sort`` parameter (:issue:`43375`)\n- Bug in :func:`merge` with :class:`MultiIndex` as column index for the ``on`` argument returning an error when assigning a column internally (:issue:`43734`)\n- Bug in :func:`crosstab` would fail when inputs are lists or tuples (:issue:`44076`)\n- Bug in :meth:`DataFrame.append` failing to retain ``index.name`` when appending a list of :class:`Series` objects (:issue:`44109`)\n- Fixed metadata propagation in :meth:`Dataframe.apply` method, consequently fixing the same issue for :meth:`Dataframe.transform`, :meth:`Dataframe.nunique` and :meth:`Dataframe.mode` (:issue:`28283`)\n- Bug in :func:`concat` casting levels of :class:`MultiIndex` to float if all levels only consist of missing values (:issue:`44900`)\n- Bug in :meth:`DataFrame.stack` with ``ExtensionDtype`` columns incorrectly raising (:issue:`43561`)\n- Bug in :func:`merge` raising ``KeyError`` when joining over differently named indexes with on keywords (:issue:`45094`)\n- Bug in :meth:`Series.unstack` with object doing unwanted type inference on resulting columns (:issue:`44595`)\n- Bug in :meth:`MultiIndex.join()` with overlapping ``IntervalIndex`` levels (:issue:`44096`)\n- Bug in :meth:`DataFrame.replace` and :meth:`Series.replace` results is different ``dtype`` based on ``regex`` parameter (:issue:`44864`)\n- Bug in :meth:`DataFrame.pivot` with ``index=None`` when the :class:`DataFrame` index was a :class:`MultiIndex` (:issue:`23955`)\n\nSparse\n^^^^^^\n- Bug in :meth:`DataFrame.sparse.to_coo` raising ``AttributeError`` when column names are not unique (:issue:`29564`)\n- Bug in :meth:`SparseArray.max` and :meth:`SparseArray.min` raising ``ValueError`` for arrays with 0 non-null elements (:issue:`43527`)\n- Bug in :meth:`DataFrame.sparse.to_coo` silently converting non-zero fill values to zero (:issue:`24817`)\n- Bug in :class:`SparseArray` comparison methods with an array-like operand of mismatched length raising ``AssertionError`` or unclear ``ValueError`` depending on the input (:issue:`43863`)\n- Bug in :class:`SparseArray` arithmetic methods ``floordiv`` and ``mod`` behaviors when dividing by zero not matching the non-sparse :class:`Series` behavior (:issue:`38172`)\n- Bug in :class:`SparseArray` unary methods as well as :meth:`SparseArray.isna` doesn't recalculate indexes (:issue:`44955`)\n\nExtensionArray\n^^^^^^^^^^^^^^\n- Bug in :func:`array` failing to preserve :class:`PandasArray` (:issue:`43887`)\n- NumPy ufuncs ``np.abs``, ``np.positive``, ``np.negative`` now correctly preserve dtype when called on ExtensionArrays that implement ``__abs__, __pos__, __neg__``, respectively. In particular this is fixed for :class:`TimedeltaArray` (:issue:`43899`, :issue:`23316`)\n- NumPy ufuncs ``np.minimum.reduce`` ``np.maximum.reduce``, ``np.add.reduce``, and ``np.prod.reduce`` now work correctly instead of raising ``NotImplementedError`` on :class:`Series` with ``IntegerDtype`` or ``FloatDtype`` (:issue:`43923`, :issue:`44793`)\n- NumPy ufuncs with ``out`` keyword are now supported by arrays with ``IntegerDtype`` and ``FloatingDtype`` (:issue:`45122`)\n- Avoid raising ``PerformanceWarning`` about fragmented :class:`DataFrame` when using many columns with an extension dtype (:issue:`44098`)\n- Bug in :class:`IntegerArray` and :class:`FloatingArray` construction incorrectly coercing mismatched NA values (e.g. ``np.timedelta64(\"NaT\")``) to numeric NA (:issue:`44514`)\n- Bug in :meth:`BooleanArray.__eq__` and :meth:`BooleanArray.__ne__` raising ``TypeError`` on comparison with an incompatible type (like a string). This caused :meth:`DataFrame.replace` to sometimes raise a ``TypeError`` if a nullable boolean column was included (:issue:`44499`)\n- Bug in :func:`array` incorrectly raising when passed a ``ndarray`` with ``float16`` dtype (:issue:`44715`)\n- Bug in calling ``np.sqrt`` on :class:`BooleanArray` returning a malformed :class:`FloatingArray` (:issue:`44715`)\n- Bug in :meth:`Series.where` with ``ExtensionDtype`` when ``other`` is a NA scalar incompatible with the :class:`Series` dtype (e.g. ``NaT`` with a numeric dtype) incorrectly casting to a compatible NA value (:issue:`44697`)\n- Bug in :meth:`Series.replace` where explicitly passing ``value=None`` is treated as if no ``value`` was passed, and ``None`` not being in the result (:issue:`36984`, :issue:`19998`)\n- Bug in :meth:`Series.replace` with unwanted downcasting being done in no-op replacements (:issue:`44498`)\n- Bug in :meth:`Series.replace` with ``FloatDtype``, ``string[python]``, or ``string[pyarrow]`` dtype not being preserved when possible (:issue:`33484`, :issue:`40732`, :issue:`31644`, :issue:`41215`, :issue:`25438`)\n\nStyler\n^^^^^^\n- Bug in :class:`.Styler` where the ``uuid`` at initialization maintained a floating underscore (:issue:`43037`)\n- Bug in :meth:`.Styler.to_html` where the ``Styler`` object was updated if the ``to_html`` method was called with some args (:issue:`43034`)\n- Bug in :meth:`.Styler.copy` where ``uuid`` was not previously copied (:issue:`40675`)\n- Bug in :meth:`Styler.apply` where functions which returned :class:`Series` objects were not correctly handled in terms of aligning their index labels (:issue:`13657`, :issue:`42014`)\n- Bug when rendering an empty :class:`DataFrame` with a named :class:`Index` (:issue:`43305`)\n- Bug when rendering a single level :class:`MultiIndex` (:issue:`43383`)\n- Bug when combining non-sparse rendering and :meth:`.Styler.hide_columns` or :meth:`.Styler.hide_index` (:issue:`43464`)\n- Bug setting a table style when using multiple selectors in :class:`.Styler` (:issue:`44011`)\n- Bugs where row trimming and column trimming failed to reflect hidden rows (:issue:`43703`, :issue:`44247`)\n\nOther\n^^^^^\n- Bug in :meth:`DataFrame.astype` with non-unique columns and a :class:`Series` ``dtype`` argument (:issue:`44417`)\n- Bug in :meth:`CustomBusinessMonthBegin.__add__` (:meth:`CustomBusinessMonthEnd.__add__`) not applying the extra ``offset`` parameter when beginning (end) of the target month is already a business day (:issue:`41356`)\n- Bug in :meth:`RangeIndex.union` with another ``RangeIndex`` with matching (even) ``step`` and starts differing by strictly less than ``step / 2`` (:issue:`44019`)\n- Bug in :meth:`RangeIndex.difference` with ``sort=None`` and ``step<0`` failing to sort (:issue:`44085`)\n- Bug in :meth:`Series.replace` and :meth:`DataFrame.replace` with ``value=None`` and ExtensionDtypes (:issue:`44270`, :issue:`37899`)\n- Bug in :meth:`FloatingArray.equals` failing to consider two arrays equal if they contain ``np.nan`` values (:issue:`44382`)\n- Bug in :meth:`DataFrame.shift` with ``axis=1`` and ``ExtensionDtype`` columns incorrectly raising when an incompatible ``fill_value`` is passed (:issue:`44564`)\n- Bug in :meth:`DataFrame.shift` with ``axis=1`` and ``periods`` larger than ``len(frame.columns)`` producing an invalid :class:`DataFrame` (:issue:`44978`)\n- Bug in :meth:`DataFrame.diff` when passing a NumPy integer object instead of an ``int`` object (:issue:`44572`)\n- Bug in :meth:`Series.replace` raising ``ValueError`` when using ``regex=True`` with a :class:`Series` containing ``np.nan`` values (:issue:`43344`)\n- Bug in :meth:`DataFrame.to_records` where an incorrect ``n`` was used when missing names were replaced by ``level_n`` (:issue:`44818`)\n- Bug in :meth:`DataFrame.eval` where ``resolvers`` argument was overriding the default resolvers (:issue:`34966`)\n- :meth:`Series.__repr__` and :meth:`DataFrame.__repr__` no longer replace all null-values in indexes with \"NaN\" but use their real string-representations. \"NaN\" is used only for ``float(\"nan\")`` (:issue:`45263`)\n\n.. ---------------------------------------------------------------------------\n\n.. _whatsnew_140.contributors:\n\nContributors\n~~~~~~~~~~~~\n\n.. contributors:: v1.3.5..v1.4.0\n\n\n\n.. _whatsnew_050:\n\nVersion 0.5.0 (October 24, 2011)\n--------------------------------\n\n{{ header }}\n\nNew features\n~~~~~~~~~~~~\n\n- :ref:`Added <basics.df_join>` ``DataFrame.align`` method with standard join options\n- :ref:`Added <io.parse_dates>` ``parse_dates`` option to ``read_csv`` and ``read_table`` methods to optionally try to parse dates in the index columns\n- :ref:`Added <io.parse_dates>` ``nrows``, ``chunksize``, and ``iterator`` arguments to ``read_csv`` and ``read_table``. The last two return a new ``TextParser`` class capable of lazily iterating through chunks of a flat file (:issue:`242`)\n- :ref:`Added <merging.multikey_join>` ability to join on multiple columns in ``DataFrame.join`` (:issue:`214`)\n- Added private ``_get_duplicates`` function to ``Index`` for identifying duplicate values more easily (ENH5c_)\n- :ref:`Added <indexing.df_cols>` column attribute access to DataFrame.\n- :ref:`Added <indexing.df_cols>` Python tab completion hook for DataFrame columns. (:issue:`233`, :issue:`230`)\n- :ref:`Implemented <basics.describe>` ``Series.describe`` for Series containing objects (:issue:`241`)\n- :ref:`Added <merging.df_inner_join>` inner join option to ``DataFrame.join`` when joining on key(s) (:issue:`248`)\n- :ref:`Implemented <indexing.df_cols>` selecting DataFrame columns by passing a list to ``__getitem__`` (:issue:`253`)\n- :ref:`Implemented <indexing.set_ops>` & and | to intersect / union Index objects, respectively (:issue:`261`)\n- :ref:`Added<reshaping.pivot>` ``pivot_table`` convenience function to pandas namespace (:issue:`234`)\n- :ref:`Implemented <basics.rename_axis>` ``Panel.rename_axis`` function (:issue:`243`)\n- DataFrame will show index level names in console output (:issue:`334`)\n- :ref:`Implemented <advanced.take>` ``Panel.take``\n- :ref:`Added<basics.console_output>` ``set_eng_float_format`` for alternate DataFrame floating point string formatting (ENH61_)\n- :ref:`Added <indexing.set_index>` convenience ``set_index`` function for creating a DataFrame index from its existing columns\n- :ref:`Implemented <groupby.multiindex>` ``groupby`` hierarchical index level name  (:issue:`223`)\n- :ref:`Added <io.store_in_csv>` support for different delimiters in ``DataFrame.to_csv`` (:issue:`244`)\n\nPerformance enhancements\n~~~~~~~~~~~~~~~~~~~~~~~~\n\n- VBENCH Major performance improvements in file parsing functions ``read_csv`` and ``read_table``\n- VBENCH Added Cython function for converting tuples to ndarray very fast. Speeds up many MultiIndex-related operations\n- VBENCH Refactored merging / joining code into a tidy class and disabled unnecessary computations in the float/object case, thus getting about 10% better performance (:issue:`211`)\n- VBENCH Improved speed of ``DataFrame.xs`` on mixed-type DataFrame objects by about 5x, regression from 0.3.0 (:issue:`215`)\n- VBENCH With new ``DataFrame.align`` method, speeding up binary operations between differently-indexed DataFrame objects by 10-25%.\n- VBENCH Significantly sped up conversion of nested dict into DataFrame (:issue:`212`)\n- VBENCH Significantly speed up DataFrame ``__repr__`` and ``count`` on large mixed-type DataFrame objects\n\n.. _ENH61: https://github.com/pandas-dev/pandas/commit/6141961\n.. _ENH5c: https://github.com/pandas-dev/pandas/commit/5ca6ff5d822ee4ddef1ec0d87b6d83d8b4bbd3eb\n\n\n.. _whatsnew_0.5.0.contributors:\n\nContributors\n~~~~~~~~~~~~\n\n.. contributors:: v0.4.0..v0.5.0\n\n\n.. _whatsnew_134:\n\nWhat's new in 1.3.4 (October 17, 2021)\n--------------------------------------\n\nThese are the changes in pandas 1.3.4. See :ref:`release` for a full changelog\nincluding other versions of pandas.\n\n{{ header }}\n\n.. ---------------------------------------------------------------------------\n\n.. _whatsnew_134.regressions:\n\nFixed regressions\n~~~~~~~~~~~~~~~~~\n- Fixed regression in :meth:`DataFrame.convert_dtypes` incorrectly converts byte strings to strings (:issue:`43183`)\n- Fixed regression in :meth:`.DataFrameGroupBy.agg` and :meth:`.SeriesGroupBy.agg` were failing silently with mixed data types along ``axis=1`` and :class:`MultiIndex` (:issue:`43209`)\n- Fixed regression in :func:`merge` with integer and ``NaN`` keys failing with ``outer`` merge (:issue:`43550`)\n- Fixed regression in :meth:`DataFrame.corr` raising ``ValueError`` with ``method=\"spearman\"`` on 32-bit platforms (:issue:`43588`)\n- Fixed performance regression in :meth:`MultiIndex.equals` (:issue:`43549`)\n- Fixed performance regression in :meth:`.DataFrameGroupBy.first`, :meth:`.SeriesGroupBy.first`, :meth:`.DataFrameGroupBy.last`, and :meth:`.SeriesGroupBy.last` with :class:`StringDtype` (:issue:`41596`)\n- Fixed regression in :meth:`Series.cat.reorder_categories` failing to update the categories on the ``Series`` (:issue:`43232`)\n- Fixed regression in :meth:`Series.cat.categories` setter failing to update the categories on the ``Series`` (:issue:`43334`)\n- Fixed regression in :func:`read_csv` raising ``UnicodeDecodeError`` exception when ``memory_map=True`` (:issue:`43540`)\n- Fixed regression in :meth:`DataFrame.explode` raising ``AssertionError`` when ``column`` is any scalar which is not a string (:issue:`43314`)\n- Fixed regression in :meth:`Series.aggregate` attempting to pass ``args`` and ``kwargs`` multiple times to the user supplied ``func`` in certain cases (:issue:`43357`)\n- Fixed regression when iterating over a :class:`DataFrame.groupby.rolling` object causing the resulting DataFrames to have an incorrect index if the input groupings were not sorted (:issue:`43386`)\n- Fixed regression in :meth:`DataFrame.groupby.rolling.cov` and :meth:`DataFrame.groupby.rolling.corr` computing incorrect results if the input groupings were not sorted (:issue:`43386`)\n\n.. ---------------------------------------------------------------------------\n\n.. _whatsnew_134.bug_fixes:\n\nBug fixes\n~~~~~~~~~\n- Fixed bug in :meth:`pandas.DataFrame.groupby.rolling` and :class:`pandas.api.indexers.FixedForwardWindowIndexer` leading to segfaults and window endpoints being mixed across groups (:issue:`43267`)\n- Fixed bug in :meth:`.DataFrameGroupBy.mean` and :meth:`.SeriesGroupBy.mean` with datetimelike values including ``NaT`` values returning incorrect results (:issue:`43132`)\n- Fixed bug in :meth:`Series.aggregate` not passing the first ``args`` to the user supplied ``func`` in certain cases (:issue:`43357`)\n- Fixed memory leaks in :meth:`Series.rolling.quantile` and :meth:`Series.rolling.median` (:issue:`43339`)\n\n.. ---------------------------------------------------------------------------\n\n.. _whatsnew_134.other:\n\nOther\n~~~~~\n- The minimum version of Cython needed to compile pandas is now ``0.29.24`` (:issue:`43729`)\n\n.. ---------------------------------------------------------------------------\n\n.. _whatsnew_134.contributors:\n\nContributors\n~~~~~~~~~~~~\n\n.. contributors:: v1.3.3..v1.3.4\n\n\n.. _whatsnew_0210:\n\nVersion 0.21.0 (October 27, 2017)\n---------------------------------\n\n{{ header }}\n\n.. ipython:: python\n   :suppress:\n\n   from pandas import *  noqa F401, F403\n\n\nThis is a major release from 0.20.3 and includes a number of API changes, deprecations, new features,\nenhancements, and performance improvements along with a large number of bug fixes. We recommend that all\nusers upgrade to this version.\n\nHighlights include:\n\n- Integration with `Apache Parquet <https://parquet.apache.org/>`__, including a new top-level :func:`read_parquet` function and :meth:`DataFrame.to_parquet` method, see :ref:`here <whatsnew_0210.enhancements.parquet>`.\n- New user-facing :class:`pandas.api.types.CategoricalDtype` for specifying\n  categoricals independent of the data, see :ref:`here <whatsnew_0210.enhancements.categorical_dtype>`.\n- The behavior of ``sum`` and ``prod`` on all-NaN Series/DataFrames is now consistent and no longer depends on whether `bottleneck <https://bottleneck.readthedocs.io>`__ is installed, and ``sum`` and ``prod`` on empty Series now return NaN instead of 0, see :ref:`here <whatsnew_0210.api_breaking.bottleneck>`.\n- Compatibility fixes for pypy, see :ref:`here <whatsnew_0210.pypy>`.\n- Additions to the ``drop``, ``reindex`` and ``rename`` API to make them more consistent, see :ref:`here <whatsnew_0210.enhancements.drop_api>`.\n- Addition of the new methods ``DataFrame.infer_objects`` (see :ref:`here <whatsnew_0210.enhancements.infer_objects>`) and ``GroupBy.pipe`` (see :ref:`here <whatsnew_0210.enhancements.GroupBy_pipe>`).\n- Indexing with a list of labels, where one or more of the labels is missing, is deprecated and will raise a KeyError in a future version, see :ref:`here <whatsnew_0210.api_breaking.loc>`.\n\nCheck the :ref:`API Changes <whatsnew_0210.api_breaking>` and :ref:`deprecations <whatsnew_0210.deprecations>` before updating.\n\n.. contents:: What's new in v0.21.0\n    :local:\n    :backlinks: none\n    :depth: 2\n\n.. _whatsnew_0210.enhancements:\n\nNew features\n~~~~~~~~~~~~\n\n.. _whatsnew_0210.enhancements.parquet:\n\nIntegration with Apache Parquet file format\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nIntegration with `Apache Parquet <https://parquet.apache.org/>`__, including a new top-level :func:`read_parquet` and :func:`DataFrame.to_parquet` method, see :ref:`here <io.parquet>` (:issue:`15838`, :issue:`17438`).\n\n`Apache Parquet <https://parquet.apache.org/>`__ provides a cross-language, binary file format for reading and writing data frames efficiently.\nParquet is designed to faithfully serialize and de-serialize ``DataFrame`` s, supporting all of the pandas\ndtypes, including extension dtypes such as datetime with timezones.\n\nThis functionality depends on either the `pyarrow <http://arrow.apache.org/docs/python/>`__ or `fastparquet <https://fastparquet.readthedocs.io/en/latest/>`__ library.\nFor more details, see :ref:`the IO docs on Parquet <io.parquet>`.\n\n\n.. _whatsnew_0210.enhancements.infer_objects:\n\nMethod ``infer_objects`` type conversion\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nThe :meth:`DataFrame.infer_objects` and :meth:`Series.infer_objects`\nmethods have been added to perform dtype inference on object columns, replacing\nsome of the functionality of the deprecated ``convert_objects``\nmethod. See the documentation :ref:`here <basics.object_conversion>`\nfor more details. (:issue:`11221`)\n\nThis method only performs soft conversions on object columns, converting Python objects\nto native types, but not any coercive conversions. For example:\n\n.. ipython:: python\n\n   df = pd.DataFrame({'A': [1, 2, 3],\n                      'B': np.array([1, 2, 3], dtype='object'),\n                      'C': ['1', '2', '3']})\n   df.dtypes\n   df.infer_objects().dtypes\n\nNote that column ``'C'`` was not converted - only scalar numeric types\nwill be converted to a new type.  Other types of conversion should be accomplished\nusing the :func:`to_numeric` function (or :func:`to_datetime`, :func:`to_timedelta`).\n\n.. ipython:: python\n\n   df = df.infer_objects()\n   df['C'] = pd.to_numeric(df['C'], errors='coerce')\n   df.dtypes\n\n.. _whatsnew_0210.enhancements.attribute_access:\n\nImproved warnings when attempting to create columns\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nNew users are often puzzled by the relationship between column operations and\nattribute access on ``DataFrame`` instances (:issue:`7175`). One specific\ninstance of this confusion is attempting to create a new column by setting an\nattribute on the ``DataFrame``:\n\n.. code-block:: ipython\n\n   In [1]: df = pd.DataFrame({'one': [1., 2., 3.]})\n   In [2]: df.two = [4, 5, 6]\n\nThis does not raise any obvious exceptions, but also does not create a new column:\n\n.. code-block:: ipython\n\n   In [3]: df\n   Out[3]:\n       one\n   0  1.0\n   1  2.0\n   2  3.0\n\nSetting a list-like data structure into a new attribute now raises a ``UserWarning`` about the potential for unexpected behavior. See :ref:`Attribute Access <indexing.attribute_access>`.\n\n.. _whatsnew_0210.enhancements.drop_api:\n\nMethod ``drop`` now also accepts index/columns keywords\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nThe :meth:`~DataFrame.drop` method has gained ``index``/``columns`` keywords as an\nalternative to specifying the ``axis``. This is similar to the behavior of ``reindex``\n(:issue:`12392`).\n\nFor example:\n\n.. ipython:: python\n\n    df = pd.DataFrame(np.arange(8).reshape(2, 4),\n                      columns=['A', 'B', 'C', 'D'])\n    df\n    df.drop(['B', 'C'], axis=1)\n     the following is now equivalent\n    df.drop(columns=['B', 'C'])\n\n.. _whatsnew_0210.enhancements.rename_reindex_axis:\n\nMethods ``rename``, ``reindex`` now also accept axis keyword\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nThe :meth:`DataFrame.rename` and :meth:`DataFrame.reindex` methods have gained\nthe ``axis`` keyword to specify the axis to target with the operation\n(:issue:`12392`).\n\nHere's ``rename``:\n\n.. ipython:: python\n\n   df = pd.DataFrame({\"A\": [1, 2, 3], \"B\": [4, 5, 6]})\n   df.rename(str.lower, axis='columns')\n   df.rename(id, axis='index')\n\nAnd ``reindex``:\n\n.. ipython:: python\n\n   df.reindex(['A', 'B', 'C'], axis='columns')\n   df.reindex([0, 1, 3], axis='index')\n\nThe \"index, columns\" style continues to work as before.\n\n.. ipython:: python\n\n   df.rename(index=id, columns=str.lower)\n   df.reindex(index=[0, 1, 3], columns=['A', 'B', 'C'])\n\nWe *highly* encourage using named arguments to avoid confusion when using either\nstyle.\n\n.. _whatsnew_0210.enhancements.categorical_dtype:\n\n``CategoricalDtype`` for specifying categoricals\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n:class:`pandas.api.types.CategoricalDtype` has been added to the public API and\nexpanded to include the ``categories`` and ``ordered`` attributes. A\n``CategoricalDtype`` can be used to specify the set of categories and\norderedness of an array, independent of the data. This can be useful for example,\nwhen converting string data to a ``Categorical`` (:issue:`14711`,\n:issue:`15078`, :issue:`16015`, :issue:`17643`):\n\n.. ipython:: python\n\n   from pandas.api.types import CategoricalDtype\n\n   s = pd.Series(['a', 'b', 'c', 'a'])   strings\n   dtype = CategoricalDtype(categories=['a', 'b', 'c', 'd'], ordered=True)\n   s.astype(dtype)\n\nOne place that deserves special mention is in :meth:`read_csv`. Previously, with\n``dtype={'col': 'category'}``, the returned values and categories would always\nbe strings.\n\n.. ipython:: python\n   :suppress:\n\n   from io import StringIO\n\n.. ipython:: python\n\n   data = 'A,B\\na,1\\nb,2\\nc,3'\n   pd.read_csv(StringIO(data), dtype={'B': 'category'}).B.cat.categories\n\nNotice the \"object\" dtype.\n\nWith a ``CategoricalDtype`` of all numerics, datetimes, or\ntimedeltas, we can automatically convert to the correct type\n\n.. ipython:: python\n\n   dtype = {'B': CategoricalDtype([1, 2, 3])}\n   pd.read_csv(StringIO(data), dtype=dtype).B.cat.categories\n\nThe values have been correctly interpreted as integers.\n\nThe ``.dtype`` property of a ``Categorical``, ``CategoricalIndex`` or a\n``Series`` with categorical type will now return an instance of\n``CategoricalDtype``. While the repr has changed, ``str(CategoricalDtype())`` is\nstill the string ``'category'``. We'll take this moment to remind users that the\n*preferred* way to detect categorical data is to use\n:func:`pandas.api.types.is_categorical_dtype`, and not ``str(dtype) == 'category'``.\n\nSee the :ref:`CategoricalDtype docs <categorical.categoricaldtype>` for more.\n\n.. _whatsnew_0210.enhancements.GroupBy_pipe:\n\n``GroupBy`` objects now have a ``pipe`` method\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n``GroupBy`` objects now have a ``pipe`` method, similar to the one on\n``DataFrame`` and ``Series``, that allow for functions that take a\n``GroupBy`` to be composed in a clean, readable syntax. (:issue:`17871`)\n\nFor a concrete example on combining ``.groupby`` and ``.pipe`` , imagine having a\nDataFrame with columns for stores, products, revenue and sold quantity. We'd like to\ndo a groupwise calculation of *prices* (i.e. revenue/quantity) per store and per product.\nWe could do this in a multi-step operation, but expressing it in terms of piping can make the\ncode more readable.\n\nFirst we set the data:\n\n.. ipython:: python\n\n   import numpy as np\n   n = 1000\n   df = pd.DataFrame({'Store': np.random.choice(['Store_1', 'Store_2'], n),\n                      'Product': np.random.choice(['Product_1',\n                                                   'Product_2',\n                                                   'Product_3'\n                                                   ], n),\n                      'Revenue': (np.random.random(n) * 50 + 10).round(2),\n                      'Quantity': np.random.randint(1, 10, size=n)})\n   df.head(2)\n\nNow, to find prices per store/product, we can simply do:\n\n.. ipython:: python\n\n   (df.groupby(['Store', 'Product'])\n      .pipe(lambda grp: grp.Revenue.sum() / grp.Quantity.sum())\n      .unstack().round(2))\n\nSee the :ref:`documentation <groupby.pipe>` for more.\n\n\n.. _whatsnew_0210.enhancements.rename_categories:\n\n``Categorical.rename_categories`` accepts a dict-like\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n:meth:`~Series.cat.rename_categories` now accepts a dict-like argument for\n``new_categories``. The previous categories are looked up in the dictionary's\nkeys and replaced if found. The behavior of missing and extra keys is the same\nas in :meth:`DataFrame.rename`.\n\n.. ipython:: python\n\n   c = pd.Categorical(['a', 'a', 'b'])\n   c.rename_categories({\"a\": \"eh\", \"b\": \"bee\"})\n\n.. warning::\n\n    To assist with upgrading pandas, ``rename_categories`` treats ``Series`` as\n    list-like. Typically, Series are considered to be dict-like (e.g. in\n    ``.rename``, ``.map``). In a future version of pandas ``rename_categories``\n    will change to treat them as dict-like. Follow the warning message's\n    recommendations for writing future-proof code.\n\n    .. code-block:: ipython\n\n        In [33]: c.rename_categories(pd.Series([0, 1], index=['a', 'c']))\n        FutureWarning: Treating Series 'new_categories' as a list-like and using the values.\n        In a future version, 'rename_categories' will treat Series like a dictionary.\n        For dict-like, use 'new_categories.to_dict()'\n        For list-like, use 'new_categories.values'.\n        Out[33]:\n        [0, 0, 1]\n        Categories (2, int64): [0, 1]\n\n\n.. _whatsnew_0210.enhancements.other:\n\nOther enhancements\n^^^^^^^^^^^^^^^^^^\n\nNew functions or methods\n\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\n\n- :meth:`.Resampler.nearest` is added to support nearest-neighbor upsampling (:issue:`17496`).\n- :class:`~pandas.Index` has added support for a ``to_frame`` method (:issue:`15230`).\n\nNew keywords\n\"\"\"\"\"\"\"\"\"\"\"\"\n\n- Added a ``skipna`` parameter to :func:`~pandas.api.types.infer_dtype` to\n  support type inference in the presence of missing values (:issue:`17059`).\n- :func:`Series.to_dict` and :func:`DataFrame.to_dict` now support an ``into`` keyword which allows you to specify the ``collections.Mapping`` subclass that you would like returned.  The default is ``dict``, which is backwards compatible. (:issue:`16122`)\n- :func:`Series.set_axis` and :func:`DataFrame.set_axis` now support the ``inplace`` parameter. (:issue:`14636`)\n- :func:`Series.to_pickle` and :func:`DataFrame.to_pickle` have gained a ``protocol`` parameter (:issue:`16252`). By default, this parameter is set to `HIGHEST_PROTOCOL <https://docs.python.org/3/library/pickle.html#data-stream-format>`__\n- :func:`read_feather` has gained the ``nthreads`` parameter for multi-threaded operations (:issue:`16359`)\n- :func:`DataFrame.clip()` and :func:`Series.clip()` have gained an ``inplace`` argument. (:issue:`15388`)\n- :func:`crosstab` has gained a ``margins_name`` parameter to define the name of the row / column that will contain the totals when ``margins=True``. (:issue:`15972`)\n- :func:`read_json` now accepts a ``chunksize`` parameter that can be used when ``lines=True``. If ``chunksize`` is passed, read_json now returns an iterator which reads in ``chunksize`` lines with each iteration. (:issue:`17048`)\n- :func:`read_json` and :func:`~DataFrame.to_json` now accept a ``compression`` argument which allows them to transparently handle compressed files. (:issue:`17798`)\n\nVarious enhancements\n\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\n\n- Improved the import time of pandas by about 2.25x.  (:issue:`16764`)\n- Support for `PEP 519 -- Adding a file system path protocol\n  <https://www.python.org/dev/peps/pep-0519/>`_ on most readers (e.g.\n  :func:`read_csv`) and writers (e.g. :meth:`DataFrame.to_csv`) (:issue:`13823`).\n- Added a ``__fspath__`` method to ``pd.HDFStore``, ``pd.ExcelFile``,\n  and ``pd.ExcelWriter`` to work properly with the file system path protocol (:issue:`13823`).\n- The ``validate`` argument for :func:`merge` now checks whether a merge is one-to-one, one-to-many, many-to-one, or many-to-many. If a merge is found to not be an example of specified merge type, an exception of type ``MergeError`` will be raised. For more, see :ref:`here <merging.validation>` (:issue:`16270`)\n- Added support for `PEP 518 <https://www.python.org/dev/peps/pep-0518/>`_ (``pyproject.toml``) to the build system (:issue:`16745`)\n- :func:`RangeIndex.append` now returns a ``RangeIndex`` object when possible (:issue:`16212`)\n- :func:`Series.rename_axis` and :func:`DataFrame.rename_axis` with ``inplace=True`` now return ``None`` while renaming the axis inplace. (:issue:`15704`)\n- :func:`api.types.infer_dtype` now infers decimals. (:issue:`15690`)\n- :func:`DataFrame.select_dtypes` now accepts scalar values for include/exclude as well as list-like. (:issue:`16855`)\n- :func:`date_range` now accepts 'YS' in addition to 'AS' as an alias for start of year. (:issue:`9313`)\n- :func:`date_range` now accepts 'Y' in addition to 'A' as an alias for end of year. (:issue:`9313`)\n- :func:`DataFrame.add_prefix` and :func:`DataFrame.add_suffix` now accept strings containing the '%' character. (:issue:`17151`)\n- Read/write methods that infer compression (:func:`read_csv`, :func:`read_table`, :func:`read_pickle`, and :meth:`~DataFrame.to_pickle`) can now infer from path-like objects, such as ``pathlib.Path``. (:issue:`17206`)\n- :func:`read_sas` now recognizes much more of the most frequently used date (datetime) formats in SAS7BDAT files. (:issue:`15871`)\n- :func:`DataFrame.items` and :func:`Series.items` are now present in both Python 2 and 3 and is lazy in all cases. (:issue:`13918`, :issue:`17213`)\n- :meth:`pandas.io.formats.style.Styler.where` has been implemented as a convenience for :meth:`pandas.io.formats.style.Styler.applymap`. (:issue:`17474`)\n- :func:`MultiIndex.is_monotonic_decreasing` has been implemented.  Previously returned ``False`` in all cases. (:issue:`16554`)\n- :func:`read_excel` raises ``ImportError`` with a better message if ``xlrd`` is not installed. (:issue:`17613`)\n- :meth:`DataFrame.assign` will preserve the original order of ``**kwargs`` for Python 3.6+ users instead of sorting the column names. (:issue:`14207`)\n- :func:`Series.reindex`, :func:`DataFrame.reindex`, :func:`Index.get_indexer` now support list-like argument for ``tolerance``. (:issue:`17367`)\n\n.. _whatsnew_0210.api_breaking:\n\nBackwards incompatible API changes\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\n.. _whatsnew_0210.api_breaking.deps:\n\nDependencies have increased minimum versions\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nWe have updated our minimum supported versions of dependencies (:issue:`15206`, :issue:`15543`, :issue:`15214`).\nIf installed, we now require:\n\n   +--------------+-----------------+----------+\n   | Package      | Minimum Version | Required |\n   +==============+=================+==========+\n   | Numpy        | 1.9.0           |    X     |\n   +--------------+-----------------+----------+\n   | Matplotlib   | 1.4.3           |          |\n   +--------------+-----------------+----------+\n   | Scipy        | 0.14.0          |          |\n   +--------------+-----------------+----------+\n   | Bottleneck   | 1.0.0           |          |\n   +--------------+-----------------+----------+\n\nAdditionally, support has been dropped for Python 3.4 (:issue:`15251`).\n\n\n.. _whatsnew_0210.api_breaking.bottleneck:\n\nSum/prod of all-NaN or empty Series/DataFrames is now consistently NaN\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n.. note::\n\n   The changes described here have been partially reverted. See\n   the :ref:`v0.22.0 Whatsnew <whatsnew_0220>` for more.\n\n\nThe behavior of ``sum`` and ``prod`` on all-NaN Series/DataFrames no longer depends on\nwhether `bottleneck <https://bottleneck.readthedocs.io>`__ is installed, and return value of ``sum`` and ``prod`` on an empty Series has changed (:issue:`9422`, :issue:`15507`).\n\nCalling ``sum`` or ``prod`` on an empty or all-``NaN`` ``Series``, or columns of a ``DataFrame``, will result in ``NaN``. See the :ref:`docs <missing_data.calculations>`.\n\n.. ipython:: python\n\n   s = pd.Series([np.nan])\n\nPreviously WITHOUT ``bottleneck`` installed:\n\n.. code-block:: ipython\n\n   In [2]: s.sum()\n   Out[2]: np.nan\n\nPreviously WITH ``bottleneck``:\n\n.. code-block:: ipython\n\n   In [2]: s.sum()\n   Out[2]: 0.0\n\nNew behavior, without regard to the bottleneck installation:\n\n.. ipython:: python\n\n   s.sum()\n\nNote that this also changes the sum of an empty ``Series``. Previously this always returned 0 regardless of a ``bottleneck`` installation:\n\n.. code-block:: ipython\n\n   In [1]: pd.Series([]).sum()\n   Out[1]: 0\n\nbut for consistency with the all-NaN case, this was changed to return 0 as well:\n\n.. code-block:: ipython\n\n   In [2]: pd.Series([]).sum()\n   Out[2]: 0\n\n.. _whatsnew_0210.api_breaking.loc:\n\nIndexing with a list with missing labels is deprecated\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nPreviously, selecting with a list of labels, where one or more labels were missing would always succeed, returning ``NaN`` for missing labels.\nThis will now show a ``FutureWarning``. In the future this will raise a ``KeyError`` (:issue:`15747`).\nThis warning will trigger on a ``DataFrame`` or a ``Series`` for using ``.loc[]``  or ``[[]]`` when passing a list-of-labels with at least 1 missing label.\n\n\n.. ipython:: python\n\n   s = pd.Series([1, 2, 3])\n   s\n\nPrevious behavior\n\n.. code-block:: ipython\n\n   In [4]: s.loc[[1, 2, 3]]\n   Out[4]:\n   1    2.0\n   2    3.0\n   3    NaN\n   dtype: float64\n\n\nCurrent behavior\n\n.. code-block:: ipython\n\n   In [4]: s.loc[[1, 2, 3]]\n   Passing list-likes to .loc or [] with any missing label will raise\n   KeyError in the future, you can use .reindex() as an alternative.\n\n   See the documentation here:\n   https://pandas.pydata.org/pandas-docs/stable/indexing.html#deprecate-loc-reindex-listlike\n\n   Out[4]:\n   1    2.0\n   2    3.0\n   3    NaN\n   dtype: float64\n\nThe idiomatic way to achieve selecting potentially not-found elements is via ``.reindex()``\n\n.. ipython:: python\n\n   s.reindex([1, 2, 3])\n\nSelection with all keys found is unchanged.\n\n.. ipython:: python\n\n   s.loc[[1, 2]]\n\n\n.. _whatsnew_0210.api.na_changes:\n\nNA naming changes\n^^^^^^^^^^^^^^^^^\n\nIn order to promote more consistency among the pandas API, we have added additional top-level\nfunctions :func:`isna` and :func:`notna` that are aliases for :func:`isnull` and :func:`notnull`.\nThe naming scheme is now more consistent with methods like ``.dropna()`` and ``.fillna()``. Furthermore\nin all cases where ``.isnull()`` and ``.notnull()`` methods are defined, these have additional methods\nnamed ``.isna()`` and ``.notna()``, these are included for classes ``Categorical``,\n``Index``, ``Series``, and ``DataFrame``. (:issue:`15001`).\n\nThe configuration option ``pd.options.mode.use_inf_as_null`` is deprecated, and ``pd.options.mode.use_inf_as_na`` is added as a replacement.\n\n\n.. _whatsnew_0210.api_breaking.iteration_scalars:\n\nIteration of Series/Index will now return Python scalars\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nPreviously, when using certain iteration methods for a ``Series`` with dtype ``int`` or ``float``, you would receive a ``numpy`` scalar, e.g. a ``np.int64``, rather than a Python ``int``. Issue (:issue:`10904`) corrected this for ``Series.tolist()`` and ``list(Series)``. This change makes all iteration methods consistent, in particular, for ``__iter__()`` and ``.map()``; note that this only affects int/float dtypes. (:issue:`13236`, :issue:`13258`, :issue:`14216`).\n\n.. ipython:: python\n\n   s = pd.Series([1, 2, 3])\n   s\n\nPreviously:\n\n.. code-block:: ipython\n\n   In [2]: type(list(s)[0])\n   Out[2]: numpy.int64\n\nNew behavior:\n\n.. ipython:: python\n\n   type(list(s)[0])\n\nFurthermore this will now correctly box the results of iteration for :func:`DataFrame.to_dict` as well.\n\n.. ipython:: python\n\n   d = {'a': [1], 'b': ['b']}\n   df = pd.DataFrame(d)\n\nPreviously:\n\n.. code-block:: ipython\n\n   In [8]: type(df.to_dict()['a'][0])\n   Out[8]: numpy.int64\n\nNew behavior:\n\n.. ipython:: python\n\n   type(df.to_dict()['a'][0])\n\n\n.. _whatsnew_0210.api_breaking.loc_with_index:\n\nIndexing with a Boolean Index\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nPreviously when passing a boolean ``Index`` to ``.loc``, if the index of the ``Series/DataFrame`` had ``boolean`` labels,\nyou would get a label based selection, potentially duplicating result labels, rather than a boolean indexing selection\n(where ``True`` selects elements), this was inconsistent how a boolean numpy array indexed. The new behavior is to\nact like a boolean numpy array indexer. (:issue:`17738`)\n\nPrevious behavior:\n\n.. ipython:: python\n\n   s = pd.Series([1, 2, 3], index=[False, True, False])\n   s\n\n.. code-block:: ipython\n\n   In [59]: s.loc[pd.Index([True, False, True])]\n   Out[59]:\n   True     2\n   False    1\n   False    3\n   True     2\n   dtype: int64\n\nCurrent behavior\n\n.. ipython:: python\n\n   s.loc[pd.Index([True, False, True])]\n\n\nFurthermore, previously if you had an index that was non-numeric (e.g. strings), then a boolean Index would raise a ``KeyError``.\nThis will now be treated as a boolean indexer.\n\nPreviously behavior:\n\n.. ipython:: python\n\n   s = pd.Series([1, 2, 3], index=['a', 'b', 'c'])\n   s\n\n.. code-block:: ipython\n\n   In [39]: s.loc[pd.Index([True, False, True])]\n   KeyError: \"None of [Index([True, False, True], dtype='object')] are in the [index]\"\n\nCurrent behavior\n\n.. ipython:: python\n\n   s.loc[pd.Index([True, False, True])]\n\n\n.. _whatsnew_0210.api_breaking.period_index_resampling:\n\n``PeriodIndex`` resampling\n^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nIn previous versions of pandas, resampling a ``Series``/``DataFrame`` indexed by a ``PeriodIndex`` returned a ``DatetimeIndex`` in some cases (:issue:`12884`). Resampling to a multiplied frequency now returns a ``PeriodIndex`` (:issue:`15944`). As a minor enhancement, resampling a ``PeriodIndex`` can now handle ``NaT`` values (:issue:`13224`)\n\nPrevious behavior:\n\n.. code-block:: ipython\n\n   In [1]: pi = pd.period_range('2017-01', periods=12, freq='M')\n\n   In [2]: s = pd.Series(np.arange(12), index=pi)\n\n   In [3]: resampled = s.resample('2Q').mean()\n\n   In [4]: resampled\n   Out[4]:\n   2017-03-31     1.0\n   2017-09-30     5.5\n   2018-03-31    10.0\n   Freq: 2Q-DEC, dtype: float64\n\n   In [5]: resampled.index\n   Out[5]: DatetimeIndex(['2017-03-31', '2017-09-30', '2018-03-31'], dtype='datetime64[ns]', freq='2Q-DEC')\n\nNew behavior:\n\n.. code-block:: ipython\n\n   In [1]: pi = pd.period_range('2017-01', periods=12, freq='M')\n\n   In [2]: s = pd.Series(np.arange(12), index=pi)\n\n   In [3]: resampled = s.resample('2Q').mean()\n\n   In [4]: resampled\n   Out[4]:\n   2017Q1    2.5\n   2017Q3    8.5\n   Freq: 2Q-DEC, dtype: float64\n\n   In [5]: resampled.index\n   Out[5]: PeriodIndex(['2017Q1', '2017Q3'], dtype='period[2Q-DEC]')\n\nUpsampling and calling ``.ohlc()`` previously returned a ``Series``, basically identical to calling ``.asfreq()``. OHLC upsampling now returns a DataFrame with columns ``open``, ``high``, ``low`` and ``close`` (:issue:`13083`). This is consistent with downsampling and ``DatetimeIndex`` behavior.\n\nPrevious behavior:\n\n.. code-block:: ipython\n\n   In [1]: pi = pd.period_range(start='2000-01-01', freq='D', periods=10)\n\n   In [2]: s = pd.Series(np.arange(10), index=pi)\n\n   In [3]: s.resample('H').ohlc()\n   Out[3]:\n   2000-01-01 00:00    0.0\n                   ...\n   2000-01-10 23:00    NaN\n   Freq: H, Length: 240, dtype: float64\n\n   In [4]: s.resample('M').ohlc()\n   Out[4]:\n            open  high  low  close\n   2000-01     0     9    0      9\n\nNew behavior:\n\n.. code-block:: ipython\n\n   In [56]: pi = pd.period_range(start='2000-01-01', freq='D', periods=10)\n\n   In [57]: s = pd.Series(np.arange(10), index=pi)\n\n   In [58]: s.resample('H').ohlc()\n   Out[58]:\n                     open  high  low  close\n   2000-01-01 00:00   0.0   0.0  0.0    0.0\n   2000-01-01 01:00   NaN   NaN  NaN    NaN\n   2000-01-01 02:00   NaN   NaN  NaN    NaN\n   2000-01-01 03:00   NaN   NaN  NaN    NaN\n   2000-01-01 04:00   NaN   NaN  NaN    NaN\n   ...                ...   ...  ...    ...\n   2000-01-10 19:00   NaN   NaN  NaN    NaN\n   2000-01-10 20:00   NaN   NaN  NaN    NaN\n   2000-01-10 21:00   NaN   NaN  NaN    NaN\n   2000-01-10 22:00   NaN   NaN  NaN    NaN\n   2000-01-10 23:00   NaN   NaN  NaN    NaN\n\n   [240 rows x 4 columns]\n\n   In [59]: s.resample('M').ohlc()\n   Out[59]:\n            open  high  low  close\n   2000-01     0     9    0      9\n\n   [1 rows x 4 columns]\n\n\n.. _whatsnew_0210.api_breaking.pandas_eval:\n\nImproved error handling during item assignment in pd.eval\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n:func:`eval` will now raise a ``ValueError`` when item assignment malfunctions, or\ninplace operations are specified, but there is no item assignment in the expression (:issue:`16732`)\n\n.. ipython:: python\n\n   arr = np.array([1, 2, 3])\n\nPreviously, if you attempted the following expression, you would get a not very helpful error message:\n\n.. code-block:: ipython\n\n   In [3]: pd.eval(\"a = 1 + 2\", target=arr, inplace=True)\n   ...\n   IndexError: only integers, slices (`:`), ellipsis (`...`), numpy.newaxis (`None`)\n   and integer or boolean arrays are valid indices\n\nThis is a very long way of saying numpy arrays don't support string-item indexing. With this\nchange, the error message is now this:\n\n.. code-block:: python\n\n   In [3]: pd.eval(\"a = 1 + 2\", target=arr, inplace=True)\n   ...\n   ValueError: Cannot assign expression output to target\n\nIt also used to be possible to evaluate expressions inplace, even if there was no item assignment:\n\n.. code-block:: ipython\n\n   In [4]: pd.eval(\"1 + 2\", target=arr, inplace=True)\n   Out[4]: 3\n\nHowever, this input does not make much sense because the output is not being assigned to\nthe target. Now, a ``ValueError`` will be raised when such an input is passed in:\n\n.. code-block:: ipython\n\n   In [4]: pd.eval(\"1 + 2\", target=arr, inplace=True)\n   ...\n   ValueError: Cannot operate inplace if there is no assignment\n\n\n.. _whatsnew_0210.api_breaking.dtype_conversions:\n\nDtype conversions\n^^^^^^^^^^^^^^^^^\n\nPreviously assignments, ``.where()`` and ``.fillna()`` with a ``bool`` assignment, would coerce to same the type (e.g. int / float), or raise for datetimelikes. These will now preserve the bools with ``object`` dtypes. (:issue:`16821`).\n\n.. ipython:: python\n\n   s = pd.Series([1, 2, 3])\n\n.. code-block:: python\n\n   In [5]: s[1] = True\n\n   In [6]: s\n   Out[6]:\n   0    1\n   1    1\n   2    3\n   dtype: int64\n\nNew behavior\n\n.. code-block:: ipython\n\n   In [7]: s[1] = True\n\n   In [8]: s\n   Out[8]:\n   0       1\n   1    True\n   2       3\n   Length: 3, dtype: object\n\nPreviously, as assignment to a datetimelike with a non-datetimelike would coerce the\nnon-datetime-like item being assigned (:issue:`14145`).\n\n.. ipython:: python\n\n   s = pd.Series([pd.Timestamp('2011-01-01'), pd.Timestamp('2012-01-01')])\n\n.. code-block:: python\n\n   In [1]: s[1] = 1\n\n   In [2]: s\n   Out[2]:\n   0   2011-01-01 00:00:00.000000000\n   1   1970-01-01 00:00:00.000000001\n   dtype: datetime64[ns]\n\nThese now coerce to ``object`` dtype.\n\n.. code-block:: python\n\n   In [1]: s[1] = 1\n\n   In [2]: s\n   Out[2]:\n   0    2011-01-01 00:00:00\n   1                      1\n   dtype: object\n\n- Inconsistent behavior in ``.where()`` with datetimelikes which would raise rather than coerce to ``object`` (:issue:`16402`)\n- Bug in assignment against ``int64`` data with ``np.ndarray`` with ``float64`` dtype may keep ``int64`` dtype (:issue:`14001`)\n\n\n.. _whatsnew_210.api.multiindex_single:\n\nMultiIndex constructor with a single level\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nThe ``MultiIndex`` constructors no longer squeezes a MultiIndex with all\nlength-one levels down to a regular ``Index``. This affects all the\n``MultiIndex`` constructors. (:issue:`17178`)\n\nPrevious behavior:\n\n.. code-block:: ipython\n\n   In [2]: pd.MultiIndex.from_tuples([('a',), ('b',)])\n   Out[2]: Index(['a', 'b'], dtype='object')\n\nLength 1 levels are no longer special-cased. They behave exactly as if you had\nlength 2+ levels, so a :class:`MultiIndex` is always returned from all of the\n``MultiIndex`` constructors:\n\n.. ipython:: python\n\n   pd.MultiIndex.from_tuples([('a',), ('b',)])\n\n.. _whatsnew_0210.api.utc_localization_with_series:\n\nUTC localization with Series\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nPreviously, :func:`to_datetime` did not localize datetime ``Series`` data when ``utc=True`` was passed. Now, :func:`to_datetime` will correctly localize ``Series`` with a ``datetime64[ns, UTC]`` dtype to be consistent with how list-like and ``Index`` data are handled. (:issue:`6415`).\n\nPrevious behavior\n\n.. ipython:: python\n\n   s = pd.Series(['20130101 00:00:00'] * 3)\n\n.. code-block:: ipython\n\n   In [12]: pd.to_datetime(s, utc=True)\n   Out[12]:\n   0   2013-01-01\n   1   2013-01-01\n   2   2013-01-01\n   dtype: datetime64[ns]\n\nNew behavior\n\n.. ipython:: python\n\n   pd.to_datetime(s, utc=True)\n\nAdditionally, DataFrames with datetime columns that were parsed by :func:`read_sql_table` and :func:`read_sql_query` will also be localized to UTC only if the original SQL columns were timezone aware datetime columns.\n\n.. _whatsnew_0210.api.consistency_of_range_functions:\n\nConsistency of range functions\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nIn previous versions, there were some inconsistencies between the various range functions: :func:`date_range`, :func:`bdate_range`, :func:`period_range`, :func:`timedelta_range`, and :func:`interval_range`. (:issue:`17471`).\n\nOne of the inconsistent behaviors occurred when the ``start``, ``end`` and ``period`` parameters were all specified, potentially leading to ambiguous ranges.  When all three parameters were passed, ``interval_range`` ignored the ``period`` parameter, ``period_range`` ignored the ``end`` parameter, and the other range functions raised.  To promote consistency among the range functions, and avoid potentially ambiguous ranges, ``interval_range`` and ``period_range`` will now raise when all three parameters are passed.\n\nPrevious behavior:\n\n.. code-block:: ipython\n\n   In [2]: pd.interval_range(start=0, end=4, periods=6)\n   Out[2]:\n   IntervalIndex([(0, 1], (1, 2], (2, 3]]\n                 closed='right',\n                 dtype='interval[int64]')\n\n  In [3]: pd.period_range(start='2017Q1', end='2017Q4', periods=6, freq='Q')\n  Out[3]: PeriodIndex(['2017Q1', '2017Q2', '2017Q3', '2017Q4', '2018Q1', '2018Q2'], dtype='period[Q-DEC]', freq='Q-DEC')\n\nNew behavior:\n\n.. code-block:: ipython\n\n  In [2]: pd.interval_range(start=0, end=4, periods=6)\n  ---------------------------------------------------------------------------\n  ValueError: Of the three parameters: start, end, and periods, exactly two must be specified\n\n  In [3]: pd.period_range(start='2017Q1', end='2017Q4', periods=6, freq='Q')\n  ---------------------------------------------------------------------------\n  ValueError: Of the three parameters: start, end, and periods, exactly two must be specified\n\nAdditionally, the endpoint parameter ``end`` was not included in the intervals produced by ``interval_range``.  However, all other range functions include ``end`` in their output.  To promote consistency among the range functions, ``interval_range`` will now include ``end`` as the right endpoint of the final interval, except if ``freq`` is specified in a way which skips ``end``.\n\nPrevious behavior:\n\n.. code-block:: ipython\n\n   In [4]: pd.interval_range(start=0, end=4)\n   Out[4]:\n   IntervalIndex([(0, 1], (1, 2], (2, 3]]\n                 closed='right',\n                 dtype='interval[int64]')\n\n\nNew behavior:\n\n.. ipython:: python\n\n   pd.interval_range(start=0, end=4)\n\n.. _whatsnew_0210.api.mpl_converters:\n\nNo automatic Matplotlib converters\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\npandas no longer registers our ``date``, ``time``, ``datetime``,\n``datetime64``, and ``Period`` converters with matplotlib when pandas is\nimported. Matplotlib plot methods (``plt.plot``, ``ax.plot``, ...), will not\nnicely format the x-axis for ``DatetimeIndex`` or ``PeriodIndex`` values. You\nmust explicitly register these methods:\n\npandas built-in ``Series.plot`` and ``DataFrame.plot`` *will* register these\nconverters on first-use (:issue:`17710`).\n\n.. note::\n\n  This change has been temporarily reverted in pandas 0.21.1,\n  for more details see :ref:`here <whatsnew_0211.converters>`.\n\n.. _whatsnew_0210.api:\n\nOther API changes\n^^^^^^^^^^^^^^^^^\n\n- The Categorical constructor no longer accepts a scalar for the ``categories`` keyword. (:issue:`16022`)\n- Accessing a non-existent attribute on a closed :class:`~pandas.HDFStore` will now\n  raise an ``AttributeError`` rather than a ``ClosedFileError`` (:issue:`16301`)\n- :func:`read_csv` now issues a ``UserWarning`` if the ``names`` parameter contains duplicates (:issue:`17095`)\n- :func:`read_csv` now treats ``'null'`` and ``'n/a'`` strings as missing values by default (:issue:`16471`, :issue:`16078`)\n- :class:`pandas.HDFStore`'s string representation is now faster and less detailed. For the previous behavior, use ``pandas.HDFStore.info()``. (:issue:`16503`).\n- Compression defaults in HDF stores now follow pytables standards. Default is no compression and if ``complib`` is missing and ``complevel`` > 0 ``zlib`` is used (:issue:`15943`)\n- ``Index.get_indexer_non_unique()`` now returns a ndarray indexer rather than an ``Index``; this is consistent with ``Index.get_indexer()`` (:issue:`16819`)\n- Removed the ``slow`` decorator from ``pandas._testing``, which caused issues for some downstream packages' test suites. Use ``pytest.mark.slow`` instead, which achieves the same thing (:issue:`16850`)\n- Moved definition of ``MergeError`` to the ``pandas.errors`` module.\n- The signature of :func:`Series.set_axis` and :func:`DataFrame.set_axis` has been changed from ``set_axis(axis, labels)`` to ``set_axis(labels, axis=0)``, for consistency with the rest of the API. The old signature is deprecated and will show a ``FutureWarning`` (:issue:`14636`)\n- :func:`Series.argmin` and :func:`Series.argmax` will now raise a ``TypeError`` when used with ``object`` dtypes, instead of a ``ValueError`` (:issue:`13595`)\n- :class:`Period` is now immutable, and will now raise an ``AttributeError`` when a user tries to assign a new value to the ``ordinal`` or ``freq`` attributes (:issue:`17116`).\n- :func:`to_datetime` when passed a tz-aware ``origin=`` kwarg will now raise a more informative ``ValueError`` rather than a ``TypeError`` (:issue:`16842`)\n- :func:`to_datetime` now raises a ``ValueError`` when format includes ``%W`` or ``%U`` without also including day of the week and calendar year (:issue:`16774`)\n- Renamed non-functional ``index`` to ``index_col`` in :func:`read_stata` to improve API consistency (:issue:`16342`)\n- Bug in :func:`DataFrame.drop` caused boolean labels ``False`` and ``True`` to be treated as labels 0 and 1 respectively when dropping indices from a numeric index. This will now raise a ValueError (:issue:`16877`)\n- Restricted DateOffset keyword arguments.  Previously, ``DateOffset`` subclasses allowed arbitrary keyword arguments which could lead to unexpected behavior.  Now, only valid arguments will be accepted. (:issue:`17176`).\n\n.. _whatsnew_0210.deprecations:\n\nDeprecations\n~~~~~~~~~~~~\n\n- :meth:`DataFrame.from_csv` and :meth:`Series.from_csv` have been deprecated in favor of :func:`read_csv()` (:issue:`4191`)\n- :func:`read_excel()` has deprecated ``sheetname`` in favor of ``sheet_name`` for consistency with ``.to_excel()`` (:issue:`10559`).\n- :func:`read_excel()` has deprecated ``parse_cols`` in favor of ``usecols`` for consistency with :func:`read_csv` (:issue:`4988`)\n- :func:`read_csv()` has deprecated the ``tupleize_cols`` argument. Column tuples will always be converted to a ``MultiIndex`` (:issue:`17060`)\n- :meth:`DataFrame.to_csv` has deprecated the ``tupleize_cols`` argument. MultiIndex columns will be always written as rows in the CSV file (:issue:`17060`)\n- The ``convert`` parameter has been deprecated in the ``.take()`` method, as it was not being respected (:issue:`16948`)\n- ``pd.options.html.border`` has been deprecated in favor of ``pd.options.display.html.border`` (:issue:`15793`).\n- :func:`SeriesGroupBy.nth` has deprecated ``True`` in favor of ``'all'`` for its kwarg ``dropna`` (:issue:`11038`).\n- :func:`DataFrame.as_blocks` is deprecated, as this is exposing the internal implementation (:issue:`17302`)\n- ``pd.TimeGrouper`` is deprecated in favor of :class:`pandas.Grouper` (:issue:`16747`)\n- ``cdate_range`` has been deprecated in favor of :func:`bdate_range`, which has gained ``weekmask`` and ``holidays`` parameters for building custom frequency date ranges. See the :ref:`documentation <timeseries.custom-freq-ranges>` for more details (:issue:`17596`)\n- passing ``categories`` or ``ordered`` kwargs to :func:`Series.astype` is deprecated, in favor of passing a :ref:`CategoricalDtype <whatsnew_0210.enhancements.categorical_dtype>` (:issue:`17636`)\n- ``.get_value`` and ``.set_value`` on ``Series``, ``DataFrame``, ``Panel``, ``SparseSeries``, and ``SparseDataFrame`` are deprecated in favor of using ``.iat[]`` or ``.at[]`` accessors (:issue:`15269`)\n- Passing a non-existent column in ``.to_excel(..., columns=)`` is deprecated and will raise a ``KeyError`` in the future (:issue:`17295`)\n- ``raise_on_error`` parameter to :func:`Series.where`, :func:`Series.mask`, :func:`DataFrame.where`, :func:`DataFrame.mask` is deprecated, in favor of ``errors=`` (:issue:`14968`)\n- Using :meth:`DataFrame.rename_axis` and :meth:`Series.rename_axis` to alter index or column *labels* is now deprecated in favor of using ``.rename``. ``rename_axis`` may still be used to alter the name of the index or columns (:issue:`17833`).\n- :meth:`~DataFrame.reindex_axis` has been deprecated in favor of :meth:`~DataFrame.reindex`. See :ref:`here <whatsnew_0210.enhancements.rename_reindex_axis>` for more (:issue:`17833`).\n\n.. _whatsnew_0210.deprecations.select:\n\nSeries.select and DataFrame.select\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nThe :meth:`Series.select` and :meth:`DataFrame.select` methods are deprecated in favor of using ``df.loc[labels.map(crit)]`` (:issue:`12401`)\n\n.. ipython:: python\n\n   df = pd.DataFrame({'A': [1, 2, 3]}, index=['foo', 'bar', 'baz'])\n\n.. code-block:: ipython\n\n   In [3]: df.select(lambda x: x in ['bar', 'baz'])\n   FutureWarning: select is deprecated and will be removed in a future release. You can use .loc[crit] as a replacement\n   Out[3]:\n        A\n   bar  2\n   baz  3\n\n.. ipython:: python\n\n   df.loc[df.index.map(lambda x: x in ['bar', 'baz'])]\n\n\n.. _whatsnew_0210.deprecations.argmin_min:\n\nSeries.argmax and Series.argmin\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nThe behavior of :func:`Series.argmax` and :func:`Series.argmin` have been deprecated in favor of :func:`Series.idxmax` and :func:`Series.idxmin`, respectively (:issue:`16830`).\n\nFor compatibility with NumPy arrays, ``pd.Series`` implements ``argmax`` and\n``argmin``. Since pandas 0.13.0, ``argmax`` has been an alias for\n:meth:`pandas.Series.idxmax`, and ``argmin`` has been an alias for\n:meth:`pandas.Series.idxmin`. They return the *label* of the maximum or minimum,\nrather than the *position*.\n\nWe've deprecated the current behavior of ``Series.argmax`` and\n``Series.argmin``. Using either of these will emit a ``FutureWarning``. Use\n:meth:`Series.idxmax` if you want the label of the maximum. Use\n``Series.values.argmax()`` if you want the position of the maximum. Likewise for\nthe minimum. In a future release ``Series.argmax`` and ``Series.argmin`` will\nreturn the position of the maximum or minimum.\n\n.. _whatsnew_0210.prior_deprecations:\n\nRemoval of prior version deprecations/changes\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\n- :func:`read_excel()` has dropped the ``has_index_names`` parameter (:issue:`10967`)\n- The ``pd.options.display.height`` configuration has been dropped (:issue:`3663`)\n- The ``pd.options.display.line_width`` configuration has been dropped (:issue:`2881`)\n- The ``pd.options.display.mpl_style`` configuration has been dropped (:issue:`12190`)\n- ``Index`` has dropped the ``.sym_diff()`` method in favor of ``.symmetric_difference()`` (:issue:`12591`)\n- ``Categorical`` has dropped the ``.order()`` and ``.sort()`` methods in favor of ``.sort_values()`` (:issue:`12882`)\n- :func:`eval` and :func:`DataFrame.eval` have changed the default of ``inplace`` from ``None`` to ``False`` (:issue:`11149`)\n- The function ``get_offset_name`` has been dropped in favor of the ``.freqstr`` attribute for an offset (:issue:`11834`)\n- pandas no longer tests for compatibility with hdf5-files created with pandas < 0.11 (:issue:`17404`).\n\n\n\n.. _whatsnew_0210.performance:\n\nPerformance improvements\n~~~~~~~~~~~~~~~~~~~~~~~~\n\n- Improved performance of instantiating :class:`SparseDataFrame` (:issue:`16773`)\n- :attr:`Series.dt` no longer performs frequency inference, yielding a large speedup when accessing the attribute (:issue:`17210`)\n- Improved performance of :meth:`~Series.cat.set_categories` by not materializing the values (:issue:`17508`)\n- :attr:`Timestamp.microsecond` no longer re-computes on attribute access (:issue:`17331`)\n- Improved performance of the :class:`CategoricalIndex` for data that is already categorical dtype (:issue:`17513`)\n- Improved performance of :meth:`RangeIndex.min` and :meth:`RangeIndex.max` by using ``RangeIndex`` properties to perform the computations (:issue:`17607`)\n\n.. _whatsnew_0210.docs:\n\nDocumentation changes\n~~~~~~~~~~~~~~~~~~~~~\n\n- Several ``NaT`` method docstrings (e.g. :func:`NaT.ctime`) were incorrect (:issue:`17327`)\n- The documentation has had references to versions < v0.17 removed and cleaned up (:issue:`17442`, :issue:`17442`, :issue:`17404` & :issue:`17504`)\n\n.. _whatsnew_0210.bug_fixes:\n\nBug fixes\n~~~~~~~~~\n\nConversion\n^^^^^^^^^^\n\n- Bug in assignment against datetime-like data with ``int`` may incorrectly convert to datetime-like (:issue:`14145`)\n- Bug in assignment against ``int64`` data with ``np.ndarray`` with ``float64`` dtype may keep ``int64`` dtype (:issue:`14001`)\n- Fixed the return type of ``IntervalIndex.is_non_overlapping_monotonic`` to be a Python ``bool`` for consistency with similar attributes/methods.  Previously returned a ``numpy.bool_``. (:issue:`17237`)\n- Bug in ``IntervalIndex.is_non_overlapping_monotonic`` when intervals are closed on both sides and overlap at a point (:issue:`16560`)\n- Bug in :func:`Series.fillna` returns frame when ``inplace=True`` and ``value`` is dict (:issue:`16156`)\n- Bug in :attr:`Timestamp.weekday_name` returning a UTC-based weekday name when localized to a timezone (:issue:`17354`)\n- Bug in ``Timestamp.replace`` when replacing ``tzinfo`` around DST changes (:issue:`15683`)\n- Bug in ``Timedelta`` construction and arithmetic that would not propagate the ``Overflow`` exception (:issue:`17367`)\n- Bug in :meth:`~DataFrame.astype` converting to object dtype when passed extension type classes (``DatetimeTZDtype``, ``CategoricalDtype``) rather than instances. Now a ``TypeError`` is raised when a class is passed (:issue:`17780`).\n- Bug in :meth:`to_numeric` in which elements were not always being coerced to numeric when ``errors='coerce'`` (:issue:`17007`, :issue:`17125`)\n- Bug in ``DataFrame`` and ``Series`` constructors where ``range`` objects are converted to ``int32`` dtype on Windows instead of ``int64`` (:issue:`16804`)\n\nIndexing\n^^^^^^^^\n\n- When called with a null slice (e.g. ``df.iloc[:]``), the ``.iloc`` and ``.loc`` indexers return a shallow copy of the original object. Previously they returned the original object. (:issue:`13873`).\n- When called on an unsorted ``MultiIndex``, the ``loc`` indexer now will raise ``UnsortedIndexError`` only if proper slicing is used on non-sorted levels (:issue:`16734`).\n- Fixes regression in 0.20.3 when indexing with a string on a ``TimedeltaIndex`` (:issue:`16896`).\n- Fixed :func:`TimedeltaIndex.get_loc` handling of ``np.timedelta64`` inputs (:issue:`16909`).\n- Fix :func:`MultiIndex.sort_index` ordering when ``ascending`` argument is a list, but not all levels are specified, or are in a different order (:issue:`16934`).\n- Fixes bug where indexing with ``np.inf`` caused an ``OverflowError`` to be raised (:issue:`16957`)\n- Bug in reindexing on an empty ``CategoricalIndex`` (:issue:`16770`)\n- Fixes ``DataFrame.loc`` for setting with alignment and tz-aware ``DatetimeIndex`` (:issue:`16889`)\n- Avoids ``IndexError`` when passing an Index or Series to ``.iloc`` with older numpy (:issue:`17193`)\n- Allow unicode empty strings as placeholders in multilevel columns in Python 2 (:issue:`17099`)\n- Bug in ``.iloc`` when used with inplace addition or assignment and an int indexer on a ``MultiIndex`` causing the wrong indexes to be read from and written to (:issue:`17148`)\n- Bug in ``.isin()`` in which checking membership in empty ``Series`` objects raised an error (:issue:`16991`)\n- Bug in ``CategoricalIndex`` reindexing in which specified indices containing duplicates were not being respected (:issue:`17323`)\n- Bug in intersection of ``RangeIndex`` with negative step (:issue:`17296`)\n- Bug in ``IntervalIndex`` where performing a scalar lookup fails for included right endpoints of non-overlapping monotonic decreasing indexes (:issue:`16417`, :issue:`17271`)\n- Bug in :meth:`DataFrame.first_valid_index` and :meth:`DataFrame.last_valid_index` when no valid entry (:issue:`17400`)\n- Bug in :func:`Series.rename` when called with a callable, incorrectly alters the name of the ``Series``, rather than the name of the ``Index``. (:issue:`17407`)\n- Bug in :func:`String.str_get` raises ``IndexError`` instead of inserting NaNs when using a negative index. (:issue:`17704`)\n\nIO\n^^\n\n- Bug in :func:`read_hdf` when reading a timezone aware index from ``fixed`` format HDFStore (:issue:`17618`)\n- Bug in :func:`read_csv` in which columns were not being thoroughly de-duplicated (:issue:`17060`)\n- Bug in :func:`read_csv` in which specified column names were not being thoroughly de-duplicated (:issue:`17095`)\n- Bug in :func:`read_csv` in which non integer values for the header argument generated an unhelpful / unrelated error message (:issue:`16338`)\n- Bug in :func:`read_csv` in which memory management issues in exception handling, under certain conditions, would cause the interpreter to segfault (:issue:`14696`, :issue:`16798`).\n- Bug in :func:`read_csv` when called with ``low_memory=False`` in which a CSV with at least one column > 2GB in size would incorrectly raise a ``MemoryError`` (:issue:`16798`).\n- Bug in :func:`read_csv` when called with a single-element list ``header`` would return a ``DataFrame`` of all NaN values (:issue:`7757`)\n- Bug in :meth:`DataFrame.to_csv` defaulting to 'ascii' encoding in Python 3, instead of 'utf-8' (:issue:`17097`)\n- Bug in :func:`read_stata` where value labels could not be read when using an iterator (:issue:`16923`)\n- Bug in :func:`read_stata` where the index was not set (:issue:`16342`)\n- Bug in :func:`read_html` where import check fails when run in multiple threads (:issue:`16928`)\n- Bug in :func:`read_csv` where automatic delimiter detection caused a ``TypeError`` to be thrown when a bad line was encountered rather than the correct error message (:issue:`13374`)\n- Bug in :meth:`DataFrame.to_html` with ``notebook=True`` where DataFrames with named indices or non-MultiIndex indices had undesired horizontal or vertical alignment for column or row labels, respectively (:issue:`16792`)\n- Bug in :meth:`DataFrame.to_html` in which there was no validation of the ``justify`` parameter (:issue:`17527`)\n- Bug in :func:`HDFStore.select` when reading a contiguous mixed-data table featuring VLArray (:issue:`17021`)\n- Bug in :func:`to_json` where several conditions (including objects with unprintable symbols, objects with deep recursion, overlong labels) caused segfaults instead of raising the appropriate exception (:issue:`14256`)\n\nPlotting\n^^^^^^^^\n- Bug in plotting methods using ``secondary_y`` and ``fontsize`` not setting secondary axis font size (:issue:`12565`)\n- Bug when plotting ``timedelta`` and ``datetime`` dtypes on y-axis (:issue:`16953`)\n- Line plots no longer assume monotonic x data when calculating xlims, they show the entire lines now even for unsorted x data. (:issue:`11310`, :issue:`11471`)\n- With matplotlib 2.0.0 and above, calculation of x limits for line plots is left to matplotlib, so that its new default settings are applied. (:issue:`15495`)\n- Bug in ``Series.plot.bar`` or ``DataFrame.plot.bar`` with ``y`` not respecting user-passed ``color`` (:issue:`16822`)\n- Bug causing ``plotting.parallel_coordinates`` to reset the random seed when using random colors (:issue:`17525`)\n\n\nGroupBy/resample/rolling\n^^^^^^^^^^^^^^^^^^^^^^^^\n\n- Bug in ``DataFrame.resample(...).size()`` where an empty ``DataFrame`` did not return a ``Series`` (:issue:`14962`)\n- Bug in :func:`infer_freq` causing indices with 2-day gaps during the working week to be wrongly inferred as business daily (:issue:`16624`)\n- Bug in ``.rolling(...).quantile()`` which incorrectly used different defaults than :func:`Series.quantile()` and :func:`DataFrame.quantile()` (:issue:`9413`, :issue:`16211`)\n- Bug in ``groupby.transform()`` that would coerce boolean dtypes back to float (:issue:`16875`)\n- Bug in ``Series.resample(...).apply()`` where an empty ``Series`` modified the source index and did not return the name of a ``Series`` (:issue:`14313`)\n- Bug in ``.rolling(...).apply(...)`` with a ``DataFrame`` with a ``DatetimeIndex``, a ``window`` of a timedelta-convertible and ``min_periods >= 1`` (:issue:`15305`)\n- Bug in ``DataFrame.groupby`` where index and column keys were not recognized correctly when the number of keys equaled the number of elements on the groupby axis (:issue:`16859`)\n- Bug in ``groupby.nunique()`` with ``TimeGrouper`` which cannot handle ``NaT`` correctly (:issue:`17575`)\n- Bug in ``DataFrame.groupby`` where a single level selection from a ``MultiIndex`` unexpectedly sorts (:issue:`17537`)\n- Bug in ``DataFrame.groupby`` where spurious warning is raised when ``Grouper`` object is used to override ambiguous column name (:issue:`17383`)\n- Bug in ``TimeGrouper`` differs when passes as a list and as a scalar (:issue:`17530`)\n\nSparse\n^^^^^^\n\n- Bug in ``SparseSeries`` raises ``AttributeError`` when a dictionary is passed in as data (:issue:`16905`)\n- Bug in :func:`SparseDataFrame.fillna` not filling all NaNs when frame was instantiated from SciPy sparse matrix (:issue:`16112`)\n- Bug in :func:`SparseSeries.unstack` and :func:`SparseDataFrame.stack` (:issue:`16614`, :issue:`15045`)\n- Bug in :func:`make_sparse` treating two numeric/boolean data, which have same bits, as same when array ``dtype`` is ``object`` (:issue:`17574`)\n- :func:`SparseArray.all` and :func:`SparseArray.any` are now implemented to handle ``SparseArray``, these were used but not implemented (:issue:`17570`)\n\nReshaping\n^^^^^^^^^\n- Joining/Merging with a non unique ``PeriodIndex`` raised a ``TypeError`` (:issue:`16871`)\n- Bug in :func:`crosstab` where non-aligned series of integers were casted to float (:issue:`17005`)\n- Bug in merging with categorical dtypes with datetimelikes incorrectly raised a ``TypeError`` (:issue:`16900`)\n- Bug when using :func:`isin` on a large object series and large comparison array (:issue:`16012`)\n- Fixes regression from 0.20, :func:`Series.aggregate` and :func:`DataFrame.aggregate` allow dictionaries as return values again (:issue:`16741`)\n- Fixes dtype of result with integer dtype input, from :func:`pivot_table` when called with ``margins=True`` (:issue:`17013`)\n- Bug in :func:`crosstab` where passing two ``Series`` with the same name raised a ``KeyError`` (:issue:`13279`)\n- :func:`Series.argmin`, :func:`Series.argmax`, and their counterparts on ``DataFrame`` and groupby objects work correctly with floating point data that contains infinite values (:issue:`13595`).\n- Bug in :func:`unique` where checking a tuple of strings raised a ``TypeError`` (:issue:`17108`)\n- Bug in :func:`concat` where order of result index was unpredictable if it contained non-comparable elements (:issue:`17344`)\n- Fixes regression when sorting by multiple columns on a ``datetime64`` dtype ``Series`` with ``NaT`` values (:issue:`16836`)\n- Bug in :func:`pivot_table` where the result's columns did not preserve the categorical dtype of ``columns`` when ``dropna`` was ``False`` (:issue:`17842`)\n- Bug in ``DataFrame.drop_duplicates`` where dropping with non-unique column names raised a ``ValueError`` (:issue:`17836`)\n- Bug in :func:`unstack` which, when called on a list of levels, would discard the ``fillna`` argument (:issue:`13971`)\n- Bug in the alignment of ``range`` objects and other list-likes with ``DataFrame`` leading to operations being performed row-wise instead of column-wise (:issue:`17901`)\n\nNumeric\n^^^^^^^\n- Bug in ``.clip()`` with ``axis=1`` and a list-like for ``threshold`` is passed; previously this raised ``ValueError`` (:issue:`15390`)\n- :func:`Series.clip()` and :func:`DataFrame.clip()` now treat NA values for upper and lower arguments as ``None`` instead of raising ``ValueError`` (:issue:`17276`).\n\n\nCategorical\n^^^^^^^^^^^\n- Bug in :func:`Series.isin` when called with a categorical (:issue:`16639`)\n- Bug in the categorical constructor with empty values and categories causing the ``.categories`` to be an empty ``Float64Index`` rather than an empty ``Index`` with object dtype (:issue:`17248`)\n- Bug in categorical operations with :ref:`Series.cat <categorical.cat>` not preserving the original Series' name (:issue:`17509`)\n- Bug in :func:`DataFrame.merge` failing for categorical columns with boolean/int data types (:issue:`17187`)\n- Bug in constructing a ``Categorical``/``CategoricalDtype`` when the specified ``categories`` are of categorical type (:issue:`17884`).\n\n.. _whatsnew_0210.pypy:\n\nPyPy\n^^^^\n\n- Compatibility with PyPy in :func:`read_csv` with ``usecols=[<unsorted ints>]`` and\n  :func:`read_json` (:issue:`17351`)\n- Split tests into cases for CPython and PyPy where needed, which highlights the fragility\n  of index matching with ``float('nan')``, ``np.nan`` and ``NAT`` (:issue:`17351`)\n- Fix :func:`DataFrame.memory_usage` to support PyPy. Objects on PyPy do not have a fixed size,\n  so an approximation is used instead (:issue:`17228`)\n\nOther\n^^^^^\n- Bug where some inplace operators were not being wrapped and produced a copy when invoked (:issue:`12962`)\n- Bug in :func:`eval` where the ``inplace`` parameter was being incorrectly handled (:issue:`16732`)\n\n\n\n.. _whatsnew_0.21.0.contributors:\n\nContributors\n~~~~~~~~~~~~\n\n.. contributors:: v0.20.3..v0.21.0\n\n\n.. _whatsnew_0100:\n\nVersion 0.10.0 (December 17, 2012)\n----------------------------------\n\n{{ header }}\n\n\nThis is a major release from 0.9.1 and includes many new features and\nenhancements along with a large number of bug fixes. There are also a number of\nimportant API changes that long-time pandas users should pay close attention\nto.\n\nFile parsing new features\n~~~~~~~~~~~~~~~~~~~~~~~~~\n\nThe delimited file parsing engine (the guts of ``read_csv`` and ``read_table``)\nhas been rewritten from the ground up and now uses a fraction the amount of\nmemory while parsing, while being 40% or more faster in most use cases (in some\ncases much faster).\n\nThere are also many new features:\n\n- Much-improved Unicode handling via the ``encoding`` option.\n- Column filtering (``usecols``)\n- Dtype specification (``dtype`` argument)\n- Ability to specify strings to be recognized as True/False\n- Ability to yield NumPy record arrays (``as_recarray``)\n- High performance ``delim_whitespace`` option\n- Decimal format (e.g. European format) specification\n- Easier CSV dialect options: ``escapechar``, ``lineterminator``,\n  ``quotechar``, etc.\n- More robust handling of many exceptional kinds of files observed in the wild\n\nAPI changes\n~~~~~~~~~~~\n\n**Deprecated DataFrame BINOP TimeSeries special case behavior**\n\nThe default behavior of binary operations between a DataFrame and a Series has\nalways been to align on the DataFrame's columns and broadcast down the rows,\n**except** in the special case that the DataFrame contains time series. Since\nthere are now method for each binary operator enabling you to specify how you\nwant to broadcast, we are phasing out this special case (Zen of Python:\n*Special cases aren't special enough to break the rules*). Here's what I'm\ntalking about:\n\n.. ipython:: python\n   :okwarning:\n\n   import pandas as pd\n\n   df = pd.DataFrame(np.random.randn(6, 4), index=pd.date_range(\"1/1/2000\", periods=6))\n   df\n    deprecated now\n   df - df[0]\n    Change your code to\n   df.sub(df[0], axis=0)   align on axis 0 (rows)\n\nYou will get a deprecation warning in the 0.10.x series, and the deprecated\nfunctionality will be removed in 0.11 or later.\n\n**Altered resample default behavior**\n\nThe default time series ``resample`` binning behavior of daily ``D`` and\n*higher* frequencies has been changed to ``closed='left', label='left'``. Lower\nnfrequencies are unaffected. The prior defaults were causing a great deal of\nconfusion for users, especially resampling data to daily frequency (which\nlabeled the aggregated group with the end of the interval: the next day).\n\n.. code-block:: ipython\n\n   In [1]: dates = pd.date_range('1/1/2000', '1/5/2000', freq='4h')\n\n   In [2]: series = pd.Series(np.arange(len(dates)), index=dates)\n\n   In [3]: series\n   Out[3]:\n   2000-01-01 00:00:00     0\n   2000-01-01 04:00:00     1\n   2000-01-01 08:00:00     2\n   2000-01-01 12:00:00     3\n   2000-01-01 16:00:00     4\n   2000-01-01 20:00:00     5\n   2000-01-02 00:00:00     6\n   2000-01-02 04:00:00     7\n   2000-01-02 08:00:00     8\n   2000-01-02 12:00:00     9\n   2000-01-02 16:00:00    10\n   2000-01-02 20:00:00    11\n   2000-01-03 00:00:00    12\n   2000-01-03 04:00:00    13\n   2000-01-03 08:00:00    14\n   2000-01-03 12:00:00    15\n   2000-01-03 16:00:00    16\n   2000-01-03 20:00:00    17\n   2000-01-04 00:00:00    18\n   2000-01-04 04:00:00    19\n   2000-01-04 08:00:00    20\n   2000-01-04 12:00:00    21\n   2000-01-04 16:00:00    22\n   2000-01-04 20:00:00    23\n   2000-01-05 00:00:00    24\n   Freq: 4H, dtype: int64\n\n   In [4]: series.resample('D', how='sum')\n   Out[4]:\n   2000-01-01     15\n   2000-01-02     51\n   2000-01-03     87\n   2000-01-04    123\n   2000-01-05     24\n   Freq: D, dtype: int64\n\n   In [5]:  old behavior\n   In [6]: series.resample('D', how='sum', closed='right', label='right')\n   Out[6]:\n   2000-01-01      0\n   2000-01-02     21\n   2000-01-03     57\n   2000-01-04     93\n   2000-01-05    129\n   Freq: D, dtype: int64\n\n- Infinity and negative infinity are no longer treated as NA by ``isnull`` and\n  ``notnull``. That they ever were was a relic of early pandas. This behavior\n  can be re-enabled globally by the ``mode.use_inf_as_null`` option:\n\n.. code-block:: ipython\n\n    In [6]: s = pd.Series([1.5, np.inf, 3.4, -np.inf])\n\n    In [7]: pd.isnull(s)\n    Out[7]:\n    0    False\n    1    False\n    2    False\n    3    False\n    Length: 4, dtype: bool\n\n    In [8]: s.fillna(0)\n    Out[8]:\n    0    1.500000\n    1         inf\n    2    3.400000\n    3        -inf\n    Length: 4, dtype: float64\n\n    In [9]: pd.set_option('use_inf_as_null', True)\n\n    In [10]: pd.isnull(s)\n    Out[10]:\n    0    False\n    1     True\n    2    False\n    3     True\n    Length: 4, dtype: bool\n\n    In [11]: s.fillna(0)\n    Out[11]:\n    0    1.5\n    1    0.0\n    2    3.4\n    3    0.0\n    Length: 4, dtype: float64\n\n    In [12]: pd.reset_option('use_inf_as_null')\n\n- Methods with the ``inplace`` option now all return ``None`` instead of the\n  calling object. E.g. code written like ``df = df.fillna(0, inplace=True)``\n  may stop working. To fix, simply delete the unnecessary variable assignment.\n\n- ``pandas.merge`` no longer sorts the group keys (``sort=False``) by\n  default. This was done for performance reasons: the group-key sorting is\n  often one of the more expensive parts of the computation and is often\n  unnecessary.\n\n- The default column names for a file with no header have been changed to the\n  integers ``0`` through ``N - 1``. This is to create consistency with the\n  DataFrame constructor with no columns specified. The v0.9.0 behavior (names\n  ``X0``, ``X1``, ...) can be reproduced by specifying ``prefix='X'``:\n\n.. code-block:: ipython\n\n    In [6]: import io\n\n    In [7]: data = \"\"\"\n      ...: a,b,c\n      ...: 1,Yes,2\n      ...: 3,No,4\n      ...: \"\"\"\n      ...:\n\n    In [8]: print(data)\n\n        a,b,c\n        1,Yes,2\n        3,No,4\n\n    In [9]: pd.read_csv(io.StringIO(data), header=None)\n    Out[9]:\n           0    1  2\n    0      a    b  c\n    1      1  Yes  2\n    2      3   No  4\n\n    In [10]: pd.read_csv(io.StringIO(data), header=None, prefix=\"X\")\n    Out[10]:\n            X0   X1 X2\n    0       a    b  c\n    1       1  Yes  2\n    2       3   No  4\n\n- Values like ``'Yes'`` and ``'No'`` are not interpreted as boolean by default,\n  though this can be controlled by new ``true_values`` and ``false_values``\n  arguments:\n\n.. code-block:: ipython\n\n    In [4]: print(data)\n\n        a,b,c\n        1,Yes,2\n        3,No,4\n\n    In [5]: pd.read_csv(io.StringIO(data))\n    Out[5]:\n           a    b  c\n    0      1  Yes  2\n    1      3   No  4\n\n    In [6]: pd.read_csv(io.StringIO(data), true_values=[\"Yes\"], false_values=[\"No\"])\n    Out[6]:\n           a      b  c\n    0      1   True  2\n    1      3  False  4\n\n- The file parsers will not recognize non-string values arising from a\n  converter function as NA if passed in the ``na_values`` argument. It's better\n  to do post-processing using the ``replace`` function instead.\n\n- Calling ``fillna`` on Series or DataFrame with no arguments is no longer\n  valid code. You must either specify a fill value or an interpolation method:\n\n.. ipython:: python\n   :okwarning:\n\n   s = pd.Series([np.nan, 1.0, 2.0, np.nan, 4])\n   s\n   s.fillna(0)\n   s.fillna(method=\"pad\")\n\nConvenience methods ``ffill`` and  ``bfill`` have been added:\n\n.. ipython:: python\n\n   s.ffill()\n\n\n- ``Series.apply`` will now operate on a returned value from the applied\n  function, that is itself a series, and possibly upcast the result to a\n  DataFrame\n\n  .. ipython:: python\n\n      def f(x):\n          return pd.Series([x, x ** 2], index=[\"x\", \"x^2\"])\n\n\n      s = pd.Series(np.random.rand(5))\n      s\n      s.apply(f)\n\n- New API functions for working with pandas options (:issue:`2097`):\n\n  - ``get_option`` / ``set_option`` - get/set the value of an option. Partial\n    names are accepted.  - ``reset_option`` - reset one or more options to\n    their default value. Partial names are accepted.  - ``describe_option`` -\n    print a description of one or more options. When called with no\n    arguments. print all registered options.\n\n  Note: ``set_printoptions``/ ``reset_printoptions`` are now deprecated (but\n  functioning), the print options now live under \"display.XYZ\". For example:\n\n  .. ipython:: python\n\n     pd.get_option(\"display.max_rows\")\n\n- to_string() methods now always return unicode strings  (:issue:`2224`).\n\nNew features\n~~~~~~~~~~~~\n\nWide DataFrame printing\n~~~~~~~~~~~~~~~~~~~~~~~\n\nInstead of printing the summary information, pandas now splits the string\nrepresentation across multiple rows by default:\n\n.. ipython:: python\n\n   wide_frame = pd.DataFrame(np.random.randn(5, 16))\n\n   wide_frame\n\nThe old behavior of printing out summary information can be achieved via the\n'expand_frame_repr' print option:\n\n.. ipython:: python\n\n   pd.set_option(\"expand_frame_repr\", False)\n\n   wide_frame\n\n.. ipython:: python\n   :suppress:\n\n   pd.reset_option(\"expand_frame_repr\")\n\nThe width of each line can be changed via 'line_width' (80 by default):\n\n.. code-block:: python\n\n   pd.set_option(\"line_width\", 40)\n\n   wide_frame\n\n\nUpdated PyTables support\n~~~~~~~~~~~~~~~~~~~~~~~~\n\n:ref:`Docs <io.hdf5>` for PyTables ``Table`` format & several enhancements to the api. Here is a taste of what to expect.\n\n.. code-block:: ipython\n\n    In [41]: store = pd.HDFStore('store.h5')\n\n    In [42]: df = pd.DataFrame(np.random.randn(8, 3),\n       ....:                   index=pd.date_range('1/1/2000', periods=8),\n       ....:                   columns=['A', 'B', 'C'])\n\n    In [43]: df\n    Out[43]:\n                       A         B         C\n    2000-01-01 -2.036047  0.000830 -0.955697\n    2000-01-02 -0.898872 -0.725411  0.059904\n    2000-01-03 -0.449644  1.082900 -1.221265\n    2000-01-04  0.361078  1.330704  0.855932\n    2000-01-05 -1.216718  1.488887  0.018993\n    2000-01-06 -0.877046  0.045976  0.437274\n    2000-01-07 -0.567182 -0.888657 -0.556383\n    2000-01-08  0.655457  1.117949 -2.782376\n\n    [8 rows x 3 columns]\n\n     appending data frames\n    In [44]: df1 = df[0:4]\n\n    In [45]: df2 = df[4:]\n\n    In [46]: store.append('df', df1)\n\n    In [47]: store.append('df', df2)\n\n    In [48]: store\n    Out[48]:\n    <class 'pandas.io.pytables.HDFStore'>\n    File path: store.h5\n    /df            frame_table  (typ->appendable,nrows->8,ncols->3,indexers->[index])\n\n     selecting the entire store\n    In [49]: store.select('df')\n    Out[49]:\n                       A         B         C\n    2000-01-01 -2.036047  0.000830 -0.955697\n    2000-01-02 -0.898872 -0.725411  0.059904\n    2000-01-03 -0.449644  1.082900 -1.221265\n    2000-01-04  0.361078  1.330704  0.855932\n    2000-01-05 -1.216718  1.488887  0.018993\n    2000-01-06 -0.877046  0.045976  0.437274\n    2000-01-07 -0.567182 -0.888657 -0.556383\n    2000-01-08  0.655457  1.117949 -2.782376\n\n    [8 rows x 3 columns]\n\n.. code-block:: ipython\n\n    In [50]: wp = pd.Panel(np.random.randn(2, 5, 4), items=['Item1', 'Item2'],\n       ....:               major_axis=pd.date_range('1/1/2000', periods=5),\n       ....:               minor_axis=['A', 'B', 'C', 'D'])\n\n    In [51]: wp\n    Out[51]:\n    <class 'pandas.core.panel.Panel'>\n    Dimensions: 2 (items) x 5 (major_axis) x 4 (minor_axis)\n    Items axis: Item1 to Item2\n    Major_axis axis: 2000-01-01 00:00:00 to 2000-01-05 00:00:00\n    Minor_axis axis: A to D\n\n     storing a panel\n    In [52]: store.append('wp', wp)\n\n     selecting via A QUERY\n    In [53]: store.select('wp', [pd.Term('major_axis>20000102'),\n       ....:                     pd.Term('minor_axis', '=', ['A', 'B'])])\n       ....:\n    Out[53]:\n    <class 'pandas.core.panel.Panel'>\n    Dimensions: 2 (items) x 3 (major_axis) x 2 (minor_axis)\n    Items axis: Item1 to Item2\n    Major_axis axis: 2000-01-03 00:00:00 to 2000-01-05 00:00:00\n    Minor_axis axis: A to B\n\n     removing data from tables\n    In [54]: store.remove('wp', pd.Term('major_axis>20000103'))\n    Out[54]: 8\n\n    In [55]: store.select('wp')\n    Out[55]:\n    <class 'pandas.core.panel.Panel'>\n    Dimensions: 2 (items) x 3 (major_axis) x 4 (minor_axis)\n    Items axis: Item1 to Item2\n    Major_axis axis: 2000-01-01 00:00:00 to 2000-01-03 00:00:00\n    Minor_axis axis: A to D\n\n     deleting a store\n    In [56]: del store['df']\n\n    In [57]: store\n    Out[57]:\n    <class 'pandas.io.pytables.HDFStore'>\n    File path: store.h5\n    /wp            wide_table   (typ->appendable,nrows->12,ncols->2,indexers->[major_axis,minor_axis])\n\n\n**Enhancements**\n\n- added ability to hierarchical keys\n\n   .. code-block:: ipython\n\n        In [58]: store.put('foo/bar/bah', df)\n\n        In [59]: store.append('food/orange', df)\n\n        In [60]: store.append('food/apple', df)\n\n        In [61]: store\n        Out[61]:\n        <class 'pandas.io.pytables.HDFStore'>\n        File path: store.h5\n        /foo/bar/bah            frame        (shape->[8,3])\n        /food/apple             frame_table  (typ->appendable,nrows->8,ncols->3,indexers->[index])\n        /food/orange            frame_table  (typ->appendable,nrows->8,ncols->3,indexers->[index])\n        /wp                     wide_table   (typ->appendable,nrows->12,ncols->2,indexers->[major_axis,minor_axis])\n\n         remove all nodes under this level\n        In [62]: store.remove('food')\n\n        In [63]: store\n        Out[63]:\n        <class 'pandas.io.pytables.HDFStore'>\n        File path: store.h5\n        /foo/bar/bah            frame        (shape->[8,3])\n        /wp                     wide_table   (typ->appendable,nrows->12,ncols->2,indexers->[major_axis,minor_axis])\n\n- added mixed-dtype support!\n\n   .. code-block:: ipython\n\n        In [64]: df['string'] = 'string'\n\n        In [65]: df['int'] = 1\n\n        In [66]: store.append('df', df)\n\n        In [67]: df1 = store.select('df')\n\n        In [68]: df1\n        Out[68]:\n                           A         B         C  string  int\n        2000-01-01 -2.036047  0.000830 -0.955697  string    1\n        2000-01-02 -0.898872 -0.725411  0.059904  string    1\n        2000-01-03 -0.449644  1.082900 -1.221265  string    1\n        2000-01-04  0.361078  1.330704  0.855932  string    1\n        2000-01-05 -1.216718  1.488887  0.018993  string    1\n        2000-01-06 -0.877046  0.045976  0.437274  string    1\n        2000-01-07 -0.567182 -0.888657 -0.556383  string    1\n        2000-01-08  0.655457  1.117949 -2.782376  string    1\n\n        [8 rows x 5 columns]\n\n        In [69]: df1.get_dtype_counts()\n        Out[69]:\n        float64    3\n        int64      1\n        object     1\n        dtype: int64\n\n- performance improvements on table writing\n- support for arbitrarily indexed dimensions\n- ``SparseSeries`` now has a ``density`` property (:issue:`2384`)\n- enable ``Series.str.strip/lstrip/rstrip`` methods to take an input argument\n  to strip arbitrary characters (:issue:`2411`)\n- implement ``value_vars`` in ``melt`` to limit values to certain columns\n  and add ``melt`` to pandas namespace (:issue:`2412`)\n\n**Bug Fixes**\n\n- added ``Term`` method of specifying where conditions (:issue:`1996`).\n- ``del store['df']`` now call ``store.remove('df')`` for store deletion\n- deleting of consecutive rows is much faster than before\n- ``min_itemsize`` parameter can be specified in table creation to force a\n  minimum size for indexing columns (the previous implementation would set the\n  column size based on the first append)\n- indexing support via ``create_table_index`` (requires PyTables >= 2.3)\n  (:issue:`698`).\n- appending on a store would fail if the table was not first created via ``put``\n- fixed issue with missing attributes after loading a pickled dataframe (GH2431)\n- minor change to select and remove: require a table ONLY if where is also\n  provided (and not None)\n\n**Compatibility**\n\n0.10 of ``HDFStore`` is backwards compatible for reading tables created in a prior version of pandas,\nhowever, query terms using the prior (undocumented) methodology are unsupported. You must read in the entire\nfile and write it out using the new format to take advantage of the updates.\n\nN dimensional panels (experimental)\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\nAdding experimental support for Panel4D and factory functions to create n-dimensional named panels.\nHere is a taste of what to expect.\n\n.. code-block:: ipython\n\n  In [58]: p4d = Panel4D(np.random.randn(2, 2, 5, 4),\n    ....:       labels=['Label1','Label2'],\n    ....:       items=['Item1', 'Item2'],\n    ....:       major_axis=date_range('1/1/2000', periods=5),\n    ....:       minor_axis=['A', 'B', 'C', 'D'])\n    ....:\n\n  In [59]: p4d\n  Out[59]:\n  <class 'pandas.core.panelnd.Panel4D'>\n  Dimensions: 2 (labels) x 2 (items) x 5 (major_axis) x 4 (minor_axis)\n  Labels axis: Label1 to Label2\n  Items axis: Item1 to Item2\n  Major_axis axis: 2000-01-01 00:00:00 to 2000-01-05 00:00:00\n  Minor_axis axis: A to D\n\n\n\n\n\nSee the :ref:`full release notes\n<release>` or issue tracker\non GitHub for a complete list.\n\n\n.. _whatsnew_0.10.0.contributors:\n\nContributors\n~~~~~~~~~~~~\n\n.. contributors:: v0.9.0..v0.10.0\n\n\n.. _whatsnew_0131:\n\nVersion 0.13.1 (February 3, 2014)\n---------------------------------\n\n{{ header }}\n\n\n\nThis is a minor release from 0.13.0 and includes a small number of API changes, several new features,\nenhancements, and performance improvements along with a large number of bug fixes. We recommend that all\nusers upgrade to this version.\n\nHighlights include:\n\n- Added ``infer_datetime_format`` keyword to ``read_csv/to_datetime`` to allow speedups for homogeneously formatted datetimes.\n- Will intelligently limit display precision for datetime/timedelta formats.\n- Enhanced Panel :meth:`~pandas.Panel.apply` method.\n- Suggested tutorials in new :ref:`Tutorials<tutorials>` section.\n- Our pandas ecosystem is growing, We now feature related projects in a new `ecosystem page <https://pandas.pydata.org/community/ecosystem.html>`_ section.\n- Much work has been taking place on improving the docs, and a new :ref:`Contributing<contributing>` section has been added.\n- Even though it may only be of interest to devs, we <3 our new CI status page: `ScatterCI <http://scatterci.github.io/pydata/pandas>`__.\n\n.. warning::\n\n   0.13.1 fixes a bug that was caused by a combination of having numpy < 1.8, and doing\n   chained assignment on a string-like array. Please review :ref:`the docs<indexing.view_versus_copy>`,\n   chained indexing can have unexpected results and should generally be avoided.\n\n   This would previously segfault:\n\n   .. code-block:: python\n\n      df = pd.DataFrame({\"A\": np.array([\"foo\", \"bar\", \"bah\", \"foo\", \"bar\"])})\n      df[\"A\"].iloc[0] = np.nan\n\n   The recommended way to do this type of assignment is:\n\n   .. ipython:: python\n\n      df = pd.DataFrame({\"A\": np.array([\"foo\", \"bar\", \"bah\", \"foo\", \"bar\"])})\n      df.loc[0, \"A\"] = np.nan\n      df\n\nOutput formatting enhancements\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\n- df.info() view now display dtype info per column (:issue:`5682`)\n\n- df.info() now honors the option ``max_info_rows``, to disable null counts for large frames (:issue:`5974`)\n\n  .. ipython:: python\n\n     max_info_rows = pd.get_option(\"max_info_rows\")\n\n     df = pd.DataFrame(\n         {\n             \"A\": np.random.randn(10),\n             \"B\": np.random.randn(10),\n             \"C\": pd.date_range(\"20130101\", periods=10),\n         }\n     )\n     df.iloc[3:6, [0, 2]] = np.nan\n\n  .. ipython:: python\n\n      set to not display the null counts\n     pd.set_option(\"max_info_rows\", 0)\n     df.info()\n\n  .. ipython:: python\n\n      this is the default (same as in 0.13.0)\n     pd.set_option(\"max_info_rows\", max_info_rows)\n     df.info()\n\n- Add ``show_dimensions`` display option for the new DataFrame repr to control whether the dimensions print.\n\n  .. ipython:: python\n\n      df = pd.DataFrame([[1, 2], [3, 4]])\n      pd.set_option(\"show_dimensions\", False)\n      df\n\n      pd.set_option(\"show_dimensions\", True)\n      df\n\n- The ``ArrayFormatter`` for ``datetime`` and ``timedelta64`` now intelligently\n  limit precision based on the values in the array (:issue:`3401`)\n\n  Previously output might look like:\n\n  ..   code-block:: text\n\n        age                 today               diff\n      0 2001-01-01 00:00:00 2013-04-19 00:00:00 4491 days, 00:00:00\n      1 2004-06-01 00:00:00 2013-04-19 00:00:00 3244 days, 00:00:00\n\n  Now the output looks like:\n\n  .. ipython:: python\n\n     df = pd.DataFrame(\n         [pd.Timestamp(\"20010101\"), pd.Timestamp(\"20040601\")], columns=[\"age\"]\n     )\n     df[\"today\"] = pd.Timestamp(\"20130419\")\n     df[\"diff\"] = df[\"today\"] - df[\"age\"]\n     df\n\nAPI changes\n~~~~~~~~~~~\n\n- Add ``-NaN`` and ``-nan`` to the default set of NA values (:issue:`5952`).\n  See :ref:`NA Values <io.na_values>`.\n\n- Added ``Series.str.get_dummies`` vectorized string method (:issue:`6021`), to extract\n  dummy/indicator variables for separated string columns:\n\n  .. ipython:: python\n\n      s = pd.Series([\"a\", \"a|b\", np.nan, \"a|c\"])\n      s.str.get_dummies(sep=\"|\")\n\n- Added the ``NDFrame.equals()`` method to compare if two NDFrames are\n  equal have equal axes, dtypes, and values. Added the\n  ``array_equivalent`` function to compare if two ndarrays are\n  equal. NaNs in identical locations are treated as\n  equal. (:issue:`5283`) See also :ref:`the docs<basics.equals>` for a motivating example.\n\n  .. code-block:: python\n\n      df = pd.DataFrame({\"col\": [\"foo\", 0, np.nan]})\n      df2 = pd.DataFrame({\"col\": [np.nan, 0, \"foo\"]}, index=[2, 1, 0])\n      df.equals(df2)\n      df.equals(df2.sort_index())\n\n- ``DataFrame.apply`` will use the ``reduce`` argument to determine whether a\n  ``Series`` or a ``DataFrame`` should be returned when the ``DataFrame`` is\n  empty (:issue:`6007`).\n\n  Previously, calling ``DataFrame.apply`` an empty ``DataFrame`` would return\n  either a ``DataFrame`` if there were no columns, or the function being\n  applied would be called with an empty ``Series`` to guess whether a\n  ``Series`` or ``DataFrame`` should be returned:\n\n  .. code-block:: ipython\n\n    In [32]: def applied_func(col):\n      ....:    print(\"Apply function being called with: \", col)\n      ....:    return col.sum()\n      ....:\n\n    In [33]: empty = DataFrame(columns=['a', 'b'])\n\n    In [34]: empty.apply(applied_func)\n    Apply function being called with:  Series([], Length: 0, dtype: float64)\n    Out[34]:\n    a   NaN\n    b   NaN\n    Length: 2, dtype: float64\n\n  Now, when ``apply`` is called on an empty ``DataFrame``: if the ``reduce``\n  argument is ``True`` a ``Series`` will returned, if it is ``False`` a\n  ``DataFrame`` will be returned, and if it is ``None`` (the default) the\n  function being applied will be called with an empty series to try and guess\n  the return type.\n\n  .. code-block:: ipython\n\n    In [35]: empty.apply(applied_func, reduce=True)\n    Out[35]:\n    a   NaN\n    b   NaN\n    Length: 2, dtype: float64\n\n    In [36]: empty.apply(applied_func, reduce=False)\n    Out[36]:\n    Empty DataFrame\n    Columns: [a, b]\n    Index: []\n\n    [0 rows x 2 columns]\n\n\nPrior version deprecations/changes\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\nThere are no announced changes in 0.13 or prior that are taking effect as of 0.13.1\n\nDeprecations\n~~~~~~~~~~~~\n\nThere are no deprecations of prior behavior in 0.13.1\n\nEnhancements\n~~~~~~~~~~~~\n\n- ``pd.read_csv`` and ``pd.to_datetime`` learned a new ``infer_datetime_format`` keyword which greatly\n  improves parsing perf in many cases. Thanks to lexual for suggesting and danbirken\n  for rapidly implementing. (:issue:`5490`, :issue:`6021`)\n\n  If ``parse_dates`` is enabled and this flag is set, pandas will attempt to\n  infer the format of the datetime strings in the columns, and if it can\n  be inferred, switch to a faster method of parsing them.  In some cases\n  this can increase the parsing speed by ~5-10x.\n\n  .. code-block:: python\n\n       Try to infer the format for the index column\n      df = pd.read_csv(\n          \"foo.csv\", index_col=0, parse_dates=True, infer_datetime_format=True\n      )\n\n- ``date_format`` and ``datetime_format`` keywords can now be specified when writing to ``excel``\n  files (:issue:`4133`)\n\n- ``MultiIndex.from_product`` convenience function for creating a MultiIndex from\n  the cartesian product of a set of iterables (:issue:`6055`):\n\n  .. ipython:: python\n\n      shades = [\"light\", \"dark\"]\n      colors = [\"red\", \"green\", \"blue\"]\n\n      pd.MultiIndex.from_product([shades, colors], names=[\"shade\", \"color\"])\n\n- Panel :meth:`~pandas.Panel.apply` will work on non-ufuncs. See :ref:`the docs<basics.apply>`.\n\n  .. code-block:: ipython\n\n      In [28]: import pandas._testing as tm\n\n      In [29]: panel = tm.makePanel(5)\n\n      In [30]: panel\n      Out[30]:\n      <class 'pandas.core.panel.Panel'>\n      Dimensions: 3 (items) x 5 (major_axis) x 4 (minor_axis)\n      Items axis: ItemA to ItemC\n      Major_axis axis: 2000-01-03 00:00:00 to 2000-01-07 00:00:00\n      Minor_axis axis: A to D\n\n      In [31]: panel['ItemA']\n      Out[31]:\n                         A         B         C         D\n      2000-01-03 -0.673690  0.577046 -1.344312 -1.469388\n      2000-01-04  0.113648 -1.715002  0.844885  0.357021\n      2000-01-05 -1.478427 -1.039268  1.075770 -0.674600\n      2000-01-06  0.524988 -0.370647 -0.109050 -1.776904\n      2000-01-07  0.404705 -1.157892  1.643563 -0.968914\n\n      [5 rows x 4 columns]\n\n  Specifying an ``apply`` that operates on a Series (to return a single element)\n\n  .. code-block:: ipython\n\n      In [32]: panel.apply(lambda x: x.dtype, axis='items')\n      Out[32]:\n                        A        B        C        D\n      2000-01-03  float64  float64  float64  float64\n      2000-01-04  float64  float64  float64  float64\n      2000-01-05  float64  float64  float64  float64\n      2000-01-06  float64  float64  float64  float64\n      2000-01-07  float64  float64  float64  float64\n\n      [5 rows x 4 columns]\n\n  A similar reduction type operation\n\n  .. code-block:: ipython\n\n      In [33]: panel.apply(lambda x: x.sum(), axis='major_axis')\n      Out[33]:\n            ItemA     ItemB     ItemC\n      A -1.108775 -1.090118 -2.984435\n      B -3.705764  0.409204  1.866240\n      C  2.110856  2.960500 -0.974967\n      D -4.532785  0.303202 -3.685193\n\n      [4 rows x 3 columns]\n\n  This is equivalent to\n\n  .. code-block:: ipython\n\n      In [34]: panel.sum('major_axis')\n      Out[34]:\n            ItemA     ItemB     ItemC\n      A -1.108775 -1.090118 -2.984435\n      B -3.705764  0.409204  1.866240\n      C  2.110856  2.960500 -0.974967\n      D -4.532785  0.303202 -3.685193\n\n      [4 rows x 3 columns]\n\n  A transformation operation that returns a Panel, but is computing\n  the z-score across the major_axis\n\n  .. code-block:: ipython\n\n      In [35]: result = panel.apply(lambda x: (x - x.mean()) / x.std(),\n        ....:                      axis='major_axis')\n        ....:\n\n      In [36]: result\n      Out[36]:\n      <class 'pandas.core.panel.Panel'>\n      Dimensions: 3 (items) x 5 (major_axis) x 4 (minor_axis)\n      Items axis: ItemA to ItemC\n      Major_axis axis: 2000-01-03 00:00:00 to 2000-01-07 00:00:00\n      Minor_axis axis: A to D\n\n      In [37]: result['ItemA']                            noqa E999\n      Out[37]:\n                        A         B         C         D\n      2000-01-03 -0.535778  1.500802 -1.506416 -0.681456\n      2000-01-04  0.397628 -1.108752  0.360481  1.529895\n      2000-01-05 -1.489811 -0.339412  0.557374  0.280845\n      2000-01-06  0.885279  0.421830 -0.453013 -1.053785\n      2000-01-07  0.742682 -0.474468  1.041575 -0.075499\n\n      [5 rows x 4 columns]\n\n- Panel :meth:`~pandas.Panel.apply` operating on cross-sectional slabs. (:issue:`1148`)\n\n  .. code-block:: ipython\n\n      In [38]: def f(x):\n         ....:     return ((x.T - x.mean(1)) / x.std(1)).T\n         ....:\n\n      In [39]: result = panel.apply(f, axis=['items', 'major_axis'])\n\n      In [40]: result\n      Out[40]:\n      <class 'pandas.core.panel.Panel'>\n      Dimensions: 4 (items) x 5 (major_axis) x 3 (minor_axis)\n      Items axis: A to D\n      Major_axis axis: 2000-01-03 00:00:00 to 2000-01-07 00:00:00\n      Minor_axis axis: ItemA to ItemC\n\n      In [41]: result.loc[:, :, 'ItemA']\n      Out[41]:\n                         A         B         C         D\n      2000-01-03  0.012922 -0.030874 -0.629546 -0.757034\n      2000-01-04  0.392053 -1.071665  0.163228  0.548188\n      2000-01-05 -1.093650 -0.640898  0.385734 -1.154310\n      2000-01-06  1.005446 -1.154593 -0.595615 -0.809185\n      2000-01-07  0.783051 -0.198053  0.919339 -1.052721\n\n      [5 rows x 4 columns]\n\n  This is equivalent to the following\n\n  .. code-block:: ipython\n\n      In [42]: result = pd.Panel({ax: f(panel.loc[:, :, ax]) for ax in panel.minor_axis})\n\n      In [43]: result\n      Out[43]:\n      <class 'pandas.core.panel.Panel'>\n      Dimensions: 4 (items) x 5 (major_axis) x 3 (minor_axis)\n      Items axis: A to D\n      Major_axis axis: 2000-01-03 00:00:00 to 2000-01-07 00:00:00\n      Minor_axis axis: ItemA to ItemC\n\n      In [44]: result.loc[:, :, 'ItemA']\n      Out[44]:\n                         A         B         C         D\n      2000-01-03  0.012922 -0.030874 -0.629546 -0.757034\n      2000-01-04  0.392053 -1.071665  0.163228  0.548188\n      2000-01-05 -1.093650 -0.640898  0.385734 -1.154310\n      2000-01-06  1.005446 -1.154593 -0.595615 -0.809185\n      2000-01-07  0.783051 -0.198053  0.919339 -1.052721\n\n      [5 rows x 4 columns]\n\nPerformance\n~~~~~~~~~~~\n\nPerformance improvements for 0.13.1\n\n- Series datetime/timedelta binary operations (:issue:`5801`)\n- DataFrame ``count/dropna`` for ``axis=1``\n- Series.str.contains now has a ``regex=False`` keyword which can be faster for plain (non-regex) string patterns. (:issue:`5879`)\n- Series.str.extract (:issue:`5944`)\n- ``dtypes/ftypes`` methods (:issue:`5968`)\n- indexing with object dtypes (:issue:`5968`)\n- ``DataFrame.apply`` (:issue:`6013`)\n- Regression in JSON IO (:issue:`5765`)\n- Index construction from Series (:issue:`6150`)\n\nExperimental\n~~~~~~~~~~~~\n\nThere are no experimental changes in 0.13.1\n\n.. _release.bug_fixes-0.13.1:\n\nBug fixes\n~~~~~~~~~\n\n- Bug in ``io.wb.get_countries`` not including all countries (:issue:`6008`)\n- Bug in Series replace with timestamp dict (:issue:`5797`)\n- read_csv/read_table now respects the ``prefix`` kwarg (:issue:`5732`).\n- Bug in selection with missing values via ``.ix`` from a duplicate indexed DataFrame failing (:issue:`5835`)\n- Fix issue of boolean comparison on empty DataFrames (:issue:`5808`)\n- Bug in isnull handling ``NaT`` in an object array (:issue:`5443`)\n- Bug in ``to_datetime`` when passed a ``np.nan`` or integer datelike and a format string (:issue:`5863`)\n- Bug in groupby dtype conversion with datetimelike (:issue:`5869`)\n- Regression in handling of empty Series as indexers to Series  (:issue:`5877`)\n- Bug in internal caching, related to (:issue:`5727`)\n- Testing bug in reading JSON/msgpack from a non-filepath on windows under py3 (:issue:`5874`)\n- Bug when assigning to .ix[tuple(...)] (:issue:`5896`)\n- Bug in fully reindexing a Panel (:issue:`5905`)\n- Bug in idxmin/max with object dtypes (:issue:`5914`)\n- Bug in ``BusinessDay`` when adding n days to a date not on offset when n>5 and n%5==0 (:issue:`5890`)\n- Bug in assigning to chained series with a series via ix (:issue:`5928`)\n- Bug in creating an empty DataFrame, copying, then assigning (:issue:`5932`)\n- Bug in DataFrame.tail with empty frame (:issue:`5846`)\n- Bug in propagating metadata on ``resample`` (:issue:`5862`)\n- Fixed string-representation of ``NaT`` to be \"NaT\" (:issue:`5708`)\n- Fixed string-representation for Timestamp to show nanoseconds if present (:issue:`5912`)\n- ``pd.match`` not returning passed sentinel\n- ``Panel.to_frame()`` no longer fails when ``major_axis`` is a\n  ``MultiIndex`` (:issue:`5402`).\n- Bug in ``pd.read_msgpack`` with inferring a ``DateTimeIndex`` frequency\n  incorrectly (:issue:`5947`)\n- Fixed ``to_datetime`` for array with both Tz-aware datetimes and ``NaT``'s  (:issue:`5961`)\n- Bug in rolling skew/kurtosis when passed a Series with bad data (:issue:`5749`)\n- Bug in scipy ``interpolate`` methods with a datetime index (:issue:`5975`)\n- Bug in NaT comparison if a mixed datetime/np.datetime64 with NaT were passed (:issue:`5968`)\n- Fixed bug with ``pd.concat`` losing dtype information if all inputs are empty (:issue:`5742`)\n- Recent changes in IPython cause warnings to be emitted when using previous versions\n  of pandas in QTConsole, now fixed. If you're using an older version and\n  need to suppress the warnings, see (:issue:`5922`).\n- Bug in merging ``timedelta`` dtypes (:issue:`5695`)\n- Bug in plotting.scatter_matrix function. Wrong alignment among diagonal\n  and off-diagonal plots, see (:issue:`5497`).\n- Regression in Series with a MultiIndex via ix (:issue:`6018`)\n- Bug in Series.xs with a MultiIndex (:issue:`6018`)\n- Bug in Series construction of mixed type with datelike and an integer (which should result in\n  object type and not automatic conversion) (:issue:`6028`)\n- Possible segfault when chained indexing with an object array under NumPy 1.7.1 (:issue:`6026`, :issue:`6056`)\n- Bug in setting using fancy indexing a single element with a non-scalar (e.g. a list),\n  (:issue:`6043`)\n- ``to_sql`` did not respect ``if_exists`` (:issue:`4110` :issue:`4304`)\n- Regression in ``.get(None)`` indexing from 0.12 (:issue:`5652`)\n- Subtle ``iloc`` indexing bug, surfaced in (:issue:`6059`)\n- Bug with insert of strings into DatetimeIndex (:issue:`5818`)\n- Fixed unicode bug in to_html/HTML repr (:issue:`6098`)\n- Fixed missing arg validation in get_options_data (:issue:`6105`)\n- Bug in assignment with duplicate columns in a frame where the locations\n  are a slice (e.g. next to each other) (:issue:`6120`)\n- Bug in propagating _ref_locs during construction of a DataFrame with dups\n  index/columns (:issue:`6121`)\n- Bug in ``DataFrame.apply`` when using mixed datelike reductions (:issue:`6125`)\n- Bug in ``DataFrame.append`` when appending a row with different columns (:issue:`6129`)\n- Bug in DataFrame construction with recarray and non-ns datetime dtype (:issue:`6140`)\n- Bug in ``.loc`` setitem indexing with a dataframe on rhs, multiple item setting, and\n  a datetimelike (:issue:`6152`)\n- Fixed a bug in ``query``/``eval`` during lexicographic string comparisons (:issue:`6155`).\n- Fixed a bug in ``query`` where the index of a single-element ``Series`` was\n  being thrown away (:issue:`6148`).\n- Bug in ``HDFStore`` on appending a dataframe with MultiIndexed columns to\n  an existing table (:issue:`6167`)\n- Consistency with dtypes in setting an empty DataFrame (:issue:`6171`)\n- Bug in selecting on a MultiIndex ``HDFStore`` even in the presence of under\n  specified column spec (:issue:`6169`)\n- Bug in ``nanops.var`` with ``ddof=1`` and 1 elements would sometimes return ``inf``\n  rather than ``nan`` on some platforms (:issue:`6136`)\n- Bug in Series and DataFrame bar plots ignoring the ``use_index`` keyword (:issue:`6209`)\n- Bug in groupby with mixed str/int under python3 fixed; ``argsort`` was failing (:issue:`6212`)\n\n.. _whatsnew_0.13.1.contributors:\n\nContributors\n~~~~~~~~~~~~\n\n.. contributors:: v0.13.0..v0.13.1\n\n\n.. _whatsnew_0180:\n\nVersion 0.18.0 (March 13, 2016)\n-------------------------------\n\n{{ header }}\n\n\nThis is a major release from 0.17.1 and includes a small number of API changes, several new features,\nenhancements, and performance improvements along with a large number of bug fixes. We recommend that all\nusers upgrade to this version.\n\n.. warning::\n\n   pandas >= 0.18.0 no longer supports compatibility with Python version 2.6\n   and 3.3 (:issue:`7718`, :issue:`11273`)\n\n.. warning::\n\n   ``numexpr`` version 2.4.4 will now show a warning and not be used as a computation back-end for pandas because of some buggy behavior. This does not affect other versions (>= 2.1 and >= 2.4.6). (:issue:`12489`)\n\nHighlights include:\n\n- Moving and expanding window functions are now methods on Series and DataFrame,\n  similar to ``.groupby``, see :ref:`here <whatsnew_0180.enhancements.moments>`.\n- Adding support for a ``RangeIndex`` as a specialized form of the ``Int64Index``\n  for memory savings, see :ref:`here <whatsnew_0180.enhancements.rangeindex>`.\n- API breaking change to the ``.resample`` method to make it more ``.groupby``\n  like, see :ref:`here <whatsnew_0180.breaking.resample>`.\n- Removal of support for positional indexing with floats, which was deprecated\n  since 0.14.0. This will now raise a ``TypeError``, see :ref:`here <whatsnew_0180.float_indexers>`.\n- The ``.to_xarray()`` function has been added for compatibility with the\n  `xarray package <http://xarray.pydata.org/en/stable/>`__, see :ref:`here <whatsnew_0180.enhancements.xarray>`.\n- The ``read_sas`` function has been enhanced to read ``sas7bdat`` files, see :ref:`here <whatsnew_0180.enhancements.sas>`.\n- Addition of the :ref:`.str.extractall() method <whatsnew_0180.enhancements.extract>`,\n  and API changes to the :ref:`.str.extract() method <whatsnew_0180.enhancements.extract>`\n  and :ref:`.str.cat() method <whatsnew_0180.enhancements.strcat>`.\n- ``pd.test()`` top-level nose test runner is available (:issue:`4327`).\n\nCheck the :ref:`API Changes <whatsnew_0180.api_breaking>` and :ref:`deprecations <whatsnew_0180.deprecations>` before updating.\n\n.. contents:: What's new in v0.18.0\n    :local:\n    :backlinks: none\n\n.. _whatsnew_0180.enhancements:\n\nNew features\n~~~~~~~~~~~~\n\n.. _whatsnew_0180.enhancements.moments:\n\nWindow functions are now methods\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nWindow functions have been refactored to be methods on ``Series/DataFrame`` objects, rather than top-level functions, which are now deprecated. This allows these window-type functions, to have a similar API to that of ``.groupby``. See the full documentation :ref:`here <window.overview>` (:issue:`11603`, :issue:`12373`)\n\n\n.. ipython:: python\n\n   np.random.seed(1234)\n   df = pd.DataFrame({'A': range(10), 'B': np.random.randn(10)})\n   df\n\nPrevious behavior:\n\n.. code-block:: ipython\n\n   In [8]: pd.rolling_mean(df, window=3)\n           FutureWarning: pd.rolling_mean is deprecated for DataFrame and will be removed in a future version, replace with\n                          DataFrame.rolling(window=3,center=False).mean()\n   Out[8]:\n       A         B\n   0 NaN       NaN\n   1 NaN       NaN\n   2   1  0.237722\n   3   2 -0.023640\n   4   3  0.133155\n   5   4 -0.048693\n   6   5  0.342054\n   7   6  0.370076\n   8   7  0.079587\n   9   8 -0.954504\n\nNew behavior:\n\n.. ipython:: python\n\n   r = df.rolling(window=3)\n\nThese show a descriptive repr\n\n.. ipython:: python\n\n   r\nwith tab-completion of available methods and properties.\n\n.. code-block:: ipython\n\n   In [9]: r.<TAB>   noqa E225, E999\n   r.A           r.agg         r.apply       r.count       r.exclusions  r.max         r.median      r.name        r.skew        r.sum\n   r.B           r.aggregate   r.corr        r.cov         r.kurt        r.mean        r.min         r.quantile    r.std         r.var\n\nThe methods operate on the ``Rolling`` object itself\n\n.. ipython:: python\n\n   r.mean()\n\nThey provide getitem accessors\n\n.. ipython:: python\n\n   r['A'].mean()\n\nAnd multiple aggregations\n\n.. ipython:: python\n\n   r.agg({'A': ['mean', 'std'],\n          'B': ['mean', 'std']})\n\n.. _whatsnew_0180.enhancements.rename:\n\nChanges to rename\n^^^^^^^^^^^^^^^^^\n\n``Series.rename`` and ``NDFrame.rename_axis`` can now take a scalar or list-like\nargument for altering the Series or axis *name*, in addition to their old behaviors of altering labels. (:issue:`9494`, :issue:`11965`)\n\n.. ipython:: python\n\n   s = pd.Series(np.random.randn(5))\n   s.rename('newname')\n\n.. ipython:: python\n\n   df = pd.DataFrame(np.random.randn(5, 2))\n   (df.rename_axis(\"indexname\")\n      .rename_axis(\"columns_name\", axis=\"columns\"))\n\nThe new functionality works well in method chains. Previously these methods only accepted functions or dicts mapping a *label* to a new label.\nThis continues to work as before for function or dict-like values.\n\n\n.. _whatsnew_0180.enhancements.rangeindex:\n\nRange Index\n^^^^^^^^^^^\n\nA ``RangeIndex`` has been added to the ``Int64Index`` sub-classes to support a memory saving alternative for common use cases. This has a similar implementation to the python ``range`` object (``xrange`` in python 2), in that it only stores the start, stop, and step values for the index. It will transparently interact with the user API, converting to ``Int64Index`` if needed.\n\nThis will now be the default constructed index for ``NDFrame`` objects, rather than previous an ``Int64Index``. (:issue:`939`, :issue:`12070`, :issue:`12071`, :issue:`12109`, :issue:`12888`)\n\nPrevious behavior:\n\n.. code-block:: ipython\n\n   In [3]: s = pd.Series(range(1000))\n\n   In [4]: s.index\n   Out[4]:\n   Int64Index([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,\n               ...\n               990, 991, 992, 993, 994, 995, 996, 997, 998, 999], dtype='int64', length=1000)\n\n   In [6]: s.index.nbytes\n   Out[6]: 8000\n\n\nNew behavior:\n\n.. ipython:: python\n\n   s = pd.Series(range(1000))\n   s.index\n   s.index.nbytes\n\n.. _whatsnew_0180.enhancements.extract:\n\nChanges to str.extract\n^^^^^^^^^^^^^^^^^^^^^^\n\nThe :ref:`.str.extract <text.extract>` method takes a regular\nexpression with capture groups, finds the first match in each subject\nstring, and returns the contents of the capture groups\n(:issue:`11386`).\n\nIn v0.18.0, the ``expand`` argument was added to\n``extract``.\n\n- ``expand=False``: it returns a ``Series``, ``Index``, or ``DataFrame``, depending on the subject and regular expression pattern (same behavior as pre-0.18.0).\n- ``expand=True``: it always returns a ``DataFrame``, which is more consistent and less confusing from the perspective of a user.\n\nCurrently the default is ``expand=None`` which gives a ``FutureWarning`` and uses ``expand=False``. To avoid this warning, please explicitly specify ``expand``.\n\n.. code-block:: ipython\n\n   In [1]: pd.Series(['a1', 'b2', 'c3']).str.extract(r'[ab](\\d)', expand=None)\n   FutureWarning: currently extract(expand=None) means expand=False (return Index/Series/DataFrame)\n   but in a future version of pandas this will be changed to expand=True (return DataFrame)\n\n   Out[1]:\n   0      1\n   1      2\n   2    NaN\n   dtype: object\n\nExtracting a regular expression with one group returns a Series if\n``expand=False``.\n\n.. ipython:: python\n\n   pd.Series(['a1', 'b2', 'c3']).str.extract(r'[ab](\\d)', expand=False)\n\nIt returns a ``DataFrame`` with one column if ``expand=True``.\n\n.. ipython:: python\n\n   pd.Series(['a1', 'b2', 'c3']).str.extract(r'[ab](\\d)', expand=True)\n\nCalling on an ``Index`` with a regex with exactly one capture group\nreturns an ``Index`` if ``expand=False``.\n\n.. ipython:: python\n\n   s = pd.Series([\"a1\", \"b2\", \"c3\"], [\"A11\", \"B22\", \"C33\"])\n   s.index\n   s.index.str.extract(\"(?P<letter>[a-zA-Z])\", expand=False)\n\nIt returns a ``DataFrame`` with one column if ``expand=True``.\n\n.. ipython:: python\n\n   s.index.str.extract(\"(?P<letter>[a-zA-Z])\", expand=True)\n\nCalling on an ``Index`` with a regex with more than one capture group\nraises ``ValueError`` if ``expand=False``.\n\n.. code-block:: python\n\n    >>> s.index.str.extract(\"(?P<letter>[a-zA-Z])([0-9]+)\", expand=False)\n    ValueError: only one regex group is supported with Index\n\nIt returns a ``DataFrame`` if ``expand=True``.\n\n.. ipython:: python\n\n   s.index.str.extract(\"(?P<letter>[a-zA-Z])([0-9]+)\", expand=True)\n\nIn summary, ``extract(expand=True)`` always returns a ``DataFrame``\nwith a row for every subject string, and a column for every capture\ngroup.\n\n.. _whatsnew_0180.enhancements.extractall:\n\nAddition of str.extractall\n^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nThe :ref:`.str.extractall <text.extractall>` method was added\n(:issue:`11386`).  Unlike ``extract``, which returns only the first\nmatch.\n\n.. ipython:: python\n\n   s = pd.Series([\"a1a2\", \"b1\", \"c1\"], [\"A\", \"B\", \"C\"])\n   s\n   s.str.extract(r\"(?P<letter>[ab])(?P<digit>\\d)\", expand=False)\n\nThe ``extractall`` method returns all matches.\n\n.. ipython:: python\n\n   s.str.extractall(r\"(?P<letter>[ab])(?P<digit>\\d)\")\n\n.. _whatsnew_0180.enhancements.strcat:\n\nChanges to str.cat\n^^^^^^^^^^^^^^^^^^\n\nThe method ``.str.cat()`` concatenates the members of a ``Series``. Before, if ``NaN`` values were present in the Series, calling ``.str.cat()`` on it would return ``NaN``, unlike the rest of the ``Series.str.*`` API. This behavior has been amended to ignore ``NaN`` values by default. (:issue:`11435`).\n\nA new, friendlier ``ValueError`` is added to protect against the mistake of supplying the ``sep`` as an arg, rather than as a kwarg. (:issue:`11334`).\n\n.. ipython:: python\n\n    pd.Series(['a', 'b', np.nan, 'c']).str.cat(sep=' ')\n    pd.Series(['a', 'b', np.nan, 'c']).str.cat(sep=' ', na_rep='?')\n\n.. code-block:: ipython\n\n    In [2]: pd.Series(['a', 'b', np.nan, 'c']).str.cat(' ')\n    ValueError: Did you mean to supply a ``sep`` keyword?\n\n\n.. _whatsnew_0180.enhancements.rounding:\n\nDatetimelike rounding\n^^^^^^^^^^^^^^^^^^^^^\n\n``DatetimeIndex``, ``Timestamp``, ``TimedeltaIndex``, ``Timedelta`` have gained the ``.round()``, ``.floor()`` and ``.ceil()`` method for datetimelike rounding, flooring and ceiling. (:issue:`4314`, :issue:`11963`)\n\nNaive datetimes\n\n.. ipython:: python\n\n   dr = pd.date_range('20130101 09:12:56.1234', periods=3)\n   dr\n   dr.round('s')\n\n    Timestamp scalar\n   dr[0]\n   dr[0].round('10s')\n\nTz-aware are rounded, floored and ceiled in local times\n\n.. ipython:: python\n\n   dr = dr.tz_localize('US/Eastern')\n   dr\n   dr.round('s')\n\nTimedeltas\n\n.. ipython:: python\n\n   t = pd.timedelta_range('1 days 2 hr 13 min 45 us', periods=3, freq='d')\n   t\n   t.round('10min')\n\n    Timedelta scalar\n   t[0]\n   t[0].round('2h')\n\n\nIn addition, ``.round()``, ``.floor()`` and ``.ceil()`` will be available through the ``.dt`` accessor of ``Series``.\n\n.. ipython:: python\n\n   s = pd.Series(dr)\n   s\n   s.dt.round('D')\n\nFormatting of integers in FloatIndex\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nIntegers in ``FloatIndex``, e.g. 1., are now formatted with a decimal point and a ``0`` digit, e.g. ``1.0`` (:issue:`11713`)\nThis change not only affects the display to the console, but also the output of IO methods like ``.to_csv`` or ``.to_html``.\n\nPrevious behavior:\n\n.. code-block:: ipython\n\n   In [2]: s = pd.Series([1, 2, 3], index=np.arange(3.))\n\n   In [3]: s\n   Out[3]:\n   0    1\n   1    2\n   2    3\n   dtype: int64\n\n   In [4]: s.index\n   Out[4]: Float64Index([0.0, 1.0, 2.0], dtype='float64')\n\n   In [5]: print(s.to_csv(path=None))\n   0,1\n   1,2\n   2,3\n\n\nNew behavior:\n\n.. ipython:: python\n\n   s = pd.Series([1, 2, 3], index=np.arange(3.))\n   s\n   s.index\n   print(s.to_csv(path_or_buf=None, header=False))\n\nChanges to dtype assignment behaviors\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nWhen a DataFrame's slice is updated with a new slice of the same dtype, the dtype of the DataFrame will now remain the same. (:issue:`10503`)\n\nPrevious behavior:\n\n.. code-block:: ipython\n\n   In [5]: df = pd.DataFrame({'a': [0, 1, 1],\n                              'b': pd.Series([100, 200, 300], dtype='uint32')})\n\n   In [7]: df.dtypes\n   Out[7]:\n   a     int64\n   b    uint32\n   dtype: object\n\n   In [8]: ix = df['a'] == 1\n\n   In [9]: df.loc[ix, 'b'] = df.loc[ix, 'b']\n\n   In [11]: df.dtypes\n   Out[11]:\n   a    int64\n   b    int64\n   dtype: object\n\nNew behavior:\n\n.. ipython:: python\n\n   df = pd.DataFrame({'a': [0, 1, 1],\n                      'b': pd.Series([100, 200, 300], dtype='uint32')})\n   df.dtypes\n   ix = df['a'] == 1\n   df.loc[ix, 'b'] = df.loc[ix, 'b']\n   df.dtypes\n\nWhen a DataFrame's integer slice is partially updated with a new slice of floats that could potentially be down-casted to integer without losing precision, the dtype of the slice will be set to float instead of integer.\n\nPrevious behavior:\n\n.. code-block:: ipython\n\n   In [4]: df = pd.DataFrame(np.array(range(1,10)).reshape(3,3),\n                             columns=list('abc'),\n                             index=[[4,4,8], [8,10,12]])\n\n   In [5]: df\n   Out[5]:\n         a  b  c\n   4 8   1  2  3\n     10  4  5  6\n   8 12  7  8  9\n\n   In [7]: df.ix[4, 'c'] = np.array([0., 1.])\n\n   In [8]: df\n   Out[8]:\n         a  b  c\n   4 8   1  2  0\n     10  4  5  1\n   8 12  7  8  9\n\nNew behavior:\n\n.. ipython:: python\n\n   df = pd.DataFrame(np.array(range(1,10)).reshape(3,3),\n                     columns=list('abc'),\n                     index=[[4,4,8], [8,10,12]])\n   df\n   df.loc[4, 'c'] = np.array([0., 1.])\n   df\n\n.. _whatsnew_0180.enhancements.xarray:\n\nMethod to_xarray\n^^^^^^^^^^^^^^^^\n\nIn a future version of pandas, we will be deprecating ``Panel`` and other > 2 ndim objects. In order to provide for continuity,\nall ``NDFrame`` objects have gained the ``.to_xarray()`` method in order to convert to ``xarray`` objects, which has\na pandas-like interface for > 2 ndim. (:issue:`11972`)\n\nSee the `xarray full-documentation here <http://xarray.pydata.org/en/stable/>`__.\n\n.. code-block:: ipython\n\n   In [1]: p = Panel(np.arange(2*3*4).reshape(2,3,4))\n\n   In [2]: p.to_xarray()\n   Out[2]:\n   <xarray.DataArray (items: 2, major_axis: 3, minor_axis: 4)>\n   array([[[ 0,  1,  2,  3],\n           [ 4,  5,  6,  7],\n           [ 8,  9, 10, 11]],\n\n          [[12, 13, 14, 15],\n           [16, 17, 18, 19],\n           [20, 21, 22, 23]]])\n   Coordinates:\n     * items       (items) int64 0 1\n     * major_axis  (major_axis) int64 0 1 2\n     * minor_axis  (minor_axis) int64 0 1 2 3\n\nLatex representation\n^^^^^^^^^^^^^^^^^^^^\n\n``DataFrame`` has gained a ``._repr_latex_()`` method in order to allow for conversion to latex in a ipython/jupyter notebook using nbconvert. (:issue:`11778`)\n\nNote that this must be activated by setting the option ``pd.display.latex.repr=True`` (:issue:`12182`)\n\nFor example, if you have a jupyter notebook you plan to convert to latex using nbconvert, place the statement ``pd.display.latex.repr=True`` in the first cell to have the contained DataFrame output also stored as latex.\n\nThe options ``display.latex.escape`` and ``display.latex.longtable`` have also been added to the configuration and are used automatically by the ``to_latex``\nmethod. See the :ref:`available options docs <options.available>` for more info.\n\n.. _whatsnew_0180.enhancements.sas:\n\n``pd.read_sas()`` changes\n^^^^^^^^^^^^^^^^^^^^^^^^^\n\n``read_sas`` has gained the ability to read SAS7BDAT files, including compressed files.  The files can be read in entirety, or incrementally.  For full details see :ref:`here <io.sas>`. (:issue:`4052`)\n\n.. _whatsnew_0180.enhancements.other:\n\nOther enhancements\n^^^^^^^^^^^^^^^^^^\n\n- Handle truncated floats in SAS xport files (:issue:`11713`)\n- Added option to hide index in ``Series.to_string`` (:issue:`11729`)\n- ``read_excel`` now supports s3 urls of the format ``s3://bucketname/filename`` (:issue:`11447`)\n- add support for ``AWS_S3_HOST`` env variable when reading from s3 (:issue:`12198`)\n- A simple version of ``Panel.round()`` is now implemented (:issue:`11763`)\n- For Python 3.x, ``round(DataFrame)``, ``round(Series)``, ``round(Panel)`` will work (:issue:`11763`)\n- ``sys.getsizeof(obj)`` returns the memory usage of a pandas object, including the\n  values it contains (:issue:`11597`)\n- ``Series`` gained an ``is_unique`` attribute (:issue:`11946`)\n- ``DataFrame.quantile`` and ``Series.quantile`` now accept ``interpolation`` keyword (:issue:`10174`).\n- Added ``DataFrame.style.format`` for more flexible formatting of cell values (:issue:`11692`)\n- ``DataFrame.select_dtypes`` now allows the ``np.float16`` type code (:issue:`11990`)\n- ``pivot_table()`` now accepts most iterables for the ``values`` parameter (:issue:`12017`)\n- Added Google ``BigQuery`` service account authentication support, which enables authentication on remote servers. (:issue:`11881`, :issue:`12572`). For further details see `here <https://pandas-gbq.readthedocs.io/en/latest/intro.html>`__\n- ``HDFStore`` is now iterable: ``for k in store`` is equivalent to ``for k in store.keys()`` (:issue:`12221`).\n- Add missing methods/fields to ``.dt`` for ``Period`` (:issue:`8848`)\n- The entire code base has been ``PEP``-ified (:issue:`12096`)\n\n.. _whatsnew_0180.api_breaking:\n\nBackwards incompatible API changes\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\n- the leading white spaces have been removed from the output of ``.to_string(index=False)`` method (:issue:`11833`)\n- the ``out`` parameter has been removed from the ``Series.round()`` method. (:issue:`11763`)\n- ``DataFrame.round()`` leaves non-numeric columns unchanged in its return, rather than raises. (:issue:`11885`)\n- ``DataFrame.head(0)`` and ``DataFrame.tail(0)`` return empty frames, rather than ``self``.  (:issue:`11937`)\n- ``Series.head(0)`` and ``Series.tail(0)`` return empty series, rather than ``self``.  (:issue:`11937`)\n- ``to_msgpack`` and ``read_msgpack`` encoding now defaults to ``'utf-8'``. (:issue:`12170`)\n- the order of keyword arguments to text file parsing functions (``.read_csv()``, ``.read_table()``, ``.read_fwf()``) changed to group related arguments. (:issue:`11555`)\n- ``NaTType.isoformat`` now returns the string ``'NaT`` to allow the result to\n  be passed to the constructor of ``Timestamp``. (:issue:`12300`)\n\nNaT and Timedelta operations\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n``NaT`` and ``Timedelta`` have expanded arithmetic operations, which are extended to ``Series``\narithmetic where applicable.  Operations defined for ``datetime64[ns]`` or ``timedelta64[ns]``\nare now also defined for ``NaT`` (:issue:`11564`).\n\n``NaT`` now supports arithmetic operations with integers and floats.\n\n.. ipython:: python\n\n   pd.NaT * 1\n   pd.NaT * 1.5\n   pd.NaT / 2\n   pd.NaT * np.nan\n\n``NaT`` defines more arithmetic operations with ``datetime64[ns]`` and ``timedelta64[ns]``.\n\n.. ipython:: python\n\n   pd.NaT / pd.NaT\n   pd.Timedelta('1s') / pd.NaT\n\n``NaT`` may represent either a ``datetime64[ns]`` null or a ``timedelta64[ns]`` null.\nGiven the ambiguity, it is treated as a ``timedelta64[ns]``, which allows more operations\nto succeed.\n\n.. ipython:: python\n\n   pd.NaT + pd.NaT\n\n    same as\n   pd.Timedelta('1s') + pd.Timedelta('1s')\n\nas opposed to\n\n.. code-block:: ipython\n\n   In [3]: pd.Timestamp('19900315') + pd.Timestamp('19900315')\n   TypeError: unsupported operand type(s) for +: 'Timestamp' and 'Timestamp'\n\nHowever, when wrapped in a ``Series`` whose ``dtype`` is ``datetime64[ns]`` or ``timedelta64[ns]``,\nthe ``dtype`` information is respected.\n\n.. code-block:: ipython\n\n   In [1]: pd.Series([pd.NaT], dtype='<M8[ns]') + pd.Series([pd.NaT], dtype='<M8[ns]')\n   TypeError: can only operate on a datetimes for subtraction,\n              but the operator [__add__] was passed\n\n.. ipython:: python\n\n   pd.Series([pd.NaT], dtype='<m8[ns]') + pd.Series([pd.NaT], dtype='<m8[ns]')\n\n``Timedelta`` division by ``floats`` now works.\n\n.. ipython:: python\n\n   pd.Timedelta('1s') / 2.0\n\nSubtraction by ``Timedelta`` in a ``Series`` by a ``Timestamp`` works (:issue:`11925`)\n\n.. ipython:: python\n\n   ser = pd.Series(pd.timedelta_range('1 day', periods=3))\n   ser\n   pd.Timestamp('2012-01-01') - ser\n\n\n``NaT.isoformat()`` now returns ``'NaT'``. This change allows\n``pd.Timestamp`` to rehydrate any timestamp like object from its isoformat\n(:issue:`12300`).\n\nChanges to msgpack\n^^^^^^^^^^^^^^^^^^\n\nForward incompatible changes in ``msgpack`` writing format were made over 0.17.0 and 0.18.0; older versions of pandas cannot read files packed by newer versions (:issue:`12129`, :issue:`10527`)\n\nBugs in ``to_msgpack`` and ``read_msgpack`` introduced in 0.17.0 and fixed in 0.18.0, caused files packed in Python 2 unreadable by Python 3 (:issue:`12142`). The following table describes the backward and forward compat of msgpacks.\n\n.. warning::\n\n   +----------------------+------------------------+\n   | Packed with          | Can be unpacked with   |\n   +======================+========================+\n   | pre-0.17 / Python 2  | any                    |\n   +----------------------+------------------------+\n   | pre-0.17 / Python 3  | any                    |\n   +----------------------+------------------------+\n   | 0.17 / Python 2      | - ==0.17 / Python 2    |\n   |                      | - >=0.18 / any Python  |\n   +----------------------+------------------------+\n   | 0.17 / Python 3      | >=0.18 / any Python    |\n   +----------------------+------------------------+\n   | 0.18                 | >= 0.18                |\n   +----------------------+------------------------+\n\n\n   0.18.0 is backward-compatible for reading files packed by older versions, except for files packed with 0.17 in Python 2, in which case only they can only be unpacked in Python 2.\n\nSignature change for .rank\n^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n``Series.rank`` and ``DataFrame.rank`` now have the same signature (:issue:`11759`)\n\nPrevious signature\n\n.. code-block:: ipython\n\n   In [3]: pd.Series([0,1]).rank(method='average', na_option='keep',\n                                 ascending=True, pct=False)\n   Out[3]:\n   0    1\n   1    2\n   dtype: float64\n\n   In [4]: pd.DataFrame([0,1]).rank(axis=0, numeric_only=None,\n                                    method='average', na_option='keep',\n                                    ascending=True, pct=False)\n   Out[4]:\n      0\n   0  1\n   1  2\n\nNew signature\n\n.. ipython:: python\n\n   pd.Series([0,1]).rank(axis=0, method='average', numeric_only=False,\n                         na_option='keep', ascending=True, pct=False)\n   pd.DataFrame([0,1]).rank(axis=0, method='average', numeric_only=False,\n                            na_option='keep', ascending=True, pct=False)\n\n\nBug in QuarterBegin with n=0\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nIn previous versions, the behavior of the QuarterBegin offset was inconsistent\ndepending on the date when the ``n`` parameter was 0. (:issue:`11406`)\n\nThe general semantics of anchored offsets for ``n=0`` is to not move the date\nwhen it is an anchor point (e.g., a quarter start date), and otherwise roll\nforward to the next anchor point.\n\n.. ipython:: python\n\n   d = pd.Timestamp('2014-02-01')\n   d\n   d + pd.offsets.QuarterBegin(n=0, startingMonth=2)\n   d + pd.offsets.QuarterBegin(n=0, startingMonth=1)\n\nFor the ``QuarterBegin`` offset in previous versions, the date would be rolled\n*backwards* if date was in the same month as the quarter start date.\n\n.. code-block:: ipython\n\n   In [3]: d = pd.Timestamp('2014-02-15')\n\n   In [4]: d + pd.offsets.QuarterBegin(n=0, startingMonth=2)\n   Out[4]: Timestamp('2014-02-01 00:00:00')\n\nThis behavior has been corrected in version 0.18.0, which is consistent with\nother anchored offsets like ``MonthBegin`` and ``YearBegin``.\n\n.. ipython:: python\n\n   d = pd.Timestamp('2014-02-15')\n   d + pd.offsets.QuarterBegin(n=0, startingMonth=2)\n\n.. _whatsnew_0180.breaking.resample:\n\nResample API\n^^^^^^^^^^^^\n\nLike the change in the window functions API :ref:`above <whatsnew_0180.enhancements.moments>`, ``.resample(...)`` is changing to have a more groupby-like API. (:issue:`11732`, :issue:`12702`, :issue:`12202`, :issue:`12332`, :issue:`12334`, :issue:`12348`, :issue:`12448`).\n\n.. ipython:: python\n\n   np.random.seed(1234)\n   df = pd.DataFrame(np.random.rand(10,4),\n                     columns=list('ABCD'),\n                     index=pd.date_range('2010-01-01 09:00:00',\n                                         periods=10, freq='s'))\n   df\n\n\n**Previous API**:\n\nYou would write a resampling operation that immediately evaluates. If a ``how`` parameter was not provided, it\nwould default to ``how='mean'``.\n\n.. code-block:: ipython\n\n   In [6]: df.resample('2s')\n   Out[6]:\n                            A         B         C         D\n   2010-01-01 09:00:00  0.485748  0.447351  0.357096  0.793615\n   2010-01-01 09:00:02  0.820801  0.794317  0.364034  0.531096\n   2010-01-01 09:00:04  0.433985  0.314582  0.424104  0.625733\n   2010-01-01 09:00:06  0.624988  0.609738  0.633165  0.612452\n   2010-01-01 09:00:08  0.510470  0.534317  0.573201  0.806949\n\nYou could also specify a ``how`` directly\n\n.. code-block:: ipython\n\n   In [7]: df.resample('2s', how='sum')\n   Out[7]:\n                            A         B         C         D\n   2010-01-01 09:00:00  0.971495  0.894701  0.714192  1.587231\n   2010-01-01 09:00:02  1.641602  1.588635  0.728068  1.062191\n   2010-01-01 09:00:04  0.867969  0.629165  0.848208  1.251465\n   2010-01-01 09:00:06  1.249976  1.219477  1.266330  1.224904\n   2010-01-01 09:00:08  1.020940  1.068634  1.146402  1.613897\n\n**New API**:\n\nNow, you can write ``.resample(..)`` as a 2-stage operation like ``.groupby(...)``, which\nyields a ``Resampler``.\n\n.. ipython:: python\n   :okwarning:\n\n   r = df.resample('2s')\n   r\n\nDownsampling\n\"\"\"\"\"\"\"\"\"\"\"\"\n\nYou can then use this object to perform operations.\nThese are downsampling operations (going from a higher frequency to a lower one).\n\n.. ipython:: python\n\n   r.mean()\n\n.. ipython:: python\n\n   r.sum()\n\nFurthermore, resample now supports ``getitem`` operations to perform the resample on specific columns.\n\n.. ipython:: python\n\n   r[['A','C']].mean()\n\nand ``.aggregate`` type operations.\n\n.. ipython:: python\n\n   r.agg({'A' : 'mean', 'B' : 'sum'})\n\nThese accessors can of course, be combined\n\n.. ipython:: python\n\n   r[['A','B']].agg(['mean','sum'])\n\nUpsampling\n\"\"\"\"\"\"\"\"\"\"\n\n.. currentmodule:: pandas.tseries.resample\n\nUpsampling operations take you from a lower frequency to a higher frequency. These are now\nperformed with the ``Resampler`` objects with :meth:`~Resampler.backfill`,\n:meth:`~Resampler.ffill`, :meth:`~Resampler.fillna` and :meth:`~Resampler.asfreq` methods.\n\n.. code-block:: ipython\n\n   In [89]: s = pd.Series(np.arange(5, dtype='int64'),\n                 index=pd.date_range('2010-01-01', periods=5, freq='Q'))\n\n   In [90]: s\n   Out[90]:\n   2010-03-31    0\n   2010-06-30    1\n   2010-09-30    2\n   2010-12-31    3\n   2011-03-31    4\n   Freq: Q-DEC, Length: 5, dtype: int64\n\nPreviously\n\n.. code-block:: ipython\n\n   In [6]: s.resample('M', fill_method='ffill')\n   Out[6]:\n   2010-03-31    0\n   2010-04-30    0\n   2010-05-31    0\n   2010-06-30    1\n   2010-07-31    1\n   2010-08-31    1\n   2010-09-30    2\n   2010-10-31    2\n   2010-11-30    2\n   2010-12-31    3\n   2011-01-31    3\n   2011-02-28    3\n   2011-03-31    4\n   Freq: M, dtype: int64\n\nNew API\n\n.. code-block:: ipython\n\n   In [91]: s.resample('M').ffill()\n   Out[91]:\n   2010-03-31    0\n   2010-04-30    0\n   2010-05-31    0\n   2010-06-30    1\n   2010-07-31    1\n   2010-08-31    1\n   2010-09-30    2\n   2010-10-31    2\n   2010-11-30    2\n   2010-12-31    3\n   2011-01-31    3\n   2011-02-28    3\n   2011-03-31    4\n   Freq: M, Length: 13, dtype: int64\n\n.. note::\n\n   In the new API, you can either downsample OR upsample. The prior implementation would allow you to pass an aggregator function (like ``mean``) even though you were upsampling, providing a bit of confusion.\n\nPrevious API will work but with deprecations\n\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\n\n.. warning::\n\n   This new API for resample includes some internal changes for the prior-to-0.18.0 API, to work with a deprecation warning in most cases, as the resample operation returns a deferred object. We can intercept operations and just do what the (pre 0.18.0) API did (with a warning). Here is a typical use case:\n\n   .. code-block:: ipython\n\n      In [4]: r = df.resample('2s')\n\n      In [6]: r*10\n      pandas/tseries/resample.py:80: FutureWarning: .resample() is now a deferred operation\n      use .resample(...).mean() instead of .resample(...)\n\n      Out[6]:\n                            A         B         C         D\n      2010-01-01 09:00:00  4.857476  4.473507  3.570960  7.936154\n      2010-01-01 09:00:02  8.208011  7.943173  3.640340  5.310957\n      2010-01-01 09:00:04  4.339846  3.145823  4.241039  6.257326\n      2010-01-01 09:00:06  6.249881  6.097384  6.331650  6.124518\n      2010-01-01 09:00:08  5.104699  5.343172  5.732009  8.069486\n\n   However, getting and assignment operations directly on a ``Resampler`` will raise a ``ValueError``:\n\n   .. code-block:: ipython\n\n      In [7]: r.iloc[0] = 5\n      ValueError: .resample() is now a deferred operation\n      use .resample(...).mean() instead of .resample(...)\n\n   There is a situation where the new API can not perform all the operations when using original code.\n   This code is intending to resample every 2s, take the ``mean`` AND then take the ``min`` of those results.\n\n   .. code-block:: ipython\n\n      In [4]: df.resample('2s').min()\n      Out[4]:\n      A    0.433985\n      B    0.314582\n      C    0.357096\n      D    0.531096\n      dtype: float64\n\n   The new API will:\n\n   .. ipython:: python\n\n      df.resample('2s').min()\n\n   The good news is the return dimensions will differ between the new API and the old API, so this should loudly raise\n   an exception.\n\n   To replicate the original operation\n\n   .. ipython:: python\n\n      df.resample('2s').mean().min()\n\nChanges to eval\n^^^^^^^^^^^^^^^\n\nIn prior versions, new columns assignments in an ``eval`` expression resulted\nin an inplace change to the ``DataFrame``. (:issue:`9297`, :issue:`8664`, :issue:`10486`)\n\n.. ipython:: python\n\n   df = pd.DataFrame({'a': np.linspace(0, 10, 5), 'b': range(5)})\n   df\n\n.. ipython:: python\n   :suppress:\n\n   df.eval('c = a + b', inplace=True)\n\n.. code-block:: ipython\n\n   In [12]: df.eval('c = a + b')\n   FutureWarning: eval expressions containing an assignment currentlydefault to operating inplace.\n   This will change in a future version of pandas, use inplace=True to avoid this warning.\n\n   In [13]: df\n   Out[13]:\n         a  b     c\n   0   0.0  0   0.0\n   1   2.5  1   3.5\n   2   5.0  2   7.0\n   3   7.5  3  10.5\n   4  10.0  4  14.0\n\nIn version 0.18.0, a new ``inplace`` keyword was added to choose whether the\nassignment should be done inplace or return a copy.\n\n.. ipython:: python\n\n   df\n   df.eval('d = c - b', inplace=False)\n   df\n   df.eval('d = c - b', inplace=True)\n   df\n\n.. warning::\n\n   For backwards compatibility, ``inplace`` defaults to ``True`` if not specified.\n   This will change in a future version of pandas. If your code depends on an\n   inplace assignment you should update to explicitly set ``inplace=True``\n\nThe ``inplace`` keyword parameter was also added the ``query`` method.\n\n.. ipython:: python\n\n   df.query('a > 5')\n   df.query('a > 5', inplace=True)\n   df\n\n.. warning::\n\n   Note that the default value for ``inplace`` in a ``query``\n   is ``False``, which is consistent with prior versions.\n\n``eval`` has also been updated to allow multi-line expressions for multiple\nassignments.  These expressions will be evaluated one at a time in order.  Only\nassignments are valid for multi-line expressions.\n\n.. ipython:: python\n\n   df\n   df.eval(\"\"\"\n   e = d + a\n   f = e - 22\n   g = f / 2.0\"\"\", inplace=True)\n   df\n\n\n.. _whatsnew_0180.api:\n\nOther API changes\n^^^^^^^^^^^^^^^^^\n- ``DataFrame.between_time`` and ``Series.between_time`` now only parse a fixed set of time strings. Parsing of date strings is no longer supported and raises a ``ValueError``. (:issue:`11818`)\n\n  .. code-block:: ipython\n\n     In [107]: s = pd.Series(range(10), pd.date_range('2015-01-01', freq='H', periods=10))\n\n     In [108]: s.between_time(\"7:00am\", \"9:00am\")\n     Out[108]:\n     2015-01-01 07:00:00    7\n     2015-01-01 08:00:00    8\n     2015-01-01 09:00:00    9\n     Freq: H, Length: 3, dtype: int64\n\n  This will now raise.\n\n  .. code-block:: ipython\n\n     In [2]: s.between_time('20150101 07:00:00','20150101 09:00:00')\n     ValueError: Cannot convert arg ['20150101 07:00:00'] to a time.\n\n- ``.memory_usage()`` now includes values in the index, as does memory_usage in ``.info()`` (:issue:`11597`)\n- ``DataFrame.to_latex()`` now supports non-ascii encodings (eg ``utf-8``) in Python 2 with the parameter ``encoding`` (:issue:`7061`)\n- ``pandas.merge()`` and ``DataFrame.merge()`` will show a specific error message when trying to merge with an object that is not of type ``DataFrame`` or a subclass (:issue:`12081`)\n- ``DataFrame.unstack`` and ``Series.unstack`` now take ``fill_value`` keyword to allow direct replacement of missing values when an unstack results in missing values in the resulting ``DataFrame``. As an added benefit, specifying ``fill_value`` will preserve the data type of the original stacked data.  (:issue:`9746`)\n- As part of the new API for :ref:`window functions <whatsnew_0180.enhancements.moments>` and :ref:`resampling <whatsnew_0180.breaking.resample>`, aggregation functions have been clarified, raising more informative error messages on invalid aggregations. (:issue:`9052`). A full set of examples are presented in :ref:`groupby <groupby.aggregate>`.\n- Statistical functions for ``NDFrame`` objects (like ``sum(), mean(), min()``) will now raise if non-numpy-compatible arguments are passed in for ``**kwargs`` (:issue:`12301`)\n- ``.to_latex`` and ``.to_html`` gain a ``decimal`` parameter like ``.to_csv``; the default is ``'.'`` (:issue:`12031`)\n- More helpful error message when constructing a ``DataFrame`` with empty data but with indices (:issue:`8020`)\n- ``.describe()`` will now properly handle bool dtype as a categorical (:issue:`6625`)\n- More helpful error message with an invalid ``.transform`` with user defined input (:issue:`10165`)\n- Exponentially weighted functions now allow specifying alpha directly (:issue:`10789`) and raise ``ValueError`` if parameters violate ``0 < alpha <= 1`` (:issue:`12492`)\n\n.. _whatsnew_0180.deprecations:\n\nDeprecations\n^^^^^^^^^^^^\n\n.. _whatsnew_0180.window_deprecations:\n\n- The functions ``pd.rolling_*``, ``pd.expanding_*``, and ``pd.ewm*`` are deprecated and replaced by the corresponding method call. Note that\n  the new suggested syntax includes all of the arguments (even if default) (:issue:`11603`)\n\n  .. code-block:: ipython\n\n     In [1]: s = pd.Series(range(3))\n\n     In [2]: pd.rolling_mean(s,window=2,min_periods=1)\n             FutureWarning: pd.rolling_mean is deprecated for Series and\n                  will be removed in a future version, replace with\n                  Series.rolling(min_periods=1,window=2,center=False).mean()\n     Out[2]:\n             0    0.0\n             1    0.5\n             2    1.5\n             dtype: float64\n\n     In [3]: pd.rolling_cov(s, s, window=2)\n             FutureWarning: pd.rolling_cov is deprecated for Series and\n                  will be removed in a future version, replace with\n                  Series.rolling(window=2).cov(other=<Series>)\n     Out[3]:\n             0    NaN\n             1    0.5\n             2    0.5\n             dtype: float64\n\n- The ``freq`` and ``how`` arguments to the ``.rolling``, ``.expanding``, and ``.ewm`` (new) functions are deprecated, and will be removed in a future version. You can simply resample the input prior to creating a window function. (:issue:`11603`).\n\n  For example, instead of ``s.rolling(window=5,freq='D').max()`` to get the max value on a rolling 5 Day window, one could use ``s.resample('D').mean().rolling(window=5).max()``, which first resamples the data to daily data, then provides a rolling 5 day window.\n\n- ``pd.tseries.frequencies.get_offset_name`` function is deprecated. Use offset's ``.freqstr`` property as alternative (:issue:`11192`)\n- ``pandas.stats.fama_macbeth`` routines are deprecated and will be removed in a future version (:issue:`6077`)\n- ``pandas.stats.ols``, ``pandas.stats.plm`` and ``pandas.stats.var`` routines are deprecated and will be removed in a future version (:issue:`6077`)\n- show a ``FutureWarning`` rather than a ``DeprecationWarning`` on using long-time deprecated syntax in ``HDFStore.select``, where the ``where`` clause is not a string-like (:issue:`12027`)\n\n- The ``pandas.options.display.mpl_style`` configuration has been deprecated\n  and will be removed in a future version of pandas. This functionality\n  is better handled by matplotlib's `style sheets`_ (:issue:`11783`).\n\n\n.. _style sheets: http://matplotlib.org/users/style_sheets.html\n\n.. _whatsnew_0180.float_indexers:\n\nRemoval of deprecated float indexers\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nIn :issue:`4892` indexing with floating point numbers on a non-``Float64Index`` was deprecated (in version 0.14.0).\nIn 0.18.0, this deprecation warning is removed and these will now raise a ``TypeError``. (:issue:`12165`, :issue:`12333`)\n\n.. ipython:: python\n\n   s = pd.Series([1, 2, 3], index=[4, 5, 6])\n   s\n   s2 = pd.Series([1, 2, 3], index=list('abc'))\n   s2\n\nPrevious behavior:\n\n.. code-block:: ipython\n\n    this is label indexing\n   In [2]: s[5.0]\n   FutureWarning: scalar indexers for index type Int64Index should be integers and not floating point\n   Out[2]: 2\n\n    this is positional indexing\n   In [3]: s.iloc[1.0]\n   FutureWarning: scalar indexers for index type Int64Index should be integers and not floating point\n   Out[3]: 2\n\n    this is label indexing\n   In [4]: s.loc[5.0]\n   FutureWarning: scalar indexers for index type Int64Index should be integers and not floating point\n   Out[4]: 2\n\n    .ix would coerce 1.0 to the positional 1, and index\n   In [5]: s2.ix[1.0] = 10\n   FutureWarning: scalar indexers for index type Index should be integers and not floating point\n\n   In [6]: s2\n   Out[6]:\n   a     1\n   b    10\n   c     3\n   dtype: int64\n\nNew behavior:\n\nFor iloc, getting & setting via a float scalar will always raise.\n\n.. code-block:: ipython\n\n   In [3]: s.iloc[2.0]\n   TypeError: cannot do label indexing on <class 'pandas.indexes.numeric.Int64Index'> with these indexers [2.0] of <type 'float'>\n\nOther indexers will coerce to a like integer for both getting and setting. The ``FutureWarning`` has been dropped for ``.loc``, ``.ix`` and ``[]``.\n\n.. ipython:: python\n\n   s[5.0]\n   s.loc[5.0]\n\nand setting\n\n.. ipython:: python\n\n   s_copy = s.copy()\n   s_copy[5.0] = 10\n   s_copy\n   s_copy = s.copy()\n   s_copy.loc[5.0] = 10\n   s_copy\n\nPositional setting with ``.ix`` and a float indexer will ADD this value to the index, rather than previously setting the value by position.\n\n.. code-block:: ipython\n\n   In [3]: s2.ix[1.0] = 10\n   In [4]: s2\n   Out[4]:\n   a       1\n   b       2\n   c       3\n   1.0    10\n   dtype: int64\n\nSlicing will also coerce integer-like floats to integers for a non-``Float64Index``.\n\n.. ipython:: python\n\n   s.loc[5.0:6]\n\nNote that for floats that are NOT coercible to ints, the label based bounds will be excluded\n\n.. ipython:: python\n\n   s.loc[5.1:6]\n\nFloat indexing on a ``Float64Index`` is unchanged.\n\n.. ipython:: python\n\n   s = pd.Series([1, 2, 3], index=np.arange(3.))\n   s[1.0]\n   s[1.0:2.5]\n\n.. _whatsnew_0180.prior_deprecations:\n\nRemoval of prior version deprecations/changes\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n- Removal of ``rolling_corr_pairwise`` in favor of ``.rolling().corr(pairwise=True)`` (:issue:`4950`)\n- Removal of ``expanding_corr_pairwise`` in favor of ``.expanding().corr(pairwise=True)`` (:issue:`4950`)\n- Removal of ``DataMatrix`` module. This was not imported into the pandas namespace in any event (:issue:`12111`)\n- Removal of ``cols`` keyword in favor of ``subset`` in ``DataFrame.duplicated()`` and ``DataFrame.drop_duplicates()`` (:issue:`6680`)\n- Removal of the ``read_frame`` and ``frame_query`` (both aliases for ``pd.read_sql``)\n  and ``write_frame`` (alias of ``to_sql``) functions in the ``pd.io.sql`` namespace,\n  deprecated since 0.14.0 (:issue:`6292`).\n- Removal of the ``order`` keyword from ``.factorize()`` (:issue:`6930`)\n\n.. _whatsnew_0180.performance:\n\nPerformance improvements\n~~~~~~~~~~~~~~~~~~~~~~~~\n\n- Improved performance of ``andrews_curves`` (:issue:`11534`)\n- Improved huge ``DatetimeIndex``, ``PeriodIndex`` and ``TimedeltaIndex``'s ops performance including ``NaT`` (:issue:`10277`)\n- Improved performance of ``pandas.concat`` (:issue:`11958`)\n- Improved performance of ``StataReader`` (:issue:`11591`)\n- Improved performance in construction of ``Categoricals`` with ``Series`` of datetimes containing ``NaT`` (:issue:`12077`)\n\n\n- Improved performance of ISO 8601 date parsing for dates without separators (:issue:`11899`), leading zeros (:issue:`11871`) and with white space preceding the time zone (:issue:`9714`)\n\n\n\n\n.. _whatsnew_0180.bug_fixes:\n\nBug fixes\n~~~~~~~~~\n\n- Bug in ``GroupBy.size`` when data-frame is empty. (:issue:`11699`)\n- Bug in ``Period.end_time`` when a multiple of time period is requested (:issue:`11738`)\n- Regression in ``.clip`` with tz-aware datetimes (:issue:`11838`)\n- Bug in ``date_range`` when the boundaries fell on the frequency (:issue:`11804`, :issue:`12409`)\n- Bug in consistency of passing nested dicts to ``.groupby(...).agg(...)`` (:issue:`9052`)\n- Accept unicode in ``Timedelta`` constructor (:issue:`11995`)\n- Bug in value label reading for ``StataReader`` when reading incrementally (:issue:`12014`)\n- Bug in vectorized ``DateOffset`` when ``n`` parameter is ``0`` (:issue:`11370`)\n- Compat for numpy 1.11 w.r.t. ``NaT`` comparison changes (:issue:`12049`)\n- Bug in ``read_csv`` when reading from a ``StringIO`` in threads (:issue:`11790`)\n- Bug in not treating ``NaT`` as a missing value in datetimelikes when factorizing & with ``Categoricals`` (:issue:`12077`)\n- Bug in getitem when the values of a ``Series`` were tz-aware (:issue:`12089`)\n- Bug in ``Series.str.get_dummies`` when one of the variables was 'name' (:issue:`12180`)\n- Bug in ``pd.concat`` while concatenating tz-aware NaT series. (:issue:`11693`, :issue:`11755`, :issue:`12217`)\n- Bug in ``pd.read_stata`` with version <= 108 files (:issue:`12232`)\n- Bug in ``Series.resample`` using a frequency of ``Nano`` when the index is a ``DatetimeIndex`` and contains non-zero nanosecond parts (:issue:`12037`)\n- Bug in resampling with ``.nunique`` and a sparse index (:issue:`12352`)\n- Removed some compiler warnings (:issue:`12471`)\n- Work around compat issues with ``boto`` in python 3.5 (:issue:`11915`)\n- Bug in ``NaT`` subtraction from ``Timestamp`` or ``DatetimeIndex`` with timezones (:issue:`11718`)\n- Bug in subtraction of ``Series`` of a single tz-aware ``Timestamp`` (:issue:`12290`)\n- Use compat iterators in PY2 to support ``.next()`` (:issue:`12299`)\n- Bug in ``Timedelta.round`` with negative values (:issue:`11690`)\n- Bug in ``.loc`` against ``CategoricalIndex`` may result in normal ``Index`` (:issue:`11586`)\n- Bug in ``DataFrame.info`` when duplicated column names exist (:issue:`11761`)\n- Bug in ``.copy`` of datetime tz-aware objects (:issue:`11794`)\n- Bug in ``Series.apply`` and ``Series.map`` where ``timedelta64`` was not boxed (:issue:`11349`)\n- Bug in ``DataFrame.set_index()`` with tz-aware ``Series`` (:issue:`12358`)\n\n\n\n- Bug in subclasses of ``DataFrame`` where ``AttributeError`` did not propagate (:issue:`11808`)\n- Bug groupby on tz-aware data where selection not returning ``Timestamp`` (:issue:`11616`)\n- Bug in ``pd.read_clipboard`` and ``pd.to_clipboard`` functions not supporting Unicode; upgrade included ``pyperclip`` to v1.5.15 (:issue:`9263`)\n- Bug in ``DataFrame.query`` containing an assignment (:issue:`8664`)\n\n- Bug in ``from_msgpack`` where ``__contains__()`` fails for columns of the unpacked ``DataFrame``, if the ``DataFrame`` has object columns. (:issue:`11880`)\n- Bug in ``.resample`` on categorical data with ``TimedeltaIndex`` (:issue:`12169`)\n\n\n- Bug in timezone info lost when broadcasting scalar datetime to ``DataFrame`` (:issue:`11682`)\n- Bug in ``Index`` creation from ``Timestamp`` with mixed tz coerces to UTC (:issue:`11488`)\n- Bug in ``to_numeric`` where it does not raise if input is more than one dimension (:issue:`11776`)\n- Bug in parsing timezone offset strings with non-zero minutes (:issue:`11708`)\n- Bug in ``df.plot`` using incorrect colors for bar plots under matplotlib 1.5+ (:issue:`11614`)\n- Bug in the ``groupby`` ``plot`` method when using keyword arguments (:issue:`11805`).\n- Bug in ``DataFrame.duplicated`` and ``drop_duplicates`` causing spurious matches when setting ``keep=False`` (:issue:`11864`)\n- Bug in ``.loc`` result with duplicated key may have ``Index`` with incorrect dtype (:issue:`11497`)\n- Bug in ``pd.rolling_median`` where memory allocation failed even with sufficient memory (:issue:`11696`)\n- Bug in ``DataFrame.style`` with spurious zeros (:issue:`12134`)\n- Bug in ``DataFrame.style`` with integer columns not starting at 0 (:issue:`12125`)\n- Bug in ``.style.bar`` may not rendered properly using specific browser (:issue:`11678`)\n- Bug in rich comparison of ``Timedelta`` with a ``numpy.array`` of ``Timedelta`` that caused an infinite recursion (:issue:`11835`)\n- Bug in ``DataFrame.round`` dropping column index name (:issue:`11986`)\n- Bug in ``df.replace`` while replacing value in mixed dtype ``Dataframe`` (:issue:`11698`)\n- Bug in ``Index`` prevents copying name of passed ``Index``, when a new name is not provided (:issue:`11193`)\n- Bug in ``read_excel`` failing to read any non-empty sheets when empty sheets exist and ``sheetname=None`` (:issue:`11711`)\n- Bug in ``read_excel`` failing to raise ``NotImplemented`` error when keywords ``parse_dates`` and ``date_parser`` are provided (:issue:`11544`)\n- Bug in ``read_sql`` with ``pymysql`` connections failing to return chunked data (:issue:`11522`)\n- Bug in ``.to_csv`` ignoring formatting parameters ``decimal``, ``na_rep``, ``float_format`` for float indexes (:issue:`11553`)\n- Bug in ``Int64Index`` and ``Float64Index`` preventing the use of the modulo operator (:issue:`9244`)\n- Bug in ``MultiIndex.drop`` for not lexsorted MultiIndexes (:issue:`12078`)\n\n- Bug in ``DataFrame`` when masking an empty ``DataFrame`` (:issue:`11859`)\n\n\n- Bug in ``.plot`` potentially modifying the ``colors`` input when the number of columns didn't match the number of series provided (:issue:`12039`).\n- Bug in ``Series.plot`` failing when index has a ``CustomBusinessDay`` frequency (:issue:`7222`).\n- Bug in ``.to_sql`` for ``datetime.time`` values with sqlite fallback (:issue:`8341`)\n- Bug in ``read_excel`` failing to read data with one column when ``squeeze=True`` (:issue:`12157`)\n- Bug in ``read_excel`` failing to read one empty column (:issue:`12292`, :issue:`9002`)\n- Bug in ``.groupby`` where a ``KeyError`` was not raised for a wrong column if there was only one row in the dataframe (:issue:`11741`)\n- Bug in ``.read_csv`` with dtype specified on empty data producing an error (:issue:`12048`)\n- Bug in ``.read_csv`` where strings like ``'2E'`` are treated as valid floats (:issue:`12237`)\n- Bug in building *pandas* with debugging symbols (:issue:`12123`)\n\n\n- Removed ``millisecond`` property of ``DatetimeIndex``. This would always raise a ``ValueError`` (:issue:`12019`).\n- Bug in ``Series`` constructor with read-only data (:issue:`11502`)\n- Removed ``pandas._testing.choice()``.  Should use ``np.random.choice()``, instead. (:issue:`12386`)\n- Bug in ``.loc`` setitem indexer preventing the use of a TZ-aware DatetimeIndex (:issue:`12050`)\n- Bug in ``.style`` indexes and MultiIndexes not appearing (:issue:`11655`)\n- Bug in ``to_msgpack`` and ``from_msgpack`` which did not correctly serialize or deserialize ``NaT`` (:issue:`12307`).\n- Bug in ``.skew`` and ``.kurt`` due to roundoff error for highly similar values (:issue:`11974`)\n- Bug in ``Timestamp`` constructor where microsecond resolution was lost if HHMMSS were not separated with ':' (:issue:`10041`)\n- Bug in ``buffer_rd_bytes`` src->buffer could be freed more than once if reading failed, causing a segfault (:issue:`12098`)\n\n- Bug in ``crosstab`` where arguments with non-overlapping indexes would return a ``KeyError`` (:issue:`10291`)\n\n- Bug in ``DataFrame.apply`` in which reduction was not being prevented for cases in which ``dtype`` was not a numpy dtype (:issue:`12244`)\n- Bug when initializing categorical series with a scalar value. (:issue:`12336`)\n- Bug when specifying a UTC ``DatetimeIndex`` by setting ``utc=True`` in ``.to_datetime`` (:issue:`11934`)\n- Bug when increasing the buffer size of CSV reader in ``read_csv`` (:issue:`12494`)\n- Bug when setting columns of a ``DataFrame`` with duplicate column names (:issue:`12344`)\n\n\n.. _whatsnew_0.18.0.contributors:\n\nContributors\n~~~~~~~~~~~~\n\n.. contributors:: v0.17.1..v0.18.0\n\n\n.. _whatsnew_0120:\n\nVersion 0.12.0 (July 24, 2013)\n------------------------------\n\n{{ header }}\n\n\nThis is a major release from 0.11.0 and includes several new features and\nenhancements along with a large number of bug fixes.\n\nHighlights include a consistent I/O API naming scheme, routines to read html,\nwrite MultiIndexes to csv files, read & write STATA data files, read & write JSON format\nfiles, Python 3 support for ``HDFStore``, filtering of groupby expressions via ``filter``, and a\nrevamped ``replace`` routine that accepts regular expressions.\n\nAPI changes\n~~~~~~~~~~~\n\n  - The I/O API is now much more consistent with a set of top level ``reader`` functions\n    accessed like ``pd.read_csv()`` that generally return a ``pandas`` object.\n\n    * ``read_csv``\n    * ``read_excel``\n    * ``read_hdf``\n    * ``read_sql``\n    * ``read_json``\n    * ``read_html``\n    * ``read_stata``\n    * ``read_clipboard``\n\n    The corresponding ``writer`` functions are object methods that are accessed like ``df.to_csv()``\n\n    * ``to_csv``\n    * ``to_excel``\n    * ``to_hdf``\n    * ``to_sql``\n    * ``to_json``\n    * ``to_html``\n    * ``to_stata``\n    * ``to_clipboard``\n\n\n  - Fix modulo and integer division on Series,DataFrames to act similarly to ``float`` dtypes to return\n    ``np.nan`` or ``np.inf`` as appropriate (:issue:`3590`). This correct a numpy bug that treats ``integer``\n    and ``float`` dtypes differently.\n\n    .. ipython:: python\n\n        p = pd.DataFrame({\"first\": [4, 5, 8], \"second\": [0, 0, 3]})\n        p % 0\n        p % p\n        p / p\n        p / 0\n\n  - Add ``squeeze`` keyword to ``groupby`` to allow reduction from\n    DataFrame -> Series if groups are unique. This is a Regression from 0.10.1.\n    We are reverting back to the prior behavior. This means groupby will return the\n    same shaped objects whether the groups are unique or not. Revert this issue (:issue:`2893`)\n    with (:issue:`3596`).\n\n    .. code-block:: ipython\n\n        In [2]: df2 = pd.DataFrame([{\"val1\": 1, \"val2\": 20},\n           ...:                     {\"val1\": 1, \"val2\": 19},\n           ...:                     {\"val1\": 1, \"val2\": 27},\n           ...:                     {\"val1\": 1, \"val2\": 12}])\n\n        In [3]: def func(dataf):\n           ...:     return dataf[\"val2\"] - dataf[\"val2\"].mean()\n           ...:\n\n        In [4]:  squeezing the result frame to a series (because we have unique groups)\n           ...: df2.groupby(\"val1\", squeeze=True).apply(func)\n        Out[4]:\n        0    0.5\n        1   -0.5\n        2    7.5\n        3   -7.5\n        Name: 1, dtype: float64\n\n        In [5]:  no squeezing (the default, and behavior in 0.10.1)\n           ...: df2.groupby(\"val1\").apply(func)\n        Out[5]:\n        val2    0    1    2    3\n        val1\n        1     0.5 -0.5  7.5 -7.5\n\n  - Raise on ``iloc`` when boolean indexing with a label based indexer mask\n    e.g. a boolean Series, even with integer labels, will raise. Since ``iloc``\n    is purely positional based, the labels on the Series are not alignable (:issue:`3631`)\n\n    This case is rarely used, and there are plenty of alternatives. This preserves the\n    ``iloc`` API to be *purely* positional based.\n\n    .. ipython:: python\n\n       df = pd.DataFrame(range(5), index=list(\"ABCDE\"), columns=[\"a\"])\n       mask = df.a % 2 == 0\n       mask\n\n        this is what you should use\n       df.loc[mask]\n\n        this will work as well\n       df.iloc[mask.values]\n\n    ``df.iloc[mask]`` will raise a ``ValueError``\n\n  - The ``raise_on_error`` argument to plotting functions is removed. Instead,\n    plotting functions raise a ``TypeError`` when the ``dtype`` of the object\n    is ``object`` to remind you to avoid ``object`` arrays whenever possible\n    and thus you should cast to an appropriate numeric dtype if you need to\n    plot something.\n\n  - Add ``colormap`` keyword to DataFrame plotting methods. Accepts either a\n    matplotlib colormap object (ie, matplotlib.cm.jet) or a string name of such\n    an object (ie, 'jet'). The colormap is sampled to select the color for each\n    column. Please see :ref:`visualization.colormaps` for more information.\n    (:issue:`3860`)\n\n  - ``DataFrame.interpolate()`` is now deprecated. Please use\n    ``DataFrame.fillna()`` and ``DataFrame.replace()`` instead. (:issue:`3582`,\n    :issue:`3675`, :issue:`3676`)\n\n  - the ``method`` and ``axis`` arguments of ``DataFrame.replace()`` are\n    deprecated\n\n  - ``DataFrame.replace`` 's ``infer_types`` parameter is removed and now\n    performs conversion by default. (:issue:`3907`)\n\n  - Add the keyword ``allow_duplicates`` to ``DataFrame.insert`` to allow a duplicate column\n    to be inserted if ``True``, default is ``False`` (same as prior to 0.12) (:issue:`3679`)\n  - Implement ``__nonzero__`` for ``NDFrame`` objects (:issue:`3691`, :issue:`3696`)\n\n  - IO api\n\n    - added top-level function ``read_excel`` to replace the following,\n      The original API is deprecated and will be removed in a future version\n\n      .. code-block:: python\n\n         from pandas.io.parsers import ExcelFile\n\n         xls = ExcelFile(\"path_to_file.xls\")\n         xls.parse(\"Sheet1\", index_col=None, na_values=[\"NA\"])\n\n      With\n\n      .. code-block:: python\n\n         import pandas as pd\n\n         pd.read_excel(\"path_to_file.xls\", \"Sheet1\", index_col=None, na_values=[\"NA\"])\n\n    - added top-level function ``read_sql`` that is equivalent to the following\n\n      .. code-block:: python\n\n         from pandas.io.sql import read_frame\n\n         read_frame(...)\n\n  - ``DataFrame.to_html`` and ``DataFrame.to_latex`` now accept a path for\n    their first argument (:issue:`3702`)\n\n  - Do not allow astypes on ``datetime64[ns]`` except to ``object``, and\n    ``timedelta64[ns]`` to ``object/int`` (:issue:`3425`)\n\n  - The behavior of ``datetime64`` dtypes has changed with respect to certain\n    so-called reduction operations (:issue:`3726`). The following operations now\n    raise a ``TypeError`` when performed on a ``Series`` and return an *empty*\n    ``Series`` when performed on a ``DataFrame`` similar to performing these\n    operations on, for example, a ``DataFrame`` of ``slice`` objects:\n\n    - sum, prod, mean, std, var, skew, kurt, corr, and cov\n\n  - ``read_html`` now defaults to ``None`` when reading, and falls back on\n    ``bs4`` + ``html5lib`` when lxml fails to parse. a list of parsers to try\n    until success is also valid\n\n  - The internal ``pandas`` class hierarchy has changed (slightly). The\n    previous ``PandasObject`` now is called ``PandasContainer`` and a new\n    ``PandasObject`` has become the base class for ``PandasContainer`` as well\n    as ``Index``, ``Categorical``, ``GroupBy``, ``SparseList``, and\n    ``SparseArray`` (+ their base classes). Currently, ``PandasObject``\n    provides string methods (from ``StringMixin``). (:issue:`4090`, :issue:`4092`)\n\n  - New ``StringMixin`` that, given a ``__unicode__`` method, gets python 2 and\n    python 3 compatible string methods (``__str__``, ``__bytes__``, and\n    ``__repr__``). Plus string safety throughout. Now employed in many places\n    throughout the pandas library. (:issue:`4090`, :issue:`4092`)\n\nIO enhancements\n~~~~~~~~~~~~~~~\n\n  - ``pd.read_html()`` can now parse HTML strings, files or urls and return\n    DataFrames, courtesy of cpcloud. (:issue:`3477`, :issue:`3605`, :issue:`3606`, :issue:`3616`).\n    It works with a *single* parser backend: BeautifulSoup4 + html5lib :ref:`See the docs<io.html>`\n\n    You can use ``pd.read_html()`` to read the output from ``DataFrame.to_html()`` like so\n\n    .. ipython:: python\n       :okwarning:\n\n        df = pd.DataFrame({\"a\": range(3), \"b\": list(\"abc\")})\n        print(df)\n        html = df.to_html()\n        alist = pd.read_html(html, index_col=0)\n        print(df == alist[0])\n\n    Note that ``alist`` here is a Python ``list`` so ``pd.read_html()`` and\n    ``DataFrame.to_html()`` are not inverses.\n\n    - ``pd.read_html()`` no longer performs hard conversion of date strings\n      (:issue:`3656`).\n\n    .. warning::\n\n      You may have to install an older version of BeautifulSoup4,\n      :ref:`See the installation docs<install.optional_dependencies>`\n\n  - Added module for reading and writing Stata files: ``pandas.io.stata`` (:issue:`1512`)\n    accessible via ``read_stata`` top-level function for reading,\n    and ``to_stata`` DataFrame method for writing, :ref:`See the docs<io.stata>`\n\n  - Added module for reading and writing json format files: ``pandas.io.json``\n    accessible via ``read_json`` top-level function for reading,\n    and ``to_json`` DataFrame method for writing, :ref:`See the docs<io.json>`\n    various issues (:issue:`1226`, :issue:`3804`, :issue:`3876`, :issue:`3867`, :issue:`1305`)\n\n  - ``MultiIndex`` column support for reading and writing csv format files\n\n    - The ``header`` option in ``read_csv`` now accepts a\n      list of the rows from which to read the index.\n\n    - The option, ``tupleize_cols`` can now be specified in both ``to_csv`` and\n      ``read_csv``, to provide compatibility for the pre 0.12 behavior of\n      writing and reading ``MultIndex`` columns via a list of tuples. The default in\n      0.12 is to write lists of tuples and *not* interpret list of tuples as a\n      ``MultiIndex`` column.\n\n      Note: The default behavior in 0.12 remains unchanged from prior versions, but starting with 0.13,\n      the default *to* write and read ``MultiIndex`` columns will be in the new\n      format. (:issue:`3571`, :issue:`1651`, :issue:`3141`)\n\n    - If an ``index_col`` is not specified (e.g. you don't have an index, or wrote it\n      with ``df.to_csv(..., index=False``), then any ``names`` on the columns index will\n      be *lost*.\n\n      .. ipython:: python\n\n         mi_idx = pd.MultiIndex.from_arrays([[1, 2, 3, 4], list(\"abcd\")], names=list(\"ab\"))\n         mi_col = pd.MultiIndex.from_arrays([[1, 2], list(\"ab\")], names=list(\"cd\"))\n         df = pd.DataFrame(np.ones((4, 2)), index=mi_idx, columns=mi_col)\n         df.to_csv(\"mi.csv\")\n         print(open(\"mi.csv\").read())\n         pd.read_csv(\"mi.csv\", header=[0, 1, 2, 3], index_col=[0, 1])\n\n      .. ipython:: python\n         :suppress:\n\n         import os\n\n         os.remove(\"mi.csv\")\n\n  - Support for ``HDFStore`` (via ``PyTables 3.0.0``) on Python3\n\n  - Iterator support via ``read_hdf`` that automatically opens and closes the\n    store when iteration is finished. This is only for *tables*\n\n    .. code-block:: ipython\n\n        In [25]: path = 'store_iterator.h5'\n\n        In [26]: pd.DataFrame(np.random.randn(10, 2)).to_hdf(path, 'df', table=True)\n\n        In [27]: for df in pd.read_hdf(path, 'df', chunksize=3):\n           ....:     print(df)\n           ....:\n                  0         1\n        0  0.713216 -0.778461\n        1 -0.661062  0.862877\n        2  0.344342  0.149565\n                  0         1\n        3 -0.626968 -0.875772\n        4 -0.930687 -0.218983\n        5  0.949965 -0.442354\n                  0         1\n        6 -0.402985  1.111358\n        7 -0.241527 -0.670477\n        8  0.049355  0.632633\n                  0         1\n        9 -1.502767 -1.225492\n\n\n\n  - ``read_csv`` will now throw a more informative error message when a file\n    contains no columns, e.g., all newline characters\n\nOther enhancements\n~~~~~~~~~~~~~~~~~~\n\n  - ``DataFrame.replace()`` now allows regular expressions on contained\n    ``Series`` with object dtype. See the examples section in the regular docs\n    :ref:`Replacing via String Expression <missing_data.replace_expression>`\n\n    For example you can do\n\n    .. ipython:: python\n\n        df = pd.DataFrame({\"a\": list(\"ab..\"), \"b\": [1, 2, 3, 4]})\n        df.replace(regex=r\"\\s*\\.\\s*\", value=np.nan)\n\n    to replace all occurrences of the string ``'.'`` with zero or more\n    instances of surrounding white space with ``NaN``.\n\n    Regular string replacement still works as expected. For example, you can do\n\n    .. ipython:: python\n\n        df.replace(\".\", np.nan)\n\n    to replace all occurrences of the string ``'.'`` with ``NaN``.\n\n  - ``pd.melt()`` now accepts the optional parameters ``var_name`` and ``value_name``\n    to specify custom column names of the returned DataFrame.\n\n  - ``pd.set_option()`` now allows N option, value pairs (:issue:`3667`).\n\n    Let's say that we had an option ``'a.b'`` and another option ``'b.c'``.\n    We can set them at the same time:\n\n    .. code-block:: ipython\n\n        In [31]: pd.get_option('a.b')\n        Out[31]: 2\n\n        In [32]: pd.get_option('b.c')\n        Out[32]: 3\n\n        In [33]: pd.set_option('a.b', 1, 'b.c', 4)\n\n        In [34]: pd.get_option('a.b')\n        Out[34]: 1\n\n        In [35]: pd.get_option('b.c')\n        Out[35]: 4\n\n  - The ``filter`` method for group objects returns a subset of the original\n    object. Suppose we want to take only elements that belong to groups with a\n    group sum greater than 2.\n\n    .. ipython:: python\n\n       sf = pd.Series([1, 1, 2, 3, 3, 3])\n       sf.groupby(sf).filter(lambda x: x.sum() > 2)\n\n    The argument of ``filter`` must a function that, applied to the group as a\n    whole, returns ``True`` or ``False``.\n\n    Another useful operation is filtering out elements that belong to groups\n    with only a couple members.\n\n    .. ipython:: python\n\n       dff = pd.DataFrame({\"A\": np.arange(8), \"B\": list(\"aabbbbcc\")})\n       dff.groupby(\"B\").filter(lambda x: len(x) > 2)\n\n    Alternatively, instead of dropping the offending groups, we can return a\n    like-indexed objects where the groups that do not pass the filter are\n    filled with NaNs.\n\n    .. ipython:: python\n\n       dff.groupby(\"B\").filter(lambda x: len(x) > 2, dropna=False)\n\n  - Series and DataFrame hist methods now take a ``figsize`` argument (:issue:`3834`)\n\n  - DatetimeIndexes no longer try to convert mixed-integer indexes during join\n    operations (:issue:`3877`)\n\n  - Timestamp.min and Timestamp.max now represent valid Timestamp instances instead\n    of the default datetime.min and datetime.max (respectively), thanks SleepingPills\n\n  - ``read_html`` now raises when no tables are found and BeautifulSoup==4.2.0\n    is detected (:issue:`4214`)\n\n\nExperimental features\n~~~~~~~~~~~~~~~~~~~~~\n\n  - Added experimental ``CustomBusinessDay`` class to support ``DateOffsets``\n    with custom holiday calendars and custom weekmasks. (:issue:`2301`)\n\n    .. note::\n\n       This uses the ``numpy.busdaycalendar`` API introduced in Numpy 1.7 and\n       therefore requires Numpy 1.7.0 or newer.\n\n    .. ipython:: python\n\n      from pandas.tseries.offsets import CustomBusinessDay\n      from datetime import datetime\n\n       As an interesting example, let's look at Egypt where\n       a Friday-Saturday weekend is observed.\n      weekmask_egypt = \"Sun Mon Tue Wed Thu\"\n       They also observe International Workers' Day so let's\n       add that for a couple of years\n      holidays = [\"2012-05-01\", datetime(2013, 5, 1), np.datetime64(\"2014-05-01\")]\n      bday_egypt = CustomBusinessDay(holidays=holidays, weekmask=weekmask_egypt)\n      dt = datetime(2013, 4, 30)\n      print(dt + 2 * bday_egypt)\n      dts = pd.date_range(dt, periods=5, freq=bday_egypt)\n      print(pd.Series(dts.weekday, dts).map(pd.Series(\"Mon Tue Wed Thu Fri Sat Sun\".split())))\n\nBug fixes\n~~~~~~~~~\n\n  - Plotting functions now raise a ``TypeError`` before trying to plot anything\n    if the associated objects have a dtype of ``object`` (:issue:`1818`,\n    :issue:`3572`, :issue:`3911`, :issue:`3912`), but they will try to convert object arrays to\n    numeric arrays if possible so that you can still plot, for example, an\n    object array with floats. This happens before any drawing takes place which\n    eliminates any spurious plots from showing up.\n\n  - ``fillna`` methods now raise a ``TypeError`` if the ``value`` parameter is\n    a list or tuple.\n\n  - ``Series.str`` now supports iteration (:issue:`3638`). You can iterate over the\n    individual elements of each string in the ``Series``. Each iteration yields\n    a ``Series`` with either a single character at each index of the original\n    ``Series`` or ``NaN``. For example,\n\n    .. code-block:: ipython\n\n        In [38]: strs = \"go\", \"bow\", \"joe\", \"slow\"\n\n        In [32]: ds = pd.Series(strs)\n\n        In [33]: for s in ds.str:\n            ...:     print(s)\n\n        0    g\n        1    b\n        2    j\n        3    s\n        dtype: object\n        0    o\n        1    o\n        2    o\n        3    l\n        dtype: object\n        0    NaN\n        1      w\n        2      e\n        3      o\n        dtype: object\n        0    NaN\n        1    NaN\n        2    NaN\n        3      w\n        dtype: object\n\n        In [41]: s\n        Out[41]:\n        0    NaN\n        1    NaN\n        2    NaN\n        3      w\n        dtype: object\n\n        In [42]: s.dropna().values.item() == \"w\"\n        Out[42]: True\n\n    The last element yielded by the iterator will be a ``Series`` containing\n    the last element of the longest string in the ``Series`` with all other\n    elements being ``NaN``. Here since ``'slow'`` is the longest string\n    and there are no other strings with the same length ``'w'`` is the only\n    non-null string in the yielded ``Series``.\n\n  - ``HDFStore``\n\n    - will retain index attributes (freq,tz,name) on recreation (:issue:`3499`)\n    - will warn with a ``AttributeConflictWarning`` if you are attempting to append\n      an index with a different frequency than the existing, or attempting\n      to append an index with a different name than the existing\n    - support datelike columns with a timezone as data_columns (:issue:`2852`)\n\n  - Non-unique index support clarified (:issue:`3468`).\n\n    - Fix assigning a new index to a duplicate index in a DataFrame would fail (:issue:`3468`)\n    - Fix construction of a DataFrame with a duplicate index\n    - ref_locs support to allow duplicative indices across dtypes,\n      allows iget support to always find the index (even across dtypes) (:issue:`2194`)\n    - applymap on a DataFrame with a non-unique index now works\n      (removed warning) (:issue:`2786`), and fix (:issue:`3230`)\n    - Fix to_csv to handle non-unique columns (:issue:`3495`)\n    - Duplicate indexes with getitem will return items in the correct order (:issue:`3455`, :issue:`3457`)\n      and handle missing elements like unique indices (:issue:`3561`)\n    - Duplicate indexes with and empty DataFrame.from_records will return a correct frame (:issue:`3562`)\n    - Concat to produce a non-unique columns when duplicates are across dtypes is fixed (:issue:`3602`)\n    - Allow insert/delete to non-unique columns (:issue:`3679`)\n    - Non-unique indexing with a slice via ``loc`` and friends fixed (:issue:`3659`)\n    - Allow insert/delete to non-unique columns (:issue:`3679`)\n    - Extend ``reindex`` to correctly deal with non-unique indices (:issue:`3679`)\n    - ``DataFrame.itertuples()`` now works with frames with duplicate column\n      names (:issue:`3873`)\n    - Bug in non-unique indexing via ``iloc`` (:issue:`4017`); added ``takeable`` argument to\n      ``reindex`` for location-based taking\n    - Allow non-unique indexing in series via ``.ix/.loc`` and ``__getitem__`` (:issue:`4246`)\n    - Fixed non-unique indexing memory allocation issue with ``.ix/.loc`` (:issue:`4280`)\n\n  - ``DataFrame.from_records`` did not accept empty recarrays (:issue:`3682`)\n  - ``read_html`` now correctly skips tests (:issue:`3741`)\n  - Fixed a bug where ``DataFrame.replace`` with a compiled regular expression\n    in the ``to_replace`` argument wasn't working (:issue:`3907`)\n  - Improved ``network`` test decorator to catch ``IOError`` (and therefore\n    ``URLError`` as well). Added ``with_connectivity_check`` decorator to allow\n    explicitly checking a website as a proxy for seeing if there is network\n    connectivity. Plus, new ``optional_args`` decorator factory for decorators.\n    (:issue:`3910`, :issue:`3914`)\n  - Fixed testing issue where too many sockets where open thus leading to a\n    connection reset issue (:issue:`3982`, :issue:`3985`, :issue:`4028`,\n    :issue:`4054`)\n  - Fixed failing tests in test_yahoo, test_google where symbols were not\n    retrieved but were being accessed (:issue:`3982`, :issue:`3985`,\n    :issue:`4028`, :issue:`4054`)\n  - ``Series.hist`` will now take the figure from the current environment if\n    one is not passed\n  - Fixed bug where a 1xN DataFrame would barf on a 1xN mask (:issue:`4071`)\n  - Fixed running of ``tox`` under python3 where the pickle import was getting\n    rewritten in an incompatible way (:issue:`4062`, :issue:`4063`)\n  - Fixed bug where sharex and sharey were not being passed to grouped_hist\n    (:issue:`4089`)\n  - Fixed bug in ``DataFrame.replace`` where a nested dict wasn't being\n    iterated over when regex=False (:issue:`4115`)\n  - Fixed bug in the parsing of microseconds when using the ``format``\n    argument in ``to_datetime`` (:issue:`4152`)\n  - Fixed bug in ``PandasAutoDateLocator`` where ``invert_xaxis`` triggered\n    incorrectly ``MilliSecondLocator``  (:issue:`3990`)\n  - Fixed bug in plotting that wasn't raising on invalid colormap for\n    matplotlib 1.1.1 (:issue:`4215`)\n  - Fixed the legend displaying in ``DataFrame.plot(kind='kde')`` (:issue:`4216`)\n  - Fixed bug where Index slices weren't carrying the name attribute\n    (:issue:`4226`)\n  - Fixed bug in initializing ``DatetimeIndex`` with an array of strings\n    in a certain time zone (:issue:`4229`)\n  - Fixed bug where html5lib wasn't being properly skipped (:issue:`4265`)\n  - Fixed bug where get_data_famafrench wasn't using the correct file edges\n    (:issue:`4281`)\n\nSee the :ref:`full release notes\n<release>` or issue tracker\non GitHub for a complete list.\n\n\n.. _whatsnew_0.12.0.contributors:\n\nContributors\n~~~~~~~~~~~~\n\n.. contributors:: v0.11.0..v0.12.0\n\n\n.. _whatsnew_142:\n\nWhat's new in 1.4.2 (April 2, 2022)\n-----------------------------------\n\nThese are the changes in pandas 1.4.2. See :ref:`release` for a full changelog\nincluding other versions of pandas.\n\n{{ header }}\n\n.. ---------------------------------------------------------------------------\n\n.. _whatsnew_142.regressions:\n\nFixed regressions\n~~~~~~~~~~~~~~~~~\n- Fixed regression in :meth:`DataFrame.drop` and :meth:`Series.drop` when :class:`Index` had extension dtype and duplicates (:issue:`45860`)\n- Fixed regression in :func:`read_csv` killing python process when invalid file input was given for ``engine=\"c\"`` (:issue:`45957`)\n- Fixed memory performance regression in :meth:`Series.fillna` when called on a :class:`DataFrame` column with ``inplace=True`` (:issue:`46149`)\n- Provided an alternative solution for passing custom Excel formats in :meth:`.Styler.to_excel`, which was a regression based on stricter CSS validation. Examples available in the documentation for :meth:`.Styler.format` (:issue:`46152`)\n- Fixed regression in :meth:`DataFrame.replace` when a replacement value was also a target for replacement (:issue:`46306`)\n- Fixed regression in :meth:`DataFrame.replace` when the replacement value was explicitly ``None`` when passed in a dictionary to ``to_replace`` (:issue:`45601`, :issue:`45836`)\n- Fixed regression when setting values with :meth:`DataFrame.loc` losing :class:`MultiIndex` names if :class:`DataFrame`  was empty before (:issue:`46317`)\n- Fixed regression when rendering boolean datatype columns with :meth:`.Styler` (:issue:`46384`)\n- Fixed regression in :meth:`Groupby.rolling` with a frequency window that would raise a ``ValueError`` even if the datetimes within each group were monotonic (:issue:`46061`)\n\n.. ---------------------------------------------------------------------------\n\n.. _whatsnew_142.bug_fixes:\n\nBug fixes\n~~~~~~~~~\n- Fix some cases for subclasses that define their ``_constructor`` properties as general callables (:issue:`46018`)\n- Fixed \"longtable\" formatting in :meth:`.Styler.to_latex` when ``column_format`` is given in extended format (:issue:`46037`)\n- Fixed incorrect rendering in :meth:`.Styler.format` with ``hyperlinks=\"html\"`` when the url contains a colon or other special characters (:issue:`46389`)\n- Improved error message in :class:`.Rolling` when ``window`` is a frequency and ``NaT`` is in the rolling axis (:issue:`46087`)\n\n.. ---------------------------------------------------------------------------\n\n.. _whatsnew_142.contributors:\n\nContributors\n~~~~~~~~~~~~\n\n.. contributors:: v1.4.1..v1.4.2\n\n\n.. _whatsnew_0203:\n\nVersion 0.20.3 (July 7, 2017)\n-----------------------------\n\n{{ header }}\n\n.. ipython:: python\n   :suppress:\n\n   from pandas import *   noqa F401, F403\n\n\nThis is a minor bug-fix release in the 0.20.x series and includes some small regression fixes\nand bug fixes. We recommend that all users upgrade to this version.\n\n.. contents:: What's new in v0.20.3\n    :local:\n    :backlinks: none\n\n.. _whatsnew_0203.bug_fixes:\n\nBug fixes\n~~~~~~~~~\n\n- Fixed a bug in failing to compute rolling computations of a column-MultiIndexed ``DataFrame`` (:issue:`16789`, :issue:`16825`)\n- Fixed a pytest marker failing downstream packages' tests suites (:issue:`16680`)\n\nConversion\n^^^^^^^^^^\n\n- Bug in pickle compat prior to the v0.20.x series, when ``UTC`` is a timezone in a Series/DataFrame/Index (:issue:`16608`)\n- Bug in ``Series`` construction when passing a ``Series`` with ``dtype='category'`` (:issue:`16524`).\n- Bug in :meth:`DataFrame.astype` when passing a ``Series`` as the ``dtype`` kwarg. (:issue:`16717`).\n\nIndexing\n^^^^^^^^\n\n- Bug in ``Float64Index`` causing an empty array instead of ``None`` to be returned from ``.get(np.nan)`` on a Series whose index did not contain any ``NaN`` s (:issue:`8569`)\n- Bug in ``MultiIndex.isin`` causing an error when passing an empty iterable (:issue:`16777`)\n- Fixed a bug in a slicing DataFrame/Series that have a  ``TimedeltaIndex`` (:issue:`16637`)\n\nIO\n^^\n\n- Bug in :func:`read_csv` in which files weren't opened as binary files by the C engine on Windows, causing EOF characters mid-field, which would fail (:issue:`16039`, :issue:`16559`, :issue:`16675`)\n- Bug in :func:`read_hdf` in which reading a ``Series`` saved to an HDF file in 'fixed' format fails when an explicit ``mode='r'`` argument is supplied (:issue:`16583`)\n- Bug in :meth:`DataFrame.to_latex` where ``bold_rows`` was wrongly specified to be ``True`` by default, whereas in reality row labels remained non-bold whatever parameter provided. (:issue:`16707`)\n- Fixed an issue with :meth:`DataFrame.style` where generated element ids were not unique (:issue:`16780`)\n- Fixed loading a ``DataFrame`` with a ``PeriodIndex``, from a ``format='fixed'`` HDFStore, in Python 3, that was written in Python 2 (:issue:`16781`)\n\nPlotting\n^^^^^^^^\n\n- Fixed regression that prevented RGB and RGBA tuples from being used as color arguments (:issue:`16233`)\n- Fixed an issue with :meth:`DataFrame.plot.scatter` that incorrectly raised a ``KeyError`` when categorical data is used for plotting (:issue:`16199`)\n\nReshaping\n^^^^^^^^^\n\n- ``PeriodIndex`` / ``TimedeltaIndex.join`` was missing the ``sort=`` kwarg (:issue:`16541`)\n- Bug in joining on a ``MultiIndex`` with a ``category`` dtype for a level (:issue:`16627`).\n- Bug in :func:`merge` when merging/joining with multiple categorical columns (:issue:`16767`)\n\nCategorical\n^^^^^^^^^^^\n\n- Bug in ``DataFrame.sort_values`` not respecting the ``kind`` parameter with categorical data (:issue:`16793`)\n\n\n.. _whatsnew_0.20.3.contributors:\n\nContributors\n~~~~~~~~~~~~\n\n.. contributors:: v0.20.2..v0.20.3\n\n\n.. _whatsnew_0801:\n\nVersion 0.8.1 (July 22, 2012)\n-----------------------------\n\n{{ header }}\n\n\nThis release includes a few new features, performance enhancements, and over 30\nbug fixes from 0.8.0.  New features include notably NA friendly string\nprocessing functionality and a series of new plot types and options.\n\nNew features\n~~~~~~~~~~~~\n\n  - Add :ref:`vectorized string processing methods <text.string_methods>`\n    accessible via Series.str (:issue:`620`)\n  - Add option to disable adjustment in EWMA (:issue:`1584`)\n  - :ref:`Radviz plot <visualization.radviz>` (:issue:`1566`)\n  - :ref:`Parallel coordinates plot <visualization.parallel_coordinates>`\n  - :ref:`Bootstrap plot <visualization.bootstrap>`\n  - Per column styles and secondary y-axis plotting (:issue:`1559`)\n  - New datetime converters millisecond plotting  (:issue:`1599`)\n  - Add option to disable \"sparse\" display of hierarchical indexes (:issue:`1538`)\n  - Series/DataFrame's ``set_index`` method can :ref:`append levels\n    <indexing.set_index>` to an existing Index/MultiIndex (:issue:`1569`, :issue:`1577`)\n\nPerformance improvements\n~~~~~~~~~~~~~~~~~~~~~~~~\n\n  - Improved implementation of rolling min and max (thanks to `Bottleneck\n    <https://bottleneck.readthedocs.io>`__ !)\n  - Add accelerated ``'median'`` GroupBy option (:issue:`1358`)\n  - Significantly improve the performance of parsing ISO8601-format date\n    strings with ``DatetimeIndex`` or ``to_datetime`` (:issue:`1571`)\n  - Improve the performance of GroupBy on single-key aggregations and use with\n    Categorical types\n  - Significant datetime parsing performance improvements\n\n\n\n.. _whatsnew_0.8.1.contributors:\n\nContributors\n~~~~~~~~~~~~\n\n.. contributors:: v0.8.0..v0.8.1\n\n\n.. _whatsnew_112:\n\nWhat's new in 1.1.2 (September 8, 2020)\n---------------------------------------\n\nThese are the changes in pandas 1.1.2. See :ref:`release` for a full changelog\nincluding other versions of pandas.\n\n{{ header }}\n\n.. ---------------------------------------------------------------------------\n\n.. _whatsnew_112.regressions:\n\nFixed regressions\n~~~~~~~~~~~~~~~~~\n- Regression in :meth:`DatetimeIndex.intersection` incorrectly raising ``AssertionError`` when intersecting against a list (:issue:`35876`)\n- Fix regression in updating a column inplace (e.g. using ``df['col'].fillna(.., inplace=True)``) (:issue:`35731`)\n- Fix regression in :meth:`DataFrame.append` mixing tz-aware and tz-naive datetime columns (:issue:`35460`)\n- Performance regression for :meth:`RangeIndex.format` (:issue:`35712`)\n- Regression where :meth:`MultiIndex.get_loc` would return a slice spanning the full index when passed an empty list (:issue:`35878`)\n- Fix regression in invalid cache after an indexing operation; this can manifest when setting which does not update the data (:issue:`35521`)\n- Regression in :meth:`DataFrame.replace` where a ``TypeError`` would be raised when attempting to replace elements of type :class:`Interval` (:issue:`35931`)\n- Fix regression in pickle roundtrip of the ``closed`` attribute of :class:`IntervalIndex` (:issue:`35658`)\n- Fixed regression in :meth:`DataFrameGroupBy.agg` where a ``ValueError: buffer source array is read-only`` would be raised when the underlying array is read-only (:issue:`36014`)\n- Fixed regression in :meth:`Series.groupby.rolling` number of levels of :class:`MultiIndex` in input was compressed to one (:issue:`36018`)\n- Fixed regression in :class:`DataFrameGroupBy` on an empty :class:`DataFrame` (:issue:`36197`)\n\n.. ---------------------------------------------------------------------------\n\n.. _whatsnew_112.bug_fixes:\n\nBug fixes\n~~~~~~~~~\n- Bug in :meth:`DataFrame.eval` with ``object`` dtype column binary operations (:issue:`35794`)\n- Bug in :class:`Series` constructor raising a ``TypeError`` when constructing sparse datetime64 dtypes (:issue:`35762`)\n- Bug in :meth:`DataFrame.apply` with ``result_type=\"reduce\"`` returning with incorrect index (:issue:`35683`)\n- Bug in :meth:`Series.astype` and :meth:`DataFrame.astype` not respecting the ``errors`` argument when set to ``\"ignore\"`` for extension dtypes (:issue:`35471`)\n- Bug in :meth:`DateTimeIndex.format` and :meth:`PeriodIndex.format` with ``name=True`` setting the first item to ``\"None\"`` where it should be ``\"\"`` (:issue:`35712`)\n- Bug in :meth:`Float64Index.__contains__` incorrectly raising ``TypeError`` instead of returning ``False`` (:issue:`35788`)\n- Bug in :class:`Series` constructor incorrectly raising a ``TypeError`` when passed an ordered set (:issue:`36044`)\n- Bug in :meth:`Series.dt.isocalendar` and :meth:`DatetimeIndex.isocalendar` that returned incorrect year for certain dates (:issue:`36032`)\n- Bug in :class:`DataFrame` indexing returning an incorrect :class:`Series` in some cases when the series has been altered and a cache not invalidated (:issue:`33675`)\n- Bug in :meth:`DataFrame.corr` causing subsequent indexing lookups to be incorrect (:issue:`35882`)\n- Bug in :meth:`import_optional_dependency` returning incorrect package names in cases where package name is different from import name (:issue:`35948`)\n- Bug when setting empty :class:`DataFrame` column to a :class:`Series` in preserving name of index in frame (:issue:`31368`)\n\n.. ---------------------------------------------------------------------------\n\n.. _whatsnew_112.other:\n\nOther\n~~~~~\n- :meth:`factorize` now supports ``na_sentinel=None`` to include NaN in the uniques of the values and remove ``dropna`` keyword which was unintentionally exposed to public facing API in 1.1 version from :meth:`factorize` (:issue:`35667`)\n- :meth:`DataFrame.plot` and :meth:`Series.plot` raise ``UserWarning`` about usage of ``FixedFormatter`` and ``FixedLocator`` (:issue:`35684` and :issue:`35945`)\n\n.. ---------------------------------------------------------------------------\n\n.. _whatsnew_112.contributors:\n\nContributors\n~~~~~~~~~~~~\n\n.. contributors:: v1.1.1..v1.1.2\n\n\n.. _whatsnew_0700:\n\nVersion 0.7.0 (February 9, 2012)\n--------------------------------\n\n{{ header }}\n\n\nNew features\n~~~~~~~~~~~~\n\n- New unified :ref:`merge function <merging.join>` for efficiently performing\n  full gamut of database / relational-algebra operations. Refactored existing\n  join methods to use the new infrastructure, resulting in substantial\n  performance gains (:issue:`220`, :issue:`249`, :issue:`267`)\n\n- New :ref:`unified concatenation function <merging.concat>` for concatenating\n  Series, DataFrame or Panel objects along an axis. Can form union or\n  intersection of the other axes. Improves performance of ``Series.append`` and\n  ``DataFrame.append`` (:issue:`468`, :issue:`479`, :issue:`273`)\n\n- Can pass multiple DataFrames to\n  ``DataFrame.append`` to concatenate (stack) and multiple Series to\n  ``Series.append`` too\n\n- :ref:`Can<basics.dataframe.from_list_of_dicts>` pass list of dicts (e.g., a\n  list of JSON objects) to DataFrame constructor (:issue:`526`)\n\n- You can now :ref:`set multiple columns <indexing.columns.multiple>` in a\n  DataFrame via ``__getitem__``, useful for transformation (:issue:`342`)\n\n- Handle differently-indexed output values in ``DataFrame.apply`` (:issue:`498`)\n\n.. code-block:: ipython\n\n   In [1]: df = pd.DataFrame(np.random.randn(10, 4))\n   In [2]: df.apply(lambda x: x.describe())\n   Out[2]:\n                  0          1          2          3\n   count  10.000000  10.000000  10.000000  10.000000\n   mean    0.190912  -0.395125  -0.731920  -0.403130\n   std     0.730951   0.813266   1.112016   0.961912\n   min    -0.861849  -2.104569  -1.776904  -1.469388\n   25%    -0.411391  -0.698728  -1.501401  -1.076610\n   50%     0.380863  -0.228039  -1.191943  -1.004091\n   75%     0.658444   0.057974  -0.034326   0.461706\n   max     1.212112   0.577046   1.643563   1.071804\n\n   [8 rows x 4 columns]\n\n- :ref:`Add<advanced.reorderlevels>` ``reorder_levels`` method to Series and\n  DataFrame (:issue:`534`)\n\n- :ref:`Add<indexing.dictionarylike>` dict-like ``get`` function to DataFrame\n  and Panel (:issue:`521`)\n\n- :ref:`Add<basics.iterrows>` ``DataFrame.iterrows`` method for efficiently\n  iterating through the rows of a DataFrame\n\n- Add ``DataFrame.to_panel`` with code adapted from\n  ``LongPanel.to_long``\n\n- :ref:`Add <basics.reindexing>` ``reindex_axis`` method added to DataFrame\n\n- :ref:`Add <basics.stats>` ``level`` option to binary arithmetic functions on\n  ``DataFrame`` and ``Series``\n\n- :ref:`Add <advanced.advanced_reindex>` ``level`` option to the ``reindex``\n  and ``align`` methods on Series and DataFrame for broadcasting values across\n  a level (:issue:`542`, :issue:`552`, others)\n\n- Add attribute-based item access to\n  ``Panel`` and add IPython completion (:issue:`563`)\n\n- :ref:`Add <visualization.basic>` ``logy`` option to ``Series.plot`` for\n  log-scaling on the Y axis\n\n- :ref:`Add <io.formatting>` ``index`` and ``header`` options to\n  ``DataFrame.to_string``\n\n- :ref:`Can <merging.multiple_join>` pass multiple DataFrames to\n  ``DataFrame.join`` to join on index (:issue:`115`)\n\n- :ref:`Can <merging.multiple_join>` pass multiple Panels to ``Panel.join``\n  (:issue:`115`)\n\n- :ref:`Added <io.formatting>` ``justify`` argument to ``DataFrame.to_string``\n  to allow different alignment of column headers\n\n- :ref:`Add <groupby.attributes>` ``sort`` option to GroupBy to allow disabling\n  sorting of the group keys for potential speedups (:issue:`595`)\n\n- :ref:`Can <basics.dataframe.from_series>` pass MaskedArray to Series\n  constructor (:issue:`563`)\n\n- Add Panel item access via attributes\n  and IPython completion (:issue:`554`)\n\n- Implement ``DataFrame.lookup``, fancy-indexing analogue for retrieving values\n  given a sequence of row and column labels (:issue:`338`)\n\n- Can pass a :ref:`list of functions <groupby.aggregate.multifunc>` to\n  aggregate with groupby on a DataFrame, yielding an aggregated result with\n  hierarchical columns (:issue:`166`)\n\n- Can call ``cummin`` and ``cummax`` on Series and DataFrame to get cumulative\n  minimum and maximum, respectively (:issue:`647`)\n\n- ``value_range`` added as utility function to get min and max of a dataframe\n  (:issue:`288`)\n\n- Added ``encoding`` argument to ``read_csv``, ``read_table``, ``to_csv`` and\n  ``from_csv`` for non-ascii text (:issue:`717`)\n\n- :ref:`Added <basics.stats>` ``abs`` method to pandas objects\n\n- :ref:`Added <reshaping.pivot>` ``crosstab`` function for easily computing frequency tables\n\n- :ref:`Added <indexing.set_ops>` ``isin`` method to index objects\n\n- :ref:`Added <advanced.xs>` ``level`` argument to ``xs`` method of DataFrame.\n\n\nAPI changes to integer indexing\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\nOne of the potentially riskiest API changes in 0.7.0, but also one of the most\nimportant, was a complete review of how **integer indexes** are handled with\nregard to label-based indexing. Here is an example:\n\n.. code-block:: ipython\n\n    In [3]: s = pd.Series(np.random.randn(10), index=range(0, 20, 2))\n    In [4]: s\n    Out[4]:\n    0    -1.294524\n    2     0.413738\n    4     0.276662\n    6    -0.472035\n    8    -0.013960\n    10   -0.362543\n    12   -0.006154\n    14   -0.923061\n    16    0.895717\n    18    0.805244\n    Length: 10, dtype: float64\n\n    In [5]: s[0]\n    Out[5]: -1.2945235902555294\n\n    In [6]: s[2]\n    Out[6]: 0.41373810535784006\n\n    In [7]: s[4]\n    Out[7]: 0.2766617129497566\n\nThis is all exactly identical to the behavior before. However, if you ask for a\nkey **not** contained in the Series, in versions 0.6.1 and prior, Series would\n*fall back* on a location-based lookup. This now raises a ``KeyError``:\n\n.. code-block:: ipython\n\n   In [2]: s[1]\n   KeyError: 1\n\nThis change also has the same impact on DataFrame:\n\n.. code-block:: ipython\n\n   In [3]: df = pd.DataFrame(np.random.randn(8, 4), index=range(0, 16, 2))\n\n   In [4]: df\n       0        1       2       3\n   0   0.88427  0.3363 -0.1787  0.03162\n   2   0.14451 -0.1415  0.2504  0.58374\n   4  -1.44779 -0.9186 -1.4996  0.27163\n   6  -0.26598 -2.4184 -0.2658  0.11503\n   8  -0.58776  0.3144 -0.8566  0.61941\n   10  0.10940 -0.7175 -1.0108  0.47990\n   12 -1.16919 -0.3087 -0.6049 -0.43544\n   14 -0.07337  0.3410  0.0424 -0.16037\n\n   In [5]: df.ix[3]\n   KeyError: 3\n\nIn order to support purely integer-based indexing, the following methods have\nbeen added:\n\n.. csv-table::\n    :header: \"Method\",\"Description\"\n    :widths: 40,60\n\n        ``Series.iget_value(i)``, Retrieve value stored at location ``i``\n        ``Series.iget(i)``, Alias for ``iget_value``\n        ``DataFrame.irow(i)``, Retrieve the ``i``-th row\n        ``DataFrame.icol(j)``, Retrieve the ``j``-th column\n        \"``DataFrame.iget_value(i, j)``\", Retrieve the value at row ``i`` and column ``j``\n\nAPI tweaks regarding label-based slicing\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\nLabel-based slicing using ``ix`` now requires that the index be sorted\n(monotonic) **unless** both the start and endpoint are contained in the index:\n\n.. code-block:: python\n\n   In [1]: s = pd.Series(np.random.randn(6), index=list('gmkaec'))\n\n   In [2]: s\n   Out[2]:\n   g   -1.182230\n   m   -0.276183\n   k   -0.243550\n   a    1.628992\n   e    0.073308\n   c   -0.539890\n   dtype: float64\n\nThen this is OK:\n\n.. code-block:: python\n\n   In [3]: s.ix['k':'e']\n   Out[3]:\n   k   -0.243550\n   a    1.628992\n   e    0.073308\n   dtype: float64\n\nBut this is not:\n\n.. code-block:: ipython\n\n   In [12]: s.ix['b':'h']\n   KeyError 'b'\n\nIf the index had been sorted, the \"range selection\" would have been possible:\n\n.. code-block:: python\n\n   In [4]: s2 = s.sort_index()\n\n   In [5]: s2\n   Out[5]:\n   a    1.628992\n   c   -0.539890\n   e    0.073308\n   g   -1.182230\n   k   -0.243550\n   m   -0.276183\n   dtype: float64\n\n   In [6]: s2.ix['b':'h']\n   Out[6]:\n   c   -0.539890\n   e    0.073308\n   g   -1.182230\n   dtype: float64\n\nChanges to Series ``[]`` operator\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\nAs as notational convenience, you can pass a sequence of labels or a label\nslice to a Series when getting and setting values via ``[]`` (i.e. the\n``__getitem__`` and ``__setitem__`` methods). The behavior will be the same as\npassing similar input to ``ix`` **except in the case of integer indexing**:\n\n.. code-block:: ipython\n\n  In [8]: s = pd.Series(np.random.randn(6), index=list('acegkm'))\n\n  In [9]: s\n  Out[9]:\n  a   -1.206412\n  c    2.565646\n  e    1.431256\n  g    1.340309\n  k   -1.170299\n  m   -0.226169\n  Length: 6, dtype: float64\n\n  In [10]: s[['m', 'a', 'c', 'e']]\n  Out[10]:\n  m   -0.226169\n  a   -1.206412\n  c    2.565646\n  e    1.431256\n  Length: 4, dtype: float64\n\n  In [11]: s['b':'l']\n  Out[11]:\n  c    2.565646\n  e    1.431256\n  g    1.340309\n  k   -1.170299\n  Length: 4, dtype: float64\n\n  In [12]: s['c':'k']\n  Out[12]:\n  c    2.565646\n  e    1.431256\n  g    1.340309\n  k   -1.170299\n  Length: 4, dtype: float64\n\nIn the case of integer indexes, the behavior will be exactly as before\n(shadowing ``ndarray``):\n\n.. code-block:: ipython\n\n  In [13]: s = pd.Series(np.random.randn(6), index=range(0, 12, 2))\n\n  In [14]: s[[4, 0, 2]]\n  Out[14]:\n  4    0.132003\n  0    0.410835\n  2    0.813850\n  Length: 3, dtype: float64\n\n  In [15]: s[1:5]\n  Out[15]:\n  2    0.813850\n  4    0.132003\n  6   -0.827317\n  8   -0.076467\n  Length: 4, dtype: float64\n\nIf you wish to do indexing with sequences and slicing on an integer index with\nlabel semantics, use ``ix``.\n\nOther API changes\n~~~~~~~~~~~~~~~~~\n\n- The deprecated ``LongPanel`` class has been completely removed\n\n- If ``Series.sort`` is called on a column of a DataFrame, an exception will\n  now be raised. Before it was possible to accidentally mutate a DataFrame's\n  column by doing ``df[col].sort()`` instead of the side-effect free method\n  ``df[col].order()`` (:issue:`316`)\n\n- Miscellaneous renames and deprecations which will (harmlessly) raise\n  ``FutureWarning``\n\n- ``drop`` added as an optional parameter to ``DataFrame.reset_index`` (:issue:`699`)\n\nPerformance improvements\n~~~~~~~~~~~~~~~~~~~~~~~~\n\n- :ref:`Cythonized GroupBy aggregations <groupby.aggregate.builtin>` no longer\n  presort the data, thus achieving a significant speedup (:issue:`93`).  GroupBy\n  aggregations with Python functions significantly sped up by clever\n  manipulation of the ndarray data type in Cython (:issue:`496`).\n- Better error message in DataFrame constructor when passed column labels\n  don't match data (:issue:`497`)\n- Substantially improve performance of multi-GroupBy aggregation when a\n  Python function is passed, reuse ndarray object in Cython (:issue:`496`)\n- Can store objects indexed by tuples and floats in HDFStore (:issue:`492`)\n- Don't print length by default in Series.to_string, add ``length`` option (:issue:`489`)\n- Improve Cython code for multi-groupby to aggregate without having to sort\n  the data (:issue:`93`)\n- Improve MultiIndex reindexing speed by storing tuples in the MultiIndex,\n  test for backwards unpickling compatibility\n- Improve column reindexing performance by using specialized Cython take\n  function\n- Further performance tweaking of Series.__getitem__ for standard use cases\n- Avoid Index dict creation in some cases (i.e. when getting slices, etc.),\n  regression from prior versions\n- Friendlier error message in setup.py if NumPy not installed\n- Use common set of NA-handling operations (sum, mean, etc.) in Panel class\n  also (:issue:`536`)\n- Default name assignment when calling ``reset_index`` on DataFrame with a\n  regular (non-hierarchical) index (:issue:`476`)\n- Use Cythonized groupers when possible in Series/DataFrame stat ops with\n  ``level`` parameter passed (:issue:`545`)\n- Ported skiplist data structure to C to speed up ``rolling_median`` by about\n  5-10x in most typical use cases (:issue:`374`)\n\n\n.. _whatsnew_0.7.0.contributors:\n\nContributors\n~~~~~~~~~~~~\n\n.. contributors:: v0.6.1..v0.7.0\n\n\n.. _whatsnew_122:\n\nWhat's new in 1.2.2 (February 09, 2021)\n---------------------------------------\n\nThese are the changes in pandas 1.2.2. See :ref:`release` for a full changelog\nincluding other versions of pandas.\n\n{{ header }}\n\n.. ---------------------------------------------------------------------------\n\n.. _whatsnew_122.regressions:\n\nFixed regressions\n~~~~~~~~~~~~~~~~~\n\n- Fixed regression in :func:`read_excel` that caused it to raise ``AttributeError`` when checking version of older xlrd versions (:issue:`38955`)\n- Fixed regression in :class:`DataFrame` constructor reordering element when construction from datetime ndarray with dtype not ``\"datetime64[ns]\"`` (:issue:`39422`)\n- Fixed regression in :meth:`DataFrame.astype` and :meth:`Series.astype` not casting to bytes dtype (:issue:`39474`)\n- Fixed regression in :meth:`~DataFrame.to_pickle` failing to create bz2/xz compressed pickle files with ``protocol=5`` (:issue:`39002`)\n- Fixed regression in :func:`pandas.testing.assert_series_equal` and :func:`pandas.testing.assert_frame_equal` always raising ``AssertionError`` when comparing extension dtypes (:issue:`39410`)\n- Fixed regression in :meth:`~DataFrame.to_csv` opening ``codecs.StreamWriter`` in binary mode instead of in text mode and ignoring user-provided ``mode`` (:issue:`39247`)\n- Fixed regression in :meth:`Categorical.astype` casting to incorrect dtype when ``np.int32`` is passed to dtype argument (:issue:`39402`)\n- Fixed regression in :meth:`~DataFrame.to_excel` creating corrupt files when appending (``mode=\"a\"``) to an existing file (:issue:`39576`)\n- Fixed regression in :meth:`DataFrame.transform` failing in case of an empty DataFrame or Series (:issue:`39636`)\n- Fixed regression in :meth:`~DataFrame.groupby` or :meth:`~DataFrame.resample` when aggregating an all-NaN or numeric object dtype column (:issue:`39329`)\n- Fixed regression in :meth:`.Rolling.count` where the ``min_periods`` argument would be set to ``0`` after the operation (:issue:`39554`)\n- Fixed regression in :func:`read_excel` that incorrectly raised when the argument ``io`` was a non-path and non-buffer and the ``engine`` argument was specified (:issue:`39528`)\n\n.. ---------------------------------------------------------------------------\n\n.. _whatsnew_122.bug_fixes:\n\nBug fixes\n~~~~~~~~~\n\n- :func:`pandas.read_excel` error message when a specified ``sheetname`` does not exist is now uniform across engines (:issue:`39250`)\n- Fixed bug in :func:`pandas.read_excel` producing incorrect results when the engine ``openpyxl`` is used and the excel file is missing or has incorrect dimension information; the fix requires ``openpyxl`` >= 3.0.0, prior versions may still fail (:issue:`38956`, :issue:`39001`)\n- Fixed bug in :func:`pandas.read_excel` sometimes producing a ``DataFrame`` with trailing rows of ``np.nan`` when the engine ``openpyxl`` is used (:issue:`39181`)\n\n.. ---------------------------------------------------------------------------\n\n.. _whatsnew_122.contributors:\n\nContributors\n~~~~~~~~~~~~\n\n.. contributors:: v1.2.1..v1.2.2\n\n\n.. _whatsnew_220:\n\nWhat's new in 2.2.0 (January 19, 2024)\n--------------------------------------\n\nThese are the changes in pandas 2.2.0. See :ref:`release` for a full changelog\nincluding other versions of pandas.\n\n{{ header }}\n\n.. ---------------------------------------------------------------------------\n\n.. _whatsnew_220.upcoming_changes:\n\nUpcoming changes in pandas 3.0\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\npandas 3.0 will bring two bigger changes to the default behavior of pandas.\n\nCopy-on-Write\n^^^^^^^^^^^^^\n\nThe currently optional mode Copy-on-Write will be enabled by default in pandas 3.0. There\nwon't be an option to keep the current behavior enabled. The new behavioral semantics are\nexplained in the :ref:`user guide about Copy-on-Write <copy_on_write>`.\n\nThe new behavior can be enabled since pandas 2.0 with the following option:\n\n.. code-block:: ipython\n\n   pd.options.mode.copy_on_write = True\n\nThis change brings different changes in behavior in how pandas operates with respect to\ncopies and views. Some of these changes allow a clear deprecation, like the changes in\nchained assignment. Other changes are more subtle and thus, the warnings are hidden behind\nan option that can be enabled in pandas 2.2.\n\n.. code-block:: ipython\n\n   pd.options.mode.copy_on_write = \"warn\"\n\nThis mode will warn in many different scenarios that aren't actually relevant to\nmost queries. We recommend exploring this mode, but it is not necessary to get rid\nof all of these warnings. The :ref:`migration guide <copy_on_write.migration_guide>`\nexplains the upgrade process in more detail.\n\nDedicated string data type (backed by Arrow) by default\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nHistorically, pandas represented string columns with NumPy object data type. This\nrepresentation has numerous problems, including slow performance and a large memory\nfootprint. This will change in pandas 3.0. pandas will start inferring string columns\nas a new ``string`` data type, backed by Arrow, which represents strings contiguous in memory. This brings\na huge performance and memory improvement.\n\nOld behavior:\n\n.. code-block:: ipython\n\n    In [1]: ser = pd.Series([\"a\", \"b\"])\n    Out[1]:\n    0    a\n    1    b\n    dtype: object\n\nNew behavior:\n\n\n.. code-block:: ipython\n\n    In [1]: ser = pd.Series([\"a\", \"b\"])\n    Out[1]:\n    0    a\n    1    b\n    dtype: string\n\nThe string data type that is used in these scenarios will mostly behave as NumPy\nobject would, including missing value semantics and general operations on these\ncolumns.\n\nThis change includes a few additional changes across the API:\n\n- Currently, specifying ``dtype=\"string\"`` creates a dtype that is backed by Python strings\n  which are stored in a NumPy array. This will change in pandas 3.0, this dtype\n  will create an Arrow backed string column.\n- The column names and the Index will also be backed by Arrow strings.\n- PyArrow will become a required dependency with pandas 3.0 to accommodate this change.\n\nThis future dtype inference logic can be enabled with:\n\n.. code-block:: ipython\n\n   pd.options.future.infer_string = True\n\n.. _whatsnew_220.enhancements:\n\nEnhancements\n~~~~~~~~~~~~\n\n.. _whatsnew_220.enhancements.adbc_support:\n\nADBC Driver support in to_sql and read_sql\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n:func:`read_sql` and :meth:`~DataFrame.to_sql` now work with `Apache Arrow ADBC\n<https://arrow.apache.org/adbc/current/index.html>`_ drivers. Compared to\ntraditional drivers used via SQLAlchemy, ADBC drivers should provide\nsignificant performance improvements, better type support and cleaner\nnullability handling.\n\n.. code-block:: ipython\n\n   import adbc_driver_postgresql.dbapi as pg_dbapi\n\n   df = pd.DataFrame(\n       [\n           [1, 2, 3],\n           [4, 5, 6],\n       ],\n       columns=['a', 'b', 'c']\n   )\n   uri = \"postgresql://postgres:postgreslocalhost/postgres\"\n   with pg_dbapi.connect(uri) as conn:\n       df.to_sql(\"pandas_table\", conn, index=False)\n\n    for round-tripping\n   with pg_dbapi.connect(uri) as conn:\n       df2 = pd.read_sql(\"pandas_table\", conn)\n\nThe Arrow type system offers a wider array of types that can more closely match\nwhat databases like PostgreSQL can offer. To illustrate, note this (non-exhaustive)\nlisting of types available in different databases and pandas backends:\n\n+-----------------+-----------------------+----------------+---------+\n|numpy/pandas     |arrow                  |postgres        |sqlite   |\n+=================+=======================+================+=========+\n|int16/Int16      |int16                  |SMALLINT        |INTEGER  |\n+-----------------+-----------------------+----------------+---------+\n|int32/Int32      |int32                  |INTEGER         |INTEGER  |\n+-----------------+-----------------------+----------------+---------+\n|int64/Int64      |int64                  |BIGINT          |INTEGER  |\n+-----------------+-----------------------+----------------+---------+\n|float32          |float32                |REAL            |REAL     |\n+-----------------+-----------------------+----------------+---------+\n|float64          |float64                |DOUBLE PRECISION|REAL     |\n+-----------------+-----------------------+----------------+---------+\n|object           |string                 |TEXT            |TEXT     |\n+-----------------+-----------------------+----------------+---------+\n|bool             |``bool_``              |BOOLEAN         |         |\n+-----------------+-----------------------+----------------+---------+\n|datetime64[ns]   |timestamp(us)          |TIMESTAMP       |         |\n+-----------------+-----------------------+----------------+---------+\n|datetime64[ns,tz]|timestamp(us,tz)       |TIMESTAMPTZ     |         |\n+-----------------+-----------------------+----------------+---------+\n|                 |date32                 |DATE            |         |\n+-----------------+-----------------------+----------------+---------+\n|                 |month_day_nano_interval|INTERVAL        |         |\n+-----------------+-----------------------+----------------+---------+\n|                 |binary                 |BINARY          |BLOB     |\n+-----------------+-----------------------+----------------+---------+\n|                 |decimal128             |DECIMAL [f1]_  |         |\n+-----------------+-----------------------+----------------+---------+\n|                 |list                   |ARRAY [f1]_    |         |\n+-----------------+-----------------------+----------------+---------+\n|                 |struct                 |COMPOSITE TYPE  |         |\n|                 |                       | [f1]_         |         |\n+-----------------+-----------------------+----------------+---------+\n\n.. rubric:: Footnotes\n\n.. [f1] Not implemented as of writing, but theoretically possible\n\nIf you are interested in preserving database types as best as possible\nthroughout the lifecycle of your DataFrame, users are encouraged to\nleverage the ``dtype_backend=\"pyarrow\"`` argument of :func:`~pandas.read_sql`\n\n.. code-block:: ipython\n\n    for round-tripping\n   with pg_dbapi.connect(uri) as conn:\n       df2 = pd.read_sql(\"pandas_table\", conn, dtype_backend=\"pyarrow\")\n\nThis will prevent your data from being converted to the traditional pandas/NumPy\ntype system, which often converts SQL types in ways that make them impossible to\nround-trip.\n\nFor a full list of ADBC drivers and their development status, see the `ADBC Driver\nImplementation Status <https://arrow.apache.org/adbc/current/driver/status.html>`_\ndocumentation.\n\n.. _whatsnew_220.enhancements.case_when:\n\nCreate a pandas Series based on one or more conditions\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nThe :meth:`Series.case_when` function has been added to create a Series object based on one or more conditions. (:issue:`39154`)\n\n.. ipython:: python\n\n   import pandas as pd\n\n   df = pd.DataFrame(dict(a=[1, 2, 3], b=[4, 5, 6]))\n   default=pd.Series('default', index=df.index)\n   default.case_when(\n        caselist=[\n            (df.a == 1, 'first'),                               condition, replacement\n            (df.a.gt(1) & df.b.eq(5), 'second'),   condition, replacement\n        ],\n   )\n\n.. _whatsnew_220.enhancements.to_numpy_ea:\n\n``to_numpy`` for NumPy nullable and Arrow types converts to suitable NumPy dtype\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n``to_numpy`` for NumPy nullable and Arrow types will now convert to a\nsuitable NumPy dtype instead of ``object`` dtype for nullable and PyArrow backed extension dtypes.\n\n*Old behavior:*\n\n.. code-block:: ipython\n\n    In [1]: ser = pd.Series([1, 2, 3], dtype=\"Int64\")\n    In [2]: ser.to_numpy()\n    Out[2]: array([1, 2, 3], dtype=object)\n\n*New behavior:*\n\n.. ipython:: python\n\n    ser = pd.Series([1, 2, 3], dtype=\"Int64\")\n    ser.to_numpy()\n\n    ser = pd.Series([1, 2, 3], dtype=\"timestamp[ns][pyarrow]\")\n    ser.to_numpy()\n\nThe default NumPy dtype (without any arguments) is determined as follows:\n\n- float dtypes are cast to NumPy floats\n- integer dtypes without missing values are cast to NumPy integer dtypes\n- integer dtypes with missing values are cast to NumPy float dtypes and ``NaN`` is used as missing value indicator\n- boolean dtypes without missing values are cast to NumPy bool dtype\n- boolean dtypes with missing values keep object dtype\n- datetime and timedelta types are cast to Numpy datetime64 and timedelta64 types respectively and ``NaT`` is used as missing value indicator\n\n.. _whatsnew_220.enhancements.struct_accessor:\n\nSeries.struct accessor for PyArrow structured data\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nThe ``Series.struct`` accessor provides attributes and methods for processing\ndata with ``struct[pyarrow]`` dtype Series. For example,\n:meth:`Series.struct.explode` converts PyArrow structured data to a pandas\nDataFrame. (:issue:`54938`)\n\n.. ipython:: python\n\n    import pyarrow as pa\n    series = pd.Series(\n        [\n            {\"project\": \"pandas\", \"version\": \"2.2.0\"},\n            {\"project\": \"numpy\", \"version\": \"1.25.2\"},\n            {\"project\": \"pyarrow\", \"version\": \"13.0.0\"},\n        ],\n        dtype=pd.ArrowDtype(\n            pa.struct([\n                (\"project\", pa.string()),\n                (\"version\", pa.string()),\n            ])\n        ),\n    )\n    series.struct.explode()\n\nUse :meth:`Series.struct.field` to index into a (possible nested)\nstruct field.\n\n\n.. ipython:: python\n\n    series.struct.field(\"project\")\n\n.. _whatsnew_220.enhancements.list_accessor:\n\nSeries.list accessor for PyArrow list data\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nThe ``Series.list`` accessor provides attributes and methods for processing\ndata with ``list[pyarrow]`` dtype Series. For example,\n:meth:`Series.list.__getitem__` allows indexing pyarrow lists in\na Series. (:issue:`55323`)\n\n.. ipython:: python\n\n    import pyarrow as pa\n    series = pd.Series(\n        [\n            [1, 2, 3],\n            [4, 5],\n            [6],\n        ],\n        dtype=pd.ArrowDtype(\n            pa.list_(pa.int64())\n        ),\n    )\n    series.list[0]\n\n.. _whatsnew_220.enhancements.calamine:\n\nCalamine engine for :func:`read_excel`\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nThe ``calamine`` engine was added to :func:`read_excel`.\nIt uses ``python-calamine``, which provides Python bindings for the Rust library `calamine <https://crates.io/crates/calamine>`__.\nThis engine supports Excel files (``.xlsx``, ``.xlsm``, ``.xls``, ``.xlsb``) and OpenDocument spreadsheets (``.ods``) (:issue:`50395`).\n\nThere are two advantages of this engine:\n\n1. Calamine is often faster than other engines, some benchmarks show results up to 5x faster than 'openpyxl', 20x - 'odf', 4x - 'pyxlsb', and 1.5x - 'xlrd'.\n   But, 'openpyxl' and 'pyxlsb' are faster in reading a few rows from large files because of lazy iteration over rows.\n2. Calamine supports the recognition of datetime in ``.xlsb`` files, unlike 'pyxlsb' which is the only other engine in pandas that can read ``.xlsb`` files.\n\n.. code-block:: python\n\n   pd.read_excel(\"path_to_file.xlsb\", engine=\"calamine\")\n\n\nFor more, see :ref:`io.calamine` in the user guide on IO tools.\n\n.. _whatsnew_220.enhancements.other:\n\nOther enhancements\n^^^^^^^^^^^^^^^^^^\n\n- :meth:`~DataFrame.to_sql` with method parameter set to ``multi`` works with Oracle on the backend\n- :attr:`Series.attrs` / :attr:`DataFrame.attrs` now uses a deepcopy for propagating ``attrs`` (:issue:`54134`).\n- :func:`get_dummies` now returning  extension dtypes ``boolean`` or ``bool[pyarrow]`` that are compatible with the input dtype (:issue:`56273`)\n- :func:`read_csv` now supports ``on_bad_lines`` parameter with ``engine=\"pyarrow\"`` (:issue:`54480`)\n- :func:`read_sas` returns ``datetime64`` dtypes with resolutions better matching those stored natively in SAS, and avoids returning object-dtype in cases that cannot be stored with ``datetime64[ns]`` dtype (:issue:`56127`)\n- :func:`read_spss` now returns a :class:`DataFrame` that stores the metadata in :attr:`DataFrame.attrs` (:issue:`54264`)\n- :func:`tseries.api.guess_datetime_format` is now part of the public API (:issue:`54727`)\n- :meth:`DataFrame.apply` now allows the usage of numba (via ``engine=\"numba\"``) to JIT compile the passed function, allowing for potential speedups (:issue:`54666`)\n- :meth:`ExtensionArray._explode` interface method added to allow extension type implementations of the ``explode`` method (:issue:`54833`)\n- :meth:`ExtensionArray.duplicated` added to allow extension type implementations of the ``duplicated`` method (:issue:`55255`)\n- :meth:`Series.ffill`, :meth:`Series.bfill`, :meth:`DataFrame.ffill`, and :meth:`DataFrame.bfill` have gained the argument ``limit_area``; 3rd party :class:`.ExtensionArray` authors need to add this argument to the method ``_pad_or_backfill`` (:issue:`56492`)\n- Allow passing ``read_only``, ``data_only`` and ``keep_links`` arguments to openpyxl using ``engine_kwargs`` of :func:`read_excel` (:issue:`55027`)\n- Implement :meth:`Series.interpolate` and :meth:`DataFrame.interpolate` for :class:`ArrowDtype` and masked dtypes (:issue:`56267`)\n- Implement masked algorithms for :meth:`Series.value_counts` (:issue:`54984`)\n- Implemented :meth:`Series.dt` methods and attributes for :class:`ArrowDtype` with ``pyarrow.duration`` type (:issue:`52284`)\n- Implemented :meth:`Series.str.extract` for :class:`ArrowDtype` (:issue:`56268`)\n- Improved error message that appears in :meth:`DatetimeIndex.to_period` with frequencies which are not supported as period frequencies, such as ``\"BMS\"`` (:issue:`56243`)\n- Improved error message when constructing :class:`Period` with invalid offsets such as ``\"QS\"`` (:issue:`55785`)\n- The dtypes ``string[pyarrow]`` and ``string[pyarrow_numpy]`` now both utilize the ``large_string`` type from PyArrow to avoid overflow for long columns (:issue:`56259`)\n\n.. ---------------------------------------------------------------------------\n.. _whatsnew_220.notable_bug_fixes:\n\nNotable bug fixes\n~~~~~~~~~~~~~~~~~\n\nThese are bug fixes that might have notable behavior changes.\n\n.. _whatsnew_220.notable_bug_fixes.merge_sort_behavior:\n\n:func:`merge` and :meth:`DataFrame.join` now consistently follow documented sort behavior\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nIn previous versions of pandas, :func:`merge` and :meth:`DataFrame.join` did not\nalways return a result that followed the documented sort behavior. pandas now\nfollows the documented sort behavior in merge and join operations (:issue:`54611`, :issue:`56426`, :issue:`56443`).\n\nAs documented, ``sort=True`` sorts the join keys lexicographically in the resulting\n:class:`DataFrame`. With ``sort=False``, the order of the join keys depends on the\njoin type (``how`` keyword):\n\n- ``how=\"left\"``: preserve the order of the left keys\n- ``how=\"right\"``: preserve the order of the right keys\n- ``how=\"inner\"``: preserve the order of the left keys\n- ``how=\"outer\"``: sort keys lexicographically\n\nOne example with changing behavior is inner joins with non-unique left join keys\nand ``sort=False``:\n\n.. ipython:: python\n\n    left = pd.DataFrame({\"a\": [1, 2, 1]})\n    right = pd.DataFrame({\"a\": [1, 2]})\n    result = pd.merge(left, right, how=\"inner\", on=\"a\", sort=False)\n\n*Old Behavior*\n\n.. code-block:: ipython\n\n    In [5]: result\n    Out[5]:\n       a\n    0  1\n    1  1\n    2  2\n\n*New Behavior*\n\n.. ipython:: python\n\n    result\n\n.. _whatsnew_220.notable_bug_fixes.multiindex_join_different_levels:\n\n:func:`merge` and :meth:`DataFrame.join` no longer reorder levels when levels differ\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nIn previous versions of pandas, :func:`merge` and :meth:`DataFrame.join` would reorder\nindex levels when joining on two indexes with different levels (:issue:`34133`).\n\n.. ipython:: python\n\n    left = pd.DataFrame({\"left\": 1}, index=pd.MultiIndex.from_tuples([(\"x\", 1), (\"x\", 2)], names=[\"A\", \"B\"]))\n    right = pd.DataFrame({\"right\": 2}, index=pd.MultiIndex.from_tuples([(1, 1), (2, 2)], names=[\"B\", \"C\"]))\n    left\n    right\n    result = left.join(right)\n\n*Old Behavior*\n\n.. code-block:: ipython\n\n    In [5]: result\n    Out[5]:\n           left  right\n    B A C\n    1 x 1     1      2\n    2 x 2     1      2\n\n*New Behavior*\n\n.. ipython:: python\n\n    result\n\n.. _whatsnew_220.api_breaking.deps:\n\nIncreased minimum versions for dependencies\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nFor `optional dependencies <https://pandas.pydata.org/docs/getting_started/install.html>`_ the general recommendation is to use the latest version.\nOptional dependencies below the lowest tested version may still work but are not considered supported.\nThe following table lists the optional dependencies that have had their minimum tested version increased.\n\n+-----------------+---------------------+\n| Package         | New Minimum Version |\n+=================+=====================+\n| beautifulsoup4  | 4.11.2              |\n+-----------------+---------------------+\n| blosc           | 1.21.3              |\n+-----------------+---------------------+\n| bottleneck      | 1.3.6               |\n+-----------------+---------------------+\n| fastparquet     | 2022.12.0           |\n+-----------------+---------------------+\n| fsspec          | 2022.11.0           |\n+-----------------+---------------------+\n| gcsfs           | 2022.11.0           |\n+-----------------+---------------------+\n| lxml            | 4.9.2               |\n+-----------------+---------------------+\n| matplotlib      | 3.6.3               |\n+-----------------+---------------------+\n| numba           | 0.56.4              |\n+-----------------+---------------------+\n| numexpr         | 2.8.4               |\n+-----------------+---------------------+\n| qtpy            | 2.3.0               |\n+-----------------+---------------------+\n| openpyxl        | 3.1.0               |\n+-----------------+---------------------+\n| psycopg2        | 2.9.6               |\n+-----------------+---------------------+\n| pyreadstat      | 1.2.0               |\n+-----------------+---------------------+\n| pytables        | 3.8.0               |\n+-----------------+---------------------+\n| pyxlsb          | 1.0.10              |\n+-----------------+---------------------+\n| s3fs            | 2022.11.0           |\n+-----------------+---------------------+\n| scipy           | 1.10.0              |\n+-----------------+---------------------+\n| sqlalchemy      | 2.0.0               |\n+-----------------+---------------------+\n| tabulate        | 0.9.0               |\n+-----------------+---------------------+\n| xarray          | 2022.12.0           |\n+-----------------+---------------------+\n| xlsxwriter      | 3.0.5               |\n+-----------------+---------------------+\n| zstandard       | 0.19.0              |\n+-----------------+---------------------+\n| pyqt5           | 5.15.8              |\n+-----------------+---------------------+\n| tzdata          | 2022.7              |\n+-----------------+---------------------+\n\nSee :ref:`install.dependencies` and :ref:`install.optional_dependencies` for more.\n\n.. _whatsnew_220.api_breaking.other:\n\nOther API changes\n^^^^^^^^^^^^^^^^^\n- The hash values of nullable extension dtypes changed to improve the performance of the hashing operation (:issue:`56507`)\n- ``check_exact`` now only takes effect for floating-point dtypes in :func:`testing.assert_frame_equal` and :func:`testing.assert_series_equal`. In particular, integer dtypes are always checked exactly (:issue:`55882`)\n\n.. ---------------------------------------------------------------------------\n.. _whatsnew_220.deprecations:\n\nDeprecations\n~~~~~~~~~~~~\n\nChained assignment\n^^^^^^^^^^^^^^^^^^\n\nIn preparation of larger upcoming changes to the copy / view behaviour in pandas 3.0\n(:ref:`copy_on_write`, PDEP-7), we started deprecating *chained assignment*.\n\nChained assignment occurs when you try to update a pandas DataFrame or Series through\ntwo subsequent indexing operations. Depending on the type and order of those operations\nthis currently does or does not work.\n\nA typical example is as follows:\n\n.. code-block:: python\n\n    df = pd.DataFrame({\"foo\": [1, 2, 3], \"bar\": [4, 5, 6]})\n\n     first selecting rows with a mask, then assigning values to a column\n     -> this has never worked and raises a SettingWithCopyWarning\n    df[df[\"bar\"] > 5][\"foo\"] = 100\n\n     first selecting the column, and then assigning to a subset of that column\n     -> this currently works\n    df[\"foo\"][df[\"bar\"] > 5] = 100\n\nThis second example of chained assignment currently works to update the original ``df``.\nThis will no longer work in pandas 3.0, and therefore we started deprecating this:\n\n.. code-block:: python\n\n    >>> df[\"foo\"][df[\"bar\"] > 5] = 100\n    FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n    You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n    A typical example is when you are setting values in a column of a DataFrame, like:\n\n    df[\"col\"][row_indexer] = value\n\n    Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n\n    See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n\nYou can fix this warning and ensure your code is ready for pandas 3.0 by removing\nthe usage of chained assignment. Typically, this can be done by doing the assignment\nin a single step using for example ``.loc``. For the example above, we can do:\n\n.. code-block:: python\n\n    df.loc[df[\"bar\"] > 5, \"foo\"] = 100\n\nThe same deprecation applies to inplace methods that are done in a chained manner, such as:\n\n.. code-block:: python\n\n    >>> df[\"foo\"].fillna(0, inplace=True)\n    FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n    The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\n    For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\nWhen the goal is to update the column in the DataFrame ``df``, the alternative here is\nto call the method on ``df`` itself, such as ``df.fillna({\"foo\": 0}, inplace=True)``.\n\nSee more details in the :ref:`migration guide <copy_on_write.migration_guide>`.\n\n\nDeprecate aliases ``M``, ``Q``, ``Y``, etc. in favour of ``ME``, ``QE``, ``YE``, etc. for offsets\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nDeprecated the following frequency aliases (:issue:`9586`):\n\n+-------------------------------+------------------+------------------+\n|offsets                        |deprecated aliases|new aliases       |\n+===============================+==================+==================+\n|:class:`MonthEnd`              |      ``M``       |     ``ME``       |\n+-------------------------------+------------------+------------------+\n|:class:`BusinessMonthEnd`      |      ``BM``      |     ``BME``      |\n+-------------------------------+------------------+------------------+\n|:class:`SemiMonthEnd`          |      ``SM``      |     ``SME``      |\n+-------------------------------+------------------+------------------+\n|:class:`CustomBusinessMonthEnd`|      ``CBM``     |     ``CBME``     |\n+-------------------------------+------------------+------------------+\n|:class:`QuarterEnd`            |      ``Q``       |     ``QE``       |\n+-------------------------------+------------------+------------------+\n|:class:`BQuarterEnd`           |      ``BQ``      |     ``BQE``      |\n+-------------------------------+------------------+------------------+\n|:class:`YearEnd`               |      ``Y``       |     ``YE``       |\n+-------------------------------+------------------+------------------+\n|:class:`BYearEnd`              |      ``BY``      |     ``BYE``      |\n+-------------------------------+------------------+------------------+\n\nFor example:\n\n*Previous behavior*:\n\n.. code-block:: ipython\n\n    In [8]: pd.date_range('2020-01-01', periods=3, freq='Q-NOV')\n    Out[8]:\n    DatetimeIndex(['2020-02-29', '2020-05-31', '2020-08-31'],\n                  dtype='datetime64[ns]', freq='Q-NOV')\n\n*Future behavior*:\n\n.. ipython:: python\n\n    pd.date_range('2020-01-01', periods=3, freq='QE-NOV')\n\nDeprecated automatic downcasting\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nDeprecated the automatic downcasting of object dtype results in a number of\nmethods. These would silently change the dtype in a hard to predict manner since the\nbehavior was value dependent. Additionally, pandas is moving away from silent dtype\nchanges (:issue:`54710`, :issue:`54261`).\n\nThese methods are:\n\n- :meth:`Series.replace` and :meth:`DataFrame.replace`\n- :meth:`DataFrame.fillna`, :meth:`Series.fillna`\n- :meth:`DataFrame.ffill`, :meth:`Series.ffill`\n- :meth:`DataFrame.bfill`, :meth:`Series.bfill`\n- :meth:`DataFrame.mask`, :meth:`Series.mask`\n- :meth:`DataFrame.where`, :meth:`Series.where`\n- :meth:`DataFrame.clip`, :meth:`Series.clip`\n\nExplicitly call :meth:`DataFrame.infer_objects` to replicate the current behavior in the future.\n\n.. code-block:: ipython\n\n    result = result.infer_objects(copy=False)\n\nOr explicitly cast all-round floats to ints using ``astype``.\n\nSet the following option to opt into the future behavior:\n\n.. code-block:: ipython\n\n    In [9]: pd.set_option(\"future.no_silent_downcasting\", True)\n\nOther Deprecations\n^^^^^^^^^^^^^^^^^^\n- Changed :meth:`Timedelta.resolution_string` to return ``h``, ``min``, ``s``, ``ms``, ``us``, and ``ns`` instead of ``H``, ``T``, ``S``, ``L``, ``U``, and ``N``, for compatibility with respective deprecations in frequency aliases (:issue:`52536`)\n- Deprecated :attr:`offsets.Day.delta`, :attr:`offsets.Hour.delta`, :attr:`offsets.Minute.delta`, :attr:`offsets.Second.delta`, :attr:`offsets.Milli.delta`, :attr:`offsets.Micro.delta`, :attr:`offsets.Nano.delta`, use ``pd.Timedelta(obj)`` instead (:issue:`55498`)\n- Deprecated :func:`pandas.api.types.is_interval` and :func:`pandas.api.types.is_period`, use ``isinstance(obj, pd.Interval)`` and ``isinstance(obj, pd.Period)`` instead (:issue:`55264`)\n- Deprecated :func:`read_gbq` and :meth:`DataFrame.to_gbq`. Use ``pandas_gbq.read_gbq`` and ``pandas_gbq.to_gbq`` instead https://pandas-gbq.readthedocs.io/en/latest/api.html (:issue:`55525`)\n- Deprecated :meth:`.DataFrameGroupBy.fillna` and :meth:`.SeriesGroupBy.fillna`; use :meth:`.DataFrameGroupBy.ffill`, :meth:`.DataFrameGroupBy.bfill` for forward and backward filling or :meth:`.DataFrame.fillna` to fill with a single value (or the Series equivalents) (:issue:`55718`)\n- Deprecated :meth:`DateOffset.is_anchored`, use ``obj.n == 1`` for non-Tick subclasses (for Tick this was always False) (:issue:`55388`)\n- Deprecated :meth:`DatetimeArray.__init__` and :meth:`TimedeltaArray.__init__`, use :func:`array` instead (:issue:`55623`)\n- Deprecated :meth:`Index.format`, use ``index.astype(str)`` or ``index.map(formatter)`` instead (:issue:`55413`)\n- Deprecated :meth:`Series.ravel`, the underlying array is already 1D, so ravel is not necessary (:issue:`52511`)\n- Deprecated :meth:`Series.resample` and :meth:`DataFrame.resample` with a :class:`PeriodIndex` (and the 'convention' keyword), convert to :class:`DatetimeIndex` (with ``.to_timestamp()``) before resampling instead (:issue:`53481`)\n- Deprecated :meth:`Series.view`, use :meth:`Series.astype` instead to change the dtype (:issue:`20251`)\n- Deprecated :meth:`offsets.Tick.is_anchored`, use ``False`` instead (:issue:`55388`)\n- Deprecated ``core.internals`` members ``Block``, ``ExtensionBlock``, and ``DatetimeTZBlock``, use public APIs instead (:issue:`55139`)\n- Deprecated ``year``, ``month``, ``quarter``, ``day``, ``hour``, ``minute``, and ``second`` keywords in the :class:`PeriodIndex` constructor, use :meth:`PeriodIndex.from_fields` instead (:issue:`55960`)\n- Deprecated accepting a type as an argument in :meth:`Index.view`, call without any arguments instead (:issue:`55709`)\n- Deprecated allowing non-integer ``periods`` argument in :func:`date_range`, :func:`timedelta_range`, :func:`period_range`, and :func:`interval_range` (:issue:`56036`)\n- Deprecated allowing non-keyword arguments in :meth:`DataFrame.to_clipboard` (:issue:`54229`)\n- Deprecated allowing non-keyword arguments in :meth:`DataFrame.to_csv` except ``path_or_buf`` (:issue:`54229`)\n- Deprecated allowing non-keyword arguments in :meth:`DataFrame.to_dict` (:issue:`54229`)\n- Deprecated allowing non-keyword arguments in :meth:`DataFrame.to_excel` except ``excel_writer`` (:issue:`54229`)\n- Deprecated allowing non-keyword arguments in :meth:`DataFrame.to_gbq` except ``destination_table`` (:issue:`54229`)\n- Deprecated allowing non-keyword arguments in :meth:`DataFrame.to_hdf` except ``path_or_buf`` (:issue:`54229`)\n- Deprecated allowing non-keyword arguments in :meth:`DataFrame.to_html` except ``buf`` (:issue:`54229`)\n- Deprecated allowing non-keyword arguments in :meth:`DataFrame.to_json` except ``path_or_buf`` (:issue:`54229`)\n- Deprecated allowing non-keyword arguments in :meth:`DataFrame.to_latex` except ``buf`` (:issue:`54229`)\n- Deprecated allowing non-keyword arguments in :meth:`DataFrame.to_markdown` except ``buf`` (:issue:`54229`)\n- Deprecated allowing non-keyword arguments in :meth:`DataFrame.to_parquet` except ``path`` (:issue:`54229`)\n- Deprecated allowing non-keyword arguments in :meth:`DataFrame.to_pickle` except ``path`` (:issue:`54229`)\n- Deprecated allowing non-keyword arguments in :meth:`DataFrame.to_string` except ``buf`` (:issue:`54229`)\n- Deprecated allowing non-keyword arguments in :meth:`DataFrame.to_xml` except ``path_or_buffer`` (:issue:`54229`)\n- Deprecated allowing passing :class:`BlockManager` objects to :class:`DataFrame` or :class:`SingleBlockManager` objects to :class:`Series` (:issue:`52419`)\n- Deprecated behavior of :meth:`Index.insert` with an object-dtype index silently performing type inference on the result, explicitly call ``result.infer_objects(copy=False)`` for the old behavior instead (:issue:`51363`)\n- Deprecated casting non-datetimelike values (mainly strings) in :meth:`Series.isin` and :meth:`Index.isin` with ``datetime64``, ``timedelta64``, and :class:`PeriodDtype` dtypes (:issue:`53111`)\n- Deprecated dtype inference in :class:`Index`, :class:`Series` and :class:`DataFrame` constructors when giving a pandas input, call ``.infer_objects`` on the input to keep the current behavior (:issue:`56012`)\n- Deprecated dtype inference when setting a :class:`Index` into a :class:`DataFrame`, cast explicitly instead (:issue:`56102`)\n- Deprecated including the groups in computations when using :meth:`.DataFrameGroupBy.apply` and :meth:`.DataFrameGroupBy.resample`; pass ``include_groups=False`` to exclude the groups (:issue:`7155`)\n- Deprecated indexing an :class:`Index`  with a boolean indexer of length zero (:issue:`55820`)\n- Deprecated not passing a tuple to :class:`.DataFrameGroupBy.get_group` or :class:`.SeriesGroupBy.get_group` when grouping by a length-1 list-like (:issue:`25971`)\n- Deprecated string ``AS`` denoting frequency in :class:`YearBegin` and strings ``AS-DEC``, ``AS-JAN``, etc. denoting annual frequencies with various fiscal year starts (:issue:`54275`)\n- Deprecated string ``A`` denoting frequency in :class:`YearEnd` and strings ``A-DEC``, ``A-JAN``, etc. denoting annual frequencies with various fiscal year ends (:issue:`54275`)\n- Deprecated string ``BAS`` denoting frequency in :class:`BYearBegin` and strings ``BAS-DEC``, ``BAS-JAN``, etc. denoting annual frequencies with various fiscal year starts (:issue:`54275`)\n- Deprecated string ``BA`` denoting frequency in :class:`BYearEnd` and strings ``BA-DEC``, ``BA-JAN``, etc. denoting annual frequencies with various fiscal year ends (:issue:`54275`)\n- Deprecated strings ``H``, ``BH``, and ``CBH`` denoting frequencies in :class:`Hour`, :class:`BusinessHour`, :class:`CustomBusinessHour` (:issue:`52536`)\n- Deprecated strings ``H``, ``S``, ``U``, and ``N`` denoting units in :func:`to_timedelta` (:issue:`52536`)\n- Deprecated strings ``H``, ``T``, ``S``, ``L``, ``U``, and ``N`` denoting units in :class:`Timedelta` (:issue:`52536`)\n- Deprecated strings ``T``, ``S``, ``L``, ``U``, and ``N`` denoting frequencies in :class:`Minute`, :class:`Second`, :class:`Milli`, :class:`Micro`, :class:`Nano` (:issue:`52536`)\n- Deprecated support for combining parsed datetime columns in :func:`read_csv` along with the ``keep_date_col`` keyword (:issue:`55569`)\n- Deprecated the :attr:`.DataFrameGroupBy.grouper` and :attr:`SeriesGroupBy.grouper`; these attributes will be removed in a future version of pandas (:issue:`56521`)\n- Deprecated the :class:`.Grouping` attributes ``group_index``, ``result_index``, and ``group_arraylike``; these will be removed in a future version of pandas (:issue:`56148`)\n- Deprecated the ``delim_whitespace`` keyword in :func:`read_csv` and :func:`read_table`, use ``sep=\"\\\\s+\"`` instead (:issue:`55569`)\n- Deprecated the ``errors=\"ignore\"`` option in :func:`to_datetime`, :func:`to_timedelta`, and :func:`to_numeric`; explicitly catch exceptions instead (:issue:`54467`)\n- Deprecated the ``fastpath`` keyword in the :class:`Series` constructor (:issue:`20110`)\n- Deprecated the ``kind`` keyword in :meth:`Series.resample` and :meth:`DataFrame.resample`, explicitly cast the object's ``index`` instead (:issue:`55895`)\n- Deprecated the ``ordinal`` keyword in :class:`PeriodIndex`, use :meth:`PeriodIndex.from_ordinals` instead (:issue:`55960`)\n- Deprecated the ``unit`` keyword in :class:`TimedeltaIndex` construction, use :func:`to_timedelta` instead (:issue:`55499`)\n- Deprecated the ``verbose`` keyword in :func:`read_csv` and :func:`read_table` (:issue:`55569`)\n- Deprecated the behavior of :meth:`DataFrame.replace` and :meth:`Series.replace` with :class:`CategoricalDtype`; in a future version replace will change the values while preserving the categories. To change the categories, use ``ser.cat.rename_categories`` instead (:issue:`55147`)\n- Deprecated the behavior of :meth:`Series.value_counts` and :meth:`Index.value_counts` with object dtype; in a future version these will not perform dtype inference on the resulting :class:`Index`, do ``result.index = result.index.infer_objects()`` to retain the old behavior (:issue:`56161`)\n- Deprecated the default of ``observed=False`` in :meth:`DataFrame.pivot_table`; will be ``True`` in a future version (:issue:`56236`)\n- Deprecated the extension test classes ``BaseNoReduceTests``, ``BaseBooleanReduceTests``, and ``BaseNumericReduceTests``, use ``BaseReduceTests`` instead (:issue:`54663`)\n- Deprecated the option ``mode.data_manager`` and the ``ArrayManager``; only the ``BlockManager`` will be available in future versions (:issue:`55043`)\n- Deprecated the previous implementation of :class:`DataFrame.stack`; specify ``future_stack=True`` to adopt the future version (:issue:`53515`)\n-\n\n.. ---------------------------------------------------------------------------\n.. _whatsnew_220.performance:\n\nPerformance improvements\n~~~~~~~~~~~~~~~~~~~~~~~~\n- Performance improvement in :func:`.testing.assert_frame_equal` and :func:`.testing.assert_series_equal` (:issue:`55949`, :issue:`55971`)\n- Performance improvement in :func:`concat` with ``axis=1`` and objects with unaligned indexes (:issue:`55084`)\n- Performance improvement in :func:`get_dummies` (:issue:`56089`)\n- Performance improvement in :func:`merge` and :func:`merge_ordered` when joining on sorted ascending keys (:issue:`56115`)\n- Performance improvement in :func:`merge_asof` when ``by`` is not ``None`` (:issue:`55580`, :issue:`55678`)\n- Performance improvement in :func:`read_stata` for files with many variables (:issue:`55515`)\n- Performance improvement in :meth:`DataFrame.groupby` when aggregating pyarrow timestamp and duration dtypes (:issue:`55031`)\n- Performance improvement in :meth:`DataFrame.join` when joining on unordered categorical indexes (:issue:`56345`)\n- Performance improvement in :meth:`DataFrame.loc` and :meth:`Series.loc` when indexing with a :class:`MultiIndex` (:issue:`56062`)\n- Performance improvement in :meth:`DataFrame.sort_index` and :meth:`Series.sort_index` when indexed by a :class:`MultiIndex` (:issue:`54835`)\n- Performance improvement in :meth:`DataFrame.to_dict` on converting DataFrame to dictionary (:issue:`50990`)\n- Performance improvement in :meth:`Index.difference` (:issue:`55108`)\n- Performance improvement in :meth:`Index.sort_values` when index is already sorted (:issue:`56128`)\n- Performance improvement in :meth:`MultiIndex.get_indexer` when ``method`` is not ``None`` (:issue:`55839`)\n- Performance improvement in :meth:`Series.duplicated` for pyarrow dtypes (:issue:`55255`)\n- Performance improvement in :meth:`Series.str.get_dummies` when dtype is ``\"string[pyarrow]\"`` or ``\"string[pyarrow_numpy]\"`` (:issue:`56110`)\n- Performance improvement in :meth:`Series.str` methods (:issue:`55736`)\n- Performance improvement in :meth:`Series.value_counts` and :meth:`Series.mode` for masked dtypes (:issue:`54984`, :issue:`55340`)\n- Performance improvement in :meth:`.DataFrameGroupBy.nunique` and :meth:`.SeriesGroupBy.nunique` (:issue:`55972`)\n- Performance improvement in :meth:`.SeriesGroupBy.idxmax`, :meth:`.SeriesGroupBy.idxmin`, :meth:`.DataFrameGroupBy.idxmax`, :meth:`.DataFrameGroupBy.idxmin` (:issue:`54234`)\n- Performance improvement when hashing a nullable extension array (:issue:`56507`)\n- Performance improvement when indexing into a non-unique index (:issue:`55816`)\n- Performance improvement when indexing with more than 4 keys (:issue:`54550`)\n- Performance improvement when localizing time to UTC (:issue:`55241`)\n\n.. ---------------------------------------------------------------------------\n.. _whatsnew_220.bug_fixes:\n\nBug fixes\n~~~~~~~~~\n\nCategorical\n^^^^^^^^^^^\n- :meth:`Categorical.isin` raising ``InvalidIndexError`` for categorical containing overlapping :class:`Interval` values (:issue:`34974`)\n- Bug in :meth:`CategoricalDtype.__eq__` returning ``False`` for unordered categorical data with mixed types (:issue:`55468`)\n- Bug when casting ``pa.dictionary`` to :class:`CategoricalDtype` using a ``pa.DictionaryArray`` as categories (:issue:`56672`)\n\nDatetimelike\n^^^^^^^^^^^^\n- Bug in :class:`DatetimeIndex` construction when passing both a ``tz`` and either ``dayfirst`` or ``yearfirst`` ignoring dayfirst/yearfirst (:issue:`55813`)\n- Bug in :class:`DatetimeIndex` when passing an object-dtype ndarray of float objects and a ``tz`` incorrectly localizing the result (:issue:`55780`)\n- Bug in :func:`Series.isin` with :class:`DatetimeTZDtype` dtype and comparison values that are all ``NaT`` incorrectly returning all-``False`` even if the series contains ``NaT`` entries (:issue:`56427`)\n- Bug in :func:`concat` raising ``AttributeError`` when concatenating all-NA DataFrame with :class:`DatetimeTZDtype` dtype DataFrame (:issue:`52093`)\n- Bug in :func:`testing.assert_extension_array_equal` that could use the wrong unit when comparing resolutions (:issue:`55730`)\n- Bug in :func:`to_datetime` and :class:`DatetimeIndex` when passing a list of mixed-string-and-numeric types incorrectly raising (:issue:`55780`)\n- Bug in :func:`to_datetime` and :class:`DatetimeIndex` when passing mixed-type objects with a mix of timezones or mix of timezone-awareness failing to raise ``ValueError`` (:issue:`55693`)\n- Bug in :meth:`.Tick.delta` with very large ticks raising ``OverflowError`` instead of ``OutOfBoundsTimedelta`` (:issue:`55503`)\n- Bug in :meth:`DatetimeIndex.shift` with non-nanosecond resolution incorrectly returning with nanosecond resolution (:issue:`56117`)\n- Bug in :meth:`DatetimeIndex.union` returning object dtype for tz-aware indexes with the same timezone but different units (:issue:`55238`)\n- Bug in :meth:`Index.is_monotonic_increasing` and :meth:`Index.is_monotonic_decreasing` always caching :meth:`Index.is_unique` as ``True`` when first value in index is ``NaT`` (:issue:`55755`)\n- Bug in :meth:`Index.view` to a datetime64 dtype with non-supported resolution incorrectly raising (:issue:`55710`)\n- Bug in :meth:`Series.dt.round` with non-nanosecond resolution and ``NaT`` entries incorrectly raising ``OverflowError`` (:issue:`56158`)\n- Bug in :meth:`Series.fillna` with non-nanosecond resolution dtypes and higher-resolution vector values returning incorrect (internally-corrupted) results (:issue:`56410`)\n- Bug in :meth:`Timestamp.unit` being inferred incorrectly from an ISO8601 format string with minute or hour resolution and a timezone offset (:issue:`56208`)\n- Bug in ``.astype`` converting from a higher-resolution ``datetime64`` dtype to a lower-resolution ``datetime64`` dtype (e.g. ``datetime64[us]->datetime64[ms]``) silently overflowing with values near the lower implementation bound (:issue:`55979`)\n- Bug in adding or subtracting a :class:`Week` offset to a ``datetime64`` :class:`Series`, :class:`Index`, or :class:`DataFrame` column with non-nanosecond resolution returning incorrect results (:issue:`55583`)\n- Bug in addition or subtraction of :class:`BusinessDay` offset with ``offset`` attribute to non-nanosecond :class:`Index`, :class:`Series`, or :class:`DataFrame` column giving incorrect results (:issue:`55608`)\n- Bug in addition or subtraction of :class:`DateOffset` objects with microsecond components to ``datetime64`` :class:`Index`, :class:`Series`, or :class:`DataFrame` columns with non-nanosecond resolution (:issue:`55595`)\n- Bug in addition or subtraction of very large :class:`.Tick` objects with :class:`Timestamp` or :class:`Timedelta` objects raising ``OverflowError`` instead of ``OutOfBoundsTimedelta`` (:issue:`55503`)\n- Bug in creating a :class:`Index`, :class:`Series`, or :class:`DataFrame` with a non-nanosecond :class:`DatetimeTZDtype` and inputs that would be out of bounds with nanosecond resolution incorrectly raising ``OutOfBoundsDatetime`` (:issue:`54620`)\n- Bug in creating a :class:`Index`, :class:`Series`, or :class:`DataFrame` with a non-nanosecond ``datetime64`` (or :class:`DatetimeTZDtype`) from mixed-numeric inputs treating those as nanoseconds instead of as multiples of the dtype's unit (which would happen with non-mixed numeric inputs) (:issue:`56004`)\n- Bug in creating a :class:`Index`, :class:`Series`, or :class:`DataFrame` with a non-nanosecond ``datetime64`` dtype and inputs that would be out of bounds for a ``datetime64[ns]`` incorrectly raising ``OutOfBoundsDatetime`` (:issue:`55756`)\n- Bug in parsing datetime strings with nanosecond resolution with non-ISO8601 formats incorrectly truncating sub-microsecond components (:issue:`56051`)\n- Bug in parsing datetime strings with sub-second resolution and trailing zeros incorrectly inferring second or millisecond resolution (:issue:`55737`)\n- Bug in the results of :func:`to_datetime` with an floating-dtype argument with ``unit`` not matching the pointwise results of :class:`Timestamp` (:issue:`56037`)\n- Fixed regression where :func:`concat` would raise an error when concatenating ``datetime64`` columns with differing resolutions (:issue:`53641`)\n\nTimedelta\n^^^^^^^^^\n- Bug in :class:`Timedelta` construction raising ``OverflowError`` instead of ``OutOfBoundsTimedelta`` (:issue:`55503`)\n- Bug in rendering (``__repr__``) of :class:`TimedeltaIndex` and :class:`Series` with timedelta64 values with non-nanosecond resolution entries that are all multiples of 24 hours failing to use the compact representation used in the nanosecond cases (:issue:`55405`)\n\nTimezones\n^^^^^^^^^\n- Bug in :class:`AbstractHolidayCalendar` where timezone data was not propagated when computing holiday observances (:issue:`54580`)\n- Bug in :class:`Timestamp` construction with an ambiguous value and a ``pytz`` timezone failing to raise ``pytz.AmbiguousTimeError`` (:issue:`55657`)\n- Bug in :meth:`Timestamp.tz_localize` with ``nonexistent=\"shift_forward`` around UTC+0 during DST (:issue:`51501`)\n\nNumeric\n^^^^^^^\n- Bug in :func:`read_csv` with ``engine=\"pyarrow\"`` causing rounding errors for large integers (:issue:`52505`)\n- Bug in :meth:`Series.__floordiv__` and :meth:`Series.__truediv__` for :class:`ArrowDtype` with integral dtypes raising for large divisors (:issue:`56706`)\n- Bug in :meth:`Series.__floordiv__` for :class:`ArrowDtype` with integral dtypes raising for large values (:issue:`56645`)\n- Bug in :meth:`Series.pow` not filling missing values correctly (:issue:`55512`)\n- Bug in :meth:`Series.replace` and :meth:`DataFrame.replace` matching float ``0.0`` with ``False`` and vice versa (:issue:`55398`)\n- Bug in :meth:`Series.round` raising for nullable boolean dtype (:issue:`55936`)\n\nConversion\n^^^^^^^^^^\n- Bug in :meth:`DataFrame.astype` when called with ``str`` on unpickled array - the array might change in-place (:issue:`54654`)\n- Bug in :meth:`DataFrame.astype` where ``errors=\"ignore\"`` had no effect for extension types (:issue:`54654`)\n- Bug in :meth:`Series.convert_dtypes` not converting all NA column to ``null[pyarrow]`` (:issue:`55346`)\n- Bug in :meth:``DataFrame.loc`` was not throwing \"incompatible dtype warning\" (see `PDEP6 <https://pandas.pydata.org/pdeps/0006-ban-upcasting.html>`_) when assigning a ``Series`` with a different dtype using a full column setter (e.g. ``df.loc[:, 'a'] = incompatible_value``) (:issue:`39584`)\n\nStrings\n^^^^^^^\n- Bug in :func:`pandas.api.types.is_string_dtype` while checking object array with no elements is of the string dtype (:issue:`54661`)\n- Bug in :meth:`DataFrame.apply` failing when ``engine=\"numba\"`` and columns or index have ``StringDtype`` (:issue:`56189`)\n- Bug in :meth:`DataFrame.reindex` not matching :class:`Index` with ``string[pyarrow_numpy]`` dtype (:issue:`56106`)\n- Bug in :meth:`Index.str.cat` always casting result to object dtype (:issue:`56157`)\n- Bug in :meth:`Series.__mul__` for :class:`ArrowDtype` with ``pyarrow.string`` dtype and ``string[pyarrow]`` for the pyarrow backend (:issue:`51970`)\n- Bug in :meth:`Series.str.find` when ``start < 0`` for :class:`ArrowDtype` with ``pyarrow.string`` (:issue:`56411`)\n- Bug in :meth:`Series.str.fullmatch` when ``dtype=pandas.ArrowDtype(pyarrow.string()))`` allows partial matches when regex ends in literal //$ (:issue:`56652`)\n- Bug in :meth:`Series.str.replace` when ``n < 0`` for :class:`ArrowDtype` with ``pyarrow.string`` (:issue:`56404`)\n- Bug in :meth:`Series.str.startswith` and :meth:`Series.str.endswith` with arguments of type ``tuple[str, ...]`` for :class:`ArrowDtype` with ``pyarrow.string`` dtype (:issue:`56579`)\n- Bug in :meth:`Series.str.startswith` and :meth:`Series.str.endswith` with arguments of type ``tuple[str, ...]`` for ``string[pyarrow]`` (:issue:`54942`)\n- Bug in comparison operations for ``dtype=\"string[pyarrow_numpy]\"`` raising if dtypes can't be compared (:issue:`56008`)\n\nInterval\n^^^^^^^^\n- Bug in :class:`Interval` ``__repr__`` not displaying UTC offsets for :class:`Timestamp` bounds. Additionally the hour, minute and second components will now be shown (:issue:`55015`)\n- Bug in :meth:`IntervalIndex.factorize` and :meth:`Series.factorize` with :class:`IntervalDtype` with datetime64 or timedelta64 intervals not preserving non-nanosecond units (:issue:`56099`)\n- Bug in :meth:`IntervalIndex.from_arrays` when passed ``datetime64`` or ``timedelta64`` arrays with mismatched resolutions constructing an invalid ``IntervalArray`` object (:issue:`55714`)\n- Bug in :meth:`IntervalIndex.from_tuples` raising if subtype is a nullable extension dtype (:issue:`56765`)\n- Bug in :meth:`IntervalIndex.get_indexer` with datetime or timedelta intervals incorrectly matching on integer targets (:issue:`47772`)\n- Bug in :meth:`IntervalIndex.get_indexer` with timezone-aware datetime intervals incorrectly matching on a sequence of timezone-naive targets (:issue:`47772`)\n- Bug in setting values on a :class:`Series` with an :class:`IntervalIndex` using a slice incorrectly raising (:issue:`54722`)\n\nIndexing\n^^^^^^^^\n- Bug in :meth:`DataFrame.loc` mutating a boolean indexer when :class:`DataFrame` has a :class:`MultiIndex` (:issue:`56635`)\n- Bug in :meth:`DataFrame.loc` when setting :class:`Series` with extension dtype into NumPy dtype (:issue:`55604`)\n- Bug in :meth:`Index.difference` not returning a unique set of values when ``other`` is empty or ``other`` is considered non-comparable (:issue:`55113`)\n- Bug in setting :class:`Categorical` values into a :class:`DataFrame` with numpy dtypes raising ``RecursionError`` (:issue:`52927`)\n- Fixed bug when creating new column with missing values when setting a single string value (:issue:`56204`)\n\nMissing\n^^^^^^^\n- Bug in :meth:`DataFrame.update` wasn't updating in-place for tz-aware datetime64 dtypes (:issue:`56227`)\n\nMultiIndex\n^^^^^^^^^^\n- Bug in :meth:`MultiIndex.get_indexer` not raising ``ValueError`` when ``method`` provided and index is non-monotonic (:issue:`53452`)\n\nI/O\n^^^\n- Bug in :func:`read_csv` where ``engine=\"python\"`` did not respect ``chunksize`` arg when ``skiprows`` was specified (:issue:`56323`)\n- Bug in :func:`read_csv` where ``engine=\"python\"`` was causing a ``TypeError`` when a callable ``skiprows`` and a chunk size was specified (:issue:`55677`)\n- Bug in :func:`read_csv` where ``on_bad_lines=\"warn\"`` would write to ``stderr`` instead of raising a Python warning; this now yields a :class:`.errors.ParserWarning` (:issue:`54296`)\n- Bug in :func:`read_csv` with ``engine=\"pyarrow\"`` where ``quotechar`` was ignored (:issue:`52266`)\n- Bug in :func:`read_csv` with ``engine=\"pyarrow\"`` where ``usecols`` wasn't working with a CSV with no headers (:issue:`54459`)\n- Bug in :func:`read_excel`, with ``engine=\"xlrd\"`` (``xls`` files) erroring when the file contains ``NaN`` or ``Inf`` (:issue:`54564`)\n- Bug in :func:`read_json` not handling dtype conversion properly if ``infer_string`` is set (:issue:`56195`)\n- Bug in :meth:`DataFrame.to_excel`, with ``OdsWriter`` (``ods`` files) writing Boolean/string value (:issue:`54994`)\n- Bug in :meth:`DataFrame.to_hdf` and :func:`read_hdf` with ``datetime64`` dtypes with non-nanosecond resolution failing to round-trip correctly (:issue:`55622`)\n- Bug in :meth:`DataFrame.to_stata` raising for extension dtypes (:issue:`54671`)\n- Bug in :meth:`~pandas.read_excel` with ``engine=\"odf\"`` (``ods`` files) when a string cell contains an annotation (:issue:`55200`)\n- Bug in :meth:`~pandas.read_excel` with an ODS file without cached formatted cell for float values (:issue:`55219`)\n- Bug where :meth:`DataFrame.to_json` would raise an ``OverflowError`` instead of a ``TypeError`` with unsupported NumPy types (:issue:`55403`)\n\nPeriod\n^^^^^^\n- Bug in :class:`PeriodIndex` construction when more than one of ``data``, ``ordinal`` and ``**fields`` are passed failing to raise ``ValueError`` (:issue:`55961`)\n- Bug in :class:`Period` addition silently wrapping around instead of raising ``OverflowError`` (:issue:`55503`)\n- Bug in casting from :class:`PeriodDtype` with ``astype`` to ``datetime64`` or :class:`DatetimeTZDtype` with non-nanosecond unit incorrectly returning with nanosecond unit (:issue:`55958`)\n\nPlotting\n^^^^^^^^\n- Bug in :meth:`DataFrame.plot.box` with ``vert=False`` and a Matplotlib ``Axes`` created with ``sharey=True`` (:issue:`54941`)\n- Bug in :meth:`DataFrame.plot.scatter` discarding string columns (:issue:`56142`)\n- Bug in :meth:`Series.plot` when reusing an ``ax`` object failing to raise when a ``how`` keyword is passed (:issue:`55953`)\n\nGroupby/resample/rolling\n^^^^^^^^^^^^^^^^^^^^^^^^\n- Bug in :meth:`.DataFrameGroupBy.idxmin`, :meth:`.DataFrameGroupBy.idxmax`, :meth:`.SeriesGroupBy.idxmin`, and :meth:`.SeriesGroupBy.idxmax` would not retain :class:`.Categorical` dtype when the index was a :class:`.CategoricalIndex` that contained NA values (:issue:`54234`)\n- Bug in :meth:`.DataFrameGroupBy.transform` and :meth:`.SeriesGroupBy.transform` when ``observed=False`` and ``f=\"idxmin\"`` or ``f=\"idxmax\"`` would incorrectly raise on unobserved categories (:issue:`54234`)\n- Bug in :meth:`.DataFrameGroupBy.value_counts` and :meth:`.SeriesGroupBy.value_counts` could result in incorrect sorting if the columns of the DataFrame or name of the Series are integers (:issue:`55951`)\n- Bug in :meth:`.DataFrameGroupBy.value_counts` and :meth:`.SeriesGroupBy.value_counts` would not respect ``sort=False`` in :meth:`DataFrame.groupby` and :meth:`Series.groupby` (:issue:`55951`)\n- Bug in :meth:`.DataFrameGroupBy.value_counts` and :meth:`.SeriesGroupBy.value_counts` would sort by proportions rather than frequencies when ``sort=True`` and ``normalize=True`` (:issue:`55951`)\n- Bug in :meth:`DataFrame.asfreq` and :meth:`Series.asfreq` with a :class:`DatetimeIndex` with non-nanosecond resolution incorrectly converting to nanosecond resolution (:issue:`55958`)\n- Bug in :meth:`DataFrame.ewm` when passed ``times`` with non-nanosecond ``datetime64`` or :class:`DatetimeTZDtype` dtype (:issue:`56262`)\n- Bug in :meth:`DataFrame.groupby` and :meth:`Series.groupby` where grouping by a combination of ``Decimal`` and NA values would fail when ``sort=True`` (:issue:`54847`)\n- Bug in :meth:`DataFrame.groupby` for DataFrame subclasses when selecting a subset of columns to apply the function to (:issue:`56761`)\n- Bug in :meth:`DataFrame.resample` not respecting ``closed`` and ``label`` arguments for :class:`~pandas.tseries.offsets.BusinessDay` (:issue:`55282`)\n- Bug in :meth:`DataFrame.resample` when resampling on a :class:`ArrowDtype` of ``pyarrow.timestamp`` or ``pyarrow.duration`` type (:issue:`55989`)\n- Bug in :meth:`DataFrame.resample` where bin edges were not correct for :class:`~pandas.tseries.offsets.BusinessDay` (:issue:`55281`)\n- Bug in :meth:`DataFrame.resample` where bin edges were not correct for :class:`~pandas.tseries.offsets.MonthBegin` (:issue:`55271`)\n- Bug in :meth:`DataFrame.rolling` and :meth:`Series.rolling` where duplicate datetimelike indexes are treated as consecutive rather than equal with ``closed='left'`` and ``closed='neither'`` (:issue:`20712`)\n- Bug in :meth:`DataFrame.rolling` and :meth:`Series.rolling` where either the ``index`` or ``on`` column was :class:`ArrowDtype` with ``pyarrow.timestamp`` type (:issue:`55849`)\n\nReshaping\n^^^^^^^^^\n- Bug in :func:`concat` ignoring ``sort`` parameter when passed :class:`DatetimeIndex` indexes (:issue:`54769`)\n- Bug in :func:`concat` renaming :class:`Series` when ``ignore_index=False`` (:issue:`15047`)\n- Bug in :func:`merge_asof` raising ``TypeError`` when ``by`` dtype is not ``object``, ``int64``, or ``uint64`` (:issue:`22794`)\n- Bug in :func:`merge_asof` raising incorrect error for string dtype (:issue:`56444`)\n- Bug in :func:`merge_asof` when using a :class:`Timedelta` tolerance on a :class:`ArrowDtype` column (:issue:`56486`)\n- Bug in :func:`merge` not raising when merging datetime columns with timedelta columns (:issue:`56455`)\n- Bug in :func:`merge` not raising when merging string columns with numeric columns (:issue:`56441`)\n- Bug in :func:`merge` not sorting for new string dtype (:issue:`56442`)\n- Bug in :func:`merge` returning columns in incorrect order when left and/or right is empty (:issue:`51929`)\n- Bug in :meth:`DataFrame.melt` where an exception was raised if ``var_name`` was not a string (:issue:`55948`)\n- Bug in :meth:`DataFrame.melt` where it would not preserve the datetime (:issue:`55254`)\n- Bug in :meth:`DataFrame.pivot_table` where the row margin is incorrect when the columns have numeric names (:issue:`26568`)\n- Bug in :meth:`DataFrame.pivot` with numeric columns and extension dtype for data (:issue:`56528`)\n- Bug in :meth:`DataFrame.stack` with ``future_stack=True`` would not preserve NA values in the index (:issue:`56573`)\n\nSparse\n^^^^^^\n- Bug in :meth:`arrays.SparseArray.take` when using a different fill value than the array's fill value (:issue:`55181`)\n\nOther\n^^^^^\n- :meth:`DataFrame.__dataframe__` did not support pyarrow large strings (:issue:`56702`)\n- Bug in :func:`DataFrame.describe` when formatting percentiles in the resulting percentile 99.999% is rounded to 100% (:issue:`55765`)\n- Bug in :func:`api.interchange.from_dataframe` where it raised  ``NotImplementedError`` when handling empty string columns (:issue:`56703`)\n- Bug in :func:`cut` and :func:`qcut` with ``datetime64`` dtype values with non-nanosecond units incorrectly returning nanosecond-unit bins (:issue:`56101`)\n- Bug in :func:`cut` incorrectly allowing cutting of timezone-aware datetimes with timezone-naive bins (:issue:`54964`)\n- Bug in :func:`infer_freq` and :meth:`DatetimeIndex.inferred_freq` with weekly frequencies and non-nanosecond resolutions (:issue:`55609`)\n- Bug in :meth:`DataFrame.apply` where passing ``raw=True`` ignored ``args`` passed to the applied function (:issue:`55009`)\n- Bug in :meth:`DataFrame.from_dict` which would always sort the rows of the created :class:`DataFrame`.  (:issue:`55683`)\n- Bug in :meth:`DataFrame.sort_index` when passing ``axis=\"columns\"`` and ``ignore_index=True`` raising a ``ValueError`` (:issue:`56478`)\n- Bug in rendering ``inf`` values inside a :class:`DataFrame` with the ``use_inf_as_na`` option enabled (:issue:`55483`)\n- Bug in rendering a :class:`Series` with a :class:`MultiIndex` when one of the index level's names is 0 not having that name displayed (:issue:`55415`)\n- Bug in the error message when assigning an empty :class:`DataFrame` to a column (:issue:`55956`)\n- Bug when time-like strings were being cast to :class:`ArrowDtype` with ``pyarrow.time64`` type (:issue:`56463`)\n- Fixed a spurious deprecation warning from ``numba`` >= 0.58.0 when passing a numpy ufunc in :class:`core.window.Rolling.apply` with ``engine=\"numba\"`` (:issue:`55247`)\n\n.. ---------------------------------------------------------------------------\n.. _whatsnew_220.contributors:\n\nContributors\n~~~~~~~~~~~~\n\n.. contributors:: v2.1.4..v2.2.0\n\n\n.. _whatsnew_060:\n\nVersion 0.6.0 (November 25, 2011)\n---------------------------------\n\n{{ header }}\n\nNew features\n~~~~~~~~~~~~\n- :ref:`Added <reshaping.melt>` ``melt`` function to ``pandas.core.reshape``\n- :ref:`Added <groupby.multiindex>` ``level`` parameter to group by level in Series and DataFrame descriptive statistics (:issue:`313`)\n- :ref:`Added <basics.head_tail>` ``head`` and ``tail`` methods to Series, analogous to DataFrame (:issue:`296`)\n- :ref:`Added <indexing.boolean>` ``Series.isin`` function which checks if each value is contained in a passed sequence (:issue:`289`)\n- :ref:`Added <io.formatting>` ``float_format`` option to ``Series.to_string``\n- :ref:`Added <io.parse_dates>` ``skip_footer`` (:issue:`291`) and ``converters`` (:issue:`343`) options to ``read_csv`` and ``read_table``\n- :ref:`Added <indexing.duplicate>` ``drop_duplicates`` and ``duplicated`` functions for removing duplicate DataFrame rows and checking for duplicate rows, respectively (:issue:`319`)\n- :ref:`Implemented <dsintro.boolean>` operators '&', '|', '^', '-' on DataFrame (:issue:`347`)\n- :ref:`Added <basics.stats>` ``Series.mad``, mean absolute deviation\n- :ref:`Added <timeseries.offsets>` ``QuarterEnd`` DateOffset (:issue:`321`)\n- :ref:`Added <dsintro.numpy_interop>` ``dot`` to DataFrame (:issue:`65`)\n- Added ``orient`` option to ``Panel.from_dict`` (:issue:`359`, :issue:`301`)\n- :ref:`Added <basics.dataframe.from_dict>` ``orient`` option to ``DataFrame.from_dict``\n- :ref:`Added <basics.dataframe.from_records>` passing list of tuples or list of lists to ``DataFrame.from_records`` (:issue:`357`)\n- :ref:`Added <groupby.multiindex>` multiple levels to groupby (:issue:`103`)\n- :ref:`Allow <basics.sorting>` multiple columns in ``by`` argument of ``DataFrame.sort_index`` (:issue:`92`, :issue:`362`)\n- :ref:`Added <indexing.basics.get_value>` fast ``get_value`` and ``put_value`` methods to DataFrame (:issue:`360`)\n- Added ``cov`` instance methods to Series and DataFrame (:issue:`194`, :issue:`362`)\n- :ref:`Added <visualization.barplot>` ``kind='bar'`` option to ``DataFrame.plot`` (:issue:`348`)\n- :ref:`Added <basics.idxmin>` ``idxmin`` and ``idxmax`` to Series and DataFrame (:issue:`286`)\n- :ref:`Added <io.clipboard>` ``read_clipboard`` function to parse DataFrame from clipboard (:issue:`300`)\n- :ref:`Added <basics.stats>` ``nunique`` function to Series for counting unique elements (:issue:`297`)\n- :ref:`Made <basics.dataframe>` DataFrame constructor use Series name if no columns passed (:issue:`373`)\n- :ref:`Support <io.parse_dates>` regular expressions in read_table/read_csv (:issue:`364`)\n- :ref:`Added <io.html>` ``DataFrame.to_html`` for writing DataFrame to HTML (:issue:`387`)\n- :ref:`Added <basics.dataframe>` support for MaskedArray data in DataFrame, masked values converted to NaN (:issue:`396`)\n- :ref:`Added <visualization.box>` ``DataFrame.boxplot`` function (:issue:`368`)\n- :ref:`Can <basics.apply>` pass extra args, kwds to DataFrame.apply (:issue:`376`)\n- :ref:`Implement <merging.multikey_join>` ``DataFrame.join`` with vector ``on`` argument (:issue:`312`)\n- :ref:`Added <visualization.basic>` ``legend`` boolean flag to ``DataFrame.plot`` (:issue:`324`)\n- :ref:`Can <reshaping.stacking>` pass multiple levels to ``stack`` and ``unstack`` (:issue:`370`)\n- :ref:`Can <reshaping.pivot>` pass multiple values columns to ``pivot_table`` (:issue:`381`)\n- :ref:`Use <groupby.multiindex>` Series name in GroupBy for result index (:issue:`363`)\n- :ref:`Added <basics.apply>` ``raw`` option to ``DataFrame.apply`` for performance if only need ndarray (:issue:`309`)\n- Added proper, tested weighted least squares to standard and panel OLS (:issue:`303`)\n\nPerformance enhancements\n~~~~~~~~~~~~~~~~~~~~~~~~\n- VBENCH Cythonized ``cache_readonly``, resulting in substantial micro-performance enhancements throughout the code base (:issue:`361`)\n- VBENCH Special Cython matrix iterator for applying arbitrary reduction operations with 3-5x better performance than ``np.apply_along_axis`` (:issue:`309`)\n- VBENCH Improved performance of ``MultiIndex.from_tuples``\n- VBENCH Special Cython matrix iterator for applying arbitrary reduction operations\n- VBENCH + DOCUMENT Add ``raw`` option to ``DataFrame.apply`` for getting better performance when\n- VBENCH Faster cythonized count by level in Series and DataFrame (:issue:`341`)\n- VBENCH? Significant GroupBy performance enhancement with multiple keys with many \"empty\" combinations\n- VBENCH New Cython vectorized function ``map_infer`` speeds up ``Series.apply`` and ``Series.map`` significantly when passed elementwise Python function, motivated by (:issue:`355`)\n- VBENCH Significantly improved performance of ``Series.order``, which also makes np.unique called on a Series faster (:issue:`327`)\n- VBENCH Vastly improved performance of GroupBy on axes with a MultiIndex (:issue:`299`)\n\n\n\n.. _whatsnew_0.6.0.contributors:\n\nContributors\n~~~~~~~~~~~~\n\n.. contributors:: v0.5.0..v0.6.0\n\n\n\n.. _whatsnew_061:\n\nVersion 0.6.1 (December 13, 2011)\n---------------------------------\n\nNew features\n~~~~~~~~~~~~\n- Can append single rows (as Series) to a DataFrame\n- Add Spearman and Kendall rank correlation\n  options to Series.corr and DataFrame.corr (:issue:`428`)\n- :ref:`Added <indexing.basics.get_value>` ``get_value`` and ``set_value`` methods to\n  Series, DataFrame, and Panel for very low-overhead access (>2x faster in many\n  cases) to scalar elements (:issue:`437`, :issue:`438`). ``set_value`` is capable of\n  producing an enlarged object.\n- Add PyQt table widget to sandbox (:issue:`435`)\n- DataFrame.align can :ref:`accept Series arguments <basics.align.frame.series>`\n  and an :ref:`axis option <basics.df_join>` (:issue:`461`)\n- Implement new :ref:`SparseArray <sparse.array>` and ``SparseList``\n  data structures. SparseSeries now derives from SparseArray (:issue:`463`)\n- :ref:`Better console printing options <basics.console_output>` (:issue:`453`)\n- Implement fast data ranking for Series and\n  DataFrame, fast versions of scipy.stats.rankdata (:issue:`428`)\n- Implement ``DataFrame.from_items`` alternate\n  constructor (:issue:`444`)\n- DataFrame.convert_objects method for :ref:`inferring better dtypes <basics.cast>`\n  for object columns (:issue:`302`)\n- Add :ref:`rolling_corr_pairwise <window.corr_pairwise>` function for\n  computing Panel of correlation matrices (:issue:`189`)\n- Add :ref:`margins <reshaping.pivot.margins>` option to :ref:`pivot_table\n  <reshaping.pivot>` for computing subgroup aggregates (:issue:`114`)\n- Add ``Series.from_csv`` function (:issue:`482`)\n- :ref:`Can pass <window.cov_corr>` DataFrame/DataFrame and\n  DataFrame/Series to rolling_corr/rolling_cov (GH 462)\n- MultiIndex.get_level_values can :ref:`accept the level name <advanced.get_level_values>`\n\nPerformance improvements\n~~~~~~~~~~~~~~~~~~~~~~~~\n\n- Improve memory usage of ``DataFrame.describe`` (do not copy data\n  unnecessarily) (PR 425)\n\n- Optimize scalar value lookups in the general case by 25% or more in Series\n  and DataFrame\n\n- Fix performance regression in cross-sectional count in DataFrame, affecting\n  DataFrame.dropna speed\n- Column deletion in DataFrame copies no data (computes views on blocks) (GH\n  158)\n\n\n\n.. _whatsnew_0.6.1.contributors:\n\nContributors\n~~~~~~~~~~~~\n\n.. contributors:: v0.6.0..v0.6.1\n\n\n.. _whatsnew_152:\n\nWhat's new in 1.5.2 (November 21, 2022)\n---------------------------------------\n\nThese are the changes in pandas 1.5.2. See :ref:`release` for a full changelog\nincluding other versions of pandas.\n\n{{ header }}\n\n.. ---------------------------------------------------------------------------\n.. _whatsnew_152.regressions:\n\nFixed regressions\n~~~~~~~~~~~~~~~~~\n- Fixed regression in :meth:`MultiIndex.join` for extension array dtypes (:issue:`49277`)\n- Fixed regression in :meth:`Series.replace` raising ``RecursionError`` with numeric dtype and when specifying ``value=None`` (:issue:`45725`)\n- Fixed regression in arithmetic operations for :class:`DataFrame` with :class:`MultiIndex` columns with different dtypes (:issue:`49769`)\n- Fixed regression in :meth:`DataFrame.plot` preventing :class:`~matplotlib.colors.Colormap` instance\n  from being passed using the ``colormap`` argument if Matplotlib 3.6+ is used (:issue:`49374`)\n- Fixed regression in :func:`date_range` returning an invalid set of periods for ``CustomBusinessDay`` frequency and ``start`` date with timezone (:issue:`49441`)\n- Fixed performance regression in groupby operations (:issue:`49676`)\n- Fixed regression in :class:`Timedelta` constructor returning object of wrong type when subclassing ``Timedelta`` (:issue:`49579`)\n\n.. ---------------------------------------------------------------------------\n.. _whatsnew_152.bug_fixes:\n\nBug fixes\n~~~~~~~~~\n- Bug in the Copy-on-Write implementation losing track of views in certain chained indexing cases (:issue:`48996`)\n- Fixed memory leak in :meth:`.Styler.to_excel` (:issue:`49751`)\n\n.. ---------------------------------------------------------------------------\n.. _whatsnew_152.other:\n\nOther\n~~~~~\n- Reverted ``color`` as an alias for ``c`` and ``size`` as an alias for ``s`` in function :meth:`DataFrame.plot.scatter` (:issue:`49732`)\n\n.. ---------------------------------------------------------------------------\n.. _whatsnew_152.contributors:\n\nContributors\n~~~~~~~~~~~~\n\n.. contributors:: v1.5.1..v1.5.2\n\n\n.. _whatsnew_0220:\n\nVersion 0.22.0 (December 29, 2017)\n----------------------------------\n\n{{ header }}\n\n.. ipython:: python\n   :suppress:\n\n   from pandas import *   noqa F401, F403\n\n\nThis is a major release from 0.21.1 and includes a single, API-breaking change.\nWe recommend that all users upgrade to this version after carefully reading the\nrelease note (singular!).\n\n.. _whatsnew_0220.api_breaking:\n\nBackwards incompatible API changes\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\npandas 0.22.0 changes the handling of empty and all-*NA* sums and products. The\nsummary is that\n\n* The sum of an empty or all-*NA* ``Series`` is now ``0``\n* The product of an empty or all-*NA* ``Series`` is now ``1``\n* We've added a ``min_count`` parameter to ``.sum()`` and ``.prod()`` controlling\n  the minimum number of valid values for the result to be valid. If fewer than\n  ``min_count`` non-*NA* values are present, the result is *NA*. The default is\n  ``0``. To return ``NaN``, the 0.21 behavior, use ``min_count=1``.\n\nSome background: In pandas 0.21, we fixed a long-standing inconsistency\nin the return value of all-*NA* series depending on whether or not bottleneck\nwas installed. See :ref:`whatsnew_0210.api_breaking.bottleneck`. At the same\ntime, we changed the sum and prod of an empty ``Series`` to also be ``NaN``.\n\nBased on feedback, we've partially reverted those changes.\n\nArithmetic operations\n^^^^^^^^^^^^^^^^^^^^^\n\nThe default sum for empty or all-*NA* ``Series`` is now ``0``.\n\n*pandas 0.21.x*\n\n.. code-block:: ipython\n\n   In [1]: pd.Series([]).sum()\n   Out[1]: nan\n\n   In [2]: pd.Series([np.nan]).sum()\n   Out[2]: nan\n\n*pandas 0.22.0*\n\n.. ipython:: python\n   :okwarning:\n\n   pd.Series([]).sum()\n   pd.Series([np.nan]).sum()\n\nThe default behavior is the same as pandas 0.20.3 with bottleneck installed. It\nalso matches the behavior of NumPy's ``np.nansum`` on empty and all-*NA* arrays.\n\nTo have the sum of an empty series return ``NaN`` (the default behavior of\npandas 0.20.3 without bottleneck, or pandas 0.21.x), use the ``min_count``\nkeyword.\n\n.. ipython:: python\n   :okwarning:\n\n   pd.Series([]).sum(min_count=1)\n\nThanks to the ``skipna`` parameter, the ``.sum`` on an all-*NA*\nseries is conceptually the same as the ``.sum`` of an empty one with\n``skipna=True`` (the default).\n\n.. ipython:: python\n\n   pd.Series([np.nan]).sum(min_count=1)   skipna=True by default\n\nThe ``min_count`` parameter refers to the minimum number of *non-null* values\nrequired for a non-NA sum or product.\n\n:meth:`Series.prod` has been updated to behave the same as :meth:`Series.sum`,\nreturning ``1`` instead.\n\n.. ipython:: python\n   :okwarning:\n\n   pd.Series([]).prod()\n   pd.Series([np.nan]).prod()\n   pd.Series([]).prod(min_count=1)\n\nThese changes affect :meth:`DataFrame.sum` and :meth:`DataFrame.prod` as well.\nFinally, a few less obvious places in pandas are affected by this change.\n\nGrouping by a Categorical\n^^^^^^^^^^^^^^^^^^^^^^^^^\n\nGrouping by a ``Categorical`` and summing now returns ``0`` instead of\n``NaN`` for categories with no observations. The product now returns ``1``\ninstead of ``NaN``.\n\n*pandas 0.21.x*\n\n.. code-block:: ipython\n\n   In [8]: grouper = pd.Categorical(['a', 'a'], categories=['a', 'b'])\n\n   In [9]: pd.Series([1, 2]).groupby(grouper, observed=False).sum()\n   Out[9]:\n   a    3.0\n   b    NaN\n   dtype: float64\n\n*pandas 0.22*\n\n.. ipython:: python\n\n   grouper = pd.Categorical([\"a\", \"a\"], categories=[\"a\", \"b\"])\n   pd.Series([1, 2]).groupby(grouper, observed=False).sum()\n\nTo restore the 0.21 behavior of returning ``NaN`` for unobserved groups,\nuse ``min_count>=1``.\n\n.. ipython:: python\n\n   pd.Series([1, 2]).groupby(grouper, observed=False).sum(min_count=1)\n\nResample\n^^^^^^^^\n\nThe sum and product of all-*NA* bins has changed from ``NaN`` to ``0`` for\nsum and ``1`` for product.\n\n*pandas 0.21.x*\n\n.. code-block:: ipython\n\n   In [11]: s = pd.Series([1, 1, np.nan, np.nan],\n      ....:               index=pd.date_range('2017', periods=4))\n      ....: s\n   Out[11]:\n   2017-01-01    1.0\n   2017-01-02    1.0\n   2017-01-03    NaN\n   2017-01-04    NaN\n   Freq: D, dtype: float64\n\n   In [12]: s.resample('2d').sum()\n   Out[12]:\n   2017-01-01    2.0\n   2017-01-03    NaN\n   Freq: 2D, dtype: float64\n\n*pandas 0.22.0*\n\n.. ipython:: python\n\n   s = pd.Series([1, 1, np.nan, np.nan], index=pd.date_range(\"2017\", periods=4))\n   s.resample(\"2d\").sum()\n\nTo restore the 0.21 behavior of returning ``NaN``, use ``min_count>=1``.\n\n.. ipython:: python\n\n   s.resample(\"2d\").sum(min_count=1)\n\nIn particular, upsampling and taking the sum or product is affected, as\nupsampling introduces missing values even if the original series was\nentirely valid.\n\n*pandas 0.21.x*\n\n.. code-block:: ipython\n\n   In [14]: idx = pd.DatetimeIndex(['2017-01-01', '2017-01-02'])\n\n   In [15]: pd.Series([1, 2], index=idx).resample('12H').sum()\n   Out[15]:\n   2017-01-01 00:00:00    1.0\n   2017-01-01 12:00:00    NaN\n   2017-01-02 00:00:00    2.0\n   Freq: 12H, dtype: float64\n\n*pandas 0.22.0*\n\n.. code-block:: ipython\n\n   In [14]: idx = pd.DatetimeIndex([\"2017-01-01\", \"2017-01-02\"])\n   In [15]: pd.Series([1, 2], index=idx).resample(\"12H\").sum()\n   Out[15]:\n   2017-01-01 00:00:00    1\n   2017-01-01 12:00:00    0\n   2017-01-02 00:00:00    2\n   Freq: 12H, Length: 3, dtype: int64\n\nOnce again, the ``min_count`` keyword is available to restore the 0.21 behavior.\n\n.. code-block:: ipython\n\n   In [16]: pd.Series([1, 2], index=idx).resample(\"12H\").sum(min_count=1)\n   Out[16]:\n   2017-01-01 00:00:00    1.0\n   2017-01-01 12:00:00    NaN\n   2017-01-02 00:00:00    2.0\n   Freq: 12H, Length: 3, dtype: float64\n\n\nRolling and expanding\n^^^^^^^^^^^^^^^^^^^^^\n\nRolling and expanding already have a ``min_periods`` keyword that behaves\nsimilar to ``min_count``. The only case that changes is when doing a rolling\nor expanding sum with ``min_periods=0``. Previously this returned ``NaN``,\nwhen fewer than ``min_periods`` non-*NA* values were in the window. Now it\nreturns ``0``.\n\n*pandas 0.21.1*\n\n.. code-block:: ipython\n\n   In [17]: s = pd.Series([np.nan, np.nan])\n\n   In [18]: s.rolling(2, min_periods=0).sum()\n   Out[18]:\n   0   NaN\n   1   NaN\n   dtype: float64\n\n*pandas 0.22.0*\n\n.. ipython:: python\n\n   s = pd.Series([np.nan, np.nan])\n   s.rolling(2, min_periods=0).sum()\n\nThe default behavior of ``min_periods=None``, implying that ``min_periods``\nequals the window size, is unchanged.\n\nCompatibility\n~~~~~~~~~~~~~\n\nIf you maintain a library that should work across pandas versions, it\nmay be easiest to exclude pandas 0.21 from your requirements. Otherwise, all your\n``sum()`` calls would need to check if the ``Series`` is empty before summing.\n\nWith setuptools, in your ``setup.py`` use::\n\n    install_requires=['pandas!=0.21.*', ...]\n\nWith conda, use\n\n.. code-block:: yaml\n\n    requirements:\n      run:\n        - pandas !=0.21.0,!=0.21.1\n\nNote that the inconsistency in the return value for all-*NA* series is still\nthere for pandas 0.20.3 and earlier. Avoiding pandas 0.21 will only help with\nthe empty case.\n\n\n.. _whatsnew_0.22.0.contributors:\n\nContributors\n~~~~~~~~~~~~\n\n.. contributors:: v0.21.1..v0.22.0\n\n\n.. _whatsnew_0190:\n\nVersion 0.19.0 (October 2, 2016)\n--------------------------------\n\n{{ header }}\n\nThis is a major release from 0.18.1 and includes number of API changes, several new features,\nenhancements, and performance improvements along with a large number of bug fixes. We recommend that all\nusers upgrade to this version.\n\nHighlights include:\n\n- :func:`merge_asof` for asof-style time-series joining, see :ref:`here <whatsnew_0190.enhancements.asof_merge>`\n- ``.rolling()`` is now time-series aware, see :ref:`here <whatsnew_0190.enhancements.rolling_ts>`\n- :func:`read_csv` now supports parsing ``Categorical`` data, see :ref:`here <whatsnew_0190.enhancements.read_csv_categorical>`\n- A function :func:`union_categorical` has been added for combining categoricals, see :ref:`here <whatsnew_0190.enhancements.union_categoricals>`\n- ``PeriodIndex`` now has its own ``period`` dtype, and changed to be more consistent with other ``Index`` classes. See :ref:`here <whatsnew_0190.api.period>`\n- Sparse data structures gained enhanced support of ``int`` and ``bool`` dtypes, see :ref:`here <whatsnew_0190.sparse>`\n- Comparison operations with ``Series`` no longer ignores the index, see :ref:`here <whatsnew_0190.api.series_ops>` for an overview of the API changes.\n- Introduction of a pandas development API for utility functions, see :ref:`here <whatsnew_0190.dev_api>`.\n- Deprecation of ``Panel4D`` and ``PanelND``. We recommend to represent these types of n-dimensional data with the `xarray package <http://xarray.pydata.org/en/stable/>`__.\n- Removal of the previously deprecated modules ``pandas.io.data``, ``pandas.io.wb``, ``pandas.tools.rplot``.\n\n.. warning::\n\n    pandas >= 0.19.0 will no longer silence numpy ufunc warnings upon import, see :ref:`here <whatsnew_0190.errstate>`.\n\n.. contents:: What's new in v0.19.0\n    :local:\n    :backlinks: none\n\n.. _whatsnew_0190.new_features:\n\nNew features\n~~~~~~~~~~~~\n\n.. _whatsnew_0190.enhancements.asof_merge:\n\nFunction ``merge_asof`` for asof-style time-series joining\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nA long-time requested feature has been added through the :func:`merge_asof` function, to\nsupport asof style joining of time-series (:issue:`1870`, :issue:`13695`, :issue:`13709`, :issue:`13902`). Full documentation is\n:ref:`here <merging.merge_asof>`.\n\nThe :func:`merge_asof` performs an asof merge, which is similar to a left-join\nexcept that we match on nearest key rather than equal keys.\n\n.. ipython:: python\n\n   left = pd.DataFrame({\"a\": [1, 5, 10], \"left_val\": [\"a\", \"b\", \"c\"]})\n   right = pd.DataFrame({\"a\": [1, 2, 3, 6, 7], \"right_val\": [1, 2, 3, 6, 7]})\n\n   left\n   right\n\nWe typically want to match exactly when possible, and use the most\nrecent value otherwise.\n\n.. ipython:: python\n\n   pd.merge_asof(left, right, on=\"a\")\n\nWe can also match rows ONLY with prior data, and not an exact match.\n\n.. ipython:: python\n\n   pd.merge_asof(left, right, on=\"a\", allow_exact_matches=False)\n\n\nIn a typical time-series example, we have ``trades`` and ``quotes`` and we want to ``asof-join`` them.\nThis also illustrates using the ``by`` parameter to group data before merging.\n\n.. ipython:: python\n\n   trades = pd.DataFrame(\n       {\n           \"time\": pd.to_datetime(\n               [\n                   \"20160525 13:30:00.023\",\n                   \"20160525 13:30:00.038\",\n                   \"20160525 13:30:00.048\",\n                   \"20160525 13:30:00.048\",\n                   \"20160525 13:30:00.048\",\n               ]\n           ),\n           \"ticker\": [\"MSFT\", \"MSFT\", \"GOOG\", \"GOOG\", \"AAPL\"],\n           \"price\": [51.95, 51.95, 720.77, 720.92, 98.00],\n           \"quantity\": [75, 155, 100, 100, 100],\n       },\n       columns=[\"time\", \"ticker\", \"price\", \"quantity\"],\n   )\n\n   quotes = pd.DataFrame(\n       {\n           \"time\": pd.to_datetime(\n               [\n                   \"20160525 13:30:00.023\",\n                   \"20160525 13:30:00.023\",\n                   \"20160525 13:30:00.030\",\n                   \"20160525 13:30:00.041\",\n                   \"20160525 13:30:00.048\",\n                   \"20160525 13:30:00.049\",\n                   \"20160525 13:30:00.072\",\n                   \"20160525 13:30:00.075\",\n               ]\n           ),\n           \"ticker\": [\"GOOG\", \"MSFT\", \"MSFT\", \"MSFT\", \"GOOG\", \"AAPL\", \"GOOG\", \"MSFT\"],\n           \"bid\": [720.50, 51.95, 51.97, 51.99, 720.50, 97.99, 720.50, 52.01],\n           \"ask\": [720.93, 51.96, 51.98, 52.00, 720.93, 98.01, 720.88, 52.03],\n       },\n       columns=[\"time\", \"ticker\", \"bid\", \"ask\"],\n   )\n\n.. ipython:: python\n\n   trades\n   quotes\n\nAn asof merge joins on the ``on``, typically a datetimelike field, which is ordered, and\nin this case we are using a grouper in the ``by`` field. This is like a left-outer join, except\nthat forward filling happens automatically taking the most recent non-NaN value.\n\n.. ipython:: python\n\n   pd.merge_asof(trades, quotes, on=\"time\", by=\"ticker\")\n\nThis returns a merged DataFrame with the entries in the same order as the original left\npassed DataFrame (``trades`` in this case), with the fields of the ``quotes`` merged.\n\n.. _whatsnew_0190.enhancements.rolling_ts:\n\nMethod ``.rolling()`` is now time-series aware\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n``.rolling()`` objects are now time-series aware and can accept a time-series offset (or convertible) for the ``window`` argument (:issue:`13327`, :issue:`12995`).\nSee the full documentation :ref:`here <window.generic>`.\n\n.. ipython:: python\n\n   dft = pd.DataFrame(\n       {\"B\": [0, 1, 2, np.nan, 4]},\n       index=pd.date_range(\"20130101 09:00:00\", periods=5, freq=\"s\"),\n   )\n   dft\n\nThis is a regular frequency index. Using an integer window parameter works to roll along the window frequency.\n\n.. ipython:: python\n\n   dft.rolling(2).sum()\n   dft.rolling(2, min_periods=1).sum()\n\nSpecifying an offset allows a more intuitive specification of the rolling frequency.\n\n.. ipython:: python\n\n   dft.rolling(\"2s\").sum()\n\nUsing a non-regular, but still monotonic index, rolling with an integer window does not impart any special calculation.\n\n.. ipython:: python\n\n\n   dft = pd.DataFrame(\n       {\"B\": [0, 1, 2, np.nan, 4]},\n       index=pd.Index(\n           [\n               pd.Timestamp(\"20130101 09:00:00\"),\n               pd.Timestamp(\"20130101 09:00:02\"),\n               pd.Timestamp(\"20130101 09:00:03\"),\n               pd.Timestamp(\"20130101 09:00:05\"),\n               pd.Timestamp(\"20130101 09:00:06\"),\n           ],\n           name=\"foo\",\n       ),\n   )\n\n   dft\n   dft.rolling(2).sum()\n\nUsing the time-specification generates variable windows for this sparse data.\n\n.. ipython:: python\n\n   dft.rolling(\"2s\").sum()\n\nFurthermore, we now allow an optional ``on`` parameter to specify a column (rather than the\ndefault of the index) in a DataFrame.\n\n.. ipython:: python\n\n   dft = dft.reset_index()\n   dft\n   dft.rolling(\"2s\", on=\"foo\").sum()\n\n.. _whatsnew_0190.enhancements.read_csv_dupe_col_names_support:\n\nMethod ``read_csv`` has improved support for duplicate column names\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n.. ipython:: python\n   :suppress:\n\n   from io import StringIO\n\n:ref:`Duplicate column names <io.dupe_names>` are now supported in :func:`read_csv` whether\nthey are in the file or passed in as the ``names`` parameter (:issue:`7160`, :issue:`9424`)\n\n.. ipython:: python\n\n   data = \"0,1,2\\n3,4,5\"\n   names = [\"a\", \"b\", \"a\"]\n\n**Previous behavior**:\n\n.. code-block:: ipython\n\n   In [2]: pd.read_csv(StringIO(data), names=names)\n   Out[2]:\n      a  b  a\n   0  2  1  2\n   1  5  4  5\n\nThe first ``a`` column contained the same data as the second ``a`` column, when it should have\ncontained the values ``[0, 3]``.\n\n**New behavior**:\n\n.. ipython:: python\n   :okexcept:\n\n   pd.read_csv(StringIO(data), names=names)\n\n\n.. _whatsnew_0190.enhancements.read_csv_categorical:\n\nMethod ``read_csv`` supports parsing ``Categorical`` directly\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nThe :func:`read_csv` function now supports parsing a ``Categorical`` column when\nspecified as a dtype (:issue:`10153`).  Depending on the structure of the data,\nthis can result in a faster parse time and lower memory usage compared to\nconverting to ``Categorical`` after parsing.  See the io :ref:`docs here <io.categorical>`.\n\n.. ipython:: python\n\n   data = \"\"\"\n   col1,col2,col3\n   a,b,1\n   a,b,2\n   c,d,3\n   \"\"\"\n\n   pd.read_csv(StringIO(data))\n   pd.read_csv(StringIO(data)).dtypes\n   pd.read_csv(StringIO(data), dtype=\"category\").dtypes\n\nIndividual columns can be parsed as a ``Categorical`` using a dict specification\n\n.. ipython:: python\n\n   pd.read_csv(StringIO(data), dtype={\"col1\": \"category\"}).dtypes\n\n.. note::\n\n   The resulting categories will always be parsed as strings (object dtype).\n   If the categories are numeric they can be converted using the\n   :func:`to_numeric` function, or as appropriate, another converter\n   such as :func:`to_datetime`.\n\n   .. ipython:: python\n\n      df = pd.read_csv(StringIO(data), dtype=\"category\")\n      df.dtypes\n      df[\"col3\"]\n      new_categories = pd.to_numeric(df[\"col3\"].cat.categories)\n      df[\"col3\"] = df[\"col3\"].cat.rename_categories(new_categories)\n      df[\"col3\"]\n\n.. _whatsnew_0190.enhancements.union_categoricals:\n\nCategorical concatenation\n^^^^^^^^^^^^^^^^^^^^^^^^^\n\n- A function :func:`union_categoricals` has been added for combining categoricals, see :ref:`Unioning Categoricals<categorical.union>` (:issue:`13361`, :issue:`13763`, :issue:`13846`, :issue:`14173`)\n\n  .. ipython:: python\n\n     from pandas.api.types import union_categoricals\n\n     a = pd.Categorical([\"b\", \"c\"])\n     b = pd.Categorical([\"a\", \"b\"])\n     union_categoricals([a, b])\n\n- ``concat`` and ``append`` now can concat ``category`` dtypes with different ``categories`` as ``object`` dtype (:issue:`13524`)\n\n  .. ipython:: python\n\n     s1 = pd.Series([\"a\", \"b\"], dtype=\"category\")\n     s2 = pd.Series([\"b\", \"c\"], dtype=\"category\")\n\n**Previous behavior**:\n\n.. code-block:: ipython\n\n   In [1]: pd.concat([s1, s2])\n   ValueError: incompatible categories in categorical concat\n\n**New behavior**:\n\n.. ipython:: python\n\n   pd.concat([s1, s2])\n\n.. _whatsnew_0190.enhancements.semi_month_offsets:\n\nSemi-month offsets\n^^^^^^^^^^^^^^^^^^\n\npandas has gained new frequency offsets, ``SemiMonthEnd`` ('SM') and ``SemiMonthBegin`` ('SMS').\nThese provide date offsets anchored (by default) to the 15th and end of month, and 15th and 1st of month respectively.\n(:issue:`1543`)\n\n.. ipython:: python\n\n   from pandas.tseries.offsets import SemiMonthEnd, SemiMonthBegin\n\n**SemiMonthEnd**:\n\n.. code-block:: python\n\n   In [46]: pd.Timestamp(\"2016-01-01\") + SemiMonthEnd()\n   Out[46]: Timestamp('2016-01-15 00:00:00')\n\n   In [47]: pd.date_range(\"2015-01-01\", freq=\"SM\", periods=4)\n   Out[47]: DatetimeIndex(['2015-01-15', '2015-01-31', '2015-02-15', '2015-02-28'], dtype='datetime64[ns]', freq='SM-15')\n\n**SemiMonthBegin**:\n\n.. ipython:: python\n\n   pd.Timestamp(\"2016-01-01\") + SemiMonthBegin()\n\n   pd.date_range(\"2015-01-01\", freq=\"SMS\", periods=4)\n\nUsing the anchoring suffix, you can also specify the day of month to use instead of the 15th.\n\n.. code-block:: python\n\n   In [50]: pd.date_range(\"2015-01-01\", freq=\"SMS-16\", periods=4)\n   Out[50]: DatetimeIndex(['2015-01-01', '2015-01-16', '2015-02-01', '2015-02-16'], dtype='datetime64[ns]', freq='SMS-16')\n\n   In [51]: pd.date_range(\"2015-01-01\", freq=\"SM-14\", periods=4)\n   Out[51]: DatetimeIndex(['2015-01-14', '2015-01-31', '2015-02-14', '2015-02-28'], dtype='datetime64[ns]', freq='SM-14')\n\n.. _whatsnew_0190.enhancements.index:\n\nNew Index methods\n^^^^^^^^^^^^^^^^^\n\nThe following methods and options are added to ``Index``, to be more consistent with the ``Series`` and ``DataFrame`` API.\n\n``Index`` now supports the ``.where()`` function for same shape indexing (:issue:`13170`)\n\n.. ipython:: python\n\n   idx = pd.Index([\"a\", \"b\", \"c\"])\n   idx.where([True, False, True])\n\n\n``Index`` now supports ``.dropna()`` to exclude missing values (:issue:`6194`)\n\n.. ipython:: python\n\n   idx = pd.Index([1, 2, np.nan, 4])\n   idx.dropna()\n\nFor ``MultiIndex``, values are dropped if any level is missing by default. Specifying\n``how='all'`` only drops values where all levels are missing.\n\n.. ipython:: python\n\n   midx = pd.MultiIndex.from_arrays([[1, 2, np.nan, 4], [1, 2, np.nan, np.nan]])\n   midx\n   midx.dropna()\n   midx.dropna(how=\"all\")\n\n``Index`` now supports ``.str.extractall()`` which returns a ``DataFrame``, see the :ref:`docs here <text.extractall>` (:issue:`10008`, :issue:`13156`)\n\n.. ipython:: python\n\n   idx = pd.Index([\"a1a2\", \"b1\", \"c1\"])\n   idx.str.extractall(r\"[ab](?P<digit>\\d)\")\n\n``Index.astype()`` now accepts an optional boolean argument ``copy``, which allows optional copying if the requirements on dtype are satisfied (:issue:`13209`)\n\n.. _whatsnew_0190.gbq:\n\nGoogle BigQuery enhancements\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n- The :func:`read_gbq` method has gained the ``dialect`` argument to allow users to specify whether to use BigQuery's legacy SQL or BigQuery's standard SQL. See the `docs <https://pandas-gbq.readthedocs.io/en/latest/reading.html>`__ for more details (:issue:`13615`).\n- The :func:`~DataFrame.to_gbq` method now allows the DataFrame column order to differ from the destination table schema (:issue:`11359`).\n\n.. _whatsnew_0190.errstate:\n\nFine-grained NumPy errstate\n^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nPrevious versions of pandas would permanently silence numpy's ufunc error handling when ``pandas`` was imported. pandas did this in order to silence the warnings that would arise from using numpy ufuncs on missing data, which are usually represented as ``NaN`` s. Unfortunately, this silenced legitimate warnings arising in non-pandas code in the application. Starting with 0.19.0, pandas will use the ``numpy.errstate`` context manager to silence these warnings in a more fine-grained manner, only around where these operations are actually used in the pandas code base. (:issue:`13109`, :issue:`13145`)\n\nAfter upgrading pandas, you may see *new* ``RuntimeWarnings`` being issued from your code. These are likely legitimate, and the underlying cause likely existed in the code when using previous versions of pandas that simply silenced the warning. Use `numpy.errstate <https://numpy.org/doc/stable/reference/generated/numpy.errstate.html>`__ around the source of the ``RuntimeWarning`` to control how these conditions are handled.\n\n.. _whatsnew_0190.get_dummies_dtypes:\n\nMethod ``get_dummies`` now returns integer dtypes\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nThe ``pd.get_dummies`` function now returns dummy-encoded columns as small integers, rather than floats (:issue:`8725`). This should provide an improved memory footprint.\n\n**Previous behavior**:\n\n.. code-block:: ipython\n\n   In [1]: pd.get_dummies(['a', 'b', 'a', 'c']).dtypes\n\n   Out[1]:\n   a    float64\n   b    float64\n   c    float64\n   dtype: object\n\n**New behavior**:\n\n.. ipython:: python\n\n   pd.get_dummies([\"a\", \"b\", \"a\", \"c\"]).dtypes\n\n\n.. _whatsnew_0190.enhancements.to_numeric_downcast:\n\nDowncast values to smallest possible dtype in ``to_numeric``\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n``pd.to_numeric()`` now accepts a ``downcast`` parameter, which will downcast the data if possible to smallest specified numerical dtype (:issue:`13352`)\n\n.. ipython:: python\n\n   s = [\"1\", 2, 3]\n   pd.to_numeric(s, downcast=\"unsigned\")\n   pd.to_numeric(s, downcast=\"integer\")\n\n.. _whatsnew_0190.dev_api:\n\npandas development API\n^^^^^^^^^^^^^^^^^^^^^^\n\nAs part of making pandas API more uniform and accessible in the future, we have created a standard\nsub-package of pandas, ``pandas.api`` to hold public API's. We are starting by exposing type\nintrospection functions in ``pandas.api.types``. More sub-packages and officially sanctioned API's\nwill be published in future versions of pandas (:issue:`13147`, :issue:`13634`)\n\nThe following are now part of this API:\n\n.. ipython:: python\n\n   import pprint\n   from pandas.api import types\n\n   funcs = [f for f in dir(types) if not f.startswith(\"_\")]\n   pprint.pprint(funcs)\n\n.. note::\n\n   Calling these functions from the internal module ``pandas.core.common`` will now show a ``DeprecationWarning`` (:issue:`13990`)\n\n\n.. _whatsnew_0190.enhancements.other:\n\nOther enhancements\n^^^^^^^^^^^^^^^^^^\n\n- ``Timestamp`` can now accept positional and keyword parameters similar to :func:`datetime.datetime` (:issue:`10758`, :issue:`11630`)\n\n  .. ipython:: python\n\n     pd.Timestamp(2012, 1, 1)\n\n     pd.Timestamp(year=2012, month=1, day=1, hour=8, minute=30)\n\n- The ``.resample()`` function now accepts a ``on=`` or ``level=`` parameter for resampling on a datetimelike column or ``MultiIndex`` level (:issue:`13500`)\n\n  .. ipython:: python\n\n     df = pd.DataFrame(\n         {\"date\": pd.date_range(\"2015-01-01\", freq=\"W\", periods=5), \"a\": np.arange(5)},\n         index=pd.MultiIndex.from_arrays(\n             [[1, 2, 3, 4, 5], pd.date_range(\"2015-01-01\", freq=\"W\", periods=5)],\n             names=[\"v\", \"d\"],\n         ),\n     )\n     df\n\n  .. code-block:: ipython\n\n     In [74]: df.resample(\"M\", on=\"date\")[[\"a\"]].sum()\n     Out[74]:\n                 a\n     date\n     2015-01-31  6\n     2015-02-28  4\n\n     [2 rows x 1 columns]\n\n     In [75]: df.resample(\"M\", level=\"d\")[[\"a\"]].sum()\n     Out[75]:\n                 a\n     d\n     2015-01-31  6\n     2015-02-28  4\n\n     [2 rows x 1 columns]\n\n- The ``.get_credentials()`` method of ``GbqConnector`` can now first try to fetch `the application default credentials <https://developers.google.com/identity/protocols/application-default-credentials>`__. See the docs for more details (:issue:`13577`).\n- The ``.tz_localize()`` method of ``DatetimeIndex`` and ``Timestamp`` has gained the ``errors`` keyword, so you can potentially coerce nonexistent timestamps to ``NaT``. The default behavior remains to raising a ``NonExistentTimeError`` (:issue:`13057`)\n- ``.to_hdf/read_hdf()`` now accept path objects (e.g. ``pathlib.Path``, ``py.path.local``) for the file path (:issue:`11773`)\n- The ``pd.read_csv()`` with ``engine='python'`` has gained support for the\n  ``decimal`` (:issue:`12933`), ``na_filter`` (:issue:`13321`) and the ``memory_map`` option (:issue:`13381`).\n- Consistent with the Python API, ``pd.read_csv()`` will now interpret ``+inf`` as positive infinity (:issue:`13274`)\n- The ``pd.read_html()`` has gained support for the ``na_values``, ``converters``, ``keep_default_na``  options (:issue:`13461`)\n- ``Categorical.astype()`` now accepts an optional boolean argument ``copy``, effective when dtype is categorical (:issue:`13209`)\n- ``DataFrame`` has gained the ``.asof()`` method to return the last non-NaN values according to the selected subset (:issue:`13358`)\n- The ``DataFrame`` constructor will now respect key ordering if a list of ``OrderedDict`` objects are passed in (:issue:`13304`)\n- ``pd.read_html()`` has gained support for the ``decimal`` option (:issue:`12907`)\n- ``Series`` has gained the properties ``.is_monotonic``, ``.is_monotonic_increasing``, ``.is_monotonic_decreasing``, similar to ``Index`` (:issue:`13336`)\n- ``DataFrame.to_sql()`` now allows a single value as the SQL type for all columns (:issue:`11886`).\n- ``Series.append`` now supports the ``ignore_index`` option (:issue:`13677`)\n- ``.to_stata()`` and ``StataWriter`` can now write variable labels to Stata dta files using a dictionary to make column names to labels (:issue:`13535`, :issue:`13536`)\n- ``.to_stata()`` and ``StataWriter`` will automatically convert ``datetime64[ns]`` columns to Stata format ``%tc``, rather than raising a ``ValueError`` (:issue:`12259`)\n- ``read_stata()`` and ``StataReader`` raise with a more explicit error message when reading Stata files with repeated value labels when ``convert_categoricals=True`` (:issue:`13923`)\n- ``DataFrame.style`` will now render sparsified MultiIndexes (:issue:`11655`)\n- ``DataFrame.style`` will now show column level names (e.g. ``DataFrame.columns.names``) (:issue:`13775`)\n- ``DataFrame`` has gained support to re-order the columns based on the values\n  in a row using ``df.sort_values(by='...', axis=1)`` (:issue:`10806`)\n\n  .. ipython:: python\n\n     df = pd.DataFrame({\"A\": [2, 7], \"B\": [3, 5], \"C\": [4, 8]}, index=[\"row1\", \"row2\"])\n     df\n     df.sort_values(by=\"row2\", axis=1)\n\n- Added documentation to :ref:`I/O<io.dtypes>` regarding the perils of reading in columns with mixed dtypes and how to handle it (:issue:`13746`)\n- :meth:`~DataFrame.to_html` now has a ``border`` argument to control the value in the opening ``<table>`` tag. The default is the value of the ``html.border`` option, which defaults to 1. This also affects the notebook HTML repr, but since Jupyter's CSS includes a border-width attribute, the visual effect is the same. (:issue:`11563`).\n- Raise ``ImportError`` in the sql functions when ``sqlalchemy`` is not installed and a connection string is used (:issue:`11920`).\n- Compatibility with matplotlib 2.0. Older versions of pandas should also work with matplotlib 2.0 (:issue:`13333`)\n- ``Timestamp``, ``Period``, ``DatetimeIndex``, ``PeriodIndex`` and ``.dt`` accessor have gained a ``.is_leap_year`` property to check whether the date belongs to a leap year. (:issue:`13727`)\n- ``astype()`` will now accept a dict of column name to data types mapping as the ``dtype`` argument. (:issue:`12086`)\n- The ``pd.read_json`` and ``DataFrame.to_json`` has gained support for reading and writing json lines with ``lines`` option see :ref:`Line delimited json <io.jsonl>` (:issue:`9180`)\n- :func:`read_excel` now supports the true_values and false_values keyword arguments (:issue:`13347`)\n- ``groupby()`` will now accept a scalar and a single-element list for specifying ``level`` on a non-``MultiIndex`` grouper. (:issue:`13907`)\n- Non-convertible dates in an excel date column will be returned without conversion and the column will be ``object`` dtype, rather than raising an exception (:issue:`10001`).\n- ``pd.Timedelta(None)`` is now accepted and will return ``NaT``, mirroring ``pd.Timestamp`` (:issue:`13687`)\n- ``pd.read_stata()`` can now handle some format 111 files, which are produced by SAS when generating Stata dta files (:issue:`11526`)\n- ``Series`` and ``Index`` now support ``divmod`` which will return a tuple of\n  series or indices. This behaves like a standard binary operator with regards\n  to broadcasting rules (:issue:`14208`).\n\n\n.. _whatsnew_0190.api:\n\nAPI changes\n~~~~~~~~~~~\n\n``Series.tolist()`` will now return Python types\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n``Series.tolist()`` will now return Python types in the output, mimicking NumPy ``.tolist()`` behavior (:issue:`10904`)\n\n\n.. ipython:: python\n\n   s = pd.Series([1, 2, 3])\n\n**Previous behavior**:\n\n.. code-block:: ipython\n\n   In [7]: type(s.tolist()[0])\n   Out[7]:\n    <class 'numpy.int64'>\n\n**New behavior**:\n\n.. ipython:: python\n\n   type(s.tolist()[0])\n\n.. _whatsnew_0190.api.series_ops:\n\n``Series`` operators for different indexes\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nFollowing ``Series`` operators have been changed to make all operators consistent,\nincluding ``DataFrame`` (:issue:`1134`, :issue:`4581`, :issue:`13538`)\n\n- ``Series`` comparison operators now raise ``ValueError`` when ``index`` are different.\n- ``Series`` logical operators align both ``index`` of left and right hand side.\n\n.. warning::\n   Until 0.18.1, comparing ``Series`` with the same length, would succeed even if\n   the ``.index`` are different (the result ignores ``.index``). As of 0.19.0, this will raises ``ValueError`` to be more strict. This section also describes how to keep previous behavior or align different indexes, using the flexible comparison methods like ``.eq``.\n\n\nAs a result, ``Series`` and ``DataFrame`` operators behave as below:\n\nArithmetic operators\n\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\n\nArithmetic operators align both ``index`` (no changes).\n\n.. ipython:: python\n\n   s1 = pd.Series([1, 2, 3], index=list(\"ABC\"))\n   s2 = pd.Series([2, 2, 2], index=list(\"ABD\"))\n   s1 + s2\n\n   df1 = pd.DataFrame([1, 2, 3], index=list(\"ABC\"))\n   df2 = pd.DataFrame([2, 2, 2], index=list(\"ABD\"))\n   df1 + df2\n\nComparison operators\n\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\n\nComparison operators raise ``ValueError`` when ``.index`` are different.\n\n**Previous behavior** (``Series``):\n\n``Series`` compared values ignoring the ``.index`` as long as both had the same length:\n\n.. code-block:: ipython\n\n   In [1]: s1 == s2\n   Out[1]:\n   A    False\n   B     True\n   C    False\n   dtype: bool\n\n**New behavior** (``Series``):\n\n.. code-block:: ipython\n\n   In [2]: s1 == s2\n   Out[2]:\n   ValueError: Can only compare identically-labeled Series objects\n\n.. note::\n\n   To achieve the same result as previous versions (compare values based on locations ignoring ``.index``), compare both ``.values``.\n\n   .. ipython:: python\n\n      s1.values == s2.values\n\n   If you want to compare ``Series`` aligning its ``.index``, see flexible comparison methods section below:\n\n   .. ipython:: python\n\n      s1.eq(s2)\n\n**Current behavior** (``DataFrame``, no change):\n\n.. code-block:: ipython\n\n   In [3]: df1 == df2\n   Out[3]:\n   ValueError: Can only compare identically-labeled DataFrame objects\n\nLogical operators\n\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\n\nLogical operators align both ``.index`` of left and right hand side.\n\n**Previous behavior** (``Series``), only left hand side ``index`` was kept:\n\n.. code-block:: ipython\n\n   In [4]: s1 = pd.Series([True, False, True], index=list('ABC'))\n   In [5]: s2 = pd.Series([True, True, True], index=list('ABD'))\n   In [6]: s1 & s2\n   Out[6]:\n   A     True\n   B    False\n   C    False\n   dtype: bool\n\n**New behavior** (``Series``):\n\n.. ipython:: python\n\n   s1 = pd.Series([True, False, True], index=list(\"ABC\"))\n   s2 = pd.Series([True, True, True], index=list(\"ABD\"))\n   s1 & s2\n\n.. note::\n   ``Series`` logical operators fill a ``NaN`` result with ``False``.\n\n.. note::\n   To achieve the same result as previous versions (compare values based on only left hand side index), you can use ``reindex_like``:\n\n   .. ipython:: python\n\n      s1 & s2.reindex_like(s1)\n\n**Current behavior** (``DataFrame``, no change):\n\n.. ipython:: python\n\n   df1 = pd.DataFrame([True, False, True], index=list(\"ABC\"))\n   df2 = pd.DataFrame([True, True, True], index=list(\"ABD\"))\n   df1 & df2\n\nFlexible comparison methods\n\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\n\n``Series`` flexible comparison methods like ``eq``, ``ne``, ``le``, ``lt``, ``ge`` and ``gt`` now align both ``index``. Use these operators if you want to compare two ``Series``\nwhich has the different ``index``.\n\n.. ipython:: python\n\n   s1 = pd.Series([1, 2, 3], index=[\"a\", \"b\", \"c\"])\n   s2 = pd.Series([2, 2, 2], index=[\"b\", \"c\", \"d\"])\n   s1.eq(s2)\n   s1.ge(s2)\n\nPreviously, this worked the same as comparison operators (see above).\n\n.. _whatsnew_0190.api.promote:\n\n``Series`` type promotion on assignment\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nA ``Series`` will now correctly promote its dtype for assignment with incompat values to the current dtype (:issue:`13234`)\n\n\n.. ipython:: python\n   :okwarning:\n\n   s = pd.Series()\n\n**Previous behavior**:\n\n.. code-block:: ipython\n\n   In [2]: s[\"a\"] = pd.Timestamp(\"2016-01-01\")\n\n   In [3]: s[\"b\"] = 3.0\n   TypeError: invalid type promotion\n\n**New behavior**:\n\n.. ipython:: python\n\n   s[\"a\"] = pd.Timestamp(\"2016-01-01\")\n   s[\"b\"] = 3.0\n   s\n   s.dtype\n\n.. _whatsnew_0190.api.to_datetime_coerce:\n\nFunction ``.to_datetime()`` changes\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nPreviously if ``.to_datetime()`` encountered mixed integers/floats and strings, but no datetimes with ``errors='coerce'`` it would convert all to ``NaT``.\n\n**Previous behavior**:\n\n.. code-block:: ipython\n\n   In [2]: pd.to_datetime([1, 'foo'], errors='coerce')\n   Out[2]: DatetimeIndex(['NaT', 'NaT'], dtype='datetime64[ns]', freq=None)\n\n**Current behavior**:\n\nThis will now convert integers/floats with the default unit of ``ns``.\n\n.. ipython:: python\n\n   pd.to_datetime([1, \"foo\"], errors=\"coerce\")\n\nBug fixes related to ``.to_datetime()``:\n\n- Bug in ``pd.to_datetime()`` when passing integers or floats, and no ``unit`` and ``errors='coerce'`` (:issue:`13180`).\n- Bug in ``pd.to_datetime()`` when passing invalid data types (e.g. bool); will now respect the ``errors`` keyword (:issue:`13176`)\n- Bug in ``pd.to_datetime()`` which overflowed on ``int8``, and ``int16`` dtypes (:issue:`13451`)\n- Bug in ``pd.to_datetime()`` raise ``AttributeError`` with ``NaN`` and the other string is not valid when ``errors='ignore'`` (:issue:`12424`)\n- Bug in ``pd.to_datetime()`` did not cast floats correctly when ``unit`` was specified, resulting in truncated datetime (:issue:`13834`)\n\n.. _whatsnew_0190.api.merging:\n\nMerging changes\n^^^^^^^^^^^^^^^\n\nMerging will now preserve the dtype of the join keys (:issue:`8596`)\n\n.. ipython:: python\n\n   df1 = pd.DataFrame({\"key\": [1], \"v1\": [10]})\n   df1\n   df2 = pd.DataFrame({\"key\": [1, 2], \"v1\": [20, 30]})\n   df2\n\n**Previous behavior**:\n\n.. code-block:: ipython\n\n   In [5]: pd.merge(df1, df2, how='outer')\n   Out[5]:\n      key    v1\n   0  1.0  10.0\n   1  1.0  20.0\n   2  2.0  30.0\n\n   In [6]: pd.merge(df1, df2, how='outer').dtypes\n   Out[6]:\n   key    float64\n   v1     float64\n   dtype: object\n\n**New behavior**:\n\nWe are able to preserve the join keys\n\n.. ipython:: python\n\n   pd.merge(df1, df2, how=\"outer\")\n   pd.merge(df1, df2, how=\"outer\").dtypes\n\nOf course if you have missing values that are introduced, then the\nresulting dtype will be upcast, which is unchanged from previous.\n\n.. ipython:: python\n\n   pd.merge(df1, df2, how=\"outer\", on=\"key\")\n   pd.merge(df1, df2, how=\"outer\", on=\"key\").dtypes\n\n.. _whatsnew_0190.api.describe:\n\nMethod ``.describe()`` changes\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nPercentile identifiers in the index of a ``.describe()`` output will now be rounded to the least precision that keeps them distinct (:issue:`13104`)\n\n.. ipython:: python\n\n   s = pd.Series([0, 1, 2, 3, 4])\n   df = pd.DataFrame([0, 1, 2, 3, 4])\n\n**Previous behavior**:\n\nThe percentiles were rounded to at most one decimal place, which could raise ``ValueError`` for a data frame if the percentiles were duplicated.\n\n.. code-block:: ipython\n\n   In [3]: s.describe(percentiles=[0.0001, 0.0005, 0.001, 0.999, 0.9995, 0.9999])\n   Out[3]:\n   count     5.000000\n   mean      2.000000\n   std       1.581139\n   min       0.000000\n   0.0%      0.000400\n   0.1%      0.002000\n   0.1%      0.004000\n   50%       2.000000\n   99.9%     3.996000\n   100.0%    3.998000\n   100.0%    3.999600\n   max       4.000000\n   dtype: float64\n\n   In [4]: df.describe(percentiles=[0.0001, 0.0005, 0.001, 0.999, 0.9995, 0.9999])\n   Out[4]:\n   ...\n   ValueError: cannot reindex from a duplicate axis\n\n**New behavior**:\n\n.. ipython:: python\n\n   s.describe(percentiles=[0.0001, 0.0005, 0.001, 0.999, 0.9995, 0.9999])\n   df.describe(percentiles=[0.0001, 0.0005, 0.001, 0.999, 0.9995, 0.9999])\n\nFurthermore:\n\n- Passing duplicated ``percentiles`` will now raise a ``ValueError``.\n- Bug in ``.describe()`` on a DataFrame with a mixed-dtype column index, which would previously raise a ``TypeError`` (:issue:`13288`)\n\n.. _whatsnew_0190.api.period:\n\n``Period`` changes\n^^^^^^^^^^^^^^^^^^\n\nThe ``PeriodIndex`` now has ``period`` dtype\n\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\n\n``PeriodIndex`` now has its own ``period`` dtype. The ``period`` dtype is a\npandas extension dtype like ``category`` or the :ref:`timezone aware dtype <timeseries.timezone_series>` (``datetime64[ns, tz]``) (:issue:`13941`).\nAs a consequence of this change, ``PeriodIndex`` no longer has an integer dtype:\n\n**Previous behavior**:\n\n.. code-block:: ipython\n\n   In [1]: pi = pd.PeriodIndex(['2016-08-01'], freq='D')\n\n   In [2]: pi\n   Out[2]: PeriodIndex(['2016-08-01'], dtype='int64', freq='D')\n\n   In [3]: pd.api.types.is_integer_dtype(pi)\n   Out[3]: True\n\n   In [4]: pi.dtype\n   Out[4]: dtype('int64')\n\n**New behavior**:\n\n.. ipython:: python\n   :okwarning:\n\n   pi = pd.PeriodIndex([\"2016-08-01\"], freq=\"D\")\n   pi\n   pd.api.types.is_integer_dtype(pi)\n   pd.api.types.is_period_dtype(pi)\n   pi.dtype\n   type(pi.dtype)\n\n.. _whatsnew_0190.api.periodnat:\n\n``Period('NaT')`` now returns ``pd.NaT``\n\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\n\nPreviously, ``Period`` has its own ``Period('NaT')`` representation different from ``pd.NaT``. Now ``Period('NaT')`` has been changed to return ``pd.NaT``. (:issue:`12759`, :issue:`13582`)\n\n**Previous behavior**:\n\n.. code-block:: ipython\n\n   In [5]: pd.Period('NaT', freq='D')\n   Out[5]: Period('NaT', 'D')\n\n**New behavior**:\n\nThese result in ``pd.NaT`` without providing ``freq`` option.\n\n.. ipython:: python\n\n   pd.Period(\"NaT\")\n   pd.Period(None)\n\n\nTo be compatible with ``Period`` addition and subtraction, ``pd.NaT`` now supports addition and subtraction with ``int``. Previously it raised ``ValueError``.\n\n**Previous behavior**:\n\n.. code-block:: ipython\n\n   In [5]: pd.NaT + 1\n   ...\n   ValueError: Cannot add integral value to Timestamp without freq.\n\n**New behavior**:\n\n.. ipython:: python\n\n   pd.NaT + 1\n   pd.NaT - 1\n\n``PeriodIndex.values`` now returns array of ``Period`` object\n\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\n\n``.values`` is changed to return an array of ``Period`` objects, rather than an array\nof integers (:issue:`13988`).\n\n**Previous behavior**:\n\n.. code-block:: ipython\n\n   In [6]: pi = pd.PeriodIndex(['2011-01', '2011-02'], freq='M')\n   In [7]: pi.values\n   Out[7]: array([492, 493])\n\n**New behavior**:\n\n.. ipython:: python\n\n   pi = pd.PeriodIndex([\"2011-01\", \"2011-02\"], freq=\"M\")\n   pi.values\n\n\n.. _whatsnew_0190.api.setops:\n\nIndex ``+`` / ``-`` no longer used for set operations\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nAddition and subtraction of the base Index type and of DatetimeIndex\n(not the numeric index types)\npreviously performed set operations (set union and difference). This\nbehavior was already deprecated since 0.15.0 (in favor using the specific\n``.union()`` and ``.difference()`` methods), and is now disabled. When\npossible, ``+`` and ``-`` are now used for element-wise operations, for\nexample for concatenating strings or subtracting datetimes\n(:issue:`8227`, :issue:`14127`).\n\nPrevious behavior:\n\n.. code-block:: ipython\n\n   In [1]: pd.Index(['a', 'b']) + pd.Index(['a', 'c'])\n   FutureWarning: using '+' to provide set union with Indexes is deprecated, use '|' or .union()\n   Out[1]: Index(['a', 'b', 'c'], dtype='object')\n\n**New behavior**: the same operation will now perform element-wise addition:\n\n.. ipython:: python\n\n   pd.Index([\"a\", \"b\"]) + pd.Index([\"a\", \"c\"])\n\nNote that numeric Index objects already performed element-wise operations.\nFor example, the behavior of adding two integer Indexes is unchanged.\nThe base ``Index`` is now made consistent with this behavior.\n\n.. ipython:: python\n\n   pd.Index([1, 2, 3]) + pd.Index([2, 3, 4])\n\nFurther, because of this change, it is now possible to subtract two\nDatetimeIndex objects resulting in a TimedeltaIndex:\n\n**Previous behavior**:\n\n.. code-block:: ipython\n\n    In [1]: (pd.DatetimeIndex(['2016-01-01', '2016-01-02'])\n       ...:  - pd.DatetimeIndex(['2016-01-02', '2016-01-03']))\n    FutureWarning: using '-' to provide set differences with datetimelike Indexes is deprecated, use .difference()\n    Out[1]: DatetimeIndex(['2016-01-01'], dtype='datetime64[ns]', freq=None)\n\n**New behavior**:\n\n.. ipython:: python\n\n    (\n        pd.DatetimeIndex([\"2016-01-01\", \"2016-01-02\"])\n        - pd.DatetimeIndex([\"2016-01-02\", \"2016-01-03\"])\n    )\n\n\n.. _whatsnew_0190.api.difference:\n\n``Index.difference`` and ``.symmetric_difference`` changes\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n``Index.difference`` and ``Index.symmetric_difference`` will now, more consistently, treat ``NaN`` values as any other values. (:issue:`13514`)\n\n.. ipython:: python\n\n   idx1 = pd.Index([1, 2, 3, np.nan])\n   idx2 = pd.Index([0, 1, np.nan])\n\n**Previous behavior**:\n\n.. code-block:: ipython\n\n   In [3]: idx1.difference(idx2)\n   Out[3]: Float64Index([nan, 2.0, 3.0], dtype='float64')\n\n   In [4]: idx1.symmetric_difference(idx2)\n   Out[4]: Float64Index([0.0, nan, 2.0, 3.0], dtype='float64')\n\n**New behavior**:\n\n.. ipython:: python\n\n   idx1.difference(idx2)\n   idx1.symmetric_difference(idx2)\n\n.. _whatsnew_0190.api.unique_index:\n\n``Index.unique`` consistently returns ``Index``\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n``Index.unique()`` now returns unique values as an\n``Index`` of the appropriate ``dtype``. (:issue:`13395`).\nPreviously, most ``Index`` classes returned ``np.ndarray``, and ``DatetimeIndex``,\n``TimedeltaIndex`` and ``PeriodIndex`` returned ``Index`` to keep metadata like timezone.\n\n**Previous behavior**:\n\n.. code-block:: ipython\n\n   In [1]: pd.Index([1, 2, 3]).unique()\n   Out[1]: array([1, 2, 3])\n\n   In [2]: pd.DatetimeIndex(['2011-01-01', '2011-01-02',\n      ...:                   '2011-01-03'], tz='Asia/Tokyo').unique()\n   Out[2]:\n   DatetimeIndex(['2011-01-01 00:00:00+09:00', '2011-01-02 00:00:00+09:00',\n                  '2011-01-03 00:00:00+09:00'],\n                 dtype='datetime64[ns, Asia/Tokyo]', freq=None)\n\n**New behavior**:\n\n.. ipython:: python\n\n   pd.Index([1, 2, 3]).unique()\n   pd.DatetimeIndex(\n       [\"2011-01-01\", \"2011-01-02\", \"2011-01-03\"], tz=\"Asia/Tokyo\"\n   ).unique()\n\n.. _whatsnew_0190.api.multiindex:\n\n``MultiIndex`` constructors, ``groupby`` and ``set_index`` preserve categorical dtypes\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n``MultiIndex.from_arrays`` and ``MultiIndex.from_product`` will now preserve categorical dtype\nin ``MultiIndex`` levels (:issue:`13743`, :issue:`13854`).\n\n.. ipython:: python\n\n   cat = pd.Categorical([\"a\", \"b\"], categories=list(\"bac\"))\n   lvl1 = [\"foo\", \"bar\"]\n   midx = pd.MultiIndex.from_arrays([cat, lvl1])\n   midx\n\n**Previous behavior**:\n\n.. code-block:: ipython\n\n   In [4]: midx.levels[0]\n   Out[4]: Index(['b', 'a', 'c'], dtype='object')\n\n   In [5]: midx.get_level_values[0]\n   Out[5]: Index(['a', 'b'], dtype='object')\n\n**New behavior**: the single level is now a ``CategoricalIndex``:\n\n.. ipython:: python\n\n   midx.levels[0]\n   midx.get_level_values(0)\n\nAn analogous change has been made to ``MultiIndex.from_product``.\nAs a consequence, ``groupby`` and ``set_index`` also preserve categorical dtypes in indexes\n\n.. ipython:: python\n\n   df = pd.DataFrame({\"A\": [0, 1], \"B\": [10, 11], \"C\": cat})\n   df_grouped = df.groupby(by=[\"A\", \"C\"], observed=False).first()\n   df_set_idx = df.set_index([\"A\", \"C\"])\n\n**Previous behavior**:\n\n.. code-block:: ipython\n\n   In [11]: df_grouped.index.levels[1]\n   Out[11]: Index(['b', 'a', 'c'], dtype='object', name='C')\n   In [12]: df_grouped.reset_index().dtypes\n   Out[12]:\n   A      int64\n   C     object\n   B    float64\n   dtype: object\n\n   In [13]: df_set_idx.index.levels[1]\n   Out[13]: Index(['b', 'a', 'c'], dtype='object', name='C')\n   In [14]: df_set_idx.reset_index().dtypes\n   Out[14]:\n   A      int64\n   C     object\n   B      int64\n   dtype: object\n\n**New behavior**:\n\n.. ipython:: python\n\n   df_grouped.index.levels[1]\n   df_grouped.reset_index().dtypes\n\n   df_set_idx.index.levels[1]\n   df_set_idx.reset_index().dtypes\n\n.. _whatsnew_0190.api.autogenerated_chunksize_index:\n\nFunction ``read_csv`` will progressively enumerate chunks\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nWhen :func:`read_csv` is called with ``chunksize=n`` and without specifying an index,\neach chunk used to have an independently generated index from ``0`` to ``n-1``.\nThey are now given instead a progressive index, starting from ``0`` for the first chunk,\nfrom ``n`` for the second, and so on, so that, when concatenated, they are identical to\nthe result of calling :func:`read_csv` without the ``chunksize=`` argument\n(:issue:`12185`).\n\n.. ipython:: python\n\n   data = \"A,B\\n0,1\\n2,3\\n4,5\\n6,7\"\n\n**Previous behavior**:\n\n.. code-block:: ipython\n\n   In [2]: pd.concat(pd.read_csv(StringIO(data), chunksize=2))\n   Out[2]:\n      A  B\n   0  0  1\n   1  2  3\n   0  4  5\n   1  6  7\n\n**New behavior**:\n\n.. ipython:: python\n\n   pd.concat(pd.read_csv(StringIO(data), chunksize=2))\n\n.. _whatsnew_0190.sparse:\n\nSparse changes\n^^^^^^^^^^^^^^\n\nThese changes allow pandas to handle sparse data with more dtypes, and for work to make a smoother experience with data handling.\n\nTypes ``int64`` and ``bool`` support enhancements\n\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\n\nSparse data structures now gained enhanced support of ``int64`` and ``bool`` ``dtype`` (:issue:`667`, :issue:`13849`).\n\nPreviously, sparse data were ``float64`` dtype by default, even if all inputs were of ``int`` or ``bool`` dtype. You had to specify ``dtype`` explicitly to create sparse data with ``int64`` dtype. Also, ``fill_value`` had to be specified explicitly because the default was ``np.nan`` which doesn't appear in ``int64`` or ``bool`` data.\n\n.. code-block:: ipython\n\n   In [1]: pd.SparseArray([1, 2, 0, 0])\n   Out[1]:\n   [1.0, 2.0, 0.0, 0.0]\n   Fill: nan\n   IntIndex\n   Indices: array([0, 1, 2, 3], dtype=int32)\n\n    specifying int64 dtype, but all values are stored in sp_values because\n    fill_value default is np.nan\n   In [2]: pd.SparseArray([1, 2, 0, 0], dtype=np.int64)\n   Out[2]:\n   [1, 2, 0, 0]\n   Fill: nan\n   IntIndex\n   Indices: array([0, 1, 2, 3], dtype=int32)\n\n   In [3]: pd.SparseArray([1, 2, 0, 0], dtype=np.int64, fill_value=0)\n   Out[3]:\n   [1, 2, 0, 0]\n   Fill: 0\n   IntIndex\n   Indices: array([0, 1], dtype=int32)\n\nAs of v0.19.0, sparse data keeps the input dtype, and uses more appropriate ``fill_value`` defaults (``0`` for ``int64`` dtype, ``False`` for ``bool`` dtype).\n\n.. ipython:: python\n\n   pd.arrays.SparseArray([1, 2, 0, 0], dtype=np.int64)\n   pd.arrays.SparseArray([True, False, False, False])\n\nSee the :ref:`docs <sparse.dtype>` for more details.\n\nOperators now preserve dtypes\n\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\n\n- Sparse data structure now can preserve ``dtype`` after arithmetic ops (:issue:`13848`)\n\n.. code-block:: python\n\n   s = pd.SparseSeries([0, 2, 0, 1], fill_value=0, dtype=np.int64)\n   s.dtype\n\n   s + 1\n\n- Sparse data structure now support ``astype`` to convert internal ``dtype`` (:issue:`13900`)\n\n.. code-block:: python\n\n   s = pd.SparseSeries([1.0, 0.0, 2.0, 0.0], fill_value=0)\n   s\n   s.astype(np.int64)\n\n``astype`` fails if data contains values which cannot be converted to specified ``dtype``.\nNote that the limitation is applied to ``fill_value`` which default is ``np.nan``.\n\n.. code-block:: ipython\n\n   In [7]: pd.SparseSeries([1., np.nan, 2., np.nan], fill_value=np.nan).astype(np.int64)\n   Out[7]:\n   ValueError: unable to coerce current fill_value nan to int64 dtype\n\nOther sparse fixes\n\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\n\n- Subclassed ``SparseDataFrame`` and ``SparseSeries`` now preserve class types when slicing or transposing. (:issue:`13787`)\n- ``SparseArray`` with ``bool`` dtype now supports logical (bool) operators (:issue:`14000`)\n- Bug in ``SparseSeries`` with ``MultiIndex`` ``[]`` indexing may raise ``IndexError`` (:issue:`13144`)\n- Bug in ``SparseSeries`` with ``MultiIndex`` ``[]`` indexing result may have normal ``Index`` (:issue:`13144`)\n- Bug in ``SparseDataFrame`` in which ``axis=None`` did not default to ``axis=0`` (:issue:`13048`)\n- Bug in ``SparseSeries`` and ``SparseDataFrame`` creation with ``object`` dtype may raise ``TypeError`` (:issue:`11633`)\n- Bug in ``SparseDataFrame`` doesn't respect passed ``SparseArray`` or ``SparseSeries`` 's dtype and ``fill_value``  (:issue:`13866`)\n- Bug in ``SparseArray`` and ``SparseSeries`` don't apply ufunc to ``fill_value`` (:issue:`13853`)\n- Bug in ``SparseSeries.abs`` incorrectly keeps negative ``fill_value`` (:issue:`13853`)\n- Bug in single row slicing on multi-type ``SparseDataFrame`` s, types were previously forced to float (:issue:`13917`)\n- Bug in ``SparseSeries`` slicing changes integer dtype to float (:issue:`8292`)\n- Bug in ``SparseDataFarme`` comparison ops may raise ``TypeError`` (:issue:`13001`)\n- Bug in ``SparseDataFarme.isnull`` raises ``ValueError`` (:issue:`8276`)\n- Bug in ``SparseSeries`` representation with ``bool`` dtype may raise ``IndexError`` (:issue:`13110`)\n- Bug in ``SparseSeries`` and ``SparseDataFrame`` of ``bool`` or ``int64`` dtype may display its values like ``float64`` dtype (:issue:`13110`)\n- Bug in sparse indexing using ``SparseArray`` with ``bool`` dtype may return incorrect result  (:issue:`13985`)\n- Bug in ``SparseArray`` created from ``SparseSeries`` may lose ``dtype`` (:issue:`13999`)\n- Bug in ``SparseSeries`` comparison with dense returns normal ``Series`` rather than ``SparseSeries`` (:issue:`13999`)\n\n\n.. _whatsnew_0190.indexer_dtype:\n\nIndexer dtype changes\n^^^^^^^^^^^^^^^^^^^^^\n\n.. note::\n\n   This change only affects 64 bit python running on Windows, and only affects relatively advanced\n   indexing operations\n\nMethods such as ``Index.get_indexer`` that return an indexer array, coerce that array to a \"platform int\", so that it can be\ndirectly used in 3rd party library operations like ``numpy.take``.  Previously, a platform int was defined as ``np.int_``\nwhich corresponds to a C integer, but the correct type, and what is being used now, is ``np.intp``, which corresponds\nto the C integer size that can hold a pointer (:issue:`3033`, :issue:`13972`).\n\nThese types are the same on many platform, but for 64 bit python on Windows,\n``np.int_`` is 32 bits, and ``np.intp`` is 64 bits.  Changing this behavior improves performance for many\noperations on that platform.\n\n**Previous behavior**:\n\n.. code-block:: ipython\n\n   In [1]: i = pd.Index(['a', 'b', 'c'])\n\n   In [2]: i.get_indexer(['b', 'b', 'c']).dtype\n   Out[2]: dtype('int32')\n\n**New behavior**:\n\n.. code-block:: ipython\n\n   In [1]: i = pd.Index(['a', 'b', 'c'])\n\n   In [2]: i.get_indexer(['b', 'b', 'c']).dtype\n   Out[2]: dtype('int64')\n\n\n.. _whatsnew_0190.api.other:\n\nOther API changes\n^^^^^^^^^^^^^^^^^\n\n- ``Timestamp.to_pydatetime`` will issue a ``UserWarning`` when ``warn=True``, and the instance has a non-zero number of nanoseconds, previously this would print a message to stdout (:issue:`14101`).\n- ``Series.unique()`` with datetime and timezone now returns return array of ``Timestamp`` with timezone (:issue:`13565`).\n- ``Panel.to_sparse()`` will raise a ``NotImplementedError`` exception when called (:issue:`13778`).\n- ``Index.reshape()`` will raise a ``NotImplementedError`` exception when called (:issue:`12882`).\n- ``.filter()`` enforces mutual exclusion of the keyword arguments (:issue:`12399`).\n- ``eval``'s upcasting rules for ``float32`` types have been updated to be more consistent with NumPy's rules.  New behavior will not upcast to ``float64`` if you multiply a pandas ``float32`` object by a scalar float64 (:issue:`12388`).\n- An ``UnsupportedFunctionCall`` error is now raised if NumPy ufuncs like ``np.mean`` are called on groupby or resample objects (:issue:`12811`).\n- ``__setitem__`` will no longer apply a callable rhs as a function instead of storing it. Call ``where`` directly to get the previous behavior (:issue:`13299`).\n- Calls to ``.sample()`` will respect the random seed set via ``numpy.random.seed(n)`` (:issue:`13161`)\n- ``Styler.apply`` is now more strict about the outputs your function must return. For ``axis=0`` or ``axis=1``, the output shape must be identical. For ``axis=None``, the output must be a DataFrame with identical columns and index labels (:issue:`13222`).\n- ``Float64Index.astype(int)`` will now raise ``ValueError`` if ``Float64Index`` contains ``NaN`` values (:issue:`13149`)\n- ``TimedeltaIndex.astype(int)`` and ``DatetimeIndex.astype(int)`` will now return ``Int64Index`` instead of ``np.array`` (:issue:`13209`)\n- Passing ``Period`` with multiple frequencies to normal ``Index`` now returns ``Index`` with ``object`` dtype (:issue:`13664`)\n- ``PeriodIndex.fillna`` with ``Period`` has different freq now coerces to ``object`` dtype (:issue:`13664`)\n- Faceted boxplots from ``DataFrame.boxplot(by=col)`` now return a ``Series`` when ``return_type`` is not None. Previously these returned an ``OrderedDict``. Note that when ``return_type=None``, the default, these still return a 2-D NumPy array (:issue:`12216`, :issue:`7096`).\n- ``pd.read_hdf`` will now raise a ``ValueError`` instead of ``KeyError``, if a mode other than ``r``, ``r+`` and ``a`` is supplied. (:issue:`13623`)\n- ``pd.read_csv()``, ``pd.read_table()``, and ``pd.read_hdf()`` raise the builtin ``FileNotFoundError`` exception for Python 3.x when called on a nonexistent file; this is back-ported as ``IOError`` in Python 2.x (:issue:`14086`)\n- More informative exceptions are passed through the csv parser. The exception type would now be the original exception type instead of ``CParserError`` (:issue:`13652`).\n- ``pd.read_csv()`` in the C engine will now issue a ``ParserWarning`` or raise a ``ValueError`` when ``sep`` encoded is more than one character long (:issue:`14065`)\n- ``DataFrame.values`` will now return ``float64`` with a ``DataFrame`` of mixed ``int64`` and ``uint64`` dtypes, conforming to ``np.find_common_type`` (:issue:`10364`, :issue:`13917`)\n- ``.groupby.groups`` will now return a dictionary of ``Index`` objects, rather than a dictionary of ``np.ndarray`` or ``lists`` (:issue:`14293`)\n\n.. _whatsnew_0190.deprecations:\n\nDeprecations\n~~~~~~~~~~~~\n- ``Series.reshape`` and ``Categorical.reshape`` have been deprecated and will be removed in a subsequent release (:issue:`12882`, :issue:`12882`)\n- ``PeriodIndex.to_datetime`` has been deprecated in favor of ``PeriodIndex.to_timestamp`` (:issue:`8254`)\n- ``Timestamp.to_datetime`` has been deprecated in favor of ``Timestamp.to_pydatetime`` (:issue:`8254`)\n- ``Index.to_datetime`` and ``DatetimeIndex.to_datetime`` have been deprecated in favor of ``pd.to_datetime`` (:issue:`8254`)\n- ``pandas.core.datetools`` module has been deprecated and will be removed in a subsequent release (:issue:`14094`)\n- ``SparseList`` has been deprecated and will be removed in a future version (:issue:`13784`)\n- ``DataFrame.to_html()`` and ``DataFrame.to_latex()`` have dropped the ``colSpace`` parameter in favor of ``col_space`` (:issue:`13857`)\n- ``DataFrame.to_sql()`` has deprecated the ``flavor`` parameter, as it is superfluous when SQLAlchemy is not installed (:issue:`13611`)\n- Deprecated ``read_csv`` keywords:\n\n  - ``compact_ints`` and ``use_unsigned`` have been deprecated and will be removed in a future version (:issue:`13320`)\n  - ``buffer_lines`` has been deprecated and will be removed in a future version (:issue:`13360`)\n  - ``as_recarray`` has been deprecated and will be removed in a future version (:issue:`13373`)\n  - ``skip_footer`` has been deprecated in favor of ``skipfooter`` and will be removed in a future version (:issue:`13349`)\n\n- top-level ``pd.ordered_merge()`` has been renamed to ``pd.merge_ordered()`` and the original name will be removed in a future version (:issue:`13358`)\n- ``Timestamp.offset`` property (and named arg in the constructor), has been deprecated in favor of ``freq`` (:issue:`12160`)\n- ``pd.tseries.util.pivot_annual`` is deprecated. Use ``pivot_table`` as alternative, an example is :ref:`here <cookbook.pivot>` (:issue:`736`)\n- ``pd.tseries.util.isleapyear`` has been deprecated and will be removed in a subsequent release. Datetime-likes now have a ``.is_leap_year`` property (:issue:`13727`)\n- ``Panel4D`` and ``PanelND`` constructors are deprecated and will be removed in a future version. The recommended way to represent these types of n-dimensional data are with the `xarray package <http://xarray.pydata.org/en/stable/>`__. pandas provides a :meth:`~Panel4D.to_xarray` method to automate this conversion (:issue:`13564`).\n- ``pandas.tseries.frequencies.get_standard_freq`` is deprecated. Use  ``pandas.tseries.frequencies.to_offset(freq).rule_code`` instead (:issue:`13874`)\n- ``pandas.tseries.frequencies.to_offset``'s ``freqstr`` keyword is deprecated in favor of ``freq`` (:issue:`13874`)\n- ``Categorical.from_array`` has been deprecated and will be removed in a future version (:issue:`13854`)\n\n.. _whatsnew_0190.prior_deprecations:\n\nRemoval of prior version deprecations/changes\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\n- The ``SparsePanel`` class has been removed (:issue:`13778`)\n- The ``pd.sandbox`` module has been removed in favor of the external library ``pandas-qt`` (:issue:`13670`)\n- The ``pandas.io.data`` and ``pandas.io.wb`` modules are removed in favor of\n  the `pandas-datareader package <https://github.com/pydata/pandas-datareader>`__ (:issue:`13724`).\n- The ``pandas.tools.rplot`` module has been removed in favor of\n  the `seaborn package <https://github.com/mwaskom/seaborn>`__ (:issue:`13855`)\n- ``DataFrame.to_csv()`` has dropped the ``engine`` parameter, as was deprecated in 0.17.1 (:issue:`11274`, :issue:`13419`)\n- ``DataFrame.to_dict()`` has dropped the ``outtype`` parameter in favor of ``orient`` (:issue:`13627`, :issue:`8486`)\n- ``pd.Categorical`` has dropped setting of the ``ordered`` attribute directly in favor of the ``set_ordered`` method (:issue:`13671`)\n- ``pd.Categorical`` has dropped the ``levels`` attribute in favor of ``categories`` (:issue:`8376`)\n- ``DataFrame.to_sql()`` has dropped the ``mysql`` option for the ``flavor`` parameter (:issue:`13611`)\n- ``Panel.shift()`` has dropped the ``lags`` parameter in favor of ``periods`` (:issue:`14041`)\n- ``pd.Index`` has dropped the ``diff`` method in favor of ``difference`` (:issue:`13669`)\n- ``pd.DataFrame`` has dropped the ``to_wide`` method in favor of ``to_panel`` (:issue:`14039`)\n- ``Series.to_csv`` has dropped the ``nanRep`` parameter in favor of ``na_rep`` (:issue:`13804`)\n- ``Series.xs``, ``DataFrame.xs``, ``Panel.xs``, ``Panel.major_xs``, and ``Panel.minor_xs`` have dropped the ``copy`` parameter (:issue:`13781`)\n- ``str.split`` has dropped the ``return_type`` parameter in favor of ``expand`` (:issue:`13701`)\n- Removal of the legacy time rules (offset aliases), deprecated since 0.17.0 (this has been alias since 0.8.0) (:issue:`13590`, :issue:`13868`). Now legacy time rules raises ``ValueError``. For the list of currently supported offsets, see :ref:`here <timeseries.offset_aliases>`.\n- The default value for the ``return_type`` parameter for ``DataFrame.plot.box`` and ``DataFrame.boxplot`` changed from ``None`` to ``\"axes\"``. These methods will now return a matplotlib axes by default instead of a dictionary of artists. See :ref:`here <visualization.box.return>` (:issue:`6581`).\n- The ``tquery`` and ``uquery`` functions in the ``pandas.io.sql`` module are removed (:issue:`5950`).\n\n\n.. _whatsnew_0190.performance:\n\nPerformance improvements\n~~~~~~~~~~~~~~~~~~~~~~~~\n\n- Improved performance of sparse ``IntIndex.intersect`` (:issue:`13082`)\n- Improved performance of sparse arithmetic with ``BlockIndex`` when the number of blocks are large, though recommended to use ``IntIndex`` in such cases (:issue:`13082`)\n- Improved performance of ``DataFrame.quantile()`` as it now operates per-block (:issue:`11623`)\n- Improved performance of float64 hash table operations, fixing some very slow indexing and groupby operations in python 3 (:issue:`13166`, :issue:`13334`)\n- Improved performance of ``DataFrameGroupBy.transform`` (:issue:`12737`)\n- Improved performance of ``Index`` and ``Series`` ``.duplicated`` (:issue:`10235`)\n- Improved performance of ``Index.difference`` (:issue:`12044`)\n- Improved performance of ``RangeIndex.is_monotonic_increasing`` and ``is_monotonic_decreasing`` (:issue:`13749`)\n- Improved performance of datetime string parsing in ``DatetimeIndex`` (:issue:`13692`)\n- Improved performance of hashing ``Period`` (:issue:`12817`)\n- Improved performance of ``factorize`` of datetime with timezone (:issue:`13750`)\n- Improved performance of by lazily creating indexing hashtables on larger Indexes (:issue:`14266`)\n- Improved performance of ``groupby.groups`` (:issue:`14293`)\n- Unnecessary materializing of a MultiIndex when introspecting for memory usage (:issue:`14308`)\n\n.. _whatsnew_0190.bug_fixes:\n\nBug fixes\n~~~~~~~~~\n\n- Bug in ``groupby().shift()``, which could cause a segfault or corruption in rare circumstances when grouping by columns with missing values (:issue:`13813`)\n- Bug in ``groupby().cumsum()`` calculating ``cumprod`` when ``axis=1``. (:issue:`13994`)\n- Bug in ``pd.to_timedelta()`` in which the ``errors`` parameter was not being respected (:issue:`13613`)\n- Bug in ``io.json.json_normalize()``, where non-ascii keys raised an exception (:issue:`13213`)\n- Bug when passing a not-default-indexed ``Series`` as ``xerr`` or ``yerr`` in ``.plot()`` (:issue:`11858`)\n- Bug in area plot draws legend incorrectly if subplot is enabled or legend is moved after plot (matplotlib 1.5.0 is required to draw area plot legend properly) (:issue:`9161`, :issue:`13544`)\n- Bug in ``DataFrame`` assignment with an object-dtyped ``Index`` where the resultant column is mutable to the original object. (:issue:`13522`)\n- Bug in matplotlib ``AutoDataFormatter``; this restores the second scaled formatting and re-adds micro-second scaled formatting (:issue:`13131`)\n- Bug in selection from a ``HDFStore`` with a fixed format and ``start`` and/or ``stop`` specified will now return the selected range (:issue:`8287`)\n- Bug in ``Categorical.from_codes()`` where an unhelpful error was raised when an invalid ``ordered`` parameter was passed in (:issue:`14058`)\n- Bug in ``Series`` construction from a tuple of integers on windows not returning default dtype (int64) (:issue:`13646`)\n- Bug in ``TimedeltaIndex`` addition with a Datetime-like object where addition overflow was not being caught (:issue:`14068`)\n- Bug in ``.groupby(..).resample(..)`` when the same object is called multiple times (:issue:`13174`)\n- Bug in ``.to_records()`` when index name is a unicode string (:issue:`13172`)\n- Bug in calling ``.memory_usage()`` on object which doesn't implement (:issue:`12924`)\n- Regression in ``Series.quantile`` with nans (also shows up in ``.median()`` and ``.describe()`` ); furthermore now names the ``Series`` with the quantile (:issue:`13098`, :issue:`13146`)\n- Bug in ``SeriesGroupBy.transform`` with datetime values and missing groups (:issue:`13191`)\n- Bug where empty ``Series`` were incorrectly coerced in datetime-like numeric operations (:issue:`13844`)\n- Bug in ``Categorical`` constructor when passed a ``Categorical`` containing datetimes with timezones (:issue:`14190`)\n- Bug in ``Series.str.extractall()`` with ``str`` index raises ``ValueError``  (:issue:`13156`)\n- Bug in ``Series.str.extractall()`` with single group and quantifier  (:issue:`13382`)\n- Bug in ``DatetimeIndex`` and ``Period`` subtraction raises ``ValueError`` or ``AttributeError`` rather than ``TypeError`` (:issue:`13078`)\n- Bug in ``Index`` and ``Series`` created with ``NaN`` and ``NaT`` mixed data may not have ``datetime64`` dtype  (:issue:`13324`)\n- Bug in ``Index`` and ``Series`` may ignore ``np.datetime64('nat')`` and ``np.timdelta64('nat')`` to infer dtype (:issue:`13324`)\n- Bug in ``PeriodIndex`` and ``Period`` subtraction raises ``AttributeError`` (:issue:`13071`)\n- Bug in ``PeriodIndex`` construction returning a ``float64`` index in some circumstances (:issue:`13067`)\n- Bug in ``.resample(..)`` with a ``PeriodIndex`` not changing its ``freq`` appropriately when empty (:issue:`13067`)\n- Bug in ``.resample(..)`` with a ``PeriodIndex`` not retaining its type or name with an empty ``DataFrame`` appropriately when empty (:issue:`13212`)\n- Bug in ``groupby(..).apply(..)`` when the passed function returns scalar values per group (:issue:`13468`).\n- Bug in ``groupby(..).resample(..)`` where passing some keywords would raise an exception (:issue:`13235`)\n- Bug in ``.tz_convert`` on a tz-aware ``DateTimeIndex`` that relied on index being sorted for correct results (:issue:`13306`)\n- Bug in ``.tz_localize`` with ``dateutil.tz.tzlocal`` may return incorrect result (:issue:`13583`)\n- Bug in ``DatetimeTZDtype`` dtype with ``dateutil.tz.tzlocal`` cannot be regarded as valid dtype (:issue:`13583`)\n- Bug in ``pd.read_hdf()`` where attempting to load an HDF file with a single dataset, that had one or more categorical columns, failed unless the key argument was set to the name of the dataset. (:issue:`13231`)\n- Bug in ``.rolling()`` that allowed a negative integer window in construction of the ``Rolling()`` object, but would later fail on aggregation (:issue:`13383`)\n- Bug in ``Series`` indexing with tuple-valued data and a numeric index (:issue:`13509`)\n- Bug in printing ``pd.DataFrame`` where unusual elements with the ``object`` dtype were causing segfaults (:issue:`13717`)\n- Bug in ranking ``Series`` which could result in segfaults (:issue:`13445`)\n- Bug in various index types, which did not propagate the name of passed index (:issue:`12309`)\n- Bug in ``DatetimeIndex``, which did not honour the ``copy=True`` (:issue:`13205`)\n- Bug in ``DatetimeIndex.is_normalized`` returns incorrectly for normalized date_range in case of local timezones (:issue:`13459`)\n- Bug in ``pd.concat`` and ``.append`` may coerces ``datetime64`` and ``timedelta`` to ``object`` dtype containing python built-in ``datetime`` or ``timedelta`` rather than ``Timestamp`` or ``Timedelta`` (:issue:`13626`)\n- Bug in ``PeriodIndex.append`` may raises ``AttributeError`` when the result is ``object`` dtype (:issue:`13221`)\n- Bug in ``CategoricalIndex.append`` may accept normal ``list`` (:issue:`13626`)\n- Bug in ``pd.concat`` and ``.append`` with the same timezone get reset to UTC (:issue:`7795`)\n- Bug in ``Series`` and ``DataFrame`` ``.append`` raises ``AmbiguousTimeError`` if data contains datetime near DST boundary (:issue:`13626`)\n- Bug in ``DataFrame.to_csv()`` in which float values were being quoted even though quotations were specified for non-numeric values only (:issue:`12922`, :issue:`13259`)\n- Bug in ``DataFrame.describe()`` raising ``ValueError`` with only boolean columns (:issue:`13898`)\n- Bug in ``MultiIndex`` slicing where extra elements were returned when level is non-unique (:issue:`12896`)\n- Bug in ``.str.replace`` does not raise ``TypeError`` for invalid replacement (:issue:`13438`)\n- Bug in ``MultiIndex.from_arrays`` which didn't check for input array lengths matching (:issue:`13599`)\n- Bug in ``cartesian_product`` and ``MultiIndex.from_product`` which may raise with empty input arrays (:issue:`12258`)\n- Bug in ``pd.read_csv()`` which may cause a segfault or corruption when iterating in large chunks over a stream/file under rare circumstances (:issue:`13703`)\n- Bug in ``pd.read_csv()`` which caused errors to be raised when a dictionary containing scalars is passed in for ``na_values`` (:issue:`12224`)\n- Bug in ``pd.read_csv()`` which caused BOM files to be incorrectly parsed by not ignoring the BOM (:issue:`4793`)\n- Bug in ``pd.read_csv()`` with ``engine='python'`` which raised errors when a numpy array was passed in for ``usecols`` (:issue:`12546`)\n- Bug in ``pd.read_csv()`` where the index columns were being incorrectly parsed when parsed as dates with a ``thousands`` parameter (:issue:`14066`)\n- Bug in ``pd.read_csv()`` with ``engine='python'`` in which ``NaN`` values weren't being detected after data was converted to numeric values (:issue:`13314`)\n- Bug in ``pd.read_csv()`` in which the ``nrows`` argument was not properly validated for both engines (:issue:`10476`)\n- Bug in ``pd.read_csv()`` with ``engine='python'`` in which infinities of mixed-case forms were not being interpreted properly (:issue:`13274`)\n- Bug in ``pd.read_csv()`` with ``engine='python'`` in which trailing ``NaN`` values were not being parsed (:issue:`13320`)\n- Bug in ``pd.read_csv()`` with ``engine='python'`` when reading from a ``tempfile.TemporaryFile`` on Windows with Python 3 (:issue:`13398`)\n- Bug in ``pd.read_csv()`` that prevents ``usecols`` kwarg from accepting single-byte unicode strings (:issue:`13219`)\n- Bug in ``pd.read_csv()`` that prevents ``usecols`` from being an empty set (:issue:`13402`)\n- Bug in ``pd.read_csv()`` in the C engine where the NULL character was not being parsed as NULL (:issue:`14012`)\n- Bug in ``pd.read_csv()`` with ``engine='c'`` in which NULL ``quotechar`` was not accepted even though ``quoting`` was specified as ``None`` (:issue:`13411`)\n- Bug in ``pd.read_csv()`` with ``engine='c'`` in which fields were not properly cast to float when quoting was specified as non-numeric (:issue:`13411`)\n- Bug in ``pd.read_csv()`` in Python 2.x with non-UTF8 encoded, multi-character separated data (:issue:`3404`)\n- Bug in ``pd.read_csv()``, where aliases for utf-xx (e.g. UTF-xx, UTF_xx, utf_xx) raised UnicodeDecodeError (:issue:`13549`)\n- Bug in ``pd.read_csv``, ``pd.read_table``, ``pd.read_fwf``, ``pd.read_stata`` and ``pd.read_sas`` where files were opened by parsers but not closed if both ``chunksize`` and ``iterator`` were ``None``. (:issue:`13940`)\n- Bug in ``StataReader``, ``StataWriter``, ``XportReader`` and ``SAS7BDATReader`` where a file was not properly closed when an error was raised. (:issue:`13940`)\n- Bug in ``pd.pivot_table()`` where ``margins_name`` is ignored when ``aggfunc`` is a list (:issue:`13354`)\n- Bug in ``pd.Series.str.zfill``, ``center``, ``ljust``, ``rjust``, and ``pad`` when passing non-integers, did not raise ``TypeError`` (:issue:`13598`)\n- Bug in checking for any null objects in a ``TimedeltaIndex``, which always returned ``True`` (:issue:`13603`)\n- Bug in ``Series`` arithmetic raises ``TypeError`` if it contains datetime-like as ``object`` dtype (:issue:`13043`)\n- Bug ``Series.isnull()`` and ``Series.notnull()`` ignore ``Period('NaT')``  (:issue:`13737`)\n- Bug ``Series.fillna()`` and ``Series.dropna()`` don't affect to ``Period('NaT')``  (:issue:`13737`\n- Bug in ``.fillna(value=np.nan)`` incorrectly raises ``KeyError`` on a ``category`` dtyped ``Series`` (:issue:`14021`)\n- Bug in extension dtype creation where the created types were not is/identical (:issue:`13285`)\n- Bug in ``.resample(..)`` where incorrect warnings were triggered by IPython introspection (:issue:`13618`)\n- Bug in ``NaT`` - ``Period`` raises ``AttributeError`` (:issue:`13071`)\n- Bug in ``Series`` comparison may output incorrect result if rhs contains ``NaT`` (:issue:`9005`)\n- Bug in ``Series`` and ``Index`` comparison may output incorrect result if it contains ``NaT`` with ``object`` dtype (:issue:`13592`)\n- Bug in ``Period`` addition raises ``TypeError`` if ``Period`` is on right hand side (:issue:`13069`)\n- Bug in ``Period`` and ``Series`` or ``Index`` comparison raises ``TypeError`` (:issue:`13200`)\n- Bug in ``pd.set_eng_float_format()`` that would prevent NaN and Inf from formatting (:issue:`11981`)\n- Bug in ``.unstack`` with ``Categorical`` dtype resets ``.ordered`` to ``True`` (:issue:`13249`)\n- Clean some compile time warnings in datetime parsing (:issue:`13607`)\n- Bug in ``factorize`` raises ``AmbiguousTimeError`` if data contains datetime near DST boundary (:issue:`13750`)\n- Bug in ``.set_index`` raises ``AmbiguousTimeError`` if new index contains DST boundary and multi levels (:issue:`12920`)\n- Bug in ``.shift`` raises ``AmbiguousTimeError`` if data contains datetime near DST boundary (:issue:`13926`)\n- Bug in ``pd.read_hdf()`` returns incorrect result when a ``DataFrame`` with a ``categorical`` column and a query which doesn't match any values (:issue:`13792`)\n- Bug in ``.iloc`` when indexing with a non lexsorted MultiIndex (:issue:`13797`)\n- Bug in ``.loc`` when indexing with date strings in a reverse sorted ``DatetimeIndex`` (:issue:`14316`)\n- Bug in ``Series`` comparison operators when dealing with zero dim NumPy arrays (:issue:`13006`)\n- Bug in ``.combine_first`` may return incorrect ``dtype`` (:issue:`7630`, :issue:`10567`)\n- Bug in ``groupby`` where ``apply`` returns different result depending on whether first result is ``None`` or not (:issue:`12824`)\n- Bug in ``groupby(..).nth()`` where the group key is included inconsistently if called after ``.head()/.tail()`` (:issue:`12839`)\n- Bug in ``.to_html``, ``.to_latex`` and ``.to_string`` silently ignore custom datetime formatter passed through the ``formatters`` key word (:issue:`10690`)\n- Bug in ``DataFrame.iterrows()``, not yielding a ``Series`` subclasse if defined (:issue:`13977`)\n- Bug in ``pd.to_numeric`` when ``errors='coerce'`` and input contains non-hashable objects (:issue:`13324`)\n- Bug in invalid ``Timedelta`` arithmetic and comparison may raise ``ValueError`` rather than ``TypeError`` (:issue:`13624`)\n- Bug in invalid datetime parsing in ``to_datetime`` and ``DatetimeIndex`` may raise ``TypeError`` rather than ``ValueError`` (:issue:`11169`, :issue:`11287`)\n- Bug in ``Index`` created with tz-aware ``Timestamp`` and mismatched ``tz`` option incorrectly coerces timezone (:issue:`13692`)\n- Bug in ``DatetimeIndex`` with nanosecond frequency does not include timestamp specified with ``end`` (:issue:`13672`)\n- Bug in ``Series`` when setting a slice with a ``np.timedelta64`` (:issue:`14155`)\n- Bug in ``Index`` raises ``OutOfBoundsDatetime`` if ``datetime`` exceeds ``datetime64[ns]`` bounds, rather than coercing to ``object`` dtype (:issue:`13663`)\n- Bug in ``Index`` may ignore specified ``datetime64`` or ``timedelta64`` passed as ``dtype``  (:issue:`13981`)\n- Bug in ``RangeIndex`` can be created without no arguments rather than raises ``TypeError`` (:issue:`13793`)\n- Bug in ``.value_counts()`` raises ``OutOfBoundsDatetime`` if data exceeds ``datetime64[ns]`` bounds (:issue:`13663`)\n- Bug in ``DatetimeIndex`` may raise ``OutOfBoundsDatetime`` if input ``np.datetime64`` has other unit than ``ns`` (:issue:`9114`)\n- Bug in ``Series`` creation with ``np.datetime64`` which has other unit than ``ns`` as ``object`` dtype results in incorrect values (:issue:`13876`)\n- Bug in ``resample`` with timedelta data where data was casted to float (:issue:`13119`).\n- Bug in ``pd.isnull()`` ``pd.notnull()`` raise ``TypeError`` if input datetime-like has other unit than ``ns`` (:issue:`13389`)\n- Bug in ``pd.merge()`` may raise ``TypeError`` if input datetime-like has other unit than ``ns`` (:issue:`13389`)\n- Bug in ``HDFStore``/``read_hdf()`` discarded ``DatetimeIndex.name`` if ``tz`` was set (:issue:`13884`)\n- Bug in ``Categorical.remove_unused_categories()`` changes ``.codes`` dtype to platform int (:issue:`13261`)\n- Bug in ``groupby`` with ``as_index=False`` returns all NaN's when grouping on multiple columns including a categorical one (:issue:`13204`)\n- Bug in ``df.groupby(...)[...]`` where getitem with ``Int64Index`` raised an error (:issue:`13731`)\n- Bug in the CSS classes assigned to ``DataFrame.style`` for index names. Previously they were assigned ``\"col_heading level<n> col<c>\"`` where ``n`` was the number of levels + 1. Now they are assigned ``\"index_name level<n>\"``, where ``n`` is the correct level for that MultiIndex.\n- Bug where ``pd.read_gbq()`` could throw ``ImportError: No module named discovery`` as a result of a naming conflict with another python package called apiclient  (:issue:`13454`)\n- Bug in ``Index.union`` returns an incorrect result with a named empty index (:issue:`13432`)\n- Bugs in ``Index.difference`` and ``DataFrame.join`` raise in Python3 when using mixed-integer indexes (:issue:`13432`, :issue:`12814`)\n- Bug in subtract tz-aware ``datetime.datetime`` from tz-aware ``datetime64`` series (:issue:`14088`)\n- Bug in ``.to_excel()`` when DataFrame contains a MultiIndex which contains a label with a NaN value (:issue:`13511`)\n- Bug in invalid frequency offset string like \"D1\", \"-2-3H\" may not raise ``ValueError`` (:issue:`13930`)\n- Bug in ``concat`` and ``groupby`` for hierarchical frames with ``RangeIndex`` levels (:issue:`13542`).\n- Bug in ``Series.str.contains()`` for Series containing only ``NaN`` values of ``object`` dtype (:issue:`14171`)\n- Bug in ``agg()`` function on groupby dataframe changes dtype of ``datetime64[ns]`` column to ``float64`` (:issue:`12821`)\n- Bug in using NumPy ufunc with ``PeriodIndex`` to add or subtract integer raise ``IncompatibleFrequency``. Note that using standard operator like ``+`` or ``-`` is recommended, because standard operators use more efficient path (:issue:`13980`)\n- Bug in operations on ``NaT`` returning ``float`` instead of ``datetime64[ns]`` (:issue:`12941`)\n- Bug in ``Series`` flexible arithmetic methods (like ``.add()``) raises ``ValueError`` when ``axis=None`` (:issue:`13894`)\n- Bug in ``DataFrame.to_csv()`` with ``MultiIndex`` columns in which a stray empty line was added (:issue:`6618`)\n- Bug in ``DatetimeIndex``, ``TimedeltaIndex`` and ``PeriodIndex.equals()`` may return ``True`` when input isn't ``Index`` but contains the same values (:issue:`13107`)\n- Bug in assignment against datetime with timezone may not work if it contains datetime near DST boundary (:issue:`14146`)\n- Bug in ``pd.eval()`` and ``HDFStore`` query truncating long float literals with python 2 (:issue:`14241`)\n- Bug in ``Index`` raises ``KeyError`` displaying incorrect column when column is not in the df and columns contains duplicate values (:issue:`13822`)\n- Bug in ``Period`` and ``PeriodIndex`` creating wrong dates when frequency has combined offset aliases (:issue:`13874`)\n- Bug in ``.to_string()`` when called with an integer ``line_width`` and ``index=False`` raises an UnboundLocalError exception because ``idx`` referenced before assignment.\n- Bug in ``eval()`` where the ``resolvers`` argument would not accept a list (:issue:`14095`)\n- Bugs in ``stack``, ``get_dummies``, ``make_axis_dummies`` which don't preserve categorical dtypes in (multi)indexes (:issue:`13854`)\n- ``PeriodIndex`` can now accept ``list`` and ``array`` which contains ``pd.NaT`` (:issue:`13430`)\n- Bug in ``df.groupby`` where ``.median()`` returns arbitrary values if grouped dataframe contains empty bins (:issue:`13629`)\n- Bug in ``Index.copy()`` where ``name`` parameter was ignored (:issue:`14302`)\n\n\n.. _whatsnew_0.19.0.contributors:\n\nContributors\n~~~~~~~~~~~~\n\n.. contributors:: v0.18.1..v0.19.0\n\n\n.. _whatsnew_202:\n\nWhat's new in 2.0.2 (May 29, 2023)\n-----------------------------------\n\nThese are the changes in pandas 2.0.2. See :ref:`release` for a full changelog\nincluding other versions of pandas.\n\n{{ header }}\n\n.. ---------------------------------------------------------------------------\n.. _whatsnew_202.regressions:\n\nFixed regressions\n~~~~~~~~~~~~~~~~~\n- Fixed performance regression in :meth:`GroupBy.apply` (:issue:`53195`)\n- Fixed regression in :func:`merge` on Windows when dtype is ``np.intc`` (:issue:`52451`)\n- Fixed regression in :func:`read_sql` dropping columns with duplicated column names (:issue:`53117`)\n- Fixed regression in :meth:`DataFrame.loc` losing :class:`MultiIndex` name when enlarging object (:issue:`53053`)\n- Fixed regression in :meth:`DataFrame.to_string` printing a backslash at the end of the first row of data, instead of headers, when the DataFrame doesn't fit the line width (:issue:`53054`)\n- Fixed regression in :meth:`MultiIndex.join` returning levels in wrong order (:issue:`53093`)\n\n.. ---------------------------------------------------------------------------\n.. _whatsnew_202.bug_fixes:\n\nBug fixes\n~~~~~~~~~\n- Bug in :class:`.arrays.ArrowExtensionArray` incorrectly assigning ``dict`` instead of ``list`` for ``.type`` with ``pyarrow.map_`` and raising a ``NotImplementedError`` with ``pyarrow.struct`` (:issue:`53328`)\n- Bug in :func:`api.interchange.from_dataframe` was raising ``IndexError`` on empty categorical data (:issue:`53077`)\n- Bug in :func:`api.interchange.from_dataframe` was returning :class:`DataFrame`'s of incorrect sizes when called on slices (:issue:`52824`)\n- Bug in :func:`api.interchange.from_dataframe` was unnecessarily raising on bitmasks (:issue:`49888`)\n- Bug in :func:`merge` when merging on datetime columns on different resolutions (:issue:`53200`)\n- Bug in :func:`read_csv` raising ``OverflowError`` for ``engine=\"pyarrow\"`` and ``parse_dates`` set (:issue:`53295`)\n- Bug in :func:`to_datetime` was inferring format to contain ``\"%H\"`` instead of ``\"%I\"`` if date contained \"AM\" / \"PM\" tokens (:issue:`53147`)\n- Bug in :func:`to_timedelta` was raising ``ValueError`` with ``pandas.NA`` (:issue:`52909`)\n- Bug in :meth:`DataFrame.__getitem__` not preserving dtypes for :class:`MultiIndex` partial keys (:issue:`51895`)\n- Bug in :meth:`DataFrame.convert_dtypes` ignores ``convert_*`` keywords when set to False ``dtype_backend=\"pyarrow\"`` (:issue:`52872`)\n- Bug in :meth:`DataFrame.convert_dtypes` losing timezone for tz-aware dtypes and ``dtype_backend=\"pyarrow\"`` (:issue:`53382`)\n- Bug in :meth:`DataFrame.sort_values` raising for PyArrow ``dictionary`` dtype (:issue:`53232`)\n- Bug in :meth:`Series.describe` treating pyarrow-backed timestamps and timedeltas as categorical data (:issue:`53001`)\n- Bug in :meth:`Series.rename` not making a lazy copy when Copy-on-Write is enabled when a scalar is passed to it (:issue:`52450`)\n- Bug in :meth:`pd.array` raising for ``NumPy`` array and ``pa.large_string`` or ``pa.large_binary`` (:issue:`52590`)\n\n.. ---------------------------------------------------------------------------\n.. _whatsnew_202.other:\n\nOther\n~~~~~\n- Raised a better error message when calling :func:`Series.dt.to_pydatetime` with :class:`ArrowDtype` with ``pyarrow.date32`` or ``pyarrow.date64`` type (:issue:`52812`)\n\n.. ---------------------------------------------------------------------------\n.. _whatsnew_202.contributors:\n\nContributors\n~~~~~~~~~~~~\n\n.. contributors:: v2.0.1..v2.0.2\n\n\n.. _whatsnew_124:\n\nWhat's new in 1.2.4 (April 12, 2021)\n------------------------------------\n\nThese are the changes in pandas 1.2.4. See :ref:`release` for a full changelog\nincluding other versions of pandas.\n\n{{ header }}\n\n.. ---------------------------------------------------------------------------\n\n.. _whatsnew_124.regressions:\n\nFixed regressions\n~~~~~~~~~~~~~~~~~\n\n- Fixed regression in :meth:`DataFrame.sum` when ``min_count`` greater than the :class:`DataFrame` shape was passed resulted in a ``ValueError`` (:issue:`39738`)\n- Fixed regression in :meth:`DataFrame.to_json` raising ``AttributeError`` when run on PyPy (:issue:`39837`)\n- Fixed regression in (in)equality comparison of ``pd.NaT`` with a non-datetimelike numpy array returning a scalar instead of an array (:issue:`40722`)\n- Fixed regression in :meth:`DataFrame.where` not returning a copy in the case of an all True condition (:issue:`39595`)\n- Fixed regression in :meth:`DataFrame.replace` raising ``IndexError`` when ``regex`` was a multi-key dictionary (:issue:`39338`)\n- Fixed regression in repr of floats in an ``object`` column not respecting ``float_format`` when printed in the console or outputted through :meth:`DataFrame.to_string`, :meth:`DataFrame.to_html`, and :meth:`DataFrame.to_latex` (:issue:`40024`)\n- Fixed regression in NumPy ufuncs such as ``np.add`` not passing through all arguments for :class:`DataFrame` (:issue:`40662`)\n\n.. ---------------------------------------------------------------------------\n\n.. _whatsnew_124.contributors:\n\nContributors\n~~~~~~~~~~~~\n\n.. contributors:: v1.2.3..v1.2.4\n\n\n\n.. _whatsnew_104:\n\nWhat's new in 1.0.4 (May 28, 2020)\n------------------------------------\n\nThese are the changes in pandas 1.0.4. See :ref:`release` for a full changelog\nincluding other versions of pandas.\n\n{{ header }}\n\n.. ---------------------------------------------------------------------------\n\n.. _whatsnew_104.regressions:\n\nFixed regressions\n~~~~~~~~~~~~~~~~~\n- Fix regression where :meth:`Series.isna` and :meth:`DataFrame.isna` would raise for categorical dtype when ``pandas.options.mode.use_inf_as_na`` was set to ``True`` (:issue:`33594`)\n- Fix regression in :meth:`.DataFrameGroupBy.first`, :meth:`.SeriesGroupBy.first`, :meth:`.DataFrameGroupBy.last`, and :meth:`.SeriesGroupBy.last` where None is not preserved in object dtype (:issue:`32800`)\n- Fix regression in DataFrame reductions using ``numeric_only=True`` and ExtensionArrays (:issue:`33256`).\n- Fix performance regression in ``memory_usage(deep=True)`` for object dtype (:issue:`33012`)\n- Fix regression where :meth:`Categorical.replace` would replace with ``NaN`` whenever the new value and replacement value were equal (:issue:`33288`)\n- Fix regression where an ordered :class:`Categorical` containing only ``NaN`` values would raise rather than returning ``NaN`` when taking the minimum or maximum  (:issue:`33450`)\n- Fix regression in :meth:`DataFrameGroupBy.agg` with dictionary input losing ``ExtensionArray`` dtypes (:issue:`32194`)\n- Fix to preserve the ability to index with the \"nearest\" method with xarray's CFTimeIndex, an :class:`Index` subclass (`pydata/xarray3751 <https://github.com/pydata/xarray/issues/3751>`_, :issue:`32905`).\n- Fix regression in :meth:`DataFrame.describe` raising ``TypeError: unhashable type: 'dict'`` (:issue:`32409`)\n- Fix regression in :meth:`DataFrame.replace` casts columns to ``object`` dtype if items in ``to_replace`` not in values (:issue:`32988`)\n- Fix regression in :meth:`Series.groupby` would raise ``ValueError`` when grouping by :class:`PeriodIndex` level (:issue:`34010`)\n- Fix regression in :meth:`DataFrameGroupBy.rolling.apply` and :meth:`SeriesGroupBy.rolling.apply` ignoring args and kwargs parameters (:issue:`33433`)\n- Fix regression in error message with ``np.min`` or ``np.max`` on unordered :class:`Categorical` (:issue:`33115`)\n- Fix regression in :meth:`DataFrame.loc` and :meth:`Series.loc` throwing an error when a ``datetime64[ns, tz]`` value is provided (:issue:`32395`)\n\n.. _whatsnew_104.bug_fixes:\n\nBug fixes\n~~~~~~~~~\n- Bug in :meth:`SeriesGroupBy.first`, :meth:`SeriesGroupBy.last`, :meth:`SeriesGroupBy.min`, and :meth:`SeriesGroupBy.max` returning floats when applied to nullable Booleans (:issue:`33071`)\n- Bug in :meth:`Rolling.min` and :meth:`Rolling.max`: Growing memory usage after multiple calls when using a fixed window (:issue:`30726`)\n- Bug in :meth:`~DataFrame.to_parquet` was not raising ``PermissionError`` when writing to a private s3 bucket with invalid creds. (:issue:`27679`)\n- Bug in :meth:`~DataFrame.to_csv` was silently failing when writing to an invalid s3 bucket. (:issue:`32486`)\n- Bug in :meth:`read_parquet` was raising a ``FileNotFoundError`` when passed an s3 directory path. (:issue:`26388`)\n- Bug in :meth:`~DataFrame.to_parquet` was throwing an ``AttributeError`` when writing a partitioned parquet file to s3 (:issue:`27596`)\n- Bug in :meth:`.DataFrameGroupBy.quantile` and :meth:`.SeriesGroupBy.quantile` causes the quantiles to be shifted when the ``by`` axis contains ``NaN`` (:issue:`33200`, :issue:`33569`)\n\nContributors\n~~~~~~~~~~~~\n\n.. contributors:: v1.0.3..v1.0.4\n\n\n.. _whatsnew_201:\n\nWhat's new in 2.0.1 (April 24, 2023)\n------------------------------------\n\nThese are the changes in pandas 2.0.1. See :ref:`release` for a full changelog\nincluding other versions of pandas.\n\n{{ header }}\n\n.. ---------------------------------------------------------------------------\n.. _whatsnew_201.regressions:\n\nFixed regressions\n~~~~~~~~~~~~~~~~~\n- Fixed regression for subclassed Series when constructing from a dictionary (:issue:`52445`)\n- Fixed regression in :meth:`.SeriesGroupBy.agg` failing when grouping with categorical data, multiple groupings, ``as_index=False``, and a list of aggregations (:issue:`52760`)\n- Fixed regression in :meth:`DataFrame.pivot` changing :class:`Index` name of input object (:issue:`52629`)\n- Fixed regression in :meth:`DataFrame.resample` raising on a DataFrame with no columns (:issue:`52484`)\n- Fixed regression in :meth:`DataFrame.sort_values` not resetting index when :class:`DataFrame` is already sorted and ``ignore_index=True`` (:issue:`52553`)\n- Fixed regression in :meth:`MultiIndex.isin` raising ``TypeError`` for ``Generator`` (:issue:`52568`)\n- Fixed regression in :meth:`Series.describe` showing ``RuntimeWarning`` for extension dtype :class:`Series` with one element (:issue:`52515`)\n- Fixed regression when adding a new column to a :class:`DataFrame` when the :attr:`DataFrame.columns` was a :class:`RangeIndex` and the new key was hashable but not a scalar (:issue:`52652`)\n\n.. ---------------------------------------------------------------------------\n.. _whatsnew_201.bug_fixes:\n\nBug fixes\n~~~~~~~~~\n- Bug in :attr:`Series.dt.days` that would overflow ``int32`` number of days (:issue:`52391`)\n- Bug in :class:`arrays.DatetimeArray` constructor returning an incorrect unit when passed a non-nanosecond numpy datetime array (:issue:`52555`)\n- Bug in :class:`~arrays.ArrowExtensionArray` with duration dtype overflowing when constructed from data containing numpy ``NaT`` (:issue:`52843`)\n- Bug in :func:`Series.dt.round` when passing a ``freq`` of equal or higher resolution compared to the :class:`Series` would raise a ``ZeroDivisionError`` (:issue:`52761`)\n- Bug in :func:`Series.median` with :class:`ArrowDtype` returning an approximate median (:issue:`52679`)\n- Bug in :func:`api.interchange.from_dataframe` was unnecessarily raising on categorical dtypes (:issue:`49889`)\n- Bug in :func:`api.interchange.from_dataframe` was unnecessarily raising on large string dtypes (:issue:`52795`)\n- Bug in :func:`pandas.testing.assert_series_equal` where ``check_dtype=False`` would still raise for datetime or timedelta types with different resolutions (:issue:`52449`)\n- Bug in :func:`read_csv` casting PyArrow datetimes to NumPy when ``dtype_backend=\"pyarrow\"`` and ``parse_dates`` is set causing a performance bottleneck in the process (:issue:`52546`)\n- Bug in :func:`to_datetime` and :func:`to_timedelta` when trying to convert numeric data with a :class:`ArrowDtype` (:issue:`52425`)\n- Bug in :func:`to_numeric` with ``errors='coerce'`` and ``dtype_backend='pyarrow'`` with :class:`ArrowDtype` data (:issue:`52588`)\n- Bug in :meth:`ArrowDtype.__from_arrow__` not respecting if dtype is explicitly given (:issue:`52533`)\n- Bug in :meth:`DataFrame.describe` not respecting ``ArrowDtype`` in ``include`` and ``exclude`` (:issue:`52570`)\n- Bug in :meth:`DataFrame.max` and related casting different :class:`Timestamp` resolutions always to nanoseconds (:issue:`52524`)\n- Bug in :meth:`Series.describe` not returning :class:`ArrowDtype` with ``pyarrow.float64`` type with numeric data (:issue:`52427`)\n- Bug in :meth:`Series.dt.tz_localize` incorrectly localizing timestamps with :class:`ArrowDtype` (:issue:`52677`)\n- Bug in arithmetic between ``np.datetime64`` and ``np.timedelta64`` ``NaT`` scalars with units always returning nanosecond resolution (:issue:`52295`)\n- Bug in logical and comparison operations between :class:`ArrowDtype` and numpy masked types (e.g. ``\"boolean\"``) (:issue:`52625`)\n- Fixed bug in :func:`merge` when merging with ``ArrowDtype`` one one and a NumPy dtype on the other side (:issue:`52406`)\n- Fixed segfault in :meth:`Series.to_numpy` with ``null[pyarrow]`` dtype (:issue:`52443`)\n\n.. ---------------------------------------------------------------------------\n.. _whatsnew_201.other:\n\nOther\n~~~~~\n- :class:`DataFrame` created from empty dicts had :attr:`~DataFrame.columns`  of dtype ``object``. It is now a :class:`RangeIndex` (:issue:`52404`)\n- :class:`Series` created from empty dicts had :attr:`~Series.index`  of dtype ``object``. It is now a :class:`RangeIndex` (:issue:`52404`)\n- Implemented :meth:`Series.str.split` and :meth:`Series.str.rsplit` for :class:`ArrowDtype` with ``pyarrow.string`` (:issue:`52401`)\n- Implemented most ``str`` accessor methods for :class:`ArrowDtype` with ``pyarrow.string`` (:issue:`52401`)\n- Supplying a non-integer hashable key that tests ``False`` in :func:`api.types.is_scalar` now raises a ``KeyError`` for :meth:`RangeIndex.get_loc`, like it does for :meth:`Index.get_loc`. Previously it raised an ``InvalidIndexError`` (:issue:`52652`).\n\n.. ---------------------------------------------------------------------------\n.. _whatsnew_201.contributors:\n\nContributors\n~~~~~~~~~~~~\n\n.. contributors:: v2.0.0..v2.0.1\n\n\n.. _whatsnew_123:\n\nWhat's new in 1.2.3 (March 02, 2021)\n------------------------------------\n\nThese are the changes in pandas 1.2.3. See :ref:`release` for a full changelog\nincluding other versions of pandas.\n\n{{ header }}\n\n.. ---------------------------------------------------------------------------\n\n.. _whatsnew_123.regressions:\n\nFixed regressions\n~~~~~~~~~~~~~~~~~\n\n- Fixed regression in :meth:`~DataFrame.to_excel` raising ``KeyError`` when giving duplicate columns with ``columns`` attribute (:issue:`39695`)\n- Fixed regression in nullable integer unary ops propagating mask on assignment (:issue:`39943`)\n- Fixed regression in :meth:`DataFrame.__setitem__` not aligning :class:`DataFrame` on right-hand side for boolean indexer (:issue:`39931`)\n- Fixed regression in :meth:`~DataFrame.to_json` failing to use ``compression`` with URL-like paths that are internally opened in binary mode or with user-provided file objects that are opened in binary mode (:issue:`39985`)\n- Fixed regression in :meth:`Series.sort_index` and :meth:`DataFrame.sort_index`, which exited with an ungraceful error when having kwarg ``ascending=None`` passed. Passing ``ascending=None`` is still considered invalid, and the improved error message suggests a proper usage (``ascending`` must be a boolean or a list-like of boolean) (:issue:`39434`)\n- Fixed regression in :meth:`DataFrame.transform` and :meth:`Series.transform` giving incorrect column labels when passed a dictionary with a mix of list and non-list values (:issue:`40018`)\n\n.. ---------------------------------------------------------------------------\n\n.. _whatsnew_123.contributors:\n\nContributors\n~~~~~~~~~~~~\n\n.. contributors:: v1.2.2..v1.2.3\n\n\n.. _whatsnew_0241:\n\nWhat's new in 0.24.1 (February 3, 2019)\n---------------------------------------\n\n.. warning::\n\n   The 0.24.x series of releases will be the last to support Python 2. Future feature\n   releases will support Python 3 only. See `Dropping Python 2.7 <https://pandas.pydata.org/pandas-docs/version/0.24/install.html#install-dropping-27>`_ for more.\n\n{{ header }}\n\nThese are the changes in pandas 0.24.1. See :ref:`release` for a full changelog\nincluding other versions of pandas. See :ref:`whatsnew_0240` for the 0.24.0 changelog.\n\n.. _whatsnew_0241.api:\n\nAPI changes\n~~~~~~~~~~~\n\nChanging the ``sort`` parameter for :class:`Index` set operations\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nThe default ``sort`` value for :meth:`Index.union` has changed from ``True`` to ``None`` (:issue:`24959`).\nThe default *behavior*, however, remains the same: the result is sorted, unless\n\n1. ``self`` and ``other`` are identical\n2. ``self`` or ``other`` is empty\n3. ``self`` or ``other`` contain values that can not be compared (a ``RuntimeWarning`` is raised).\n\nThis change will allow ``sort=True`` to mean \"always sort\" in a future release.\n\nThe same change applies to :meth:`Index.difference` and :meth:`Index.symmetric_difference`, which\nwould not sort the result when the values could not be compared.\n\nThe ``sort`` option for :meth:`Index.intersection` has changed in three ways.\n\n1. The default has changed from ``True`` to ``False``, to restore the\n   pandas 0.23.4 and earlier behavior of not sorting by default.\n2. The behavior of ``sort=True`` can now be obtained with ``sort=None``.\n   This will sort the result only if the values in ``self`` and ``other``\n   are not identical.\n3. The value ``sort=True`` is no longer allowed. A future version of pandas\n   will properly support ``sort=True`` meaning \"always sort\".\n\n.. _whatsnew_0241.regressions:\n\nFixed regressions\n~~~~~~~~~~~~~~~~~\n\n- Fixed regression in :meth:`DataFrame.to_dict` with ``records`` orient raising an\n  ``AttributeError`` when the ``DataFrame`` contained more than 255 columns, or\n  wrongly converting column names that were not valid python identifiers (:issue:`24939`, :issue:`24940`).\n- Fixed regression in :func:`read_sql` when passing certain queries with MySQL/pymysql (:issue:`24988`).\n- Fixed regression in :class:`Index.intersection` incorrectly sorting the values by default (:issue:`24959`).\n- Fixed regression in :func:`merge` when merging an empty ``DataFrame`` with multiple timezone-aware columns on one of the timezone-aware columns (:issue:`25014`).\n- Fixed regression in :meth:`Series.rename_axis` and :meth:`DataFrame.rename_axis` where passing ``None`` failed to remove the axis name (:issue:`25034`)\n- Fixed regression in :func:`to_timedelta` with ``box=False`` incorrectly returning a ``datetime64`` object instead of a ``timedelta64`` object (:issue:`24961`)\n- Fixed regression where custom hashable types could not be used as column keys in :meth:`DataFrame.set_index` (:issue:`24969`)\n\n.. _whatsnew_0241.bug_fixes:\n\nBug fixes\n~~~~~~~~~\n\n**Reshaping**\n\n- Bug in :meth:`DataFrame.groupby` with :class:`Grouper` when there is a time change (DST) and grouping frequency is ``'1d'`` (:issue:`24972`)\n\n**Visualization**\n\n- Fixed the warning for implicitly registered matplotlib converters not showing. See :ref:`whatsnew_0211.converters` for more (:issue:`24963`).\n\n**Other**\n\n- Fixed AttributeError when printing a DataFrame's HTML repr after accessing the IPython config object (:issue:`25036`)\n\n.. _whatsnew_0.241.contributors:\n\nContributors\n~~~~~~~~~~~~\n\n.. Including the contributors hardcoded for this release, as backporting with\n   MeeseeksDev loses the commit authors\n\nA total of 7 people contributed patches to this release. People with a \"+\" by their names contributed a patch for the first time.\n\n* Alex Buchkovsky\n* Roman Yurchak\n* h-vetinari\n* jbrockmendel\n* Jeremy Schendel\n* Joris Van den Bossche\n* Tom Augspurger\n\n\n.. _whatsnew_135:\n\nWhat's new in 1.3.5 (December 12, 2021)\n---------------------------------------\n\nThese are the changes in pandas 1.3.5. See :ref:`release` for a full changelog\nincluding other versions of pandas.\n\n{{ header }}\n\n.. ---------------------------------------------------------------------------\n\n.. _whatsnew_135.regressions:\n\nFixed regressions\n~~~~~~~~~~~~~~~~~\n- Fixed regression in :meth:`Series.equals` when comparing floats with dtype object to None (:issue:`44190`)\n- Fixed regression in :func:`merge_asof` raising error when array was supplied as join key (:issue:`42844`)\n- Fixed regression when resampling :class:`DataFrame` with :class:`DateTimeIndex` with empty groups and ``uint8``, ``uint16`` or ``uint32`` columns incorrectly raising ``RuntimeError`` (:issue:`43329`)\n- Fixed regression in creating a :class:`DataFrame` from a timezone-aware :class:`Timestamp` scalar near a Daylight Savings Time transition (:issue:`42505`)\n- Fixed performance regression in :func:`read_csv` (:issue:`44106`)\n- Fixed regression in :meth:`Series.duplicated` and :meth:`Series.drop_duplicates` when Series has :class:`Categorical` dtype with boolean categories (:issue:`44351`)\n- Fixed regression in :meth:`.DataFrameGroupBy.sum` and :meth:`.SeriesGroupBy.sum` with ``timedelta64[ns]`` dtype containing ``NaT`` failing to treat that value as NA (:issue:`42659`)\n- Fixed regression in :meth:`.RollingGroupby.cov` and :meth:`.RollingGroupby.corr` when ``other`` had the same shape as each group would incorrectly return superfluous groups in the result (:issue:`42915`)\n\n\n.. ---------------------------------------------------------------------------\n\n.. _whatsnew_135.contributors:\n\nContributors\n~~~~~~~~~~~~\n\n.. contributors:: v1.3.4..v1.3.5|HEAD\n\n\n.. _whatsnew_141:\n\nWhat's new in 1.4.1 (February 12, 2022)\n---------------------------------------\n\nThese are the changes in pandas 1.4.1. See :ref:`release` for a full changelog\nincluding other versions of pandas.\n\n{{ header }}\n\n.. ---------------------------------------------------------------------------\n\n.. _whatsnew_141.regressions:\n\nFixed regressions\n~~~~~~~~~~~~~~~~~\n- Regression in :meth:`Series.mask` with ``inplace=True`` and ``PeriodDtype`` and an incompatible ``other`` coercing to a common dtype instead of raising (:issue:`45546`)\n- Regression in :func:`.assert_frame_equal` not respecting ``check_flags=False`` (:issue:`45554`)\n- Regression in :meth:`DataFrame.loc` raising ``ValueError`` when indexing (getting values) on a :class:`MultiIndex` with one level (:issue:`45779`)\n- Regression in :meth:`Series.fillna` with ``downcast=False`` incorrectly downcasting ``object`` dtype (:issue:`45603`)\n- Regression in :func:`api.types.is_bool_dtype` raising an ``AttributeError`` when evaluating a categorical :class:`Series` (:issue:`45615`)\n- Regression in :meth:`DataFrame.iat` setting values leading to not propagating correctly in subsequent lookups (:issue:`45684`)\n- Regression when setting values with :meth:`DataFrame.loc` losing :class:`Index` name if :class:`DataFrame` was empty before (:issue:`45621`)\n- Regression in :meth:`~Index.join` with overlapping :class:`IntervalIndex` raising an ``InvalidIndexError`` (:issue:`45661`)\n- Regression when setting values with :meth:`Series.loc` raising with all ``False`` indexer and :class:`Series` on the right hand side (:issue:`45778`)\n- Regression in :func:`read_sql` with a DBAPI2 connection that is not an instance of ``sqlite3.Connection`` incorrectly requiring SQLAlchemy be installed (:issue:`45660`)\n- Regression in :class:`DateOffset` when constructing with an integer argument with no keywords (e.g. ``pd.DateOffset(n)``) would behave like ``datetime.timedelta(days=0)`` (:issue:`45643`, :issue:`45890`)\n\n.. ---------------------------------------------------------------------------\n\n.. _whatsnew_141.bug_fixes:\n\nBug fixes\n~~~~~~~~~\n- Fixed segfault in :meth:`DataFrame.to_json` when dumping tz-aware datetimes in Python 3.10 (:issue:`42130`)\n- Stopped emitting unnecessary ``FutureWarning`` in :meth:`DataFrame.sort_values` with sparse columns (:issue:`45618`)\n- Fixed window aggregations in :meth:`DataFrame.rolling` and :meth:`Series.rolling` to skip over unused elements (:issue:`45647`)\n- Fixed builtin highlighters in :class:`.Styler` to be responsive to ``NA`` with nullable dtypes (:issue:`45804`)\n- Bug in :meth:`~Rolling.apply` with ``axis=1`` raising an erroneous ``ValueError`` (:issue:`45912`)\n\n.. ---------------------------------------------------------------------------\n\n.. _whatsnew_141.other:\n\nOther\n~~~~~\n- Reverted performance speedup of :meth:`DataFrame.corr` for ``method=pearson`` to fix precision regression (:issue:`45640`, :issue:`42761`)\n\n.. ---------------------------------------------------------------------------\n\n.. _whatsnew_141.contributors:\n\nContributors\n~~~~~~~~~~~~\n\n.. contributors:: v1.4.0..v1.4.1\n\n\n.. _whatsnew_0130:\n\nVersion 0.13.0 (January 3, 2014)\n--------------------------------\n\n{{ header }}\n\n\n\nThis is a major release from 0.12.0 and includes a number of API changes, several new features and\nenhancements along with a large number of bug fixes.\n\nHighlights include:\n\n- support for a new index type ``Float64Index``, and other Indexing enhancements\n- ``HDFStore`` has a new string based syntax for query specification\n- support for new methods of interpolation\n- updated ``timedelta`` operations\n- a new string manipulation method ``extract``\n- Nanosecond support for Offsets\n- ``isin`` for DataFrames\n\nSeveral experimental features are added, including:\n\n- new ``eval/query`` methods for expression evaluation\n- support for ``msgpack`` serialization\n- an i/o interface to Google's ``BigQuery``\n\nTheir are several new or updated docs sections including:\n\n- :ref:`Comparison with SQL<compare_with_sql>`, which should be useful for those familiar with SQL but still learning pandas.\n- :ref:`Comparison with R<compare_with_r>`, idiom translations from R to pandas.\n- :ref:`Enhancing Performance<enhancingperf>`, ways to enhance pandas performance with ``eval/query``.\n\n.. warning::\n\n   In 0.13.0 ``Series`` has internally been refactored to no longer sub-class ``ndarray``\n   but instead subclass ``NDFrame``, similar to the rest of the pandas containers. This should be\n   a transparent change with only very limited API implications. See :ref:`Internal Refactoring<whatsnew_0130.refactoring>`\n\nAPI changes\n~~~~~~~~~~~\n\n- ``read_excel`` now supports an integer in its ``sheetname`` argument giving\n  the index of the sheet to read in (:issue:`4301`).\n- Text parser now treats anything that reads like inf (\"inf\", \"Inf\", \"-Inf\",\n  \"iNf\", etc.) as infinity. (:issue:`4220`, :issue:`4219`), affecting\n  ``read_table``, ``read_csv``, etc.\n- ``pandas`` now is Python 2/3 compatible without the need for 2to3 thanks to\n  jtratner. As a result, pandas now uses iterators more extensively. This\n  also led to the introduction of substantive parts of the Benjamin\n  Peterson's ``six`` library into compat. (:issue:`4384`, :issue:`4375`,\n  :issue:`4372`)\n- ``pandas.util.compat`` and ``pandas.util.py3compat`` have been merged into\n  ``pandas.compat``. ``pandas.compat`` now includes many functions allowing\n  2/3 compatibility. It contains both list and iterator versions of range,\n  filter, map and zip, plus other necessary elements for Python 3\n  compatibility. ``lmap``, ``lzip``, ``lrange`` and ``lfilter`` all produce\n  lists instead of iterators, for compatibility with ``numpy``, subscripting\n  and ``pandas`` constructors.(:issue:`4384`, :issue:`4375`, :issue:`4372`)\n- ``Series.get`` with negative indexers now returns the same as ``[]`` (:issue:`4390`)\n- Changes to how ``Index`` and ``MultiIndex`` handle metadata (``levels``,\n  ``labels``, and ``names``) (:issue:`4039`):\n\n  .. code-block:: python\n\n      previously, you would have set levels or labels directly\n     >>> pd.index.levels = [[1, 2, 3, 4], [1, 2, 4, 4]]\n\n      now, you use the set_levels or set_labels methods\n     >>> index = pd.index.set_levels([[1, 2, 3, 4], [1, 2, 4, 4]])\n\n      similarly, for names, you can rename the object\n      but setting names is not deprecated\n     >>> index = pd.index.set_names([\"bob\", \"cranberry\"])\n\n      and all methods take an inplace kwarg - but return None\n     >>> pd.index.set_names([\"bob\", \"cranberry\"], inplace=True)\n\n- **All** division with ``NDFrame`` objects is now *truedivision*, regardless\n  of the future import. This means that operating on pandas objects will by default\n  use *floating point* division, and return a floating point dtype.\n  You can use ``//`` and ``floordiv`` to do integer division.\n\n  Integer division\n\n  .. code-block:: ipython\n\n     In [3]: arr = np.array([1, 2, 3, 4])\n\n     In [4]: arr2 = np.array([5, 3, 2, 1])\n\n     In [5]: arr / arr2\n     Out[5]: array([0, 0, 1, 4])\n\n     In [6]: pd.Series(arr) // pd.Series(arr2)\n     Out[6]:\n     0    0\n     1    0\n     2    1\n     3    4\n     dtype: int64\n\n  True Division\n\n  .. code-block:: ipython\n\n      In [7]: pd.Series(arr) / pd.Series(arr2)   no future import required\n      Out[7]:\n      0    0.200000\n      1    0.666667\n      2    1.500000\n      3    4.000000\n      dtype: float64\n\n- Infer and downcast dtype if ``downcast='infer'`` is passed to ``fillna/ffill/bfill`` (:issue:`4604`)\n- ``__nonzero__`` for all NDFrame objects, will now raise a ``ValueError``, this reverts back to (:issue:`1073`, :issue:`4633`)\n  behavior. See :ref:`gotchas<gotchas.truth>` for a more detailed discussion.\n\n  This prevents doing boolean comparison on *entire* pandas objects, which is inherently ambiguous. These all will raise a ``ValueError``.\n\n  .. code-block:: python\n\n     >>> df = pd.DataFrame({'A': np.random.randn(10),\n     ...                    'B': np.random.randn(10),\n     ...                    'C': pd.date_range('20130101', periods=10)\n     ...                    })\n     ...\n     >>> if df:\n     ...     pass\n     ...\n     Traceback (most recent call last):\n         ...\n     ValueError: The truth value of a DataFrame is ambiguous.  Use a.empty,\n     a.bool(), a.item(), a.any() or a.all().\n\n     >>> df1 = df\n     >>> df2 = df\n     >>> df1 and df2\n     Traceback (most recent call last):\n         ...\n     ValueError: The truth value of a DataFrame is ambiguous.  Use a.empty,\n     a.bool(), a.item(), a.any() or a.all().\n\n     >>> d = [1, 2, 3]\n     >>> s1 = pd.Series(d)\n     >>> s2 = pd.Series(d)\n     >>> s1 and s2\n     Traceback (most recent call last):\n         ...\n     ValueError: The truth value of a DataFrame is ambiguous.  Use a.empty,\n     a.bool(), a.item(), a.any() or a.all().\n\n  Added the ``.bool()`` method to ``NDFrame`` objects to facilitate evaluating of single-element boolean Series:\n\n  .. code-block:: python\n\n     >>> pd.Series([True]).bool()\n      True\n     >>> pd.Series([False]).bool()\n      False\n     >>> pd.DataFrame([[True]]).bool()\n      True\n     >>> pd.DataFrame([[False]]).bool()\n      False\n\n- All non-Index NDFrames (``Series``, ``DataFrame``, ``Panel``, ``Panel4D``,\n  ``SparsePanel``, etc.), now support the entire set of arithmetic operators\n  and arithmetic flex methods (add, sub, mul, etc.). ``SparsePanel`` does not\n  support ``pow`` or ``mod`` with non-scalars. (:issue:`3765`)\n- ``Series`` and ``DataFrame`` now have a ``mode()`` method to calculate the\n  statistical mode(s) by axis/Series. (:issue:`5367`)\n\n- Chained assignment will now by default warn if the user is assigning to a copy. This can be changed\n  with the option ``mode.chained_assignment``, allowed options are ``raise/warn/None``. See :ref:`the docs<indexing.view_versus_copy>`.\n\n  .. ipython:: python\n\n     dfc = pd.DataFrame({'A': ['aaa', 'bbb', 'ccc'], 'B': [1, 2, 3]})\n     pd.set_option('chained_assignment', 'warn')\n\n  The following warning / exception will show if this is attempted.\n\n  .. ipython:: python\n     :okwarning:\n\n     dfc.loc[0]['A'] = 1111\n\n  ::\n\n     Traceback (most recent call last)\n        ...\n     SettingWithCopyWarning:\n        A value is trying to be set on a copy of a slice from a DataFrame.\n        Try using .loc[row_index,col_indexer] = value instead\n\n  Here is the correct method of assignment.\n\n  .. ipython:: python\n\n     dfc.loc[0, 'A'] = 11\n     dfc\n\n- ``Panel.reindex`` has the following call signature ``Panel.reindex(items=None, major_axis=None, minor_axis=None, **kwargs)``\n   to conform with other ``NDFrame`` objects. See :ref:`Internal Refactoring<whatsnew_0130.refactoring>` for more information.\n\n- ``Series.argmin`` and ``Series.argmax`` are now aliased to ``Series.idxmin`` and ``Series.idxmax``. These return the *index* of the\n   min or max element respectively. Prior to 0.13.0 these would return the position of the min / max element. (:issue:`6214`)\n\nPrior version deprecations/changes\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\nThese were announced changes in 0.12 or prior that are taking effect as of 0.13.0\n\n- Remove deprecated ``Factor`` (:issue:`3650`)\n- Remove deprecated ``set_printoptions/reset_printoptions`` (:issue:`3046`)\n- Remove deprecated ``_verbose_info`` (:issue:`3215`)\n- Remove deprecated ``read_clipboard/to_clipboard/ExcelFile/ExcelWriter`` from ``pandas.io.parsers`` (:issue:`3717`)\n  These are available as functions in the main pandas namespace (e.g. ``pd.read_clipboard``)\n- default for ``tupleize_cols`` is now ``False`` for both ``to_csv`` and ``read_csv``. Fair warning in 0.12 (:issue:`3604`)\n- default for ``display.max_seq_len`` is now 100 rather than ``None``. This activates\n  truncated display (\"...\") of long sequences in various places. (:issue:`3391`)\n\nDeprecations\n~~~~~~~~~~~~\n\nDeprecated in 0.13.0\n\n- deprecated ``iterkv``, which will be removed in a future release (this was\n  an alias of iteritems used to bypass ``2to3``'s changes).\n  (:issue:`4384`, :issue:`4375`, :issue:`4372`)\n- deprecated the string method ``match``, whose role is now performed more\n  idiomatically by ``extract``. In a future release, the default behavior\n  of ``match`` will change to become analogous to ``contains``, which returns\n  a boolean indexer. (Their\n  distinction is strictness: ``match`` relies on ``re.match`` while\n  ``contains`` relies on ``re.search``.) In this release, the deprecated\n  behavior is the default, but the new behavior is available through the\n  keyword argument ``as_indexer=True``.\n\nIndexing API changes\n~~~~~~~~~~~~~~~~~~~~\n\nPrior to 0.13, it was impossible to use a label indexer (``.loc/.ix``) to set a value that\nwas not contained in the index of a particular axis. (:issue:`2578`). See :ref:`the docs<indexing.basics.partial_setting>`\n\nIn the ``Series`` case this is effectively an appending operation\n\n.. ipython:: python\n\n   s = pd.Series([1, 2, 3])\n   s\n   s[5] = 5.\n   s\n\n.. ipython:: python\n\n   dfi = pd.DataFrame(np.arange(6).reshape(3, 2),\n                      columns=['A', 'B'])\n   dfi\n\nThis would previously ``KeyError``\n\n.. ipython:: python\n\n   dfi.loc[:, 'C'] = dfi.loc[:, 'A']\n   dfi\n\nThis is like an ``append`` operation.\n\n.. ipython:: python\n\n   dfi.loc[3] = 5\n   dfi\n\nA Panel setting operation on an arbitrary axis aligns the input to the Panel\n\n.. code-block:: ipython\n\n   In [20]: p = pd.Panel(np.arange(16).reshape(2, 4, 2),\n      ....:              items=['Item1', 'Item2'],\n      ....:              major_axis=pd.date_range('2001/1/12', periods=4),\n      ....:              minor_axis=['A', 'B'], dtype='float64')\n      ....:\n\n   In [21]: p\n   Out[21]:\n   <class 'pandas.core.panel.Panel'>\n   Dimensions: 2 (items) x 4 (major_axis) x 2 (minor_axis)\n   Items axis: Item1 to Item2\n   Major_axis axis: 2001-01-12 00:00:00 to 2001-01-15 00:00:00\n   Minor_axis axis: A to B\n\n   In [22]: p.loc[:, :, 'C'] = pd.Series([30, 32], index=p.items)\n\n   In [23]: p\n   Out[23]:\n   <class 'pandas.core.panel.Panel'>\n   Dimensions: 2 (items) x 4 (major_axis) x 3 (minor_axis)\n   Items axis: Item1 to Item2\n   Major_axis axis: 2001-01-12 00:00:00 to 2001-01-15 00:00:00\n   Minor_axis axis: A to C\n\n   In [24]: p.loc[:, :, 'C']\n   Out[24]:\n               Item1  Item2\n   2001-01-12   30.0   32.0\n   2001-01-13   30.0   32.0\n   2001-01-14   30.0   32.0\n   2001-01-15   30.0   32.0\n\nFloat64Index API change\n~~~~~~~~~~~~~~~~~~~~~~~\n\n- Added a new index type, ``Float64Index``. This will be automatically created when passing floating values in index creation.\n  This enables a pure label-based slicing paradigm that makes ``[],ix,loc`` for scalar indexing and slicing work exactly the\n  same. (:issue:`263`)\n\n  Construction is by default for floating type values.\n\n  .. ipython:: python\n\n     index = pd.Index([1.5, 2, 3, 4.5, 5])\n     index\n     s = pd.Series(range(5), index=index)\n     s\n\n  Scalar selection for ``[],.ix,.loc`` will always be label based. An integer will match an equal float index (e.g. ``3`` is equivalent to ``3.0``)\n\n  .. ipython:: python\n\n     s[3]\n     s.loc[3]\n\n  The only positional indexing is via ``iloc``\n\n  .. ipython:: python\n\n     s.iloc[3]\n\n  A scalar index that is not found will raise ``KeyError``\n\n  Slicing is ALWAYS on the values of the index, for ``[],ix,loc`` and ALWAYS positional with ``iloc``\n\n  .. ipython:: python\n     :okwarning:\n\n     s[2:4]\n     s.loc[2:4]\n     s.iloc[2:4]\n\n  In float indexes, slicing using floats are allowed\n\n  .. ipython:: python\n\n     s[2.1:4.6]\n     s.loc[2.1:4.6]\n\n- Indexing on other index types are preserved (and positional fallback for ``[],ix``), with the exception, that floating point slicing\n  on indexes on non ``Float64Index`` will now raise a ``TypeError``.\n\n  .. code-block:: ipython\n\n     In [1]: pd.Series(range(5))[3.5]\n     TypeError: the label [3.5] is not a proper indexer for this index type (Int64Index)\n\n     In [1]: pd.Series(range(5))[3.5:4.5]\n     TypeError: the slice start [3.5] is not a proper indexer for this index type (Int64Index)\n\n  Using a scalar float indexer will be deprecated in a future version, but is allowed for now.\n\n  .. code-block:: ipython\n\n     In [3]: pd.Series(range(5))[3.0]\n     Out[3]: 3\n\nHDFStore API changes\n~~~~~~~~~~~~~~~~~~~~\n\n- Query Format Changes. A much more string-like query format is now supported. See :ref:`the docs<io.hdf5-query>`.\n\n  .. ipython:: python\n\n     path = 'test.h5'\n     dfq = pd.DataFrame(np.random.randn(10, 4),\n                        columns=list('ABCD'),\n                        index=pd.date_range('20130101', periods=10))\n     dfq.to_hdf(path, key='dfq', format='table', data_columns=True)\n\n  Use boolean expressions, with in-line function evaluation.\n\n  .. ipython:: python\n\n     pd.read_hdf(path, 'dfq',\n                 where=\"index>Timestamp('20130104') & columns=['A', 'B']\")\n\n  Use an inline column reference\n\n  .. ipython:: python\n\n     pd.read_hdf(path, 'dfq',\n                 where=\"A>0 or C>0\")\n\n  .. ipython:: python\n     :suppress:\n\n     import os\n     os.remove(path)\n\n- the ``format`` keyword now replaces the ``table`` keyword; allowed values are ``fixed(f)`` or ``table(t)``\n  the same defaults as prior < 0.13.0 remain, e.g. ``put`` implies ``fixed`` format and ``append`` implies\n  ``table`` format. This default format can be set as an option by setting ``io.hdf.default_format``.\n\n  .. ipython:: python\n\n     path = 'test.h5'\n     df = pd.DataFrame(np.random.randn(10, 2))\n     df.to_hdf(path, key='df_table', format='table')\n     df.to_hdf(path, key='df_table2', append=True)\n     df.to_hdf(path, key='df_fixed')\n     with pd.HDFStore(path) as store:\n         print(store)\n\n  .. ipython:: python\n     :suppress:\n\n     import os\n     os.remove(path)\n\n- Significant table writing performance improvements\n- handle a passed ``Series`` in table format (:issue:`4330`)\n- can now serialize a ``timedelta64[ns]`` dtype in a table (:issue:`3577`), See :ref:`the docs<io.hdf5-timedelta>`.\n- added an ``is_open`` property to indicate if the underlying file handle is_open;\n  a closed store will now report 'CLOSED' when viewing the store (rather than raising an error)\n  (:issue:`4409`)\n- a close of a ``HDFStore`` now will close that instance of the ``HDFStore``\n  but will only close the actual file if the ref count (by ``PyTables``) w.r.t. all of the open handles\n  are 0. Essentially you have a local instance of ``HDFStore`` referenced by a variable. Once you\n  close it, it will report closed. Other references (to the same file) will continue to operate\n  until they themselves are closed. Performing an action on a closed file will raise\n  ``ClosedFileError``\n\n  .. ipython:: python\n\n     path = 'test.h5'\n     df = pd.DataFrame(np.random.randn(10, 2))\n     store1 = pd.HDFStore(path)\n     store2 = pd.HDFStore(path)\n     store1.append('df', df)\n     store2.append('df2', df)\n\n     store1\n     store2\n     store1.close()\n     store2\n     store2.close()\n     store2\n\n  .. ipython:: python\n     :suppress:\n\n     import os\n     os.remove(path)\n\n- removed the ``_quiet`` attribute, replace by a ``DuplicateWarning`` if retrieving\n  duplicate rows from a table (:issue:`4367`)\n- removed the ``warn`` argument from ``open``. Instead a ``PossibleDataLossError`` exception will\n  be raised if you try to use ``mode='w'`` with an OPEN file handle (:issue:`4367`)\n- allow a passed locations array or mask as a ``where`` condition (:issue:`4467`).\n  See :ref:`the docs<io.hdf5-where_mask>` for an example.\n- add the keyword ``dropna=True`` to ``append`` to change whether ALL nan rows are not written\n  to the store (default is ``True``, ALL nan rows are NOT written), also settable\n  via the option ``io.hdf.dropna_table`` (:issue:`4625`)\n- pass through store creation arguments; can be used to support in-memory stores\n\nDataFrame repr changes\n~~~~~~~~~~~~~~~~~~~~~~\n\nThe HTML and plain text representations of :class:`DataFrame` now show\na truncated view of the table once it exceeds a certain size, rather\nthan switching to the short info view (:issue:`4886`, :issue:`5550`).\nThis makes the representation more consistent as small DataFrames get\nlarger.\n\n.. image:: ../_static/df_repr_truncated.png\n   :alt: Truncated HTML representation of a DataFrame\n\nTo get the info view, call :meth:`DataFrame.info`. If you prefer the\ninfo view as the repr for large DataFrames, you can set this by running\n``set_option('display.large_repr', 'info')``.\n\nEnhancements\n~~~~~~~~~~~~\n\n- ``df.to_clipboard()`` learned a new ``excel`` keyword that let's you\n  paste df data directly into excel (enabled by default). (:issue:`5070`).\n- ``read_html`` now raises a ``URLError`` instead of catching and raising a\n  ``ValueError`` (:issue:`4303`, :issue:`4305`)\n- Added a test for ``read_clipboard()`` and ``to_clipboard()`` (:issue:`4282`)\n- Clipboard functionality now works with PySide (:issue:`4282`)\n- Added a more informative error message when plot arguments contain\n  overlapping color and style arguments (:issue:`4402`)\n- ``to_dict`` now takes ``records`` as a possible out type.  Returns an array\n  of column-keyed dictionaries. (:issue:`4936`)\n\n- ``NaN`` handing in get_dummies (:issue:`4446`) with ``dummy_na``\n\n  .. ipython:: python\n\n      previously, nan was erroneously counted as 2 here\n      now it is not counted at all\n     pd.get_dummies([1, 2, np.nan])\n\n      unless requested\n     pd.get_dummies([1, 2, np.nan], dummy_na=True)\n\n\n- ``timedelta64[ns]`` operations. See :ref:`the docs<timedeltas.timedeltas_convert>`.\n\n  .. warning::\n\n     Most of these operations require ``numpy >= 1.7``\n\n  Using the new top-level ``to_timedelta``, you can convert a scalar or array from the standard\n  timedelta format (produced by ``to_csv``) into a timedelta type (``np.timedelta64`` in ``nanoseconds``).\n\n  .. ipython:: python\n\n     pd.to_timedelta('1 days 06:05:01.00003')\n     pd.to_timedelta('15.5us')\n     pd.to_timedelta(['1 days 06:05:01.00003', '15.5us', 'nan'])\n     pd.to_timedelta(np.arange(5), unit='s')\n     pd.to_timedelta(np.arange(5), unit='d')\n\n  A Series of dtype ``timedelta64[ns]`` can now be divided by another\n  ``timedelta64[ns]`` object, or astyped to yield a ``float64`` dtyped Series. This\n  is frequency conversion. See :ref:`the docs<timedeltas.timedeltas_convert>` for the docs.\n\n  .. ipython:: python\n\n     import datetime\n     td = pd.Series(pd.date_range('20130101', periods=4)) - pd.Series(\n         pd.date_range('20121201', periods=4))\n     td[2] += np.timedelta64(datetime.timedelta(minutes=5, seconds=3))\n     td[3] = np.nan\n     td\n\n  .. code-block:: ipython\n\n      to days\n     In [63]: td / np.timedelta64(1, 'D')\n     Out[63]:\n     0    31.000000\n     1    31.000000\n     2    31.003507\n     3          NaN\n     dtype: float64\n\n     In [64]: td.astype('timedelta64[D]')\n     Out[64]:\n     0    31.0\n     1    31.0\n     2    31.0\n     3     NaN\n     dtype: float64\n\n      to seconds\n     In [65]: td / np.timedelta64(1, 's')\n     Out[65]:\n     0    2678400.0\n     1    2678400.0\n     2    2678703.0\n     3          NaN\n     dtype: float64\n\n     In [66]: td.astype('timedelta64[s]')\n     Out[66]:\n     0    2678400.0\n     1    2678400.0\n     2    2678703.0\n     3          NaN\n     dtype: float64\n\n  Dividing or multiplying a ``timedelta64[ns]`` Series by an integer or integer Series\n\n  .. ipython:: python\n\n     td * -1\n     td * pd.Series([1, 2, 3, 4])\n\n  Absolute ``DateOffset`` objects can act equivalently to ``timedeltas``\n\n  .. ipython:: python\n\n     from pandas import offsets\n     td + offsets.Minute(5) + offsets.Milli(5)\n\n  Fillna is now supported for timedeltas\n\n  .. ipython:: python\n\n     td.fillna(pd.Timedelta(0))\n     td.fillna(datetime.timedelta(days=1, seconds=5))\n\n  You can do numeric reduction operations on timedeltas.\n\n  .. ipython:: python\n\n     td.mean()\n     td.quantile(.1)\n\n- ``plot(kind='kde')`` now accepts the optional parameters ``bw_method`` and\n  ``ind``, passed to scipy.stats.gaussian_kde() (for scipy >= 0.11.0) to set\n  the bandwidth, and to gkde.evaluate() to specify the indices at which it\n  is evaluated, respectively. See scipy docs. (:issue:`4298`)\n\n- DataFrame constructor now accepts a numpy masked record array (:issue:`3478`)\n\n- The new vectorized string method ``extract`` return regular expression\n  matches more conveniently.\n\n  .. ipython:: python\n     :okwarning:\n\n     pd.Series(['a1', 'b2', 'c3']).str.extract('[ab](\\\\d)')\n\n  Elements that do not match return ``NaN``. Extracting a regular expression\n  with more than one group returns a DataFrame with one column per group.\n\n\n  .. ipython:: python\n     :okwarning:\n\n     pd.Series(['a1', 'b2', 'c3']).str.extract('([ab])(\\\\d)')\n\n  Elements that do not match return a row of ``NaN``.\n  Thus, a Series of messy strings can be *converted* into a\n  like-indexed Series or DataFrame of cleaned-up or more useful strings,\n  without necessitating ``get()`` to access tuples or ``re.match`` objects.\n\n  Named groups like\n\n  .. ipython:: python\n     :okwarning:\n\n     pd.Series(['a1', 'b2', 'c3']).str.extract(\n         '(?P<letter>[ab])(?P<digit>\\\\d)')\n\n  and optional groups can also be used.\n\n  .. ipython:: python\n     :okwarning:\n\n      pd.Series(['a1', 'b2', '3']).str.extract(\n          '(?P<letter>[ab])?(?P<digit>\\\\d)')\n\n- ``read_stata`` now accepts Stata 13 format (:issue:`4291`)\n\n- ``read_fwf`` now infers the column specifications from the first 100 rows of\n  the file if the data has correctly separated and properly aligned columns\n  using the delimiter provided to the function (:issue:`4488`).\n\n- support for nanosecond times as an offset\n\n  .. warning::\n\n     These operations require ``numpy >= 1.7``\n\n  Period conversions in the range of seconds and below were reworked and extended\n  up to nanoseconds. Periods in the nanosecond range are now available.\n\n  .. code-block:: python\n\n     In [79]: pd.date_range('2013-01-01', periods=5, freq='5N')\n     Out[79]:\n     DatetimeIndex([          '2013-01-01 00:00:00',\n                    '2013-01-01 00:00:00.000000005',\n                    '2013-01-01 00:00:00.000000010',\n                    '2013-01-01 00:00:00.000000015',\n                    '2013-01-01 00:00:00.000000020'],\n                   dtype='datetime64[ns]', freq='5N')\n\n  or with frequency as offset\n\n  .. ipython:: python\n\n     pd.date_range('2013-01-01', periods=5, freq=pd.offsets.Nano(5))\n\n  Timestamps can be modified in the nanosecond range\n\n  .. ipython:: python\n\n     t = pd.Timestamp('20130101 09:01:02')\n     t + pd.tseries.offsets.Nano(123)\n\n- A new method, ``isin`` for DataFrames, which plays nicely with boolean indexing. The argument to ``isin``, what we're comparing the DataFrame to, can be a DataFrame, Series, dict, or array of values. See :ref:`the docs<indexing.basics.indexing_isin>` for more.\n\n  To get the rows where any of the conditions are met:\n\n  .. ipython:: python\n\n     dfi = pd.DataFrame({'A': [1, 2, 3, 4], 'B': ['a', 'b', 'f', 'n']})\n     dfi\n     other = pd.DataFrame({'A': [1, 3, 3, 7], 'B': ['e', 'f', 'f', 'e']})\n     mask = dfi.isin(other)\n     mask\n     dfi[mask.any(axis=1)]\n\n- ``Series`` now supports a ``to_frame`` method to convert it to a single-column DataFrame (:issue:`5164`)\n\n- All R datasets listed here http://stat.ethz.ch/R-manual/R-devel/library/datasets/html/00Index.html can now be loaded into pandas objects\n\n  .. code-block:: python\n\n      note that pandas.rpy was deprecated in v0.16.0\n     import pandas.rpy.common as com\n     com.load_data('Titanic')\n\n- ``tz_localize`` can infer a fall daylight savings transition based on the structure\n  of the unlocalized data (:issue:`4230`), see :ref:`the docs<timeseries.timezone>`\n\n- ``DatetimeIndex`` is now in the API documentation, see :ref:`the docs<api.datetimeindex>`\n\n- :meth:`~pandas.io.json.json_normalize` is a new method to allow you to create a flat table\n  from semi-structured JSON data. See :ref:`the docs<io.json_normalize>` (:issue:`1067`)\n\n- Added PySide support for the qtpandas DataFrameModel and DataFrameWidget.\n\n- Python csv parser now supports usecols (:issue:`4335`)\n\n- Frequencies gained several new offsets:\n\n  * ``LastWeekOfMonth`` (:issue:`4637`)\n  * ``FY5253``, and ``FY5253Quarter`` (:issue:`4511`)\n\n\n- DataFrame has a new ``interpolate`` method, similar to Series (:issue:`4434`, :issue:`1892`)\n\n  .. ipython:: python\n\n      df = pd.DataFrame({'A': [1, 2.1, np.nan, 4.7, 5.6, 6.8],\n                        'B': [.25, np.nan, np.nan, 4, 12.2, 14.4]})\n      df.interpolate()\n\n  Additionally, the ``method`` argument to ``interpolate`` has been expanded\n  to include ``'nearest', 'zero', 'slinear', 'quadratic', 'cubic',\n  'barycentric', 'krogh', 'piecewise_polynomial', 'pchip', 'polynomial', 'spline'``\n  The new methods require scipy_. Consult the Scipy reference guide_ and documentation_ for more information\n  about when the various methods are appropriate. See :ref:`the docs<missing_data.interpolate>`.\n\n  Interpolate now also accepts a ``limit`` keyword argument.\n  This works similar to ``fillna``'s limit:\n\n  .. ipython:: python\n\n    ser = pd.Series([1, 3, np.nan, np.nan, np.nan, 11])\n    ser.interpolate(limit=2)\n\n- Added ``wide_to_long`` panel data convenience function. See :ref:`the docs<reshaping.melt>`.\n\n  .. ipython:: python\n\n    np.random.seed(123)\n    df = pd.DataFrame({\"A1970\" : {0 : \"a\", 1 : \"b\", 2 : \"c\"},\n                       \"A1980\" : {0 : \"d\", 1 : \"e\", 2 : \"f\"},\n                       \"B1970\" : {0 : 2.5, 1 : 1.2, 2 : .7},\n                       \"B1980\" : {0 : 3.2, 1 : 1.3, 2 : .1},\n                       \"X\"     : dict(zip(range(3), np.random.randn(3)))\n                      })\n    df[\"id\"] = df.index\n    df\n    pd.wide_to_long(df, [\"A\", \"B\"], i=\"id\", j=\"year\")\n\n.. _scipy: http://www.scipy.org\n.. _documentation: http://docs.scipy.org/doc/scipy/reference/interpolate.html#univariate-interpolation\n.. _guide: https://docs.scipy.org/doc/scipy/tutorial/interpolate.html\n\n- ``to_csv`` now takes a ``date_format`` keyword argument that specifies how\n  output datetime objects should be formatted. Datetimes encountered in the\n  index, columns, and values will all have this formatting applied. (:issue:`4313`)\n- ``DataFrame.plot`` will scatter plot x versus y by passing ``kind='scatter'`` (:issue:`2215`)\n- Added support for Google Analytics v3 API segment IDs that also supports v2 IDs. (:issue:`5271`)\n\n.. _whatsnew_0130.experimental:\n\nExperimental\n~~~~~~~~~~~~\n\n- The new :func:`~pandas.eval` function implements expression evaluation using\n  ``numexpr`` behind the scenes. This results in large speedups for\n  complicated expressions involving large DataFrames/Series. For example,\n\n  .. ipython:: python\n\n     nrows, ncols = 20000, 100\n     df1, df2, df3, df4 = [pd.DataFrame(np.random.randn(nrows, ncols))\n                           for _ in range(4)]\n\n  .. ipython:: python\n\n      eval with NumExpr backend\n     %timeit pd.eval('df1 + df2 + df3 + df4')\n\n  .. ipython:: python\n\n      pure Python evaluation\n     %timeit df1 + df2 + df3 + df4\n\n  For more details, see the :ref:`the docs<enhancingperf.eval>`\n\n- Similar to ``pandas.eval``, :class:`~pandas.DataFrame` has a new\n  ``DataFrame.eval`` method that evaluates an expression in the context of\n  the ``DataFrame``. For example,\n\n  .. ipython:: python\n     :suppress:\n\n     try:\n         del a   noqa: F821\n     except NameError:\n         pass\n\n     try:\n         del b   noqa: F821\n     except NameError:\n         pass\n\n  .. ipython:: python\n\n     df = pd.DataFrame(np.random.randn(10, 2), columns=['a', 'b'])\n     df.eval('a + b')\n\n- :meth:`~pandas.DataFrame.query` method has been added that allows\n  you to select elements of a ``DataFrame`` using a natural query syntax\n  nearly identical to Python syntax. For example,\n\n  .. ipython:: python\n     :suppress:\n\n     try:\n         del a   noqa: F821\n     except NameError:\n         pass\n\n     try:\n         del b   noqa: F821\n     except NameError:\n         pass\n\n     try:\n         del c   noqa: F821\n     except NameError:\n         pass\n\n  .. ipython:: python\n\n     n = 20\n     df = pd.DataFrame(np.random.randint(n, size=(n, 3)), columns=['a', 'b', 'c'])\n     df.query('a < b < c')\n\n  selects all the rows of ``df`` where ``a < b < c`` evaluates to ``True``.\n  For more details see the :ref:`the docs<indexing.query>`.\n\n- ``pd.read_msgpack()`` and ``pd.to_msgpack()`` are now a supported method of serialization\n  of arbitrary pandas (and python objects) in a lightweight portable binary format. See :ref:`the docs<io.msgpack>`\n\n  .. warning::\n\n     Since this is an EXPERIMENTAL LIBRARY, the storage format may not be stable until a future release.\n\n  .. code-block:: python\n\n     df = pd.DataFrame(np.random.rand(5, 2), columns=list('AB'))\n     df.to_msgpack('foo.msg')\n     pd.read_msgpack('foo.msg')\n\n     s = pd.Series(np.random.rand(5), index=pd.date_range('20130101', periods=5))\n     pd.to_msgpack('foo.msg', df, s)\n     pd.read_msgpack('foo.msg')\n\n  You can pass ``iterator=True`` to iterator over the unpacked results\n\n  .. code-block:: python\n\n     for o in pd.read_msgpack('foo.msg', iterator=True):\n         print(o)\n\n  .. ipython:: python\n     :suppress:\n     :okexcept:\n\n     os.remove('foo.msg')\n\n- ``pandas.io.gbq`` provides a simple way to extract from, and load data into,\n  Google's BigQuery Data Sets by way of pandas DataFrames. BigQuery is a high\n  performance SQL-like database service, useful for performing ad-hoc queries\n  against extremely large datasets. :ref:`See the docs <io.bigquery>`\n\n  .. code-block:: python\n\n     from pandas.io import gbq\n\n      A query to select the average monthly temperatures in the\n      in the year 2000 across the USA. The dataset,\n      publicata:samples.gsod, is available on all BigQuery accounts,\n      and is based on NOAA gsod data.\n\n     query = \"\"\"SELECT station_number as STATION,\n     month as MONTH, AVG(mean_temp) as MEAN_TEMP\n     FROM publicdata:samples.gsod\n     WHERE YEAR = 2000\n     GROUP BY STATION, MONTH\n     ORDER BY STATION, MONTH ASC\"\"\"\n\n      Fetch the result set for this query\n\n      Your Google BigQuery Project ID\n      To find this, see your dashboard:\n      https://console.developers.google.com/iam-admin/projects?authuser=0\n     projectid = 'xxxxxxxxx'\n     df = gbq.read_gbq(query, project_id=projectid)\n\n      Use pandas to process and reshape the dataset\n\n     df2 = df.pivot(index='STATION', columns='MONTH', values='MEAN_TEMP')\n     df3 = pd.concat([df2.min(), df2.mean(), df2.max()],\n                     axis=1, keys=[\"Min Tem\", \"Mean Temp\", \"Max Temp\"])\n\n  The resulting DataFrame is::\n\n     > df3\n                 Min Tem  Mean Temp    Max Temp\n      MONTH\n      1     -53.336667  39.827892   89.770968\n      2     -49.837500  43.685219   93.437932\n      3     -77.926087  48.708355   96.099998\n      4     -82.892858  55.070087   97.317240\n      5     -92.378261  61.428117  102.042856\n      6     -77.703334  65.858888  102.900000\n      7     -87.821428  68.169663  106.510714\n      8     -89.431999  68.614215  105.500000\n      9     -86.611112  63.436935  107.142856\n      10    -78.209677  56.880838   92.103333\n      11    -50.125000  48.861228   94.996428\n      12    -50.332258  42.286879   94.396774\n\n  .. warning::\n\n     To use this module, you will need a BigQuery account. See\n     <https://cloud.google.com/products/big-query> for details.\n\n     As of 10/10/13, there is a bug in Google's API preventing result sets\n     from being larger than 100,000 rows. A patch is scheduled for the week of\n     10/14/13.\n\n.. _whatsnew_0130.refactoring:\n\nInternal refactoring\n~~~~~~~~~~~~~~~~~~~~\n\nIn 0.13.0 there is a major refactor primarily to subclass ``Series`` from\n``NDFrame``, which is the base class currently for ``DataFrame`` and ``Panel``,\nto unify methods and behaviors. Series formerly subclassed directly from\n``ndarray``. (:issue:`4080`, :issue:`3862`, :issue:`816`)\n\n.. warning::\n\n   There are two potential incompatibilities from < 0.13.0\n\n   - Using certain numpy functions would previously return a ``Series`` if passed a ``Series``\n     as an argument. This seems only to affect ``np.ones_like``, ``np.empty_like``,\n     ``np.diff`` and ``np.where``. These now return ``ndarrays``.\n\n     .. ipython:: python\n\n        s = pd.Series([1, 2, 3, 4])\n\n     Numpy Usage\n\n     .. ipython:: python\n\n        np.ones_like(s)\n        np.diff(s)\n        np.where(s > 1, s, np.nan)\n\n     Pandonic Usage\n\n     .. ipython:: python\n\n        pd.Series(1, index=s.index)\n        s.diff()\n        s.where(s > 1)\n\n   - Passing a ``Series`` directly to a cython function expecting an ``ndarray`` type will no\n     long work directly, you must pass ``Series.values``, See :ref:`Enhancing Performance<enhancingperf.ndarray>`\n\n   - ``Series(0.5)`` would previously return the scalar ``0.5``, instead this will return a 1-element ``Series``\n\n   - This change breaks ``rpy2<=2.3.8``. an Issue has been opened against rpy2 and a workaround\n     is detailed in :issue:`5698`. Thanks JanSchulz.\n\n- Pickle compatibility is preserved for pickles created prior to 0.13. These must be unpickled with ``pd.read_pickle``, see :ref:`Pickling<io.pickle>`.\n\n- Refactor of series.py/frame.py/panel.py to move common code to generic.py\n\n  - added ``_setup_axes`` to created generic NDFrame structures\n  - moved methods\n\n    - ``from_axes,_wrap_array,axes,ix,loc,iloc,shape,empty,swapaxes,transpose,pop``\n    - ``__iter__,keys,__contains__,__len__,__neg__,__invert__``\n    - ``convert_objects,as_blocks,as_matrix,values``\n    - ``__getstate__,__setstate__`` (compat remains in frame/panel)\n    - ``__getattr__,__setattr__``\n    - ``_indexed_same,reindex_like,align,where,mask``\n    - ``fillna,replace`` (``Series`` replace is now consistent with ``DataFrame``)\n    - ``filter`` (also added axis argument to selectively filter on a different axis)\n    - ``reindex,reindex_axis,take``\n    - ``truncate`` (moved to become part of ``NDFrame``)\n\n- These are API changes which make ``Panel`` more consistent with ``DataFrame``\n\n  - ``swapaxes`` on a ``Panel`` with the same axes specified now return a copy\n  - support attribute access for setting\n  - filter supports the same API as the original ``DataFrame`` filter\n\n- Reindex called with no arguments will now return a copy of the input object\n\n- ``TimeSeries`` is now an alias for ``Series``. the property ``is_time_series``\n  can be used to distinguish (if desired)\n\n- Refactor of Sparse objects to use BlockManager\n\n  - Created a new block type in internals, ``SparseBlock``, which can hold multi-dtypes\n    and is non-consolidatable. ``SparseSeries`` and ``SparseDataFrame`` now inherit\n    more methods from there hierarchy (Series/DataFrame), and no longer inherit\n    from ``SparseArray`` (which instead is the object of the ``SparseBlock``)\n  - Sparse suite now supports integration with non-sparse data. Non-float sparse\n    data is supportable (partially implemented)\n  - Operations on sparse structures within DataFrames should preserve sparseness,\n    merging type operations will convert to dense (and back to sparse), so might\n    be somewhat inefficient\n  - enable setitem on ``SparseSeries`` for boolean/integer/slices\n  - ``SparsePanels`` implementation is unchanged (e.g. not using BlockManager, needs work)\n\n- added ``ftypes`` method to Series/DataFrame, similar to ``dtypes``, but indicates\n  if the underlying is sparse/dense (as well as the dtype)\n- All ``NDFrame`` objects can now use ``__finalize__()`` to specify various\n  values to propagate to new objects from an existing one (e.g. ``name`` in ``Series`` will\n  follow more automatically now)\n- Internal type checking is now done via a suite of generated classes, allowing ``isinstance(value, klass)``\n  without having to directly import the klass, courtesy of jtratner\n- Bug in Series update where the parent frame is not updating its cache based on\n  changes (:issue:`4080`) or types (:issue:`3217`), fillna (:issue:`3386`)\n- Indexing with dtype conversions fixed (:issue:`4463`, :issue:`4204`)\n- Refactor ``Series.reindex`` to core/generic.py (:issue:`4604`, :issue:`4618`), allow ``method=`` in reindexing\n  on a Series to work\n- ``Series.copy`` no longer accepts the ``order`` parameter and is now consistent with ``NDFrame`` copy\n- Refactor ``rename`` methods to core/generic.py; fixes ``Series.rename`` for (:issue:`4605`), and adds ``rename``\n  with the same signature for ``Panel``\n- Refactor ``clip`` methods to core/generic.py (:issue:`4798`)\n- Refactor of ``_get_numeric_data/_get_bool_data`` to core/generic.py, allowing Series/Panel functionality\n- ``Series`` (for index) / ``Panel`` (for items) now allow attribute access to its elements  (:issue:`1903`)\n\n  .. ipython:: python\n\n     s = pd.Series([1, 2, 3], index=list('abc'))\n     s.b\n     s.a = 5\n     s\n\n.. _release.bug_fixes-0.13.0:\n\nBug fixes\n~~~~~~~~~\n\n- ``HDFStore``\n\n  - raising an invalid ``TypeError`` rather than ``ValueError`` when\n    appending with a different block ordering (:issue:`4096`)\n  - ``read_hdf`` was not respecting as passed ``mode`` (:issue:`4504`)\n  - appending a 0-len table will work correctly (:issue:`4273`)\n  - ``to_hdf`` was raising when passing both arguments ``append`` and\n    ``table`` (:issue:`4584`)\n  - reading from a store with duplicate columns across dtypes would raise\n    (:issue:`4767`)\n  - Fixed a bug where ``ValueError`` wasn't correctly raised when column\n    names weren't strings (:issue:`4956`)\n  - A zero length series written in Fixed format not deserializing properly.\n    (:issue:`4708`)\n  - Fixed decoding perf issue on pyt3 (:issue:`5441`)\n  - Validate levels in a MultiIndex before storing (:issue:`5527`)\n  - Correctly handle ``data_columns`` with a Panel (:issue:`5717`)\n- Fixed bug in tslib.tz_convert(vals, tz1, tz2): it could raise IndexError\n  exception while trying to access trans[pos + 1] (:issue:`4496`)\n- The ``by`` argument now works correctly with the ``layout`` argument\n  (:issue:`4102`, :issue:`4014`) in ``*.hist`` plotting methods\n- Fixed bug in ``PeriodIndex.map`` where using ``str`` would return the str\n  representation of the index (:issue:`4136`)\n- Fixed test failure ``test_time_series_plot_color_with_empty_kwargs`` when\n  using custom matplotlib default colors (:issue:`4345`)\n- Fix running of stata IO tests. Now uses temporary files to write\n  (:issue:`4353`)\n- Fixed an issue where ``DataFrame.sum`` was slower than ``DataFrame.mean``\n  for integer valued frames (:issue:`4365`)\n- ``read_html`` tests now work with Python 2.6 (:issue:`4351`)\n- Fixed bug where ``network`` testing was throwing ``NameError`` because a\n  local variable was undefined (:issue:`4381`)\n- In ``to_json``, raise if a passed ``orient`` would cause loss of data\n  because of a duplicate index (:issue:`4359`)\n- In ``to_json``, fix date handling so milliseconds are the default timestamp\n  as the docstring says (:issue:`4362`).\n- ``as_index`` is no longer ignored when doing groupby apply (:issue:`4648`,\n  :issue:`3417`)\n- JSON NaT handling fixed, NaTs are now serialized to ``null`` (:issue:`4498`)\n- Fixed JSON handling of escapable characters in JSON object keys\n  (:issue:`4593`)\n- Fixed passing ``keep_default_na=False`` when ``na_values=None``\n  (:issue:`4318`)\n- Fixed bug with ``values`` raising an error on a DataFrame with duplicate\n  columns and mixed dtypes, surfaced in (:issue:`4377`)\n- Fixed bug with duplicate columns and type conversion in ``read_json`` when\n  ``orient='split'`` (:issue:`4377`)\n- Fixed JSON bug where locales with decimal separators other than '.' threw\n  exceptions when encoding / decoding certain values. (:issue:`4918`)\n- Fix ``.iat`` indexing with a ``PeriodIndex`` (:issue:`4390`)\n- Fixed an issue where ``PeriodIndex`` joining with self was returning a new\n  instance rather than the same instance (:issue:`4379`); also adds a test\n  for this for the other index types\n- Fixed a bug with all the dtypes being converted to object when using the\n  CSV cparser with the usecols parameter (:issue:`3192`)\n- Fix an issue in merging blocks where the resulting DataFrame had partially\n  set _ref_locs (:issue:`4403`)\n- Fixed an issue where hist subplots were being overwritten when they were\n  called using the top level matplotlib API (:issue:`4408`)\n- Fixed a bug where calling ``Series.astype(str)`` would truncate the string\n  (:issue:`4405`, :issue:`4437`)\n- Fixed a py3 compat issue where bytes were being repr'd as tuples\n  (:issue:`4455`)\n- Fixed Panel attribute naming conflict if item is named 'a'\n  (:issue:`3440`)\n- Fixed an issue where duplicate indexes were raising when plotting\n  (:issue:`4486`)\n- Fixed an issue where cumsum and cumprod didn't work with bool dtypes\n  (:issue:`4170`, :issue:`4440`)\n- Fixed Panel slicing issued in ``xs`` that was returning an incorrect dimmed\n  object (:issue:`4016`)\n- Fix resampling bug where custom reduce function not used if only one group\n  (:issue:`3849`, :issue:`4494`)\n- Fixed Panel assignment with a transposed frame (:issue:`3830`)\n- Raise on set indexing with a Panel and a Panel as a value which needs\n  alignment (:issue:`3777`)\n- frozenset objects now raise in the ``Series`` constructor (:issue:`4482`,\n  :issue:`4480`)\n- Fixed issue with sorting a duplicate MultiIndex that has multiple dtypes\n  (:issue:`4516`)\n- Fixed bug in ``DataFrame.set_values`` which was causing name attributes to\n  be lost when expanding the index. (:issue:`3742`, :issue:`4039`)\n- Fixed issue where individual ``names``, ``levels`` and ``labels`` could be\n  set on ``MultiIndex`` without validation (:issue:`3714`, :issue:`4039`)\n- Fixed (:issue:`3334`) in pivot_table. Margins did not compute if values is\n  the index.\n- Fix bug in having a rhs of ``np.timedelta64`` or ``np.offsets.DateOffset``\n  when operating with datetimes (:issue:`4532`)\n- Fix arithmetic with series/datetimeindex and ``np.timedelta64`` not working\n  the same (:issue:`4134`) and buggy timedelta in NumPy 1.6 (:issue:`4135`)\n- Fix bug in ``pd.read_clipboard`` on windows with PY3 (:issue:`4561`); not\n  decoding properly\n- ``tslib.get_period_field()`` and ``tslib.get_period_field_arr()`` now raise\n  if code argument out of range (:issue:`4519`, :issue:`4520`)\n- Fix boolean indexing on an empty series loses index names (:issue:`4235`),\n  infer_dtype works with empty arrays.\n- Fix reindexing with multiple axes; if an axes match was not replacing the\n  current axes, leading to a possible lazy frequency inference issue\n  (:issue:`3317`)\n- Fixed issue where ``DataFrame.apply`` was reraising exceptions incorrectly\n  (causing the original stack trace to be truncated).\n- Fix selection with ``ix/loc`` and non_unique selectors (:issue:`4619`)\n- Fix assignment with iloc/loc involving a dtype change in an existing column\n  (:issue:`4312`, :issue:`5702`) have internal setitem_with_indexer in core/indexing\n  to use Block.setitem\n- Fixed bug where thousands operator was not handled correctly for floating\n  point numbers in csv_import (:issue:`4322`)\n- Fix an issue with CacheableOffset not properly being used by many\n  DateOffset; this prevented the DateOffset from being cached (:issue:`4609`)\n- Fix boolean comparison with a DataFrame on the lhs, and a list/tuple on the\n  rhs (:issue:`4576`)\n- Fix error/dtype conversion with setitem of ``None`` on ``Series/DataFrame``\n  (:issue:`4667`)\n- Fix decoding based on a passed in non-default encoding in ``pd.read_stata``\n  (:issue:`4626`)\n- Fix ``DataFrame.from_records`` with a plain-vanilla ``ndarray``.\n  (:issue:`4727`)\n- Fix some inconsistencies with ``Index.rename`` and ``MultiIndex.rename``,\n  etc. (:issue:`4718`, :issue:`4628`)\n- Bug in using ``iloc/loc`` with a cross-sectional and duplicate indices\n  (:issue:`4726`)\n- Bug with using ``QUOTE_NONE`` with ``to_csv`` causing ``Exception``.\n  (:issue:`4328`)\n- Bug with Series indexing not raising an error when the right-hand-side has\n  an incorrect length (:issue:`2702`)\n- Bug in MultiIndexing with a partial string selection as one part of a\n  MultIndex (:issue:`4758`)\n- Bug with reindexing on the index with a non-unique index will now raise\n  ``ValueError`` (:issue:`4746`)\n- Bug in setting with ``loc/ix`` a single indexer with a MultiIndex axis and\n  a NumPy array, related to (:issue:`3777`)\n- Bug in concatenation with duplicate columns across dtypes not merging with\n  axis=0 (:issue:`4771`, :issue:`4975`)\n- Bug in ``iloc`` with a slice index failing (:issue:`4771`)\n- Incorrect error message with no colspecs or width in ``read_fwf``.\n  (:issue:`4774`)\n- Fix bugs in indexing in a Series with a duplicate index (:issue:`4548`,\n  :issue:`4550`)\n- Fixed bug with reading compressed files with ``read_fwf`` in Python 3.\n  (:issue:`3963`)\n- Fixed an issue with a duplicate index and assignment with a dtype change\n  (:issue:`4686`)\n- Fixed bug with reading compressed files in as ``bytes`` rather than ``str``\n  in Python 3. Simplifies bytes-producing file-handling in Python 3\n  (:issue:`3963`, :issue:`4785`).\n- Fixed an issue related to ticklocs/ticklabels with log scale bar plots\n  across different versions of matplotlib (:issue:`4789`)\n- Suppressed DeprecationWarning associated with internal calls issued by\n  repr() (:issue:`4391`)\n- Fixed an issue with a duplicate index and duplicate selector with ``.loc``\n  (:issue:`4825`)\n- Fixed an issue with ``DataFrame.sort_index`` where, when sorting by a\n  single column and passing a list for ``ascending``, the argument for\n  ``ascending`` was being interpreted as ``True`` (:issue:`4839`,\n  :issue:`4846`)\n- Fixed ``Panel.tshift`` not working. Added ``freq`` support to ``Panel.shift``\n  (:issue:`4853`)\n- Fix an issue in TextFileReader w/ Python engine (i.e. PythonParser)\n  with thousands != \",\" (:issue:`4596`)\n- Bug in getitem with a duplicate index when using where (:issue:`4879`)\n- Fix Type inference code coerces float column into datetime (:issue:`4601`)\n- Fixed ``_ensure_numeric`` does not check for complex numbers\n  (:issue:`4902`)\n- Fixed a bug in ``Series.hist`` where two figures were being created when\n  the ``by`` argument was passed (:issue:`4112`, :issue:`4113`).\n- Fixed a bug in ``convert_objects`` for > 2 ndims (:issue:`4937`)\n- Fixed a bug in DataFrame/Panel cache insertion and subsequent indexing\n  (:issue:`4939`, :issue:`5424`)\n- Fixed string methods for ``FrozenNDArray`` and ``FrozenList``\n  (:issue:`4929`)\n- Fixed a bug with setting invalid or out-of-range values in indexing\n  enlargement scenarios (:issue:`4940`)\n- Tests for fillna on empty Series (:issue:`4346`), thanks immerrr\n- Fixed ``copy()`` to shallow copy axes/indices as well and thereby keep\n  separate metadata. (:issue:`4202`, :issue:`4830`)\n- Fixed skiprows option in Python parser for read_csv (:issue:`4382`)\n- Fixed bug preventing ``cut`` from working with ``np.inf`` levels without\n  explicitly passing labels (:issue:`3415`)\n- Fixed wrong check for overlapping in ``DatetimeIndex.union``\n  (:issue:`4564`)\n- Fixed conflict between thousands separator and date parser in csv_parser\n  (:issue:`4678`)\n- Fix appending when dtypes are not the same (error showing mixing\n  float/np.datetime64) (:issue:`4993`)\n- Fix repr for DateOffset. No longer show duplicate entries in kwds.\n  Removed unused offset fields. (:issue:`4638`)\n- Fixed wrong index name during read_csv if using usecols. Applies to c\n  parser only. (:issue:`4201`)\n- ``Timestamp`` objects can now appear in the left hand side of a comparison\n  operation with a ``Series`` or ``DataFrame`` object (:issue:`4982`).\n- Fix a bug when indexing with ``np.nan`` via ``iloc/loc`` (:issue:`5016`)\n- Fixed a bug where low memory c parser could create different types in\n  different chunks of the same file. Now coerces to numerical type or raises\n  warning. (:issue:`3866`)\n- Fix a bug where reshaping a ``Series`` to its own shape raised\n  ``TypeError`` (:issue:`4554`) and other reshaping issues.\n- Bug in setting with ``ix/loc`` and a mixed int/string index (:issue:`4544`)\n- Make sure series-series boolean comparisons are label based (:issue:`4947`)\n- Bug in multi-level indexing with a Timestamp partial indexer\n  (:issue:`4294`)\n- Tests/fix for MultiIndex construction of an all-nan frame (:issue:`4078`)\n- Fixed a bug where :func:`~pandas.read_html` wasn't correctly inferring\n  values of tables with commas (:issue:`5029`)\n- Fixed a bug where :func:`~pandas.read_html` wasn't providing a stable\n  ordering of returned tables (:issue:`4770`, :issue:`5029`).\n- Fixed a bug where :func:`~pandas.read_html` was incorrectly parsing when\n  passed ``index_col=0`` (:issue:`5066`).\n- Fixed a bug where :func:`~pandas.read_html` was incorrectly inferring the\n  type of headers (:issue:`5048`).\n- Fixed a bug where ``DatetimeIndex`` joins with ``PeriodIndex`` caused a\n  stack overflow (:issue:`3899`).\n- Fixed a bug where ``groupby`` objects didn't allow plots (:issue:`5102`).\n- Fixed a bug where ``groupby`` objects weren't tab-completing column names\n  (:issue:`5102`).\n- Fixed a bug where ``groupby.plot()`` and friends were duplicating figures\n  multiple times (:issue:`5102`).\n- Provide automatic conversion of ``object`` dtypes on fillna, related\n  (:issue:`5103`)\n- Fixed a bug where default options were being overwritten in the option\n  parser cleaning (:issue:`5121`).\n- Treat a list/ndarray identically for ``iloc`` indexing with list-like\n  (:issue:`5006`)\n- Fix ``MultiIndex.get_level_values()`` with missing values (:issue:`5074`)\n- Fix bound checking for Timestamp() with datetime64 input (:issue:`4065`)\n- Fix a bug where ``TestReadHtml`` wasn't calling the correct ``read_html()``\n  function (:issue:`5150`).\n- Fix a bug with ``NDFrame.replace()`` which made replacement appear as\n  though it was (incorrectly) using regular expressions (:issue:`5143`).\n- Fix better error message for to_datetime (:issue:`4928`)\n- Made sure different locales are tested on travis-ci (:issue:`4918`). Also\n  adds a couple of utilities for getting locales and setting locales with a\n  context manager.\n- Fixed segfault on ``isnull(MultiIndex)`` (now raises an error instead)\n  (:issue:`5123`, :issue:`5125`)\n- Allow duplicate indices when performing operations that align\n  (:issue:`5185`, :issue:`5639`)\n- Compound dtypes in a constructor raise ``NotImplementedError``\n  (:issue:`5191`)\n- Bug in comparing duplicate frames (:issue:`4421`) related\n- Bug in describe on duplicate frames\n- Bug in ``to_datetime`` with a format and ``coerce=True`` not raising\n  (:issue:`5195`)\n- Bug in ``loc`` setting with multiple indexers and a rhs of a Series that\n  needs broadcasting (:issue:`5206`)\n- Fixed bug where inplace setting of levels or labels on ``MultiIndex`` would\n  not clear cached ``values`` property and therefore return wrong ``values``.\n  (:issue:`5215`)\n- Fixed bug where filtering a grouped DataFrame or Series did not maintain\n  the original ordering (:issue:`4621`).\n- Fixed ``Period`` with a business date freq to always roll-forward if on a\n  non-business date. (:issue:`5203`)\n- Fixed bug in Excel writers where frames with duplicate column names weren't\n  written correctly. (:issue:`5235`)\n- Fixed issue with ``drop`` and a non-unique index on Series (:issue:`5248`)\n- Fixed segfault in C parser caused by passing more names than columns in\n  the file. (:issue:`5156`)\n- Fix ``Series.isin`` with date/time-like dtypes (:issue:`5021`)\n- C and Python Parser can now handle the more common MultiIndex column\n  format which doesn't have a row for index names (:issue:`4702`)\n- Bug when trying to use an out-of-bounds date as an object dtype\n  (:issue:`5312`)\n- Bug when trying to display an embedded PandasObject (:issue:`5324`)\n- Allows operating of Timestamps to return a datetime if the result is out-of-bounds\n  related (:issue:`5312`)\n- Fix return value/type signature of ``initObjToJSON()`` to be compatible\n  with numpy's ``import_array()`` (:issue:`5334`, :issue:`5326`)\n- Bug when renaming then set_index on a DataFrame (:issue:`5344`)\n- Test suite no longer leaves around temporary files when testing graphics. (:issue:`5347`)\n  (thanks for catching this yarikoptic!)\n- Fixed html tests on win32. (:issue:`4580`)\n- Make sure that ``head/tail`` are ``iloc`` based, (:issue:`5370`)\n- Fixed bug for ``PeriodIndex`` string representation if there are 1 or 2\n  elements. (:issue:`5372`)\n- The GroupBy methods ``transform`` and ``filter`` can be used on Series\n  and DataFrames that have repeated (non-unique) indices. (:issue:`4620`)\n- Fix empty series not printing name in repr (:issue:`4651`)\n- Make tests create temp files in temp directory by default. (:issue:`5419`)\n- ``pd.to_timedelta`` of a scalar returns a scalar (:issue:`5410`)\n- ``pd.to_timedelta`` accepts ``NaN`` and ``NaT``, returning ``NaT`` instead of raising (:issue:`5437`)\n- performance improvements in ``isnull`` on larger size pandas objects\n- Fixed various setitem with 1d ndarray that does not have a matching\n  length to the indexer (:issue:`5508`)\n- Bug in getitem with a MultiIndex and ``iloc`` (:issue:`5528`)\n- Bug in delitem on a Series (:issue:`5542`)\n- Bug fix in apply when using custom function and objects are not mutated (:issue:`5545`)\n- Bug in selecting from a non-unique index with ``loc`` (:issue:`5553`)\n- Bug in groupby returning non-consistent types when user function returns a ``None``, (:issue:`5592`)\n- Work around regression in numpy 1.7.0 which erroneously raises IndexError from ``ndarray.item`` (:issue:`5666`)\n- Bug in repeated indexing of object with resultant non-unique index (:issue:`5678`)\n- Bug in fillna with Series and a passed series/dict (:issue:`5703`)\n- Bug in groupby transform with a datetime-like grouper (:issue:`5712`)\n- Bug in MultiIndex selection in PY3 when using certain keys (:issue:`5725`)\n- Row-wise concat of differing dtypes failing in certain cases (:issue:`5754`)\n\n.. _whatsnew_0.13.0.contributors:\n\nContributors\n~~~~~~~~~~~~\n\n.. contributors:: v0.12.0..v0.13.0\n\n\n.. _whatsnew_111:\n\nWhat's new in 1.1.1 (August 20, 2020)\n-------------------------------------\n\nThese are the changes in pandas 1.1.1. See :ref:`release` for a full changelog\nincluding other versions of pandas.\n\n{{ header }}\n\n.. ---------------------------------------------------------------------------\n\n.. _whatsnew_111.regressions:\n\nFixed regressions\n~~~~~~~~~~~~~~~~~\n\n- Fixed regression in :meth:`CategoricalIndex.format` where, when stringified scalars had different lengths, the shorter string would be right-filled with spaces, so it had the same length as the longest string (:issue:`35439`)\n- Fixed regression in :meth:`Series.truncate` when trying to truncate a single-element series (:issue:`35544`)\n- Fixed regression where :meth:`DataFrame.to_numpy` would raise a ``RuntimeError`` for mixed dtypes when converting to ``str`` (:issue:`35455`)\n- Fixed regression where :func:`read_csv` would raise a ``ValueError`` when ``pandas.options.mode.use_inf_as_na`` was set to ``True`` (:issue:`35493`)\n- Fixed regression where :func:`pandas.testing.assert_series_equal` would raise an error when non-numeric dtypes were passed with ``check_exact=True`` (:issue:`35446`)\n- Fixed regression in ``.groupby(..).rolling(..)`` where column selection was ignored (:issue:`35486`)\n- Fixed regression where :meth:`DataFrame.interpolate` would raise a ``TypeError`` when the :class:`DataFrame` was empty (:issue:`35598`)\n- Fixed regression in :meth:`DataFrame.shift` with ``axis=1`` and heterogeneous dtypes (:issue:`35488`)\n- Fixed regression in :meth:`DataFrame.diff` with read-only data (:issue:`35559`)\n- Fixed regression in ``.groupby(..).rolling(..)`` where a segfault would occur with ``center=True`` and an odd number of values (:issue:`35552`)\n- Fixed regression in :meth:`DataFrame.apply` where functions that altered the input in-place only operated on a single row (:issue:`35462`)\n- Fixed regression in :meth:`DataFrame.reset_index` would raise a ``ValueError`` on empty :class:`DataFrame` with a :class:`MultiIndex` with a ``datetime64`` dtype level (:issue:`35606`, :issue:`35657`)\n- Fixed regression where :func:`pandas.merge_asof` would raise a ``UnboundLocalError`` when ``left_index``, ``right_index`` and ``tolerance`` were set (:issue:`35558`)\n- Fixed regression in ``.groupby(..).rolling(..)`` where a custom ``BaseIndexer`` would be ignored (:issue:`35557`)\n- Fixed regression in :meth:`DataFrame.replace` and :meth:`Series.replace` where compiled regular expressions would be ignored during replacement (:issue:`35680`)\n- Fixed regression in :meth:`.DataFrameGroupBy.aggregate` where a list of functions would produce the wrong results if at least one of the functions did not aggregate (:issue:`35490`)\n- Fixed memory usage issue when instantiating large :class:`pandas.arrays.StringArray` (:issue:`35499`)\n\n.. ---------------------------------------------------------------------------\n\n.. _whatsnew_111.bug_fixes:\n\nBug fixes\n~~~~~~~~~\n\n- Bug in :class:`~pandas.io.formats.style.Styler` whereby ``cell_ids`` argument had no effect due to other recent changes (:issue:`35588`) (:issue:`35663`)\n- Bug in :func:`pandas.testing.assert_series_equal` and :func:`pandas.testing.assert_frame_equal` where extension dtypes were not ignored when ``check_dtypes`` was set to ``False`` (:issue:`35715`)\n- Bug in :meth:`to_timedelta` fails when ``arg`` is a :class:`Series` with ``Int64`` dtype containing null values (:issue:`35574`)\n- Bug in ``.groupby(..).rolling(..)`` where passing ``closed`` with column selection would raise a ``ValueError`` (:issue:`35549`)\n- Bug in :class:`DataFrame` constructor failing to raise ``ValueError`` in some cases when ``data`` and ``index`` have mismatched lengths (:issue:`33437`)\n\n.. ---------------------------------------------------------------------------\n\n.. _whatsnew_111.contributors:\n\nContributors\n~~~~~~~~~~~~\n\n.. contributors:: v1.1.0..v1.1.1\n\n\n.. _whatsnew_0900:\n\n{{ header }}\n\n\nVersion 0.9.0 (October 7, 2012)\n-------------------------------\n\nThis is a major release from 0.8.1 and includes several new features and\nenhancements along with a large number of bug fixes. New features include\nvectorized unicode encoding/decoding for ``Series.str``, ``to_latex`` method to\nDataFrame, more flexible parsing of boolean values, and enabling the download of\noptions data from Yahoo! Finance.\n\nNew features\n~~~~~~~~~~~~\n\n  - Add ``encode`` and ``decode`` for unicode handling to :ref:`vectorized\n    string processing methods <text.string_methods>` in Series.str  (:issue:`1706`)\n  - Add ``DataFrame.to_latex`` method (:issue:`1735`)\n  - Add convenient expanding window equivalents of all rolling_* ops (:issue:`1785`)\n  - Add Options class to pandas.io.data for fetching options data from Yahoo!\n    Finance (:issue:`1748`, :issue:`1739`)\n  - More flexible parsing of boolean values (Yes, No, TRUE, FALSE, etc)\n    (:issue:`1691`, :issue:`1295`)\n  - Add ``level`` parameter to ``Series.reset_index``\n  - ``TimeSeries.between_time`` can now select times across midnight (:issue:`1871`)\n  - Series constructor can now handle generator as input (:issue:`1679`)\n  - ``DataFrame.dropna`` can now take multiple axes (tuple/list) as input\n    (:issue:`924`)\n  - Enable ``skip_footer`` parameter in ``ExcelFile.parse`` (:issue:`1843`)\n\nAPI changes\n~~~~~~~~~~~\n\n  - The default column names when ``header=None`` and no columns names passed to\n    functions like ``read_csv`` has changed to be more Pythonic and amenable to\n    attribute access:\n\n.. ipython:: python\n\n   import io\n\n   data = \"\"\"\n   0,0,1\n   1,1,0\n   0,1,0\n   \"\"\"\n   df = pd.read_csv(io.StringIO(data), header=None)\n   df\n\n\n- Creating a Series from another Series, passing an index, will cause reindexing\n  to happen inside rather than treating the Series like an ndarray. Technically\n  improper usages like ``Series(df[col1], index=df[col2])`` that worked before\n  \"by accident\" (this was never intended) will lead to all NA Series in some\n  cases. To be perfectly clear:\n\n.. ipython:: python\n\n   s1 = pd.Series([1, 2, 3])\n   s1\n\n   s2 = pd.Series(s1, index=[\"foo\", \"bar\", \"baz\"])\n   s2\n\n- Deprecated ``day_of_year`` API removed from PeriodIndex, use ``dayofyear``\n  (:issue:`1723`)\n\n- Don't modify NumPy suppress printoption to True at import time\n\n- The internal HDF5 data arrangement for DataFrames has been transposed.  Legacy\n  files will still be readable by HDFStore (:issue:`1834`, :issue:`1824`)\n\n- Legacy cruft removed: pandas.stats.misc.quantileTS\n\n- Use ISO8601 format for Period repr: monthly, daily, and on down (:issue:`1776`)\n\n- Empty DataFrame columns are now created as object dtype. This will prevent a\n  class of TypeErrors that was occurring in code where the dtype of a column\n  would depend on the presence of data or not (e.g. a SQL query having results)\n  (:issue:`1783`)\n\n- Setting parts of DataFrame/Panel using ix now aligns input Series/DataFrame\n  (:issue:`1630`)\n\n- ``first`` and ``last`` methods in ``GroupBy`` no longer drop non-numeric\n  columns (:issue:`1809`)\n\n- Resolved inconsistencies in specifying custom NA values in text parser.\n  ``na_values`` of type dict no longer override default NAs unless\n  ``keep_default_na`` is set to false explicitly (:issue:`1657`)\n\n- ``DataFrame.dot`` will not do data alignment, and also work with Series\n  (:issue:`1915`)\n\n\nSee the :ref:`full release notes\n<release>` or issue tracker\non GitHub for a complete list.\n\n\n\n.. _whatsnew_0.9.0.contributors:\n\nContributors\n~~~~~~~~~~~~\n\n.. contributors:: v0.8.1..v0.9.0\n\n\n.. _whatsnew_144:\n\nWhat's new in 1.4.4 (August 31, 2022)\n-------------------------------------\n\nThese are the changes in pandas 1.4.4. See :ref:`release` for a full changelog\nincluding other versions of pandas.\n\n{{ header }}\n\n.. ---------------------------------------------------------------------------\n\n.. _whatsnew_144.regressions:\n\nFixed regressions\n~~~~~~~~~~~~~~~~~\n- Fixed regression in :meth:`DataFrame.fillna` not working on a :class:`DataFrame` with a :class:`MultiIndex` (:issue:`47649`)\n- Fixed regression in taking NULL :class:`objects` from a :class:`DataFrame` causing a segmentation violation. These NULL values are created by :meth:`numpy.empty_like` (:issue:`46848`)\n- Fixed regression in :func:`concat` materializing the :class:`Index` during sorting even if the :class:`Index` was already sorted (:issue:`47501`)\n- Fixed regression in :func:`concat` or :func:`merge` handling of all-NaN ExtensionArrays with custom attributes (:issue:`47762`)\n- Fixed regression in calling bitwise numpy ufuncs (for example, ``np.bitwise_and``) on Index objects (:issue:`46769`)\n- Fixed regression in :func:`cut` when using a ``datetime64`` IntervalIndex as bins (:issue:`46218`)\n- Fixed regression in :meth:`DataFrame.select_dtypes` where ``include=\"number\"`` included :class:`BooleanDtype` (:issue:`46870`)\n- Fixed regression in :meth:`DataFrame.loc` raising error when indexing with a ``NamedTuple`` (:issue:`48124`)\n- Fixed regression in :meth:`DataFrame.loc` not updating the cache correctly after values were set (:issue:`47867`)\n- Fixed regression in :meth:`DataFrame.loc` not aligning index in some cases when setting a :class:`DataFrame` (:issue:`47578`)\n- Fixed regression in :meth:`DataFrame.loc` setting a length-1 array like value to a single value in the DataFrame (:issue:`46268`)\n- Fixed regression when slicing with :meth:`DataFrame.loc` with :class:`DatetimeIndex` with a :class:`.DateOffset` object for its ``freq`` (:issue:`46671`)\n- Fixed regression in setting ``None`` or non-string value into a ``string``-dtype Series using a mask (:issue:`47628`)\n- Fixed regression in updating a DataFrame column through Series ``__setitem__`` (using chained assignment) not updating column values inplace and using too much memory (:issue:`47172`)\n- Fixed regression in :meth:`DataFrame.select_dtypes` returning a view on the original DataFrame (:issue:`48090`)\n- Fixed regression using custom Index subclasses (for example, used in xarray) with :meth:`~DataFrame.reset_index` or :meth:`Index.insert` (:issue:`47071`)\n- Fixed regression in :meth:`~Index.intersection` when the :class:`DatetimeIndex` has dates crossing daylight savings time (:issue:`46702`)\n- Fixed regression in :func:`merge` throwing an error when passing a :class:`Series` with a multi-level name (:issue:`47946`)\n- Fixed regression in :meth:`DataFrame.eval` creating a copy when updating inplace (:issue:`47449`)\n- Fixed regression where getting a row using :meth:`DataFrame.iloc` with :class:`SparseDtype` would raise (:issue:`46406`)\n\n.. ---------------------------------------------------------------------------\n\n.. _whatsnew_144.bug_fixes:\n\nBug fixes\n~~~~~~~~~\n- The ``FutureWarning`` raised when passing arguments (other than ``filepath_or_buffer``) as positional in :func:`read_csv` is now raised at the correct stacklevel (:issue:`47385`)\n- Bug in :meth:`DataFrame.to_sql` when ``method`` was a ``callable`` that did not return an ``int`` and would raise a ``TypeError`` (:issue:`46891`)\n- Bug in :meth:`.DataFrameGroupBy.value_counts` where ``subset`` had no effect (:issue:`46383`)\n- Bug when getting values with :meth:`DataFrame.loc` with a list of keys causing an internal inconsistency that could lead to a disconnect between ``frame.at[x, y]`` vs ``frame[y].loc[x]`` (:issue:`22372`)\n- Bug in the :meth:`Series.dt.strftime` accessor return a float instead of object dtype Series for all-NaT input, which also causes a spurious deprecation warning (:issue:`45858`)\n\n.. ---------------------------------------------------------------------------\n\n.. _whatsnew_144.other:\n\nOther\n~~~~~\n- The minimum version of Cython needed to compile pandas is now ``0.29.32`` (:issue:`47978`)\n\n.. ---------------------------------------------------------------------------\n\n.. _whatsnew_144.contributors:\n\nContributors\n~~~~~~~~~~~~\n\n.. contributors:: v1.4.3..v1.4.4|HEAD\n\n\n.. _whatsnew_0242:\n\nWhat's new in 0.24.2 (March 12, 2019)\n-------------------------------------\n\n.. warning::\n\n   The 0.24.x series of releases will be the last to support Python 2. Future feature\n   releases will support Python 3 only. See `Dropping Python 2.7 <https://pandas.pydata.org/pandas-docs/version/0.24/install.html#install-dropping-27>`_ for more.\n\n{{ header }}\n\nThese are the changes in pandas 0.24.2. See :ref:`release` for a full changelog\nincluding other versions of pandas.\n\n.. _whatsnew_0242.regressions:\n\nFixed regressions\n~~~~~~~~~~~~~~~~~\n\n- Fixed regression in :meth:`DataFrame.all` and :meth:`DataFrame.any` where ``bool_only=True`` was ignored (:issue:`25101`)\n- Fixed issue in ``DataFrame`` construction with passing a mixed list of mixed types could segfault. (:issue:`25075`)\n- Fixed regression in :meth:`DataFrame.apply` causing ``RecursionError`` when ``dict``-like classes were passed as argument. (:issue:`25196`)\n- Fixed regression in :meth:`DataFrame.replace` where ``regex=True`` was only replacing patterns matching the start of the string (:issue:`25259`)\n- Fixed regression in :meth:`DataFrame.duplicated()`, where empty dataframe was not returning a boolean dtyped Series. (:issue:`25184`)\n- Fixed regression in :meth:`Series.min` and :meth:`Series.max` where ``numeric_only=True`` was ignored when the ``Series`` contained ``Categorical`` data (:issue:`25299`)\n- Fixed regression in subtraction between :class:`Series` objects with ``datetime64[ns]`` dtype incorrectly raising ``OverflowError`` when the ``Series`` on the right contains null values (:issue:`25317`)\n- Fixed regression in :class:`TimedeltaIndex` where ``np.sum(index)`` incorrectly returned a zero-dimensional object instead of a scalar (:issue:`25282`)\n- Fixed regression in ``IntervalDtype`` construction where passing an incorrect string with 'Interval' as a prefix could result in a ``RecursionError``. (:issue:`25338`)\n- Fixed regression in creating a period-dtype array from a read-only NumPy array of period objects. (:issue:`25403`)\n- Fixed regression in :class:`Categorical`, where constructing it from a categorical ``Series`` and an explicit ``categories=`` that differed from that in the ``Series`` created an invalid object which could trigger segfaults. (:issue:`25318`)\n- Fixed regression in :func:`to_timedelta` losing precision when converting floating data to ``Timedelta`` data (:issue:`25077`).\n- Fixed pip installing from source into an environment without NumPy (:issue:`25193`)\n- Fixed regression in :meth:`DataFrame.replace` where large strings of numbers would be coerced into ``int64``, causing an ``OverflowError`` (:issue:`25616`)\n- Fixed regression in :func:`factorize` when passing a custom ``na_sentinel`` value with ``sort=True`` (:issue:`25409`).\n- Fixed regression in :meth:`DataFrame.to_csv` writing duplicate line endings with gzip compress (:issue:`25311`)\n\n.. _whatsnew_0242.bug_fixes:\n\nBug fixes\n~~~~~~~~~\n\n**I/O**\n\n- Better handling of terminal printing when the terminal dimensions are not known (:issue:`25080`)\n- Bug in reading a HDF5 table-format ``DataFrame`` created in Python 2, in Python 3 (:issue:`24925`)\n- Bug in reading a JSON with ``orient='table'`` generated by :meth:`DataFrame.to_json` with ``index=False`` (:issue:`25170`)\n- Bug where float indexes could have misaligned values when printing (:issue:`25061`)\n\n**Categorical**\n\n- Bug where calling :meth:`Series.replace` on categorical data could return a ``Series`` with incorrect dimensions (:issue:`24971`)\n-\n\n**Reshaping**\n\n- Bug in :meth:`.GroupBy.transform` where applying a function to a timezone aware column would return a timezone naive result (:issue:`24198`)\n- Bug in :func:`DataFrame.join` when joining on a timezone aware :class:`DatetimeIndex` (:issue:`23931`)\n\n**Visualization**\n\n- Bug in :meth:`Series.plot` where a secondary y axis could not be set to log scale (:issue:`25545`)\n\n**Other**\n\n- Bug in :meth:`Series.is_unique` where single occurrences of ``NaN`` were not considered unique (:issue:`25180`)\n- Bug in :func:`merge` when merging an empty ``DataFrame`` with an ``Int64`` column or a non-empty ``DataFrame`` with an ``Int64`` column that is all ``NaN`` (:issue:`25183`)\n- Bug in ``IntervalTree`` where a ``RecursionError`` occurs upon construction due to an overflow when adding endpoints, which also causes :class:`IntervalIndex` to crash during indexing operations (:issue:`25485`)\n- Bug in :attr:`Series.size` raising for some extension-array-backed ``Series``, rather than returning the size (:issue:`25580`)\n- Bug in resampling raising for nullable integer-dtype columns (:issue:`25580`)\n\n.. _whatsnew_0242.contributors:\n\nContributors\n~~~~~~~~~~~~\n\n.. Including the contributors hardcoded for this release, as backporting with\n   MeeseeksDev loses the commit authors\n\nA total of 25 people contributed patches to this release. People with a \"+\" by their names contributed a patch for the first time.\n\n* Albert Villanova del Moral\n* Arno Veenstra +\n* chris-b1\n* Devin Petersohn +\n* EternalLearner42 +\n* Flavien Lambert +\n* gfyoung\n* Gioia Ballin\n* jbrockmendel\n* Jeff Reback\n* Jeremy Schendel\n* Johan von Forstner +\n* Joris Van den Bossche\n* Josh\n* Justin Zheng\n* Kendall Masse\n* Matthew Roeschke\n* Max Bolingbroke +\n* rbenes +\n* Sterling Paramore +\n* Tao He +\n* Thomas A Caswell\n* Tom Augspurger\n* Vibhu Agarwal +\n* William Ayd\n* Zach Angell\n\n\n.. _whatsnew_0230:\n\nWhat's new in 0.23.0 (May 15, 2018)\n-----------------------------------\n\n{{ header }}\n\n.. ipython:: python\n   :suppress:\n\n   from pandas import *  noqa F401, F403\n\n\nThis is a major release from 0.22.0 and includes a number of API changes,\ndeprecations, new features, enhancements, and performance improvements along\nwith a large number of bug fixes. We recommend that all users upgrade to this\nversion.\n\nHighlights include:\n\n- :ref:`Round-trippable JSON format with 'table' orient <whatsnew_0230.enhancements.round-trippable_json>`.\n- :ref:`Instantiation from dicts respects order for Python 3.6+ <whatsnew_0230.api_breaking.dict_insertion_order>`.\n- :ref:`Dependent column arguments for assign <whatsnew_0230.enhancements.assign_dependent>`.\n- :ref:`Merging / sorting on a combination of columns and index levels <whatsnew_0230.enhancements.merge_on_columns_and_levels>`.\n- :ref:`Extending pandas with custom types <whatsnew_023.enhancements.extension>`.\n- :ref:`Excluding unobserved categories from groupby <whatsnew_0230.enhancements.categorical_grouping>`.\n- :ref:`Changes to make output shape of DataFrame.apply consistent <whatsnew_0230.api_breaking.apply>`.\n\nCheck the :ref:`API Changes <whatsnew_0230.api_breaking>` and :ref:`deprecations <whatsnew_0230.deprecations>` before updating.\n\n.. warning::\n\n   Starting January 1, 2019, pandas feature releases will support Python 3 only.\n   See `Dropping Python 2.7 <https://pandas.pydata.org/pandas-docs/version/0.24/install.html#install-dropping-27>`_ for more.\n\n.. contents:: What's new in v0.23.0\n    :local:\n    :backlinks: none\n    :depth: 2\n\n.. _whatsnew_0230.enhancements:\n\nNew features\n~~~~~~~~~~~~\n\n.. _whatsnew_0230.enhancements.round-trippable_json:\n\nJSON read/write round-trippable with ``orient='table'``\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nA ``DataFrame`` can now be written to and subsequently read back via JSON while preserving metadata through usage of the ``orient='table'`` argument (see :issue:`18912` and :issue:`9146`). Previously, none of the available ``orient`` values guaranteed the preservation of dtypes and index names, amongst other metadata.\n\n.. ipython:: python\n\n   df = pd.DataFrame({'foo': [1, 2, 3, 4],\n                      'bar': ['a', 'b', 'c', 'd'],\n                      'baz': pd.date_range('2018-01-01', freq='d', periods=4),\n                      'qux': pd.Categorical(['a', 'b', 'c', 'c'])},\n                     index=pd.Index(range(4), name='idx'))\n   df\n   df.dtypes\n   df.to_json('test.json', orient='table')\n   new_df = pd.read_json('test.json', orient='table')\n   new_df\n   new_df.dtypes\n\nPlease note that the string ``index`` is not supported with the round trip format, as it is used by default in ``write_json`` to indicate a missing index name.\n\n.. ipython:: python\n   :okwarning:\n\n   df.index.name = 'index'\n\n   df.to_json('test.json', orient='table')\n   new_df = pd.read_json('test.json', orient='table')\n   new_df\n   new_df.dtypes\n\n.. ipython:: python\n   :suppress:\n\n   import os\n   os.remove('test.json')\n\n\n.. _whatsnew_0230.enhancements.assign_dependent:\n\n\nMethod ``.assign()`` accepts dependent arguments\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nThe :func:`DataFrame.assign` now accepts dependent keyword arguments for python version later than 3.6 (see also `PEP 468\n<https://www.python.org/dev/peps/pep-0468/>`_). Later keyword arguments may now refer to earlier ones if the argument is a callable. See the\n:ref:`documentation here <dsintro.chained_assignment>` (:issue:`14207`)\n\n.. ipython:: python\n\n    df = pd.DataFrame({'A': [1, 2, 3]})\n    df\n    df.assign(B=df.A, C=lambda x: x['A'] + x['B'])\n\n.. warning::\n\n  This may subtly change the behavior of your code when you're\n  using ``.assign()`` to update an existing column. Previously, callables\n  referring to other variables being updated would get the \"old\" values\n\n  Previous behavior:\n\n  .. code-block:: ipython\n\n      In [2]: df = pd.DataFrame({\"A\": [1, 2, 3]})\n\n      In [3]: df.assign(A=lambda df: df.A + 1, C=lambda df: df.A * -1)\n      Out[3]:\n         A  C\n      0  2 -1\n      1  3 -2\n      2  4 -3\n\n  New behavior:\n\n  .. ipython:: python\n\n      df.assign(A=df.A + 1, C=lambda df: df.A * -1)\n\n\n\n.. _whatsnew_0230.enhancements.merge_on_columns_and_levels:\n\nMerging on a combination of columns and index levels\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nStrings passed to :meth:`DataFrame.merge` as the ``on``, ``left_on``, and ``right_on``\nparameters may now refer to either column names or index level names.\nThis enables merging ``DataFrame`` instances on a combination of index levels\nand columns without resetting indexes. See the :ref:`Merge on columns and\nlevels <merging.merge_on_columns_and_levels>` documentation section.\n(:issue:`14355`)\n\n.. ipython:: python\n\n   left_index = pd.Index(['K0', 'K0', 'K1', 'K2'], name='key1')\n\n   left = pd.DataFrame({'A': ['A0', 'A1', 'A2', 'A3'],\n                        'B': ['B0', 'B1', 'B2', 'B3'],\n                        'key2': ['K0', 'K1', 'K0', 'K1']},\n                       index=left_index)\n\n   right_index = pd.Index(['K0', 'K1', 'K2', 'K2'], name='key1')\n\n   right = pd.DataFrame({'C': ['C0', 'C1', 'C2', 'C3'],\n                         'D': ['D0', 'D1', 'D2', 'D3'],\n                         'key2': ['K0', 'K0', 'K0', 'K1']},\n                        index=right_index)\n\n   left.merge(right, on=['key1', 'key2'])\n\n.. _whatsnew_0230.enhancements.sort_by_columns_and_levels:\n\nSorting by a combination of columns and index levels\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nStrings passed to :meth:`DataFrame.sort_values` as the ``by`` parameter may\nnow refer to either column names or index level names.  This enables sorting\n``DataFrame`` instances by a combination of index levels and columns without\nresetting indexes. See the :ref:`Sorting by Indexes and Values\n<basics.sort_indexes_and_values>` documentation section.\n(:issue:`14353`)\n\n.. ipython:: python\n\n    Build MultiIndex\n   idx = pd.MultiIndex.from_tuples([('a', 1), ('a', 2), ('a', 2),\n                                    ('b', 2), ('b', 1), ('b', 1)])\n   idx.names = ['first', 'second']\n\n    Build DataFrame\n   df_multi = pd.DataFrame({'A': np.arange(6, 0, -1)},\n                           index=idx)\n   df_multi\n\n    Sort by 'second' (index) and 'A' (column)\n   df_multi.sort_values(by=['second', 'A'])\n\n\n.. _whatsnew_023.enhancements.extension:\n\nExtending pandas with custom types (experimental)\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\npandas now supports storing array-like objects that aren't necessarily 1-D NumPy\narrays as columns in a DataFrame or values in a Series. This allows third-party\nlibraries to implement extensions to NumPy's types, similar to how pandas\nimplemented categoricals, datetimes with timezones, periods, and intervals.\n\nAs a demonstration, we'll use cyberpandas_, which provides an ``IPArray`` type\nfor storing ip addresses.\n\n.. code-block:: ipython\n\n   In [1]: from cyberpandas import IPArray\n\n   In [2]: values = IPArray([\n      ...:     0,\n      ...:     3232235777,\n      ...:     42540766452641154071740215577757643572\n      ...: ])\n      ...:\n      ...:\n\n``IPArray`` isn't a normal 1-D NumPy array, but because it's a pandas\n:class:`~pandas.api.extensions.ExtensionArray`, it can be stored properly inside pandas' containers.\n\n.. code-block:: ipython\n\n   In [3]: ser = pd.Series(values)\n\n   In [4]: ser\n   Out[4]:\n   0                         0.0.0.0\n   1                     192.168.1.1\n   2    2001:db8:85a3::8a2e:370:7334\n   dtype: ip\n\nNotice that the dtype is ``ip``. The missing value semantics of the underlying\narray are respected:\n\n.. code-block:: ipython\n\n   In [5]: ser.isna()\n   Out[5]:\n   0     True\n   1    False\n   2    False\n   dtype: bool\n\nFor more, see the :ref:`extension types <extending.extension-types>`\ndocumentation. If you build an extension array, publicize it on `the ecosystem page <https://pandas.pydata.org/community/ecosystem.html>`_.\n\n.. _cyberpandas: https://cyberpandas.readthedocs.io/en/latest/\n\n\n.. _whatsnew_0230.enhancements.categorical_grouping:\n\nNew ``observed`` keyword for excluding unobserved categories in ``GroupBy``\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nGrouping by a categorical includes the unobserved categories in the output.\nWhen grouping by multiple categorical columns, this means you get the cartesian product of all the\ncategories, including combinations where there are no observations, which can result in a large\nnumber of groups. We have added a keyword ``observed`` to control this behavior, it defaults to\n``observed=False`` for backward-compatibility. (:issue:`14942`, :issue:`8138`, :issue:`15217`, :issue:`17594`, :issue:`8669`, :issue:`20583`, :issue:`20902`)\n\n.. ipython:: python\n\n   cat1 = pd.Categorical([\"a\", \"a\", \"b\", \"b\"],\n                         categories=[\"a\", \"b\", \"z\"], ordered=True)\n   cat2 = pd.Categorical([\"c\", \"d\", \"c\", \"d\"],\n                         categories=[\"c\", \"d\", \"y\"], ordered=True)\n   df = pd.DataFrame({\"A\": cat1, \"B\": cat2, \"values\": [1, 2, 3, 4]})\n   df['C'] = ['foo', 'bar'] * 2\n   df\n\nTo show all values, the previous behavior:\n\n.. ipython:: python\n\n   df.groupby(['A', 'B', 'C'], observed=False).count()\n\n\nTo show only observed values:\n\n.. ipython:: python\n\n   df.groupby(['A', 'B', 'C'], observed=True).count()\n\nFor pivoting operations, this behavior is *already* controlled by the ``dropna`` keyword:\n\n.. ipython:: python\n\n   cat1 = pd.Categorical([\"a\", \"a\", \"b\", \"b\"],\n                         categories=[\"a\", \"b\", \"z\"], ordered=True)\n   cat2 = pd.Categorical([\"c\", \"d\", \"c\", \"d\"],\n                         categories=[\"c\", \"d\", \"y\"], ordered=True)\n   df = pd.DataFrame({\"A\": cat1, \"B\": cat2, \"values\": [1, 2, 3, 4]})\n   df\n\n\n.. code-block:: ipython\n\n    In [1]: pd.pivot_table(df, values='values', index=['A', 'B'], dropna=True)\n\n    Out[1]:\n         values\n    A B\n    a c     1.0\n      d     2.0\n    b c     3.0\n      d     4.0\n\n    In [2]: pd.pivot_table(df, values='values', index=['A', 'B'], dropna=False)\n\n    Out[2]:\n         values\n    A B\n    a c     1.0\n      d     2.0\n      y     NaN\n    b c     3.0\n      d     4.0\n      y     NaN\n    z c     NaN\n      d     NaN\n      y     NaN\n\n\n.. _whatsnew_0230.enhancements.window_raw:\n\nRolling/Expanding.apply() accepts ``raw=False`` to pass a ``Series`` to the function\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n:func:`Series.rolling().apply() <.Rolling.apply>`, :func:`DataFrame.rolling().apply() <.Rolling.apply>`,\n:func:`Series.expanding().apply() <.Expanding.apply>`, and :func:`DataFrame.expanding().apply() <.Expanding.apply>` have gained a ``raw=None`` parameter.\nThis is similar to :func:`DataFame.apply`. This parameter, if ``True`` allows one to send a ``np.ndarray`` to the applied function. If ``False`` a ``Series`` will be passed. The\ndefault is ``None``, which preserves backward compatibility, so this will default to ``True``, sending an ``np.ndarray``.\nIn a future version the default will be changed to ``False``, sending a ``Series``. (:issue:`5071`, :issue:`20584`)\n\n.. ipython:: python\n\n   s = pd.Series(np.arange(5), np.arange(5) + 1)\n   s\n\nPass a ``Series``:\n\n.. ipython:: python\n\n   s.rolling(2, min_periods=1).apply(lambda x: x.iloc[-1], raw=False)\n\nMimic the original behavior of passing a ndarray:\n\n.. ipython:: python\n\n   s.rolling(2, min_periods=1).apply(lambda x: x[-1], raw=True)\n\n\n.. _whatsnew_0210.enhancements.limit_area:\n\n``DataFrame.interpolate`` has gained the ``limit_area`` kwarg\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n:meth:`DataFrame.interpolate` has gained a ``limit_area`` parameter to allow further control of which ``NaN`` s are replaced.\nUse ``limit_area='inside'`` to fill only NaNs surrounded by valid values or use ``limit_area='outside'`` to fill only ``NaN`` s\noutside the existing valid values while preserving those inside.  (:issue:`16284`) See the :ref:`full documentation here <missing_data.interp_limits>`.\n\n\n.. ipython:: python\n\n   ser = pd.Series([np.nan, np.nan, 5, np.nan, np.nan,\n                    np.nan, 13, np.nan, np.nan])\n   ser\n\nFill one consecutive inside value in both directions\n\n.. ipython:: python\n\n   ser.interpolate(limit_direction='both', limit_area='inside', limit=1)\n\nFill all consecutive outside values backward\n\n.. ipython:: python\n\n   ser.interpolate(limit_direction='backward', limit_area='outside')\n\nFill all consecutive outside values in both directions\n\n.. ipython:: python\n\n   ser.interpolate(limit_direction='both', limit_area='outside')\n\n.. _whatsnew_0210.enhancements.get_dummies_dtype:\n\nFunction ``get_dummies`` now supports ``dtype`` argument\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nThe :func:`get_dummies` now accepts a ``dtype`` argument, which specifies a dtype for the new columns. The default remains uint8. (:issue:`18330`)\n\n.. ipython:: python\n\n   df = pd.DataFrame({'a': [1, 2], 'b': [3, 4], 'c': [5, 6]})\n   pd.get_dummies(df, columns=['c']).dtypes\n   pd.get_dummies(df, columns=['c'], dtype=bool).dtypes\n\n\n.. _whatsnew_0230.enhancements.timedelta_mod:\n\nTimedelta mod method\n^^^^^^^^^^^^^^^^^^^^\n\n``mod`` (%) and ``divmod`` operations are now defined on ``Timedelta`` objects\nwhen operating with either timedelta-like or with numeric arguments.\nSee the :ref:`documentation here <timedeltas.mod_divmod>`. (:issue:`19365`)\n\n.. ipython:: python\n\n    td = pd.Timedelta(hours=37)\n    td % pd.Timedelta(minutes=45)\n\n.. _whatsnew_0230.enhancements.ran_inf:\n\nMethod ``.rank()`` handles ``inf`` values when ``NaN`` are present\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nIn previous versions, ``.rank()`` would assign ``inf`` elements ``NaN`` as their ranks. Now ranks are calculated properly. (:issue:`6945`)\n\n.. ipython:: python\n\n    s = pd.Series([-np.inf, 0, 1, np.nan, np.inf])\n    s\n\nPrevious behavior:\n\n.. code-block:: ipython\n\n    In [11]: s.rank()\n    Out[11]:\n    0    1.0\n    1    2.0\n    2    3.0\n    3    NaN\n    4    NaN\n    dtype: float64\n\nCurrent behavior:\n\n.. ipython:: python\n\n    s.rank()\n\nFurthermore, previously if you rank ``inf`` or ``-inf`` values together with ``NaN`` values, the calculation won't distinguish ``NaN`` from infinity when using 'top' or 'bottom' argument.\n\n.. ipython:: python\n\n    s = pd.Series([np.nan, np.nan, -np.inf, -np.inf])\n    s\n\nPrevious behavior:\n\n.. code-block:: ipython\n\n    In [15]: s.rank(na_option='top')\n    Out[15]:\n    0    2.5\n    1    2.5\n    2    2.5\n    3    2.5\n    dtype: float64\n\nCurrent behavior:\n\n.. ipython:: python\n\n    s.rank(na_option='top')\n\nThese bugs were squashed:\n\n- Bug in :meth:`DataFrame.rank` and :meth:`Series.rank` when ``method='dense'`` and ``pct=True`` in which percentile ranks were not being used with the number of distinct observations (:issue:`15630`)\n- Bug in :meth:`Series.rank` and :meth:`DataFrame.rank` when ``ascending='False'`` failed to return correct ranks for infinity if ``NaN`` were present (:issue:`19538`)\n- Bug in :func:`DataFrameGroupBy.rank` where ranks were incorrect when both infinity and ``NaN`` were present (:issue:`20561`)\n\n\n.. _whatsnew_0230.enhancements.str_cat_align:\n\n``Series.str.cat`` has gained the ``join`` kwarg\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nPreviously, :meth:`Series.str.cat` did not -- in contrast to most of ``pandas`` -- align :class:`Series` on their index before concatenation (see :issue:`18657`).\nThe method has now gained a keyword ``join`` to control the manner of alignment, see examples below and :ref:`here <text.concatenate>`.\n\nIn v.0.23 ``join`` will default to None (meaning no alignment), but this default will change to ``'left'`` in a future version of pandas.\n\n.. ipython:: python\n   :okwarning:\n\n    s = pd.Series(['a', 'b', 'c', 'd'])\n    t = pd.Series(['b', 'd', 'e', 'c'], index=[1, 3, 4, 2])\n    s.str.cat(t)\n    s.str.cat(t, join='left', na_rep='-')\n\nFurthermore, :meth:`Series.str.cat` now works for ``CategoricalIndex`` as well (previously raised a ``ValueError``; see :issue:`20842`).\n\n.. _whatsnew_0230.enhancements.astype_category:\n\n``DataFrame.astype`` performs column-wise conversion to ``Categorical``\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n:meth:`DataFrame.astype` can now perform column-wise conversion to ``Categorical`` by supplying the string ``'category'`` or\na :class:`~pandas.api.types.CategoricalDtype`. Previously, attempting this would raise a ``NotImplementedError``. See the\n:ref:`categorical.objectcreation` section of the documentation for more details and examples. (:issue:`12860`, :issue:`18099`)\n\nSupplying the string ``'category'`` performs column-wise conversion, with only labels appearing in a given column set as categories:\n\n.. ipython:: python\n\n    df = pd.DataFrame({'A': list('abca'), 'B': list('bccd')})\n    df = df.astype('category')\n    df['A'].dtype\n    df['B'].dtype\n\n\nSupplying a ``CategoricalDtype`` will make the categories in each column consistent with the supplied dtype:\n\n.. ipython:: python\n\n    from pandas.api.types import CategoricalDtype\n    df = pd.DataFrame({'A': list('abca'), 'B': list('bccd')})\n    cdt = CategoricalDtype(categories=list('abcd'), ordered=True)\n    df = df.astype(cdt)\n    df['A'].dtype\n    df['B'].dtype\n\n\n.. _whatsnew_0230.enhancements.other:\n\nOther enhancements\n^^^^^^^^^^^^^^^^^^\n\n- Unary ``+`` now permitted for ``Series`` and ``DataFrame`` as  numeric operator (:issue:`16073`)\n- Better support for :meth:`~pandas.io.formats.style.Styler.to_excel` output with the ``xlsxwriter`` engine. (:issue:`16149`)\n- :func:`pandas.tseries.frequencies.to_offset` now accepts leading '+' signs e.g. '+1h'. (:issue:`18171`)\n- :func:`MultiIndex.unique` now supports the ``level=`` argument, to get unique values from a specific index level (:issue:`17896`)\n- :class:`pandas.io.formats.style.Styler` now has method ``hide_index()`` to determine whether the index will be rendered in output (:issue:`14194`)\n- :class:`pandas.io.formats.style.Styler` now has method ``hide_columns()`` to determine whether columns will be hidden in output (:issue:`14194`)\n- Improved wording of ``ValueError`` raised in :func:`to_datetime` when ``unit=`` is passed with a non-convertible value (:issue:`14350`)\n- :func:`Series.fillna` now accepts a Series or a dict as a ``value`` for a categorical dtype (:issue:`17033`)\n- :func:`pandas.read_clipboard` updated to use qtpy, falling back to PyQt5 and then PyQt4, adding compatibility with Python3 and multiple python-qt bindings (:issue:`17722`)\n- Improved wording of ``ValueError`` raised in :func:`read_csv` when the ``usecols`` argument cannot match all columns. (:issue:`17301`)\n- :func:`DataFrame.corrwith` now silently drops non-numeric columns when passed a Series. Before, an exception was raised (:issue:`18570`).\n- :class:`IntervalIndex` now supports time zone aware ``Interval`` objects (:issue:`18537`, :issue:`18538`)\n- :func:`Series` / :func:`DataFrame` tab completion also returns identifiers in the first level of a :func:`MultiIndex`. (:issue:`16326`)\n- :func:`read_excel()` has gained the ``nrows`` parameter (:issue:`16645`)\n- :meth:`DataFrame.append` can now in more cases preserve the type of the calling dataframe's columns (e.g. if both are ``CategoricalIndex``) (:issue:`18359`)\n- :meth:`DataFrame.to_json` and :meth:`Series.to_json` now accept an ``index`` argument which allows the user to exclude the index from the JSON output (:issue:`17394`)\n- ``IntervalIndex.to_tuples()`` has gained the ``na_tuple`` parameter to control whether NA is returned as a tuple of NA, or NA itself (:issue:`18756`)\n- ``Categorical.rename_categories``, ``CategoricalIndex.rename_categories`` and :attr:`Series.cat.rename_categories`\n  can now take a callable as their argument (:issue:`18862`)\n- :class:`Interval` and :class:`IntervalIndex` have gained a ``length`` attribute (:issue:`18789`)\n- ``Resampler`` objects now have a functioning :attr:`.Resampler.pipe` method.\n  Previously, calls to ``pipe`` were diverted to  the ``mean`` method (:issue:`17905`).\n- :func:`~pandas.api.types.is_scalar` now returns ``True`` for ``DateOffset`` objects (:issue:`18943`).\n- :func:`DataFrame.pivot` now accepts a list for the ``values=`` kwarg (:issue:`17160`).\n- Added :func:`pandas.api.extensions.register_dataframe_accessor`,\n  :func:`pandas.api.extensions.register_series_accessor`, and\n  :func:`pandas.api.extensions.register_index_accessor`, accessor for libraries downstream of pandas\n  to register custom accessors like ``.cat`` on pandas objects. See\n  :ref:`Registering Custom Accessors <extending.register-accessors>` for more (:issue:`14781`).\n\n- ``IntervalIndex.astype`` now supports conversions between subtypes when passed an ``IntervalDtype`` (:issue:`19197`)\n- :class:`IntervalIndex` and its associated constructor methods (``from_arrays``, ``from_breaks``, ``from_tuples``) have gained a ``dtype`` parameter (:issue:`19262`)\n- Added :func:`.SeriesGroupBy.is_monotonic_increasing` and :func:`.SeriesGroupBy.is_monotonic_decreasing` (:issue:`17015`)\n- For subclassed ``DataFrames``, :func:`DataFrame.apply` will now preserve the ``Series`` subclass (if defined) when passing the data to the applied function (:issue:`19822`)\n- :func:`DataFrame.from_dict` now accepts a ``columns`` argument that can be used to specify the column names when ``orient='index'`` is used (:issue:`18529`)\n- Added option ``display.html.use_mathjax`` so `MathJax <https://www.mathjax.org/>`_ can be disabled when rendering tables in ``Jupyter`` notebooks (:issue:`19856`, :issue:`19824`)\n- :func:`DataFrame.replace` now supports the ``method`` parameter, which can be used to specify the replacement method when ``to_replace`` is a scalar, list or tuple and ``value`` is ``None`` (:issue:`19632`)\n- :meth:`Timestamp.month_name`, :meth:`DatetimeIndex.month_name`, and :meth:`Series.dt.month_name` are now available (:issue:`12805`)\n- :meth:`Timestamp.day_name` and :meth:`DatetimeIndex.day_name` are now available to return day names with a specified locale (:issue:`12806`)\n- :meth:`DataFrame.to_sql` now performs a multi-value insert if the underlying connection supports itk rather than inserting row by row.\n  ``SQLAlchemy`` dialects supporting multi-value inserts include: ``mysql``, ``postgresql``, ``sqlite`` and any dialect with ``supports_multivalues_insert``. (:issue:`14315`, :issue:`8953`)\n- :func:`read_html` now accepts a ``displayed_only`` keyword argument to controls whether or not hidden elements are parsed (``True`` by default) (:issue:`20027`)\n- :func:`read_html` now reads all ``<tbody>`` elements in a ``<table>``, not just the first. (:issue:`20690`)\n- :meth:`.Rolling.quantile` and :meth:`.Expanding.quantile` now accept the ``interpolation`` keyword, ``linear`` by default (:issue:`20497`)\n- zip compression is supported via ``compression=zip`` in :func:`DataFrame.to_pickle`, :func:`Series.to_pickle`, :func:`DataFrame.to_csv`, :func:`Series.to_csv`, :func:`DataFrame.to_json`, :func:`Series.to_json`. (:issue:`17778`)\n- :class:`~pandas.tseries.offsets.WeekOfMonth` constructor now supports ``n=0`` (:issue:`20517`).\n- :class:`DataFrame` and :class:`Series` now support matrix multiplication (````) operator (:issue:`10259`) for Python>=3.5\n- Updated :meth:`DataFrame.to_gbq` and :meth:`pandas.read_gbq` signature and documentation to reflect changes from\n  the pandas-gbq library version 0.4.0. Adds intersphinx mapping to pandas-gbq\n  library. (:issue:`20564`)\n- Added new writer for exporting Stata dta files in version 117, ``StataWriter117``.  This format supports exporting strings with lengths up to 2,000,000 characters (:issue:`16450`)\n- :func:`to_hdf` and :func:`read_hdf` now accept an ``errors`` keyword argument to control encoding error handling (:issue:`20835`)\n- :func:`cut` has gained the ``duplicates='raise'|'drop'`` option to control whether to raise on duplicated edges (:issue:`20947`)\n- :func:`date_range`, :func:`timedelta_range`, and :func:`interval_range` now return a linearly spaced index if ``start``, ``stop``, and ``periods`` are specified, but ``freq`` is not. (:issue:`20808`, :issue:`20983`, :issue:`20976`)\n\n.. _whatsnew_0230.api_breaking:\n\nBackwards incompatible API changes\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\n.. _whatsnew_0230.api_breaking.deps:\n\nDependencies have increased minimum versions\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nWe have updated our minimum supported versions of dependencies (:issue:`15184`).\nIf installed, we now require:\n\n+-----------------+-----------------+----------+---------------+\n| Package         | Minimum Version | Required |     Issue     |\n+=================+=================+==========+===============+\n| python-dateutil | 2.5.0           |    X     | :issue:`15184`|\n+-----------------+-----------------+----------+---------------+\n| openpyxl        | 2.4.0           |          | :issue:`15184`|\n+-----------------+-----------------+----------+---------------+\n| beautifulsoup4  | 4.2.1           |          | :issue:`20082`|\n+-----------------+-----------------+----------+---------------+\n| setuptools      | 24.2.0          |          | :issue:`20698`|\n+-----------------+-----------------+----------+---------------+\n\n.. _whatsnew_0230.api_breaking.dict_insertion_order:\n\nInstantiation from dicts preserves dict insertion order for Python 3.6+\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nUntil Python 3.6, dicts in Python had no formally defined ordering. For Python\nversion 3.6 and later, dicts are ordered by insertion order, see\n`PEP 468 <https://www.python.org/dev/peps/pep-0468/>`_.\npandas will use the dict's insertion order, when creating a ``Series`` or\n``DataFrame`` from a dict and you're using Python version 3.6 or\nhigher. (:issue:`19884`)\n\nPrevious behavior (and current behavior if on Python < 3.6):\n\n.. code-block:: ipython\n\n    In [16]: pd.Series({'Income': 2000,\n       ....:            'Expenses': -1500,\n       ....:            'Taxes': -200,\n       ....:            'Net result': 300})\n    Out[16]:\n    Expenses     -1500\n    Income        2000\n    Net result     300\n    Taxes         -200\n    dtype: int64\n\nNote the Series above is ordered alphabetically by the index values.\n\nNew behavior (for Python >= 3.6):\n\n.. ipython:: python\n\n    pd.Series({'Income': 2000,\n               'Expenses': -1500,\n               'Taxes': -200,\n               'Net result': 300})\n\nNotice that the Series is now ordered by insertion order. This new behavior is\nused for all relevant pandas types (``Series``, ``DataFrame``, ``SparseSeries``\nand ``SparseDataFrame``).\n\nIf you wish to retain the old behavior while using Python >= 3.6, you can use\n``.sort_index()``:\n\n.. ipython:: python\n\n    pd.Series({'Income': 2000,\n               'Expenses': -1500,\n               'Taxes': -200,\n               'Net result': 300}).sort_index()\n\n.. _whatsnew_0230.api_breaking.deprecate_panel:\n\nDeprecate Panel\n^^^^^^^^^^^^^^^\n\n``Panel`` was deprecated in the 0.20.x release, showing as a ``DeprecationWarning``. Using ``Panel`` will now show a ``FutureWarning``. The recommended way to represent 3-D data are\nwith a ``MultiIndex`` on a ``DataFrame`` via the :meth:`~Panel.to_frame` or with the `xarray package <http://xarray.pydata.org/en/stable/>`__. pandas\nprovides a :meth:`~Panel.to_xarray` method to automate this conversion (:issue:`13563`, :issue:`18324`).\n\n.. code-block:: ipython\n\n    In [75]: import pandas._testing as tm\n\n    In [76]: p = tm.makePanel()\n\n    In [77]: p\n    Out[77]:\n    <class 'pandas.core.panel.Panel'>\n    Dimensions: 3 (items) x 3 (major_axis) x 4 (minor_axis)\n    Items axis: ItemA to ItemC\n    Major_axis axis: 2000-01-03 00:00:00 to 2000-01-05 00:00:00\n    Minor_axis axis: A to D\n\nConvert to a MultiIndex DataFrame\n\n.. code-block:: ipython\n\n    In [78]: p.to_frame()\n    Out[78]:\n                         ItemA     ItemB     ItemC\n    major      minor\n    2000-01-03 A      0.469112  0.721555  0.404705\n               B     -1.135632  0.271860 -1.039268\n               C      0.119209  0.276232 -1.344312\n               D     -2.104569  0.113648 -0.109050\n    2000-01-04 A     -0.282863 -0.706771  0.577046\n               B      1.212112 -0.424972 -0.370647\n               C     -1.044236 -1.087401  0.844885\n               D     -0.494929 -1.478427  1.643563\n    2000-01-05 A     -1.509059 -1.039575 -1.715002\n               B     -0.173215  0.567020 -1.157892\n               C     -0.861849 -0.673690  1.075770\n               D      1.071804  0.524988 -1.469388\n\n    [12 rows x 3 columns]\n\nConvert to an xarray DataArray\n\n.. code-block:: ipython\n\n    In [79]: p.to_xarray()\n    Out[79]:\n    <xarray.DataArray (items: 3, major_axis: 3, minor_axis: 4)>\n    array([[[ 0.469112, -1.135632,  0.119209, -2.104569],\n            [-0.282863,  1.212112, -1.044236, -0.494929],\n            [-1.509059, -0.173215, -0.861849,  1.071804]],\n\n           [[ 0.721555,  0.27186 ,  0.276232,  0.113648],\n            [-0.706771, -0.424972, -1.087401, -1.478427],\n            [-1.039575,  0.56702 , -0.67369 ,  0.524988]],\n\n           [[ 0.404705, -1.039268, -1.344312, -0.10905 ],\n            [ 0.577046, -0.370647,  0.844885,  1.643563],\n            [-1.715002, -1.157892,  1.07577 , -1.469388]]])\n    Coordinates:\n      * items       (items) object 'ItemA' 'ItemB' 'ItemC'\n      * major_axis  (major_axis) datetime64[ns] 2000-01-03 2000-01-04 2000-01-05\n      * minor_axis  (minor_axis) object 'A' 'B' 'C' 'D'\n\n\n.. _whatsnew_0230.api_breaking.core_common:\n\npandas.core.common removals\n^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nThe following error & warning messages are removed from ``pandas.core.common`` (:issue:`13634`, :issue:`19769`):\n\n- ``PerformanceWarning``\n- ``UnsupportedFunctionCall``\n- ``UnsortedIndexError``\n- ``AbstractMethodError``\n\nThese are available from import from ``pandas.errors`` (since 0.19.0).\n\n\n.. _whatsnew_0230.api_breaking.apply:\n\nChanges to make output of ``DataFrame.apply`` consistent\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n:func:`DataFrame.apply` was inconsistent when applying an arbitrary user-defined-function that returned a list-like with ``axis=1``. Several bugs and inconsistencies\nare resolved. If the applied function returns a Series, then pandas will return a DataFrame; otherwise a Series will be returned, this includes the case\nwhere a list-like (e.g. ``tuple`` or ``list`` is returned) (:issue:`16353`, :issue:`17437`, :issue:`17970`, :issue:`17348`, :issue:`17892`, :issue:`18573`,\n:issue:`17602`, :issue:`18775`, :issue:`18901`, :issue:`18919`).\n\n.. ipython:: python\n\n    df = pd.DataFrame(np.tile(np.arange(3), 6).reshape(6, -1) + 1,\n                      columns=['A', 'B', 'C'])\n    df\n\nPrevious behavior: if the returned shape happened to match the length of original columns, this would return a ``DataFrame``.\nIf the return shape did not match, a ``Series`` with lists was returned.\n\n.. code-block:: python\n\n   In [3]: df.apply(lambda x: [1, 2, 3], axis=1)\n   Out[3]:\n      A  B  C\n   0  1  2  3\n   1  1  2  3\n   2  1  2  3\n   3  1  2  3\n   4  1  2  3\n   5  1  2  3\n\n   In [4]: df.apply(lambda x: [1, 2], axis=1)\n   Out[4]:\n   0    [1, 2]\n   1    [1, 2]\n   2    [1, 2]\n   3    [1, 2]\n   4    [1, 2]\n   5    [1, 2]\n   dtype: object\n\n\nNew behavior: When the applied function returns a list-like, this will now *always* return a ``Series``.\n\n.. ipython:: python\n\n    df.apply(lambda x: [1, 2, 3], axis=1)\n    df.apply(lambda x: [1, 2], axis=1)\n\nTo have expanded columns, you can use ``result_type='expand'``\n\n.. ipython:: python\n\n    df.apply(lambda x: [1, 2, 3], axis=1, result_type='expand')\n\nTo broadcast the result across the original columns (the old behaviour for\nlist-likes of the correct length), you can use ``result_type='broadcast'``.\nThe shape must match the original columns.\n\n.. ipython:: python\n\n    df.apply(lambda x: [1, 2, 3], axis=1, result_type='broadcast')\n\nReturning a ``Series`` allows one to control the exact return structure and column names:\n\n.. ipython:: python\n\n    df.apply(lambda x: pd.Series([1, 2, 3], index=['D', 'E', 'F']), axis=1)\n\n.. _whatsnew_0230.api_breaking.concat:\n\nConcatenation will no longer sort\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nIn a future version of pandas :func:`pandas.concat` will no longer sort the non-concatenation axis when it is not already aligned.\nThe current behavior is the same as the previous (sorting), but now a warning is issued when ``sort`` is not specified and the non-concatenation axis is not aligned (:issue:`4588`).\n\n.. ipython:: python\n   :okwarning:\n\n   df1 = pd.DataFrame({\"a\": [1, 2], \"b\": [1, 2]}, columns=['b', 'a'])\n   df2 = pd.DataFrame({\"a\": [4, 5]})\n\n   pd.concat([df1, df2])\n\nTo keep the previous behavior (sorting) and silence the warning, pass ``sort=True``\n\n.. ipython:: python\n\n   pd.concat([df1, df2], sort=True)\n\nTo accept the future behavior (no sorting), pass ``sort=False``\n\n.. ipython\n\n   pd.concat([df1, df2], sort=False)\n\nNote that this change also applies to :meth:`DataFrame.append`, which has also received a ``sort`` keyword for controlling this behavior.\n\n\n.. _whatsnew_0230.api_breaking.build_changes:\n\nBuild changes\n^^^^^^^^^^^^^\n\n- Building pandas for development now requires ``cython >= 0.24`` (:issue:`18613`)\n- Building from source now explicitly requires ``setuptools`` in ``setup.py`` (:issue:`18113`)\n- Updated conda recipe to be in compliance with conda-build 3.0+ (:issue:`18002`)\n\n.. _whatsnew_0230.api_breaking.index_division_by_zero:\n\nIndex division by zero fills correctly\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nDivision operations on ``Index`` and subclasses will now fill division of positive numbers by zero with ``np.inf``, division of negative numbers by zero with ``-np.inf`` and ``0 / 0`` with ``np.nan``.  This matches existing ``Series`` behavior. (:issue:`19322`, :issue:`19347`)\n\nPrevious behavior:\n\n.. code-block:: ipython\n\n    In [6]: index = pd.Int64Index([-1, 0, 1])\n\n    In [7]: index / 0\n    Out[7]: Int64Index([0, 0, 0], dtype='int64')\n\n     Previous behavior yielded different results depending on the type of zero in the divisor\n    In [8]: index / 0.0\n    Out[8]: Float64Index([-inf, nan, inf], dtype='float64')\n\n    In [9]: index = pd.UInt64Index([0, 1])\n\n    In [10]: index / np.array([0, 0], dtype=np.uint64)\n    Out[10]: UInt64Index([0, 0], dtype='uint64')\n\n    In [11]: pd.RangeIndex(1, 5) / 0\n    ZeroDivisionError: integer division or modulo by zero\n\nCurrent behavior:\n\n.. code-block:: ipython\n\n    In [12]: index = pd.Int64Index([-1, 0, 1])\n     division by zero gives -infinity where negative,\n     +infinity where positive, and NaN for 0 / 0\n    In [13]: index / 0\n\n     The result of division by zero should not depend on\n     whether the zero is int or float\n    In [14]: index / 0.0\n\n    In [15]: index = pd.UInt64Index([0, 1])\n    In [16]: index / np.array([0, 0], dtype=np.uint64)\n\n    In [17]: pd.RangeIndex(1, 5) / 0\n\n.. _whatsnew_0230.api_breaking.extract:\n\nExtraction of matching patterns from strings\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nBy default, extracting matching patterns from strings with :func:`str.extract` used to return a\n``Series`` if a single group was being extracted (a ``DataFrame`` if more than one group was\nextracted). As of pandas 0.23.0 :func:`str.extract` always returns a ``DataFrame``, unless\n``expand`` is set to ``False``. Finally, ``None`` was an accepted value for\nthe ``expand`` parameter (which was equivalent to ``False``), but now raises a ``ValueError``. (:issue:`11386`)\n\nPrevious behavior:\n\n.. code-block:: ipython\n\n    In [1]: s = pd.Series(['number 10', '12 eggs'])\n\n    In [2]: extracted = s.str.extract(r'.*(\\d\\d).*')\n\n    In [3]: extracted\n    Out [3]:\n    0    10\n    1    12\n    dtype: object\n\n    In [4]: type(extracted)\n    Out [4]:\n    pandas.core.series.Series\n\nNew behavior:\n\n.. ipython:: python\n\n    s = pd.Series(['number 10', '12 eggs'])\n    extracted = s.str.extract(r'.*(\\d\\d).*')\n    extracted\n    type(extracted)\n\nTo restore previous behavior, simply set ``expand`` to ``False``:\n\n.. ipython:: python\n\n    s = pd.Series(['number 10', '12 eggs'])\n    extracted = s.str.extract(r'.*(\\d\\d).*', expand=False)\n    extracted\n    type(extracted)\n\n.. _whatsnew_0230.api_breaking.cdt_ordered:\n\nDefault value for the ``ordered`` parameter of ``CategoricalDtype``\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nThe default value of the ``ordered`` parameter for :class:`~pandas.api.types.CategoricalDtype` has changed from ``False`` to ``None`` to allow updating of ``categories`` without impacting ``ordered``.  Behavior should remain consistent for downstream objects, such as :class:`Categorical` (:issue:`18790`)\n\nIn previous versions, the default value for the ``ordered`` parameter was ``False``.  This could potentially lead to the ``ordered`` parameter unintentionally being changed from ``True`` to ``False`` when users attempt to update ``categories`` if ``ordered`` is not explicitly specified, as it would silently default to ``False``.  The new behavior for ``ordered=None`` is to retain the existing value of ``ordered``.\n\nNew behavior:\n\n.. code-block:: ipython\n\n    In [2]: from pandas.api.types import CategoricalDtype\n\n    In [3]: cat = pd.Categorical(list('abcaba'), ordered=True, categories=list('cba'))\n\n    In [4]: cat\n    Out[4]:\n    [a, b, c, a, b, a]\n    Categories (3, object): [c < b < a]\n\n    In [5]: cdt = CategoricalDtype(categories=list('cbad'))\n\n    In [6]: cat.astype(cdt)\n    Out[6]:\n    [a, b, c, a, b, a]\n    Categories (4, object): [c < b < a < d]\n\nNotice in the example above that the converted ``Categorical`` has retained ``ordered=True``.  Had the default value for ``ordered`` remained as ``False``, the converted ``Categorical`` would have become unordered, despite ``ordered=False`` never being explicitly specified.  To change the value of ``ordered``, explicitly pass it to the new dtype, e.g. ``CategoricalDtype(categories=list('cbad'), ordered=False)``.\n\nNote that the unintentional conversion of ``ordered`` discussed above did not arise in previous versions due to separate bugs that prevented ``astype`` from doing any type of category to category conversion (:issue:`10696`, :issue:`18593`).  These bugs have been fixed in this release, and motivated changing the default value of ``ordered``.\n\n.. _whatsnew_0230.api_breaking.pretty_printing:\n\nBetter pretty-printing of DataFrames in a terminal\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nPreviously, the default value for the maximum number of columns was\n``pd.options.display.max_columns=20``. This meant that relatively wide data\nframes would not fit within the terminal width, and pandas would introduce line\nbreaks to display these 20 columns. This resulted in an output that was\nrelatively difficult to read:\n\n.. image:: ../_static/print_df_old.png\n\nIf Python runs in a terminal, the maximum number of columns is now determined\nautomatically so that the printed data frame fits within the current terminal\nwidth (``pd.options.display.max_columns=0``) (:issue:`17023`). If Python runs\nas a Jupyter kernel (such as the Jupyter QtConsole or a Jupyter notebook, as\nwell as in many IDEs), this value cannot be inferred automatically and is thus\nset to ``20`` as in previous versions. In a terminal, this results in a much\nnicer output:\n\n.. image:: ../_static/print_df_new.png\n\nNote that if you don't like the new default, you can always set this option\nyourself. To revert to the old setting, you can run this line:\n\n.. code-block:: python\n\n  pd.options.display.max_columns = 20\n\n.. _whatsnew_0230.api.datetimelike:\n\nDatetimelike API changes\n^^^^^^^^^^^^^^^^^^^^^^^^\n\n- The default ``Timedelta`` constructor now accepts an ``ISO 8601 Duration`` string as an argument (:issue:`19040`)\n- Subtracting ``NaT`` from a :class:`Series` with ``dtype='datetime64[ns]'`` returns a ``Series`` with ``dtype='timedelta64[ns]'`` instead of ``dtype='datetime64[ns]'`` (:issue:`18808`)\n- Addition or subtraction of ``NaT`` from :class:`TimedeltaIndex` will return ``TimedeltaIndex`` instead of ``DatetimeIndex`` (:issue:`19124`)\n- :func:`DatetimeIndex.shift` and :func:`TimedeltaIndex.shift` will now raise ``NullFrequencyError`` (which subclasses ``ValueError``, which was raised in older versions) when the index object frequency is ``None`` (:issue:`19147`)\n- Addition and subtraction of ``NaN`` from a :class:`Series` with ``dtype='timedelta64[ns]'`` will raise a ``TypeError`` instead of treating the ``NaN`` as ``NaT`` (:issue:`19274`)\n- ``NaT`` division with :class:`datetime.timedelta` will now return ``NaN`` instead of raising (:issue:`17876`)\n- Operations between a :class:`Series` with dtype ``dtype='datetime64[ns]'`` and a :class:`PeriodIndex` will correctly raises ``TypeError`` (:issue:`18850`)\n- Subtraction of :class:`Series` with timezone-aware ``dtype='datetime64[ns]'`` with mismatched timezones will raise ``TypeError`` instead of ``ValueError`` (:issue:`18817`)\n- :class:`Timestamp` will no longer silently ignore unused or invalid ``tz`` or ``tzinfo`` keyword arguments (:issue:`17690`)\n- :class:`Timestamp` will no longer silently ignore invalid ``freq`` arguments (:issue:`5168`)\n- :class:`CacheableOffset` and :class:`WeekDay` are no longer available in the ``pandas.tseries.offsets`` module (:issue:`17830`)\n- ``pandas.tseries.frequencies.get_freq_group()`` and ``pandas.tseries.frequencies.DAYS`` are removed from the public API (:issue:`18034`)\n- :func:`Series.truncate` and :func:`DataFrame.truncate` will raise a ``ValueError`` if the index is not sorted instead of an unhelpful ``KeyError`` (:issue:`17935`)\n- :attr:`Series.first` and :attr:`DataFrame.first` will now raise a ``TypeError``\n  rather than ``NotImplementedError`` when index is not a :class:`DatetimeIndex` (:issue:`20725`).\n- :attr:`Series.last` and :attr:`DataFrame.last` will now raise a ``TypeError``\n  rather than ``NotImplementedError`` when index is not a :class:`DatetimeIndex` (:issue:`20725`).\n- Restricted ``DateOffset`` keyword arguments. Previously, ``DateOffset`` subclasses allowed arbitrary keyword arguments which could lead to unexpected behavior. Now, only valid arguments will be accepted. (:issue:`17176`, :issue:`18226`).\n- :func:`pandas.merge` provides a more informative error message when trying to merge on timezone-aware and timezone-naive columns (:issue:`15800`)\n- For :class:`DatetimeIndex` and :class:`TimedeltaIndex` with ``freq=None``, addition or subtraction of integer-dtyped array or ``Index`` will raise ``NullFrequencyError`` instead of ``TypeError`` (:issue:`19895`)\n- :class:`Timestamp` constructor now accepts a ``nanosecond`` keyword or positional argument (:issue:`18898`)\n- :class:`DatetimeIndex` will now raise an ``AttributeError`` when the ``tz`` attribute is set after instantiation (:issue:`3746`)\n- :class:`DatetimeIndex` with a ``pytz`` timezone will now return a consistent ``pytz`` timezone (:issue:`18595`)\n\n.. _whatsnew_0230.api.other:\n\nOther API changes\n^^^^^^^^^^^^^^^^^\n\n- :func:`Series.astype` and :func:`Index.astype` with an incompatible dtype will now raise a ``TypeError`` rather than a ``ValueError`` (:issue:`18231`)\n- ``Series`` construction with an ``object`` dtyped tz-aware datetime and ``dtype=object`` specified, will now return an ``object`` dtyped ``Series``, previously this would infer the datetime dtype (:issue:`18231`)\n- A :class:`Series` of ``dtype=category`` constructed from an empty ``dict`` will now have categories of ``dtype=object`` rather than ``dtype=float64``, consistently with the case in which an empty list is passed (:issue:`18515`)\n- All-NaN levels in a ``MultiIndex`` are now assigned ``float`` rather than ``object`` dtype, promoting consistency with ``Index`` (:issue:`17929`).\n- Levels names of a ``MultiIndex`` (when not None) are now required to be unique: trying to create a ``MultiIndex`` with repeated names will raise a ``ValueError`` (:issue:`18872`)\n- Both construction and renaming of ``Index``/``MultiIndex`` with non-hashable ``name``/``names`` will now raise ``TypeError`` (:issue:`20527`)\n- :func:`Index.map` can now accept ``Series`` and dictionary input objects (:issue:`12756`, :issue:`18482`, :issue:`18509`).\n- :func:`DataFrame.unstack` will now default to filling with ``np.nan`` for ``object`` columns. (:issue:`12815`)\n- :class:`IntervalIndex` constructor will raise if the ``closed`` parameter conflicts with how the input data is inferred to be closed (:issue:`18421`)\n- Inserting missing values into indexes will work for all types of indexes and automatically insert the correct type of missing value (``NaN``, ``NaT``, etc.) regardless of the type passed in (:issue:`18295`)\n- When created with duplicate labels, ``MultiIndex`` now raises a ``ValueError``. (:issue:`17464`)\n- :func:`Series.fillna` now raises a ``TypeError`` instead of a ``ValueError`` when passed a list, tuple or DataFrame as a ``value`` (:issue:`18293`)\n- :func:`pandas.DataFrame.merge` no longer casts a ``float`` column to ``object`` when merging on ``int`` and ``float`` columns (:issue:`16572`)\n- :func:`pandas.merge` now raises a ``ValueError`` when trying to merge on incompatible data types (:issue:`9780`)\n- The default NA value for :class:`UInt64Index` has changed from 0 to ``NaN``, which impacts methods that mask with NA, such as ``UInt64Index.where()`` (:issue:`18398`)\n- Refactored ``setup.py`` to use ``find_packages`` instead of explicitly listing out all subpackages (:issue:`18535`)\n- Rearranged the order of keyword arguments in :func:`read_excel()` to align with :func:`read_csv()` (:issue:`16672`)\n- :func:`wide_to_long` previously kept numeric-like suffixes as ``object`` dtype. Now they are cast to numeric if possible (:issue:`17627`)\n- In :func:`read_excel`, the ``comment`` argument is now exposed as a named parameter (:issue:`18735`)\n- Rearranged the order of keyword arguments in :func:`read_excel()` to align with :func:`read_csv()` (:issue:`16672`)\n- The options ``html.border`` and ``mode.use_inf_as_null`` were deprecated in prior versions, these will now show ``FutureWarning`` rather than a ``DeprecationWarning`` (:issue:`19003`)\n- :class:`IntervalIndex` and ``IntervalDtype`` no longer support categorical, object, and string subtypes (:issue:`19016`)\n- ``IntervalDtype`` now returns ``True`` when compared against ``'interval'`` regardless of subtype, and ``IntervalDtype.name`` now returns ``'interval'`` regardless of subtype (:issue:`18980`)\n- ``KeyError`` now raises instead of ``ValueError`` in :meth:`~DataFrame.drop`, :meth:`~Panel.drop`, :meth:`~Series.drop`, :meth:`~Index.drop` when dropping a non-existent element in an axis with duplicates (:issue:`19186`)\n- :func:`Series.to_csv` now accepts a ``compression`` argument that works in the same way as the ``compression`` argument in :func:`DataFrame.to_csv` (:issue:`18958`)\n- Set operations (union, difference...) on :class:`IntervalIndex` with incompatible index types will now raise a ``TypeError`` rather than a ``ValueError`` (:issue:`19329`)\n- :class:`DateOffset` objects render more simply, e.g. ``<DateOffset: days=1>`` instead of ``<DateOffset: kwds={'days': 1}>`` (:issue:`19403`)\n- ``Categorical.fillna`` now validates its ``value`` and ``method`` keyword arguments. It now raises when both or none are specified, matching the behavior of :meth:`Series.fillna` (:issue:`19682`)\n- ``pd.to_datetime('today')`` now returns a datetime, consistent with ``pd.Timestamp('today')``; previously ``pd.to_datetime('today')`` returned a ``.normalized()`` datetime (:issue:`19935`)\n- :func:`Series.str.replace` now takes an optional ``regex`` keyword which, when set to ``False``, uses literal string replacement rather than regex replacement (:issue:`16808`)\n- :func:`DatetimeIndex.strftime` and :func:`PeriodIndex.strftime` now return an ``Index`` instead of a numpy array to be consistent with similar accessors (:issue:`20127`)\n- Constructing a Series from a list of length 1 no longer broadcasts this list when a longer index is specified (:issue:`19714`, :issue:`20391`).\n- :func:`DataFrame.to_dict` with ``orient='index'`` no longer casts int columns to float for a DataFrame with only int and float columns (:issue:`18580`)\n- A user-defined-function that is passed to :func:`Series.rolling().aggregate() <.Rolling.aggregate>`, :func:`DataFrame.rolling().aggregate() <.Rolling.aggregate>`, or its expanding cousins, will now *always* be passed a ``Series``, rather than a ``np.array``; ``.apply()`` only has the ``raw`` keyword, see :ref:`here <whatsnew_0230.enhancements.window_raw>`. This is consistent with the signatures of ``.aggregate()`` across pandas (:issue:`20584`)\n- Rolling and Expanding types raise ``NotImplementedError`` upon iteration (:issue:`11704`).\n\n.. _whatsnew_0230.deprecations:\n\nDeprecations\n~~~~~~~~~~~~\n\n- ``Series.from_array`` and ``SparseSeries.from_array`` are deprecated. Use the normal constructor ``Series(..)`` and ``SparseSeries(..)`` instead (:issue:`18213`).\n- ``DataFrame.as_matrix`` is deprecated. Use ``DataFrame.values`` instead (:issue:`18458`).\n- ``Series.asobject``, ``DatetimeIndex.asobject``, ``PeriodIndex.asobject`` and ``TimeDeltaIndex.asobject`` have been deprecated. Use ``.astype(object)`` instead (:issue:`18572`)\n- Grouping by a tuple of keys now emits a ``FutureWarning`` and is deprecated.\n  In the future, a tuple passed to ``'by'`` will always refer to a single key\n  that is the actual tuple, instead of treating the tuple as multiple keys. To\n  retain the previous behavior, use a list instead of a tuple (:issue:`18314`)\n- ``Series.valid`` is deprecated. Use :meth:`Series.dropna` instead (:issue:`18800`).\n- :func:`read_excel` has deprecated the ``skip_footer`` parameter. Use ``skipfooter`` instead (:issue:`18836`)\n- :meth:`ExcelFile.parse` has deprecated ``sheetname`` in favor of ``sheet_name`` for consistency with :func:`read_excel` (:issue:`20920`).\n- The ``is_copy`` attribute is deprecated and will be removed in a future version (:issue:`18801`).\n- ``IntervalIndex.from_intervals`` is deprecated in favor of the :class:`IntervalIndex` constructor (:issue:`19263`)\n- ``DataFrame.from_items`` is deprecated. Use :func:`DataFrame.from_dict` instead, or ``DataFrame.from_dict(OrderedDict())`` if you wish to preserve the key order (:issue:`17320`, :issue:`17312`)\n- Indexing a :class:`MultiIndex` or a :class:`FloatIndex` with a list containing some missing keys will now show a :class:`FutureWarning`, which is consistent with other types of indexes (:issue:`17758`).\n\n- The ``broadcast`` parameter of ``.apply()`` is deprecated in favor of ``result_type='broadcast'`` (:issue:`18577`)\n- The ``reduce`` parameter of ``.apply()`` is deprecated in favor of ``result_type='reduce'`` (:issue:`18577`)\n- The ``order`` parameter of :func:`factorize` is deprecated and will be removed in a future release (:issue:`19727`)\n- :attr:`Timestamp.weekday_name`, :attr:`DatetimeIndex.weekday_name`, and :attr:`Series.dt.weekday_name` are deprecated in favor of :meth:`Timestamp.day_name`, :meth:`DatetimeIndex.day_name`, and :meth:`Series.dt.day_name` (:issue:`12806`)\n\n- ``pandas.tseries.plotting.tsplot`` is deprecated. Use :func:`Series.plot` instead (:issue:`18627`)\n- ``Index.summary()`` is deprecated and will be removed in a future version (:issue:`18217`)\n- ``NDFrame.get_ftype_counts()`` is deprecated and will be removed in a future version (:issue:`18243`)\n- The ``convert_datetime64`` parameter in :func:`DataFrame.to_records` has been deprecated and will be removed in a future version. The NumPy bug motivating this parameter has been resolved. The default value for this parameter has also changed from ``True`` to ``None`` (:issue:`18160`).\n- :func:`Series.rolling().apply() <.Rolling.apply>`, :func:`DataFrame.rolling().apply() <.Rolling.apply>`, :func:`Series.expanding().apply() <.Expanding.apply>`, and :func:`DataFrame.expanding().apply() <.Expanding.apply>` have deprecated passing an ``np.array`` by default. One will need to pass the new ``raw`` parameter to be explicit about what is passed (:issue:`20584`)\n- The ``data``, ``base``, ``strides``, ``flags`` and ``itemsize`` properties\n  of the ``Series`` and ``Index`` classes have been deprecated and will be\n  removed in a future version (:issue:`20419`).\n- ``DatetimeIndex.offset`` is deprecated. Use ``DatetimeIndex.freq`` instead (:issue:`20716`)\n- Floor division between an integer ndarray and a :class:`Timedelta` is deprecated. Divide by :attr:`Timedelta.value` instead (:issue:`19761`)\n- Setting ``PeriodIndex.freq`` (which was not guaranteed to work correctly) is deprecated. Use :meth:`PeriodIndex.asfreq` instead (:issue:`20678`)\n- ``Index.get_duplicates()`` is deprecated and will be removed in a future version (:issue:`20239`)\n- The previous default behavior of negative indices in ``Categorical.take`` is deprecated. In a future version it will change from meaning missing values to meaning positional indices from the right. The future behavior is consistent with :meth:`Series.take` (:issue:`20664`).\n- Passing multiple axes to the ``axis`` parameter in :func:`DataFrame.dropna` has been deprecated and will be removed in a future version (:issue:`20987`)\n\n\n.. _whatsnew_0230.prior_deprecations:\n\nRemoval of prior version deprecations/changes\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\n- Warnings against the obsolete usage ``Categorical(codes, categories)``, which were emitted for instance when the first two arguments to ``Categorical()`` had different dtypes, and recommended the use of ``Categorical.from_codes``, have now been removed (:issue:`8074`)\n- The ``levels`` and ``labels`` attributes of a ``MultiIndex`` can no longer be set directly (:issue:`4039`).\n- ``pd.tseries.util.pivot_annual`` has been removed (deprecated since v0.19). Use ``pivot_table`` instead (:issue:`18370`)\n- ``pd.tseries.util.isleapyear`` has been removed (deprecated since v0.19). Use ``.is_leap_year`` property in Datetime-likes instead (:issue:`18370`)\n- ``pd.ordered_merge`` has been removed (deprecated since v0.19). Use ``pd.merge_ordered`` instead (:issue:`18459`)\n- The ``SparseList`` class has been removed (:issue:`14007`)\n- The ``pandas.io.wb`` and ``pandas.io.data`` stub modules have been removed (:issue:`13735`)\n- ``Categorical.from_array`` has been removed (:issue:`13854`)\n- The ``freq`` and ``how`` parameters have been removed from the ``rolling``/``expanding``/``ewm`` methods of DataFrame\n  and Series (deprecated since v0.18). Instead, resample before calling the methods. (:issue:`18601` & :issue:`18668`)\n- ``DatetimeIndex.to_datetime``, ``Timestamp.to_datetime``, ``PeriodIndex.to_datetime``, and ``Index.to_datetime`` have been removed (:issue:`8254`, :issue:`14096`, :issue:`14113`)\n- :func:`read_csv` has dropped the ``skip_footer`` parameter (:issue:`13386`)\n- :func:`read_csv` has dropped the ``as_recarray`` parameter (:issue:`13373`)\n- :func:`read_csv` has dropped the ``buffer_lines`` parameter (:issue:`13360`)\n- :func:`read_csv` has dropped the ``compact_ints`` and ``use_unsigned`` parameters (:issue:`13323`)\n- The ``Timestamp`` class has dropped the ``offset`` attribute in favor of ``freq`` (:issue:`13593`)\n- The ``Series``, ``Categorical``, and ``Index`` classes have dropped the ``reshape`` method (:issue:`13012`)\n- ``pandas.tseries.frequencies.get_standard_freq`` has been removed in favor of ``pandas.tseries.frequencies.to_offset(freq).rule_code`` (:issue:`13874`)\n- The ``freqstr`` keyword has been removed from ``pandas.tseries.frequencies.to_offset`` in favor of ``freq`` (:issue:`13874`)\n- The ``Panel4D`` and ``PanelND`` classes have been removed (:issue:`13776`)\n- The ``Panel`` class has dropped the ``to_long`` and ``toLong`` methods (:issue:`19077`)\n- The options ``display.line_with`` and ``display.height`` are removed in favor of ``display.width`` and ``display.max_rows`` respectively (:issue:`4391`, :issue:`19107`)\n- The ``labels`` attribute of the ``Categorical`` class has been removed in favor of :attr:`Categorical.codes` (:issue:`7768`)\n- The ``flavor`` parameter have been removed from :func:`to_sql` method (:issue:`13611`)\n- The modules ``pandas.tools.hashing`` and ``pandas.util.hashing`` have been removed (:issue:`16223`)\n- The top-level functions ``pd.rolling_*``, ``pd.expanding_*`` and ``pd.ewm*`` have been removed (Deprecated since v0.18).\n  Instead, use the DataFrame/Series methods :attr:`~DataFrame.rolling`, :attr:`~DataFrame.expanding` and :attr:`~DataFrame.ewm` (:issue:`18723`)\n- Imports from ``pandas.core.common`` for functions such as ``is_datetime64_dtype`` are now removed. These are located in ``pandas.api.types``. (:issue:`13634`, :issue:`19769`)\n- The ``infer_dst`` keyword in :meth:`Series.tz_localize`, :meth:`DatetimeIndex.tz_localize`\n  and :class:`DatetimeIndex` have been removed. ``infer_dst=True`` is equivalent to\n  ``ambiguous='infer'``, and ``infer_dst=False`` to ``ambiguous='raise'`` (:issue:`7963`).\n- When ``.resample()`` was changed from an eager to a lazy operation, like ``.groupby()`` in v0.18.0, we put in place compatibility (with a ``FutureWarning``),\n  so operations would continue to work. This is now fully removed, so a ``Resampler`` will no longer forward compat operations (:issue:`20554`)\n- Remove long deprecated ``axis=None`` parameter from ``.replace()`` (:issue:`20271`)\n\n.. _whatsnew_0230.performance:\n\nPerformance improvements\n~~~~~~~~~~~~~~~~~~~~~~~~\n\n- Indexers on ``Series`` or ``DataFrame`` no longer create a reference cycle (:issue:`17956`)\n- Added a keyword argument, ``cache``, to :func:`to_datetime` that improved the performance of converting duplicate datetime arguments (:issue:`11665`)\n- :class:`DateOffset` arithmetic performance is improved (:issue:`18218`)\n- Converting a ``Series`` of ``Timedelta`` objects to days, seconds, etc... sped up through vectorization of underlying methods (:issue:`18092`)\n- Improved performance of ``.map()`` with a ``Series/dict`` input (:issue:`15081`)\n- The overridden ``Timedelta`` properties of days, seconds and microseconds have been removed, leveraging their built-in Python versions instead (:issue:`18242`)\n- ``Series`` construction will reduce the number of copies made of the input data in certain cases (:issue:`17449`)\n- Improved performance of :func:`Series.dt.date` and :func:`DatetimeIndex.date` (:issue:`18058`)\n- Improved performance of :func:`Series.dt.time` and :func:`DatetimeIndex.time` (:issue:`18461`)\n- Improved performance of :func:`IntervalIndex.symmetric_difference()` (:issue:`18475`)\n- Improved performance of ``DatetimeIndex`` and ``Series`` arithmetic operations with Business-Month and Business-Quarter frequencies (:issue:`18489`)\n- :func:`Series` / :func:`DataFrame` tab completion limits to 100 values, for better performance. (:issue:`18587`)\n- Improved performance of :func:`DataFrame.median` with ``axis=1`` when bottleneck is not installed (:issue:`16468`)\n- Improved performance of :func:`MultiIndex.get_loc` for large indexes, at the cost of a reduction in performance for small ones (:issue:`18519`)\n- Improved performance of :func:`MultiIndex.remove_unused_levels` when there are no unused levels, at the cost of a reduction in performance when there are (:issue:`19289`)\n- Improved performance of :func:`Index.get_loc` for non-unique indexes (:issue:`19478`)\n- Improved performance of pairwise ``.rolling()`` and ``.expanding()`` with ``.cov()`` and ``.corr()`` operations (:issue:`17917`)\n- Improved performance of :func:`.GroupBy.rank` (:issue:`15779`)\n- Improved performance of variable ``.rolling()`` on ``.min()`` and ``.max()`` (:issue:`19521`)\n- Improved performance of :func:`.GroupBy.ffill` and :func:`.GroupBy.bfill` (:issue:`11296`)\n- Improved performance of :func:`.GroupBy.any` and :func:`.GroupBy.all` (:issue:`15435`)\n- Improved performance of :func:`.GroupBy.pct_change` (:issue:`19165`)\n- Improved performance of :func:`Series.isin` in the case of categorical dtypes (:issue:`20003`)\n- Improved performance of ``getattr(Series, attr)`` when the Series has certain index types. This manifested in slow printing of large Series with a ``DatetimeIndex`` (:issue:`19764`)\n- Fixed a performance regression for :func:`GroupBy.nth` and :func:`GroupBy.last` with some object columns (:issue:`19283`)\n- Improved performance of :func:`.Categorical.from_codes` (:issue:`18501`)\n\n.. _whatsnew_0230.docs:\n\nDocumentation changes\n~~~~~~~~~~~~~~~~~~~~~\n\nThanks to all of the contributors who participated in the pandas Documentation\nSprint, which took place on March 10th. We had about 500 participants from over\n30 locations across the world. You should notice that many of the\n:ref:`API docstrings <api>` have greatly improved.\n\nThere were too many simultaneous contributions to include a release note for each\nimprovement, but this `GitHub search`_ should give you an idea of how many docstrings\nwere improved.\n\nSpecial thanks to `Marc Garcia`_ for organizing the sprint. For more information,\nread the `NumFOCUS blogpost`_ recapping the sprint.\n\n.. _GitHub search: https://github.com/pandas-dev/pandas/pulls?utf8=%E2%9C%93&q=is%3Apr+label%3ADocs+created%3A2018-03-10..2018-03-15+\n.. _NumFOCUS blogpost: https://www.numfocus.org/blog/worldwide-pandas-sprint/\n.. _Marc Garcia: https://github.com/datapythonista\n\n- Changed spelling of \"numpy\" to \"NumPy\", and \"python\" to \"Python\". (:issue:`19017`)\n- Consistency when introducing code samples, using either colon or period.\n  Rewrote some sentences for greater clarity, added more dynamic references\n  to functions, methods and classes.\n  (:issue:`18941`, :issue:`18948`, :issue:`18973`, :issue:`19017`)\n- Added a reference to :func:`DataFrame.assign` in the concatenate section of the merging documentation (:issue:`18665`)\n\n.. _whatsnew_0230.bug_fixes:\n\nBug fixes\n~~~~~~~~~\n\nCategorical\n^^^^^^^^^^^\n\n.. warning::\n\n   A class of bugs were introduced in pandas 0.21 with ``CategoricalDtype`` that\n   affects the correctness of operations like ``merge``, ``concat``, and\n   indexing when comparing multiple unordered ``Categorical`` arrays that have\n   the same categories, but in a different order. We highly recommend upgrading\n   or manually aligning your categories before doing these operations.\n\n- Bug in ``Categorical.equals`` returning the wrong result when comparing two\n  unordered ``Categorical`` arrays with the same categories, but in a different\n  order (:issue:`16603`)\n- Bug in :func:`pandas.api.types.union_categoricals` returning the wrong result\n  when for unordered categoricals with the categories in a different order.\n  This affected :func:`pandas.concat` with Categorical data (:issue:`19096`).\n- Bug in :func:`pandas.merge` returning the wrong result when joining on an\n  unordered ``Categorical`` that had the same categories but in a different\n  order (:issue:`19551`)\n- Bug in :meth:`CategoricalIndex.get_indexer` returning the wrong result when\n  ``target`` was an unordered ``Categorical`` that had the same categories as\n  ``self`` but in a different order (:issue:`19551`)\n- Bug in :meth:`Index.astype` with a categorical dtype where the resultant index is not converted to a :class:`CategoricalIndex` for all types of index (:issue:`18630`)\n- Bug in :meth:`Series.astype` and ``Categorical.astype()`` where an existing categorical data does not get updated (:issue:`10696`, :issue:`18593`)\n- Bug in :meth:`Series.str.split` with ``expand=True`` incorrectly raising an IndexError on empty strings (:issue:`20002`).\n- Bug in :class:`Index` constructor with ``dtype=CategoricalDtype(...)`` where ``categories`` and ``ordered`` are not maintained (:issue:`19032`)\n- Bug in :class:`Series` constructor with scalar and ``dtype=CategoricalDtype(...)`` where ``categories`` and ``ordered`` are not maintained (:issue:`19565`)\n- Bug in ``Categorical.__iter__`` not converting to Python types (:issue:`19909`)\n- Bug in :func:`pandas.factorize` returning the unique codes for the ``uniques``. This now returns a ``Categorical`` with the same dtype as the input (:issue:`19721`)\n- Bug in :func:`pandas.factorize` including an item for missing values in the ``uniques`` return value (:issue:`19721`)\n- Bug in :meth:`Series.take` with categorical data interpreting ``-1`` in ``indices`` as missing value markers, rather than the last element of the Series (:issue:`20664`)\n\nDatetimelike\n^^^^^^^^^^^^\n\n- Bug in :func:`Series.__sub__` subtracting a non-nanosecond ``np.datetime64`` object from a ``Series`` gave incorrect results (:issue:`7996`)\n- Bug in :class:`DatetimeIndex`, :class:`TimedeltaIndex` addition and subtraction of zero-dimensional integer arrays gave incorrect results (:issue:`19012`)\n- Bug in :class:`DatetimeIndex` and :class:`TimedeltaIndex` where adding or subtracting an array-like of ``DateOffset`` objects either raised (``np.array``, ``pd.Index``) or broadcast incorrectly (``pd.Series``) (:issue:`18849`)\n- Bug in :func:`Series.__add__` adding Series with dtype ``timedelta64[ns]`` to a timezone-aware ``DatetimeIndex`` incorrectly dropped timezone information (:issue:`13905`)\n- Adding a ``Period`` object to a ``datetime`` or ``Timestamp`` object will now correctly raise a ``TypeError`` (:issue:`17983`)\n- Bug in :class:`Timestamp` where comparison with an array of ``Timestamp`` objects would result in a ``RecursionError`` (:issue:`15183`)\n- Bug in :class:`Series` floor-division where operating on a scalar ``timedelta`` raises an exception (:issue:`18846`)\n- Bug in :class:`DatetimeIndex` where the repr was not showing high-precision time values at the end of a day (e.g., 23:59:59.999999999) (:issue:`19030`)\n- Bug in ``.astype()`` to non-ns timedelta units would hold the incorrect dtype (:issue:`19176`, :issue:`19223`, :issue:`12425`)\n- Bug in subtracting :class:`Series` from ``NaT`` incorrectly returning ``NaT`` (:issue:`19158`)\n- Bug in :func:`Series.truncate` which raises ``TypeError`` with a monotonic ``PeriodIndex`` (:issue:`17717`)\n- Bug in :func:`~DataFrame.pct_change` using ``periods`` and ``freq`` returned different length outputs (:issue:`7292`)\n- Bug in comparison of :class:`DatetimeIndex` against ``None`` or ``datetime.date`` objects raising ``TypeError`` for ``==`` and ``!=`` comparisons instead of all-``False`` and all-``True``, respectively (:issue:`19301`)\n- Bug in :class:`Timestamp` and :func:`to_datetime` where a string representing a barely out-of-bounds timestamp would be incorrectly rounded down instead of raising ``OutOfBoundsDatetime`` (:issue:`19382`)\n- Bug in :func:`Timestamp.floor` :func:`DatetimeIndex.floor` where time stamps far in the future and past were not rounded correctly (:issue:`19206`)\n- Bug in :func:`to_datetime` where passing an out-of-bounds datetime with ``errors='coerce'`` and ``utc=True`` would raise ``OutOfBoundsDatetime`` instead of parsing to ``NaT`` (:issue:`19612`)\n- Bug in :class:`DatetimeIndex` and :class:`TimedeltaIndex` addition and subtraction where name of the returned object was not always set consistently. (:issue:`19744`)\n- Bug in :class:`DatetimeIndex` and :class:`TimedeltaIndex` addition and subtraction where operations with numpy arrays raised ``TypeError`` (:issue:`19847`)\n- Bug in :class:`DatetimeIndex` and :class:`TimedeltaIndex` where setting the ``freq`` attribute was not fully supported (:issue:`20678`)\n\nTimedelta\n^^^^^^^^^\n\n- Bug in :func:`Timedelta.__mul__` where multiplying by ``NaT`` returned ``NaT`` instead of raising a ``TypeError`` (:issue:`19819`)\n- Bug in :class:`Series` with ``dtype='timedelta64[ns]'`` where addition or subtraction of ``TimedeltaIndex`` had results cast to ``dtype='int64'`` (:issue:`17250`)\n- Bug in :class:`Series` with ``dtype='timedelta64[ns]'`` where addition or subtraction of ``TimedeltaIndex`` could return a ``Series`` with an incorrect name (:issue:`19043`)\n- Bug in :func:`Timedelta.__floordiv__` and :func:`Timedelta.__rfloordiv__` dividing by many incompatible numpy objects was incorrectly allowed (:issue:`18846`)\n- Bug where dividing a scalar timedelta-like object with :class:`TimedeltaIndex` performed the reciprocal operation (:issue:`19125`)\n- Bug in :class:`TimedeltaIndex` where division by a ``Series`` would return a ``TimedeltaIndex`` instead of a ``Series`` (:issue:`19042`)\n- Bug in :func:`Timedelta.__add__`, :func:`Timedelta.__sub__` where adding or subtracting a ``np.timedelta64`` object would return another ``np.timedelta64`` instead of a ``Timedelta`` (:issue:`19738`)\n- Bug in :func:`Timedelta.__floordiv__`, :func:`Timedelta.__rfloordiv__` where operating with a ``Tick`` object would raise a ``TypeError`` instead of returning a numeric value (:issue:`19738`)\n- Bug in :func:`Period.asfreq` where periods near ``datetime(1, 1, 1)`` could be converted incorrectly (:issue:`19643`, :issue:`19834`)\n- Bug in :func:`Timedelta.total_seconds()` causing precision errors, for example ``Timedelta('30S').total_seconds()==30.000000000000004`` (:issue:`19458`)\n- Bug in :func:`Timedelta.__rmod__` where operating with a ``numpy.timedelta64`` returned a ``timedelta64`` object instead of a ``Timedelta`` (:issue:`19820`)\n- Multiplication of :class:`TimedeltaIndex` by ``TimedeltaIndex`` will now raise ``TypeError`` instead of raising ``ValueError`` in cases of length mismatch (:issue:`19333`)\n- Bug in indexing a :class:`TimedeltaIndex` with a ``np.timedelta64`` object which was raising a ``TypeError`` (:issue:`20393`)\n\n\nTimezones\n^^^^^^^^^\n\n- Bug in creating a ``Series`` from an array that contains both tz-naive and tz-aware values will result in a ``Series`` whose dtype is tz-aware instead of object (:issue:`16406`)\n- Bug in comparison of timezone-aware :class:`DatetimeIndex` against ``NaT`` incorrectly raising ``TypeError`` (:issue:`19276`)\n- Bug in :meth:`DatetimeIndex.astype` when converting between timezone aware dtypes, and converting from timezone aware to naive (:issue:`18951`)\n- Bug in comparing :class:`DatetimeIndex`, which failed to raise ``TypeError`` when attempting to compare timezone-aware and timezone-naive datetimelike objects (:issue:`18162`)\n- Bug in localization of a naive, datetime string in a ``Series`` constructor with a ``datetime64[ns, tz]`` dtype (:issue:`174151`)\n- :func:`Timestamp.replace` will now handle Daylight Savings transitions gracefully (:issue:`18319`)\n- Bug in tz-aware :class:`DatetimeIndex` where addition/subtraction with a :class:`TimedeltaIndex` or array with ``dtype='timedelta64[ns]'`` was incorrect (:issue:`17558`)\n- Bug in :func:`DatetimeIndex.insert` where inserting ``NaT`` into a timezone-aware index incorrectly raised (:issue:`16357`)\n- Bug in :class:`DataFrame` constructor, where tz-aware Datetimeindex and a given column name will result in an empty ``DataFrame`` (:issue:`19157`)\n- Bug in :func:`Timestamp.tz_localize` where localizing a timestamp near the minimum or maximum valid values could overflow and return a timestamp with an incorrect nanosecond value (:issue:`12677`)\n- Bug when iterating over :class:`DatetimeIndex` that was localized with fixed timezone offset that rounded nanosecond precision to microseconds (:issue:`19603`)\n- Bug in :func:`DataFrame.diff` that raised an ``IndexError`` with tz-aware values (:issue:`18578`)\n- Bug in :func:`melt` that converted tz-aware dtypes to tz-naive (:issue:`15785`)\n- Bug in :func:`Dataframe.count` that raised an ``ValueError``, if :func:`Dataframe.dropna` was called for a single column with timezone-aware values. (:issue:`13407`)\n\nOffsets\n^^^^^^^\n\n- Bug in :class:`WeekOfMonth` and :class:`Week` where addition and subtraction did not roll correctly (:issue:`18510`, :issue:`18672`, :issue:`18864`)\n- Bug in :class:`WeekOfMonth` and :class:`LastWeekOfMonth` where default keyword arguments for constructor raised ``ValueError`` (:issue:`19142`)\n- Bug in :class:`FY5253Quarter`, :class:`LastWeekOfMonth` where rollback and rollforward behavior was inconsistent with addition and subtraction behavior (:issue:`18854`)\n- Bug in :class:`FY5253` where ``datetime`` addition and subtraction incremented incorrectly for dates on the year-end but not normalized to midnight (:issue:`18854`)\n- Bug in :class:`FY5253` where date offsets could incorrectly raise an ``AssertionError`` in arithmetic operations (:issue:`14774`)\n\nNumeric\n^^^^^^^\n- Bug in :class:`Series` constructor with an int or float list where specifying ``dtype=str``, ``dtype='str'`` or ``dtype='U'`` failed to convert the data elements to strings (:issue:`16605`)\n- Bug in :class:`Index` multiplication and division methods where operating with a ``Series`` would return an ``Index`` object instead of a ``Series`` object (:issue:`19042`)\n- Bug in the :class:`DataFrame` constructor in which data containing very large positive or very large negative numbers was causing ``OverflowError`` (:issue:`18584`)\n- Bug in :class:`Index` constructor with ``dtype='uint64'`` where int-like floats were not coerced to :class:`UInt64Index` (:issue:`18400`)\n- Bug in :class:`DataFrame` flex arithmetic (e.g. ``df.add(other, fill_value=foo)``) with a ``fill_value`` other than ``None`` failed to raise ``NotImplementedError`` in corner cases where either the frame or ``other`` has length zero (:issue:`19522`)\n- Multiplication and division of numeric-dtyped :class:`Index` objects with timedelta-like scalars returns ``TimedeltaIndex`` instead of raising ``TypeError`` (:issue:`19333`)\n- Bug where ``NaN`` was returned instead of 0 by :func:`Series.pct_change` and :func:`DataFrame.pct_change` when ``fill_method`` is not ``None`` (:issue:`19873`)\n\nStrings\n^^^^^^^\n- Bug in :func:`Series.str.get` with a dictionary in the values and the index not in the keys, raising ``KeyError`` (:issue:`20671`)\n\n\nIndexing\n^^^^^^^^\n\n- Bug in :class:`Index` construction from list of mixed type tuples (:issue:`18505`)\n- Bug in :func:`Index.drop` when passing a list of both tuples and non-tuples (:issue:`18304`)\n- Bug in :func:`DataFrame.drop`, :meth:`Panel.drop`, :meth:`Series.drop`, :meth:`Index.drop` where no ``KeyError`` is raised when dropping a non-existent element from an axis that contains duplicates (:issue:`19186`)\n- Bug in indexing a datetimelike ``Index`` that raised ``ValueError`` instead of ``IndexError`` (:issue:`18386`).\n- :func:`Index.to_series` now accepts ``index`` and ``name`` kwargs (:issue:`18699`)\n- :func:`DatetimeIndex.to_series` now accepts ``index`` and ``name`` kwargs (:issue:`18699`)\n- Bug in indexing non-scalar value from ``Series`` having non-unique ``Index`` will return value flattened (:issue:`17610`)\n- Bug in indexing with iterator containing only missing keys, which raised no error (:issue:`20748`)\n- Fixed inconsistency in ``.ix`` between list and scalar keys when the index has integer dtype and does not include the desired keys (:issue:`20753`)\n- Bug in ``__setitem__`` when indexing a :class:`DataFrame` with a 2-d boolean ndarray (:issue:`18582`)\n- Bug in ``str.extractall`` when there were no matches empty :class:`Index` was returned instead of appropriate :class:`MultiIndex` (:issue:`19034`)\n- Bug in :class:`IntervalIndex` where empty and purely NA data was constructed inconsistently depending on the construction method (:issue:`18421`)\n- Bug in :func:`IntervalIndex.symmetric_difference` where the symmetric difference with a non-``IntervalIndex`` did not raise (:issue:`18475`)\n- Bug in :class:`IntervalIndex` where set operations that returned an empty ``IntervalIndex`` had the wrong dtype (:issue:`19101`)\n- Bug in :meth:`DataFrame.drop_duplicates` where no ``KeyError`` is raised when passing in columns that don't exist on the ``DataFrame`` (:issue:`19726`)\n- Bug in ``Index`` subclasses constructors that ignore unexpected keyword arguments (:issue:`19348`)\n- Bug in :meth:`Index.difference` when taking difference of an ``Index`` with itself (:issue:`20040`)\n- Bug in :meth:`DataFrame.first_valid_index` and :meth:`DataFrame.last_valid_index` in presence of entire rows of NaNs in the middle of values (:issue:`20499`).\n- Bug in :class:`IntervalIndex` where some indexing operations were not supported for overlapping or non-monotonic ``uint64`` data (:issue:`20636`)\n- Bug in ``Series.is_unique`` where extraneous output in stderr is shown if Series contains objects with ``__ne__`` defined (:issue:`20661`)\n- Bug in ``.loc`` assignment with a single-element list-like incorrectly assigns as a list (:issue:`19474`)\n- Bug in partial string indexing on a ``Series/DataFrame`` with a monotonic decreasing ``DatetimeIndex`` (:issue:`19362`)\n- Bug in performing in-place operations on a ``DataFrame`` with a duplicate ``Index`` (:issue:`17105`)\n- Bug in :meth:`IntervalIndex.get_loc` and :meth:`IntervalIndex.get_indexer` when used with an :class:`IntervalIndex` containing a single interval (:issue:`17284`, :issue:`20921`)\n- Bug in ``.loc`` with a ``uint64`` indexer (:issue:`20722`)\n\nMultiIndex\n^^^^^^^^^^\n\n- Bug in :func:`MultiIndex.__contains__` where non-tuple keys would return ``True`` even if they had been dropped (:issue:`19027`)\n- Bug in :func:`MultiIndex.set_labels` which would cause casting (and potentially clipping) of the new labels if the ``level`` argument is not 0 or a list like [0, 1, ... ]  (:issue:`19057`)\n- Bug in :func:`MultiIndex.get_level_values` which would return an invalid index on level of ints with missing values (:issue:`17924`)\n- Bug in :func:`MultiIndex.unique` when called on empty :class:`MultiIndex` (:issue:`20568`)\n- Bug in :func:`MultiIndex.unique` which would not preserve level names (:issue:`20570`)\n- Bug in :func:`MultiIndex.remove_unused_levels` which would fill nan values (:issue:`18417`)\n- Bug in :func:`MultiIndex.from_tuples` which would fail to take zipped tuples in python3 (:issue:`18434`)\n- Bug in :func:`MultiIndex.get_loc` which would fail to automatically cast values between float and int (:issue:`18818`, :issue:`15994`)\n- Bug in :func:`MultiIndex.get_loc` which would cast boolean to integer labels (:issue:`19086`)\n- Bug in :func:`MultiIndex.get_loc` which would fail to locate keys containing ``NaN`` (:issue:`18485`)\n- Bug in :func:`MultiIndex.get_loc` in large :class:`MultiIndex`, would fail when levels had different dtypes (:issue:`18520`)\n- Bug in indexing where nested indexers having only numpy arrays are handled incorrectly (:issue:`19686`)\n\n\nIO\n^^\n\n- :func:`read_html` now rewinds seekable IO objects after parse failure, before attempting to parse with a new parser. If a parser errors and the object is non-seekable, an informative error is raised suggesting the use of a different parser (:issue:`17975`)\n- :meth:`DataFrame.to_html` now has an option to add an id to the leading ``<table>`` tag (:issue:`8496`)\n- Bug in :func:`read_msgpack` with a non existent file is passed in Python 2 (:issue:`15296`)\n- Bug in :func:`read_csv` where a ``MultiIndex`` with duplicate columns was not being mangled appropriately (:issue:`18062`)\n- Bug in :func:`read_csv` where missing values were not being handled properly when ``keep_default_na=False`` with dictionary ``na_values`` (:issue:`19227`)\n- Bug in :func:`read_csv` causing heap corruption on 32-bit, big-endian architectures (:issue:`20785`)\n- Bug in :func:`read_sas` where a file with 0 variables gave an ``AttributeError`` incorrectly. Now it gives an ``EmptyDataError`` (:issue:`18184`)\n- Bug in :func:`DataFrame.to_latex()` where pairs of braces meant to serve as invisible placeholders were escaped (:issue:`18667`)\n- Bug in :func:`DataFrame.to_latex()` where a ``NaN`` in a ``MultiIndex`` would cause an ``IndexError`` or incorrect output (:issue:`14249`)\n- Bug in :func:`DataFrame.to_latex()` where a non-string index-level name would result in an ``AttributeError`` (:issue:`19981`)\n- Bug in :func:`DataFrame.to_latex()` where the combination of an index name and the ``index_names=False`` option would result in incorrect output (:issue:`18326`)\n- Bug in :func:`DataFrame.to_latex()` where a ``MultiIndex`` with an empty string as its name would result in incorrect output (:issue:`18669`)\n- Bug in :func:`DataFrame.to_latex()` where missing space characters caused wrong escaping and produced non-valid latex in some cases (:issue:`20859`)\n- Bug in :func:`read_json` where large numeric values were causing an ``OverflowError`` (:issue:`18842`)\n- Bug in :func:`DataFrame.to_parquet` where an exception was raised if the write destination is S3 (:issue:`19134`)\n- :class:`Interval` now supported in :func:`DataFrame.to_excel` for all Excel file types (:issue:`19242`)\n- :class:`Timedelta` now supported in :func:`DataFrame.to_excel` for all Excel file types (:issue:`19242`, :issue:`9155`, :issue:`19900`)\n- Bug in :meth:`pandas.io.stata.StataReader.value_labels` raising an ``AttributeError`` when called on very old files. Now returns an empty dict (:issue:`19417`)\n- Bug in :func:`read_pickle` when unpickling objects with :class:`TimedeltaIndex` or :class:`Float64Index` created with pandas prior to version 0.20 (:issue:`19939`)\n- Bug in :meth:`pandas.io.json.json_normalize` where sub-records are not properly normalized if any sub-records values are NoneType (:issue:`20030`)\n- Bug in ``usecols`` parameter in :func:`read_csv` where error is not raised correctly when passing a string. (:issue:`20529`)\n- Bug in :func:`HDFStore.keys` when reading a file with a soft link causes exception (:issue:`20523`)\n- Bug in :func:`HDFStore.select_column` where a key which is not a valid store raised an ``AttributeError`` instead of a ``KeyError`` (:issue:`17912`)\n\nPlotting\n^^^^^^^^\n\n- Better error message when attempting to plot but matplotlib is not installed (:issue:`19810`).\n- :func:`DataFrame.plot` now raises a ``ValueError`` when the ``x`` or ``y`` argument is improperly formed (:issue:`18671`)\n- Bug in :func:`DataFrame.plot` when ``x`` and ``y`` arguments given as positions caused incorrect referenced columns for line, bar and area plots (:issue:`20056`)\n- Bug in formatting tick labels with ``datetime.time()`` and fractional seconds (:issue:`18478`).\n- :meth:`Series.plot.kde` has exposed the args ``ind`` and ``bw_method`` in the docstring (:issue:`18461`). The argument ``ind`` may now also be an integer (number of sample points).\n- :func:`DataFrame.plot` now supports multiple columns to the ``y`` argument (:issue:`19699`)\n\n\nGroupBy/resample/rolling\n^^^^^^^^^^^^^^^^^^^^^^^^\n\n- Bug when grouping by a single column and aggregating with a class like ``list`` or ``tuple`` (:issue:`18079`)\n- Fixed regression in :func:`DataFrame.groupby` which would not emit an error when called with a tuple key not in the index (:issue:`18798`)\n- Bug in :func:`DataFrame.resample` which silently ignored unsupported (or mistyped) options for ``label``, ``closed`` and ``convention`` (:issue:`19303`)\n- Bug in :func:`DataFrame.groupby` where tuples were interpreted as lists of keys rather than as keys (:issue:`17979`, :issue:`18249`)\n- Bug in :func:`DataFrame.groupby` where aggregation by ``first``/``last``/``min``/``max`` was causing timestamps to lose precision (:issue:`19526`)\n- Bug in :func:`DataFrame.transform` where particular aggregation functions were being incorrectly cast to match the dtype(s) of the grouped data (:issue:`19200`)\n- Bug in :func:`DataFrame.groupby` passing the ``on=`` kwarg, and subsequently using ``.apply()`` (:issue:`17813`)\n- Bug in :func:`DataFrame.resample().aggregate <.Resampler.aggregate>` not raising a ``KeyError`` when aggregating a non-existent column (:issue:`16766`, :issue:`19566`)\n- Bug in :func:`DataFrameGroupBy.cumsum` and :func:`DataFrameGroupBy.cumprod` when ``skipna`` was passed (:issue:`19806`)\n- Bug in :func:`DataFrame.resample` that dropped timezone information (:issue:`13238`)\n- Bug in :func:`DataFrame.groupby` where transformations using ``np.all`` and ``np.any`` were raising a ``ValueError`` (:issue:`20653`)\n- Bug in :func:`DataFrame.resample` where ``ffill``, ``bfill``, ``pad``, ``backfill``, ``fillna``, ``interpolate``, and ``asfreq`` were ignoring ``loffset``. (:issue:`20744`)\n- Bug in :func:`DataFrame.groupby` when applying a function that has mixed data types and the user supplied function can fail on the grouping column (:issue:`20949`)\n- Bug in :func:`DataFrameGroupBy.rolling().apply() <.Rolling.apply>` where operations performed against the associated :class:`DataFrameGroupBy` object could impact the inclusion of the grouped item(s) in the result (:issue:`14013`)\n\nSparse\n^^^^^^\n\n- Bug in which creating a :class:`SparseDataFrame` from a dense ``Series`` or an unsupported type raised an uncontrolled exception (:issue:`19374`)\n- Bug in :class:`SparseDataFrame.to_csv` causing exception (:issue:`19384`)\n- Bug in :class:`SparseSeries.memory_usage` which caused segfault by accessing non sparse elements (:issue:`19368`)\n- Bug in constructing a :class:`SparseArray`: if ``data`` is a scalar and ``index`` is defined it will coerce to ``float64`` regardless of scalar's dtype. (:issue:`19163`)\n\nReshaping\n^^^^^^^^^\n\n- Bug in :func:`DataFrame.merge` where referencing a ``CategoricalIndex`` by name, where the ``by`` kwarg would ``KeyError`` (:issue:`20777`)\n- Bug in :func:`DataFrame.stack` which fails trying to sort mixed type levels under Python 3 (:issue:`18310`)\n- Bug in :func:`DataFrame.unstack` which casts int to float if ``columns`` is a ``MultiIndex`` with unused levels (:issue:`17845`)\n- Bug in :func:`DataFrame.unstack` which raises an error if ``index`` is a ``MultiIndex`` with unused labels on the unstacked level (:issue:`18562`)\n- Fixed construction of a :class:`Series` from a ``dict`` containing ``NaN`` as key (:issue:`18480`)\n- Fixed construction of a :class:`DataFrame` from a ``dict`` containing ``NaN`` as key (:issue:`18455`)\n- Disabled construction of a :class:`Series` where len(index) > len(data) = 1, which previously would broadcast the data item, and now raises a ``ValueError`` (:issue:`18819`)\n- Suppressed error in the construction of a :class:`DataFrame` from a ``dict`` containing scalar values when the corresponding keys are not included in the passed index (:issue:`18600`)\n\n- Fixed (changed from ``object`` to ``float64``) dtype of :class:`DataFrame` initialized with axes, no data, and ``dtype=int`` (:issue:`19646`)\n- Bug in :func:`Series.rank` where ``Series`` containing ``NaT`` modifies the ``Series`` inplace (:issue:`18521`)\n- Bug in :func:`cut` which fails when using readonly arrays (:issue:`18773`)\n- Bug in :func:`DataFrame.pivot_table` which fails when the ``aggfunc`` arg is of type string.  The behavior is now consistent with other methods like ``agg`` and ``apply`` (:issue:`18713`)\n- Bug in :func:`DataFrame.merge` in which merging using ``Index`` objects as vectors raised an Exception (:issue:`19038`)\n- Bug in :func:`DataFrame.stack`, :func:`DataFrame.unstack`, :func:`Series.unstack` which were not returning subclasses (:issue:`15563`)\n- Bug in timezone comparisons, manifesting as a conversion of the index to UTC in ``.concat()`` (:issue:`18523`)\n- Bug in :func:`concat` when concatenating sparse and dense series it returns only a ``SparseDataFrame``. Should be a ``DataFrame``. (:issue:`18914`, :issue:`18686`, and :issue:`16874`)\n- Improved error message for :func:`DataFrame.merge` when there is no common merge key (:issue:`19427`)\n- Bug in :func:`DataFrame.join` which does an ``outer`` instead of a ``left`` join when being called with multiple DataFrames and some have non-unique indices (:issue:`19624`)\n- :func:`Series.rename` now accepts ``axis`` as a kwarg (:issue:`18589`)\n- Bug in :func:`~DataFrame.rename` where an Index of same-length tuples was converted to a MultiIndex (:issue:`19497`)\n- Comparisons between :class:`Series` and :class:`Index` would return a ``Series`` with an incorrect name, ignoring the ``Index``'s name attribute (:issue:`19582`)\n- Bug in :func:`qcut` where datetime and timedelta data with ``NaT`` present raised a ``ValueError`` (:issue:`19768`)\n- Bug in :func:`DataFrame.iterrows`, which would infers strings not compliant to `ISO8601 <https://en.wikipedia.org/wiki/ISO_8601>`_ to datetimes (:issue:`19671`)\n- Bug in :class:`Series` constructor with ``Categorical`` where a ``ValueError`` is not raised when an index of different length is given (:issue:`19342`)\n- Bug in :meth:`DataFrame.astype` where column metadata is lost when converting to categorical or a dictionary of dtypes (:issue:`19920`)\n- Bug in :func:`cut` and :func:`qcut` where timezone information was dropped (:issue:`19872`)\n- Bug in :class:`Series` constructor with a ``dtype=str``, previously raised in some cases (:issue:`19853`)\n- Bug in :func:`get_dummies`, and :func:`select_dtypes`, where duplicate column names caused incorrect behavior (:issue:`20848`)\n- Bug in :func:`isna`, which cannot handle ambiguous typed lists (:issue:`20675`)\n- Bug in :func:`concat` which raises an error when concatenating TZ-aware dataframes and all-NaT dataframes (:issue:`12396`)\n- Bug in :func:`concat` which raises an error when concatenating empty TZ-aware series (:issue:`18447`)\n\nOther\n^^^^^\n\n- Improved error message when attempting to use a Python keyword as an identifier in a ``numexpr`` backed query (:issue:`18221`)\n- Bug in accessing a :func:`pandas.get_option`, which raised ``KeyError`` rather than ``OptionError`` when looking up a non-existent option key in some cases (:issue:`19789`)\n- Bug in :func:`testing.assert_series_equal` and :func:`testing.assert_frame_equal` for Series or DataFrames with differing unicode data (:issue:`20503`)\n\n.. _whatsnew_0.23.0.contributors:\n\nContributors\n~~~~~~~~~~~~\n\n.. contributors:: v0.22.0..v0.23.0\n\n\n.. _whatsnew_0151:\n\nVersion 0.15.1 (November 9, 2014)\n---------------------------------\n\n{{ header }}\n\n\nThis is a minor bug-fix release from 0.15.0 and includes a small number of API changes, several new features,\nenhancements, and performance improvements along with a large number of bug fixes. We recommend that all\nusers upgrade to this version.\n\n- :ref:`Enhancements <whatsnew_0151.enhancements>`\n- :ref:`API Changes <whatsnew_0151.api>`\n- :ref:`Bug Fixes <whatsnew_0151.bug_fixes>`\n\n.. _whatsnew_0151.api:\n\nAPI changes\n~~~~~~~~~~~\n\n- ``s.dt.hour`` and other ``.dt`` accessors will now return ``np.nan`` for missing values (rather than previously -1), (:issue:`8689`)\n\n  .. ipython:: python\n\n     s = pd.Series(pd.date_range(\"20130101\", periods=5, freq=\"D\"))\n     s.iloc[2] = np.nan\n     s\n\n  previous behavior:\n\n  .. code-block:: ipython\n\n     In [6]: s.dt.hour\n     Out[6]:\n     0    0\n     1    0\n     2   -1\n     3    0\n     4    0\n     dtype: int64\n\n  current behavior:\n\n  .. ipython:: python\n\n     s.dt.hour\n\n- ``groupby`` with ``as_index=False`` will not add erroneous extra columns to\n  result (:issue:`8582`):\n\n  .. ipython:: python\n\n     np.random.seed(2718281)\n     df = pd.DataFrame(np.random.randint(0, 100, (10, 2)), columns=[\"jim\", \"joe\"])\n     df.head()\n\n     ts = pd.Series(5 * np.random.randint(0, 3, 10))\n\n  previous behavior:\n\n  .. code-block:: ipython\n\n     In [4]: df.groupby(ts, as_index=False).max()\n     Out[4]:\n        NaN  jim  joe\n     0    0   72   83\n     1    5   77   84\n     2   10   96   65\n\n  current behavior:\n\n  .. code-block:: ipython\n\n     In [4]: df.groupby(ts, as_index=False).max()\n     Out[4]:\n        jim  joe\n     0   72   83\n     1   77   84\n     2   96   65\n\n- ``groupby`` will not erroneously exclude columns if the column name conflicts\n  with the grouper name (:issue:`8112`):\n\n  .. ipython:: python\n\n     df = pd.DataFrame({\"jim\": range(5), \"joe\": range(5, 10)})\n     df\n     gr = df.groupby(df[\"jim\"] < 2)\n\n  previous behavior (excludes 1st column from output):\n\n  .. code-block:: ipython\n\n     In [4]: gr.apply(sum)\n     Out[4]:\n            joe\n     jim\n     False   24\n     True    11\n\n  current behavior:\n\n  .. ipython:: python\n     :okwarning:\n\n     gr.apply(sum)\n\n- Support for slicing with monotonic decreasing indexes, even if ``start`` or ``stop`` is\n  not found in the index (:issue:`7860`):\n\n  .. ipython:: python\n\n    s = pd.Series([\"a\", \"b\", \"c\", \"d\"], [4, 3, 2, 1])\n    s\n\n  previous behavior:\n\n  .. code-block:: ipython\n\n     In [8]: s.loc[3.5:1.5]\n     KeyError: 3.5\n\n  current behavior:\n\n  .. ipython:: python\n\n     s.loc[3.5:1.5]\n\n- ``io.data.Options`` has been fixed for a change in the format of the Yahoo Options page (:issue:`8612`), (:issue:`8741`)\n\n  .. note::\n\n    As a result of a change in Yahoo's option page layout, when an expiry date is given,\n    ``Options`` methods now return data for a single expiry date.  Previously, methods returned all\n    data for the selected month.\n\n  The ``month`` and ``year`` parameters have been undeprecated and can be used to get all\n  options data for a given month.\n\n  If an expiry date that is not valid is given, data for the next expiry after the given\n  date is returned.\n\n  Option data frames are now saved on the instance as ``callsYYMMDD`` or ``putsYYMMDD``.  Previously\n  they were saved as ``callsMMYY`` and ``putsMMYY``.  The next expiry is saved as ``calls`` and ``puts``.\n\n  New features:\n\n  - The expiry parameter can now be a single date or a list-like object containing dates.\n\n  - A new property ``expiry_dates`` was added, which returns all available expiry dates.\n\n  Current behavior:\n\n  .. code-block:: ipython\n\n      In [17]: from pandas.io.data import Options\n\n      In [18]: aapl = Options('aapl', 'yahoo')\n\n      In [19]: aapl.get_call_data().iloc[0:5, 0:1]\n      Out[19]:\n                                                   Last\n      Strike Expiry     Type Symbol\n      80     2014-11-14 call AAPL141114C00080000  29.05\n      84     2014-11-14 call AAPL141114C00084000  24.80\n      85     2014-11-14 call AAPL141114C00085000  24.05\n      86     2014-11-14 call AAPL141114C00086000  22.76\n      87     2014-11-14 call AAPL141114C00087000  21.74\n\n      In [20]: aapl.expiry_dates\n      Out[20]:\n      [datetime.date(2014, 11, 14),\n       datetime.date(2014, 11, 22),\n       datetime.date(2014, 11, 28),\n       datetime.date(2014, 12, 5),\n       datetime.date(2014, 12, 12),\n       datetime.date(2014, 12, 20),\n       datetime.date(2015, 1, 17),\n       datetime.date(2015, 2, 20),\n       datetime.date(2015, 4, 17),\n       datetime.date(2015, 7, 17),\n       datetime.date(2016, 1, 15),\n       datetime.date(2017, 1, 20)]\n\n      In [21]: aapl.get_near_stock_price(expiry=aapl.expiry_dates[0:3]).iloc[0:5, 0:1]\n      Out[21]:\n                                                  Last\n      Strike Expiry     Type Symbol\n      109    2014-11-22 call AAPL141122C00109000  1.48\n             2014-11-28 call AAPL141128C00109000  1.79\n      110    2014-11-14 call AAPL141114C00110000  0.55\n             2014-11-22 call AAPL141122C00110000  1.02\n             2014-11-28 call AAPL141128C00110000  1.32\n\n.. _whatsnew_0151.datetime64_plotting:\n\n- pandas now also registers the ``datetime64`` dtype in matplotlib's units registry\n  to plot such values as datetimes. This is activated once pandas is imported. In\n  previous versions, plotting an array of ``datetime64`` values will have resulted\n  in plotted integer values. To keep the previous behaviour, you can do\n  ``del matplotlib.units.registry[np.datetime64]`` (:issue:`8614`).\n\n\n.. _whatsnew_0151.enhancements:\n\nEnhancements\n~~~~~~~~~~~~\n\n- ``concat`` permits a wider variety of iterables of pandas objects to be\n  passed as the first parameter (:issue:`8645`):\n\n  .. ipython:: python\n\n     from collections import deque\n\n     df1 = pd.DataFrame([1, 2, 3])\n     df2 = pd.DataFrame([4, 5, 6])\n\n  previous behavior:\n\n  .. code-block:: ipython\n\n     In [7]: pd.concat(deque((df1, df2)))\n     TypeError: first argument must be a list-like of pandas objects, you passed an object of type \"deque\"\n\n  current behavior:\n\n  .. ipython:: python\n\n     pd.concat(deque((df1, df2)))\n\n- Represent ``MultiIndex`` labels with a dtype that utilizes memory based on the level size. In prior versions, the memory usage was a constant 8 bytes per element in each level. In addition, in prior versions, the *reported* memory usage was incorrect as it didn't show the usage for the memory occupied by the underling data array. (:issue:`8456`)\n\n  .. ipython:: python\n\n     dfi = pd.DataFrame(\n         1, index=pd.MultiIndex.from_product([[\"a\"], range(1000)]), columns=[\"A\"]\n     )\n\n  previous behavior:\n\n  .. code-block:: ipython\n\n      this was underreported in prior versions\n     In [1]: dfi.memory_usage(index=True)\n     Out[1]:\n     Index    8000  took about 24008 bytes in < 0.15.1\n     A        8000\n     dtype: int64\n\n\n  current behavior:\n\n  .. ipython:: python\n\n     dfi.memory_usage(index=True)\n\n- Added Index properties ``is_monotonic_increasing`` and ``is_monotonic_decreasing`` (:issue:`8680`).\n\n- Added option to select columns when importing Stata files (:issue:`7935`)\n\n- Qualify memory usage in ``DataFrame.info()`` by adding ``+`` if it is a lower bound (:issue:`8578`)\n\n- Raise errors in certain aggregation cases where an argument such as ``numeric_only`` is not handled (:issue:`8592`).\n\n- Added support for 3-character ISO and non-standard country codes in :func:`io.wb.download()` (:issue:`8482`)\n\n- World Bank data requests now will warn/raise based\n  on an ``errors`` argument, as well as a list of hard-coded country codes and\n  the World Bank's JSON response.  In prior versions, the error messages\n  didn't look at the World Bank's JSON response.  Problem-inducing input were\n  simply dropped prior to the request. The issue was that many good countries\n  were cropped in the hard-coded approach.  All countries will work now, but\n  some bad countries will raise exceptions because some edge cases break the\n  entire response. (:issue:`8482`)\n\n- Added option to ``Series.str.split()`` to return a ``DataFrame`` rather than a ``Series`` (:issue:`8428`)\n\n- Added option to ``df.info(null_counts=None|True|False)`` to override the default display options and force showing of the null-counts (:issue:`8701`)\n\n\n.. _whatsnew_0151.bug_fixes:\n\nBug fixes\n~~~~~~~~~\n\n- Bug in unpickling of a ``CustomBusinessDay`` object (:issue:`8591`)\n- Bug in coercing ``Categorical`` to a records array, e.g. ``df.to_records()`` (:issue:`8626`)\n- Bug in ``Categorical`` not created properly with ``Series.to_frame()`` (:issue:`8626`)\n- Bug in coercing in astype of a ``Categorical`` of a passed ``pd.Categorical`` (this now raises ``TypeError`` correctly), (:issue:`8626`)\n- Bug in ``cut``/``qcut`` when using ``Series`` and ``retbins=True`` (:issue:`8589`)\n- Bug in writing Categorical columns to an SQL database with ``to_sql`` (:issue:`8624`).\n- Bug in comparing ``Categorical`` of datetime raising when being compared to a scalar datetime (:issue:`8687`)\n- Bug in selecting from a ``Categorical`` with ``.iloc`` (:issue:`8623`)\n- Bug in groupby-transform with a Categorical (:issue:`8623`)\n- Bug in duplicated/drop_duplicates with a Categorical (:issue:`8623`)\n- Bug in ``Categorical`` reflected comparison operator raising if the first argument was a numpy array scalar (e.g. np.int64) (:issue:`8658`)\n- Bug in Panel indexing with a list-like (:issue:`8710`)\n- Compat issue is ``DataFrame.dtypes`` when ``options.mode.use_inf_as_null`` is True (:issue:`8722`)\n- Bug in ``read_csv``, ``dialect`` parameter would not take a string (:issue:`8703`)\n- Bug in slicing a MultiIndex level with an empty-list (:issue:`8737`)\n- Bug in numeric index operations of add/sub with Float/Index Index with numpy arrays (:issue:`8608`)\n- Bug in setitem with empty indexer and unwanted coercion of dtypes (:issue:`8669`)\n- Bug in ix/loc block splitting on setitem (manifests with integer-like dtypes, e.g. datetime64) (:issue:`8607`)\n- Bug when doing label based indexing with integers not found in the index for\n  non-unique but monotonic indexes (:issue:`8680`).\n- Bug when indexing a Float64Index with ``np.nan`` on numpy 1.7 (:issue:`8980`).\n- Fix ``shape`` attribute for ``MultiIndex`` (:issue:`8609`)\n- Bug in ``GroupBy`` where a name conflict between the grouper and columns\n  would break ``groupby`` operations (:issue:`7115`, :issue:`8112`)\n- Fixed a bug where plotting a column ``y`` and specifying a label would mutate the index name of the original DataFrame (:issue:`8494`)\n- Fix regression in plotting of a DatetimeIndex directly with matplotlib (:issue:`8614`).\n- Bug in ``date_range`` where partially-specified dates would incorporate current date (:issue:`6961`)\n- Bug in Setting by indexer to a scalar value with a mixed-dtype ``Panel4d`` was failing (:issue:`8702`)\n- Bug where ``DataReader``'s would fail if one of the symbols passed was invalid.  Now returns data for valid symbols and np.nan for invalid (:issue:`8494`)\n- Bug in ``get_quote_yahoo`` that wouldn't allow non-float return values (:issue:`5229`).\n\n\n.. _whatsnew_0.15.1.contributors:\n\nContributors\n~~~~~~~~~~~~\n\n.. contributors:: v0.15.0..v0.15.1\n\n\n.. _whatsnew_203:\n\nWhat's new in 2.0.3 (June 28, 2023)\n-----------------------------------\n\nThese are the changes in pandas 2.0.3. See :ref:`release` for a full changelog\nincluding other versions of pandas.\n\n{{ header }}\n\n.. ---------------------------------------------------------------------------\n.. _whatsnew_203.regressions:\n\nFixed regressions\n~~~~~~~~~~~~~~~~~\n- Bug in :meth:`Timestamp.weekday`` was returning incorrect results before ``'0000-02-29'`` (:issue:`53738`)\n- Fixed performance regression in merging on datetime-like columns (:issue:`53231`)\n- Fixed regression when :meth:`DataFrame.to_string` creates extra space for string dtypes (:issue:`52690`)\n\n.. ---------------------------------------------------------------------------\n.. _whatsnew_203.bug_fixes:\n\nBug fixes\n~~~~~~~~~\n- Bug in :func:`DataFrame.convert_dtype` and :func:`Series.convert_dtype` when trying to convert :class:`ArrowDtype` with ``dtype_backend=\"nullable_numpy\"`` (:issue:`53648`)\n- Bug in :func:`RangeIndex.union` when using ``sort=True`` with another :class:`RangeIndex` (:issue:`53490`)\n- Bug in :func:`Series.reindex` when expanding a non-nanosecond datetime or timedelta :class:`Series` would not fill with ``NaT`` correctly (:issue:`53497`)\n- Bug in :func:`read_csv` when defining ``dtype`` with ``bool[pyarrow]`` for the ``\"c\"`` and ``\"python\"`` engines (:issue:`53390`)\n- Bug in :meth:`Series.str.split` and :meth:`Series.str.rsplit` with ``expand=True`` for :class:`ArrowDtype` with ``pyarrow.string`` (:issue:`53532`)\n- Bug in indexing methods (e.g. :meth:`DataFrame.__getitem__`) where taking the entire :class:`DataFrame`/:class:`Series` would raise an ``OverflowError`` when Copy on Write was enabled and the length of the array was over the maximum size a 32-bit integer can hold (:issue:`53616`)\n- Bug when constructing a :class:`DataFrame` with columns of an :class:`ArrowDtype` with a ``pyarrow.dictionary`` type that reindexes the data (:issue:`53617`)\n- Bug when indexing a :class:`DataFrame` or :class:`Series` with an :class:`Index` with a timestamp :class:`ArrowDtype` would raise an ``AttributeError`` (:issue:`53644`)\n\n.. ---------------------------------------------------------------------------\n.. _whatsnew_203.other:\n\nOther\n~~~~~\n\n.. ---------------------------------------------------------------------------\n.. _whatsnew_203.contributors:\n\nContributors\n~~~~~~~~~~~~\n\n.. contributors:: v2.0.2..v2.0.3\n\n\n.. _whatsnew_200:\n\nWhat's new in 2.0.0 (April 3, 2023)\n-----------------------------------\n\nThese are the changes in pandas 2.0.0. See :ref:`release` for a full changelog\nincluding other versions of pandas.\n\n{{ header }}\n\n.. ---------------------------------------------------------------------------\n.. _whatsnew_200.enhancements:\n\nEnhancements\n~~~~~~~~~~~~\n\n.. _whatsnew_200.enhancements.optional_dependency_management_pip:\n\nInstalling optional dependencies with pip extras\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nWhen installing pandas using pip, sets of optional dependencies can also be installed by specifying extras.\n\n.. code-block:: bash\n\n  pip install \"pandas[performance, aws]>=2.0.0\"\n\nThe available extras, found in the :ref:`installation guide<install.dependencies>`, are\n``[all, performance, computation, fss, aws, gcp, excel, parquet, feather, hdf5, spss, postgresql, mysql,\nsql-other, html, xml, plot, output_formatting, clipboard, compression, test]`` (:issue:`39164`).\n\n.. _whatsnew_200.enhancements.index_can_hold_numpy_numeric_dtypes:\n\n:class:`Index` can now hold numpy numeric dtypes\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nIt is now possible to use any numpy numeric dtype in a :class:`Index` (:issue:`42717`).\n\nPreviously it was only possible to use ``int64``, ``uint64`` & ``float64`` dtypes:\n\n.. code-block:: ipython\n\n    In [1]: pd.Index([1, 2, 3], dtype=np.int8)\n    Out[1]: Int64Index([1, 2, 3], dtype=\"int64\")\n    In [2]: pd.Index([1, 2, 3], dtype=np.uint16)\n    Out[2]: UInt64Index([1, 2, 3], dtype=\"uint64\")\n    In [3]: pd.Index([1, 2, 3], dtype=np.float32)\n    Out[3]: Float64Index([1.0, 2.0, 3.0], dtype=\"float64\")\n\n:class:`Int64Index`, :class:`UInt64Index` & :class:`Float64Index` were deprecated in pandas\nversion 1.4 and have now been removed. Instead :class:`Index` should be used directly, and\ncan it now take all numpy numeric dtypes, i.e.\n``int8``/ ``int16``/``int32``/``int64``/``uint8``/``uint16``/``uint32``/``uint64``/``float32``/``float64`` dtypes:\n\n.. ipython:: python\n\n    pd.Index([1, 2, 3], dtype=np.int8)\n    pd.Index([1, 2, 3], dtype=np.uint16)\n    pd.Index([1, 2, 3], dtype=np.float32)\n\nThe ability for :class:`Index` to hold the numpy numeric dtypes has meant some changes in Pandas\nfunctionality. In particular, operations that previously were forced to create 64-bit indexes,\ncan now create indexes with lower bit sizes, e.g. 32-bit indexes.\n\nBelow is a possibly non-exhaustive list of changes:\n\n1. Instantiating using a numpy numeric array now follows the dtype of the numpy array.\n   Previously, all indexes created from numpy numeric arrays were forced to 64-bit. Now,\n   for example, ``Index(np.array([1, 2, 3]))`` will be ``int32`` on 32-bit systems, where\n   it previously would have been ``int64`` even on 32-bit systems.\n   Instantiating :class:`Index` using a list of numbers will still return 64bit dtypes,\n   e.g. ``Index([1, 2, 3])`` will have a ``int64`` dtype, which is the same as previously.\n2. The various numeric datetime attributes of :class:`DatetimeIndex` (:attr:`~DatetimeIndex.day`,\n   :attr:`~DatetimeIndex.month`, :attr:`~DatetimeIndex.year` etc.) were previously in of\n   dtype ``int64``, while they were ``int32`` for :class:`arrays.DatetimeArray`. They are now\n   ``int32`` on :class:`DatetimeIndex` also:\n\n   .. ipython:: python\n\n       idx = pd.date_range(start='1/1/2018', periods=3, freq='ME')\n       idx.array.year\n       idx.year\n\n3. Level dtypes on Indexes from :meth:`Series.sparse.from_coo` are now of dtype ``int32``,\n   the same as they are on the ``rows``/``cols`` on a scipy sparse matrix. Previously they\n   were of dtype ``int64``.\n\n   .. ipython:: python\n\n       from scipy import sparse\n       A = sparse.coo_matrix(\n           ([3.0, 1.0, 2.0], ([1, 0, 0], [0, 2, 3])), shape=(3, 4)\n       )\n       ser = pd.Series.sparse.from_coo(A)\n       ser.index.dtypes\n\n4. :class:`Index` cannot be instantiated using a float16 dtype. Previously instantiating\n   an :class:`Index` using dtype ``float16`` resulted in a :class:`Float64Index` with a\n   ``float64`` dtype. It now raises a ``NotImplementedError``:\n\n   .. ipython:: python\n       :okexcept:\n\n       pd.Index([1, 2, 3], dtype=np.float16)\n\n\n.. _whatsnew_200.enhancements.io_dtype_backend:\n\nArgument ``dtype_backend``, to return pyarrow-backed or numpy-backed nullable dtypes\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nThe following functions gained a new keyword ``dtype_backend`` (:issue:`36712`)\n\n* :func:`read_csv`\n* :func:`read_clipboard`\n* :func:`read_fwf`\n* :func:`read_excel`\n* :func:`read_html`\n* :func:`read_xml`\n* :func:`read_json`\n* :func:`read_sql`\n* :func:`read_sql_query`\n* :func:`read_sql_table`\n* :func:`read_parquet`\n* :func:`read_orc`\n* :func:`read_feather`\n* :func:`read_spss`\n* :func:`to_numeric`\n* :meth:`DataFrame.convert_dtypes`\n* :meth:`Series.convert_dtypes`\n\nWhen this option is set to ``\"numpy_nullable\"`` it will return a :class:`DataFrame` that is\nbacked by nullable dtypes.\n\nWhen this keyword is set to ``\"pyarrow\"``, then these functions will return pyarrow-backed nullable :class:`ArrowDtype` DataFrames (:issue:`48957`, :issue:`49997`):\n\n* :func:`read_csv`\n* :func:`read_clipboard`\n* :func:`read_fwf`\n* :func:`read_excel`\n* :func:`read_html`\n* :func:`read_xml`\n* :func:`read_json`\n* :func:`read_sql`\n* :func:`read_sql_query`\n* :func:`read_sql_table`\n* :func:`read_parquet`\n* :func:`read_orc`\n* :func:`read_feather`\n* :func:`read_spss`\n* :func:`to_numeric`\n* :meth:`DataFrame.convert_dtypes`\n* :meth:`Series.convert_dtypes`\n\n.. ipython:: python\n\n    import io\n    data = io.StringIO(\"\"\"a,b,c,d,e,f,g,h,i\n        1,2.5,True,a,,,,,\n        3,4.5,False,b,6,7.5,True,a,\n    \"\"\")\n    df = pd.read_csv(data, dtype_backend=\"pyarrow\")\n    df.dtypes\n\n    data.seek(0)\n    df_pyarrow = pd.read_csv(data, dtype_backend=\"pyarrow\", engine=\"pyarrow\")\n    df_pyarrow.dtypes\n\nCopy-on-Write improvements\n^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n- A new lazy copy mechanism that defers the copy until the object in question is modified\n  was added to the methods listed in\n  :ref:`Copy-on-Write optimizations <copy_on_write.optimizations>`.\n  These methods return views when Copy-on-Write is enabled, which provides a significant\n  performance improvement compared to the regular execution (:issue:`49473`).\n\n- Accessing a single column of a DataFrame as a Series (e.g. ``df[\"col\"]``) now always\n  returns a new object every time it is constructed when Copy-on-Write is enabled (not\n  returning multiple times an identical, cached Series object). This ensures that those\n  Series objects correctly follow the Copy-on-Write rules (:issue:`49450`)\n\n- The :class:`Series` constructor will now create a lazy copy (deferring the copy until\n  a modification to the data happens) when constructing a Series from an existing\n  Series with the default of ``copy=False`` (:issue:`50471`)\n\n- The :class:`DataFrame` constructor will now create a lazy copy (deferring the copy until\n  a modification to the data happens) when constructing from an existing\n  :class:`DataFrame` with the default of ``copy=False`` (:issue:`51239`)\n\n- The :class:`DataFrame` constructor, when constructing a DataFrame from a dictionary\n  of Series objects and specifying ``copy=False``, will now use a lazy copy\n  of those Series objects for the columns of the DataFrame (:issue:`50777`)\n\n- The :class:`DataFrame` constructor, when constructing a DataFrame from a\n  :class:`Series` or :class:`Index` and specifying ``copy=False``, will\n  now respect Copy-on-Write.\n\n- The :class:`DataFrame` and :class:`Series` constructors, when constructing from\n  a NumPy array, will now copy the array by default to avoid mutating\n  the :class:`DataFrame` / :class:`Series`\n  when mutating the array. Specify ``copy=False`` to get the old behavior.\n  When setting ``copy=False`` pandas does not guarantee correct Copy-on-Write\n  behavior when the NumPy array is modified after creation of the\n  :class:`DataFrame` / :class:`Series`.\n\n- The :meth:`DataFrame.from_records` will now respect Copy-on-Write when called\n  with a :class:`DataFrame`.\n\n- Trying to set values using chained assignment (for example, ``df[\"a\"][1:3] = 0``)\n  will now always raise a warning when Copy-on-Write is enabled. In this mode,\n  chained assignment can never work because we are always setting into a temporary\n  object that is the result of an indexing operation (getitem), which under\n  Copy-on-Write always behaves as a copy. Thus, assigning through a chain\n  can never update the original Series or DataFrame. Therefore, an informative\n  warning is raised to the user to avoid silently doing nothing (:issue:`49467`)\n\n- :meth:`DataFrame.replace` will now respect the Copy-on-Write mechanism\n  when ``inplace=True``.\n\n- :meth:`DataFrame.transpose` will now respect the Copy-on-Write mechanism.\n\n- Arithmetic operations that can be inplace, e.g. ``ser *= 2`` will now respect the\n  Copy-on-Write mechanism.\n\n- :meth:`DataFrame.__getitem__` will now respect the Copy-on-Write mechanism when the\n  :class:`DataFrame` has :class:`MultiIndex` columns.\n\n- :meth:`Series.__getitem__` will now respect the Copy-on-Write mechanism when the\n   :class:`Series` has a :class:`MultiIndex`.\n\n- :meth:`Series.view` will now respect the Copy-on-Write mechanism.\n\nCopy-on-Write can be enabled through one of\n\n.. code-block:: python\n\n    pd.set_option(\"mode.copy_on_write\", True)\n\n\n.. code-block:: python\n\n    pd.options.mode.copy_on_write = True\n\nAlternatively, copy on write can be enabled locally through:\n\n.. code-block:: python\n\n    with pd.option_context(\"mode.copy_on_write\", True):\n        ...\n\n.. _whatsnew_200.enhancements.other:\n\nOther enhancements\n^^^^^^^^^^^^^^^^^^\n- Added support for ``str`` accessor methods when using :class:`ArrowDtype`  with a ``pyarrow.string`` type (:issue:`50325`)\n- Added support for ``dt`` accessor methods when using :class:`ArrowDtype` with a ``pyarrow.timestamp`` type (:issue:`50954`)\n- :func:`read_sas` now supports using ``encoding='infer'`` to correctly read and use the encoding specified by the sas file. (:issue:`48048`)\n- :meth:`.DataFrameGroupBy.quantile`, :meth:`.SeriesGroupBy.quantile` and :meth:`.DataFrameGroupBy.std` now preserve nullable dtypes instead of casting to numpy dtypes (:issue:`37493`)\n- :meth:`.DataFrameGroupBy.std`, :meth:`.SeriesGroupBy.std` now support datetime64, timedelta64, and :class:`DatetimeTZDtype` dtypes (:issue:`48481`)\n- :meth:`Series.add_suffix`, :meth:`DataFrame.add_suffix`, :meth:`Series.add_prefix` and :meth:`DataFrame.add_prefix` support an ``axis`` argument. If ``axis`` is set, the default behaviour of which axis to consider can be overwritten (:issue:`47819`)\n- :func:`.testing.assert_frame_equal` now shows the first element where the DataFrames differ, analogously to ``pytest``'s output (:issue:`47910`)\n- Added ``index`` parameter to :meth:`DataFrame.to_dict` (:issue:`46398`)\n- Added support for extension array dtypes in :func:`merge` (:issue:`44240`)\n- Added metadata propagation for binary operators on :class:`DataFrame` (:issue:`28283`)\n- Added ``cumsum``, ``cumprod``, ``cummin`` and ``cummax`` to the ``ExtensionArray`` interface via ``_accumulate`` (:issue:`28385`)\n- :class:`.CategoricalConversionWarning`, :class:`.InvalidComparison`, :class:`.InvalidVersion`, :class:`.LossySetitemError`, and :class:`.NoBufferPresent` are now exposed in ``pandas.errors`` (:issue:`27656`)\n- Fix ``test`` optional_extra by adding missing test package ``pytest-asyncio`` (:issue:`48361`)\n- :func:`DataFrame.astype` exception message thrown improved to include column name when type conversion is not possible. (:issue:`47571`)\n- :func:`date_range` now supports a ``unit`` keyword (\"s\", \"ms\", \"us\", or \"ns\") to specify the desired resolution of the output index (:issue:`49106`)\n- :func:`timedelta_range` now supports a ``unit`` keyword (\"s\", \"ms\", \"us\", or \"ns\") to specify the desired resolution of the output index (:issue:`49824`)\n- :meth:`DataFrame.to_json` now supports a ``mode`` keyword with supported inputs 'w' and 'a'. Defaulting to 'w', 'a' can be used when lines=True and orient='records' to append record oriented json lines to an existing json file. (:issue:`35849`)\n- Added ``name`` parameter to :meth:`IntervalIndex.from_breaks`, :meth:`IntervalIndex.from_arrays` and :meth:`IntervalIndex.from_tuples` (:issue:`48911`)\n- Improve exception message when using :func:`.testing.assert_frame_equal` on a :class:`DataFrame` to include the column that is compared (:issue:`50323`)\n- Improved error message for :func:`merge_asof` when join-columns were duplicated (:issue:`50102`)\n- Added support for extension array dtypes to :func:`get_dummies` (:issue:`32430`)\n- Added :meth:`Index.infer_objects` analogous to :meth:`Series.infer_objects` (:issue:`50034`)\n- Added ``copy`` parameter to :meth:`Series.infer_objects` and :meth:`DataFrame.infer_objects`, passing ``False`` will avoid making copies for series or columns that are already non-object or where no better dtype can be inferred (:issue:`50096`)\n- :meth:`DataFrame.plot.hist` now recognizes ``xlabel`` and ``ylabel`` arguments (:issue:`49793`)\n- :meth:`Series.drop_duplicates` has gained ``ignore_index`` keyword to reset index (:issue:`48304`)\n- :meth:`Series.dropna` and :meth:`DataFrame.dropna` has gained ``ignore_index`` keyword to reset index (:issue:`31725`)\n- Improved error message in :func:`to_datetime` for non-ISO8601 formats, informing users about the position of the first error (:issue:`50361`)\n- Improved error message when trying to align :class:`DataFrame` objects (for example, in :func:`DataFrame.compare`) to clarify that \"identically labelled\" refers to both index and columns (:issue:`50083`)\n- Added support for :meth:`Index.min` and :meth:`Index.max` for pyarrow string dtypes (:issue:`51397`)\n- Added :meth:`DatetimeIndex.as_unit` and :meth:`TimedeltaIndex.as_unit` to convert to different resolutions; supported resolutions are \"s\", \"ms\", \"us\", and \"ns\" (:issue:`50616`)\n- Added :meth:`Series.dt.unit` and :meth:`Series.dt.as_unit` to convert to different resolutions; supported resolutions are \"s\", \"ms\", \"us\", and \"ns\" (:issue:`51223`)\n- Added new argument ``dtype`` to :func:`read_sql` to be consistent with :func:`read_sql_query` (:issue:`50797`)\n- :func:`read_csv`, :func:`read_table`, :func:`read_fwf` and :func:`read_excel` now accept ``date_format`` (:issue:`50601`)\n- :func:`to_datetime` now accepts ``\"ISO8601\"`` as an argument to ``format``, which will match any ISO8601 string (but possibly not identically-formatted) (:issue:`50411`)\n- :func:`to_datetime` now accepts ``\"mixed\"`` as an argument to ``format``, which will infer the format for each element individually (:issue:`50972`)\n- Added new argument ``engine`` to :func:`read_json` to support parsing JSON with pyarrow by specifying ``engine=\"pyarrow\"`` (:issue:`48893`)\n- Added support for SQLAlchemy 2.0 (:issue:`40686`)\n- Added support for ``decimal`` parameter when ``engine=\"pyarrow\"`` in :func:`read_csv` (:issue:`51302`)\n- :class:`Index` set operations :meth:`Index.union`, :meth:`Index.intersection`, :meth:`Index.difference`, and :meth:`Index.symmetric_difference` now support ``sort=True``, which will always return a sorted result, unlike the default ``sort=None`` which does not sort in some cases (:issue:`25151`)\n- Added new escape mode \"latex-math\" to avoid escaping \"$\" in formatter (:issue:`50040`)\n\n.. ---------------------------------------------------------------------------\n.. _whatsnew_200.notable_bug_fixes:\n\nNotable bug fixes\n~~~~~~~~~~~~~~~~~\n\nThese are bug fixes that might have notable behavior changes.\n\n.. _whatsnew_200.notable_bug_fixes.cumsum_cumprod_overflow:\n\n:meth:`.DataFrameGroupBy.cumsum` and :meth:`.DataFrameGroupBy.cumprod` overflow instead of lossy casting to float\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nIn previous versions we cast to float when applying ``cumsum`` and ``cumprod`` which\nlead to incorrect results even if the result could be hold by ``int64`` dtype.\nAdditionally, the aggregation overflows consistent with numpy and the regular\n:meth:`DataFrame.cumprod` and :meth:`DataFrame.cumsum` methods when the limit of\n``int64`` is reached (:issue:`37493`).\n\n*Old Behavior*\n\n.. code-block:: ipython\n\n    In [1]: df = pd.DataFrame({\"key\": [\"b\"] * 7, \"value\": 625})\n    In [2]: df.groupby(\"key\")[\"value\"].cumprod()[5]\n    Out[2]: 5.960464477539062e+16\n\nWe return incorrect results with the 6th value.\n\n*New Behavior*\n\n.. ipython:: python\n\n    df = pd.DataFrame({\"key\": [\"b\"] * 7, \"value\": 625})\n    df.groupby(\"key\")[\"value\"].cumprod()\n\nWe overflow with the 7th value, but the 6th value is still correct.\n\n.. _whatsnew_200.notable_bug_fixes.groupby_nth_filter:\n\n:meth:`.DataFrameGroupBy.nth` and :meth:`.SeriesGroupBy.nth` now behave as filtrations\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nIn previous versions of pandas, :meth:`.DataFrameGroupBy.nth` and\n:meth:`.SeriesGroupBy.nth` acted as if they were aggregations. However, for most\ninputs ``n``, they may return either zero or multiple rows per group. This means\nthat they are filtrations, similar to e.g. :meth:`.DataFrameGroupBy.head`. pandas\nnow treats them as filtrations (:issue:`13666`).\n\n.. ipython:: python\n\n    df = pd.DataFrame({\"a\": [1, 1, 2, 1, 2], \"b\": [np.nan, 2.0, 3.0, 4.0, 5.0]})\n    gb = df.groupby(\"a\")\n\n*Old Behavior*\n\n.. code-block:: ipython\n\n    In [5]: gb.nth(n=1)\n    Out[5]:\n       A    B\n    1  1  2.0\n    4  2  5.0\n\n*New Behavior*\n\n.. ipython:: python\n\n    gb.nth(n=1)\n\nIn particular, the index of the result is derived from the input by selecting\nthe appropriate rows. Also, when ``n`` is larger than the group, no rows instead of\n``NaN`` is returned.\n\n*Old Behavior*\n\n.. code-block:: ipython\n\n    In [5]: gb.nth(n=3, dropna=\"any\")\n    Out[5]:\n        B\n    A\n    1 NaN\n    2 NaN\n\n*New Behavior*\n\n.. ipython:: python\n\n    gb.nth(n=3, dropna=\"any\")\n\n.. ---------------------------------------------------------------------------\n.. _whatsnew_200.api_breaking:\n\nBackwards incompatible API changes\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\n.. _whatsnew_200.api_breaking.unsupported_datetimelike_dtype_arg:\n\nConstruction with datetime64 or timedelta64 dtype with unsupported resolution\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nIn past versions, when constructing a :class:`Series` or :class:`DataFrame` and\npassing a \"datetime64\" or \"timedelta64\" dtype with unsupported resolution\n(i.e. anything other than \"ns\"), pandas would silently replace the given dtype\nwith its nanosecond analogue:\n\n*Previous behavior*:\n\n.. code-block:: ipython\n\n   In [5]: pd.Series([\"2016-01-01\"], dtype=\"datetime64[s]\")\n   Out[5]:\n   0   2016-01-01\n   dtype: datetime64[ns]\n\n   In [6] pd.Series([\"2016-01-01\"], dtype=\"datetime64[D]\")\n   Out[6]:\n   0   2016-01-01\n   dtype: datetime64[ns]\n\nIn pandas 2.0 we support resolutions \"s\", \"ms\", \"us\", and \"ns\". When passing\na supported dtype (e.g. \"datetime64[s]\"), the result now has exactly\nthe requested dtype:\n\n*New behavior*:\n\n.. ipython:: python\n\n   pd.Series([\"2016-01-01\"], dtype=\"datetime64[s]\")\n\nWith an un-supported dtype, pandas now raises instead of silently swapping in\na supported dtype:\n\n*New behavior*:\n\n.. ipython:: python\n   :okexcept:\n\n   pd.Series([\"2016-01-01\"], dtype=\"datetime64[D]\")\n\n.. _whatsnew_200.api_breaking.value_counts:\n\nValue counts sets the resulting name to ``count``\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nIn past versions, when running :meth:`Series.value_counts`, the result would inherit\nthe original object's name, and the result index would be nameless. This would cause\nconfusion when resetting the index, and the column names would not correspond with the\ncolumn values.\nNow, the result name will be ``'count'`` (or ``'proportion'`` if ``normalize=True`` was passed),\nand the index will be named after the original object (:issue:`49497`).\n\n*Previous behavior*:\n\n.. code-block:: ipython\n\n    In [8]: pd.Series(['quetzal', 'quetzal', 'elk'], name='animal').value_counts()\n\n    Out[2]:\n    quetzal    2\n    elk        1\n    Name: animal, dtype: int64\n\n*New behavior*:\n\n.. ipython:: python\n\n    pd.Series(['quetzal', 'quetzal', 'elk'], name='animal').value_counts()\n\nLikewise for other ``value_counts`` methods (for example, :meth:`DataFrame.value_counts`).\n\n.. _whatsnew_200.api_breaking.astype_to_unsupported_datetimelike:\n\nDisallow astype conversion to non-supported datetime64/timedelta64 dtypes\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nIn previous versions, converting a :class:`Series` or :class:`DataFrame`\nfrom ``datetime64[ns]`` to a different ``datetime64[X]`` dtype would return\nwith ``datetime64[ns]`` dtype instead of the requested dtype. In pandas 2.0,\nsupport is added for \"datetime64[s]\", \"datetime64[ms]\", and \"datetime64[us]\" dtypes,\nso converting to those dtypes gives exactly the requested dtype:\n\n*Previous behavior*:\n\n.. ipython:: python\n\n   idx = pd.date_range(\"2016-01-01\", periods=3)\n   ser = pd.Series(idx)\n\n*Previous behavior*:\n\n.. code-block:: ipython\n\n   In [4]: ser.astype(\"datetime64[s]\")\n   Out[4]:\n   0   2016-01-01\n   1   2016-01-02\n   2   2016-01-03\n   dtype: datetime64[ns]\n\nWith the new behavior, we get exactly the requested dtype:\n\n*New behavior*:\n\n.. ipython:: python\n\n   ser.astype(\"datetime64[s]\")\n\nFor non-supported resolutions e.g. \"datetime64[D]\", we raise instead of silently\nignoring the requested dtype:\n\n*New behavior*:\n\n.. ipython:: python\n   :okexcept:\n\n   ser.astype(\"datetime64[D]\")\n\nFor conversion from ``timedelta64[ns]`` dtypes, the old behavior converted\nto a floating point format.\n\n*Previous behavior*:\n\n.. ipython:: python\n\n   idx = pd.timedelta_range(\"1 Day\", periods=3)\n   ser = pd.Series(idx)\n\n*Previous behavior*:\n\n.. code-block:: ipython\n\n   In [7]: ser.astype(\"timedelta64[s]\")\n   Out[7]:\n   0     86400.0\n   1    172800.0\n   2    259200.0\n   dtype: float64\n\n   In [8]: ser.astype(\"timedelta64[D]\")\n   Out[8]:\n   0    1.0\n   1    2.0\n   2    3.0\n   dtype: float64\n\nThe new behavior, as for datetime64, either gives exactly the requested dtype or raises:\n\n*New behavior*:\n\n.. ipython:: python\n   :okexcept:\n\n   ser.astype(\"timedelta64[s]\")\n   ser.astype(\"timedelta64[D]\")\n\n.. _whatsnew_200.api_breaking.default_to_stdlib_tzinfos:\n\nUTC and fixed-offset timezones default to standard-library tzinfo objects\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nIn previous versions, the default ``tzinfo`` object used to represent UTC\nwas ``pytz.UTC``. In pandas 2.0, we default to ``datetime.timezone.utc`` instead.\nSimilarly, for timezones represent fixed UTC offsets, we use ``datetime.timezone``\nobjects instead of ``pytz.FixedOffset`` objects. See (:issue:`34916`)\n\n*Previous behavior*:\n\n.. code-block:: ipython\n\n   In [2]: ts = pd.Timestamp(\"2016-01-01\", tz=\"UTC\")\n   In [3]: type(ts.tzinfo)\n   Out[3]: pytz.UTC\n\n   In [4]: ts2 = pd.Timestamp(\"2016-01-01 04:05:06-07:00\")\n   In [3]: type(ts2.tzinfo)\n   Out[5]: pytz._FixedOffset\n\n*New behavior*:\n\n.. ipython:: python\n\n   ts = pd.Timestamp(\"2016-01-01\", tz=\"UTC\")\n   type(ts.tzinfo)\n\n   ts2 = pd.Timestamp(\"2016-01-01 04:05:06-07:00\")\n   type(ts2.tzinfo)\n\nFor timezones that are neither UTC nor fixed offsets, e.g. \"US/Pacific\", we\ncontinue to default to ``pytz`` objects.\n\n.. _whatsnew_200.api_breaking.zero_len_indexes:\n\nEmpty DataFrames/Series will now default to have a ``RangeIndex``\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nBefore, constructing an empty (where ``data`` is ``None`` or an empty list-like argument) :class:`Series` or :class:`DataFrame` without\nspecifying the axes (``index=None``, ``columns=None``) would return the axes as empty :class:`Index` with object dtype.\n\nNow, the axes return an empty :class:`RangeIndex` (:issue:`49572`).\n\n*Previous behavior*:\n\n.. code-block:: ipython\n\n   In [8]: pd.Series().index\n   Out[8]:\n   Index([], dtype='object')\n\n   In [9] pd.DataFrame().axes\n   Out[9]:\n   [Index([], dtype='object'), Index([], dtype='object')]\n\n*New behavior*:\n\n.. ipython:: python\n\n   pd.Series().index\n   pd.DataFrame().axes\n\n.. _whatsnew_200.api_breaking.to_latex:\n\nDataFrame to LaTeX has a new render engine\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nThe existing :meth:`DataFrame.to_latex` has been restructured to utilise the\nextended implementation previously available under :meth:`.Styler.to_latex`.\nThe arguments signature is similar, albeit ``col_space`` has been removed since\nit is ignored by LaTeX engines. This render engine also requires ``jinja2`` as a\ndependency which needs to be installed, since rendering is based upon jinja2 templates.\n\nThe pandas latex options below are no longer used and have been removed. The generic\nmax rows and columns arguments remain but for this functionality should be replaced\nby the Styler equivalents.\nThe alternative options giving similar functionality are indicated below:\n\n- ``display.latex.escape``: replaced with ``styler.format.escape``,\n- ``display.latex.longtable``: replaced with ``styler.latex.environment``,\n- ``display.latex.multicolumn``, ``display.latex.multicolumn_format`` and\n  ``display.latex.multirow``: replaced with ``styler.sparse.rows``,\n  ``styler.sparse.columns``, ``styler.latex.multirow_align`` and\n  ``styler.latex.multicol_align``,\n- ``display.latex.repr``: replaced with ``styler.render.repr``,\n- ``display.max_rows`` and ``display.max_columns``: replace with\n  ``styler.render.max_rows``, ``styler.render.max_columns`` and\n  ``styler.render.max_elements``.\n\nNote that due to this change some defaults have also changed:\n\n- ``multirow`` now defaults to *True*.\n- ``multirow_align`` defaults to *\"r\"* instead of *\"l\"*.\n- ``multicol_align`` defaults to *\"r\"* instead of *\"l\"*.\n- ``escape`` now defaults to *False*.\n\nNote that the behaviour of ``_repr_latex_`` is also changed. Previously\nsetting ``display.latex.repr`` would generate LaTeX only when using nbconvert for a\nJupyterNotebook, and not when the user is running the notebook. Now the\n``styler.render.repr`` option allows control of the specific output\nwithin JupyterNotebooks for operations (not just on nbconvert). See :issue:`39911`.\n\n.. _whatsnew_200.api_breaking.deps:\n\nIncreased minimum versions for dependencies\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nSome minimum supported versions of dependencies were updated.\nIf installed, we now require:\n\n+-------------------+-----------------+----------+---------+\n| Package           | Minimum Version | Required | Changed |\n+===================+=================+==========+=========+\n| mypy (dev)        | 1.0             |          |    X    |\n+-------------------+-----------------+----------+---------+\n| pytest (dev)      | 7.0.0           |          |    X    |\n+-------------------+-----------------+----------+---------+\n| pytest-xdist (dev)| 2.2.0           |          |    X    |\n+-------------------+-----------------+----------+---------+\n| hypothesis (dev)  | 6.34.2          |          |    X    |\n+-------------------+-----------------+----------+---------+\n| python-dateutil   | 2.8.2           |    X     |    X    |\n+-------------------+-----------------+----------+---------+\n| tzdata            | 2022.1          |    X     |    X    |\n+-------------------+-----------------+----------+---------+\n\nFor `optional libraries <https://pandas.pydata.org/docs/getting_started/install.html>`_ the general recommendation is to use the latest version.\nThe following table lists the lowest version per library that is currently being tested throughout the development of pandas.\nOptional libraries below the lowest tested version may still work, but are not considered supported.\n\n+-----------------+-----------------+---------+\n| Package         | Minimum Version | Changed |\n+=================+=================+=========+\n| pyarrow         | 7.0.0           |    X    |\n+-----------------+-----------------+---------+\n| matplotlib      | 3.6.1           |    X    |\n+-----------------+-----------------+---------+\n| fastparquet     | 0.6.3           |    X    |\n+-----------------+-----------------+---------+\n| xarray          | 0.21.0          |    X    |\n+-----------------+-----------------+---------+\n\nSee :ref:`install.dependencies` and :ref:`install.optional_dependencies` for more.\n\nDatetimes are now parsed with a consistent format\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nIn the past, :func:`to_datetime` guessed the format for each element independently. This was appropriate for some cases where elements had mixed date formats - however, it would regularly cause problems when users expected a consistent format but the function would switch formats between elements. As of version 2.0.0, parsing will use a consistent format, determined by the first non-NA value (unless the user specifies a format, in which case that is used).\n\n*Old behavior*:\n\n.. code-block:: ipython\n\n   In [1]: ser = pd.Series(['13-01-2000', '12-01-2000'])\n   In [2]: pd.to_datetime(ser)\n   Out[2]:\n   0   2000-01-13\n   1   2000-12-01\n   dtype: datetime64[ns]\n\n*New behavior*:\n\n.. ipython:: python\n    :okwarning:\n\n     ser = pd.Series(['13-01-2000', '12-01-2000'])\n     pd.to_datetime(ser)\n\nNote that this affects :func:`read_csv` as well.\n\nIf you still need to parse dates with inconsistent formats, you can use\n``format='mixed'`` (possibly alongside ``dayfirst``) ::\n\n     ser = pd.Series(['13-01-2000', '12 January 2000'])\n     pd.to_datetime(ser, format='mixed', dayfirst=True)\n\nor, if your formats are all ISO8601 (but possibly not identically-formatted) ::\n\n     ser = pd.Series(['2020-01-01', '2020-01-01 03:00'])\n     pd.to_datetime(ser, format='ISO8601')\n\n.. _whatsnew_200.api_breaking.other:\n\nOther API changes\n^^^^^^^^^^^^^^^^^\n- The ``freq``, ``tz``, ``nanosecond``, and ``unit`` keywords in the :class:`Timestamp` constructor are now keyword-only (:issue:`45307`, :issue:`32526`)\n- Passing ``nanoseconds`` greater than 999 or less than 0 in :class:`Timestamp` now raises a ``ValueError`` (:issue:`48538`, :issue:`48255`)\n- :func:`read_csv`: specifying an incorrect number of columns with ``index_col`` of now raises ``ParserError`` instead of ``IndexError`` when using the c parser.\n- Default value of ``dtype`` in :func:`get_dummies` is changed to ``bool`` from ``uint8`` (:issue:`45848`)\n- :meth:`DataFrame.astype`, :meth:`Series.astype`, and :meth:`DatetimeIndex.astype` casting datetime64 data to any of \"datetime64[s]\", \"datetime64[ms]\", \"datetime64[us]\" will return an object with the given resolution instead of coercing back to \"datetime64[ns]\" (:issue:`48928`)\n- :meth:`DataFrame.astype`, :meth:`Series.astype`, and :meth:`DatetimeIndex.astype` casting timedelta64 data to any of \"timedelta64[s]\", \"timedelta64[ms]\", \"timedelta64[us]\" will return an object with the given resolution instead of coercing to \"float64\" dtype (:issue:`48963`)\n- :meth:`DatetimeIndex.astype`, :meth:`TimedeltaIndex.astype`, :meth:`PeriodIndex.astype` :meth:`Series.astype`, :meth:`DataFrame.astype` with ``datetime64``, ``timedelta64`` or :class:`PeriodDtype` dtypes no longer allow converting to integer dtypes other than \"int64\", do ``obj.astype('int64', copy=False).astype(dtype)`` instead (:issue:`49715`)\n- :meth:`Index.astype` now allows casting from ``float64`` dtype to datetime-like dtypes, matching :class:`Series` behavior (:issue:`49660`)\n- Passing data with dtype of \"timedelta64[s]\", \"timedelta64[ms]\", or \"timedelta64[us]\" to :class:`TimedeltaIndex`, :class:`Series`, or :class:`DataFrame` constructors will now retain that dtype instead of casting to \"timedelta64[ns]\"; timedelta64 data with lower resolution will be cast to the lowest supported resolution \"timedelta64[s]\" (:issue:`49014`)\n- Passing ``dtype`` of \"timedelta64[s]\", \"timedelta64[ms]\", or \"timedelta64[us]\" to :class:`TimedeltaIndex`, :class:`Series`, or :class:`DataFrame` constructors will now retain that dtype instead of casting to \"timedelta64[ns]\"; passing a dtype with lower resolution for :class:`Series` or :class:`DataFrame` will be cast to the lowest supported resolution \"timedelta64[s]\" (:issue:`49014`)\n- Passing a ``np.datetime64`` object with non-nanosecond resolution to :class:`Timestamp` will retain the input resolution if it is \"s\", \"ms\", \"us\", or \"ns\"; otherwise it will be cast to the closest supported resolution (:issue:`49008`)\n- Passing ``datetime64`` values with resolution other than nanosecond to :func:`to_datetime` will retain the input resolution if it is \"s\", \"ms\", \"us\", or \"ns\"; otherwise it will be cast to the closest supported resolution (:issue:`50369`)\n- Passing integer values and a non-nanosecond datetime64 dtype (e.g. \"datetime64[s]\") :class:`DataFrame`, :class:`Series`, or :class:`Index` will treat the values as multiples of the dtype's unit, matching the behavior of e.g. ``Series(np.array(values, dtype=\"M8[s]\"))`` (:issue:`51092`)\n- Passing a string in ISO-8601 format to :class:`Timestamp` will retain the resolution of the parsed input if it is \"s\", \"ms\", \"us\", or \"ns\"; otherwise it will be cast to the closest supported resolution (:issue:`49737`)\n- The ``other`` argument in :meth:`DataFrame.mask` and :meth:`Series.mask` now defaults to ``no_default`` instead of ``np.nan`` consistent with :meth:`DataFrame.where` and :meth:`Series.where`. Entries will be filled with the corresponding NULL value (``np.nan`` for numpy dtypes, ``pd.NA`` for extension dtypes). (:issue:`49111`)\n- Changed behavior of :meth:`Series.quantile` and :meth:`DataFrame.quantile` with :class:`SparseDtype` to retain sparse dtype (:issue:`49583`)\n- When creating a :class:`Series` with a object-dtype :class:`Index` of datetime objects, pandas no longer silently converts the index to a :class:`DatetimeIndex` (:issue:`39307`, :issue:`23598`)\n- :func:`pandas.testing.assert_index_equal` with parameter ``exact=\"equiv\"`` now considers two indexes equal when both are either a :class:`RangeIndex` or :class:`Index` with an ``int64`` dtype. Previously it meant either a :class:`RangeIndex` or a :class:`Int64Index` (:issue:`51098`)\n- :meth:`Series.unique` with dtype \"timedelta64[ns]\" or \"datetime64[ns]\" now returns :class:`TimedeltaArray` or :class:`DatetimeArray` instead of ``numpy.ndarray`` (:issue:`49176`)\n- :func:`to_datetime` and :class:`DatetimeIndex` now allow sequences containing both ``datetime`` objects and numeric entries, matching :class:`Series` behavior (:issue:`49037`, :issue:`50453`)\n- :func:`pandas.api.types.is_string_dtype` now only returns ``True`` for array-likes with ``dtype=object`` when the elements are inferred to be strings (:issue:`15585`)\n- Passing a sequence containing ``datetime`` objects and ``date`` objects to :class:`Series` constructor will return with ``object`` dtype instead of ``datetime64[ns]`` dtype, consistent with :class:`Index` behavior (:issue:`49341`)\n- Passing strings that cannot be parsed as datetimes to :class:`Series` or :class:`DataFrame` with ``dtype=\"datetime64[ns]\"`` will raise instead of silently ignoring the keyword and returning ``object`` dtype (:issue:`24435`)\n- Passing a sequence containing a type that cannot be converted to :class:`Timedelta` to :func:`to_timedelta` or to the :class:`Series` or :class:`DataFrame` constructor with ``dtype=\"timedelta64[ns]\"`` or to :class:`TimedeltaIndex` now raises ``TypeError`` instead of ``ValueError`` (:issue:`49525`)\n- Changed behavior of :class:`Index` constructor with sequence containing at least one ``NaT`` and everything else either ``None`` or ``NaN`` to infer ``datetime64[ns]`` dtype instead of ``object``, matching :class:`Series` behavior (:issue:`49340`)\n- :func:`read_stata` with parameter ``index_col`` set to ``None`` (the default) will now set the index on the returned :class:`DataFrame` to a :class:`RangeIndex` instead of a :class:`Int64Index` (:issue:`49745`)\n- Changed behavior of :class:`Index`, :class:`Series`, and :class:`DataFrame` arithmetic methods when working with object-dtypes, the results no longer do type inference on the result of the array operations, use ``result.infer_objects(copy=False)`` to do type inference on the result (:issue:`49999`, :issue:`49714`)\n- Changed behavior of :class:`Index` constructor with an object-dtype ``numpy.ndarray`` containing all-``bool`` values or all-complex values, this will now retain object dtype, consistent with the :class:`Series` behavior (:issue:`49594`)\n- Changed behavior of :meth:`Series.astype` from object-dtype containing ``bytes`` objects to string dtypes; this now does ``val.decode()`` on bytes objects instead of ``str(val)``, matching :meth:`Index.astype` behavior (:issue:`45326`)\n- Added ``\"None\"`` to default ``na_values`` in :func:`read_csv` (:issue:`50286`)\n- Changed behavior of :class:`Series` and :class:`DataFrame` constructors when given an integer dtype and floating-point data that is not round numbers, this now raises ``ValueError`` instead of silently retaining the float dtype; do ``Series(data)`` or ``DataFrame(data)`` to get the old behavior, and ``Series(data).astype(dtype)`` or ``DataFrame(data).astype(dtype)`` to get the specified dtype (:issue:`49599`)\n- Changed behavior of :meth:`DataFrame.shift` with ``axis=1``, an integer ``fill_value``, and homogeneous datetime-like dtype, this now fills new columns with integer dtypes instead of casting to datetimelike (:issue:`49842`)\n- Files are now closed when encountering an exception in :func:`read_json` (:issue:`49921`)\n- Changed behavior of :func:`read_csv`, :func:`read_json` & :func:`read_fwf`, where the index will now always be a :class:`RangeIndex`, when no index is specified. Previously the index would be a :class:`Index` with dtype ``object`` if the new DataFrame/Series has length 0 (:issue:`49572`)\n- :meth:`DataFrame.values`, :meth:`DataFrame.to_numpy`, :meth:`DataFrame.xs`, :meth:`DataFrame.reindex`, :meth:`DataFrame.fillna`, and :meth:`DataFrame.replace` no longer silently consolidate the underlying arrays; do ``df = df.copy()`` to ensure consolidation (:issue:`49356`)\n- Creating a new DataFrame using a full slice on both axes with :attr:`~DataFrame.loc`\n  or :attr:`~DataFrame.iloc` (thus, ``df.loc[:, :]`` or ``df.iloc[:, :]``) now returns a\n  new DataFrame (shallow copy) instead of the original DataFrame, consistent with other\n  methods to get a full slice (for example ``df.loc[:]`` or ``df[:]``) (:issue:`49469`)\n- The :class:`Series` and :class:`DataFrame` constructors will now return a shallow copy\n  (i.e. share data, but not attributes) when passed a Series and DataFrame,\n  respectively, and with the default of ``copy=False`` (and if no other keyword triggers\n  a copy). Previously, the new Series or DataFrame would share the index attribute (e.g.\n  ``df.index = ...`` would also update the index of the parent or child) (:issue:`49523`)\n- Disallow computing ``cumprod`` for :class:`Timedelta` object; previously this returned incorrect values (:issue:`50246`)\n- :class:`DataFrame` objects read from a :class:`HDFStore` file without an index now have a :class:`RangeIndex` instead of an ``int64`` index (:issue:`51076`)\n- Instantiating an :class:`Index` with an numeric numpy dtype with data containing :class:`NA` and/or :class:`NaT` now raises a ``ValueError``. Previously a ``TypeError`` was raised (:issue:`51050`)\n- Loading a JSON file with duplicate columns using ``read_json(orient='split')`` renames columns to avoid duplicates, as :func:`read_csv` and the other readers do (:issue:`50370`)\n- The levels of the index of the :class:`Series` returned from ``Series.sparse.from_coo`` now always have dtype ``int32``. Previously they had dtype ``int64`` (:issue:`50926`)\n- :func:`to_datetime` with ``unit`` of either \"Y\" or \"M\" will now raise if a sequence contains a non-round ``float`` value, matching the ``Timestamp`` behavior (:issue:`50301`)\n- The methods :meth:`Series.round`, :meth:`DataFrame.__invert__`, :meth:`Series.__invert__`, :meth:`DataFrame.swapaxes`, :meth:`DataFrame.first`, :meth:`DataFrame.last`, :meth:`Series.first`, :meth:`Series.last` and :meth:`DataFrame.align` will now always return new objects (:issue:`51032`)\n- :class:`DataFrame` and :class:`DataFrameGroupBy` aggregations (e.g. \"sum\") with object-dtype columns no longer infer non-object dtypes for their results, explicitly call ``result.infer_objects(copy=False)`` on the result to obtain the old behavior (:issue:`51205`, :issue:`49603`)\n- Division by zero with :class:`ArrowDtype` dtypes returns ``-inf``, ``nan``, or ``inf`` depending on the numerator, instead of raising (:issue:`51541`)\n- Added :func:`pandas.api.types.is_any_real_numeric_dtype` to check for real numeric dtypes (:issue:`51152`)\n- :meth:`~arrays.ArrowExtensionArray.value_counts` now returns data with :class:`ArrowDtype` with ``pyarrow.int64`` type instead of ``\"Int64\"`` type (:issue:`51462`)\n- :func:`factorize` and :func:`unique` preserve the original dtype when passed numpy timedelta64 or datetime64 with non-nanosecond resolution (:issue:`48670`)\n\n.. note::\n\n    A current PDEP proposes the deprecation and removal of the keywords ``inplace`` and ``copy``\n    for all but a small subset of methods from the pandas API. The current discussion takes place\n    at `here <https://github.com/pandas-dev/pandas/pull/51466>`_. The keywords won't be necessary\n    anymore in the context of Copy-on-Write. If this proposal is accepted, both\n    keywords would be deprecated in the next release of pandas and removed in pandas 3.0.\n\n.. ---------------------------------------------------------------------------\n.. _whatsnew_200.deprecations:\n\nDeprecations\n~~~~~~~~~~~~\n- Deprecated parsing datetime strings with system-local timezone to ``tzlocal``, pass a ``tz`` keyword or explicitly call ``tz_localize`` instead (:issue:`50791`)\n- Deprecated argument ``infer_datetime_format`` in :func:`to_datetime` and :func:`read_csv`, as a strict version of it is now the default (:issue:`48621`)\n- Deprecated behavior of :func:`to_datetime` with ``unit`` when parsing strings, in a future version these will be parsed as datetimes (matching unit-less behavior) instead of cast to floats. To retain the old behavior, cast strings to numeric types before calling :func:`to_datetime` (:issue:`50735`)\n- Deprecated :func:`pandas.io.sql.execute` (:issue:`50185`)\n- :meth:`Index.is_boolean` has been deprecated. Use :func:`pandas.api.types.is_bool_dtype` instead (:issue:`50042`)\n- :meth:`Index.is_integer` has been deprecated. Use :func:`pandas.api.types.is_integer_dtype` instead (:issue:`50042`)\n- :meth:`Index.is_floating` has been deprecated. Use :func:`pandas.api.types.is_float_dtype` instead (:issue:`50042`)\n- :meth:`Index.holds_integer` has been deprecated. Use :func:`pandas.api.types.infer_dtype` instead (:issue:`50243`)\n- :meth:`Index.is_numeric` has been deprecated. Use :func:`pandas.api.types.is_any_real_numeric_dtype` instead (:issue:`50042`,:issue:`51152`)\n- :meth:`Index.is_categorical` has been deprecated. Use :func:`pandas.api.types.is_categorical_dtype` instead (:issue:`50042`)\n- :meth:`Index.is_object` has been deprecated. Use :func:`pandas.api.types.is_object_dtype` instead (:issue:`50042`)\n- :meth:`Index.is_interval` has been deprecated. Use :func:`pandas.api.types.is_interval_dtype` instead (:issue:`50042`)\n- Deprecated argument ``date_parser`` in :func:`read_csv`, :func:`read_table`, :func:`read_fwf`, and :func:`read_excel` in favour of ``date_format`` (:issue:`50601`)\n- Deprecated ``all`` and ``any`` reductions with ``datetime64`` and :class:`DatetimeTZDtype` dtypes, use e.g. ``(obj != pd.Timestamp(0), tz=obj.tz).all()`` instead (:issue:`34479`)\n- Deprecated unused arguments ``*args`` and ``**kwargs`` in :class:`Resampler` (:issue:`50977`)\n- Deprecated calling ``float`` or ``int`` on a single element :class:`Series` to return a ``float`` or ``int`` respectively. Extract the element before calling ``float`` or ``int`` instead (:issue:`51101`)\n- Deprecated :meth:`Grouper.groups`, use :meth:`Groupby.groups` instead (:issue:`51182`)\n- Deprecated :meth:`Grouper.grouper`, use :meth:`Groupby.grouper` instead (:issue:`51182`)\n- Deprecated :meth:`Grouper.obj`, use :meth:`Groupby.obj` instead (:issue:`51206`)\n- Deprecated :meth:`Grouper.indexer`, use :meth:`Resampler.indexer` instead (:issue:`51206`)\n- Deprecated :meth:`Grouper.ax`, use :meth:`Resampler.ax` instead (:issue:`51206`)\n- Deprecated keyword ``use_nullable_dtypes`` in :func:`read_parquet`, use ``dtype_backend`` instead (:issue:`51853`)\n- Deprecated :meth:`Series.pad` in favor of :meth:`Series.ffill` (:issue:`33396`)\n- Deprecated :meth:`Series.backfill` in favor of :meth:`Series.bfill` (:issue:`33396`)\n- Deprecated :meth:`DataFrame.pad` in favor of :meth:`DataFrame.ffill` (:issue:`33396`)\n- Deprecated :meth:`DataFrame.backfill` in favor of :meth:`DataFrame.bfill` (:issue:`33396`)\n- Deprecated :meth:`~pandas.io.stata.StataReader.close`. Use :class:`~pandas.io.stata.StataReader` as a context manager instead (:issue:`49228`)\n- Deprecated producing a scalar when iterating over a :class:`.DataFrameGroupBy` or a :class:`.SeriesGroupBy` that has been grouped by a ``level`` parameter that is a list of length 1; a tuple of length one will be returned instead (:issue:`51583`)\n\n.. ---------------------------------------------------------------------------\n.. _whatsnew_200.prior_deprecations:\n\nRemoval of prior version deprecations/changes\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n- Removed :class:`Int64Index`, :class:`UInt64Index` and :class:`Float64Index`. See also :ref:`here <whatsnew_200.enhancements.index_can_hold_numpy_numeric_dtypes>` for more information (:issue:`42717`)\n- Removed deprecated :attr:`Timestamp.freq`, :attr:`Timestamp.freqstr` and argument ``freq`` from the :class:`Timestamp` constructor and :meth:`Timestamp.fromordinal` (:issue:`14146`)\n- Removed deprecated :class:`CategoricalBlock`, :meth:`Block.is_categorical`, require datetime64 and timedelta64 values to be wrapped in :class:`DatetimeArray` or :class:`TimedeltaArray` before passing to :meth:`Block.make_block_same_class`, require ``DatetimeTZBlock.values`` to have the correct ndim when passing to the :class:`BlockManager` constructor, and removed the \"fastpath\" keyword from the :class:`SingleBlockManager` constructor (:issue:`40226`, :issue:`40571`)\n- Removed deprecated global option ``use_inf_as_null`` in favor of ``use_inf_as_na`` (:issue:`17126`)\n- Removed deprecated module ``pandas.core.index`` (:issue:`30193`)\n- Removed deprecated alias ``pandas.core.tools.datetimes.to_time``, import the function directly from ``pandas.core.tools.times`` instead (:issue:`34145`)\n- Removed deprecated alias ``pandas.io.json.json_normalize``, import the function directly from ``pandas.json_normalize`` instead (:issue:`27615`)\n- Removed deprecated :meth:`Categorical.to_dense`, use ``np.asarray(cat)`` instead (:issue:`32639`)\n- Removed deprecated :meth:`Categorical.take_nd` (:issue:`27745`)\n- Removed deprecated :meth:`Categorical.mode`, use ``Series(cat).mode()`` instead (:issue:`45033`)\n- Removed deprecated :meth:`Categorical.is_dtype_equal` and :meth:`CategoricalIndex.is_dtype_equal` (:issue:`37545`)\n- Removed deprecated :meth:`CategoricalIndex.take_nd` (:issue:`30702`)\n- Removed deprecated :meth:`Index.is_type_compatible` (:issue:`42113`)\n- Removed deprecated :meth:`Index.is_mixed`, check ``index.inferred_type`` directly instead (:issue:`32922`)\n- Removed deprecated :func:`pandas.api.types.is_categorical`; use :func:`pandas.api.types.is_categorical_dtype` instead  (:issue:`33385`)\n- Removed deprecated :meth:`Index.asi8` (:issue:`37877`)\n- Enforced deprecation changing behavior when passing ``datetime64[ns]`` dtype data and timezone-aware dtype to :class:`Series`, interpreting the values as wall-times instead of UTC times, matching :class:`DatetimeIndex` behavior (:issue:`41662`)\n- Enforced deprecation changing behavior when applying a numpy ufunc on multiple non-aligned (on the index or columns) :class:`DataFrame` that will now align the inputs first (:issue:`39239`)\n- Removed deprecated :meth:`DataFrame._AXIS_NUMBERS`, :meth:`DataFrame._AXIS_NAMES`, :meth:`Series._AXIS_NUMBERS`, :meth:`Series._AXIS_NAMES` (:issue:`33637`)\n- Removed deprecated :meth:`Index.to_native_types`, use ``obj.astype(str)`` instead (:issue:`36418`)\n- Removed deprecated :meth:`Series.iteritems`, :meth:`DataFrame.iteritems`, use ``obj.items`` instead (:issue:`45321`)\n- Removed deprecated :meth:`DataFrame.lookup` (:issue:`35224`)\n- Removed deprecated :meth:`Series.append`, :meth:`DataFrame.append`, use :func:`concat` instead (:issue:`35407`)\n- Removed deprecated :meth:`Series.iteritems`, :meth:`DataFrame.iteritems` and :meth:`HDFStore.iteritems` use ``obj.items`` instead (:issue:`45321`)\n- Removed deprecated :meth:`DatetimeIndex.union_many` (:issue:`45018`)\n- Removed deprecated ``weekofyear`` and ``week`` attributes of :class:`DatetimeArray`, :class:`DatetimeIndex` and ``dt`` accessor in favor of ``isocalendar().week`` (:issue:`33595`)\n- Removed deprecated :meth:`RangeIndex._start`, :meth:`RangeIndex._stop`, :meth:`RangeIndex._step`, use ``start``, ``stop``, ``step`` instead (:issue:`30482`)\n- Removed deprecated :meth:`DatetimeIndex.to_perioddelta`, Use ``dtindex - dtindex.to_period(freq).to_timestamp()`` instead (:issue:`34853`)\n- Removed deprecated :meth:`.Styler.hide_index` and :meth:`.Styler.hide_columns` (:issue:`49397`)\n- Removed deprecated :meth:`.Styler.set_na_rep` and :meth:`.Styler.set_precision` (:issue:`49397`)\n- Removed deprecated :meth:`.Styler.where` (:issue:`49397`)\n- Removed deprecated :meth:`.Styler.render` (:issue:`49397`)\n- Removed deprecated argument ``col_space`` in :meth:`DataFrame.to_latex` (:issue:`47970`)\n- Removed deprecated argument ``null_color`` in :meth:`.Styler.highlight_null` (:issue:`49397`)\n- Removed deprecated argument ``check_less_precise`` in :meth:`.testing.assert_frame_equal`, :meth:`.testing.assert_extension_array_equal`, :meth:`.testing.assert_series_equal`,  :meth:`.testing.assert_index_equal` (:issue:`30562`)\n- Removed deprecated ``null_counts`` argument in :meth:`DataFrame.info`. Use ``show_counts`` instead (:issue:`37999`)\n- Removed deprecated :meth:`Index.is_monotonic`, and :meth:`Series.is_monotonic`; use ``obj.is_monotonic_increasing`` instead (:issue:`45422`)\n- Removed deprecated :meth:`Index.is_all_dates` (:issue:`36697`)\n- Enforced deprecation disallowing passing a timezone-aware :class:`Timestamp` and ``dtype=\"datetime64[ns]\"`` to :class:`Series` or :class:`DataFrame` constructors (:issue:`41555`)\n- Enforced deprecation disallowing passing a sequence of timezone-aware values and ``dtype=\"datetime64[ns]\"`` to to :class:`Series` or :class:`DataFrame` constructors (:issue:`41555`)\n- Enforced deprecation disallowing ``numpy.ma.mrecords.MaskedRecords`` in the :class:`DataFrame` constructor; pass ``\"{name: data[name] for name in data.dtype.names}`` instead (:issue:`40363`)\n- Enforced deprecation disallowing unit-less \"datetime64\" dtype in :meth:`Series.astype` and :meth:`DataFrame.astype` (:issue:`47844`)\n- Enforced deprecation disallowing using ``.astype`` to convert a ``datetime64[ns]`` :class:`Series`, :class:`DataFrame`, or :class:`DatetimeIndex` to timezone-aware dtype, use ``obj.tz_localize`` or ``ser.dt.tz_localize`` instead (:issue:`39258`)\n- Enforced deprecation disallowing using ``.astype`` to convert a timezone-aware :class:`Series`, :class:`DataFrame`, or :class:`DatetimeIndex` to timezone-naive ``datetime64[ns]`` dtype, use ``obj.tz_localize(None)`` or ``obj.tz_convert(\"UTC\").tz_localize(None)`` instead (:issue:`39258`)\n- Enforced deprecation disallowing passing non boolean argument to sort in :func:`concat` (:issue:`44629`)\n- Removed Date parser functions :func:`~pandas.io.date_converters.parse_date_time`,\n  :func:`~pandas.io.date_converters.parse_date_fields`, :func:`~pandas.io.date_converters.parse_all_fields`\n  and :func:`~pandas.io.date_converters.generic_parser` (:issue:`24518`)\n- Removed argument ``index`` from the :class:`core.arrays.SparseArray` constructor (:issue:`43523`)\n- Remove argument ``squeeze`` from :meth:`DataFrame.groupby` and :meth:`Series.groupby` (:issue:`32380`)\n- Removed deprecated ``apply``, ``apply_index``, ``__call__``, ``onOffset``, and ``isAnchored`` attributes from :class:`DateOffset` (:issue:`34171`)\n- Removed ``keep_tz`` argument in :meth:`DatetimeIndex.to_series` (:issue:`29731`)\n- Remove arguments ``names`` and ``dtype`` from :meth:`Index.copy` and ``levels`` and ``codes`` from :meth:`MultiIndex.copy` (:issue:`35853`, :issue:`36685`)\n- Remove argument ``inplace`` from :meth:`MultiIndex.set_levels` and :meth:`MultiIndex.set_codes` (:issue:`35626`)\n- Removed arguments ``verbose`` and ``encoding`` from :meth:`DataFrame.to_excel` and :meth:`Series.to_excel` (:issue:`47912`)\n- Removed argument ``line_terminator`` from :meth:`DataFrame.to_csv` and :meth:`Series.to_csv`, use ``lineterminator`` instead (:issue:`45302`)\n- Removed argument ``inplace`` from :meth:`DataFrame.set_axis` and :meth:`Series.set_axis`, use ``obj = obj.set_axis(..., copy=False)`` instead (:issue:`48130`)\n- Disallow passing positional arguments to :meth:`MultiIndex.set_levels` and :meth:`MultiIndex.set_codes` (:issue:`41485`)\n- Disallow parsing to Timedelta strings with components with units \"Y\", \"y\", or \"M\", as these do not represent unambiguous durations (:issue:`36838`)\n- Removed :meth:`MultiIndex.is_lexsorted` and :meth:`MultiIndex.lexsort_depth` (:issue:`38701`)\n- Removed argument ``how`` from :meth:`PeriodIndex.astype`, use :meth:`PeriodIndex.to_timestamp` instead (:issue:`37982`)\n- Removed argument ``try_cast`` from :meth:`DataFrame.mask`, :meth:`DataFrame.where`, :meth:`Series.mask` and :meth:`Series.where` (:issue:`38836`)\n- Removed argument ``tz`` from :meth:`Period.to_timestamp`, use ``obj.to_timestamp(...).tz_localize(tz)`` instead (:issue:`34522`)\n- Removed argument ``sort_columns`` in :meth:`DataFrame.plot` and :meth:`Series.plot` (:issue:`47563`)\n- Removed argument ``is_copy`` from :meth:`DataFrame.take` and :meth:`Series.take` (:issue:`30615`)\n- Removed argument ``kind`` from :meth:`Index.get_slice_bound`, :meth:`Index.slice_indexer` and :meth:`Index.slice_locs` (:issue:`41378`)\n- Removed arguments ``prefix``, ``squeeze``, ``error_bad_lines`` and ``warn_bad_lines`` from :func:`read_csv` (:issue:`40413`, :issue:`43427`)\n- Removed arguments ``squeeze`` from :func:`read_excel` (:issue:`43427`)\n- Removed argument ``datetime_is_numeric`` from :meth:`DataFrame.describe` and :meth:`Series.describe` as datetime data will always be summarized as numeric data (:issue:`34798`)\n- Disallow passing list ``key`` to :meth:`Series.xs` and :meth:`DataFrame.xs`, pass a tuple instead (:issue:`41789`)\n- Disallow subclass-specific keywords (e.g. \"freq\", \"tz\", \"names\", \"closed\") in the :class:`Index` constructor (:issue:`38597`)\n- Removed argument ``inplace`` from :meth:`Categorical.remove_unused_categories` (:issue:`37918`)\n- Disallow passing non-round floats to :class:`Timestamp` with ``unit=\"M\"`` or ``unit=\"Y\"`` (:issue:`47266`)\n- Remove keywords ``convert_float`` and ``mangle_dupe_cols`` from :func:`read_excel` (:issue:`41176`)\n- Remove keyword ``mangle_dupe_cols`` from :func:`read_csv` and :func:`read_table` (:issue:`48137`)\n- Removed ``errors`` keyword from :meth:`DataFrame.where`, :meth:`Series.where`, :meth:`DataFrame.mask` and :meth:`Series.mask` (:issue:`47728`)\n- Disallow passing non-keyword arguments to :func:`read_excel` except ``io`` and ``sheet_name`` (:issue:`34418`)\n- Disallow passing non-keyword arguments to :meth:`DataFrame.drop` and :meth:`Series.drop` except ``labels`` (:issue:`41486`)\n- Disallow passing non-keyword arguments to :meth:`DataFrame.fillna` and :meth:`Series.fillna` except ``value`` (:issue:`41485`)\n- Disallow passing non-keyword arguments to :meth:`StringMethods.split` and :meth:`StringMethods.rsplit` except for ``pat`` (:issue:`47448`)\n- Disallow passing non-keyword arguments to :meth:`DataFrame.set_index` except ``keys`` (:issue:`41495`)\n- Disallow passing non-keyword arguments to :meth:`Resampler.interpolate` except ``method`` (:issue:`41699`)\n- Disallow passing non-keyword arguments to :meth:`DataFrame.reset_index` and :meth:`Series.reset_index` except ``level`` (:issue:`41496`)\n- Disallow passing non-keyword arguments to :meth:`DataFrame.dropna` and :meth:`Series.dropna` (:issue:`41504`)\n- Disallow passing non-keyword arguments to :meth:`ExtensionArray.argsort` (:issue:`46134`)\n- Disallow passing non-keyword arguments to :meth:`Categorical.sort_values` (:issue:`47618`)\n- Disallow passing non-keyword arguments to :meth:`Index.drop_duplicates` and :meth:`Series.drop_duplicates` (:issue:`41485`)\n- Disallow passing non-keyword arguments to :meth:`DataFrame.drop_duplicates` except for ``subset`` (:issue:`41485`)\n- Disallow passing non-keyword arguments to :meth:`DataFrame.sort_index` and :meth:`Series.sort_index` (:issue:`41506`)\n- Disallow passing non-keyword arguments to :meth:`DataFrame.interpolate` and :meth:`Series.interpolate` except for ``method`` (:issue:`41510`)\n- Disallow passing non-keyword arguments to :meth:`DataFrame.any` and :meth:`Series.any` (:issue:`44896`)\n- Disallow passing non-keyword arguments to :meth:`Index.set_names` except for ``names`` (:issue:`41551`)\n- Disallow passing non-keyword arguments to :meth:`Index.join` except for ``other`` (:issue:`46518`)\n- Disallow passing non-keyword arguments to :func:`concat` except for ``objs`` (:issue:`41485`)\n- Disallow passing non-keyword arguments to :func:`pivot` except for ``data`` (:issue:`48301`)\n- Disallow passing non-keyword arguments to :meth:`DataFrame.pivot` (:issue:`48301`)\n- Disallow passing non-keyword arguments to :func:`read_html` except for ``io`` (:issue:`27573`)\n- Disallow passing non-keyword arguments to :func:`read_json` except for ``path_or_buf`` (:issue:`27573`)\n- Disallow passing non-keyword arguments to :func:`read_sas` except for ``filepath_or_buffer`` (:issue:`47154`)\n- Disallow passing non-keyword arguments to :func:`read_stata` except for ``filepath_or_buffer`` (:issue:`48128`)\n- Disallow passing non-keyword arguments to :func:`read_csv` except ``filepath_or_buffer`` (:issue:`41485`)\n- Disallow passing non-keyword arguments to :func:`read_table` except ``filepath_or_buffer`` (:issue:`41485`)\n- Disallow passing non-keyword arguments to :func:`read_fwf` except ``filepath_or_buffer`` (:issue:`44710`)\n- Disallow passing non-keyword arguments to :func:`read_xml` except for ``path_or_buffer`` (:issue:`45133`)\n- Disallow passing non-keyword arguments to :meth:`Series.mask` and :meth:`DataFrame.mask` except ``cond`` and ``other`` (:issue:`41580`)\n- Disallow passing non-keyword arguments to :meth:`DataFrame.to_stata` except for ``path`` (:issue:`48128`)\n- Disallow passing non-keyword arguments to :meth:`DataFrame.where` and :meth:`Series.where` except for ``cond`` and ``other`` (:issue:`41523`)\n- Disallow passing non-keyword arguments to :meth:`Series.set_axis` and :meth:`DataFrame.set_axis` except for ``labels`` (:issue:`41491`)\n- Disallow passing non-keyword arguments to :meth:`Series.rename_axis` and :meth:`DataFrame.rename_axis` except for ``mapper`` (:issue:`47587`)\n- Disallow passing non-keyword arguments to :meth:`Series.clip` and :meth:`DataFrame.clip` except ``lower`` and ``upper`` (:issue:`41511`)\n- Disallow passing non-keyword arguments to :meth:`Series.bfill`, :meth:`Series.ffill`, :meth:`DataFrame.bfill` and :meth:`DataFrame.ffill` (:issue:`41508`)\n- Disallow passing non-keyword arguments to :meth:`DataFrame.replace`, :meth:`Series.replace` except for ``to_replace`` and ``value`` (:issue:`47587`)\n- Disallow passing non-keyword arguments to :meth:`DataFrame.sort_values` except for ``by`` (:issue:`41505`)\n- Disallow passing non-keyword arguments to :meth:`Series.sort_values` (:issue:`41505`)\n- Disallow passing non-keyword arguments to :meth:`DataFrame.reindex` except for ``labels`` (:issue:`17966`)\n- Disallow :meth:`Index.reindex` with non-unique :class:`Index` objects (:issue:`42568`)\n- Disallowed constructing :class:`Categorical` with scalar ``data`` (:issue:`38433`)\n- Disallowed constructing :class:`CategoricalIndex` without passing ``data`` (:issue:`38944`)\n- Removed :meth:`.Rolling.validate`, :meth:`.Expanding.validate`, and :meth:`.ExponentialMovingWindow.validate` (:issue:`43665`)\n- Removed :attr:`Rolling.win_type` returning ``\"freq\"`` (:issue:`38963`)\n- Removed :attr:`Rolling.is_datetimelike` (:issue:`38963`)\n- Removed the ``level`` keyword in :class:`DataFrame` and :class:`Series` aggregations; use ``groupby`` instead (:issue:`39983`)\n- Removed deprecated :meth:`Timedelta.delta`, :meth:`Timedelta.is_populated`, and :attr:`Timedelta.freq` (:issue:`46430`, :issue:`46476`)\n- Removed deprecated :attr:`NaT.freq` (:issue:`45071`)\n- Removed deprecated :meth:`Categorical.replace`, use :meth:`Series.replace` instead (:issue:`44929`)\n- Removed the ``numeric_only`` keyword from :meth:`Categorical.min` and :meth:`Categorical.max` in favor of ``skipna`` (:issue:`48821`)\n- Changed behavior of :meth:`DataFrame.median` and :meth:`DataFrame.mean` with ``numeric_only=None`` to not exclude datetime-like columns THIS NOTE WILL BE IRRELEVANT ONCE ``numeric_only=None`` DEPRECATION IS ENFORCED (:issue:`29941`)\n- Removed :func:`is_extension_type` in favor of :func:`is_extension_array_dtype` (:issue:`29457`)\n- Removed ``.ExponentialMovingWindow.vol`` (:issue:`39220`)\n- Removed :meth:`Index.get_value` and :meth:`Index.set_value` (:issue:`33907`, :issue:`28621`)\n- Removed :meth:`Series.slice_shift` and :meth:`DataFrame.slice_shift` (:issue:`37601`)\n- Remove :meth:`DataFrameGroupBy.pad` and :meth:`DataFrameGroupBy.backfill` (:issue:`45076`)\n- Remove ``numpy`` argument from :func:`read_json` (:issue:`30636`)\n- Disallow passing abbreviations for ``orient`` in :meth:`DataFrame.to_dict` (:issue:`32516`)\n- Disallow partial slicing on an non-monotonic :class:`DatetimeIndex` with keys which are not in Index. This now raises a ``KeyError`` (:issue:`18531`)\n- Removed ``get_offset`` in favor of :func:`to_offset` (:issue:`30340`)\n- Removed the ``warn`` keyword in :func:`infer_freq` (:issue:`45947`)\n- Removed the ``include_start`` and ``include_end`` arguments in :meth:`DataFrame.between_time` in favor of ``inclusive`` (:issue:`43248`)\n- Removed the ``closed`` argument in :meth:`date_range` and :meth:`bdate_range` in favor of ``inclusive`` argument (:issue:`40245`)\n- Removed the ``center`` keyword in :meth:`DataFrame.expanding` (:issue:`20647`)\n- Removed the ``truediv`` keyword from :func:`eval` (:issue:`29812`)\n- Removed the ``method`` and ``tolerance`` arguments in :meth:`Index.get_loc`. Use ``index.get_indexer([label], method=..., tolerance=...)`` instead (:issue:`42269`)\n- Removed the ``pandas.datetime`` submodule (:issue:`30489`)\n- Removed the ``pandas.np`` submodule (:issue:`30296`)\n- Removed ``pandas.util.testing`` in favor of ``pandas.testing`` (:issue:`30745`)\n- Removed :meth:`Series.str.__iter__` (:issue:`28277`)\n- Removed ``pandas.SparseArray`` in favor of :class:`arrays.SparseArray` (:issue:`30642`)\n- Removed ``pandas.SparseSeries`` and ``pandas.SparseDataFrame``, including pickle support. (:issue:`30642`)\n- Enforced disallowing passing an integer ``fill_value`` to :meth:`DataFrame.shift` and :meth:`Series.shift`` with datetime64, timedelta64, or period dtypes (:issue:`32591`)\n- Enforced disallowing a string column label into ``times`` in :meth:`DataFrame.ewm` (:issue:`43265`)\n- Enforced disallowing passing ``True`` and ``False`` into ``inclusive`` in :meth:`Series.between` in favor of ``\"both\"`` and ``\"neither\"`` respectively (:issue:`40628`)\n- Enforced disallowing using ``usecols`` with out of bounds indices for ``read_csv`` with ``engine=\"c\"`` (:issue:`25623`)\n- Enforced disallowing the use of ``**kwargs`` in :class:`.ExcelWriter`; use the keyword argument ``engine_kwargs`` instead (:issue:`40430`)\n- Enforced disallowing a tuple of column labels into :meth:`.DataFrameGroupBy.__getitem__` (:issue:`30546`)\n- Enforced disallowing missing labels when indexing with a sequence of labels on a level of a :class:`MultiIndex`. This now raises a ``KeyError`` (:issue:`42351`)\n- Enforced disallowing setting values with ``.loc`` using a positional slice. Use ``.loc`` with labels or ``.iloc`` with positions instead (:issue:`31840`)\n- Enforced disallowing positional indexing with a ``float`` key even if that key is a round number, manually cast to integer instead (:issue:`34193`)\n- Enforced disallowing using a :class:`DataFrame` indexer with ``.iloc``, use ``.loc`` instead for automatic alignment (:issue:`39022`)\n- Enforced disallowing ``set`` or ``dict`` indexers in ``__getitem__`` and ``__setitem__`` methods (:issue:`42825`)\n- Enforced disallowing indexing on a :class:`Index` or positional indexing on a :class:`Series` producing multi-dimensional objects e.g. ``obj[:, None]``, convert to numpy before indexing instead (:issue:`35141`)\n- Enforced disallowing ``dict`` or ``set`` objects in ``suffixes`` in :func:`merge` (:issue:`34810`)\n- Enforced disallowing :func:`merge` to produce duplicated columns through the ``suffixes`` keyword and already existing columns (:issue:`22818`)\n- Enforced disallowing using :func:`merge` or :func:`join` on a different number of levels (:issue:`34862`)\n- Enforced disallowing ``value_name`` argument in :func:`DataFrame.melt` to match an element in the :class:`DataFrame` columns (:issue:`35003`)\n- Enforced disallowing passing ``showindex`` into ``**kwargs`` in :func:`DataFrame.to_markdown` and :func:`Series.to_markdown` in favor of ``index`` (:issue:`33091`)\n- Removed setting Categorical._codes directly (:issue:`41429`)\n- Removed setting Categorical.categories directly (:issue:`47834`)\n- Removed argument ``inplace`` from :meth:`Categorical.add_categories`, :meth:`Categorical.remove_categories`, :meth:`Categorical.set_categories`, :meth:`Categorical.rename_categories`, :meth:`Categorical.reorder_categories`, :meth:`Categorical.set_ordered`, :meth:`Categorical.as_ordered`, :meth:`Categorical.as_unordered` (:issue:`37981`, :issue:`41118`, :issue:`41133`, :issue:`47834`)\n- Enforced :meth:`Rolling.count` with ``min_periods=None`` to default to the size of the window (:issue:`31302`)\n- Renamed ``fname`` to ``path`` in :meth:`DataFrame.to_parquet`, :meth:`DataFrame.to_stata` and :meth:`DataFrame.to_feather` (:issue:`30338`)\n- Enforced disallowing indexing a :class:`Series` with a single item list with a slice (e.g. ``ser[[slice(0, 2)]]``). Either convert the list to tuple, or pass the slice directly instead (:issue:`31333`)\n- Changed behavior indexing on a :class:`DataFrame` with a :class:`DatetimeIndex` index using a string indexer, previously this operated as a slice on rows, now it operates like any other column key; use ``frame.loc[key]`` for the old behavior (:issue:`36179`)\n- Enforced the ``display.max_colwidth`` option to not accept negative integers (:issue:`31569`)\n- Removed the ``display.column_space`` option in favor of ``df.to_string(col_space=...)`` (:issue:`47280`)\n- Removed the deprecated method ``mad`` from pandas classes (:issue:`11787`)\n- Removed the deprecated method ``tshift`` from pandas classes (:issue:`11631`)\n- Changed behavior of empty data passed into :class:`Series`; the default dtype will be ``object`` instead of ``float64`` (:issue:`29405`)\n- Changed the behavior of :meth:`DatetimeIndex.union`, :meth:`DatetimeIndex.intersection`, and :meth:`DatetimeIndex.symmetric_difference` with mismatched timezones to convert to UTC instead of casting to object dtype (:issue:`39328`)\n- Changed the behavior of :func:`to_datetime` with argument \"now\" with ``utc=False`` to match ``Timestamp(\"now\")`` (:issue:`18705`)\n- Changed the behavior of indexing on a timezone-aware :class:`DatetimeIndex` with a timezone-naive ``datetime`` object or vice-versa; these now behave like any other non-comparable type by raising ``KeyError`` (:issue:`36148`)\n- Changed the behavior of :meth:`Index.reindex`, :meth:`Series.reindex`, and :meth:`DataFrame.reindex` with a ``datetime64`` dtype and a ``datetime.date`` object for ``fill_value``; these are no longer considered equivalent to ``datetime.datetime`` objects so the reindex casts to object dtype (:issue:`39767`)\n- Changed behavior of :meth:`SparseArray.astype` when given a dtype that is not explicitly ``SparseDtype``, cast to the exact requested dtype rather than silently using a ``SparseDtype`` instead (:issue:`34457`)\n- Changed behavior of :meth:`Index.ravel` to return a view on the original :class:`Index` instead of a ``np.ndarray`` (:issue:`36900`)\n- Changed behavior of :meth:`Series.to_frame` and :meth:`Index.to_frame` with explicit ``name=None`` to use ``None`` for the column name instead of the index's name or default ``0`` (:issue:`45523`)\n- Changed behavior of :func:`concat` with one array of ``bool``-dtype and another of integer dtype, this now returns ``object`` dtype instead of integer dtype; explicitly cast the bool object to integer before concatenating to get the old behavior (:issue:`45101`)\n- Changed behavior of :class:`DataFrame` constructor given floating-point ``data`` and an integer ``dtype``, when the data cannot be cast losslessly, the floating point dtype is retained, matching :class:`Series` behavior (:issue:`41170`)\n- Changed behavior of :class:`Index` constructor when given a ``np.ndarray`` with object-dtype containing numeric entries; this now retains object dtype rather than inferring a numeric dtype, consistent with :class:`Series` behavior (:issue:`42870`)\n- Changed behavior of :meth:`Index.__and__`, :meth:`Index.__or__` and :meth:`Index.__xor__` to behave as logical operations (matching :class:`Series` behavior) instead of aliases for set operations (:issue:`37374`)\n- Changed behavior of :class:`DataFrame` constructor when passed a list whose first element is a :class:`Categorical`, this now treats the elements as rows casting to ``object`` dtype, consistent with behavior for other types (:issue:`38845`)\n- Changed behavior of :class:`DataFrame` constructor when passed a ``dtype`` (other than int) that the data cannot be cast to; it now raises instead of silently ignoring the dtype (:issue:`41733`)\n- Changed the behavior of :class:`Series` constructor, it will no longer infer a datetime64 or timedelta64 dtype from string entries (:issue:`41731`)\n- Changed behavior of :class:`Timestamp` constructor with a ``np.datetime64`` object and a ``tz`` passed to interpret the input as a wall-time as opposed to a UTC time (:issue:`42288`)\n- Changed behavior of :meth:`Timestamp.utcfromtimestamp` to return a timezone-aware object satisfying ``Timestamp.utcfromtimestamp(val).timestamp() == val`` (:issue:`45083`)\n- Changed behavior of :class:`Index` constructor when passed a ``SparseArray`` or ``SparseDtype`` to retain that dtype instead of casting to ``numpy.ndarray`` (:issue:`43930`)\n- Changed behavior of setitem-like operations (``__setitem__``, ``fillna``, ``where``, ``mask``, ``replace``, ``insert``, fill_value for ``shift``) on an object with :class:`DatetimeTZDtype` when using a value with a non-matching timezone, the value will be cast to the object's timezone instead of casting both to object-dtype (:issue:`44243`)\n- Changed behavior of :class:`Index`, :class:`Series`, :class:`DataFrame` constructors with floating-dtype data and a :class:`DatetimeTZDtype`, the data are now interpreted as UTC-times instead of wall-times, consistent with how integer-dtype data are treated (:issue:`45573`)\n- Changed behavior of :class:`Series` and :class:`DataFrame` constructors with integer dtype and floating-point data containing ``NaN``, this now raises ``IntCastingNaNError`` (:issue:`40110`)\n- Changed behavior of :class:`Series` and :class:`DataFrame` constructors with an integer ``dtype`` and values that are too large to losslessly cast to this dtype, this now raises ``ValueError`` (:issue:`41734`)\n- Changed behavior of :class:`Series` and :class:`DataFrame` constructors with an integer ``dtype`` and values having either ``datetime64`` or ``timedelta64`` dtypes, this now raises ``TypeError``, use ``values.view(\"int64\")`` instead (:issue:`41770`)\n- Removed the deprecated ``base`` and ``loffset`` arguments from :meth:`pandas.DataFrame.resample`, :meth:`pandas.Series.resample` and :class:`pandas.Grouper`. Use ``offset`` or ``origin`` instead (:issue:`31809`)\n- Changed behavior of :meth:`Series.fillna` and :meth:`DataFrame.fillna` with ``timedelta64[ns]`` dtype and an incompatible ``fill_value``; this now casts to ``object`` dtype instead of raising, consistent with the behavior with other dtypes (:issue:`45746`)\n- Change the default argument of ``regex`` for :meth:`Series.str.replace` from ``True`` to ``False``. Additionally, a single character ``pat`` with ``regex=True`` is now treated as a regular expression instead of a string literal. (:issue:`36695`, :issue:`24804`)\n- Changed behavior of :meth:`DataFrame.any` and :meth:`DataFrame.all` with ``bool_only=True``; object-dtype columns with all-bool values will no longer be included, manually cast to ``bool`` dtype first (:issue:`46188`)\n- Changed behavior of :meth:`DataFrame.max`, :class:`DataFrame.min`, :class:`DataFrame.mean`, :class:`DataFrame.median`, :class:`DataFrame.skew`, :class:`DataFrame.kurt` with ``axis=None`` to return a scalar applying the aggregation across both axes (:issue:`45072`)\n- Changed behavior of comparison of a :class:`Timestamp` with a ``datetime.date`` object; these now compare as un-equal and raise on inequality comparisons, matching the ``datetime.datetime`` behavior (:issue:`36131`)\n- Changed behavior of comparison of ``NaT`` with a ``datetime.date`` object; these now raise on inequality comparisons (:issue:`39196`)\n- Enforced deprecation of silently dropping columns that raised a ``TypeError`` in :class:`Series.transform` and :class:`DataFrame.transform` when used with a list or dictionary (:issue:`43740`)\n- Changed behavior of :meth:`DataFrame.apply` with list-like so that any partial failure will raise an error (:issue:`43740`)\n- Changed behaviour of :meth:`DataFrame.to_latex` to now use the Styler implementation via :meth:`.Styler.to_latex` (:issue:`47970`)\n- Changed behavior of :meth:`Series.__setitem__` with an integer key and a :class:`Float64Index` when the key is not present in the index; previously we treated the key as positional (behaving like ``series.iloc[key] = val``), now we treat it is a label (behaving like ``series.loc[key] = val``), consistent with :meth:`Series.__getitem__`` behavior (:issue:`33469`)\n- Removed ``na_sentinel`` argument from :func:`factorize`, :meth:`.Index.factorize`, and :meth:`.ExtensionArray.factorize` (:issue:`47157`)\n- Changed behavior of :meth:`Series.diff` and :meth:`DataFrame.diff` with :class:`ExtensionDtype` dtypes whose arrays do not implement ``diff``, these now raise ``TypeError`` rather than casting to numpy (:issue:`31025`)\n- Enforced deprecation of calling numpy \"ufunc\"s on :class:`DataFrame` with ``method=\"outer\"``; this now raises ``NotImplementedError`` (:issue:`36955`)\n- Enforced deprecation disallowing passing ``numeric_only=True`` to :class:`Series` reductions (``rank``, ``any``, ``all``, ...) with non-numeric dtype (:issue:`47500`)\n- Changed behavior of :meth:`.DataFrameGroupBy.apply` and :meth:`.SeriesGroupBy.apply` so that ``group_keys`` is respected even if a transformer is detected (:issue:`34998`)\n- Comparisons between a :class:`DataFrame` and a :class:`Series` where the frame's columns do not match the series's index raise ``ValueError`` instead of automatically aligning, do ``left, right = left.align(right, axis=1, copy=False)`` before comparing (:issue:`36795`)\n- Enforced deprecation ``numeric_only=None`` (the default) in DataFrame reductions that would silently drop columns that raised; ``numeric_only`` now defaults to ``False`` (:issue:`41480`)\n- Changed default of ``numeric_only`` to ``False`` in all DataFrame methods with that argument (:issue:`46096`, :issue:`46906`)\n- Changed default of ``numeric_only`` to ``False`` in :meth:`Series.rank` (:issue:`47561`)\n- Enforced deprecation of silently dropping nuisance columns in groupby and resample operations when ``numeric_only=False`` (:issue:`41475`)\n- Enforced deprecation of silently dropping nuisance columns in :class:`Rolling`, :class:`Expanding`, and :class:`ExponentialMovingWindow` ops. This will now raise a :class:`.errors.DataError` (:issue:`42834`)\n- Changed behavior in setting values with ``df.loc[:, foo] = bar`` or ``df.iloc[:, foo] = bar``, these now always attempt to set values inplace before falling back to casting (:issue:`45333`)\n- Changed default of ``numeric_only`` in various :class:`.DataFrameGroupBy` methods; all methods now default to ``numeric_only=False`` (:issue:`46072`)\n- Changed default of ``numeric_only`` to ``False`` in :class:`.Resampler` methods (:issue:`47177`)\n- Using the method :meth:`.DataFrameGroupBy.transform` with a callable that returns DataFrames will align to the input's index (:issue:`47244`)\n- When providing a list of columns of length one to :meth:`DataFrame.groupby`, the keys that are returned by iterating over the resulting :class:`DataFrameGroupBy` object will now be tuples of length one (:issue:`47761`)\n- Removed deprecated methods :meth:`ExcelWriter.write_cells`, :meth:`ExcelWriter.save`, :meth:`ExcelWriter.cur_sheet`, :meth:`ExcelWriter.handles`, :meth:`ExcelWriter.path` (:issue:`45795`)\n- The :class:`ExcelWriter` attribute ``book`` can no longer be set; it is still available to be accessed and mutated (:issue:`48943`)\n- Removed unused ``*args`` and ``**kwargs`` in :class:`Rolling`, :class:`Expanding`, and :class:`ExponentialMovingWindow` ops (:issue:`47851`)\n- Removed the deprecated argument ``line_terminator`` from :meth:`DataFrame.to_csv` (:issue:`45302`)\n- Removed the deprecated argument ``label`` from :func:`lreshape` (:issue:`30219`)\n- Arguments after ``expr`` in :meth:`DataFrame.eval` and :meth:`DataFrame.query` are keyword-only (:issue:`47587`)\n- Removed :meth:`Index._get_attributes_dict` (:issue:`50648`)\n- Removed :meth:`Series.__array_wrap__` (:issue:`50648`)\n- Changed behavior of :meth:`.DataFrame.value_counts` to return a :class:`Series` with :class:`MultiIndex` for any list-like(one element or not) but an :class:`Index` for a single label (:issue:`50829`)\n\n.. ---------------------------------------------------------------------------\n.. _whatsnew_200.performance:\n\nPerformance improvements\n~~~~~~~~~~~~~~~~~~~~~~~~\n- Performance improvement in :meth:`.DataFrameGroupBy.median` and :meth:`.SeriesGroupBy.median` and :meth:`.DataFrameGroupBy.cumprod` for nullable dtypes (:issue:`37493`)\n- Performance improvement in :meth:`.DataFrameGroupBy.all`, :meth:`.DataFrameGroupBy.any`, :meth:`.SeriesGroupBy.all`, and :meth:`.SeriesGroupBy.any` for object dtype (:issue:`50623`)\n- Performance improvement in :meth:`MultiIndex.argsort` and :meth:`MultiIndex.sort_values` (:issue:`48406`)\n- Performance improvement in :meth:`MultiIndex.size` (:issue:`48723`)\n- Performance improvement in :meth:`MultiIndex.union` without missing values and without duplicates (:issue:`48505`, :issue:`48752`)\n- Performance improvement in :meth:`MultiIndex.difference` (:issue:`48606`)\n- Performance improvement in :class:`MultiIndex` set operations with sort=None (:issue:`49010`)\n- Performance improvement in :meth:`.DataFrameGroupBy.mean`, :meth:`.SeriesGroupBy.mean`, :meth:`.DataFrameGroupBy.var`, and :meth:`.SeriesGroupBy.var` for extension array dtypes (:issue:`37493`)\n- Performance improvement in :meth:`MultiIndex.isin` when ``level=None`` (:issue:`48622`, :issue:`49577`)\n- Performance improvement in :meth:`MultiIndex.putmask` (:issue:`49830`)\n- Performance improvement in :meth:`Index.union` and :meth:`MultiIndex.union` when index contains duplicates (:issue:`48900`)\n- Performance improvement in :meth:`Series.rank` for pyarrow-backed dtypes (:issue:`50264`)\n- Performance improvement in :meth:`Series.searchsorted` for pyarrow-backed dtypes (:issue:`50447`)\n- Performance improvement in :meth:`Series.fillna` for extension array dtypes (:issue:`49722`, :issue:`50078`)\n- Performance improvement in :meth:`Index.join`, :meth:`Index.intersection` and :meth:`Index.union` for masked and arrow dtypes when :class:`Index` is monotonic (:issue:`50310`, :issue:`51365`)\n- Performance improvement for :meth:`Series.value_counts` with nullable dtype (:issue:`48338`)\n- Performance improvement for :class:`Series` constructor passing integer numpy array with nullable dtype (:issue:`48338`)\n- Performance improvement for :class:`DatetimeIndex` constructor passing a list (:issue:`48609`)\n- Performance improvement in :func:`merge` and :meth:`DataFrame.join` when joining on a sorted :class:`MultiIndex` (:issue:`48504`)\n- Performance improvement in :func:`to_datetime` when parsing strings with timezone offsets (:issue:`50107`)\n- Performance improvement in :meth:`DataFrame.loc` and :meth:`Series.loc` for tuple-based indexing of a :class:`MultiIndex` (:issue:`48384`)\n- Performance improvement for :meth:`Series.replace` with categorical dtype (:issue:`49404`)\n- Performance improvement for :meth:`MultiIndex.unique` (:issue:`48335`)\n- Performance improvement for indexing operations with nullable and arrow dtypes (:issue:`49420`, :issue:`51316`)\n- Performance improvement for :func:`concat` with extension array backed indexes (:issue:`49128`, :issue:`49178`)\n- Performance improvement for :func:`api.types.infer_dtype` (:issue:`51054`)\n- Reduce memory usage of :meth:`DataFrame.to_pickle`/:meth:`Series.to_pickle` when using BZ2 or LZMA (:issue:`49068`)\n- Performance improvement for :class:`~arrays.StringArray` constructor passing a numpy array with type ``np.str_`` (:issue:`49109`)\n- Performance improvement in :meth:`~arrays.IntervalArray.from_tuples` (:issue:`50620`)\n- Performance improvement in :meth:`~arrays.ArrowExtensionArray.factorize` (:issue:`49177`)\n- Performance improvement in :meth:`~arrays.ArrowExtensionArray.__setitem__` (:issue:`50248`, :issue:`50632`)\n- Performance improvement in :class:`~arrays.ArrowExtensionArray` comparison methods when array contains NA (:issue:`50524`)\n- Performance improvement in :meth:`~arrays.ArrowExtensionArray.to_numpy` (:issue:`49973`, :issue:`51227`)\n- Performance improvement when parsing strings to :class:`BooleanDtype` (:issue:`50613`)\n- Performance improvement in :meth:`DataFrame.join` when joining on a subset of a :class:`MultiIndex` (:issue:`48611`)\n- Performance improvement for :meth:`MultiIndex.intersection` (:issue:`48604`)\n- Performance improvement in :meth:`DataFrame.__setitem__` (:issue:`46267`)\n- Performance improvement in ``var`` and ``std`` for nullable dtypes (:issue:`48379`).\n- Performance improvement when iterating over pyarrow and nullable dtypes (:issue:`49825`, :issue:`49851`)\n- Performance improvements to :func:`read_sas` (:issue:`47403`, :issue:`47405`, :issue:`47656`, :issue:`48502`)\n- Memory improvement in :meth:`RangeIndex.sort_values` (:issue:`48801`)\n- Performance improvement in :meth:`Series.to_numpy` if ``copy=True`` by avoiding copying twice (:issue:`24345`)\n- Performance improvement in :meth:`Series.rename` with :class:`MultiIndex` (:issue:`21055`)\n- Performance improvement in :class:`DataFrameGroupBy` and :class:`SeriesGroupBy` when ``by`` is a categorical type and ``sort=False`` (:issue:`48976`)\n- Performance improvement in :class:`DataFrameGroupBy` and :class:`SeriesGroupBy` when ``by`` is a categorical type and ``observed=False`` (:issue:`49596`)\n- Performance improvement in :func:`read_stata` with parameter ``index_col`` set to ``None`` (the default). Now the index will be a :class:`RangeIndex` instead of :class:`Int64Index` (:issue:`49745`)\n- Performance improvement in :func:`merge` when not merging on the index - the new index will now be :class:`RangeIndex` instead of :class:`Int64Index` (:issue:`49478`)\n- Performance improvement in :meth:`DataFrame.to_dict` and :meth:`Series.to_dict` when using any non-object dtypes (:issue:`46470`)\n- Performance improvement in :func:`read_html` when there are multiple tables (:issue:`49929`)\n- Performance improvement in :class:`Period` constructor when constructing from a string or integer (:issue:`38312`)\n- Performance improvement in :func:`to_datetime` when using ``'%Y%m%d'`` format (:issue:`17410`)\n- Performance improvement in :func:`to_datetime` when format is given or can be inferred (:issue:`50465`)\n- Performance improvement in :meth:`Series.median` for nullable dtypes (:issue:`50838`)\n- Performance improvement in :func:`read_csv` when passing :func:`to_datetime` lambda-function to ``date_parser`` and inputs have mixed timezone offsetes (:issue:`35296`)\n- Performance improvement in :func:`isna` and :func:`isnull` (:issue:`50658`)\n- Performance improvement in :meth:`.SeriesGroupBy.value_counts` with categorical dtype (:issue:`46202`)\n- Fixed a reference leak in :func:`read_hdf` (:issue:`37441`)\n- Fixed a memory leak in :meth:`DataFrame.to_json` and :meth:`Series.to_json` when serializing datetimes and timedeltas (:issue:`40443`)\n- Decreased memory usage in many :class:`DataFrameGroupBy` methods (:issue:`51090`)\n- Performance improvement in :meth:`DataFrame.round` for an integer ``decimal`` parameter (:issue:`17254`)\n- Performance improvement in :meth:`DataFrame.replace` and :meth:`Series.replace` when using a large dict for ``to_replace`` (:issue:`6697`)\n- Memory improvement in :class:`StataReader` when reading seekable files (:issue:`48922`)\n\n.. ---------------------------------------------------------------------------\n.. _whatsnew_200.bug_fixes:\n\nBug fixes\n~~~~~~~~~\n\nCategorical\n^^^^^^^^^^^\n- Bug in :meth:`Categorical.set_categories` losing dtype information (:issue:`48812`)\n- Bug in :meth:`Series.replace` with categorical dtype when ``to_replace`` values overlap with new values (:issue:`49404`)\n- Bug in :meth:`Series.replace` with categorical dtype losing nullable dtypes of underlying categories (:issue:`49404`)\n- Bug in :meth:`DataFrame.groupby` and :meth:`Series.groupby` would reorder categories when used as a grouper (:issue:`48749`)\n- Bug in :class:`Categorical` constructor when constructing from a :class:`Categorical` object and ``dtype=\"category\"`` losing ordered-ness (:issue:`49309`)\n- Bug in :meth:`.SeriesGroupBy.min`, :meth:`.SeriesGroupBy.max`, :meth:`.DataFrameGroupBy.min`, and :meth:`.DataFrameGroupBy.max` with unordered :class:`CategoricalDtype` with no groups failing to raise ``TypeError`` (:issue:`51034`)\n\nDatetimelike\n^^^^^^^^^^^^\n- Bug in :func:`pandas.infer_freq`, raising ``TypeError`` when inferred on :class:`RangeIndex` (:issue:`47084`)\n- Bug in :func:`to_datetime` incorrectly raising ``OverflowError`` with string arguments corresponding to large integers (:issue:`50533`)\n- Bug in :func:`to_datetime` was raising on invalid offsets with ``errors='coerce'`` and ``infer_datetime_format=True`` (:issue:`48633`)\n- Bug in :class:`DatetimeIndex` constructor failing to raise when ``tz=None`` is explicitly specified in conjunction with timezone-aware ``dtype`` or data (:issue:`48659`)\n- Bug in subtracting a ``datetime`` scalar from :class:`DatetimeIndex` failing to retain the original ``freq`` attribute (:issue:`48818`)\n- Bug in ``pandas.tseries.holiday.Holiday`` where a half-open date interval causes inconsistent return types from :meth:`USFederalHolidayCalendar.holidays` (:issue:`49075`)\n- Bug in rendering :class:`DatetimeIndex` and :class:`Series` and :class:`DataFrame` with timezone-aware dtypes with ``dateutil`` or ``zoneinfo`` timezones near daylight-savings transitions (:issue:`49684`)\n- Bug in :func:`to_datetime` was raising ``ValueError`` when parsing :class:`Timestamp`, ``datetime.datetime``, ``datetime.date``, or ``np.datetime64`` objects when non-ISO8601 ``format`` was passed (:issue:`49298`, :issue:`50036`)\n- Bug in :func:`to_datetime` was raising ``ValueError`` when parsing empty string and non-ISO8601 format was passed. Now, empty strings will be parsed as :class:`NaT`, for compatibility with how is done for ISO8601 formats (:issue:`50251`)\n- Bug in :class:`Timestamp` was showing ``UserWarning``, which was not actionable by users, when parsing non-ISO8601 delimited date strings (:issue:`50232`)\n- Bug in :func:`to_datetime` was showing misleading ``ValueError`` when parsing dates with format containing ISO week directive and ISO weekday directive (:issue:`50308`)\n- Bug in :meth:`Timestamp.round` when the ``freq`` argument has zero-duration (e.g. \"0ns\") returning incorrect results instead of raising (:issue:`49737`)\n- Bug in :func:`to_datetime` was not raising ``ValueError`` when invalid format was passed and ``errors`` was ``'ignore'`` or ``'coerce'`` (:issue:`50266`)\n- Bug in :class:`DateOffset` was throwing ``TypeError`` when constructing with milliseconds and another super-daily argument (:issue:`49897`)\n- Bug in :func:`to_datetime` was not raising ``ValueError`` when parsing string with decimal date with format ``'%Y%m%d'`` (:issue:`50051`)\n- Bug in :func:`to_datetime` was not converting ``None`` to ``NaT`` when parsing mixed-offset date strings with ISO8601 format (:issue:`50071`)\n- Bug in :func:`to_datetime` was not returning input when parsing out-of-bounds date string with ``errors='ignore'`` and ``format='%Y%m%d'`` (:issue:`14487`)\n- Bug in :func:`to_datetime` was converting timezone-naive ``datetime.datetime`` to timezone-aware when parsing with timezone-aware strings, ISO8601 format, and ``utc=False`` (:issue:`50254`)\n- Bug in :func:`to_datetime` was throwing ``ValueError`` when parsing dates with ISO8601 format where some values were not zero-padded (:issue:`21422`)\n- Bug in :func:`to_datetime` was giving incorrect results when using ``format='%Y%m%d'`` and ``errors='ignore'`` (:issue:`26493`)\n- Bug in :func:`to_datetime` was failing to parse date strings ``'today'`` and ``'now'`` if ``format`` was not ISO8601 (:issue:`50359`)\n- Bug in :func:`Timestamp.utctimetuple` raising a ``TypeError`` (:issue:`32174`)\n- Bug in :func:`to_datetime` was raising ``ValueError`` when parsing mixed-offset :class:`Timestamp` with ``errors='ignore'`` (:issue:`50585`)\n- Bug in :func:`to_datetime` was incorrectly handling floating-point inputs within 1 ``unit`` of the overflow boundaries (:issue:`50183`)\n- Bug in :func:`to_datetime` with unit of \"Y\" or \"M\" giving incorrect results, not matching pointwise :class:`Timestamp` results (:issue:`50870`)\n- Bug in :meth:`Series.interpolate` and :meth:`DataFrame.interpolate` with datetime or timedelta dtypes incorrectly raising ``ValueError`` (:issue:`11312`)\n- Bug in :func:`to_datetime` was not returning input with ``errors='ignore'`` when input was out-of-bounds (:issue:`50587`)\n- Bug in :func:`DataFrame.from_records` when given a :class:`DataFrame` input with timezone-aware datetime64 columns incorrectly dropping the timezone-awareness (:issue:`51162`)\n- Bug in :func:`to_datetime` was raising ``decimal.InvalidOperation`` when parsing date strings with ``errors='coerce'`` (:issue:`51084`)\n- Bug in :func:`to_datetime` with both ``unit`` and ``origin`` specified returning incorrect results (:issue:`42624`)\n- Bug in :meth:`Series.astype` and :meth:`DataFrame.astype` when converting an object-dtype object containing timezone-aware datetimes or strings to ``datetime64[ns]`` incorrectly localizing as UTC instead of raising ``TypeError`` (:issue:`50140`)\n- Bug in :meth:`.DataFrameGroupBy.quantile` and :meth:`.SeriesGroupBy.quantile` with datetime or timedelta dtypes giving incorrect results for groups containing ``NaT`` (:issue:`51373`)\n- Bug in :meth:`.DataFrameGroupBy.quantile` and :meth:`.SeriesGroupBy.quantile` incorrectly raising with :class:`PeriodDtype` or :class:`DatetimeTZDtype` (:issue:`51373`)\n\nTimedelta\n^^^^^^^^^\n- Bug in :func:`to_timedelta` raising error when input has nullable dtype ``Float64`` (:issue:`48796`)\n- Bug in :class:`Timedelta` constructor incorrectly raising instead of returning ``NaT`` when given a ``np.timedelta64(\"nat\")`` (:issue:`48898`)\n- Bug in :class:`Timedelta` constructor failing to raise when passed both a :class:`Timedelta` object and keywords (e.g. days, seconds) (:issue:`48898`)\n- Bug in :class:`Timedelta` comparisons with very large ``datetime.timedelta`` objects incorrect raising ``OutOfBoundsTimedelta`` (:issue:`49021`)\n\nTimezones\n^^^^^^^^^\n- Bug in :meth:`Series.astype` and :meth:`DataFrame.astype` with object-dtype containing multiple timezone-aware ``datetime`` objects with heterogeneous timezones to a :class:`DatetimeTZDtype` incorrectly raising (:issue:`32581`)\n- Bug in :func:`to_datetime` was failing to parse date strings with timezone name when ``format`` was specified with ``%Z`` (:issue:`49748`)\n- Better error message when passing invalid values to ``ambiguous`` parameter in :meth:`Timestamp.tz_localize` (:issue:`49565`)\n- Bug in string parsing incorrectly allowing a :class:`Timestamp` to be constructed with an invalid timezone, which would raise when trying to print (:issue:`50668`)\n- Corrected TypeError message in :func:`objects_to_datetime64ns` to inform that DatetimeIndex has mixed timezones (:issue:`50974`)\n\nNumeric\n^^^^^^^\n- Bug in :meth:`DataFrame.add` cannot apply ufunc when inputs contain mixed DataFrame type and Series type (:issue:`39853`)\n- Bug in arithmetic operations on :class:`Series` not propagating mask when combining masked dtypes and numpy dtypes (:issue:`45810`, :issue:`42630`)\n- Bug in :meth:`DataFrame.sem` and :meth:`Series.sem` where an erroneous ``TypeError`` would always raise when using data backed by an :class:`ArrowDtype` (:issue:`49759`)\n- Bug in :meth:`Series.__add__` casting to object for list and masked :class:`Series` (:issue:`22962`)\n- Bug in :meth:`~arrays.ArrowExtensionArray.mode` where ``dropna=False`` was not respected when there was ``NA`` values (:issue:`50982`)\n- Bug in :meth:`DataFrame.query` with ``engine=\"numexpr\"`` and column names are ``min`` or ``max`` would raise a ``TypeError`` (:issue:`50937`)\n- Bug in :meth:`DataFrame.min` and :meth:`DataFrame.max` with tz-aware data containing ``pd.NaT`` and ``axis=1`` would return incorrect results (:issue:`51242`)\n\nConversion\n^^^^^^^^^^\n- Bug in constructing :class:`Series` with ``int64`` dtype from a string list raising instead of casting (:issue:`44923`)\n- Bug in constructing :class:`Series` with masked dtype and boolean values with ``NA`` raising (:issue:`42137`)\n- Bug in :meth:`DataFrame.eval` incorrectly raising an ``AttributeError`` when there are negative values in function call (:issue:`46471`)\n- Bug in :meth:`Series.convert_dtypes` not converting dtype to nullable dtype when :class:`Series` contains ``NA`` and has dtype ``object`` (:issue:`48791`)\n- Bug where any :class:`ExtensionDtype` subclass with ``kind=\"M\"`` would be interpreted as a timezone type (:issue:`34986`)\n- Bug in :class:`.arrays.ArrowExtensionArray` that would raise ``NotImplementedError`` when passed a sequence of strings or binary (:issue:`49172`)\n- Bug in :meth:`Series.astype` raising ``pyarrow.ArrowInvalid`` when converting from a non-pyarrow string dtype to a pyarrow numeric type (:issue:`50430`)\n- Bug in :meth:`DataFrame.astype` modifying input array inplace when converting to ``string`` and ``copy=False`` (:issue:`51073`)\n- Bug in :meth:`Series.to_numpy` converting to NumPy array before applying ``na_value`` (:issue:`48951`)\n- Bug in :meth:`DataFrame.astype` not copying data when converting to pyarrow dtype (:issue:`50984`)\n- Bug in :func:`to_datetime` was not respecting ``exact`` argument when ``format`` was an ISO8601 format (:issue:`12649`)\n- Bug in :meth:`TimedeltaArray.astype` raising ``TypeError`` when converting to a pyarrow duration type (:issue:`49795`)\n- Bug in :meth:`DataFrame.eval` and :meth:`DataFrame.query` raising for extension array dtypes (:issue:`29618`, :issue:`50261`, :issue:`31913`)\n- Bug in :meth:`Series` not copying data when created from :class:`Index` and ``dtype`` is equal to ``dtype`` from :class:`Index` (:issue:`52008`)\n\nStrings\n^^^^^^^\n- Bug in :func:`pandas.api.types.is_string_dtype` that would not return ``True`` for :class:`StringDtype` or :class:`ArrowDtype` with ``pyarrow.string()`` (:issue:`15585`)\n- Bug in converting string dtypes to \"datetime64[ns]\" or \"timedelta64[ns]\" incorrectly raising ``TypeError`` (:issue:`36153`)\n- Bug in setting values in a string-dtype column with an array, mutating the array as side effect when it contains missing values (:issue:`51299`)\n\nInterval\n^^^^^^^^\n- Bug in :meth:`IntervalIndex.is_overlapping` incorrect output if interval has duplicate left boundaries (:issue:`49581`)\n- Bug in :meth:`Series.infer_objects` failing to infer :class:`IntervalDtype` for an object series of :class:`Interval` objects (:issue:`50090`)\n- Bug in :meth:`Series.shift` with :class:`IntervalDtype` and invalid null ``fill_value`` failing to raise ``TypeError`` (:issue:`51258`)\n\nIndexing\n^^^^^^^^\n- Bug in :meth:`DataFrame.__setitem__` raising when indexer is a :class:`DataFrame` with ``boolean`` dtype (:issue:`47125`)\n- Bug in :meth:`DataFrame.reindex` filling with wrong values when indexing columns and index for ``uint`` dtypes (:issue:`48184`)\n- Bug in :meth:`DataFrame.loc` when setting :class:`DataFrame` with different dtypes coercing values to single dtype (:issue:`50467`)\n- Bug in :meth:`DataFrame.sort_values` where ``None`` was not returned when ``by`` is empty list and ``inplace=True`` (:issue:`50643`)\n- Bug in :meth:`DataFrame.loc` coercing dtypes when setting values with a list indexer (:issue:`49159`)\n- Bug in :meth:`Series.loc` raising error for out of bounds end of slice indexer (:issue:`50161`)\n- Bug in :meth:`DataFrame.loc` raising ``ValueError`` with all ``False`` ``bool`` indexer and empty object (:issue:`51450`)\n- Bug in :meth:`DataFrame.loc` raising ``ValueError`` with ``bool`` indexer and :class:`MultiIndex` (:issue:`47687`)\n- Bug in :meth:`DataFrame.loc` raising ``IndexError`` when setting values for a pyarrow-backed column with a non-scalar indexer (:issue:`50085`)\n- Bug in :meth:`DataFrame.__getitem__`, :meth:`Series.__getitem__`, :meth:`DataFrame.__setitem__` and :meth:`Series.__setitem__`\n  when indexing on indexes with extension float dtypes (:class:`Float64` & :class:`Float64`) or complex dtypes using integers (:issue:`51053`)\n- Bug in :meth:`DataFrame.loc` modifying object when setting incompatible value with an empty indexer (:issue:`45981`)\n- Bug in :meth:`DataFrame.__setitem__` raising ``ValueError`` when right hand side is :class:`DataFrame` with :class:`MultiIndex` columns (:issue:`49121`)\n- Bug in :meth:`DataFrame.reindex` casting dtype to ``object`` when :class:`DataFrame` has single extension array column when re-indexing ``columns`` and ``index`` (:issue:`48190`)\n- Bug in :meth:`DataFrame.iloc` raising ``IndexError`` when indexer is a :class:`Series` with numeric extension array dtype (:issue:`49521`)\n- Bug in :func:`~DataFrame.describe` when formatting percentiles in the resulting index showed more decimals than needed (:issue:`46362`)\n- Bug in :meth:`DataFrame.compare` does not recognize differences when comparing ``NA`` with value in nullable dtypes (:issue:`48939`)\n- Bug in :meth:`Series.rename` with :class:`MultiIndex` losing extension array dtypes (:issue:`21055`)\n- Bug in :meth:`DataFrame.isetitem` coercing extension array dtypes in :class:`DataFrame` to object (:issue:`49922`)\n- Bug in :meth:`Series.__getitem__` returning corrupt object when selecting from an empty pyarrow backed object (:issue:`51734`)\n- Bug in :class:`BusinessHour` would cause creation of :class:`DatetimeIndex` to fail when no opening hour was included in the index (:issue:`49835`)\n\nMissing\n^^^^^^^\n- Bug in :meth:`Index.equals` raising ``TypeError`` when :class:`Index` consists of tuples that contain ``NA`` (:issue:`48446`)\n- Bug in :meth:`Series.map` caused incorrect result when data has NaNs and defaultdict mapping was used (:issue:`48813`)\n- Bug in :class:`NA` raising a ``TypeError`` instead of return :class:`NA` when performing a binary operation with a ``bytes`` object (:issue:`49108`)\n- Bug in :meth:`DataFrame.update` with ``overwrite=False`` raising ``TypeError`` when ``self`` has column with ``NaT`` values and column not present in ``other`` (:issue:`16713`)\n- Bug in :meth:`Series.replace` raising ``RecursionError`` when replacing value in object-dtype :class:`Series` containing ``NA`` (:issue:`47480`)\n- Bug in :meth:`Series.replace` raising ``RecursionError`` when replacing value in numeric :class:`Series` with ``NA`` (:issue:`50758`)\n\nMultiIndex\n^^^^^^^^^^\n- Bug in :meth:`MultiIndex.get_indexer` not matching ``NaN`` values (:issue:`29252`, :issue:`37222`, :issue:`38623`, :issue:`42883`, :issue:`43222`, :issue:`46173`, :issue:`48905`)\n- Bug in :meth:`MultiIndex.argsort` raising ``TypeError`` when index contains :attr:`NA` (:issue:`48495`)\n- Bug in :meth:`MultiIndex.difference` losing extension array dtype (:issue:`48606`)\n- Bug in :class:`MultiIndex.set_levels` raising ``IndexError`` when setting empty level (:issue:`48636`)\n- Bug in :meth:`MultiIndex.unique` losing extension array dtype (:issue:`48335`)\n- Bug in :meth:`MultiIndex.intersection` losing extension array (:issue:`48604`)\n- Bug in :meth:`MultiIndex.union` losing extension array (:issue:`48498`, :issue:`48505`, :issue:`48900`)\n- Bug in :meth:`MultiIndex.union` not sorting when sort=None and index contains missing values (:issue:`49010`)\n- Bug in :meth:`MultiIndex.append` not checking names for equality (:issue:`48288`)\n- Bug in :meth:`MultiIndex.symmetric_difference` losing extension array (:issue:`48607`)\n- Bug in :meth:`MultiIndex.join` losing dtypes when :class:`MultiIndex` has duplicates (:issue:`49830`)\n- Bug in :meth:`MultiIndex.putmask` losing extension array (:issue:`49830`)\n- Bug in :meth:`MultiIndex.value_counts` returning a :class:`Series` indexed by flat index of tuples instead of a :class:`MultiIndex` (:issue:`49558`)\n\nI/O\n^^^\n- Bug in :func:`read_sas` caused fragmentation of :class:`DataFrame` and raised :class:`.errors.PerformanceWarning` (:issue:`48595`)\n- Improved error message in :func:`read_excel` by including the offending sheet name when an exception is raised while reading a file (:issue:`48706`)\n- Bug when a pickling a subset PyArrow-backed data that would serialize the entire data instead of the subset (:issue:`42600`)\n- Bug in :func:`read_sql_query` ignoring ``dtype`` argument when ``chunksize`` is specified and result is empty (:issue:`50245`)\n- Bug in :func:`read_csv` for a single-line csv with fewer columns than ``names`` raised :class:`.errors.ParserError` with ``engine=\"c\"`` (:issue:`47566`)\n- Bug in :func:`read_json` raising with ``orient=\"table\"`` and ``NA`` value (:issue:`40255`)\n- Bug in displaying ``string`` dtypes not showing storage option (:issue:`50099`)\n- Bug in :meth:`DataFrame.to_string` with ``header=False`` that printed the index name on the same line as the first row of the data (:issue:`49230`)\n- Bug in :meth:`DataFrame.to_string` ignoring float formatter for extension arrays (:issue:`39336`)\n- Fixed memory leak which stemmed from the initialization of the internal JSON module (:issue:`49222`)\n- Fixed issue where :func:`json_normalize` would incorrectly remove leading characters from column names that matched the ``sep`` argument (:issue:`49861`)\n- Bug in :func:`read_csv` unnecessarily overflowing for extension array dtype when containing ``NA`` (:issue:`32134`)\n- Bug in :meth:`DataFrame.to_dict` not converting ``NA`` to ``None`` (:issue:`50795`)\n- Bug in :meth:`DataFrame.to_json` where it would segfault when failing to encode a string (:issue:`50307`)\n- Bug in :meth:`DataFrame.to_html` with ``na_rep`` set when the :class:`DataFrame` contains non-scalar data (:issue:`47103`)\n- Bug in :func:`read_xml` where file-like objects failed when iterparse is used (:issue:`50641`)\n- Bug in :func:`read_csv` when ``engine=\"pyarrow\"`` where ``encoding`` parameter was not handled correctly (:issue:`51302`)\n- Bug in :func:`read_xml` ignored repeated elements when iterparse is used (:issue:`51183`)\n- Bug in :class:`ExcelWriter` leaving file handles open if an exception occurred during instantiation (:issue:`51443`)\n- Bug in :meth:`DataFrame.to_parquet` where non-string index or columns were raising a ``ValueError`` when ``engine=\"pyarrow\"`` (:issue:`52036`)\n\nPeriod\n^^^^^^\n- Bug in :meth:`Period.strftime` and :meth:`PeriodIndex.strftime`, raising ``UnicodeDecodeError`` when a locale-specific directive was passed (:issue:`46319`)\n- Bug in adding a :class:`Period` object to an array of :class:`DateOffset` objects incorrectly raising ``TypeError`` (:issue:`50162`)\n- Bug in :class:`Period` where passing a string with finer resolution than nanosecond would result in a ``KeyError`` instead of dropping the extra precision (:issue:`50417`)\n- Bug in parsing strings representing Week-periods e.g. \"2017-01-23/2017-01-29\" as minute-frequency instead of week-frequency (:issue:`50803`)\n- Bug in :meth:`.DataFrameGroupBy.sum`, :meth:`.DataFrameGroupByGroupBy.cumsum`, :meth:`.DataFrameGroupByGroupBy.prod`, :meth:`.DataFrameGroupByGroupBy.cumprod` with :class:`PeriodDtype` failing to raise ``TypeError`` (:issue:`51040`)\n- Bug in parsing empty string with :class:`Period` incorrectly raising ``ValueError`` instead of returning ``NaT`` (:issue:`51349`)\n\nPlotting\n^^^^^^^^\n- Bug in :meth:`DataFrame.plot.hist`, not dropping elements of ``weights`` corresponding to ``NaN`` values in ``data`` (:issue:`48884`)\n- ``ax.set_xlim`` was sometimes raising ``UserWarning`` which users couldn't address due to ``set_xlim`` not accepting parsing arguments - the converter now uses :func:`Timestamp` instead (:issue:`49148`)\n\nGroupby/resample/rolling\n^^^^^^^^^^^^^^^^^^^^^^^^\n- Bug in :class:`.ExponentialMovingWindow` with ``online`` not raising a ``NotImplementedError`` for unsupported operations (:issue:`48834`)\n- Bug in :meth:`.DataFrameGroupBy.sample` raises ``ValueError`` when the object is empty (:issue:`48459`)\n- Bug in :meth:`Series.groupby` raises ``ValueError`` when an entry of the index is equal to the name of the index (:issue:`48567`)\n- Bug in :meth:`.DataFrameGroupBy.resample` produces inconsistent results when passing empty DataFrame (:issue:`47705`)\n- Bug in :class:`.DataFrameGroupBy` and :class:`.SeriesGroupBy` would not include unobserved categories in result when grouping by categorical indexes (:issue:`49354`)\n- Bug in :class:`.DataFrameGroupBy` and :class:`.SeriesGroupBy` would change result order depending on the input index when grouping by categoricals (:issue:`49223`)\n- Bug in :class:`.DataFrameGroupBy` and :class:`.SeriesGroupBy` when grouping on categorical data would sort result values even when used with ``sort=False`` (:issue:`42482`)\n- Bug in :meth:`.DataFrameGroupBy.apply` and :class:`.SeriesGroupBy.apply` with ``as_index=False`` would not attempt the computation without using the grouping keys when using them failed with a ``TypeError`` (:issue:`49256`)\n- Bug in :meth:`.DataFrameGroupBy.describe` would describe the group keys (:issue:`49256`)\n- Bug in :meth:`.SeriesGroupBy.describe` with ``as_index=False`` would have the incorrect shape (:issue:`49256`)\n- Bug in :class:`.DataFrameGroupBy` and :class:`.SeriesGroupBy` with ``dropna=False`` would drop NA values when the grouper was categorical (:issue:`36327`)\n- Bug in :meth:`.SeriesGroupBy.nunique` would incorrectly raise when the grouper was an empty categorical and ``observed=True`` (:issue:`21334`)\n- Bug in :meth:`.SeriesGroupBy.nth` would raise when grouper contained NA values after subsetting from a :class:`DataFrameGroupBy` (:issue:`26454`)\n- Bug in :meth:`DataFrame.groupby` would not include a :class:`.Grouper` specified by ``key`` in the result when ``as_index=False`` (:issue:`50413`)\n- Bug in :meth:`.DataFrameGroupBy.value_counts` would raise when used with a :class:`.TimeGrouper` (:issue:`50486`)\n- Bug in :meth:`.Resampler.size` caused a wide :class:`DataFrame` to be returned instead of a :class:`Series` with :class:`MultiIndex` (:issue:`46826`)\n- Bug in :meth:`.DataFrameGroupBy.transform` and :meth:`.SeriesGroupBy.transform` would raise incorrectly when grouper had ``axis=1`` for ``\"idxmin\"`` and ``\"idxmax\"`` arguments (:issue:`45986`)\n- Bug in :class:`.DataFrameGroupBy` would raise when used with an empty DataFrame, categorical grouper, and ``dropna=False`` (:issue:`50634`)\n- Bug in :meth:`.SeriesGroupBy.value_counts` did not respect ``sort=False`` (:issue:`50482`)\n- Bug in :meth:`.DataFrameGroupBy.resample` raises ``KeyError`` when getting the result from a key list when resampling on time index (:issue:`50840`)\n- Bug in :meth:`.DataFrameGroupBy.transform` and :meth:`.SeriesGroupBy.transform` would raise incorrectly when grouper had ``axis=1`` for ``\"ngroup\"`` argument (:issue:`45986`)\n- Bug in :meth:`.DataFrameGroupBy.describe` produced incorrect results when data had duplicate columns (:issue:`50806`)\n- Bug in :meth:`.DataFrameGroupBy.agg` with ``engine=\"numba\"`` failing to respect ``as_index=False`` (:issue:`51228`)\n- Bug in :meth:`.DataFrameGroupBy.agg`, :meth:`.SeriesGroupBy.agg`, and :meth:`.Resampler.agg` would ignore arguments when passed a list of functions (:issue:`50863`)\n- Bug in :meth:`.DataFrameGroupBy.ohlc` ignoring ``as_index=False`` (:issue:`51413`)\n- Bug in :meth:`DataFrameGroupBy.agg` after subsetting columns (e.g. ``.groupby(...)[[\"a\", \"b\"]]``) would not include groupings in the result (:issue:`51186`)\n\nReshaping\n^^^^^^^^^\n- Bug in :meth:`DataFrame.pivot_table` raising ``TypeError`` for nullable dtype and ``margins=True`` (:issue:`48681`)\n- Bug in :meth:`DataFrame.unstack` and :meth:`Series.unstack` unstacking wrong level of :class:`MultiIndex` when :class:`MultiIndex` has mixed names (:issue:`48763`)\n- Bug in :meth:`DataFrame.melt` losing extension array dtype (:issue:`41570`)\n- Bug in :meth:`DataFrame.pivot` not respecting ``None`` as column name (:issue:`48293`)\n- Bug in :meth:`DataFrame.join` when ``left_on`` or ``right_on`` is or includes a :class:`CategoricalIndex` incorrectly raising ``AttributeError`` (:issue:`48464`)\n- Bug in :meth:`DataFrame.pivot_table` raising ``ValueError`` with parameter ``margins=True`` when result is an empty :class:`DataFrame` (:issue:`49240`)\n- Clarified error message in :func:`merge` when passing invalid ``validate`` option (:issue:`49417`)\n- Bug in :meth:`DataFrame.explode` raising ``ValueError`` on multiple columns with ``NaN`` values or empty lists (:issue:`46084`)\n- Bug in :meth:`DataFrame.transpose` with ``IntervalDtype`` column with ``timedelta64[ns]`` endpoints (:issue:`44917`)\n- Bug in :meth:`DataFrame.agg` and :meth:`Series.agg` would ignore arguments when passed a list of functions (:issue:`50863`)\n\nSparse\n^^^^^^\n- Bug in :meth:`Series.astype` when converting a ``SparseDtype`` with ``datetime64[ns]`` subtype to ``int64`` dtype raising, inconsistent with the non-sparse behavior (:issue:`49631`,:issue:`50087`)\n- Bug in :meth:`Series.astype` when converting a from ``datetime64[ns]`` to ``Sparse[datetime64[ns]]`` incorrectly raising (:issue:`50082`)\n- Bug in :meth:`Series.sparse.to_coo` raising ``SystemError`` when :class:`MultiIndex` contains a ``ExtensionArray`` (:issue:`50996`)\n\nExtensionArray\n^^^^^^^^^^^^^^\n- Bug in :meth:`Series.mean` overflowing unnecessarily with nullable integers (:issue:`48378`)\n- Bug in :meth:`Series.tolist` for nullable dtypes returning numpy scalars instead of python scalars (:issue:`49890`)\n- Bug in :meth:`Series.round` for pyarrow-backed dtypes raising ``AttributeError`` (:issue:`50437`)\n- Bug when concatenating an empty DataFrame with an ExtensionDtype to another DataFrame with the same ExtensionDtype, the resulting dtype turned into object (:issue:`48510`)\n- Bug in :meth:`array.PandasArray.to_numpy` raising with ``NA`` value when ``na_value`` is specified (:issue:`40638`)\n- Bug in :meth:`api.types.is_numeric_dtype` where a custom :class:`ExtensionDtype` would not return ``True`` if ``_is_numeric`` returned ``True`` (:issue:`50563`)\n- Bug in :meth:`api.types.is_integer_dtype`, :meth:`api.types.is_unsigned_integer_dtype`, :meth:`api.types.is_signed_integer_dtype`, :meth:`api.types.is_float_dtype` where a custom :class:`ExtensionDtype` would not return ``True`` if ``kind`` returned the corresponding NumPy type (:issue:`50667`)\n- Bug in :class:`Series` constructor unnecessarily overflowing for nullable unsigned integer dtypes (:issue:`38798`, :issue:`25880`)\n- Bug in setting non-string value into ``StringArray`` raising ``ValueError`` instead of ``TypeError`` (:issue:`49632`)\n- Bug in :meth:`DataFrame.reindex` not honoring the default ``copy=True`` keyword in case of columns with ExtensionDtype (and as a result also selecting multiple columns with getitem (``[]``) didn't correctly result in a copy) (:issue:`51197`)\n- Bug in :class:`~arrays.ArrowExtensionArray` logical operations ``&`` and ``|`` raising ``KeyError`` (:issue:`51688`)\n\nStyler\n^^^^^^\n- Fix :meth:`~pandas.io.formats.style.Styler.background_gradient` for nullable dtype :class:`Series` with ``NA`` values (:issue:`50712`)\n\nMetadata\n^^^^^^^^\n- Fixed metadata propagation in :meth:`DataFrame.corr` and :meth:`DataFrame.cov` (:issue:`28283`)\n\nOther\n^^^^^\n- Bug in incorrectly accepting dtype strings containing \"[pyarrow]\" more than once (:issue:`51548`)\n- Bug in :meth:`Series.searchsorted` inconsistent behavior when accepting :class:`DataFrame` as parameter ``value`` (:issue:`49620`)\n- Bug in :func:`array` failing to raise on :class:`DataFrame` inputs (:issue:`51167`)\n\n.. ---------------------------------------------------------------------------\n.. _whatsnew_200.contributors:\n\nContributors\n~~~~~~~~~~~~\n\n.. contributors:: v1.5.0rc0..v2.0.0\n\n\n.. _whatsnew_0252:\n\nWhat's new in 0.25.2 (October 15, 2019)\n---------------------------------------\n\nThese are the changes in pandas 0.25.2. See :ref:`release` for a full changelog\nincluding other versions of pandas.\n\n.. note::\n\n    pandas 0.25.2 adds compatibility for Python 3.8 (:issue:`28147`).\n\n.. _whatsnew_0252.bug_fixes:\n\nBug fixes\n~~~~~~~~~\n\nIndexing\n^^^^^^^^\n\n- Fix regression in :meth:`DataFrame.reindex` not following the ``limit`` argument (:issue:`28631`).\n- Fix regression in :meth:`RangeIndex.get_indexer` for decreasing :class:`RangeIndex` where target values may be improperly identified as missing/present (:issue:`28678`)\n\nIO\n^^\n\n- Fix regression in notebook display where ``<th>`` tags were missing for :attr:`DataFrame.index` values (:issue:`28204`).\n- Regression in :meth:`~DataFrame.to_csv` where writing a :class:`Series` or :class:`DataFrame` indexed by an :class:`IntervalIndex` would incorrectly raise a ``TypeError`` (:issue:`28210`)\n- Fix :meth:`~DataFrame.to_csv` with ``ExtensionArray`` with list-like values (:issue:`28840`).\n\nGroupBy/resample/rolling\n^^^^^^^^^^^^^^^^^^^^^^^^\n\n- Bug incorrectly raising an ``IndexError`` when passing a list of quantiles to :meth:`.DataFrameGroupBy.quantile` (:issue:`28113`).\n- Bug in :meth:`.GroupBy.shift`, :meth:`.GroupBy.bfill` and :meth:`.GroupBy.ffill` where timezone information would be dropped (:issue:`19995`, :issue:`27992`)\n\nOther\n^^^^^\n\n- Compatibility with Python 3.8 in :meth:`DataFrame.query` (:issue:`27261`)\n- Fix to ensure that tab-completion in an IPython console does not raise\n  warnings for deprecated attributes (:issue:`27900`).\n\n.. _whatsnew_0.252.contributors:\n\nContributors\n~~~~~~~~~~~~\n\n.. contributors:: v0.25.1..v0.25.2\n\n\n.. _whatsnew_151:\n\nWhat's new in 1.5.1 (October 19, 2022)\n--------------------------------------\n\nThese are the changes in pandas 1.5.1. See :ref:`release` for a full changelog\nincluding other versions of pandas.\n\n{{ header }}\n\n.. ---------------------------------------------------------------------------\n\n.. _whatsnew_151.groupby_categorical_regr:\n\nBehavior of ``groupby`` with categorical groupers (:issue:`48645`)\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\nIn versions of pandas prior to 1.5, ``groupby`` with ``dropna=False`` would still drop\nNA values when the grouper was a categorical dtype. A fix for this was attempted in\n1.5, however it introduced a regression where passing ``observed=False`` and\n``dropna=False`` to ``groupby`` would result in only observed categories. It was found\nthat the patch fixing the ``dropna=False`` bug is incompatible with ``observed=False``,\nand decided that the best resolution is to restore the correct ``observed=False``\nbehavior at the cost of reintroducing the ``dropna=False`` bug.\n\n.. ipython:: python\n\n   df = pd.DataFrame(\n       {\n           \"x\": pd.Categorical([1, None], categories=[1, 2, 3]),\n           \"y\": [3, 4],\n       }\n   )\n   df\n\n*1.5.0 behavior*:\n\n.. code-block:: ipython\n\n   In [3]:  Correct behavior, NA values are not dropped\n           df.groupby(\"x\", observed=True, dropna=False).sum()\n   Out[3]:\n        y\n   x\n   1    3\n   NaN  4\n\n\n   In [4]:  Incorrect behavior, only observed categories present\n           df.groupby(\"x\", observed=False, dropna=False).sum()\n   Out[4]:\n        y\n   x\n   1    3\n   NaN  4\n\n\n*1.5.1 behavior*:\n\n.. ipython:: python\n\n    Incorrect behavior, NA values are dropped\n   df.groupby(\"x\", observed=True, dropna=False).sum()\n\n    Correct behavior, unobserved categories present (NA values still dropped)\n   df.groupby(\"x\", observed=False, dropna=False).sum()\n\n.. _whatsnew_151.regressions:\n\nFixed regressions\n~~~~~~~~~~~~~~~~~\n- Fixed Regression in :meth:`Series.__setitem__` casting ``None`` to ``NaN`` for object dtype (:issue:`48665`)\n- Fixed Regression in :meth:`DataFrame.loc` when setting values as a :class:`DataFrame` with all ``True`` indexer (:issue:`48701`)\n- Regression in :func:`.read_csv` causing an ``EmptyDataError`` when using an UTF-8 file handle that was already read from (:issue:`48646`)\n- Regression in :func:`to_datetime` when ``utc=True`` and ``arg`` contained timezone naive and aware arguments raised a ``ValueError`` (:issue:`48678`)\n- Fixed regression in :meth:`DataFrame.loc` raising ``FutureWarning`` when setting an empty :class:`DataFrame` (:issue:`48480`)\n- Fixed regression in :meth:`DataFrame.describe` raising ``TypeError`` when result contains ``NA`` (:issue:`48778`)\n- Fixed regression in :meth:`DataFrame.plot` ignoring invalid ``colormap`` for ``kind=\"scatter\"`` (:issue:`48726`)\n- Fixed regression in :meth:`MultiIndex.values` resetting ``freq`` attribute of underlying :class:`Index` object (:issue:`49054`)\n- Fixed performance regression in :func:`factorize` when ``na_sentinel`` is not ``None`` and ``sort=False`` (:issue:`48620`)\n- Fixed regression causing an ``AttributeError`` during warning emitted if the provided table name in :meth:`DataFrame.to_sql` and the table name actually used in the database do not match (:issue:`48733`)\n- Fixed regression in :func:`to_datetime` when ``arg`` was a date string with nanosecond and ``format`` contained ``%f`` would raise a ``ValueError`` (:issue:`48767`)\n- Fixed regression in :func:`testing.assert_frame_equal` raising for :class:`MultiIndex` with :class:`Categorical` and ``check_like=True`` (:issue:`48975`)\n- Fixed regression in :meth:`DataFrame.fillna` replacing wrong values for ``datetime64[ns]`` dtype and ``inplace=True`` (:issue:`48863`)\n- Fixed :meth:`.DataFrameGroupBy.size` not returning a Series when ``axis=1`` (:issue:`48738`)\n- Fixed Regression in :meth:`.DataFrameGroupBy.apply` when user defined function is called on an empty dataframe (:issue:`47985`)\n- Fixed regression in :meth:`DataFrame.apply` when passing non-zero ``axis`` via keyword argument (:issue:`48656`)\n- Fixed regression in :meth:`Series.groupby` and :meth:`DataFrame.groupby` when the grouper is a nullable data type (e.g. :class:`Int64`) or a PyArrow-backed string array, contains null values, and ``dropna=False`` (:issue:`48794`)\n- Fixed performance regression in :meth:`Series.isin` with mismatching dtypes (:issue:`49162`)\n- Fixed regression in :meth:`DataFrame.to_parquet` raising when file name was specified as ``bytes`` (:issue:`48944`)\n- Fixed regression in :class:`ExcelWriter` where the ``book`` attribute could no longer be set; however setting this attribute is now deprecated and this ability will be removed in a future version of pandas (:issue:`48780`)\n- Fixed regression in :meth:`DataFrame.corrwith` when computing correlation on tied data with ``method=\"spearman\"`` (:issue:`48826`)\n\n.. ---------------------------------------------------------------------------\n\n.. _whatsnew_151.bug_fixes:\n\nBug fixes\n~~~~~~~~~\n- Bug in :meth:`Series.__getitem__` not falling back to positional for integer keys and boolean :class:`Index` (:issue:`48653`)\n- Bug in :meth:`DataFrame.to_hdf` raising ``AssertionError`` with boolean index (:issue:`48667`)\n- Bug in :func:`testing.assert_index_equal` for extension arrays with non matching ``NA`` raising ``ValueError`` (:issue:`48608`)\n- Bug in :meth:`DataFrame.pivot_table` raising unexpected ``FutureWarning`` when setting datetime column as index (:issue:`48683`)\n- Bug in :meth:`DataFrame.sort_values` emitting unnecessary ``FutureWarning`` when called on :class:`DataFrame` with boolean sparse columns (:issue:`48784`)\n- Bug in :class:`.arrays.ArrowExtensionArray` with a comparison operator to an invalid object would not raise a ``NotImplementedError`` (:issue:`48833`)\n\n.. ---------------------------------------------------------------------------\n\n.. _whatsnew_151.other:\n\nOther\n~~~~~\n- Avoid showing deprecated signatures when introspecting functions with warnings about arguments becoming keyword-only (:issue:`48692`)\n\n.. ---------------------------------------------------------------------------\n\n.. _whatsnew_151.contributors:\n\nContributors\n~~~~~~~~~~~~\n\n.. contributors:: v1.5.0..v1.5.1\n\n\n.. _whatsnew_0141:\n\nVersion 0.14.1 (July 11, 2014)\n------------------------------\n\n{{ header }}\n\n\nThis is a minor release from 0.14.0 and includes a small number of API changes, several new features,\nenhancements, and performance improvements along with a large number of bug fixes. We recommend that all\nusers upgrade to this version.\n\n- Highlights include:\n\n  - New methods :meth:`~pandas.DataFrame.select_dtypes` to select columns\n    based on the dtype and :meth:`~pandas.Series.sem` to calculate the\n    standard error of the mean.\n  - Support for dateutil timezones (see :ref:`docs <timeseries.timezone>`).\n  - Support for ignoring full line comments in the :func:`~pandas.read_csv`\n    text parser.\n  - New documentation section on :ref:`Options and Settings <options>`.\n  - Lots of bug fixes.\n\n- :ref:`Enhancements <whatsnew_0141.enhancements>`\n- :ref:`API Changes <whatsnew_0141.api>`\n- :ref:`Performance Improvements <whatsnew_0141.performance>`\n- :ref:`Experimental Changes <whatsnew_0141.experimental>`\n- :ref:`Bug Fixes <whatsnew_0141.bug_fixes>`\n\n.. _whatsnew_0141.api:\n\nAPI changes\n~~~~~~~~~~~\n\n- Openpyxl now raises a ValueError on construction of the openpyxl writer\n  instead of warning on pandas import (:issue:`7284`).\n\n- For ``StringMethods.extract``, when no match is found, the result - only\n  containing ``NaN`` values - now also has ``dtype=object`` instead of\n  ``float`` (:issue:`7242`)\n\n- ``Period`` objects no longer raise a ``TypeError`` when compared using ``==``\n  with another object that *isn't* a ``Period``. Instead\n  when comparing a ``Period`` with another object using ``==`` if the other\n  object isn't a ``Period`` ``False`` is returned. (:issue:`7376`)\n\n- Previously, the behaviour on resetting the time or not in\n  ``offsets.apply``, ``rollforward`` and ``rollback`` operations differed\n  between offsets. With the support of the ``normalize`` keyword for all offsets(see\n  below) with a default value of False (preserve time), the behaviour changed for certain\n  offsets (BusinessMonthBegin, MonthEnd, BusinessMonthEnd, CustomBusinessMonthEnd,\n  BusinessYearBegin, LastWeekOfMonth, FY5253Quarter, LastWeekOfMonth, Easter):\n\n  .. code-block:: ipython\n\n    In [6]: from pandas.tseries import offsets\n\n    In [7]: d = pd.Timestamp('2014-01-01 09:00')\n\n     old behaviour < 0.14.1\n    In [8]: d + offsets.MonthEnd()\n    Out[8]: pd.Timestamp('2014-01-31 00:00:00')\n\n  Starting from 0.14.1 all offsets preserve time by default. The old\n  behaviour can be obtained with ``normalize=True``\n\n  .. ipython:: python\n     :suppress:\n\n     import pandas.tseries.offsets as offsets\n\n     d = pd.Timestamp(\"2014-01-01 09:00\")\n\n  .. ipython:: python\n\n      new behaviour\n     d + offsets.MonthEnd()\n     d + offsets.MonthEnd(normalize=True)\n\n  Note that for the other offsets the default behaviour did not change.\n\n- Add back ``N/A N/A`` as a default NA value in text parsing, (regression from 0.12) (:issue:`5521`)\n- Raise a ``TypeError`` on inplace-setting with a ``.where`` and a non ``np.nan`` value as this is inconsistent\n  with a set-item expression like ``df[mask] = None`` (:issue:`7656`)\n\n\n.. _whatsnew_0141.enhancements:\n\nEnhancements\n~~~~~~~~~~~~\n\n- Add ``dropna`` argument to ``value_counts`` and ``nunique`` (:issue:`5569`).\n- Add :meth:`~pandas.DataFrame.select_dtypes` method to allow selection of\n  columns based on dtype (:issue:`7316`). See :ref:`the docs <basics.selectdtypes>`.\n- All ``offsets`` supports the ``normalize`` keyword to specify whether\n  ``offsets.apply``, ``rollforward`` and ``rollback`` resets the time (hour,\n  minute, etc) or not (default ``False``, preserves time) (:issue:`7156`):\n\n  .. code-block:: python\n\n     import pandas.tseries.offsets as offsets\n\n     day = offsets.Day()\n     day.apply(pd.Timestamp(\"2014-01-01 09:00\"))\n\n     day = offsets.Day(normalize=True)\n     day.apply(pd.Timestamp(\"2014-01-01 09:00\"))\n\n- ``PeriodIndex`` is represented as the same format as ``DatetimeIndex`` (:issue:`7601`)\n- ``StringMethods`` now work on empty Series (:issue:`7242`)\n- The file parsers ``read_csv`` and ``read_table`` now ignore line comments provided by\n  the parameter ``comment``, which accepts only a single character for the C reader.\n  In particular, they allow for comments before file data begins (:issue:`2685`)\n- Add ``NotImplementedError`` for simultaneous use of ``chunksize`` and ``nrows``\n  for read_csv() (:issue:`6774`).\n- Tests for basic reading of public S3 buckets now exist (:issue:`7281`).\n- ``read_html`` now sports an ``encoding`` argument that is passed to the\n  underlying parser library. You can use this to read non-ascii encoded web\n  pages (:issue:`7323`).\n- ``read_excel`` now supports reading from URLs in the same way\n  that ``read_csv`` does.  (:issue:`6809`)\n- Support for dateutil timezones, which can now be used in the same way as\n  pytz timezones across pandas. (:issue:`4688`)\n\n  .. ipython:: python\n\n     rng = pd.date_range(\n         \"3/6/2012 00:00\", periods=10, freq=\"D\", tz=\"dateutil/Europe/London\"\n     )\n     rng.tz\n\n  See :ref:`the docs <timeseries.timezone>`.\n\n- Implemented ``sem`` (standard error of the mean) operation for ``Series``,\n  ``DataFrame``, ``Panel``, and ``Groupby`` (:issue:`6897`)\n- Add ``nlargest`` and ``nsmallest`` to the ``Series`` ``groupby`` allowlist,\n  which means you can now use these methods on a ``SeriesGroupBy`` object\n  (:issue:`7053`).\n- All offsets ``apply``, ``rollforward`` and ``rollback`` can now handle ``np.datetime64``, previously results in ``ApplyTypeError`` (:issue:`7452`)\n- ``Period`` and ``PeriodIndex`` can contain ``NaT`` in its values (:issue:`7485`)\n- Support pickling ``Series``, ``DataFrame`` and ``Panel`` objects with\n  non-unique labels along *item* axis (``index``, ``columns`` and ``items``\n  respectively) (:issue:`7370`).\n- Improved inference of datetime/timedelta with mixed null objects. Regression from 0.13.1 in interpretation of an object Index\n  with all null elements (:issue:`7431`)\n\n.. _whatsnew_0141.performance:\n\nPerformance\n~~~~~~~~~~~\n- Improvements in dtype inference for numeric operations involving yielding performance gains for dtypes: ``int64``, ``timedelta64``, ``datetime64`` (:issue:`7223`)\n- Improvements in Series.transform for significant performance gains (:issue:`6496`)\n- Improvements in DataFrame.transform with ufuncs and built-in grouper functions for significant performance gains (:issue:`7383`)\n- Regression in groupby aggregation of datetime64 dtypes (:issue:`7555`)\n- Improvements in ``MultiIndex.from_product`` for large iterables (:issue:`7627`)\n\n\n.. _whatsnew_0141.experimental:\n\nExperimental\n~~~~~~~~~~~~\n\n- ``pandas.io.data.Options`` has a new method, ``get_all_data`` method, and now consistently returns a\n  MultiIndexed ``DataFrame`` (:issue:`5602`)\n- ``io.gbq.read_gbq`` and ``io.gbq.to_gbq`` were refactored to remove the\n  dependency on the Google ``bq.py`` command line client. This submodule\n  now uses ``httplib2`` and the Google ``apiclient`` and ``oauth2client`` API client\n  libraries which should be more stable and, therefore, reliable than\n  ``bq.py``. See :ref:`the docs <io.bigquery>`. (:issue:`6937`).\n\n\n.. _whatsnew_0141.bug_fixes:\n\nBug fixes\n~~~~~~~~~\n- Bug in ``DataFrame.where`` with a symmetric shaped frame and a passed other of a DataFrame (:issue:`7506`)\n- Bug in Panel indexing with a MultiIndex axis (:issue:`7516`)\n- Regression in datetimelike slice indexing with a duplicated index and non-exact end-points (:issue:`7523`)\n- Bug in setitem with list-of-lists and single vs mixed types (:issue:`7551`:)\n- Bug in time ops with non-aligned Series (:issue:`7500`)\n- Bug in timedelta inference when assigning an incomplete Series (:issue:`7592`)\n- Bug in groupby ``.nth`` with a Series and integer-like column name (:issue:`7559`)\n- Bug in ``Series.get`` with a boolean accessor (:issue:`7407`)\n- Bug in ``value_counts`` where ``NaT`` did not qualify as missing (``NaN``) (:issue:`7423`)\n- Bug in ``to_timedelta`` that accepted invalid units and misinterpreted 'm/h' (:issue:`7611`, :issue:`6423`)\n- Bug in line plot doesn't set correct ``xlim`` if ``secondary_y=True`` (:issue:`7459`)\n- Bug in grouped ``hist`` and ``scatter`` plots use old ``figsize`` default (:issue:`7394`)\n- Bug in plotting subplots with ``DataFrame.plot``, ``hist`` clears passed ``ax`` even if the number of subplots is one (:issue:`7391`).\n- Bug in plotting subplots with ``DataFrame.boxplot`` with ``by`` kw raises ``ValueError`` if the number of subplots exceeds 1 (:issue:`7391`).\n- Bug in subplots displays ``ticklabels`` and ``labels`` in different rule (:issue:`5897`)\n- Bug in ``Panel.apply`` with a MultiIndex as an axis (:issue:`7469`)\n- Bug in ``DatetimeIndex.insert`` doesn't preserve ``name`` and ``tz`` (:issue:`7299`)\n- Bug in ``DatetimeIndex.asobject`` doesn't preserve ``name`` (:issue:`7299`)\n- Bug in MultiIndex slicing with datetimelike ranges (strings and Timestamps), (:issue:`7429`)\n- Bug in ``Index.min`` and ``max`` doesn't handle ``nan`` and ``NaT`` properly (:issue:`7261`)\n- Bug in ``PeriodIndex.min/max`` results in ``int`` (:issue:`7609`)\n- Bug in ``resample`` where ``fill_method`` was ignored if you passed ``how`` (:issue:`2073`)\n- Bug in ``TimeGrouper`` doesn't exclude column specified by ``key`` (:issue:`7227`)\n- Bug in ``DataFrame`` and ``Series`` bar and barh plot raises ``TypeError`` when ``bottom``\n  and ``left`` keyword is specified (:issue:`7226`)\n- Bug in ``DataFrame.hist`` raises ``TypeError`` when it contains non numeric column (:issue:`7277`)\n- Bug in ``Index.delete`` does not preserve ``name`` and ``freq`` attributes (:issue:`7302`)\n- Bug in ``DataFrame.query()``/``eval`` where local string variables with the \n  sign were being treated as temporaries attempting to be deleted\n  (:issue:`7300`).\n- Bug in ``Float64Index`` which didn't allow duplicates (:issue:`7149`).\n- Bug in ``DataFrame.replace()`` where truthy values were being replaced\n  (:issue:`7140`).\n- Bug in ``StringMethods.extract()`` where a single match group Series\n  would use the matcher's name instead of the group name (:issue:`7313`).\n- Bug in ``isnull()`` when ``mode.use_inf_as_null == True`` where isnull\n  wouldn't test ``True`` when it encountered an ``inf``/``-inf``\n  (:issue:`7315`).\n- Bug in inferred_freq results in None for eastern hemisphere timezones (:issue:`7310`)\n- Bug in ``Easter`` returns incorrect date when offset is negative (:issue:`7195`)\n- Bug in broadcasting with ``.div``, integer dtypes and divide-by-zero (:issue:`7325`)\n- Bug in ``CustomBusinessDay.apply`` raises ``NameError`` when ``np.datetime64`` object is passed (:issue:`7196`)\n- Bug in ``MultiIndex.append``, ``concat`` and ``pivot_table`` don't preserve timezone (:issue:`6606`)\n- Bug in ``.loc`` with a list of indexers on a single-multi index level (that is not nested) (:issue:`7349`)\n- Bug in ``Series.map`` when mapping a dict with tuple keys of different lengths (:issue:`7333`)\n- Bug all ``StringMethods`` now work on empty Series (:issue:`7242`)\n- Fix delegation of ``read_sql`` to ``read_sql_query`` when query does not contain 'select' (:issue:`7324`).\n- Bug where a string column name assignment to a ``DataFrame`` with a\n  ``Float64Index`` raised a ``TypeError`` during a call to ``np.isnan``\n  (:issue:`7366`).\n- Bug where ``NDFrame.replace()`` didn't correctly replace objects with\n  ``Period`` values (:issue:`7379`).\n- Bug in ``.ix`` getitem should always return a Series (:issue:`7150`)\n- Bug in MultiIndex slicing with incomplete indexers (:issue:`7399`)\n- Bug in MultiIndex slicing with a step in a sliced level (:issue:`7400`)\n- Bug where negative indexers in ``DatetimeIndex`` were not correctly sliced\n  (:issue:`7408`)\n- Bug where ``NaT`` wasn't repr'd correctly in a ``MultiIndex`` (:issue:`7406`,\n  :issue:`7409`).\n- Bug where bool objects were converted to ``nan`` in ``convert_objects``\n  (:issue:`7416`).\n- Bug in ``quantile`` ignoring the axis keyword argument (:issue:`7306`)\n- Bug where ``nanops._maybe_null_out`` doesn't work with complex numbers\n  (:issue:`7353`)\n- Bug in several ``nanops`` functions when ``axis==0`` for\n  1-dimensional ``nan`` arrays (:issue:`7354`)\n- Bug where ``nanops.nanmedian`` doesn't work when ``axis==None``\n  (:issue:`7352`)\n- Bug where ``nanops._has_infs`` doesn't work with many dtypes\n  (:issue:`7357`)\n- Bug in ``StataReader.data`` where reading a 0-observation dta failed (:issue:`7369`)\n- Bug in ``StataReader`` when reading Stata 13 (117) files containing fixed width strings (:issue:`7360`)\n- Bug in ``StataWriter`` where encoding was ignored (:issue:`7286`)\n- Bug in ``DatetimeIndex`` comparison doesn't handle ``NaT`` properly (:issue:`7529`)\n- Bug in passing input with ``tzinfo`` to some offsets ``apply``, ``rollforward`` or ``rollback`` resets ``tzinfo`` or raises ``ValueError`` (:issue:`7465`)\n- Bug in ``DatetimeIndex.to_period``, ``PeriodIndex.asobject``, ``PeriodIndex.to_timestamp`` doesn't preserve ``name`` (:issue:`7485`)\n- Bug in ``DatetimeIndex.to_period`` and ``PeriodIndex.to_timestamp`` handle ``NaT`` incorrectly (:issue:`7228`)\n- Bug in ``offsets.apply``, ``rollforward`` and ``rollback`` may return normal ``datetime`` (:issue:`7502`)\n- Bug in ``resample`` raises ``ValueError`` when target contains ``NaT`` (:issue:`7227`)\n- Bug in ``Timestamp.tz_localize`` resets ``nanosecond`` info (:issue:`7534`)\n- Bug in ``DatetimeIndex.asobject`` raises ``ValueError`` when it contains ``NaT`` (:issue:`7539`)\n- Bug in ``Timestamp.__new__`` doesn't preserve nanosecond properly (:issue:`7610`)\n- Bug in ``Index.astype(float)`` where it would return an ``object`` dtype\n  ``Index`` (:issue:`7464`).\n- Bug in ``DataFrame.reset_index`` loses ``tz`` (:issue:`3950`)\n- Bug in ``DatetimeIndex.freqstr`` raises ``AttributeError`` when ``freq`` is ``None`` (:issue:`7606`)\n- Bug in ``GroupBy.size`` created by ``TimeGrouper`` raises ``AttributeError`` (:issue:`7453`)\n- Bug in single column bar plot is misaligned (:issue:`7498`).\n- Bug in area plot with tz-aware time series raises ``ValueError`` (:issue:`7471`)\n- Bug in non-monotonic ``Index.union`` may preserve ``name`` incorrectly (:issue:`7458`)\n- Bug in ``DatetimeIndex.intersection`` doesn't preserve timezone (:issue:`4690`)\n- Bug in ``rolling_var`` where a window larger than the array would raise an error(:issue:`7297`)\n- Bug with last plotted timeseries dictating ``xlim`` (:issue:`2960`)\n- Bug with ``secondary_y`` axis not being considered for timeseries ``xlim`` (:issue:`3490`)\n- Bug in ``Float64Index`` assignment with a non scalar indexer (:issue:`7586`)\n- Bug in ``pandas.core.strings.str_contains`` does not properly match in a case insensitive fashion when ``regex=False`` and ``case=False`` (:issue:`7505`)\n- Bug in ``expanding_cov``, ``expanding_corr``, ``rolling_cov``, and ``rolling_corr`` for two arguments with mismatched index  (:issue:`7512`)\n- Bug in ``to_sql`` taking the boolean column as text column (:issue:`7678`)\n- Bug in grouped ``hist`` doesn't handle ``rot`` kw and ``sharex`` kw properly (:issue:`7234`)\n- Bug in ``.loc`` performing fallback integer indexing with ``object`` dtype indices (:issue:`7496`)\n- Bug (regression) in ``PeriodIndex`` constructor when passed ``Series`` objects (:issue:`7701`).\n\n\n.. _whatsnew_0.14.1.contributors:\n\nContributors\n~~~~~~~~~~~~\n\n.. contributors:: v0.14.0..v0.14.1\n\n\n.. _whatsnew_0140:\n\nVersion 0.14.0 (May 31 , 2014)\n------------------------------\n\n{{ header }}\n\n\nThis is a major release from 0.13.1 and includes a small number of API changes, several new features,\nenhancements, and performance improvements along with a large number of bug fixes. We recommend that all\nusers upgrade to this version.\n\n- Highlights include:\n\n  - Officially support Python 3.4\n  - SQL interfaces updated to use ``sqlalchemy``, See :ref:`Here<whatsnew_0140.sql>`.\n  - Display interface changes, See :ref:`Here<whatsnew_0140.display>`\n  - MultiIndexing Using Slicers, See :ref:`Here<whatsnew_0140.slicers>`.\n  - Ability to join a singly-indexed DataFrame with a MultiIndexed DataFrame, see :ref:`Here <merging.join_on_mi>`\n  - More consistency in groupby results and more flexible groupby specifications, See :ref:`Here<whatsnew_0140.groupby>`\n  - Holiday calendars are now supported in ``CustomBusinessDay``, see :ref:`Here <timeseries.holiday>`\n  - Several improvements in plotting functions, including: hexbin, area and pie plots, see :ref:`Here<whatsnew_0140.plotting>`.\n  - Performance doc section on I/O operations, See :ref:`Here <io.perf>`\n\n- :ref:`Other Enhancements <whatsnew_0140.enhancements>`\n\n- :ref:`API Changes <whatsnew_0140.api>`\n\n- :ref:`Text Parsing API Changes <whatsnew_0140.parsing>`\n\n- :ref:`Groupby API Changes <whatsnew_0140.groupby>`\n\n- :ref:`Performance Improvements <whatsnew_0140.performance>`\n\n- :ref:`Prior Deprecations <whatsnew_0140.prior_deprecations>`\n\n- :ref:`Deprecations <whatsnew_0140.deprecations>`\n\n- :ref:`Known Issues <whatsnew_0140.knownissues>`\n\n- :ref:`Bug Fixes <whatsnew_0140.bug_fixes>`\n\n.. warning::\n\n   In 0.14.0 all ``NDFrame`` based containers have undergone significant internal refactoring. Before that each block of\n   homogeneous data had its own labels and extra care was necessary to keep those in sync with the parent container's labels.\n   This should not have any visible user/API behavior changes (:issue:`6745`)\n\n.. _whatsnew_0140.api:\n\nAPI changes\n~~~~~~~~~~~\n\n- ``read_excel`` uses 0 as the default sheet (:issue:`6573`)\n- ``iloc`` will now accept out-of-bounds indexers for slices, e.g. a value that exceeds the length of the object being\n  indexed. These will be excluded. This will make pandas conform more with python/numpy indexing of out-of-bounds\n  values. A single indexer that is out-of-bounds and drops the dimensions of the object will still raise\n  ``IndexError`` (:issue:`6296`, :issue:`6299`). This could result in an empty axis (e.g. an empty DataFrame being returned)\n\n  .. ipython:: python\n\n     dfl = pd.DataFrame(np.random.randn(5, 2), columns=list('AB'))\n     dfl\n     dfl.iloc[:, 2:3]\n     dfl.iloc[:, 1:3]\n     dfl.iloc[4:6]\n\n  These are out-of-bounds selections\n\n  .. code-block:: python\n\n     >>> dfl.iloc[[4, 5, 6]]\n     IndexError: positional indexers are out-of-bounds\n\n     >>> dfl.iloc[:, 4]\n     IndexError: single positional indexer is out-of-bounds\n\n- Slicing with negative start, stop & step values handles corner cases better (:issue:`6531`):\n\n  - ``df.iloc[:-len(df)]`` is now empty\n  - ``df.iloc[len(df)::-1]`` now enumerates all elements in reverse\n\n- The :meth:`DataFrame.interpolate` keyword ``downcast`` default has been changed from ``infer`` to\n  ``None``. This is to preserve the original dtype unless explicitly requested otherwise (:issue:`6290`).\n- When converting a dataframe to HTML it used to return ``Empty DataFrame``. This special case has\n  been removed, instead a header with the column names is returned (:issue:`6062`).\n- ``Series`` and ``Index`` now internally share more common operations, e.g. ``factorize(),nunique(),value_counts()`` are\n  now supported on ``Index`` types as well. The ``Series.weekday`` property from is removed\n  from Series for API consistency. Using a ``DatetimeIndex/PeriodIndex`` method on a Series will now raise a ``TypeError``.\n  (:issue:`4551`, :issue:`4056`, :issue:`5519`, :issue:`6380`, :issue:`7206`).\n\n- Add ``is_month_start``, ``is_month_end``, ``is_quarter_start``, ``is_quarter_end``, ``is_year_start``, ``is_year_end`` accessors for ``DateTimeIndex`` / ``Timestamp`` which return a boolean array of whether the timestamp(s) are at the start/end of the month/quarter/year defined by the frequency of the ``DateTimeIndex`` / ``Timestamp`` (:issue:`4565`, :issue:`6998`)\n\n- Local variable usage has changed in\n  :func:`pandas.eval`/:meth:`DataFrame.eval`/:meth:`DataFrame.query`\n  (:issue:`5987`). For the :class:`~pandas.DataFrame` methods, two things have\n  changed\n\n  - Column names are now given precedence over locals\n  - Local variables must be referred to explicitly. This means that even if\n    you have a local variable that is *not* a column you must still refer to\n    it with the ``''`` prefix.\n  - You can have an expression like ``df.query('a < a')`` with no complaints\n    from ``pandas`` about ambiguity of the name ``a``.\n  - The top-level :func:`pandas.eval` function does not allow you use the\n    ``''`` prefix and provides you with an error message telling you so.\n  - ``NameResolutionError`` was removed because it isn't necessary anymore.\n\n- Define and document the order of column vs index names in query/eval (:issue:`6676`)\n- ``concat`` will now concatenate mixed Series and DataFrames using the Series name\n  or numbering columns as needed (:issue:`2385`). See :ref:`the docs <merging.mixed_ndims>`\n- Slicing and advanced/boolean indexing operations on ``Index`` classes as well\n  as :meth:`Index.delete` and :meth:`Index.drop` methods will no longer change the type of the\n  resulting index (:issue:`6440`, :issue:`7040`)\n\n  .. ipython:: python\n\n     i = pd.Index([1, 2, 3, 'a', 'b', 'c'])\n     i[[0, 1, 2]]\n     i.drop(['a', 'b', 'c'])\n\n  Previously, the above operation would return ``Int64Index``.  If you'd like\n  to do this manually, use :meth:`Index.astype`\n\n  .. ipython:: python\n\n     i[[0, 1, 2]].astype(np.int_)\n\n- ``set_index`` no longer converts MultiIndexes to an Index of tuples. For example,\n  the old behavior returned an Index in this case (:issue:`6459`):\n\n  .. ipython:: python\n     :suppress:\n\n     np.random.seed(1234)\n     from itertools import product\n     tuples = list(product(('a', 'b'), ('c', 'd')))\n     mi = pd.MultiIndex.from_tuples(tuples)\n     df_multi = pd.DataFrame(np.random.randn(4, 2), index=mi)\n     tuple_ind = pd.Index(tuples, tupleize_cols=False)\n     df_multi.index\n\n  .. ipython:: python\n\n      Old behavior, casted MultiIndex to an Index\n     tuple_ind\n     df_multi.set_index(tuple_ind)\n\n      New behavior\n     mi\n     df_multi.set_index(mi)\n\n  This also applies when passing multiple indices to ``set_index``:\n\n  .. ipython:: python\n\n    suppress\n    df_multi.index = tuple_ind\n\n     Old output, 2-level MultiIndex of tuples\n    df_multi.set_index([df_multi.index, df_multi.index])\n\n    suppress\n    df_multi.index = mi\n\n     New output, 4-level MultiIndex\n    df_multi.set_index([df_multi.index, df_multi.index])\n\n- ``pairwise`` keyword was added to the statistical moment functions\n  ``rolling_cov``, ``rolling_corr``, ``ewmcov``, ``ewmcorr``,\n  ``expanding_cov``, ``expanding_corr`` to allow the calculation of moving\n  window covariance and correlation matrices (:issue:`4950`). See\n  :ref:`Computing rolling pairwise covariances and correlations\n  <window.corr_pairwise>` in the docs.\n\n  .. code-block:: ipython\n\n     In [1]: df = pd.DataFrame(np.random.randn(10, 4), columns=list('ABCD'))\n\n     In [4]: covs = pd.rolling_cov(df[['A', 'B', 'C']],\n       ....:                       df[['B', 'C', 'D']],\n       ....:                       5,\n       ....:                       pairwise=True)\n\n\n     In [5]: covs[df.index[-1]]\n     Out[5]:\n               B         C         D\n     A  0.035310  0.326593 -0.505430\n     B  0.137748 -0.006888 -0.005383\n     C -0.006888  0.861040  0.020762\n\n- ``Series.iteritems()`` is now lazy (returns an iterator rather than a list). This was the documented behavior prior to 0.14. (:issue:`6760`)\n\n- Added ``nunique`` and ``value_counts`` functions to ``Index`` for counting unique elements. (:issue:`6734`)\n- ``stack`` and ``unstack`` now raise a ``ValueError`` when the ``level`` keyword refers\n  to a non-unique item in the ``Index`` (previously raised a ``KeyError``). (:issue:`6738`)\n- drop unused order argument from ``Series.sort``; args now are in the same order as ``Series.order``;\n  add ``na_position`` arg to conform to ``Series.order`` (:issue:`6847`)\n- default sorting algorithm for ``Series.order`` is now ``quicksort``, to conform with ``Series.sort``\n  (and numpy defaults)\n- add ``inplace`` keyword to ``Series.order/sort`` to make them inverses (:issue:`6859`)\n- ``DataFrame.sort`` now places NaNs at the beginning or end of the sort according to the ``na_position`` parameter. (:issue:`3917`)\n- accept ``TextFileReader`` in ``concat``, which was affecting a common user idiom (:issue:`6583`), this was a regression\n  from 0.13.1\n- Added ``factorize`` functions to ``Index`` and ``Series`` to get indexer and unique values (:issue:`7090`)\n- ``describe`` on a DataFrame with a mix of Timestamp and string like objects returns a different Index (:issue:`7088`).\n  Previously the index was unintentionally sorted.\n- Arithmetic operations with **only** ``bool`` dtypes now give a warning indicating\n  that they are evaluated in Python space for ``+``, ``-``,\n  and ``*`` operations and raise for all others (:issue:`7011`, :issue:`6762`,\n  :issue:`7015`, :issue:`7210`)\n\n  .. code-block:: python\n\n     >>> x = pd.Series(np.random.rand(10) > 0.5)\n     >>> y = True\n     >>> x + y   warning generated: should do x | y instead\n     UserWarning: evaluating in Python space because the '+' operator is not\n     supported by numexpr for the bool dtype, use '|' instead\n     >>> x / y   this raises because it doesn't make sense\n     NotImplementedError: operator '/' not implemented for bool dtypes\n\n- In ``HDFStore``, ``select_as_multiple`` will always raise a ``KeyError``, when a key or the selector is not found (:issue:`6177`)\n- ``df['col'] = value`` and ``df.loc[:,'col'] = value`` are now completely equivalent;\n  previously the ``.loc`` would not necessarily coerce the dtype of the resultant series (:issue:`6149`)\n- ``dtypes`` and ``ftypes`` now return a series with ``dtype=object`` on empty containers (:issue:`5740`)\n- ``df.to_csv`` will now return a string of the CSV data if neither a target path nor a buffer is provided\n  (:issue:`6061`)\n- ``pd.infer_freq()`` will now raise a ``TypeError`` if given an invalid ``Series/Index``\n  type (:issue:`6407`, :issue:`6463`)\n- A tuple passed to ``DataFame.sort_index`` will be interpreted as the levels of\n  the index, rather than requiring a list of tuple (:issue:`4370`)\n- all offset operations now return ``Timestamp`` types (rather than datetime), Business/Week frequencies were incorrect (:issue:`4069`)\n- ``to_excel`` now converts ``np.inf`` into a string representation,\n  customizable by the ``inf_rep`` keyword argument (Excel has no native inf\n  representation) (:issue:`6782`)\n- Replace ``pandas.compat.scipy.scoreatpercentile`` with ``numpy.percentile`` (:issue:`6810`)\n- ``.quantile`` on a ``datetime[ns]`` series now returns ``Timestamp`` instead\n  of ``np.datetime64`` objects (:issue:`6810`)\n- change ``AssertionError`` to ``TypeError`` for invalid types passed to ``concat`` (:issue:`6583`)\n- Raise a ``TypeError`` when ``DataFrame`` is passed an iterator as the\n  ``data`` argument (:issue:`5357`)\n\n\n.. _whatsnew_0140.display:\n\nDisplay changes\n~~~~~~~~~~~~~~~\n\n- The default way of printing large DataFrames has changed. DataFrames\n  exceeding ``max_rows`` and/or ``max_columns`` are now displayed in a\n  centrally truncated view, consistent with the printing of a\n  :class:`pandas.Series` (:issue:`5603`).\n\n  In previous versions, a DataFrame was truncated once the dimension\n  constraints were reached and an ellipse (...) signaled that part of\n  the data was cut off.\n\n  .. image:: ../_static/trunc_before.png\n      :alt: The previous look of truncate.\n\n  In the current version, large DataFrames are centrally truncated,\n  showing a preview of head and tail in both dimensions.\n\n  .. image:: ../_static/trunc_after.png\n     :alt: The new look.\n\n- allow option ``'truncate'`` for ``display.show_dimensions`` to only show the dimensions if the\n  frame is truncated (:issue:`6547`).\n\n  The default for ``display.show_dimensions`` will now be ``truncate``. This is consistent with\n  how Series display length.\n\n  .. ipython:: python\n\n     dfd = pd.DataFrame(np.arange(25).reshape(-1, 5),\n                        index=[0, 1, 2, 3, 4],\n                        columns=[0, 1, 2, 3, 4])\n\n      show dimensions since this is truncated\n     with pd.option_context('display.max_rows', 2, 'display.max_columns', 2,\n                            'display.show_dimensions', 'truncate'):\n         print(dfd)\n\n      will not show dimensions since it is not truncated\n     with pd.option_context('display.max_rows', 10, 'display.max_columns', 40,\n                            'display.show_dimensions', 'truncate'):\n         print(dfd)\n\n- Regression in the display of a MultiIndexed Series with ``display.max_rows`` is less than the\n  length of the series (:issue:`7101`)\n- Fixed a bug in the HTML repr of a truncated Series or DataFrame not showing the class name with the\n  ``large_repr`` set to 'info' (:issue:`7105`)\n- The ``verbose`` keyword in ``DataFrame.info()``, which controls whether to shorten the ``info``\n  representation, is now ``None`` by default. This will follow the global setting in\n  ``display.max_info_columns``. The global setting can be overridden with ``verbose=True`` or\n  ``verbose=False``.\n- Fixed a bug with the ``info`` repr not honoring the ``display.max_info_columns`` setting (:issue:`6939`)\n- Offset/freq info now in Timestamp __repr__ (:issue:`4553`)\n\n.. _whatsnew_0140.parsing:\n\nText parsing API changes\n~~~~~~~~~~~~~~~~~~~~~~~~\n\n:func:`read_csv`/:func:`read_table` will now be noisier w.r.t invalid options rather than falling back to the ``PythonParser``.\n\n- Raise ``ValueError`` when ``sep`` specified with\n  ``delim_whitespace=True`` in :func:`read_csv`/:func:`read_table`\n  (:issue:`6607`)\n- Raise ``ValueError`` when ``engine='c'`` specified with unsupported\n  options in :func:`read_csv`/:func:`read_table` (:issue:`6607`)\n- Raise ``ValueError`` when fallback to python parser causes options to be\n  ignored (:issue:`6607`)\n- Produce :class:`~pandas.io.parsers.ParserWarning` on fallback to python\n  parser when no options are ignored (:issue:`6607`)\n- Translate ``sep='\\s+'`` to ``delim_whitespace=True`` in\n  :func:`read_csv`/:func:`read_table` if no other C-unsupported options\n  specified (:issue:`6607`)\n\n.. _whatsnew_0140.groupby:\n\nGroupBy API changes\n~~~~~~~~~~~~~~~~~~~\n\nMore consistent behavior for some groupby methods:\n\n- groupby ``head`` and ``tail`` now act more like ``filter`` rather than an aggregation:\n\n  .. code-block:: ipython\n\n     In [1]: df = pd.DataFrame([[1, 2], [1, 4], [5, 6]], columns=['A', 'B'])\n\n     In [2]: g = df.groupby('A')\n\n     In [3]: g.head(1)   filters DataFrame\n     Out[3]:\n        A  B\n     0  1  2\n     2  5  6\n\n     In [4]: g.apply(lambda x: x.head(1))   used to simply fall-through\n     Out[4]:\n          A  B\n     A\n     1 0  1  2\n     5 2  5  6\n\n- groupby head and tail respect column selection:\n\n  .. code-block:: ipython\n\n     In [19]: g[['B']].head(1)\n     Out[19]:\n        B\n     0  2\n     2  6\n\n     [2 rows x 1 columns]\n\n- groupby ``nth`` now reduces by default; filtering can be achieved by passing ``as_index=False``. With an optional ``dropna`` argument to ignore\n  NaN. See :ref:`the docs <groupby.nth>`.\n\n  Reducing\n\n  .. ipython:: python\n\n     df = pd.DataFrame([[1, np.nan], [1, 4], [5, 6]], columns=['A', 'B'])\n     g = df.groupby('A')\n     g.nth(0)\n\n      this is equivalent to g.first()\n     g.nth(0, dropna='any')\n\n      this is equivalent to g.last()\n     g.nth(-1, dropna='any')\n\n  Filtering\n\n  .. ipython:: python\n\n     gf = df.groupby('A', as_index=False)\n     gf.nth(0)\n     gf.nth(0, dropna='any')\n\n- groupby will now not return the grouped column for non-cython functions (:issue:`5610`, :issue:`5614`, :issue:`6732`),\n  as its already the index\n\n  .. ipython:: python\n\n     df = pd.DataFrame([[1, np.nan], [1, 4], [5, 6], [5, 8]], columns=['A', 'B'])\n     g = df.groupby('A')\n     g.count()\n     g.describe()\n\n- passing ``as_index`` will leave the grouped column in-place (this is not change in 0.14.0)\n\n  .. ipython:: python\n\n     df = pd.DataFrame([[1, np.nan], [1, 4], [5, 6], [5, 8]], columns=['A', 'B'])\n     g = df.groupby('A', as_index=False)\n     g.count()\n     g.describe()\n\n- Allow specification of a more complex groupby via ``pd.Grouper``, such as grouping\n  by a Time and a string field simultaneously. See :ref:`the docs <groupby.specify>`. (:issue:`3794`)\n\n- Better propagation/preservation of Series names when performing groupby\n  operations:\n\n  - ``SeriesGroupBy.agg`` will ensure that the name attribute of the original\n    series is propagated to the result (:issue:`6265`).\n  - If the function provided to ``GroupBy.apply`` returns a named series, the\n    name of the series will be kept as the name of the column index of the\n    DataFrame returned by ``GroupBy.apply`` (:issue:`6124`).  This facilitates\n    ``DataFrame.stack`` operations where the name of the column index is used as\n    the name of the inserted column containing the pivoted data.\n\n\n.. _whatsnew_0140.sql:\n\nSQL\n~~~\n\nThe SQL reading and writing functions now support more database flavors\nthrough SQLAlchemy (:issue:`2717`, :issue:`4163`, :issue:`5950`, :issue:`6292`).\nAll databases supported by SQLAlchemy can be used, such\nas PostgreSQL, MySQL, Oracle, Microsoft SQL server (see documentation of\nSQLAlchemy on `included dialects\n<https://sqlalchemy.readthedocs.io/en/latest/dialects/index.html>`_).\n\nThe functionality of providing DBAPI connection objects will only be supported\nfor sqlite3 in the future. The ``'mysql'`` flavor is deprecated.\n\nThe new functions :func:`~pandas.read_sql_query` and :func:`~pandas.read_sql_table`\nare introduced. The function :func:`~pandas.read_sql` is kept as a convenience\nwrapper around the other two and will delegate to specific function depending on\nthe provided input (database table name or sql query).\n\nIn practice, you have to provide a SQLAlchemy ``engine`` to the sql functions.\nTo connect with SQLAlchemy you use the :func:`create_engine` function to create an engine\nobject from database URI. You only need to create the engine once per database you are\nconnecting to. For an in-memory sqlite database:\n\n.. ipython:: python\n\n   from sqlalchemy import create_engine\n    Create your connection.\n   engine = create_engine('sqlite:///:memory:')\n\nThis ``engine`` can then be used to write or read data to/from this database:\n\n.. ipython:: python\n\n    df = pd.DataFrame({'A': [1, 2, 3], 'B': ['a', 'b', 'c']})\n    df.to_sql(name='db_table', con=engine, index=False)\n\nYou can read data from a database by specifying the table name:\n\n.. ipython:: python\n\n   pd.read_sql_table('db_table', engine)\n\nor by specifying a sql query:\n\n.. ipython:: python\n\n   pd.read_sql_query('SELECT * FROM db_table', engine)\n\nSome other enhancements to the sql functions include:\n\n- support for writing the index. This can be controlled with the ``index``\n  keyword (default is True).\n- specify the column label to use when writing the index with ``index_label``.\n- specify string columns to parse as datetimes with the ``parse_dates``\n  keyword in :func:`~pandas.read_sql_query` and :func:`~pandas.read_sql_table`.\n\n.. warning::\n\n    Some of the existing functions or function aliases have been deprecated\n    and will be removed in future versions. This includes: ``tquery``, ``uquery``,\n    ``read_frame``, ``frame_query``, ``write_frame``.\n\n.. warning::\n\n    The support for the 'mysql' flavor when using DBAPI connection objects has been deprecated.\n    MySQL will be further supported with SQLAlchemy engines (:issue:`6900`).\n\n\n.. _whatsnew_0140.slicers:\n\nMulti-indexing using slicers\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\nIn 0.14.0 we added a new way to slice MultiIndexed objects.\nYou can slice a MultiIndex by providing multiple indexers.\n\nYou can provide any of the selectors as if you are indexing by label, see :ref:`Selection by Label <indexing.label>`,\nincluding slices, lists of labels, labels, and boolean indexers.\n\nYou can use ``slice(None)`` to select all the contents of *that* level. You do not need to specify all the\n*deeper* levels, they will be implied as ``slice(None)``.\n\nAs usual, **both sides** of the slicers are included as this is label indexing.\n\nSee :ref:`the docs<advanced.mi_slicers>`\nSee also issues (:issue:`6134`, :issue:`4036`, :issue:`3057`, :issue:`2598`, :issue:`5641`, :issue:`7106`)\n\n.. warning::\n\n   You should specify all axes in the ``.loc`` specifier, meaning the indexer for the **index** and\n   for the **columns**. Their are some ambiguous cases where the passed indexer could be mis-interpreted\n   as indexing *both* axes, rather than into say the MultiIndex for the rows.\n\n   You should do this:\n\n  .. code-block:: python\n\n     >>> df.loc[(slice('A1', 'A3'), ...), :]   noqa: E901\n\n   rather than this:\n\n  .. code-block:: python\n\n     >>> df.loc[(slice('A1', 'A3'), ...)]   noqa: E901\n\n.. warning::\n\n   You will need to make sure that the selection axes are fully lexsorted!\n\n.. ipython:: python\n\n   def mklbl(prefix, n):\n       return [\"%s%s\" % (prefix, i) for i in range(n)]\n\n   index = pd.MultiIndex.from_product([mklbl('A', 4),\n                                       mklbl('B', 2),\n                                       mklbl('C', 4),\n                                       mklbl('D', 2)])\n   columns = pd.MultiIndex.from_tuples([('a', 'foo'), ('a', 'bar'),\n                                        ('b', 'foo'), ('b', 'bah')],\n                                       names=['lvl0', 'lvl1'])\n   df = pd.DataFrame(np.arange(len(index) * len(columns)).reshape((len(index),\n                     len(columns))),\n                     index=index,\n                     columns=columns).sort_index().sort_index(axis=1)\n   df\n\nBasic MultiIndex slicing using slices, lists, and labels.\n\n.. ipython:: python\n\n   df.loc[(slice('A1', 'A3'), slice(None), ['C1', 'C3']), :]\n\nYou can use a ``pd.IndexSlice`` to shortcut the creation of these slices\n\n.. ipython:: python\n\n   idx = pd.IndexSlice\n   df.loc[idx[:, :, ['C1', 'C3']], idx[:, 'foo']]\n\nIt is possible to perform quite complicated selections using this method on multiple\naxes at the same time.\n\n.. ipython:: python\n\n   df.loc['A1', (slice(None), 'foo')]\n   df.loc[idx[:, :, ['C1', 'C3']], idx[:, 'foo']]\n\nUsing a boolean indexer you can provide selection related to the *values*.\n\n.. ipython:: python\n\n   mask = df[('a', 'foo')] > 200\n   df.loc[idx[mask, :, ['C1', 'C3']], idx[:, 'foo']]\n\nYou can also specify the ``axis`` argument to ``.loc`` to interpret the passed\nslicers on a single axis.\n\n.. ipython:: python\n\n   df.loc(axis=0)[:, :, ['C1', 'C3']]\n\nFurthermore you can *set* the values using these methods\n\n.. ipython:: python\n\n   df2 = df.copy()\n   df2.loc(axis=0)[:, :, ['C1', 'C3']] = -10\n   df2\n\nYou can use a right-hand-side of an alignable object as well.\n\n.. ipython:: python\n\n   df2 = df.copy()\n   df2.loc[idx[:, :, ['C1', 'C3']], :] = df2 * 1000\n   df2\n\n.. _whatsnew_0140.plotting:\n\nPlotting\n~~~~~~~~\n\n- Hexagonal bin plots from ``DataFrame.plot`` with ``kind='hexbin'`` (:issue:`5478`), See :ref:`the docs<visualization.hexbin>`.\n- ``DataFrame.plot`` and ``Series.plot`` now supports area plot with specifying ``kind='area'`` (:issue:`6656`), See :ref:`the docs<visualization.area_plot>`\n- Pie plots from ``Series.plot`` and ``DataFrame.plot`` with ``kind='pie'`` (:issue:`6976`), See :ref:`the docs<visualization.pie>`.\n- Plotting with Error Bars is now supported in the ``.plot`` method of ``DataFrame`` and ``Series`` objects (:issue:`3796`, :issue:`6834`), See :ref:`the docs<visualization.errorbars>`.\n- ``DataFrame.plot`` and ``Series.plot`` now support a ``table`` keyword for plotting ``matplotlib.Table``, See :ref:`the docs<visualization.table>`. The ``table`` keyword can receive the following values.\n\n  - ``False``: Do nothing (default).\n  - ``True``: Draw a table using the ``DataFrame`` or ``Series`` called ``plot`` method. Data will be transposed to meet matplotlib's default layout.\n  - ``DataFrame`` or ``Series``: Draw matplotlib.table using the passed data. The data will be drawn as displayed in print method (not transposed automatically).\n    Also, helper function ``pandas.tools.plotting.table`` is added to create a table from ``DataFrame`` and ``Series``, and add it to an ``matplotlib.Axes``.\n\n- ``plot(legend='reverse')`` will now reverse the order of legend labels for\n  most plot kinds. (:issue:`6014`)\n- Line plot and area plot can be stacked by ``stacked=True`` (:issue:`6656`)\n\n- Following keywords are now acceptable for :meth:`DataFrame.plot` with ``kind='bar'`` and ``kind='barh'``:\n\n  - ``width``: Specify the bar width. In previous versions, static value 0.5 was passed to matplotlib and it cannot be overwritten. (:issue:`6604`)\n  - ``align``: Specify the bar alignment. Default is ``center`` (different from matplotlib). In previous versions, pandas passes ``align='edge'`` to matplotlib and adjust the location to ``center`` by itself, and it results ``align`` keyword is not applied as expected. (:issue:`4525`)\n  - ``position``: Specify relative alignments for bar plot layout. From 0 (left/bottom-end) to 1(right/top-end). Default is 0.5 (center). (:issue:`6604`)\n\n  Because of the default ``align`` value changes, coordinates of bar plots are now located on integer values (0.0, 1.0, 2.0 ...). This is intended to make bar plot be located on the same coordinates as line plot. However, bar plot may differs unexpectedly when you manually adjust the bar location or drawing area, such as using ``set_xlim``, ``set_ylim``, etc. In this cases, please modify your script to meet with new coordinates.\n\n- The :func:`parallel_coordinates` function now takes argument ``color``\n  instead of ``colors``. A ``FutureWarning`` is raised to alert that\n  the old ``colors`` argument will not be supported in a future release. (:issue:`6956`)\n\n- The :func:`parallel_coordinates` and :func:`andrews_curves` functions now take\n  positional argument ``frame`` instead of ``data``. A ``FutureWarning`` is\n  raised if the old ``data`` argument is used by name. (:issue:`6956`)\n\n- :meth:`DataFrame.boxplot` now supports ``layout`` keyword (:issue:`6769`)\n- :meth:`DataFrame.boxplot` has a new keyword argument, ``return_type``. It accepts ``'dict'``,\n  ``'axes'``, or ``'both'``, in which case a namedtuple with the matplotlib\n  axes and a dict of matplotlib Lines is returned.\n\n\n.. _whatsnew_0140.prior_deprecations:\n\nPrior version deprecations/changes\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\nThere are prior version deprecations that are taking effect as of 0.14.0.\n\n- Remove :class:`DateRange` in favor of :class:`DatetimeIndex` (:issue:`6816`)\n- Remove ``column`` keyword from ``DataFrame.sort`` (:issue:`4370`)\n- Remove ``precision`` keyword from :func:`set_eng_float_format` (:issue:`395`)\n- Remove ``force_unicode`` keyword from :meth:`DataFrame.to_string`,\n  :meth:`DataFrame.to_latex`, and :meth:`DataFrame.to_html`; these function\n  encode in unicode by default (:issue:`2224`, :issue:`2225`)\n- Remove ``nanRep`` keyword from :meth:`DataFrame.to_csv` and\n  :meth:`DataFrame.to_string` (:issue:`275`)\n- Remove ``unique`` keyword from :meth:`HDFStore.select_column` (:issue:`3256`)\n- Remove ``inferTimeRule`` keyword from :func:`Timestamp.offset` (:issue:`391`)\n- Remove ``name`` keyword from :func:`get_data_yahoo` and\n  :func:`get_data_google` ( `commit b921d1a <https://github.com/pandas-dev/pandas/commit/b921d1a2>`__ )\n- Remove ``offset`` keyword from :class:`DatetimeIndex` constructor\n  ( `commit 3136390 <https://github.com/pandas-dev/pandas/commit/3136390>`__ )\n- Remove ``time_rule`` from several rolling-moment statistical functions, such\n  as :func:`rolling_sum` (:issue:`1042`)\n- Removed neg ``-`` boolean operations on numpy arrays in favor of inv ``~``, as this is going to\n  be deprecated in numpy 1.9 (:issue:`6960`)\n\n.. _whatsnew_0140.deprecations:\n\nDeprecations\n~~~~~~~~~~~~\n\n- The :func:`pivot_table`/:meth:`DataFrame.pivot_table` and :func:`crosstab` functions\n  now take arguments ``index`` and ``columns`` instead of ``rows`` and ``cols``.  A\n  ``FutureWarning`` is raised to alert that the old ``rows`` and ``cols`` arguments\n  will not be supported in a future release (:issue:`5505`)\n\n- The :meth:`DataFrame.drop_duplicates` and :meth:`DataFrame.duplicated` methods\n  now take argument ``subset`` instead of ``cols`` to better align with\n  :meth:`DataFrame.dropna`.  A ``FutureWarning`` is raised to alert that the old\n  ``cols`` arguments will not be supported in a future release (:issue:`6680`)\n\n- The :meth:`DataFrame.to_csv` and :meth:`DataFrame.to_excel` functions\n  now takes argument ``columns`` instead of ``cols``.  A\n  ``FutureWarning`` is raised to alert that the old ``cols`` arguments\n  will not be supported in a future release (:issue:`6645`)\n\n- Indexers will warn ``FutureWarning`` when used with a scalar indexer and\n  a non-floating point Index (:issue:`4892`, :issue:`6960`)\n\n  .. code-block:: ipython\n\n      non-floating point indexes can only be indexed by integers / labels\n     In [1]: pd.Series(1, np.arange(5))[3.0]\n             pandas/core/index.py:469: FutureWarning: scalar indexers for index type Int64Index should be integers and not floating point\n     Out[1]: 1\n\n     In [2]: pd.Series(1, np.arange(5)).iloc[3.0]\n             pandas/core/index.py:469: FutureWarning: scalar indexers for index type Int64Index should be integers and not floating point\n     Out[2]: 1\n\n     In [3]: pd.Series(1, np.arange(5)).iloc[3.0:4]\n             pandas/core/index.py:527: FutureWarning: slice indexers when using iloc should be integers and not floating point\n     Out[3]:\n             3    1\n             dtype: int64\n\n      these are Float64Indexes, so integer or floating point is acceptable\n     In [4]: pd.Series(1, np.arange(5.))[3]\n     Out[4]: 1\n\n     In [5]: pd.Series(1, np.arange(5.))[3.0]\n     Out[6]: 1\n\n- Numpy 1.9 compat w.r.t. deprecation warnings (:issue:`6960`)\n\n- :meth:`Panel.shift` now has a function signature that matches :meth:`DataFrame.shift`.\n  The old positional argument ``lags`` has been changed to a keyword argument\n  ``periods`` with a default value of 1. A ``FutureWarning`` is raised if the\n  old argument ``lags`` is used by name. (:issue:`6910`)\n- The ``order`` keyword argument of :func:`factorize` will be removed. (:issue:`6926`).\n\n- Remove the ``copy`` keyword from :meth:`DataFrame.xs`, :meth:`Panel.major_xs`, :meth:`Panel.minor_xs`. A view will be\n  returned if possible, otherwise a copy will be made. Previously the user could think that ``copy=False`` would\n  ALWAYS return a view. (:issue:`6894`)\n\n- The :func:`parallel_coordinates` function now takes argument ``color``\n  instead of ``colors``. A ``FutureWarning`` is raised to alert that\n  the old ``colors`` argument will not be supported in a future release. (:issue:`6956`)\n\n- The :func:`parallel_coordinates` and :func:`andrews_curves` functions now take\n  positional argument ``frame`` instead of ``data``. A ``FutureWarning`` is\n  raised if the old ``data`` argument is used by name. (:issue:`6956`)\n\n- The support for the 'mysql' flavor when using DBAPI connection objects has been deprecated.\n  MySQL will be further supported with SQLAlchemy engines (:issue:`6900`).\n\n- The following ``io.sql`` functions have been deprecated: ``tquery``, ``uquery``, ``read_frame``, ``frame_query``, ``write_frame``.\n\n- The ``percentile_width`` keyword argument in :meth:`~DataFrame.describe` has been deprecated.\n  Use the ``percentiles`` keyword instead, which takes a list of percentiles to display. The\n  default output is unchanged.\n\n- The default return type of :func:`boxplot` will change from a dict to a matplotlib Axes\n  in a future release. You can use the future behavior now by passing ``return_type='axes'``\n  to boxplot.\n\n.. _whatsnew_0140.knownissues:\n\nKnown issues\n~~~~~~~~~~~~\n\n- OpenPyXL 2.0.0 breaks backwards compatibility (:issue:`7169`)\n\n\n.. _whatsnew_0140.enhancements:\n\nEnhancements\n~~~~~~~~~~~~\n\n- DataFrame and Series will create a MultiIndex object if passed a tuples dict, See :ref:`the docs<basics.dataframe.from_dict_of_tuples>` (:issue:`3323`)\n\n  .. ipython:: python\n\n     pd.Series({('a', 'b'): 1, ('a', 'a'): 0,\n                ('a', 'c'): 2, ('b', 'a'): 3, ('b', 'b'): 4})\n     pd.DataFrame({('a', 'b'): {('A', 'B'): 1, ('A', 'C'): 2},\n                  ('a', 'a'): {('A', 'C'): 3, ('A', 'B'): 4},\n                  ('a', 'c'): {('A', 'B'): 5, ('A', 'C'): 6},\n                  ('b', 'a'): {('A', 'C'): 7, ('A', 'B'): 8},\n                  ('b', 'b'): {('A', 'D'): 9, ('A', 'B'): 10}})\n\n- Added the ``sym_diff`` method to ``Index`` (:issue:`5543`)\n- ``DataFrame.to_latex`` now takes a longtable keyword, which if True will return a table in a longtable environment. (:issue:`6617`)\n- Add option to turn off escaping in ``DataFrame.to_latex`` (:issue:`6472`)\n- ``pd.read_clipboard`` will, if the keyword ``sep`` is unspecified, try to detect data copied from a spreadsheet\n  and parse accordingly. (:issue:`6223`)\n- Joining a singly-indexed DataFrame with a MultiIndexed DataFrame (:issue:`3662`)\n\n  See :ref:`the docs<merging.join_on_mi>`. Joining MultiIndex DataFrames on both the left and right is not yet supported ATM.\n\n  .. ipython:: python\n\n     household = pd.DataFrame({'household_id': [1, 2, 3],\n                               'male': [0, 1, 0],\n                               'wealth': [196087.3, 316478.7, 294750]\n                               },\n                              columns=['household_id', 'male', 'wealth']\n                              ).set_index('household_id')\n     household\n     portfolio = pd.DataFrame({'household_id': [1, 2, 2, 3, 3, 3, 4],\n                               'asset_id': [\"nl0000301109\",\n                                            \"nl0000289783\",\n                                            \"gb00b03mlx29\",\n                                            \"gb00b03mlx29\",\n                                            \"lu0197800237\",\n                                            \"nl0000289965\",\n                                            np.nan],\n                               'name': [\"ABN Amro\",\n                                        \"Robeco\",\n                                        \"Royal Dutch Shell\",\n                                        \"Royal Dutch Shell\",\n                                        \"AAB Eastern Europe Equity Fund\",\n                                        \"Postbank BioTech Fonds\",\n                                        np.nan],\n                               'share': [1.0, 0.4, 0.6, 0.15, 0.6, 0.25, 1.0]\n                               },\n                              columns=['household_id', 'asset_id', 'name', 'share']\n                              ).set_index(['household_id', 'asset_id'])\n     portfolio\n\n     household.join(portfolio, how='inner')\n\n- ``quotechar``, ``doublequote``, and ``escapechar`` can now be specified when\n  using ``DataFrame.to_csv`` (:issue:`5414`, :issue:`4528`)\n- Partially sort by only the specified levels of a MultiIndex with the\n  ``sort_remaining`` boolean kwarg. (:issue:`3984`)\n- Added ``to_julian_date`` to ``TimeStamp`` and ``DatetimeIndex``.  The Julian\n  Date is used primarily in astronomy and represents the number of days from\n  noon, January 1, 4713 BC.  Because nanoseconds are used to define the time\n  in pandas the actual range of dates that you can use is 1678 AD to 2262 AD. (:issue:`4041`)\n- ``DataFrame.to_stata`` will now check data for compatibility with Stata data types\n  and will upcast when needed.  When it is not possible to losslessly upcast, a warning\n  is issued (:issue:`6327`)\n- ``DataFrame.to_stata`` and ``StataWriter`` will accept keyword arguments time_stamp\n  and data_label which allow the time stamp and dataset label to be set when creating a\n  file. (:issue:`6545`)\n- ``pandas.io.gbq`` now handles reading unicode strings properly. (:issue:`5940`)\n- :ref:`Holidays Calendars<timeseries.holiday>` are now available and can be used with the ``CustomBusinessDay`` offset (:issue:`6719`)\n- ``Float64Index`` is now backed by a ``float64`` dtype ndarray instead of an\n  ``object`` dtype array (:issue:`6471`).\n- Implemented ``Panel.pct_change`` (:issue:`6904`)\n- Added ``how`` option to rolling-moment functions to dictate how to handle resampling; :func:`rolling_max` defaults to max,\n  :func:`rolling_min` defaults to min, and all others default to mean (:issue:`6297`)\n- ``CustomBusinessMonthBegin`` and ``CustomBusinessMonthEnd`` are now available (:issue:`6866`)\n- :meth:`Series.quantile` and :meth:`DataFrame.quantile` now accept an array of\n  quantiles.\n- :meth:`~DataFrame.describe` now accepts an array of percentiles to include in the summary statistics (:issue:`4196`)\n- ``pivot_table`` can now accept ``Grouper`` by ``index`` and ``columns`` keywords (:issue:`6913`)\n\n  .. ipython:: python\n\n     import datetime\n     df = pd.DataFrame({\n         'Branch': 'A A A A A B'.split(),\n         'Buyer': 'Carl Mark Carl Carl Joe Joe'.split(),\n         'Quantity': [1, 3, 5, 1, 8, 1],\n         'Date': [datetime.datetime(2013, 11, 1, 13, 0),\n                  datetime.datetime(2013, 9, 1, 13, 5),\n                  datetime.datetime(2013, 10, 1, 20, 0),\n                  datetime.datetime(2013, 10, 2, 10, 0),\n                  datetime.datetime(2013, 11, 1, 20, 0),\n                  datetime.datetime(2013, 10, 2, 10, 0)],\n         'PayDay': [datetime.datetime(2013, 10, 4, 0, 0),\n                    datetime.datetime(2013, 10, 15, 13, 5),\n                    datetime.datetime(2013, 9, 5, 20, 0),\n                    datetime.datetime(2013, 11, 2, 10, 0),\n                    datetime.datetime(2013, 10, 7, 20, 0),\n                    datetime.datetime(2013, 9, 5, 10, 0)]})\n     df\n\n  .. code-block:: ipython\n\n     In [75]: df.pivot_table(values='Quantity',\n        ....:                index=pd.Grouper(freq='M', key='Date'),\n        ....:                columns=pd.Grouper(freq='M', key='PayDay'),\n        ....:                aggfunc=\"sum\")\n     Out[75]:\n     PayDay      2013-09-30  2013-10-31  2013-11-30\n     Date\n     2013-09-30         NaN         3.0         NaN\n     2013-10-31         6.0         NaN         1.0\n     2013-11-30         NaN         9.0         NaN\n\n     [3 rows x 3 columns]\n\n- Arrays of strings can be wrapped to a specified width (``str.wrap``) (:issue:`6999`)\n- Add :meth:`~Series.nsmallest` and :meth:`Series.nlargest` methods to Series, See :ref:`the docs <basics.nsorted>` (:issue:`3960`)\n\n- ``PeriodIndex`` fully supports partial string indexing like ``DatetimeIndex`` (:issue:`7043`)\n\n  .. code-block:: ipython\n\n     In [76]: prng = pd.period_range('2013-01-01 09:00', periods=100, freq='H')\n\n     In [77]: ps = pd.Series(np.random.randn(len(prng)), index=prng)\n\n     In [78]: ps\n     Out[78]:\n     2013-01-01 09:00    0.015696\n     2013-01-01 10:00   -2.242685\n     2013-01-01 11:00    1.150036\n     2013-01-01 12:00    0.991946\n     2013-01-01 13:00    0.953324\n                           ...\n     2013-01-05 08:00    0.285296\n     2013-01-05 09:00    0.484288\n     2013-01-05 10:00    1.363482\n     2013-01-05 11:00   -0.781105\n     2013-01-05 12:00   -0.468018\n     Freq: H, Length: 100, dtype: float64\n\n     In [79]: ps['2013-01-02']\n     Out[79]:\n     2013-01-02 00:00    0.553439\n     2013-01-02 01:00    1.318152\n     2013-01-02 02:00   -0.469305\n     2013-01-02 03:00    0.675554\n     2013-01-02 04:00   -1.817027\n                           ...\n     2013-01-02 19:00    0.036142\n     2013-01-02 20:00   -2.074978\n     2013-01-02 21:00    0.247792\n     2013-01-02 22:00   -0.897157\n     2013-01-02 23:00   -0.136795\n     Freq: H, Length: 24, dtype: float64\n\n- ``read_excel`` can now read milliseconds in Excel dates and times with xlrd >= 0.9.3. (:issue:`5945`)\n- ``pd.stats.moments.rolling_var`` now uses Welford's method for increased numerical stability (:issue:`6817`)\n- pd.expanding_apply and pd.rolling_apply now take args and kwargs that are passed on to\n  the func (:issue:`6289`)\n- ``DataFrame.rank()`` now has a percentage rank option (:issue:`5971`)\n- ``Series.rank()`` now has a percentage rank option (:issue:`5971`)\n- ``Series.rank()`` and ``DataFrame.rank()`` now accept ``method='dense'`` for ranks without gaps (:issue:`6514`)\n- Support passing ``encoding`` with xlwt (:issue:`3710`)\n- Refactor Block classes removing ``Block.items`` attributes to avoid duplication\n  in item handling (:issue:`6745`, :issue:`6988`).\n- Testing statements updated to use specialized asserts (:issue:`6175`)\n\n\n\n.. _whatsnew_0140.performance:\n\nPerformance\n~~~~~~~~~~~\n\n- Performance improvement when converting ``DatetimeIndex`` to floating ordinals\n  using ``DatetimeConverter`` (:issue:`6636`)\n- Performance improvement for  ``DataFrame.shift`` (:issue:`5609`)\n- Performance improvement in indexing into a MultiIndexed Series (:issue:`5567`)\n- Performance improvements in single-dtyped indexing (:issue:`6484`)\n- Improve performance of DataFrame construction with certain offsets, by removing faulty caching\n  (e.g. MonthEnd,BusinessMonthEnd), (:issue:`6479`)\n- Improve performance of ``CustomBusinessDay`` (:issue:`6584`)\n- improve performance of slice indexing on Series with string keys (:issue:`6341`, :issue:`6372`)\n- Performance improvement for ``DataFrame.from_records`` when reading a\n  specified number of rows from an iterable (:issue:`6700`)\n- Performance improvements in timedelta conversions for integer dtypes (:issue:`6754`)\n- Improved performance of compatible pickles (:issue:`6899`)\n- Improve performance in certain reindexing operations by optimizing ``take_2d`` (:issue:`6749`)\n- ``GroupBy.count()`` is now implemented in Cython and is much faster for large\n  numbers of groups (:issue:`7016`).\n\nExperimental\n~~~~~~~~~~~~\n\nThere are no experimental changes in 0.14.0\n\n\n.. _whatsnew_0140.bug_fixes:\n\nBug fixes\n~~~~~~~~~\n\n- Bug in Series ValueError when index doesn't match data (:issue:`6532`)\n- Prevent segfault due to MultiIndex not being supported in HDFStore table\n  format (:issue:`1848`)\n- Bug in ``pd.DataFrame.sort_index`` where mergesort wasn't stable when ``ascending=False`` (:issue:`6399`)\n- Bug in ``pd.tseries.frequencies.to_offset`` when argument has leading zeros (:issue:`6391`)\n- Bug in version string gen. for dev versions with shallow clones / install from tarball (:issue:`6127`)\n- Inconsistent tz parsing ``Timestamp`` / ``to_datetime`` for current year (:issue:`5958`)\n- Indexing bugs with reordered indexes (:issue:`6252`, :issue:`6254`)\n- Bug in ``.xs`` with a Series multiindex (:issue:`6258`, :issue:`5684`)\n- Bug in conversion of a string types to a DatetimeIndex with a specified frequency (:issue:`6273`, :issue:`6274`)\n- Bug in ``eval`` where type-promotion failed for large expressions (:issue:`6205`)\n- Bug in interpolate with ``inplace=True`` (:issue:`6281`)\n- ``HDFStore.remove`` now handles start and stop (:issue:`6177`)\n- ``HDFStore.select_as_multiple`` handles start and stop the same way as ``select`` (:issue:`6177`)\n- ``HDFStore.select_as_coordinates`` and ``select_column`` works with a ``where`` clause that results in filters (:issue:`6177`)\n- Regression in join of non_unique_indexes (:issue:`6329`)\n- Issue with groupby ``agg`` with a single function and a mixed-type frame (:issue:`6337`)\n- Bug in ``DataFrame.replace()`` when passing a non- ``bool``\n  ``to_replace`` argument (:issue:`6332`)\n- Raise when trying to align on different levels of a MultiIndex assignment (:issue:`3738`)\n- Bug in setting complex dtypes via boolean indexing (:issue:`6345`)\n- Bug in TimeGrouper/resample when presented with a non-monotonic DatetimeIndex that would return invalid results. (:issue:`4161`)\n- Bug in index name propagation in TimeGrouper/resample (:issue:`4161`)\n- TimeGrouper has a more compatible API to the rest of the groupers (e.g. ``groups`` was missing) (:issue:`3881`)\n- Bug in multiple grouping with a TimeGrouper depending on target column order (:issue:`6764`)\n- Bug in ``pd.eval`` when parsing strings with possible tokens like ``'&'``\n  (:issue:`6351`)\n- Bug correctly handle placements of ``-inf`` in Panels when dividing by integer 0 (:issue:`6178`)\n- ``DataFrame.shift`` with ``axis=1`` was raising (:issue:`6371`)\n- Disabled clipboard tests until release time (run locally with ``nosetests -A disabled``) (:issue:`6048`).\n- Bug in ``DataFrame.replace()`` when passing a nested ``dict`` that contained\n  keys not in the values to be replaced (:issue:`6342`)\n- ``str.match`` ignored the na flag (:issue:`6609`).\n- Bug in take with duplicate columns that were not consolidated (:issue:`6240`)\n- Bug in interpolate changing dtypes (:issue:`6290`)\n- Bug in ``Series.get``, was using a buggy access method (:issue:`6383`)\n- Bug in hdfstore queries of the form ``where=[('date', '>=', datetime(2013,1,1)), ('date', '<=', datetime(2014,1,1))]`` (:issue:`6313`)\n- Bug in ``DataFrame.dropna`` with duplicate indices (:issue:`6355`)\n- Regression in chained getitem indexing with embedded list-like from 0.12 (:issue:`6394`)\n- ``Float64Index`` with nans not comparing correctly (:issue:`6401`)\n- ``eval``/``query`` expressions with strings containing the ```` character\n  will now work (:issue:`6366`).\n- Bug in ``Series.reindex`` when specifying a ``method`` with some nan values was inconsistent (noted on a resample) (:issue:`6418`)\n- Bug in :meth:`DataFrame.replace` where nested dicts were erroneously\n  depending on the order of dictionary keys and values (:issue:`5338`).\n- Performance issue in concatenating with empty objects (:issue:`3259`)\n- Clarify sorting of ``sym_diff`` on ``Index`` objects with ``NaN`` values (:issue:`6444`)\n- Regression in ``MultiIndex.from_product`` with a ``DatetimeIndex`` as input (:issue:`6439`)\n- Bug in ``str.extract`` when passed a non-default index (:issue:`6348`)\n- Bug in ``str.split`` when passed ``pat=None`` and ``n=1`` (:issue:`6466`)\n- Bug in ``io.data.DataReader`` when passed ``\"F-F_Momentum_Factor\"`` and ``data_source=\"famafrench\"`` (:issue:`6460`)\n- Bug in ``sum`` of a ``timedelta64[ns]`` series (:issue:`6462`)\n- Bug in ``resample`` with a timezone and certain offsets (:issue:`6397`)\n- Bug in ``iat/iloc`` with duplicate indices on a Series (:issue:`6493`)\n- Bug in ``read_html`` where nan's were incorrectly being used to indicate\n  missing values in text. Should use the empty string for consistency with the\n  rest of pandas (:issue:`5129`).\n- Bug in ``read_html`` tests where redirected invalid URLs would make one test\n  fail (:issue:`6445`).\n- Bug in multi-axis indexing using ``.loc`` on non-unique indices (:issue:`6504`)\n- Bug that caused _ref_locs corruption when slice indexing across columns axis of a DataFrame (:issue:`6525`)\n- Regression from 0.13 in the treatment of numpy ``datetime64`` non-ns dtypes in Series creation (:issue:`6529`)\n- ``.names`` attribute of MultiIndexes passed to ``set_index`` are now preserved (:issue:`6459`).\n- Bug in setitem with a duplicate index and an alignable rhs (:issue:`6541`)\n- Bug in setitem with ``.loc`` on mixed integer Indexes (:issue:`6546`)\n- Bug in ``pd.read_stata`` which would use the wrong data types and missing values (:issue:`6327`)\n- Bug in ``DataFrame.to_stata`` that lead to data loss in certain cases, and could be exported using the\n  wrong data types and missing values (:issue:`6335`)\n- ``StataWriter`` replaces missing values in string columns by empty string (:issue:`6802`)\n- Inconsistent types in ``Timestamp`` addition/subtraction (:issue:`6543`)\n- Bug in preserving frequency across Timestamp addition/subtraction (:issue:`4547`)\n- Bug in empty list lookup caused ``IndexError`` exceptions (:issue:`6536`, :issue:`6551`)\n- ``Series.quantile`` raising on an ``object`` dtype (:issue:`6555`)\n- Bug in ``.xs`` with a ``nan`` in level when dropped (:issue:`6574`)\n- Bug in fillna with ``method='bfill/ffill'`` and ``datetime64[ns]`` dtype (:issue:`6587`)\n- Bug in sql writing with mixed dtypes possibly leading to data loss (:issue:`6509`)\n- Bug in ``Series.pop`` (:issue:`6600`)\n- Bug in ``iloc`` indexing when positional indexer matched ``Int64Index`` of the corresponding axis and no reordering happened (:issue:`6612`)\n- Bug in ``fillna`` with ``limit`` and ``value`` specified\n- Bug in ``DataFrame.to_stata`` when columns have non-string names (:issue:`4558`)\n- Bug in compat with ``np.compress``, surfaced in (:issue:`6658`)\n- Bug in binary operations with a rhs of a Series not aligning (:issue:`6681`)\n- Bug in ``DataFrame.to_stata`` which incorrectly handles nan values and ignores ``with_index`` keyword argument (:issue:`6685`)\n- Bug in resample with extra bins when using an evenly divisible frequency (:issue:`4076`)\n- Bug in consistency of groupby aggregation when passing a custom function (:issue:`6715`)\n- Bug in resample when ``how=None`` resample freq is the same as the axis frequency (:issue:`5955`)\n- Bug in downcasting inference with empty arrays (:issue:`6733`)\n- Bug in ``obj.blocks`` on sparse containers dropping all but the last items of same for dtype (:issue:`6748`)\n- Bug in unpickling ``NaT (NaTType)`` (:issue:`4606`)\n- Bug in ``DataFrame.replace()`` where regex meta characters were being treated\n  as regex even when ``regex=False`` (:issue:`6777`).\n- Bug in timedelta ops on 32-bit platforms (:issue:`6808`)\n- Bug in setting a tz-aware index directly via ``.index`` (:issue:`6785`)\n- Bug in expressions.py where numexpr would try to evaluate arithmetic ops\n  (:issue:`6762`).\n- Bug in Makefile where it didn't remove Cython generated C files with ``make\n  clean`` (:issue:`6768`)\n- Bug with numpy < 1.7.2 when reading long strings from ``HDFStore`` (:issue:`6166`)\n- Bug in ``DataFrame._reduce`` where non bool-like (0/1) integers were being\n  converted into bools. (:issue:`6806`)\n- Regression from 0.13 with ``fillna`` and a Series on datetime-like (:issue:`6344`)\n- Bug in adding ``np.timedelta64`` to ``DatetimeIndex`` with timezone outputs incorrect results (:issue:`6818`)\n- Bug in ``DataFrame.replace()`` where changing a dtype through replacement\n  would only replace the first occurrence of a value (:issue:`6689`)\n- Better error message when passing a frequency of 'MS' in ``Period`` construction (GH5332)\n- Bug in ``Series.__unicode__`` when ``max_rows=None`` and the Series has more than 1000 rows. (:issue:`6863`)\n- Bug in ``groupby.get_group`` where a datelike wasn't always accepted (:issue:`5267`)\n- Bug in ``groupBy.get_group`` created by ``TimeGrouper`` raises ``AttributeError`` (:issue:`6914`)\n- Bug in ``DatetimeIndex.tz_localize`` and ``DatetimeIndex.tz_convert`` converting ``NaT`` incorrectly (:issue:`5546`)\n- Bug in arithmetic operations affecting ``NaT`` (:issue:`6873`)\n- Bug in ``Series.str.extract`` where the resulting ``Series`` from a single\n  group match wasn't renamed to the group name\n- Bug in ``DataFrame.to_csv`` where setting ``index=False`` ignored the\n  ``header`` kwarg (:issue:`6186`)\n- Bug in ``DataFrame.plot`` and ``Series.plot``, where the legend behave inconsistently when plotting to the same axes repeatedly (:issue:`6678`)\n- Internal tests for patching ``__finalize__`` / bug in merge not finalizing (:issue:`6923`, :issue:`6927`)\n- accept ``TextFileReader`` in ``concat``, which was affecting a common user idiom (:issue:`6583`)\n- Bug in C parser with leading white space (:issue:`3374`)\n- Bug in C parser with ``delim_whitespace=True`` and ``\\r``-delimited lines\n- Bug in python parser with explicit MultiIndex in row following column header (:issue:`6893`)\n- Bug in ``Series.rank`` and ``DataFrame.rank`` that caused small floats (<1e-13) to all receive the same rank (:issue:`6886`)\n- Bug in ``DataFrame.apply`` with functions that used ``*args`` or ``**kwargs`` and returned\n  an empty result (:issue:`6952`)\n- Bug in sum/mean on 32-bit platforms on overflows (:issue:`6915`)\n- Moved ``Panel.shift`` to ``NDFrame.slice_shift`` and fixed to respect multiple dtypes. (:issue:`6959`)\n- Bug in enabling ``subplots=True`` in ``DataFrame.plot`` only has single column raises ``TypeError``, and ``Series.plot`` raises ``AttributeError`` (:issue:`6951`)\n- Bug in ``DataFrame.plot`` draws unnecessary axes when enabling ``subplots`` and ``kind=scatter`` (:issue:`6951`)\n- Bug in ``read_csv`` from a filesystem with non-utf-8 encoding (:issue:`6807`)\n- Bug in ``iloc`` when setting / aligning (:issue:`6766`)\n- Bug causing UnicodeEncodeError when get_dummies called with unicode values and a prefix (:issue:`6885`)\n- Bug in timeseries-with-frequency plot cursor display (:issue:`5453`)\n- Bug surfaced in ``groupby.plot`` when using a ``Float64Index`` (:issue:`7025`)\n- Stopped tests from failing if options data isn't able to be downloaded from Yahoo (:issue:`7034`)\n- Bug in ``parallel_coordinates`` and ``radviz`` where reordering of class column\n  caused possible color/class mismatch (:issue:`6956`)\n- Bug in ``radviz`` and ``andrews_curves`` where multiple values of 'color'\n  were being passed to plotting method (:issue:`6956`)\n- Bug in ``Float64Index.isin()`` where containing ``nan`` s would make indices\n  claim that they contained all the things (:issue:`7066`).\n- Bug in ``DataFrame.boxplot`` where it failed to use the axis passed as the ``ax`` argument (:issue:`3578`)\n- Bug in the ``XlsxWriter`` and ``XlwtWriter`` implementations that resulted in datetime columns being formatted without the time (:issue:`7075`)\n  were being passed to plotting method\n- :func:`read_fwf` treats ``None`` in ``colspec`` like regular python slices. It now reads from the beginning\n  or until the end of the line when ``colspec`` contains a ``None`` (previously raised a ``TypeError``)\n- Bug in cache coherence with chained indexing and slicing; add ``_is_view`` property to ``NDFrame`` to correctly predict\n  views; mark ``is_copy`` on ``xs`` only if its an actual copy (and not a view) (:issue:`7084`)\n- Bug in DatetimeIndex creation from string ndarray with ``dayfirst=True`` (:issue:`5917`)\n- Bug in ``MultiIndex.from_arrays`` created from ``DatetimeIndex`` doesn't preserve ``freq`` and ``tz`` (:issue:`7090`)\n- Bug in ``unstack`` raises ``ValueError`` when ``MultiIndex`` contains ``PeriodIndex`` (:issue:`4342`)\n- Bug in ``boxplot`` and ``hist`` draws unnecessary axes (:issue:`6769`)\n- Regression in ``groupby.nth()`` for out-of-bounds indexers (:issue:`6621`)\n- Bug in ``quantile`` with datetime values (:issue:`6965`)\n- Bug in ``Dataframe.set_index``, ``reindex`` and ``pivot`` don't preserve ``DatetimeIndex`` and ``PeriodIndex`` attributes (:issue:`3950`, :issue:`5878`, :issue:`6631`)\n- Bug in ``MultiIndex.get_level_values`` doesn't preserve ``DatetimeIndex`` and ``PeriodIndex`` attributes (:issue:`7092`)\n- Bug in ``Groupby`` doesn't preserve ``tz`` (:issue:`3950`)\n- Bug in ``PeriodIndex`` partial string slicing (:issue:`6716`)\n- Bug in the HTML repr of a truncated Series or DataFrame not showing the class name with the ``large_repr`` set to 'info'\n  (:issue:`7105`)\n- Bug in ``DatetimeIndex`` specifying ``freq`` raises ``ValueError`` when passed value is too short (:issue:`7098`)\n- Fixed a bug with the ``info`` repr not honoring the ``display.max_info_columns`` setting (:issue:`6939`)\n- Bug ``PeriodIndex`` string slicing with out of bounds values (:issue:`5407`)\n- Fixed a memory error in the hashtable implementation/factorizer on resizing of large tables (:issue:`7157`)\n- Bug in ``isnull`` when applied to 0-dimensional object arrays (:issue:`7176`)\n- Bug in ``query``/``eval`` where global constants were not looked up correctly\n  (:issue:`7178`)\n- Bug in recognizing out-of-bounds positional list indexers with ``iloc`` and a multi-axis tuple indexer (:issue:`7189`)\n- Bug in setitem with a single value, MultiIndex and integer indices (:issue:`7190`, :issue:`7218`)\n- Bug in expressions evaluation with reversed ops, showing in series-dataframe ops (:issue:`7198`, :issue:`7192`)\n- Bug in multi-axis indexing with > 2 ndim and a MultiIndex (:issue:`7199`)\n- Fix a bug where invalid eval/query operations would blow the stack (:issue:`5198`)\n\n\n.. _whatsnew_0.14.0.contributors:\n\nContributors\n~~~~~~~~~~~~\n\n.. contributors:: v0.13.1..v0.14.0\n\n\n.. _whatsnew_0901:\n\nVersion 0.9.1 (November 14, 2012)\n---------------------------------\n\n{{ header }}\n\n\nThis is a bug fix release from 0.9.0 and includes several new features and\nenhancements along with a large number of bug fixes. The new features include\nby-column sort order for DataFrame and Series, improved NA handling for the rank\nmethod, masking functions for DataFrame, and intraday time-series filtering for\nDataFrame.\n\nNew features\n~~~~~~~~~~~~\n\n  - ``Series.sort``, ``DataFrame.sort``, and ``DataFrame.sort_index`` can now be\n    specified in a per-column manner to support multiple sort orders (:issue:`928`)\n\n    .. code-block:: ipython\n\n       In [2]: df = pd.DataFrame(np.random.randint(0, 2, (6, 3)),\n          ...:                   columns=['A', 'B', 'C'])\n\n       In [3]: df.sort(['A', 'B'], ascending=[1, 0])\n\n       Out[3]:\n          A  B  C\n       3  0  1  1\n       4  0  1  1\n       2  0  0  1\n       0  1  0  0\n       1  1  0  0\n       5  1  0  0\n\n  - ``DataFrame.rank`` now supports additional argument values for the\n    ``na_option`` parameter so missing values can be assigned either the largest\n    or the smallest rank (:issue:`1508`, :issue:`2159`)\n\n    .. ipython:: python\n\n        df = pd.DataFrame(np.random.randn(6, 3), columns=['A', 'B', 'C'])\n\n        df.loc[2:4] = np.nan\n\n        df.rank()\n\n        df.rank(na_option='top')\n\n        df.rank(na_option='bottom')\n\n\n  - DataFrame has new ``where`` and ``mask`` methods to select values according to a\n    given boolean mask (:issue:`2109`, :issue:`2151`)\n\n        DataFrame currently supports slicing via a boolean vector the same length as the DataFrame (inside the ``[]``).\n        The returned DataFrame has the same number of columns as the original, but is sliced on its index.\n\n        .. ipython:: python\n\n            df = pd.DataFrame(np.random.randn(5, 3), columns=['A', 'B', 'C'])\n\n            df\n\n            df[df['A'] > 0]\n\n        If a DataFrame is sliced with a DataFrame based boolean condition (with the same size as the original DataFrame),\n        then a DataFrame the same size (index and columns) as the original is returned, with\n        elements that do not meet the boolean condition as ``NaN``. This is accomplished via\n        the new method ``DataFrame.where``. In addition, ``where`` takes an optional ``other`` argument for replacement.\n\n        .. ipython:: python\n\n           df[df > 0]\n\n           df.where(df > 0)\n\n           df.where(df > 0, -df)\n\n        Furthermore, ``where`` now aligns the input boolean condition (ndarray or DataFrame), such that partial selection\n        with setting is possible. This is analogous to partial setting via ``.ix`` (but on the contents rather than the axis labels)\n\n        .. ipython:: python\n\n           df2 = df.copy()\n           df2[df2[1:4] > 0] = 3\n           df2\n\n        ``DataFrame.mask`` is the inverse boolean operation of ``where``.\n\n        .. ipython:: python\n\n           df.mask(df <= 0)\n\n  - Enable referencing of Excel columns by their column names (:issue:`1936`)\n\n    .. code-block:: ipython\n\n       In [1]: xl = pd.ExcelFile('data/test.xls')\n\n       In [2]: xl.parse('Sheet1', index_col=0, parse_dates=True,\n                        parse_cols='A:D')\n\n\n  - Added option to disable pandas-style tick locators and formatters\n    using ``series.plot(x_compat=True)`` or ``pandas.plot_params['x_compat'] =\n    True`` (:issue:`2205`)\n  - Existing TimeSeries methods ``at_time`` and ``between_time`` were added to\n    DataFrame (:issue:`2149`)\n  - DataFrame.dot can now accept ndarrays (:issue:`2042`)\n  - DataFrame.drop now supports non-unique indexes (:issue:`2101`)\n  - Panel.shift now supports negative periods (:issue:`2164`)\n  - DataFrame now support unary ~ operator (:issue:`2110`)\n\nAPI changes\n~~~~~~~~~~~\n\n  - Upsampling data with a PeriodIndex will result in a higher frequency\n    TimeSeries that spans the original time window\n\n    .. code-block:: ipython\n\n       In [1]: prng = pd.period_range('2012Q1', periods=2, freq='Q')\n\n       In [2]: s = pd.Series(np.random.randn(len(prng)), prng)\n\n       In [4]: s.resample('M')\n       Out[4]:\n       2012-01   -1.471992\n       2012-02         NaN\n       2012-03         NaN\n       2012-04   -0.493593\n       2012-05         NaN\n       2012-06         NaN\n       Freq: M, dtype: float64\n\n  - Period.end_time now returns the last nanosecond in the time interval\n    (:issue:`2124`, :issue:`2125`, :issue:`1764`)\n\n    .. ipython:: python\n\n        p = pd.Period('2012')\n\n        p.end_time\n\n\n  - File parsers no longer coerce to float or bool for columns that have custom\n    converters specified (:issue:`2184`)\n\n    .. ipython:: python\n\n        import io\n\n        data = ('A,B,C\\n'\n                '00001,001,5\\n'\n                '00002,002,6')\n        pd.read_csv(io.StringIO(data), converters={'A': lambda x: x.strip()})\n\n\nSee the :ref:`full release notes\n<release>` or issue tracker\non GitHub for a complete list.\n\n\n.. _whatsnew_0.9.1.contributors:\n\nContributors\n~~~~~~~~~~~~\n\n.. contributors:: v0.9.0..v0.9.1\n\n\n.. _whatsnew_121:\n\nWhat's new in 1.2.1 (January 20, 2021)\n--------------------------------------\n\nThese are the changes in pandas 1.2.1. See :ref:`release` for a full changelog\nincluding other versions of pandas.\n\n{{ header }}\n\n.. ---------------------------------------------------------------------------\n\n.. _whatsnew_121.regressions:\n\nFixed regressions\n~~~~~~~~~~~~~~~~~\n- Fixed regression in :meth:`~DataFrame.to_csv` that created corrupted zip files when there were more rows than ``chunksize`` (:issue:`38714`)\n- Fixed regression in :meth:`~DataFrame.to_csv` opening ``codecs.StreamReaderWriter`` in binary mode instead of in text mode (:issue:`39247`)\n- Fixed regression in :meth:`read_csv` and other read functions were the encoding error policy (``errors``) did not default to ``\"replace\"`` when no encoding was specified (:issue:`38989`)\n- Fixed regression in :func:`read_excel` with non-rawbyte file handles (:issue:`38788`)\n- Fixed regression in :meth:`DataFrame.to_stata` not removing the created file when an error occurred (:issue:`39202`)\n- Fixed regression in ``DataFrame.__setitem__`` raising ``ValueError`` when expanding :class:`DataFrame` and new column is from type ``\"0 - name\"`` (:issue:`39010`)\n- Fixed regression in setting with :meth:`DataFrame.loc`  raising ``ValueError`` when :class:`DataFrame` has unsorted :class:`MultiIndex` columns and indexer is a scalar (:issue:`38601`)\n- Fixed regression in setting with :meth:`DataFrame.loc` raising ``KeyError`` with :class:`MultiIndex` and list-like columns indexer enlarging :class:`DataFrame` (:issue:`39147`)\n- Fixed regression in :meth:`~DataFrame.groupby()` with :class:`Categorical` grouping column not showing unused categories for ``grouped.indices`` (:issue:`38642`)\n- Fixed regression in :meth:`.DataFrameGroupBy.sem` and :meth:`.SeriesGroupBy.sem` where the presence of non-numeric columns would cause an error instead of being dropped (:issue:`38774`)\n- Fixed regression in :meth:`.DataFrameGroupBy.diff` raising for ``int8`` and ``int16`` columns (:issue:`39050`)\n- Fixed regression in :meth:`DataFrame.groupby` when aggregating an ``ExtensionDType`` that could fail for non-numeric values (:issue:`38980`)\n- Fixed regression in :meth:`.Rolling.skew` and :meth:`.Rolling.kurt` modifying the object inplace (:issue:`38908`)\n- Fixed regression in :meth:`DataFrame.any` and :meth:`DataFrame.all` not returning a result for tz-aware ``datetime64`` columns (:issue:`38723`)\n- Fixed regression in :meth:`DataFrame.apply` with ``axis=1`` using str accessor in apply function (:issue:`38979`)\n- Fixed regression in :meth:`DataFrame.replace` raising ``ValueError`` when :class:`DataFrame` has dtype ``bytes`` (:issue:`38900`)\n- Fixed regression in :meth:`Series.fillna` that raised ``RecursionError`` with ``datetime64[ns, UTC]`` dtype (:issue:`38851`)\n- Fixed regression in comparisons between ``NaT`` and ``datetime.date`` objects incorrectly returning ``True`` (:issue:`39151`)\n- Fixed regression in calling NumPy :func:`~numpy.ufunc.accumulate` ufuncs on DataFrames, e.g. ``np.maximum.accumulate(df)`` (:issue:`39259`)\n- Fixed regression in repr of float-like strings of an ``object`` dtype having trailing 0's truncated after the decimal (:issue:`38708`)\n- Fixed regression that raised ``AttributeError`` with PyArrow versions [0.16.0, 1.0.0) (:issue:`38801`)\n- Fixed regression in :func:`pandas.testing.assert_frame_equal` raising ``TypeError`` with ``check_like=True`` when :class:`Index` or columns have mixed dtype (:issue:`39168`)\n\nWe have reverted a commit that resulted in several plotting related regressions in pandas 1.2.0 (:issue:`38969`, :issue:`38736`, :issue:`38865`, :issue:`38947` and :issue:`39126`).\nAs a result, bugs reported as fixed in pandas 1.2.0 related to inconsistent tick labeling in bar plots are again present (:issue:`26186` and :issue:`11465`)\n\n.. ---------------------------------------------------------------------------\n\n.. _whatsnew_121.ufunc_deprecation:\n\nCalling NumPy ufuncs on non-aligned DataFrames\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\nBefore pandas 1.2.0, calling a NumPy ufunc on non-aligned DataFrames (or\nDataFrame / Series combination) would ignore the indices, only match\nthe inputs by shape, and use the index/columns of the first DataFrame for\nthe result:\n\n.. code-block:: ipython\n\n    In [1]: df1 = pd.DataFrame({\"a\": [1, 2], \"b\": [3, 4]}, index=[0, 1])\n    In [2]: df2 = pd.DataFrame({\"a\": [1, 2], \"b\": [3, 4]}, index=[1, 2])\n    In [3]: df1\n    Out[3]:\n       a  b\n    0  1  3\n    1  2  4\n    In [4]: df2\n    Out[4]:\n       a  b\n    1  1  3\n    2  2  4\n\n    In [5]: np.add(df1, df2)\n    Out[5]:\n       a  b\n    0  2  6\n    1  4  8\n\nThis contrasts with how other pandas operations work, which first align\nthe inputs:\n\n.. code-block:: ipython\n\n    In [6]: df1 + df2\n    Out[6]:\n         a    b\n    0  NaN  NaN\n    1  3.0  7.0\n    2  NaN  NaN\n\nIn pandas 1.2.0, we refactored how NumPy ufuncs are called on DataFrames, and\nthis started to align the inputs first (:issue:`39184`), as happens in other\npandas operations and as it happens for ufuncs called on Series objects.\n\nFor pandas 1.2.1, we restored the previous behaviour to avoid a breaking\nchange, but the above example of ``np.add(df1, df2)`` with non-aligned inputs\nwill now to raise a warning, and a future pandas 2.0 release will start\naligning the inputs first (:issue:`39184`). Calling a NumPy ufunc on Series\nobjects (eg ``np.add(s1, s2)``) already aligns and continues to do so.\n\nTo avoid the warning and keep the current behaviour of ignoring the indices,\nconvert one of the arguments to a NumPy array:\n\n.. code-block:: ipython\n\n    In [7]: np.add(df1, np.asarray(df2))\n    Out[7]:\n       a  b\n    0  2  6\n    1  4  8\n\nTo obtain the future behaviour and silence the warning, you can align manually\nbefore passing the arguments to the ufunc:\n\n.. code-block:: ipython\n\n    In [8]: df1, df2 = df1.align(df2)\n    In [9]: np.add(df1, df2)\n    Out[9]:\n         a    b\n    0  NaN  NaN\n    1  3.0  7.0\n    2  NaN  NaN\n\n.. ---------------------------------------------------------------------------\n\n.. _whatsnew_121.bug_fixes:\n\nBug fixes\n~~~~~~~~~\n\n- Bug in :meth:`read_csv` with ``float_precision=\"high\"`` caused segfault or wrong parsing of long exponent strings. This resulted in a regression in some cases as the default for ``float_precision`` was changed in pandas 1.2.0 (:issue:`38753`)\n- Bug in :func:`read_csv` not closing an opened file handle when a ``csv.Error`` or ``UnicodeDecodeError`` occurred while initializing (:issue:`39024`)\n- Bug in :func:`pandas.testing.assert_index_equal` raising ``TypeError`` with ``check_order=False`` when :class:`Index` has mixed dtype (:issue:`39168`)\n\n.. ---------------------------------------------------------------------------\n\n.. _whatsnew_121.other:\n\nOther\n~~~~~\n\n- The deprecated attributes ``_AXIS_NAMES`` and ``_AXIS_NUMBERS`` of :class:`DataFrame` and :class:`Series` will no longer show up in ``dir`` or ``inspect.getmembers`` calls (:issue:`38740`)\n- Bumped minimum fastparquet version to 0.4.0 to avoid ``AttributeError`` from numba (:issue:`38344`)\n- Bumped minimum pymysql version to 0.8.1 to avoid test failures (:issue:`38344`)\n- Fixed build failure on MacOS 11 in Python 3.9.1 (:issue:`38766`)\n- Added reference to backwards incompatible ``check_freq`` arg of :func:`testing.assert_frame_equal` and :func:`testing.assert_series_equal` in :ref:`pandas 1.1.0 what's new <whatsnew_110.api_breaking.testing.check_freq>` (:issue:`34050`)\n\n.. ---------------------------------------------------------------------------\n\n.. _whatsnew_121.contributors:\n\nContributors\n~~~~~~~~~~~~\n\n.. contributors:: v1.2.0..v1.2.1\n\n\n.. _whatsnew_143:\n\nWhat's new in 1.4.3 (June 23, 2022)\n-----------------------------------\n\nThese are the changes in pandas 1.4.3. See :ref:`release` for a full changelog\nincluding other versions of pandas.\n\n{{ header }}\n\n.. ---------------------------------------------------------------------------\n\n.. _whatsnew_143.concat:\n\nBehavior of ``concat`` with empty or all-NA DataFrame columns\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\nThe behavior change in version 1.4.0 to stop ignoring the data type\nof empty or all-NA columns with float or object dtype in :func:`concat`\n(:ref:`whatsnew_140.notable_bug_fixes.concat_with_empty_or_all_na`) has been\nreverted (:issue:`45637`).\n\n\n.. _whatsnew_143.regressions:\n\nFixed regressions\n~~~~~~~~~~~~~~~~~\n- Fixed regression in :meth:`DataFrame.replace` when the replacement value was explicitly ``None`` when passed in a dictionary to ``to_replace`` also casting other columns to object dtype even when there were no values to replace (:issue:`46634`)\n- Fixed regression in :meth:`DataFrame.to_csv` raising error when :class:`DataFrame` contains extension dtype categorical column (:issue:`46297`, :issue:`46812`)\n- Fixed regression in representation of ``dtypes`` attribute of :class:`MultiIndex` (:issue:`46900`)\n- Fixed regression when setting values with :meth:`DataFrame.loc` updating :class:`RangeIndex` when index was set as new column and column was updated afterwards (:issue:`47128`)\n- Fixed regression in :meth:`DataFrame.fillna` and :meth:`DataFrame.update` creating a copy when updating inplace (:issue:`47188`)\n- Fixed regression in :meth:`DataFrame.nsmallest` led to wrong results when the sorting column has ``np.nan`` values (:issue:`46589`)\n- Fixed regression in :func:`read_fwf` raising ``ValueError`` when ``widths`` was specified with ``usecols`` (:issue:`46580`)\n- Fixed regression in :func:`concat` not sorting columns for mixed column names (:issue:`47127`)\n- Fixed regression in :meth:`.Groupby.transform` and :meth:`.Groupby.agg` failing with ``engine=\"numba\"`` when the index was a :class:`MultiIndex` (:issue:`46867`)\n- Fixed regression in ``NaN`` comparison for :class:`Index` operations where the same object was compared (:issue:`47105`)\n- Fixed regression is :meth:`.Styler.to_latex` and :meth:`.Styler.to_html` where ``buf`` failed in combination with ``encoding`` (:issue:`47053`)\n- Fixed regression in :func:`read_csv` with ``index_col=False`` identifying first row as index names when ``header=None`` (:issue:`46955`)\n- Fixed regression in :meth:`.DataFrameGroupBy.agg` when used with list-likes or dict-likes and ``axis=1`` that would give incorrect results; now raises ``NotImplementedError`` (:issue:`46995`)\n- Fixed regression in :meth:`DataFrame.resample` and :meth:`DataFrame.rolling` when used with list-likes or dict-likes and ``axis=1`` that would raise an unintuitive error message; now raises ``NotImplementedError`` (:issue:`46904`)\n- Fixed regression in :func:`testing.assert_index_equal` when ``check_order=False`` and :class:`Index` has extension or object dtype (:issue:`47207`)\n- Fixed regression in :func:`read_excel` returning ints as floats on certain input sheets (:issue:`46988`)\n- Fixed regression in :meth:`DataFrame.shift` when ``axis`` is ``columns`` and ``fill_value`` is absent, ``freq`` is ignored (:issue:`47039`)\n- Fixed regression in :meth:`DataFrame.to_json` causing a segmentation violation when :class:`DataFrame` is created with an ``index`` parameter of the type :class:`PeriodIndex` (:issue:`46683`)\n\n.. ---------------------------------------------------------------------------\n\n.. _whatsnew_143.bug_fixes:\n\nBug fixes\n~~~~~~~~~\n- Bug in :func:`pandas.eval`, :meth:`DataFrame.eval` and :meth:`DataFrame.query` where passing empty ``local_dict`` or ``global_dict`` was treated as passing ``None`` (:issue:`47084`)\n- Most I/O methods no longer suppress ``OSError`` and ``ValueError`` when closing file handles (:issue:`47136`)\n- Improving error message raised by :meth:`DataFrame.from_dict` when passing an invalid ``orient`` parameter (:issue:`47450`)\n\n.. ---------------------------------------------------------------------------\n\n.. _whatsnew_143.other:\n\nOther\n~~~~~\n- The minimum version of Cython needed to compile pandas is now ``0.29.30`` (:issue:`41935`)\n\n.. ---------------------------------------------------------------------------\n\n.. _whatsnew_143.contributors:\n\nContributors\n~~~~~~~~~~~~\n\n.. contributors:: v1.4.2..v1.4.3\n\n\n.. _whatsnew_0253:\n\nWhat's new in 0.25.3 (October 31, 2019)\n---------------------------------------\n\nThese are the changes in pandas 0.25.3. See :ref:`release` for a full changelog\nincluding other versions of pandas.\n\n.. _whatsnew_0253.bug_fixes:\n\nBug fixes\n~~~~~~~~~\n\nGroupBy/resample/rolling\n^^^^^^^^^^^^^^^^^^^^^^^^\n\n- Bug in :meth:`DataFrameGroupBy.quantile` where NA values in the grouping could cause segfaults or incorrect results (:issue:`28882`)\n\nContributors\n~~~~~~~~~~~~\n\n.. contributors:: v0.25.2..v0.25.3\n\n\n.. _whatsnew_0240:\n\nWhat's new in 0.24.0 (January 25, 2019)\n---------------------------------------\n\n.. warning::\n\n   The 0.24.x series of releases will be the last to support Python 2. Future feature\n   releases will support Python 3 only. See `Dropping Python 2.7 <https://pandas.pydata.org/pandas-docs/version/0.24/install.html#install-dropping-27>`_ for more\n   details.\n\n{{ header }}\n\nThis is a major release from 0.23.4 and includes a number of API changes, new\nfeatures, enhancements, and performance improvements along with a large number\nof bug fixes.\n\nHighlights include:\n\n* :ref:`Optional Integer NA Support <whatsnew_0240.enhancements.intna>`\n* :ref:`New APIs for accessing the array backing a Series or Index <whatsnew_0240.values_api>`\n* :ref:`A new top-level method for creating arrays <whatsnew_0240.enhancements.array>`\n* :ref:`Store Interval and Period data in a Series or DataFrame <whatsnew_0240.enhancements.interval>`\n* :ref:`Support for joining on two MultiIndexes <whatsnew_0240.enhancements.join_with_two_multiindexes>`\n\n\nCheck the :ref:`API Changes <whatsnew_0240.api_breaking>` and :ref:`deprecations <whatsnew_0240.deprecations>` before updating.\n\nThese are the changes in pandas 0.24.0. See :ref:`release` for a full changelog\nincluding other versions of pandas.\n\n\nEnhancements\n~~~~~~~~~~~~\n\n.. _whatsnew_0240.enhancements.intna:\n\nOptional integer NA support\n^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\npandas has gained the ability to hold integer dtypes with missing values. This long requested feature is enabled through the use of :ref:`extension types <extending.extension-types>`.\n\n.. note::\n\n   IntegerArray is currently experimental. Its API or implementation may\n   change without warning.\n\nWe can construct a ``Series`` with the specified dtype. The dtype string ``Int64`` is a pandas ``ExtensionDtype``. Specifying a list or array using the traditional missing value\nmarker of ``np.nan`` will infer to integer dtype. The display of the ``Series`` will also use the ``NaN`` to indicate missing values in string outputs. (:issue:`20700`, :issue:`20747`, :issue:`22441`, :issue:`21789`, :issue:`22346`)\n\n.. ipython:: python\n\n   s = pd.Series([1, 2, np.nan], dtype='Int64')\n   s\n\n\nOperations on these dtypes will propagate ``NaN`` as other pandas operations.\n\n.. ipython:: python\n\n    arithmetic\n   s + 1\n\n    comparison\n   s == 1\n\n    indexing\n   s.iloc[1:3]\n\n    operate with other dtypes\n   s + s.iloc[1:3].astype('Int8')\n\n    coerce when needed\n   s + 0.01\n\nThese dtypes can operate as part of a ``DataFrame``.\n\n.. ipython:: python\n\n   df = pd.DataFrame({'A': s, 'B': [1, 1, 3], 'C': list('aab')})\n   df\n   df.dtypes\n\n\nThese dtypes can be merged, reshaped, and casted.\n\n.. ipython:: python\n\n   pd.concat([df[['A']], df[['B', 'C']]], axis=1).dtypes\n   df['A'].astype(float)\n\nReduction and groupby operations such as ``sum`` work.\n\n.. ipython:: python\n\n   df.sum()\n   df.groupby('B').A.sum()\n\n.. warning::\n\n   The Integer NA support currently uses the capitalized dtype version, e.g. ``Int8`` as compared to the traditional ``int8``. This may be changed at a future date.\n\nSee :ref:`integer_na` for more.\n\n\n.. _whatsnew_0240.values_api:\n\nAccessing the values in a Series or Index\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n:attr:`Series.array` and :attr:`Index.array` have been added for extracting the array backing a\n``Series`` or ``Index``. (:issue:`19954`, :issue:`23623`)\n\n.. ipython:: python\n\n   idx = pd.period_range('2000', periods=4)\n   idx.array\n   pd.Series(idx).array\n\nHistorically, this would have been done with ``series.values``, but with\n``.values`` it was unclear whether the returned value would be the actual array,\nsome transformation of it, or one of pandas custom arrays (like\n``Categorical``). For example, with :class:`PeriodIndex`, ``.values`` generates\na new ndarray of period objects each time.\n\n.. ipython:: python\n\n   idx.values\n   id(idx.values)\n   id(idx.values)\n\nIf you need an actual NumPy array, use :meth:`Series.to_numpy` or :meth:`Index.to_numpy`.\n\n.. ipython:: python\n\n   idx.to_numpy()\n   pd.Series(idx).to_numpy()\n\nFor Series and Indexes backed by normal NumPy arrays, :attr:`Series.array` will return a\nnew :class:`arrays.PandasArray`, which is a thin (no-copy) wrapper around a\n:class:`numpy.ndarray`. :class:`~arrays.PandasArray` isn't especially useful on its own,\nbut it does provide the same interface as any extension array defined in pandas or by\na third-party library.\n\n.. ipython:: python\n\n   ser = pd.Series([1, 2, 3])\n   ser.array\n   ser.to_numpy()\n\nWe haven't removed or deprecated :attr:`Series.values` or :attr:`DataFrame.values`, but we\nhighly recommend and using ``.array`` or ``.to_numpy()`` instead.\n\nSee :ref:`Dtypes <basics.dtypes>` and :ref:`Attributes and Underlying Data <basics.attrs>` for more.\n\n\n.. _whatsnew_0240.enhancements.array:\n\n``pandas.array``: a new top-level method for creating arrays\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nA new top-level method :func:`array` has been added for creating 1-dimensional arrays (:issue:`22860`).\nThis can be used to create any :ref:`extension array <extending.extension-types>`, including\nextension arrays registered by `3rd party libraries <https://pandas.pydata.org/community/ecosystem.html>`_.\nSee the :ref:`dtypes docs <basics.dtypes>` for more on extension arrays.\n\n.. ipython:: python\n\n   pd.array([1, 2, np.nan], dtype='Int64')\n   pd.array(['a', 'b', 'c'], dtype='category')\n\nPassing data for which there isn't dedicated extension type (e.g. float, integer, etc.)\nwill return a new :class:`arrays.PandasArray`, which is just a thin (no-copy)\nwrapper around a :class:`numpy.ndarray` that satisfies the pandas extension array interface.\n\n.. ipython:: python\n\n   pd.array([1, 2, 3])\n\nOn their own, a :class:`~arrays.PandasArray` isn't a very useful object.\nBut if you need write low-level code that works generically for any\n:class:`~pandas.api.extensions.ExtensionArray`, :class:`~arrays.PandasArray`\nsatisfies that need.\n\nNotice that by default, if no ``dtype`` is specified, the dtype of the returned\narray is inferred from the data. In particular, note that the first example of\n``[1, 2, np.nan]`` would have returned a floating-point array, since ``NaN``\nis a float.\n\n.. ipython:: python\n\n   pd.array([1, 2, np.nan])\n\n\n.. _whatsnew_0240.enhancements.interval:\n\nStoring Interval and Period data in Series and DataFrame\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n:class:`Interval` and :class:`Period` data may now be stored in a :class:`Series` or :class:`DataFrame`, in addition to an\n:class:`IntervalIndex` and :class:`PeriodIndex` like previously (:issue:`19453`, :issue:`22862`).\n\n.. ipython:: python\n\n   ser = pd.Series(pd.interval_range(0, 5))\n   ser\n   ser.dtype\n\nFor periods:\n\n.. ipython:: python\n\n   pser = pd.Series(pd.period_range(\"2000\", freq=\"D\", periods=5))\n   pser\n   pser.dtype\n\nPreviously, these would be cast to a NumPy array with object dtype. In general,\nthis should result in better performance when storing an array of intervals or periods\nin a :class:`Series` or column of a :class:`DataFrame`.\n\nUse :attr:`Series.array` to extract the underlying array of intervals or periods\nfrom the ``Series``:\n\n.. ipython:: python\n\n   ser.array\n   pser.array\n\nThese return an instance of :class:`arrays.IntervalArray` or :class:`arrays.PeriodArray`,\nthe new extension arrays that back interval and period data.\n\n.. warning::\n\n   For backwards compatibility, :attr:`Series.values` continues to return\n   a NumPy array of objects for Interval and Period data. We recommend\n   using :attr:`Series.array` when you need the array of data stored in the\n   ``Series``, and :meth:`Series.to_numpy` when you know you need a NumPy array.\n\n   See :ref:`Dtypes <basics.dtypes>` and :ref:`Attributes and Underlying Data <basics.attrs>`\n   for more.\n\n\n.. _whatsnew_0240.enhancements.join_with_two_multiindexes:\n\nJoining with two multi-indexes\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n:func:`DataFrame.merge` and :func:`DataFrame.join` can now be used to join multi-indexed ``Dataframe`` instances on the overlapping index levels (:issue:`6360`)\n\nSee the :ref:`Merge, join, and concatenate\n<merging.Join_with_two_multi_indexes>` documentation section.\n\n.. ipython:: python\n\n   index_left = pd.MultiIndex.from_tuples([('K0', 'X0'), ('K0', 'X1'),\n                                          ('K1', 'X2')],\n                                          names=['key', 'X'])\n\n   left = pd.DataFrame({'A': ['A0', 'A1', 'A2'],\n                        'B': ['B0', 'B1', 'B2']}, index=index_left)\n\n   index_right = pd.MultiIndex.from_tuples([('K0', 'Y0'), ('K1', 'Y1'),\n                                           ('K2', 'Y2'), ('K2', 'Y3')],\n                                           names=['key', 'Y'])\n\n   right = pd.DataFrame({'C': ['C0', 'C1', 'C2', 'C3'],\n                         'D': ['D0', 'D1', 'D2', 'D3']}, index=index_right)\n\n   left.join(right)\n\nFor earlier versions this can be done using the following.\n\n.. ipython:: python\n\n   pd.merge(left.reset_index(), right.reset_index(),\n            on=['key'], how='inner').set_index(['key', 'X', 'Y'])\n\n.. _whatsnew_0240.enhancements.read_html:\n\nFunction ``read_html`` enhancements\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n:func:`read_html` previously ignored ``colspan`` and ``rowspan`` attributes.\nNow it understands them, treating them as sequences of cells with the same\nvalue. (:issue:`17054`)\n\n.. ipython:: python\n\n    from io import StringIO\n    result = pd.read_html(StringIO(\"\"\"\n      <table>\n        <thead>\n          <tr>\n            <th>A</th><th>B</th><th>C</th>\n          </tr>\n        </thead>\n        <tbody>\n          <tr>\n            <td colspan=\"2\">1</td><td>2</td>\n          </tr>\n        </tbody>\n      </table>\"\"\"))\n\n*Previous behavior*:\n\n.. code-block:: ipython\n\n    In [13]: result\n    Out [13]:\n    [   A  B   C\n     0  1  2 NaN]\n\n*New behavior*:\n\n.. ipython:: python\n\n    result\n\n\nNew ``Styler.pipe()`` method\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nThe :class:`~pandas.io.formats.style.Styler` class has gained a\n:meth:`~pandas.io.formats.style.Styler.pipe` method.  This provides a\nconvenient way to apply users' predefined styling functions, and can help reduce\n\"boilerplate\" when using DataFrame styling functionality repeatedly within a notebook. (:issue:`23229`)\n\n.. ipython:: python\n\n    df = pd.DataFrame({'N': [1250, 1500, 1750], 'X': [0.25, 0.35, 0.50]})\n\n    def format_and_align(styler):\n        return (styler.format({'N': '{:,}', 'X': '{:.1%}'})\n                      .set_properties(**{'text-align': 'right'}))\n\n    df.style.pipe(format_and_align).set_caption('Summary of results.')\n\nSimilar methods already exist for other classes in pandas, including :meth:`DataFrame.pipe`,\n:meth:`GroupBy.pipe() <.GroupBy.pipe>`, and :meth:`Resampler.pipe() <.Resampler.pipe>`.\n\n.. _whatsnew_0240.enhancements.rename_axis:\n\nRenaming names in a MultiIndex\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n:func:`DataFrame.rename_axis` now supports ``index`` and ``columns`` arguments\nand :func:`Series.rename_axis` supports ``index`` argument (:issue:`19978`).\n\nThis change allows a dictionary to be passed so that some of the names\nof a ``MultiIndex`` can be changed.\n\nExample:\n\n.. ipython:: python\n\n    mi = pd.MultiIndex.from_product([list('AB'), list('CD'), list('EF')],\n                                    names=['AB', 'CD', 'EF'])\n    df = pd.DataFrame(list(range(len(mi))), index=mi, columns=['N'])\n    df\n    df.rename_axis(index={'CD': 'New'})\n\nSee the :ref:`Advanced documentation on renaming<advanced.index_names>` for more details.\n\n.. _whatsnew_0240.enhancements.other:\n\nOther enhancements\n^^^^^^^^^^^^^^^^^^\n\n- :func:`merge` now directly allows merge between objects of type ``DataFrame`` and named ``Series``, without the need to convert the ``Series`` object into a ``DataFrame`` beforehand (:issue:`21220`)\n- ``ExcelWriter`` now accepts ``mode`` as a keyword argument, enabling append to existing workbooks when using the ``openpyxl`` engine (:issue:`3441`)\n- ``FrozenList`` has gained the ``.union()`` and ``.difference()`` methods. This functionality greatly simplifies groupby's that rely on explicitly excluding certain columns. See :ref:`Splitting an object into groups <groupby.split>` for more information (:issue:`15475`, :issue:`15506`).\n- :func:`DataFrame.to_parquet` now accepts ``index`` as an argument, allowing\n  the user to override the engine's default behavior to include or omit the\n  dataframe's indexes from the resulting Parquet file. (:issue:`20768`)\n- :func:`read_feather` now accepts ``columns`` as an argument, allowing the user to specify which columns should be read. (:issue:`24025`)\n- :meth:`DataFrame.corr` and :meth:`Series.corr` now accept a callable for generic calculation methods of correlation, e.g. histogram intersection (:issue:`22684`)\n- :func:`DataFrame.to_string` now accepts ``decimal`` as an argument, allowing the user to specify which decimal separator should be used in the output. (:issue:`23614`)\n- :func:`DataFrame.to_html` now accepts ``render_links`` as an argument, allowing the user to generate HTML with links to any URLs that appear in the DataFrame.\n  See the :ref:`section on writing HTML <io.html>` in the IO docs for example usage. (:issue:`2679`)\n- :func:`pandas.read_csv` now supports pandas extension types as an argument to ``dtype``, allowing the user to use pandas extension types when reading CSVs. (:issue:`23228`)\n- The :meth:`~DataFrame.shift` method now accepts ``fill_value`` as an argument, allowing the user to specify a value which will be used instead of NA/NaT in the empty periods. (:issue:`15486`)\n- :func:`to_datetime` now supports the ``%Z`` and ``%z`` directive when passed into ``format`` (:issue:`13486`)\n- :func:`Series.mode` and :func:`DataFrame.mode` now support the ``dropna`` parameter which can be used to specify whether ``NaN``/``NaT`` values should be considered (:issue:`17534`)\n- :func:`DataFrame.to_csv` and :func:`Series.to_csv` now support the ``compression`` keyword when a file handle is passed. (:issue:`21227`)\n- :meth:`Index.droplevel` is now implemented also for flat indexes, for compatibility with :class:`MultiIndex` (:issue:`21115`)\n- :meth:`Series.droplevel` and :meth:`DataFrame.droplevel` are now implemented (:issue:`20342`)\n- Added support for reading from/writing to Google Cloud Storage via the ``gcsfs`` library (:issue:`19454`, :issue:`23094`)\n- :func:`DataFrame.to_gbq` and :func:`read_gbq` signature and documentation updated to\n  reflect changes from the `pandas-gbq library version 0.8.0\n  <https://pandas-gbq.readthedocs.io/en/latest/changelog.html#changelog-0-8-0>`__.\n  Adds a ``credentials`` argument, which enables the use of any kind of\n  `google-auth credentials\n  <https://google-auth.readthedocs.io/en/latest/>`__. (:issue:`21627`,\n  :issue:`22557`, :issue:`23662`)\n- New method :meth:`HDFStore.walk` will recursively walk the group hierarchy of an HDF5 file (:issue:`10932`)\n- :func:`read_html` copies cell data across ``colspan`` and ``rowspan``, and it treats all-``th`` table rows as headers if ``header`` kwarg is not given and there is no ``thead`` (:issue:`17054`)\n- :meth:`Series.nlargest`, :meth:`Series.nsmallest`, :meth:`DataFrame.nlargest`, and :meth:`DataFrame.nsmallest` now accept the value ``\"all\"`` for the ``keep`` argument. This keeps all ties for the nth largest/smallest value (:issue:`16818`)\n- :class:`IntervalIndex` has gained the :meth:`~IntervalIndex.set_closed` method to change the existing ``closed`` value (:issue:`21670`)\n- :func:`~DataFrame.to_csv`, :func:`~Series.to_csv`, :func:`~DataFrame.to_json`, and :func:`~Series.to_json` now support ``compression='infer'`` to infer compression based on filename extension (:issue:`15008`).\n  The default compression for ``to_csv``, ``to_json``, and ``to_pickle`` methods has been updated to ``'infer'`` (:issue:`22004`).\n- :meth:`DataFrame.to_sql` now supports writing ``TIMESTAMP WITH TIME ZONE`` types for supported databases. For databases that don't support timezones, datetime data will be stored as timezone unaware local timestamps. See the :ref:`io.sql_datetime_data` for implications (:issue:`9086`).\n- :func:`to_timedelta` now supports iso-formatted timedelta strings (:issue:`21877`)\n- :class:`Series` and :class:`DataFrame` now support :class:`Iterable` objects in the constructor (:issue:`2193`)\n- :class:`DatetimeIndex` has gained the :attr:`DatetimeIndex.timetz` attribute. This returns the local time with timezone information. (:issue:`21358`)\n- :meth:`~Timestamp.round`, :meth:`~Timestamp.ceil`, and :meth:`~Timestamp.floor` for :class:`DatetimeIndex` and :class:`Timestamp`\n  now support an ``ambiguous`` argument for handling datetimes that are rounded to ambiguous times (:issue:`18946`)\n  and a ``nonexistent`` argument for handling datetimes that are rounded to nonexistent times. See :ref:`timeseries.timezone_nonexistent` (:issue:`22647`)\n- The result of :meth:`~DataFrame.resample` is now iterable similar to ``groupby()`` (:issue:`15314`).\n- :meth:`Series.resample` and :meth:`DataFrame.resample` have gained the :meth:`.Resampler.quantile` (:issue:`15023`).\n- :meth:`DataFrame.resample` and :meth:`Series.resample` with a :class:`PeriodIndex` will now respect the ``base`` argument in the same fashion as with a :class:`DatetimeIndex`. (:issue:`23882`)\n- :meth:`pandas.api.types.is_list_like` has gained a keyword ``allow_sets`` which is ``True`` by default; if ``False``,\n  all instances of ``set`` will not be considered \"list-like\" anymore (:issue:`23061`)\n- :meth:`Index.to_frame` now supports overriding column name(s) (:issue:`22580`).\n- :meth:`Categorical.from_codes` now can take a ``dtype`` parameter as an alternative to passing ``categories`` and ``ordered`` (:issue:`24398`).\n- New attribute ``__git_version__`` will return git commit sha of current build (:issue:`21295`).\n- Compatibility with Matplotlib 3.0 (:issue:`22790`).\n- Added :meth:`Interval.overlaps`, :meth:`arrays.IntervalArray.overlaps`, and :meth:`IntervalIndex.overlaps` for determining overlaps between interval-like objects (:issue:`21998`)\n- :func:`read_fwf` now accepts keyword ``infer_nrows`` (:issue:`15138`).\n- :func:`~DataFrame.to_parquet` now supports writing a ``DataFrame`` as a directory of parquet files partitioned by a subset of the columns when ``engine = 'pyarrow'`` (:issue:`23283`)\n- :meth:`Timestamp.tz_localize`, :meth:`DatetimeIndex.tz_localize`, and :meth:`Series.tz_localize` have gained the ``nonexistent`` argument for alternative handling of nonexistent times. See :ref:`timeseries.timezone_nonexistent` (:issue:`8917`, :issue:`24466`)\n- :meth:`Index.difference`, :meth:`Index.intersection`, :meth:`Index.union`, and :meth:`Index.symmetric_difference` now have an optional ``sort`` parameter to control whether the results should be sorted if possible (:issue:`17839`, :issue:`24471`)\n- :meth:`read_excel()` now accepts ``usecols`` as a list of column names or callable (:issue:`18273`)\n- :meth:`MultiIndex.to_flat_index` has been added to flatten multiple levels into a single-level :class:`Index` object.\n- :meth:`DataFrame.to_stata` and :class:`pandas.io.stata.StataWriter117` can write mixed string columns to Stata strl format (:issue:`23633`)\n- :meth:`DataFrame.between_time` and :meth:`DataFrame.at_time` have gained the ``axis`` parameter (:issue:`8839`)\n- :meth:`DataFrame.to_records` now accepts ``index_dtypes`` and ``column_dtypes`` parameters to allow different data types in stored column and index records (:issue:`18146`)\n- :class:`IntervalIndex` has gained the :attr:`~IntervalIndex.is_overlapping` attribute to indicate if the ``IntervalIndex`` contains any overlapping intervals (:issue:`23309`)\n- :func:`pandas.DataFrame.to_sql` has gained the ``method`` argument to control SQL insertion clause. See the :ref:`insertion method <io.sql.method>` section in the documentation. (:issue:`8953`)\n- :meth:`DataFrame.corrwith` now supports Spearman's rank correlation, Kendall's tau as well as callable correlation methods. (:issue:`21925`)\n- :meth:`DataFrame.to_json`, :meth:`DataFrame.to_csv`, :meth:`DataFrame.to_pickle`, and other export methods now support tilde(~) in path argument. (:issue:`23473`)\n\n.. _whatsnew_0240.api_breaking:\n\nBackwards incompatible API changes\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\npandas 0.24.0 includes a number of API breaking changes.\n\n\n.. _whatsnew_0240.api_breaking.deps:\n\nIncreased minimum versions for dependencies\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nWe have updated our minimum supported versions of dependencies (:issue:`21242`, :issue:`18742`, :issue:`23774`, :issue:`24767`).\nIf installed, we now require:\n\n+-----------------+-----------------+----------+\n| Package         | Minimum Version | Required |\n+=================+=================+==========+\n| numpy           | 1.12.0          |    X     |\n+-----------------+-----------------+----------+\n| bottleneck      | 1.2.0           |          |\n+-----------------+-----------------+----------+\n| fastparquet     | 0.2.1           |          |\n+-----------------+-----------------+----------+\n| matplotlib      | 2.0.0           |          |\n+-----------------+-----------------+----------+\n| numexpr         | 2.6.1           |          |\n+-----------------+-----------------+----------+\n| pandas-gbq      | 0.8.0           |          |\n+-----------------+-----------------+----------+\n| pyarrow         | 0.9.0           |          |\n+-----------------+-----------------+----------+\n| pytables        | 3.4.2           |          |\n+-----------------+-----------------+----------+\n| scipy           | 0.18.1          |          |\n+-----------------+-----------------+----------+\n| xlrd            | 1.0.0           |          |\n+-----------------+-----------------+----------+\n| pytest (dev)    | 3.6             |          |\n+-----------------+-----------------+----------+\n\nAdditionally we no longer depend on ``feather-format`` for feather based storage\nand replaced it with references to ``pyarrow`` (:issue:`21639` and :issue:`23053`).\n\n.. _whatsnew_0240.api_breaking.csv_line_terminator:\n\n``os.linesep`` is used for ``line_terminator`` of ``DataFrame.to_csv``\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n:func:`DataFrame.to_csv` now uses :func:`os.linesep` rather than ``'\\n'``\nfor the default line terminator (:issue:`20353`).\nThis change only affects when running on Windows, where ``'\\r\\n'`` was used for line terminator\neven when ``'\\n'`` was passed in ``line_terminator``.\n\n*Previous behavior* on Windows:\n\n.. code-block:: ipython\n\n    In [1]: data = pd.DataFrame({\"string_with_lf\": [\"a\\nbc\"],\n       ...:                      \"string_with_crlf\": [\"a\\r\\nbc\"]})\n\n    In [2]:  When passing file PATH to to_csv,\n       ...:  line_terminator does not work, and csv is saved with '\\r\\n'.\n       ...:  Also, this converts all '\\n's in the data to '\\r\\n'.\n       ...: data.to_csv(\"test.csv\", index=False, line_terminator='\\n')\n\n    In [3]: with open(\"test.csv\", mode='rb') as f:\n       ...:     print(f.read())\n    Out[3]: b'string_with_lf,string_with_crlf\\r\\n\"a\\r\\nbc\",\"a\\r\\r\\nbc\"\\r\\n'\n\n    In [4]:  When passing file OBJECT with newline option to\n       ...:  to_csv, line_terminator works.\n       ...: with open(\"test2.csv\", mode='w', newline='\\n') as f:\n       ...:     data.to_csv(f, index=False, line_terminator='\\n')\n\n    In [5]: with open(\"test2.csv\", mode='rb') as f:\n       ...:     print(f.read())\n    Out[5]: b'string_with_lf,string_with_crlf\\n\"a\\nbc\",\"a\\r\\nbc\"\\n'\n\n\n*New behavior* on Windows:\n\nPassing ``line_terminator`` explicitly, set the ``line terminator`` to that character.\n\n.. code-block:: ipython\n\n   In [1]: data = pd.DataFrame({\"string_with_lf\": [\"a\\nbc\"],\n      ...:                      \"string_with_crlf\": [\"a\\r\\nbc\"]})\n\n   In [2]: data.to_csv(\"test.csv\", index=False, line_terminator='\\n')\n\n   In [3]: with open(\"test.csv\", mode='rb') as f:\n      ...:     print(f.read())\n   Out[3]: b'string_with_lf,string_with_crlf\\n\"a\\nbc\",\"a\\r\\nbc\"\\n'\n\n\nOn Windows, the value of ``os.linesep`` is ``'\\r\\n'``, so if ``line_terminator`` is not\nset, ``'\\r\\n'`` is used for line terminator.\n\n.. code-block:: ipython\n\n   In [1]: data = pd.DataFrame({\"string_with_lf\": [\"a\\nbc\"],\n      ...:                      \"string_with_crlf\": [\"a\\r\\nbc\"]})\n\n   In [2]: data.to_csv(\"test.csv\", index=False)\n\n   In [3]: with open(\"test.csv\", mode='rb') as f:\n      ...:     print(f.read())\n   Out[3]: b'string_with_lf,string_with_crlf\\r\\n\"a\\nbc\",\"a\\r\\nbc\"\\r\\n'\n\n\nFor file objects, specifying ``newline`` is not sufficient to set the line terminator.\nYou must pass in the ``line_terminator`` explicitly, even in this case.\n\n.. code-block:: ipython\n\n   In [1]: data = pd.DataFrame({\"string_with_lf\": [\"a\\nbc\"],\n      ...:                      \"string_with_crlf\": [\"a\\r\\nbc\"]})\n\n   In [2]: with open(\"test2.csv\", mode='w', newline='\\n') as f:\n      ...:     data.to_csv(f, index=False)\n\n   In [3]: with open(\"test2.csv\", mode='rb') as f:\n      ...:     print(f.read())\n   Out[3]: b'string_with_lf,string_with_crlf\\r\\n\"a\\nbc\",\"a\\r\\nbc\"\\r\\n'\n\n.. _whatsnew_0240.bug_fixes.nan_with_str_dtype:\n\nProper handling of ``np.nan`` in a string data-typed column with the Python engine\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nThere was bug in :func:`read_excel` and :func:`read_csv` with the Python\nengine, where missing values turned to ``'nan'`` with ``dtype=str`` and\n``na_filter=True``. Now, these missing values are converted to the string\nmissing indicator, ``np.nan``. (:issue:`20377`)\n\n.. ipython:: python\n   :suppress:\n\n   from io import StringIO\n\n*Previous behavior*:\n\n.. code-block:: ipython\n\n   In [5]: data = 'a,b,c\\n1,,3\\n4,5,6'\n   In [6]: df = pd.read_csv(StringIO(data), engine='python', dtype=str, na_filter=True)\n   In [7]: df.loc[0, 'b']\n   Out[7]:\n   'nan'\n\n*New behavior*:\n\n.. ipython:: python\n\n   data = 'a,b,c\\n1,,3\\n4,5,6'\n   df = pd.read_csv(StringIO(data), engine='python', dtype=str, na_filter=True)\n   df.loc[0, 'b']\n\nNotice how we now instead output ``np.nan`` itself instead of a stringified form of it.\n\n.. _whatsnew_0240.api.timezone_offset_parsing:\n\nParsing datetime strings with timezone offsets\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nPreviously, parsing datetime strings with UTC offsets with :func:`to_datetime`\nor :class:`DatetimeIndex` would automatically convert the datetime to UTC\nwithout timezone localization. This is inconsistent from parsing the same\ndatetime string with :class:`Timestamp` which would preserve the UTC\noffset in the ``tz`` attribute. Now, :func:`to_datetime` preserves the UTC\noffset in the ``tz`` attribute when all the datetime strings have the same\nUTC offset (:issue:`17697`, :issue:`11736`, :issue:`22457`)\n\n*Previous behavior*:\n\n.. code-block:: ipython\n\n    In [2]: pd.to_datetime(\"2015-11-18 15:30:00+05:30\")\n    Out[2]: Timestamp('2015-11-18 10:00:00')\n\n    In [3]: pd.Timestamp(\"2015-11-18 15:30:00+05:30\")\n    Out[3]: Timestamp('2015-11-18 15:30:00+0530', tz='pytz.FixedOffset(330)')\n\n     Different UTC offsets would automatically convert the datetimes to UTC (without a UTC timezone)\n    In [4]: pd.to_datetime([\"2015-11-18 15:30:00+05:30\", \"2015-11-18 16:30:00+06:30\"])\n    Out[4]: DatetimeIndex(['2015-11-18 10:00:00', '2015-11-18 10:00:00'], dtype='datetime64[ns]', freq=None)\n\n*New behavior*:\n\n.. ipython:: python\n\n    pd.to_datetime(\"2015-11-18 15:30:00+05:30\")\n    pd.Timestamp(\"2015-11-18 15:30:00+05:30\")\n\nParsing datetime strings with the same UTC offset will preserve the UTC offset in the ``tz``\n\n.. ipython:: python\n\n    pd.to_datetime([\"2015-11-18 15:30:00+05:30\"] * 2)\n\nParsing datetime strings with different UTC offsets will now create an Index of\n``datetime.datetime`` objects with different UTC offsets\n\n.. code-block:: ipython\n\n    In [59]: idx = pd.to_datetime([\"2015-11-18 15:30:00+05:30\",\n                                   \"2015-11-18 16:30:00+06:30\"])\n\n    In[60]: idx\n    Out[60]: Index([2015-11-18 15:30:00+05:30, 2015-11-18 16:30:00+06:30], dtype='object')\n\n    In[61]: idx[0]\n    Out[61]: Timestamp('2015-11-18 15:30:00+0530', tz='UTC+05:30')\n\n    In[62]: idx[1]\n    Out[62]: Timestamp('2015-11-18 16:30:00+0630', tz='UTC+06:30')\n\nPassing ``utc=True`` will mimic the previous behavior but will correctly indicate\nthat the dates have been converted to UTC\n\n.. ipython:: python\n\n    pd.to_datetime([\"2015-11-18 15:30:00+05:30\",\n                    \"2015-11-18 16:30:00+06:30\"], utc=True)\n\n\n.. _whatsnew_0240.api_breaking.read_csv_mixed_tz:\n\nParsing mixed-timezones with :func:`read_csv`\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n:func:`read_csv` no longer silently converts mixed-timezone columns to UTC (:issue:`24987`).\n\n*Previous behavior*\n\n.. code-block:: python\n\n   >>> import io\n   >>> content = \"\"\"\\\n   ... a\n   ... 2000-01-01T00:00:00+05:00\n   ... 2000-01-01T00:00:00+06:00\"\"\"\n   >>> df = pd.read_csv(io.StringIO(content), parse_dates=['a'])\n   >>> df.a\n   0   1999-12-31 19:00:00\n   1   1999-12-31 18:00:00\n   Name: a, dtype: datetime64[ns]\n\n*New behavior*\n\n.. code-block:: ipython\n\n   In[64]: import io\n\n   In[65]: content = \"\"\"\\\n      ...: a\n      ...: 2000-01-01T00:00:00+05:00\n      ...: 2000-01-01T00:00:00+06:00\"\"\"\n\n   In[66]: df = pd.read_csv(io.StringIO(content), parse_dates=['a'])\n\n   In[67]: df.a\n   Out[67]:\n   0   2000-01-01 00:00:00+05:00\n   1   2000-01-01 00:00:00+06:00\n   Name: a, Length: 2, dtype: object\n\nAs can be seen, the ``dtype`` is object; each value in the column is a string.\nTo convert the strings to an array of datetimes, the ``date_parser`` argument\n\n.. code-block:: ipython\n\n   In [3]: df = pd.read_csv(\n      ...:     io.StringIO(content),\n      ...:     parse_dates=['a'],\n      ...:     date_parser=lambda col: pd.to_datetime(col, utc=True),\n      ...: )\n\n   In [4]: df.a\n   Out[4]:\n   0   1999-12-31 19:00:00+00:00\n   1   1999-12-31 18:00:00+00:00\n   Name: a, dtype: datetime64[ns, UTC]\n\nSee :ref:`whatsnew_0240.api.timezone_offset_parsing` for more.\n\n.. _whatsnew_0240.api_breaking.period_end_time:\n\nTime values in ``dt.end_time`` and ``to_timestamp(how='end')``\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nThe time values in :class:`Period` and :class:`PeriodIndex` objects are now set\nto '23:59:59.999999999' when calling :attr:`Series.dt.end_time`, :attr:`Period.end_time`,\n:attr:`PeriodIndex.end_time`, :func:`Period.to_timestamp()` with ``how='end'``,\nor :func:`PeriodIndex.to_timestamp()` with ``how='end'`` (:issue:`17157`)\n\n*Previous behavior*:\n\n.. code-block:: ipython\n\n   In [2]: p = pd.Period('2017-01-01', 'D')\n   In [3]: pi = pd.PeriodIndex([p])\n\n   In [4]: pd.Series(pi).dt.end_time[0]\n   Out[4]: Timestamp(2017-01-01 00:00:00)\n\n   In [5]: p.end_time\n   Out[5]: Timestamp(2017-01-01 23:59:59.999999999)\n\n*New behavior*:\n\nCalling :attr:`Series.dt.end_time` will now result in a time of '23:59:59.999999999' as\nis the case with :attr:`Period.end_time`, for example\n\n.. ipython:: python\n\n   p = pd.Period('2017-01-01', 'D')\n   pi = pd.PeriodIndex([p])\n\n   pd.Series(pi).dt.end_time[0]\n\n   p.end_time\n\n.. _whatsnew_0240.api_breaking.datetime_unique:\n\nSeries.unique for timezone-aware data\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nThe return type of :meth:`Series.unique` for datetime with timezone values has changed\nfrom an :class:`numpy.ndarray` of :class:`Timestamp` objects to a :class:`arrays.DatetimeArray` (:issue:`24024`).\n\n.. ipython:: python\n\n   ser = pd.Series([pd.Timestamp('2000', tz='UTC'),\n                    pd.Timestamp('2000', tz='UTC')])\n\n*Previous behavior*:\n\n.. code-block:: ipython\n\n   In [3]: ser.unique()\n   Out[3]: array([Timestamp('2000-01-01 00:00:00+0000', tz='UTC')], dtype=object)\n\n\n*New behavior*:\n\n.. ipython:: python\n\n   ser.unique()\n\n\n.. _whatsnew_0240.api_breaking.sparse_values:\n\nSparse data structure refactor\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n``SparseArray``, the array backing ``SparseSeries`` and the columns in a ``SparseDataFrame``,\nis now an extension array (:issue:`21978`, :issue:`19056`, :issue:`22835`).\nTo conform to this interface and for consistency with the rest of pandas, some API breaking\nchanges were made:\n\n- ``SparseArray`` is no longer a subclass of :class:`numpy.ndarray`. To convert a ``SparseArray`` to a NumPy array, use :func:`numpy.asarray`.\n- ``SparseArray.dtype`` and ``SparseSeries.dtype`` are now instances of :class:`SparseDtype`, rather than ``np.dtype``. Access the underlying dtype with ``SparseDtype.subtype``.\n- ``numpy.asarray(sparse_array)`` now returns a dense array with all the values, not just the non-fill-value values (:issue:`14167`)\n- ``SparseArray.take`` now matches the API of :meth:`pandas.api.extensions.ExtensionArray.take` (:issue:`19506`):\n\n  * The default value of ``allow_fill`` has changed from ``False`` to ``True``.\n  * The ``out`` and ``mode`` parameters are now longer accepted (previously, this raised if they were specified).\n  * Passing a scalar for ``indices`` is no longer allowed.\n\n- The result of :func:`concat` with a mix of sparse and dense Series is a Series with sparse values, rather than a ``SparseSeries``.\n- ``SparseDataFrame.combine`` and ``DataFrame.combine_first`` no longer supports combining a sparse column with a dense column while preserving the sparse subtype. The result will be an object-dtype SparseArray.\n- Setting :attr:`SparseArray.fill_value` to a fill value with a different dtype is now allowed.\n- ``DataFrame[column]`` is now a :class:`Series` with sparse values, rather than a :class:`SparseSeries`, when slicing a single column with sparse values (:issue:`23559`).\n- The result of :meth:`Series.where` is now a ``Series`` with sparse values, like with other extension arrays (:issue:`24077`)\n\nSome new warnings are issued for operations that require or are likely to materialize a large dense array:\n\n- A :class:`errors.PerformanceWarning` is issued when using fillna with a ``method``, as a dense array is constructed to create the filled array. Filling with a ``value`` is the efficient way to fill a sparse array.\n- A :class:`errors.PerformanceWarning` is now issued when concatenating sparse Series with differing fill values. The fill value from the first sparse array continues to be used.\n\nIn addition to these API breaking changes, many :ref:`Performance Improvements and Bug Fixes have been made <whatsnew_0240.bug_fixes.sparse>`.\n\nFinally, a ``Series.sparse`` accessor was added to provide sparse-specific methods like :meth:`Series.sparse.from_coo`.\n\n.. ipython:: python\n\n   s = pd.Series([0, 0, 1, 1, 1], dtype='Sparse[int]')\n   s.sparse.density\n\n.. _whatsnew_0240.api_breaking.get_dummies:\n\n:meth:`get_dummies` always returns a DataFrame\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nPreviously, when ``sparse=True`` was passed to :func:`get_dummies`, the return value could be either\na :class:`DataFrame` or a :class:`SparseDataFrame`, depending on whether all or a just a subset\nof the columns were dummy-encoded. Now, a :class:`DataFrame` is always returned (:issue:`24284`).\n\n*Previous behavior*\n\nThe first :func:`get_dummies` returns a :class:`DataFrame` because the column ``A``\nis not dummy encoded. When just ``[\"B\", \"C\"]`` are passed to ``get_dummies``,\nthen all the columns are dummy-encoded, and a :class:`SparseDataFrame` was returned.\n\n.. code-block:: ipython\n\n   In [2]: df = pd.DataFrame({\"A\": [1, 2], \"B\": ['a', 'b'], \"C\": ['a', 'a']})\n\n   In [3]: type(pd.get_dummies(df, sparse=True))\n   Out[3]: pandas.core.frame.DataFrame\n\n   In [4]: type(pd.get_dummies(df[['B', 'C']], sparse=True))\n   Out[4]: pandas.core.sparse.frame.SparseDataFrame\n\n.. ipython:: python\n   :suppress:\n\n   df = pd.DataFrame({\"A\": [1, 2], \"B\": ['a', 'b'], \"C\": ['a', 'a']})\n\n*New behavior*\n\nNow, the return type is consistently a :class:`DataFrame`.\n\n.. ipython:: python\n\n   type(pd.get_dummies(df, sparse=True))\n   type(pd.get_dummies(df[['B', 'C']], sparse=True))\n\n.. note::\n\n   There's no difference in memory usage between a :class:`SparseDataFrame`\n   and a :class:`DataFrame` with sparse values. The memory usage will\n   be the same as in the previous version of pandas.\n\n.. _whatsnew_0240.api_breaking.frame_to_dict_index_orient:\n\nRaise ValueError in ``DataFrame.to_dict(orient='index')``\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nBug in :func:`DataFrame.to_dict` raises ``ValueError`` when used with\n``orient='index'`` and a non-unique index instead of losing data (:issue:`22801`)\n\n.. ipython:: python\n    :okexcept:\n\n    df = pd.DataFrame({'a': [1, 2], 'b': [0.5, 0.75]}, index=['A', 'A'])\n    df\n\n    df.to_dict(orient='index')\n\n.. _whatsnew_0240.api.datetimelike.normalize:\n\nTick DateOffset normalize restrictions\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nCreating a ``Tick`` object (:class:`Day`, :class:`Hour`, :class:`Minute`,\n:class:`Second`, :class:`Milli`, :class:`Micro`, :class:`Nano`) with\n``normalize=True`` is no longer supported.  This prevents unexpected behavior\nwhere addition could fail to be monotone or associative.  (:issue:`21427`)\n\n*Previous behavior*:\n\n.. code-block:: ipython\n\n\n   In [2]: ts = pd.Timestamp('2018-06-11 18:01:14')\n\n   In [3]: ts\n   Out[3]: Timestamp('2018-06-11 18:01:14')\n\n   In [4]: tic = pd.offsets.Hour(n=2, normalize=True)\n      ...:\n\n   In [5]: tic\n   Out[5]: <2 * Hours>\n\n   In [6]: ts + tic\n   Out[6]: Timestamp('2018-06-11 00:00:00')\n\n   In [7]: ts + tic + tic + tic == ts + (tic + tic + tic)\n   Out[7]: False\n\n*New behavior*:\n\n.. ipython:: python\n\n    ts = pd.Timestamp('2018-06-11 18:01:14')\n    tic = pd.offsets.Hour(n=2)\n    ts + tic + tic + tic == ts + (tic + tic + tic)\n\n\n.. _whatsnew_0240.api.datetimelike:\n\n\n.. _whatsnew_0240.api.period_subtraction:\n\nPeriod subtraction\n^^^^^^^^^^^^^^^^^^\n\nSubtraction of a ``Period`` from another ``Period`` will give a ``DateOffset``.\ninstead of an integer (:issue:`21314`)\n\n*Previous behavior*:\n\n.. code-block:: ipython\n\n    In [2]: june = pd.Period('June 2018')\n\n    In [3]: april = pd.Period('April 2018')\n\n    In [4]: june - april\n    Out [4]: 2\n\n*New behavior*:\n\n.. ipython:: python\n\n    june = pd.Period('June 2018')\n    april = pd.Period('April 2018')\n    june - april\n\nSimilarly, subtraction of a ``Period`` from a ``PeriodIndex`` will now return\nan ``Index`` of ``DateOffset`` objects instead of an ``Int64Index``\n\n*Previous behavior*:\n\n.. code-block:: ipython\n\n    In [2]: pi = pd.period_range('June 2018', freq='M', periods=3)\n\n    In [3]: pi - pi[0]\n    Out[3]: Int64Index([0, 1, 2], dtype='int64')\n\n*New behavior*:\n\n.. ipython:: python\n\n    pi = pd.period_range('June 2018', freq='M', periods=3)\n    pi - pi[0]\n\n\n.. _whatsnew_0240.api.timedelta64_subtract_nan:\n\nAddition/subtraction of ``NaN`` from :class:`DataFrame`\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nAdding or subtracting ``NaN`` from a :class:`DataFrame` column with\n``timedelta64[ns]`` dtype will now raise a ``TypeError`` instead of returning\nall-``NaT``.  This is for compatibility with ``TimedeltaIndex`` and\n``Series`` behavior (:issue:`22163`)\n\n.. ipython:: python\n\n   df = pd.DataFrame([pd.Timedelta(days=1)])\n   df\n\n*Previous behavior*:\n\n.. code-block:: ipython\n\n    In [4]: df = pd.DataFrame([pd.Timedelta(days=1)])\n\n    In [5]: df - np.nan\n    Out[5]:\n        0\n    0 NaT\n\n*New behavior*:\n\n.. code-block:: ipython\n\n    In [2]: df - np.nan\n    ...\n    TypeError: unsupported operand type(s) for -: 'TimedeltaIndex' and 'float'\n\n.. _whatsnew_0240.api.dataframe_cmp_broadcasting:\n\nDataFrame comparison operations broadcasting changes\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nPreviously, the broadcasting behavior of :class:`DataFrame` comparison\noperations (``==``, ``!=``, ...) was inconsistent with the behavior of\narithmetic operations (``+``, ``-``, ...).  The behavior of the comparison\noperations has been changed to match the arithmetic operations in these cases.\n(:issue:`22880`)\n\nThe affected cases are:\n\n- operating against a 2-dimensional ``np.ndarray`` with either 1 row or 1 column will now broadcast the same way a ``np.ndarray`` would (:issue:`23000`).\n- a list or tuple with length matching the number of rows in the :class:`DataFrame` will now raise ``ValueError`` instead of operating column-by-column (:issue:`22880`.\n- a list or tuple with length matching the number of columns in the :class:`DataFrame` will now operate row-by-row instead of raising ``ValueError`` (:issue:`22880`).\n\n.. ipython:: python\n\n   arr = np.arange(6).reshape(3, 2)\n   df = pd.DataFrame(arr)\n   df\n\n*Previous behavior*:\n\n.. code-block:: ipython\n\n   In [5]: df == arr[[0], :]\n       ...:  comparison previously broadcast where arithmetic would raise\n   Out[5]:\n          0      1\n   0   True   True\n   1  False  False\n   2  False  False\n   In [6]: df + arr[[0], :]\n   ...\n   ValueError: Unable to coerce to DataFrame, shape must be (3, 2): given (1, 2)\n\n   In [7]: df == (1, 2)\n       ...:  length matches number of columns;\n       ...:  comparison previously raised where arithmetic would broadcast\n   ...\n   ValueError: Invalid broadcasting comparison [(1, 2)] with block values\n   In [8]: df + (1, 2)\n   Out[8]:\n      0  1\n   0  1  3\n   1  3  5\n   2  5  7\n\n   In [9]: df == (1, 2, 3)\n       ...:   length matches number of rows\n       ...:   comparison previously broadcast where arithmetic would raise\n   Out[9]:\n          0      1\n   0  False   True\n   1   True  False\n   2  False  False\n   In [10]: df + (1, 2, 3)\n   ...\n   ValueError: Unable to coerce to Series, length must be 2: given 3\n\n*New behavior*:\n\n.. ipython:: python\n\n    Comparison operations and arithmetic operations both broadcast.\n   df == arr[[0], :]\n   df + arr[[0], :]\n\n.. ipython:: python\n\n    Comparison operations and arithmetic operations both broadcast.\n   df == (1, 2)\n   df + (1, 2)\n\n.. code-block:: ipython\n\n    Comparison operations and arithmetic operations both raise ValueError.\n   In [6]: df == (1, 2, 3)\n   ...\n   ValueError: Unable to coerce to Series, length must be 2: given 3\n\n   In [7]: df + (1, 2, 3)\n   ...\n   ValueError: Unable to coerce to Series, length must be 2: given 3\n\n.. _whatsnew_0240.api.dataframe_arithmetic_broadcasting:\n\nDataFrame arithmetic operations broadcasting changes\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n:class:`DataFrame` arithmetic operations when operating with 2-dimensional\n``np.ndarray`` objects now broadcast in the same way as ``np.ndarray``\nbroadcast.  (:issue:`23000`)\n\n.. ipython:: python\n\n   arr = np.arange(6).reshape(3, 2)\n   df = pd.DataFrame(arr)\n   df\n\n*Previous behavior*:\n\n.. code-block:: ipython\n\n   In [5]: df + arr[[0], :]    1 row, 2 columns\n   ...\n   ValueError: Unable to coerce to DataFrame, shape must be (3, 2): given (1, 2)\n   In [6]: df + arr[:, [1]]    1 column, 3 rows\n   ...\n   ValueError: Unable to coerce to DataFrame, shape must be (3, 2): given (3, 1)\n\n*New behavior*:\n\n.. ipython:: python\n\n   df + arr[[0], :]    1 row, 2 columns\n   df + arr[:, [1]]    1 column, 3 rows\n\n.. _whatsnew_0240.api.incompatibilities:\n\nSeries and Index data-dtype incompatibilities\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n``Series`` and ``Index`` constructors now raise when the\ndata is incompatible with a passed ``dtype=`` (:issue:`15832`)\n\n*Previous behavior*:\n\n.. code-block:: ipython\n\n    In [4]: pd.Series([-1], dtype=\"uint64\")\n    Out [4]:\n    0    18446744073709551615\n    dtype: uint64\n\n*New behavior*:\n\n.. code-block:: ipython\n\n    In [4]: pd.Series([-1], dtype=\"uint64\")\n    Out [4]:\n    ...\n    OverflowError: Trying to coerce negative values to unsigned integers\n\n.. _whatsnew_0240.api.concat_categorical:\n\nConcatenation changes\n^^^^^^^^^^^^^^^^^^^^^\n\nCalling :func:`pandas.concat` on a ``Categorical`` of ints with NA values now\ncauses them to be processed as objects when concatenating with anything\nother than another ``Categorical`` of ints (:issue:`19214`)\n\n.. ipython:: python\n\n    s = pd.Series([0, 1, np.nan])\n    c = pd.Series([0, 1, np.nan], dtype=\"category\")\n\n*Previous behavior*\n\n.. code-block:: ipython\n\n    In [3]: pd.concat([s, c])\n    Out[3]:\n    0    0.0\n    1    1.0\n    2    NaN\n    0    0.0\n    1    1.0\n    2    NaN\n    dtype: float64\n\n*New behavior*\n\n.. ipython:: python\n\n    pd.concat([s, c])\n\nDatetimelike API changes\n^^^^^^^^^^^^^^^^^^^^^^^^\n\n- For :class:`DatetimeIndex` and :class:`TimedeltaIndex` with non-``None`` ``freq`` attribute, addition or subtraction of integer-dtyped array or ``Index`` will return an object of the same class (:issue:`19959`)\n- :class:`DateOffset` objects are now immutable. Attempting to alter one of these will now raise ``AttributeError`` (:issue:`21341`)\n- :class:`PeriodIndex` subtraction of another ``PeriodIndex`` will now return an object-dtype :class:`Index` of :class:`DateOffset` objects instead of raising a ``TypeError`` (:issue:`20049`)\n- :func:`cut` and :func:`qcut` now returns a :class:`DatetimeIndex` or :class:`TimedeltaIndex` bins when the input is datetime or timedelta dtype respectively and ``retbins=True`` (:issue:`19891`)\n- :meth:`DatetimeIndex.to_period` and :meth:`Timestamp.to_period` will issue a warning when timezone information will be lost (:issue:`21333`)\n- :meth:`PeriodIndex.tz_convert` and :meth:`PeriodIndex.tz_localize` have been removed (:issue:`21781`)\n\n.. _whatsnew_0240.api.other:\n\nOther API changes\n^^^^^^^^^^^^^^^^^\n\n- A newly constructed empty :class:`DataFrame` with integer as the ``dtype`` will now only be cast to ``float64`` if ``index`` is specified (:issue:`22858`)\n- :meth:`Series.str.cat` will now raise if ``others`` is a ``set`` (:issue:`23009`)\n- Passing scalar values to :class:`DatetimeIndex` or :class:`TimedeltaIndex` will now raise ``TypeError`` instead of ``ValueError`` (:issue:`23539`)\n- ``max_rows`` and ``max_cols`` parameters removed from :class:`HTMLFormatter` since truncation is handled by :class:`DataFrameFormatter` (:issue:`23818`)\n- :func:`read_csv` will now raise a ``ValueError`` if a column with missing values is declared as having dtype ``bool`` (:issue:`20591`)\n- The column order of the resultant :class:`DataFrame` from :meth:`MultiIndex.to_frame` is now guaranteed to match the :attr:`MultiIndex.names` order. (:issue:`22420`)\n- Incorrectly passing a :class:`DatetimeIndex` to :meth:`MultiIndex.from_tuples`, rather than a sequence of tuples, now raises a ``TypeError`` rather than a ``ValueError`` (:issue:`24024`)\n- :func:`pd.offsets.generate_range` argument ``time_rule`` has been removed; use ``offset`` instead (:issue:`24157`)\n- In 0.23.x, pandas would raise a ``ValueError`` on a merge of a numeric column (e.g. ``int`` dtyped column) and an ``object`` dtyped column (:issue:`9780`). We have re-enabled the ability to merge ``object`` and other dtypes; pandas will still raise on a merge between a numeric and an ``object`` dtyped column that is composed only of strings (:issue:`21681`)\n- Accessing a level of a ``MultiIndex`` with a duplicate name (e.g. in\n  :meth:`~MultiIndex.get_level_values`) now raises a ``ValueError`` instead of a ``KeyError`` (:issue:`21678`).\n- Invalid construction of ``IntervalDtype`` will now always raise a ``TypeError`` rather than a ``ValueError`` if the subdtype is invalid (:issue:`21185`)\n- Trying to reindex a ``DataFrame`` with a non unique ``MultiIndex`` now raises a ``ValueError`` instead of an ``Exception`` (:issue:`21770`)\n- :class:`Index` subtraction will attempt to operate element-wise instead of raising ``TypeError`` (:issue:`19369`)\n- :class:`pandas.io.formats.style.Styler` supports a ``number-format`` property when using :meth:`~pandas.io.formats.style.Styler.to_excel` (:issue:`22015`)\n- :meth:`DataFrame.corr` and :meth:`Series.corr` now raise a ``ValueError`` along with a helpful error message instead of a ``KeyError`` when supplied with an invalid method (:issue:`22298`)\n- :meth:`shift` will now always return a copy, instead of the previous behaviour of returning self when shifting by 0 (:issue:`22397`)\n- :meth:`DataFrame.set_index` now gives a better (and less frequent) KeyError, raises a ``ValueError`` for incorrect types,\n  and will not fail on duplicate column names with ``drop=True``. (:issue:`22484`)\n- Slicing a single row of a DataFrame with multiple ExtensionArrays of the same type now preserves the dtype, rather than coercing to object (:issue:`22784`)\n- :class:`DateOffset` attribute ``_cacheable`` and method ``_should_cache`` have been removed (:issue:`23118`)\n- :meth:`Series.searchsorted`, when supplied a scalar value to search for, now returns a scalar instead of an array (:issue:`23801`).\n- :meth:`Categorical.searchsorted`, when supplied a scalar value to search for, now returns a scalar instead of an array (:issue:`23466`).\n- :meth:`Categorical.searchsorted` now raises a ``KeyError`` rather that a ``ValueError``, if a searched for key is not found in its categories (:issue:`23466`).\n- :meth:`Index.hasnans` and :meth:`Series.hasnans` now always return a python boolean. Previously, a python or a numpy boolean could be returned, depending on circumstances (:issue:`23294`).\n- The order of the arguments of :func:`DataFrame.to_html` and :func:`DataFrame.to_string` is rearranged to be consistent with each other. (:issue:`23614`)\n- :meth:`CategoricalIndex.reindex` now raises a ``ValueError`` if the target index is non-unique and not equal to the current index. It previously only raised if the target index was not of a categorical dtype (:issue:`23963`).\n- :func:`Series.to_list` and :func:`Index.to_list` are now aliases of ``Series.tolist`` respectively ``Index.tolist`` (:issue:`8826`)\n- The result of ``SparseSeries.unstack`` is now a :class:`DataFrame` with sparse values, rather than a :class:`SparseDataFrame` (:issue:`24372`).\n- :class:`DatetimeIndex` and :class:`TimedeltaIndex` no longer ignore the dtype precision. Passing a non-nanosecond resolution dtype will raise a ``ValueError`` (:issue:`24753`)\n\n\n.. _whatsnew_0240.api.extension:\n\nExtension type changes\n~~~~~~~~~~~~~~~~~~~~~~\n\n**Equality and hashability**\n\npandas now requires that extension dtypes be hashable (i.e. the respective\n``ExtensionDtype`` objects; hashability is not a requirement for the values\nof the corresponding ``ExtensionArray``). The base class implements\na default ``__eq__`` and ``__hash__``. If you have a parametrized dtype, you should\nupdate the ``ExtensionDtype._metadata`` tuple to match the signature of your\n``__init__`` method. See :class:`pandas.api.extensions.ExtensionDtype` for more (:issue:`22476`).\n\n**New and changed methods**\n\n- :meth:`~pandas.api.types.ExtensionArray.dropna` has been added (:issue:`21185`)\n- :meth:`~pandas.api.types.ExtensionArray.repeat` has been added (:issue:`24349`)\n- The ``ExtensionArray`` constructor, ``_from_sequence`` now take the keyword arg ``copy=False`` (:issue:`21185`)\n- :meth:`pandas.api.extensions.ExtensionArray.shift` added as part of the basic ``ExtensionArray`` interface (:issue:`22387`).\n- :meth:`~pandas.api.types.ExtensionArray.searchsorted` has been added (:issue:`24350`)\n- Support for reduction operations such as ``sum``, ``mean`` via opt-in base class method override (:issue:`22762`)\n- :func:`ExtensionArray.isna` is allowed to return an ``ExtensionArray`` (:issue:`22325`).\n\n**Dtype changes**\n\n- ``ExtensionDtype`` has gained the ability to instantiate from string dtypes, e.g. ``decimal`` would instantiate a registered ``DecimalDtype``; furthermore\n  the ``ExtensionDtype`` has gained the method ``construct_array_type`` (:issue:`21185`)\n- Added ``ExtensionDtype._is_numeric`` for controlling whether an extension dtype is considered numeric (:issue:`22290`).\n- Added :meth:`pandas.api.types.register_extension_dtype` to register an extension type with pandas (:issue:`22664`)\n- Updated the ``.type`` attribute for ``PeriodDtype``, ``DatetimeTZDtype``, and ``IntervalDtype`` to be instances of the dtype (``Period``, ``Timestamp``, and ``Interval`` respectively) (:issue:`22938`)\n\n.. _whatsnew_0240.enhancements.extension_array_operators:\n\n**Operator support**\n\nA ``Series`` based on an ``ExtensionArray`` now supports arithmetic and comparison\noperators (:issue:`19577`). There are two approaches for providing operator support for an ``ExtensionArray``:\n\n1. Define each of the operators on your ``ExtensionArray`` subclass.\n2. Use an operator implementation from pandas that depends on operators that are already defined\n   on the underlying elements (scalars) of the ``ExtensionArray``.\n\nSee the :ref:`ExtensionArray Operator Support\n<extending.extension.operator>` documentation section for details on both\nways of adding operator support.\n\n**Other changes**\n\n- A default repr for :class:`pandas.api.extensions.ExtensionArray` is now provided (:issue:`23601`).\n- :meth:`ExtensionArray._formatting_values` is deprecated. Use :attr:`ExtensionArray._formatter` instead. (:issue:`23601`)\n- An ``ExtensionArray`` with a boolean dtype now works correctly as a boolean indexer. :meth:`pandas.api.types.is_bool_dtype` now properly considers them boolean (:issue:`22326`)\n\n**Bug fixes**\n\n- Bug in :meth:`Series.get` for ``Series`` using ``ExtensionArray`` and integer index (:issue:`21257`)\n- :meth:`~Series.shift` now dispatches to :meth:`ExtensionArray.shift` (:issue:`22386`)\n- :meth:`Series.combine()` works correctly with :class:`~pandas.api.extensions.ExtensionArray` inside of :class:`Series` (:issue:`20825`)\n- :meth:`Series.combine()` with scalar argument now works for any function type (:issue:`21248`)\n- :meth:`Series.astype` and :meth:`DataFrame.astype` now dispatch to :meth:`ExtensionArray.astype` (:issue:`21185`).\n- Slicing a single row of a ``DataFrame`` with multiple ExtensionArrays of the same type now preserves the dtype, rather than coercing to object (:issue:`22784`)\n- Bug when concatenating multiple ``Series`` with different extension dtypes not casting to object dtype (:issue:`22994`)\n- Series backed by an ``ExtensionArray`` now work with :func:`util.hash_pandas_object` (:issue:`23066`)\n- :meth:`DataFrame.stack` no longer converts to object dtype for DataFrames where each column has the same extension dtype. The output Series will have the same dtype as the columns (:issue:`23077`).\n- :meth:`Series.unstack` and :meth:`DataFrame.unstack` no longer convert extension arrays to object-dtype ndarrays. Each column in the output ``DataFrame`` will now have the same dtype as the input (:issue:`23077`).\n- Bug when grouping :meth:`Dataframe.groupby()` and aggregating on ``ExtensionArray`` it was not returning the actual ``ExtensionArray`` dtype (:issue:`23227`).\n- Bug in :func:`pandas.merge` when merging on an extension array-backed column (:issue:`23020`).\n\n\n.. _whatsnew_0240.deprecations:\n\nDeprecations\n~~~~~~~~~~~~\n\n- :attr:`MultiIndex.labels` has been deprecated and replaced by :attr:`MultiIndex.codes`.\n  The functionality is unchanged. The new name better reflects the natures of\n  these codes and makes the ``MultiIndex`` API more similar to the API for :class:`CategoricalIndex` (:issue:`13443`).\n  As a consequence, other uses of the name ``labels`` in ``MultiIndex`` have also been deprecated and replaced with ``codes``:\n\n  - You should initialize a ``MultiIndex`` instance using a parameter named ``codes`` rather than ``labels``.\n  - ``MultiIndex.set_labels`` has been deprecated in favor of :meth:`MultiIndex.set_codes`.\n  - For method :meth:`MultiIndex.copy`, the ``labels`` parameter has been deprecated and replaced by a ``codes`` parameter.\n- :meth:`DataFrame.to_stata`, :meth:`read_stata`, :class:`StataReader` and :class:`StataWriter` have deprecated the ``encoding`` argument. The encoding of a Stata dta file is determined by the file type and cannot be changed (:issue:`21244`)\n- :meth:`MultiIndex.to_hierarchical` is deprecated and will be removed in a future version (:issue:`21613`)\n- :meth:`Series.ptp` is deprecated. Use ``numpy.ptp`` instead (:issue:`21614`)\n- :meth:`Series.compress` is deprecated. Use ``Series[condition]`` instead (:issue:`18262`)\n- The signature of :meth:`Series.to_csv` has been uniformed to that of :meth:`DataFrame.to_csv`: the name of the first argument is now ``path_or_buf``, the order of subsequent arguments has changed, the ``header`` argument now defaults to ``True``. (:issue:`19715`)\n- :meth:`Categorical.from_codes` has deprecated providing float values for the ``codes`` argument. (:issue:`21767`)\n- :func:`pandas.read_table` is deprecated. Instead, use :func:`read_csv` passing ``sep='\\t'`` if necessary. This deprecation has been removed in 0.25.0. (:issue:`21948`)\n- :meth:`Series.str.cat` has deprecated using arbitrary list-likes *within* list-likes. A list-like container may still contain\n  many ``Series``, ``Index`` or 1-dimensional ``np.ndarray``, or alternatively, only scalar values. (:issue:`21950`)\n- :meth:`FrozenNDArray.searchsorted` has deprecated the ``v`` parameter in favor of ``value`` (:issue:`14645`)\n- :func:`DatetimeIndex.shift` and :func:`PeriodIndex.shift` now accept ``periods`` argument instead of ``n`` for consistency with :func:`Index.shift` and :func:`Series.shift`. Using ``n`` throws a deprecation warning (:issue:`22458`, :issue:`22912`)\n- The ``fastpath`` keyword of the different Index constructors is deprecated (:issue:`23110`).\n- :meth:`Timestamp.tz_localize`, :meth:`DatetimeIndex.tz_localize`, and :meth:`Series.tz_localize` have deprecated the ``errors`` argument in favor of the ``nonexistent`` argument (:issue:`8917`)\n- The class ``FrozenNDArray`` has been deprecated. When unpickling, ``FrozenNDArray`` will be unpickled to ``np.ndarray`` once this class is removed (:issue:`9031`)\n- The methods :meth:`DataFrame.update` and :meth:`Panel.update` have deprecated the ``raise_conflict=False|True`` keyword in favor of ``errors='ignore'|'raise'`` (:issue:`23585`)\n- The methods :meth:`Series.str.partition` and :meth:`Series.str.rpartition` have deprecated the ``pat`` keyword in favor of ``sep`` (:issue:`22676`)\n- Deprecated the ``nthreads`` keyword of :func:`pandas.read_feather` in favor of ``use_threads`` to reflect the changes in ``pyarrow>=0.11.0``. (:issue:`23053`)\n- :func:`pandas.read_excel` has deprecated accepting ``usecols`` as an integer. Please pass in a list of ints from 0 to ``usecols`` inclusive instead (:issue:`23527`)\n- Constructing a :class:`TimedeltaIndex` from data with ``datetime64``-dtyped data is deprecated, will raise ``TypeError`` in a future version (:issue:`23539`)\n- Constructing a :class:`DatetimeIndex` from data with ``timedelta64``-dtyped data is deprecated, will raise ``TypeError`` in a future version (:issue:`23675`)\n- The ``keep_tz=False`` option (the default) of the ``keep_tz`` keyword of\n  :meth:`DatetimeIndex.to_series` is deprecated (:issue:`17832`).\n- Timezone converting a tz-aware ``datetime.datetime`` or :class:`Timestamp` with :class:`Timestamp` and the ``tz`` argument is now deprecated. Instead, use :meth:`Timestamp.tz_convert` (:issue:`23579`)\n- :func:`pandas.api.types.is_period` is deprecated in favor of ``pandas.api.types.is_period_dtype`` (:issue:`23917`)\n- :func:`pandas.api.types.is_datetimetz` is deprecated in favor of ``pandas.api.types.is_datetime64tz`` (:issue:`23917`)\n- Creating a :class:`TimedeltaIndex`, :class:`DatetimeIndex`, or :class:`PeriodIndex` by passing range arguments ``start``, ``end``, and ``periods`` is deprecated in favor of :func:`timedelta_range`, :func:`date_range`, or :func:`period_range` (:issue:`23919`)\n- Passing a string alias like ``'datetime64[ns, UTC]'`` as the ``unit`` parameter to :class:`DatetimeTZDtype` is deprecated. Use :class:`DatetimeTZDtype.construct_from_string` instead (:issue:`23990`).\n- The ``skipna`` parameter of :meth:`~pandas.api.types.infer_dtype` will switch to ``True`` by default in a future version of pandas (:issue:`17066`, :issue:`24050`)\n- In :meth:`Series.where` with Categorical data, providing an ``other`` that is not present in the categories is deprecated. Convert the categorical to a different dtype or add the ``other`` to the categories first (:issue:`24077`).\n- :meth:`Series.clip_lower`, :meth:`Series.clip_upper`, :meth:`DataFrame.clip_lower` and :meth:`DataFrame.clip_upper` are deprecated and will be removed in a future version. Use ``Series.clip(lower=threshold)``, ``Series.clip(upper=threshold)`` and the equivalent ``DataFrame`` methods (:issue:`24203`)\n- :meth:`Series.nonzero` is deprecated and will be removed in a future version (:issue:`18262`)\n- Passing an integer to :meth:`Series.fillna` and :meth:`DataFrame.fillna` with ``timedelta64[ns]`` dtypes is deprecated, will raise ``TypeError`` in a future version.  Use ``obj.fillna(pd.Timedelta(...))`` instead (:issue:`24694`)\n- ``Series.cat.categorical``, ``Series.cat.name`` and ``Series.cat.index`` have been deprecated. Use the attributes on ``Series.cat`` or ``Series`` directly. (:issue:`24751`).\n- Passing a dtype without a precision like ``np.dtype('datetime64')`` or ``timedelta64`` to :class:`Index`, :class:`DatetimeIndex` and :class:`TimedeltaIndex` is now deprecated. Use the nanosecond-precision dtype instead (:issue:`24753`).\n\n.. _whatsnew_0240.deprecations.datetimelike_int_ops:\n\nInteger addition/subtraction with datetimes and timedeltas is deprecated\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nIn the past, users could\u00e2\u0080\u0094in some cases\u00e2\u0080\u0094add or subtract integers or integer-dtype\narrays from :class:`Timestamp`, :class:`DatetimeIndex` and :class:`TimedeltaIndex`.\n\nThis usage is now deprecated.  Instead add or subtract integer multiples of\nthe object's ``freq`` attribute (:issue:`21939`, :issue:`23878`).\n\n*Previous behavior*:\n\n.. code-block:: ipython\n\n    In [5]: ts = pd.Timestamp('1994-05-06 12:15:16', freq=pd.offsets.Hour())\n    In [6]: ts + 2\n    Out[6]: Timestamp('1994-05-06 14:15:16', freq='H')\n\n    In [7]: tdi = pd.timedelta_range('1D', periods=2)\n    In [8]: tdi - np.array([2, 1])\n    Out[8]: TimedeltaIndex(['-1 days', '1 days'], dtype='timedelta64[ns]', freq=None)\n\n    In [9]: dti = pd.date_range('2001-01-01', periods=2, freq='7D')\n    In [10]: dti + pd.Index([1, 2])\n    Out[10]: DatetimeIndex(['2001-01-08', '2001-01-22'], dtype='datetime64[ns]', freq=None)\n\n*New behavior*:\n\n.. code-block:: ipython\n\n    In [108]: ts = pd.Timestamp('1994-05-06 12:15:16', freq=pd.offsets.Hour())\n\n    In[109]: ts + 2 * ts.freq\n    Out[109]: Timestamp('1994-05-06 14:15:16', freq='H')\n\n    In [110]: tdi = pd.timedelta_range('1D', periods=2)\n\n    In [111]: tdi - np.array([2 * tdi.freq, 1 * tdi.freq])\n    Out[111]: TimedeltaIndex(['-1 days', '1 days'], dtype='timedelta64[ns]', freq=None)\n\n    In [112]: dti = pd.date_range('2001-01-01', periods=2, freq='7D')\n\n    In [113]: dti + pd.Index([1 * dti.freq, 2 * dti.freq])\n    Out[113]: DatetimeIndex(['2001-01-08', '2001-01-22'], dtype='datetime64[ns]', freq=None)\n\n\n.. _whatsnew_0240.deprecations.integer_tz:\n\nPassing integer data and a timezone to DatetimeIndex\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nThe behavior of :class:`DatetimeIndex` when passed integer data and\na timezone is changing in a future version of pandas. Previously, these\nwere interpreted as wall times in the desired timezone. In the future,\nthese will be interpreted as wall times in UTC, which are then converted\nto the desired timezone (:issue:`24559`).\n\nThe default behavior remains the same, but issues a warning:\n\n.. code-block:: ipython\n\n   In [3]: pd.DatetimeIndex([946684800000000000], tz=\"US/Central\")\n   /bin/ipython:1: FutureWarning:\n       Passing integer-dtype data and a timezone to DatetimeIndex. Integer values\n       will be interpreted differently in a future version of pandas. Previously,\n       these were viewed as datetime64[ns] values representing the wall time\n       *in the specified timezone*. In the future, these will be viewed as\n       datetime64[ns] values representing the wall time *in UTC*. This is similar\n       to a nanosecond-precision UNIX epoch. To accept the future behavior, use\n\n           pd.to_datetime(integer_data, utc=True).tz_convert(tz)\n\n       To keep the previous behavior, use\n\n           pd.to_datetime(integer_data).tz_localize(tz)\n\n    !/bin/python3\n    Out[3]: DatetimeIndex(['2000-01-01 00:00:00-06:00'], dtype='datetime64[ns, US/Central]', freq=None)\n\nAs the warning message explains, opt in to the future behavior by specifying that\nthe integer values are UTC, and then converting to the final timezone:\n\n.. ipython:: python\n\n   pd.to_datetime([946684800000000000], utc=True).tz_convert('US/Central')\n\nThe old behavior can be retained with by localizing directly to the final timezone:\n\n.. ipython:: python\n\n   pd.to_datetime([946684800000000000]).tz_localize('US/Central')\n\n.. _whatsnew_0240.deprecations.tz_aware_array:\n\nConverting timezone-aware Series and Index to NumPy arrays\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nThe conversion from a :class:`Series` or :class:`Index` with timezone-aware\ndatetime data will change to preserve timezones by default (:issue:`23569`).\n\nNumPy doesn't have a dedicated dtype for timezone-aware datetimes.\nIn the past, converting a :class:`Series` or :class:`DatetimeIndex` with\ntimezone-aware datatimes would convert to a NumPy array by\n\n1. converting the tz-aware data to UTC\n2. dropping the timezone-info\n3. returning a :class:`numpy.ndarray` with ``datetime64[ns]`` dtype\n\nFuture versions of pandas will preserve the timezone information by returning an\nobject-dtype NumPy array where each value is a :class:`Timestamp` with the correct\ntimezone attached\n\n.. ipython:: python\n\n   ser = pd.Series(pd.date_range('2000', periods=2, tz=\"CET\"))\n   ser\n\nThe default behavior remains the same, but issues a warning\n\n.. code-block:: python\n\n   In [8]: np.asarray(ser)\n   /bin/ipython:1: FutureWarning: Converting timezone-aware DatetimeArray to timezone-naive\n         ndarray with 'datetime64[ns]' dtype. In the future, this will return an ndarray\n         with 'object' dtype where each element is a 'pandas.Timestamp' with the correct 'tz'.\n\n           To accept the future behavior, pass 'dtype=object'.\n           To keep the old behavior, pass 'dtype=\"datetime64[ns]\"'.\n     !/bin/python3\n   Out[8]:\n   array(['1999-12-31T23:00:00.000000000', '2000-01-01T23:00:00.000000000'],\n         dtype='datetime64[ns]')\n\nThe previous or future behavior can be obtained, without any warnings, by specifying\nthe ``dtype``\n\n*Previous behavior*\n\n.. ipython:: python\n\n   np.asarray(ser, dtype='datetime64[ns]')\n\n*Future behavior*\n\n.. ipython:: python\n\n    New behavior\n   np.asarray(ser, dtype=object)\n\n\nOr by using :meth:`Series.to_numpy`\n\n.. ipython:: python\n\n   ser.to_numpy()\n   ser.to_numpy(dtype=\"datetime64[ns]\")\n\nAll the above applies to a :class:`DatetimeIndex` with tz-aware values as well.\n\n.. _whatsnew_0240.prior_deprecations:\n\nRemoval of prior version deprecations/changes\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\n- The ``LongPanel`` and ``WidePanel`` classes have been removed (:issue:`10892`)\n- :meth:`Series.repeat` has renamed the ``reps`` argument to ``repeats`` (:issue:`14645`)\n- Several private functions were removed from the (non-public) module ``pandas.core.common`` (:issue:`22001`)\n- Removal of the previously deprecated module ``pandas.core.datetools`` (:issue:`14105`, :issue:`14094`)\n- Strings passed into :meth:`DataFrame.groupby` that refer to both column and index levels will raise a ``ValueError`` (:issue:`14432`)\n- :meth:`Index.repeat` and :meth:`MultiIndex.repeat` have renamed the ``n`` argument to ``repeats`` (:issue:`14645`)\n- The ``Series`` constructor and ``.astype`` method will now raise a ``ValueError`` if timestamp dtypes are passed in without a unit (e.g. ``np.datetime64``) for the ``dtype`` parameter (:issue:`15987`)\n- Removal of the previously deprecated ``as_indexer`` keyword completely from ``str.match()`` (:issue:`22356`, :issue:`6581`)\n- The modules ``pandas.types``, ``pandas.computation``, and ``pandas.util.decorators`` have been removed (:issue:`16157`, :issue:`16250`)\n- Removed the ``pandas.formats.style`` shim for :class:`pandas.io.formats.style.Styler` (:issue:`16059`)\n- ``pandas.pnow``, ``pandas.match``, ``pandas.groupby``, ``pd.get_store``, ``pd.Expr``, and ``pd.Term`` have been removed (:issue:`15538`, :issue:`15940`)\n- :meth:`Categorical.searchsorted` and :meth:`Series.searchsorted` have renamed the ``v`` argument to ``value`` (:issue:`14645`)\n- ``pandas.parser``, ``pandas.lib``, and ``pandas.tslib`` have been removed (:issue:`15537`)\n- :meth:`Index.searchsorted` have renamed the ``key`` argument to ``value`` (:issue:`14645`)\n- ``DataFrame.consolidate`` and ``Series.consolidate`` have been removed (:issue:`15501`)\n- Removal of the previously deprecated module ``pandas.json`` (:issue:`19944`)\n- The module ``pandas.tools`` has been removed (:issue:`15358`, :issue:`16005`)\n- :meth:`SparseArray.get_values` and :meth:`SparseArray.to_dense` have dropped the ``fill`` parameter (:issue:`14686`)\n- ``DataFrame.sortlevel`` and ``Series.sortlevel`` have been removed (:issue:`15099`)\n- :meth:`SparseSeries.to_dense` has dropped the ``sparse_only`` parameter (:issue:`14686`)\n- :meth:`DataFrame.astype` and :meth:`Series.astype` have renamed the ``raise_on_error`` argument to ``errors`` (:issue:`14967`)\n- ``is_sequence``, ``is_any_int_dtype``, and ``is_floating_dtype`` have been removed from ``pandas.api.types`` (:issue:`16163`, :issue:`16189`)\n\n.. _whatsnew_0240.performance:\n\nPerformance improvements\n~~~~~~~~~~~~~~~~~~~~~~~~\n\n- Slicing Series and DataFrames with an monotonically increasing :class:`CategoricalIndex`\n  is now very fast and has speed comparable to slicing with an ``Int64Index``.\n  The speed increase is both when indexing by label (using .loc) and position(.iloc) (:issue:`20395`)\n  Slicing a monotonically increasing :class:`CategoricalIndex` itself (i.e. ``ci[1000:2000]``)\n  shows similar speed improvements as above (:issue:`21659`)\n- Improved performance of :meth:`CategoricalIndex.equals` when comparing to another :class:`CategoricalIndex` (:issue:`24023`)\n- Improved performance of :func:`Series.describe` in case of numeric dtpyes (:issue:`21274`)\n- Improved performance of :func:`.GroupBy.rank` when dealing with tied rankings (:issue:`21237`)\n- Improved performance of :func:`DataFrame.set_index` with columns consisting of :class:`Period` objects (:issue:`21582`, :issue:`21606`)\n- Improved performance of :meth:`Series.at` and :meth:`Index.get_value` for Extension Arrays values (e.g. :class:`Categorical`) (:issue:`24204`)\n- Improved performance of membership checks in :class:`Categorical` and :class:`CategoricalIndex`\n  (i.e. ``x in cat``-style checks are much faster). :meth:`CategoricalIndex.contains`\n  is likewise much faster (:issue:`21369`, :issue:`21508`)\n- Improved performance of :meth:`HDFStore.groups` (and dependent functions like\n  :meth:`HDFStore.keys`.  (i.e. ``x in store`` checks are much faster)\n  (:issue:`21372`)\n- Improved the performance of :func:`pandas.get_dummies` with ``sparse=True`` (:issue:`21997`)\n- Improved performance of :func:`IndexEngine.get_indexer_non_unique` for sorted, non-unique indexes (:issue:`9466`)\n- Improved performance of :func:`PeriodIndex.unique` (:issue:`23083`)\n- Improved performance of :func:`concat` for ``Series`` objects (:issue:`23404`)\n- Improved performance of :meth:`DatetimeIndex.normalize` and :meth:`Timestamp.normalize` for timezone naive or UTC datetimes (:issue:`23634`)\n- Improved performance of :meth:`DatetimeIndex.tz_localize` and various ``DatetimeIndex`` attributes with dateutil UTC timezone (:issue:`23772`)\n- Fixed a performance regression on Windows with Python 3.7 of :func:`read_csv` (:issue:`23516`)\n- Improved performance of :class:`Categorical` constructor for ``Series`` objects (:issue:`23814`)\n- Improved performance of :meth:`~DataFrame.where` for Categorical data (:issue:`24077`)\n- Improved performance of iterating over a :class:`Series`. Using :meth:`DataFrame.itertuples` now creates iterators\n  without internally allocating lists of all elements (:issue:`20783`)\n- Improved performance of :class:`Period` constructor, additionally benefitting ``PeriodArray`` and ``PeriodIndex`` creation (:issue:`24084`, :issue:`24118`)\n- Improved performance of tz-aware :class:`DatetimeArray` binary operations (:issue:`24491`)\n\n.. _whatsnew_0240.bug_fixes:\n\nBug fixes\n~~~~~~~~~\n\nCategorical\n^^^^^^^^^^^\n\n- Bug in :meth:`Categorical.from_codes` where ``NaN`` values in ``codes`` were silently converted to ``0`` (:issue:`21767`). In the future this will raise a ``ValueError``. Also changes the behavior of ``.from_codes([1.1, 2.0])``.\n- Bug in :meth:`Categorical.sort_values` where ``NaN`` values were always positioned in front regardless of ``na_position`` value. (:issue:`22556`).\n- Bug when indexing with a boolean-valued ``Categorical``. Now a boolean-valued ``Categorical`` is treated as a boolean mask (:issue:`22665`)\n- Constructing a :class:`CategoricalIndex` with empty values and boolean categories was raising a ``ValueError`` after a change to dtype coercion (:issue:`22702`).\n- Bug in :meth:`Categorical.take` with a user-provided ``fill_value`` not encoding the ``fill_value``, which could result in a ``ValueError``, incorrect results, or a segmentation fault (:issue:`23296`).\n- In :meth:`Series.unstack`, specifying a ``fill_value`` not present in the categories now raises a ``TypeError`` rather than ignoring the ``fill_value`` (:issue:`23284`)\n- Bug when resampling :meth:`DataFrame.resample()` and aggregating on categorical data, the categorical dtype was getting lost. (:issue:`23227`)\n- Bug in many methods of the ``.str``-accessor, which always failed on calling the ``CategoricalIndex.str`` constructor (:issue:`23555`, :issue:`23556`)\n- Bug in :meth:`Series.where` losing the categorical dtype for categorical data (:issue:`24077`)\n- Bug in :meth:`Categorical.apply` where ``NaN`` values could be handled unpredictably. They now remain unchanged (:issue:`24241`)\n- Bug in :class:`Categorical` comparison methods incorrectly raising ``ValueError`` when operating against a :class:`DataFrame` (:issue:`24630`)\n- Bug in :meth:`Categorical.set_categories` where setting fewer new categories with ``rename=True`` caused a segmentation fault (:issue:`24675`)\n\nDatetimelike\n^^^^^^^^^^^^\n\n- Fixed bug where two :class:`DateOffset` objects with different ``normalize`` attributes could evaluate as equal (:issue:`21404`)\n- Fixed bug where :meth:`Timestamp.resolution` incorrectly returned 1-microsecond ``timedelta`` instead of 1-nanosecond :class:`Timedelta` (:issue:`21336`, :issue:`21365`)\n- Bug in :func:`to_datetime` that did not consistently return an :class:`Index` when ``box=True`` was specified (:issue:`21864`)\n- Bug in :class:`DatetimeIndex` comparisons where string comparisons incorrectly raises ``TypeError`` (:issue:`22074`)\n- Bug in :class:`DatetimeIndex` comparisons when comparing against ``timedelta64[ns]`` dtyped arrays; in some cases ``TypeError`` was incorrectly raised, in others it incorrectly failed to raise (:issue:`22074`)\n- Bug in :class:`DatetimeIndex` comparisons when comparing against object-dtyped arrays (:issue:`22074`)\n- Bug in :class:`DataFrame` with ``datetime64[ns]`` dtype addition and subtraction with ``Timedelta``-like objects (:issue:`22005`, :issue:`22163`)\n- Bug in :class:`DataFrame` with ``datetime64[ns]`` dtype addition and subtraction with ``DateOffset`` objects returning an ``object`` dtype instead of ``datetime64[ns]`` dtype (:issue:`21610`, :issue:`22163`)\n- Bug in :class:`DataFrame` with ``datetime64[ns]`` dtype comparing against ``NaT`` incorrectly (:issue:`22242`, :issue:`22163`)\n- Bug in :class:`DataFrame` with ``datetime64[ns]`` dtype subtracting ``Timestamp``-like object incorrectly returned ``datetime64[ns]`` dtype instead of ``timedelta64[ns]`` dtype (:issue:`8554`, :issue:`22163`)\n- Bug in :class:`DataFrame` with ``datetime64[ns]`` dtype subtracting ``np.datetime64`` object with non-nanosecond unit failing to convert to nanoseconds (:issue:`18874`, :issue:`22163`)\n- Bug in :class:`DataFrame` comparisons against ``Timestamp``-like objects failing to raise ``TypeError`` for inequality checks with mismatched types (:issue:`8932`, :issue:`22163`)\n- Bug in :class:`DataFrame` with mixed dtypes including ``datetime64[ns]`` incorrectly raising ``TypeError`` on equality comparisons (:issue:`13128`, :issue:`22163`)\n- Bug in :attr:`DataFrame.values` returning a :class:`DatetimeIndex` for a single-column ``DataFrame`` with tz-aware datetime values. Now a 2-D :class:`numpy.ndarray` of :class:`Timestamp` objects is returned (:issue:`24024`)\n- Bug in :meth:`DataFrame.eq` comparison against ``NaT`` incorrectly returning ``True`` or ``NaN`` (:issue:`15697`, :issue:`22163`)\n- Bug in :class:`DatetimeIndex` subtraction that incorrectly failed to raise ``OverflowError`` (:issue:`22492`, :issue:`22508`)\n- Bug in :class:`DatetimeIndex` incorrectly allowing indexing with ``Timedelta`` object (:issue:`20464`)\n- Bug in :class:`DatetimeIndex` where frequency was being set if original frequency was ``None`` (:issue:`22150`)\n- Bug in rounding methods of :class:`DatetimeIndex` (:meth:`~DatetimeIndex.round`, :meth:`~DatetimeIndex.ceil`, :meth:`~DatetimeIndex.floor`) and :class:`Timestamp` (:meth:`~Timestamp.round`, :meth:`~Timestamp.ceil`, :meth:`~Timestamp.floor`) could give rise to loss of precision (:issue:`22591`)\n- Bug in :func:`to_datetime` with an :class:`Index` argument that would drop the ``name`` from the result (:issue:`21697`)\n- Bug in :class:`PeriodIndex` where adding or subtracting a :class:`timedelta` or :class:`Tick` object produced incorrect results (:issue:`22988`)\n- Bug in the :class:`Series` repr with period-dtype data missing a space before the data (:issue:`23601`)\n- Bug in :func:`date_range` when decrementing a start date to a past end date by a negative frequency (:issue:`23270`)\n- Bug in :meth:`Series.min` which would return ``NaN`` instead of ``NaT`` when called on a series of ``NaT`` (:issue:`23282`)\n- Bug in :meth:`Series.combine_first` not properly aligning categoricals, so that missing values in ``self`` where not filled by valid values from ``other`` (:issue:`24147`)\n- Bug in :func:`DataFrame.combine` with datetimelike values raising a TypeError (:issue:`23079`)\n- Bug in :func:`date_range` with frequency of ``Day`` or higher where dates sufficiently far in the future could wrap around to the past instead of raising ``OutOfBoundsDatetime`` (:issue:`14187`)\n- Bug in :func:`period_range` ignoring the frequency of ``start`` and ``end`` when those are provided as :class:`Period` objects (:issue:`20535`).\n- Bug in :class:`PeriodIndex` with attribute ``freq.n`` greater than 1 where adding a :class:`DateOffset` object would return incorrect results (:issue:`23215`)\n- Bug in :class:`Series` that interpreted string indices as lists of characters when setting datetimelike values (:issue:`23451`)\n- Bug in :class:`DataFrame` when creating a new column from an ndarray of :class:`Timestamp` objects with timezones creating an object-dtype column, rather than datetime with timezone (:issue:`23932`)\n- Bug in :class:`Timestamp` constructor which would drop the frequency of an input :class:`Timestamp` (:issue:`22311`)\n- Bug in :class:`DatetimeIndex` where calling ``np.array(dtindex, dtype=object)`` would incorrectly return an array of ``long`` objects (:issue:`23524`)\n- Bug in :class:`Index` where passing a timezone-aware :class:`DatetimeIndex` and ``dtype=object`` would incorrectly raise a ``ValueError`` (:issue:`23524`)\n- Bug in :class:`Index` where calling ``np.array(dtindex, dtype=object)`` on a timezone-naive :class:`DatetimeIndex` would return an array of ``datetime`` objects instead of :class:`Timestamp` objects, potentially losing nanosecond portions of the timestamps (:issue:`23524`)\n- Bug in :class:`Categorical.__setitem__` not allowing setting with another ``Categorical`` when both are unordered and have the same categories, but in a different order (:issue:`24142`)\n- Bug in :func:`date_range` where using dates with millisecond resolution or higher could return incorrect values or the wrong number of values in the index (:issue:`24110`)\n- Bug in :class:`DatetimeIndex` where constructing a :class:`DatetimeIndex` from a :class:`Categorical` or :class:`CategoricalIndex` would incorrectly drop timezone information (:issue:`18664`)\n- Bug in :class:`DatetimeIndex` and :class:`TimedeltaIndex` where indexing with ``Ellipsis`` would incorrectly lose the index's ``freq`` attribute (:issue:`21282`)\n- Clarified error message produced when passing an incorrect ``freq`` argument to :class:`DatetimeIndex` with ``NaT`` as the first entry in the passed data (:issue:`11587`)\n- Bug in :func:`to_datetime` where ``box`` and ``utc`` arguments were ignored when passing a :class:`DataFrame` or ``dict`` of unit mappings (:issue:`23760`)\n- Bug in :attr:`Series.dt` where the cache would not update properly after an in-place operation (:issue:`24408`)\n- Bug in :class:`PeriodIndex` where comparisons against an array-like object with length 1 failed to raise ``ValueError`` (:issue:`23078`)\n- Bug in :meth:`DatetimeIndex.astype`, :meth:`PeriodIndex.astype` and :meth:`TimedeltaIndex.astype` ignoring the sign of the ``dtype`` for unsigned integer dtypes (:issue:`24405`).\n- Fixed bug in :meth:`Series.max` with ``datetime64[ns]``-dtype failing to return ``NaT`` when nulls are present and ``skipna=False`` is passed (:issue:`24265`)\n- Bug in :func:`to_datetime` where arrays of ``datetime`` objects containing both timezone-aware and timezone-naive ``datetimes`` would fail to raise ``ValueError`` (:issue:`24569`)\n- Bug in :func:`to_datetime` with invalid datetime format doesn't coerce input to ``NaT`` even if ``errors='coerce'`` (:issue:`24763`)\n\nTimedelta\n^^^^^^^^^\n- Bug in :class:`DataFrame` with ``timedelta64[ns]`` dtype division by ``Timedelta``-like scalar incorrectly returning ``timedelta64[ns]`` dtype instead of ``float64`` dtype (:issue:`20088`, :issue:`22163`)\n- Bug in adding a :class:`Index` with object dtype to a :class:`Series` with ``timedelta64[ns]`` dtype incorrectly raising (:issue:`22390`)\n- Bug in multiplying a :class:`Series` with numeric dtype against a ``timedelta`` object (:issue:`22390`)\n- Bug in :class:`Series` with numeric dtype when adding or subtracting an array or ``Series`` with ``timedelta64`` dtype (:issue:`22390`)\n- Bug in :class:`Index` with numeric dtype when multiplying or dividing an array with dtype ``timedelta64`` (:issue:`22390`)\n- Bug in :class:`TimedeltaIndex` incorrectly allowing indexing with ``Timestamp`` object (:issue:`20464`)\n- Fixed bug where subtracting :class:`Timedelta` from an object-dtyped array would raise ``TypeError`` (:issue:`21980`)\n- Fixed bug in adding a :class:`DataFrame` with all-`timedelta64[ns]` dtypes to a :class:`DataFrame` with all-integer dtypes returning incorrect results instead of raising ``TypeError`` (:issue:`22696`)\n- Bug in :class:`TimedeltaIndex` where adding a timezone-aware datetime scalar incorrectly returned a timezone-naive :class:`DatetimeIndex` (:issue:`23215`)\n- Bug in :class:`TimedeltaIndex` where adding ``np.timedelta64('NaT')`` incorrectly returned an all-``NaT`` :class:`DatetimeIndex` instead of an all-``NaT`` :class:`TimedeltaIndex` (:issue:`23215`)\n- Bug in :class:`Timedelta` and :func:`to_timedelta()` have inconsistencies in supported unit string (:issue:`21762`)\n- Bug in :class:`TimedeltaIndex` division where dividing by another :class:`TimedeltaIndex` raised ``TypeError`` instead of returning a :class:`Float64Index` (:issue:`23829`, :issue:`22631`)\n- Bug in :class:`TimedeltaIndex` comparison operations where comparing against non-``Timedelta``-like objects would raise ``TypeError`` instead of returning all-``False`` for ``__eq__`` and all-``True`` for ``__ne__`` (:issue:`24056`)\n- Bug in :class:`Timedelta` comparisons when comparing with a ``Tick`` object incorrectly raising ``TypeError`` (:issue:`24710`)\n\nTimezones\n^^^^^^^^^\n\n- Bug in :meth:`Index.shift` where an ``AssertionError`` would raise when shifting across DST (:issue:`8616`)\n- Bug in :class:`Timestamp` constructor where passing an invalid timezone offset designator (``Z``) would not raise a ``ValueError`` (:issue:`8910`)\n- Bug in :meth:`Timestamp.replace` where replacing at a DST boundary would retain an incorrect offset (:issue:`7825`)\n- Bug in :meth:`Series.replace` with ``datetime64[ns, tz]`` data when replacing ``NaT`` (:issue:`11792`)\n- Bug in :class:`Timestamp` when passing different string date formats with a timezone offset would produce different timezone offsets (:issue:`12064`)\n- Bug when comparing a tz-naive :class:`Timestamp` to a tz-aware :class:`DatetimeIndex` which would coerce the :class:`DatetimeIndex` to tz-naive (:issue:`12601`)\n- Bug in :meth:`Series.truncate` with a tz-aware :class:`DatetimeIndex` which would cause a core dump (:issue:`9243`)\n- Bug in :class:`Series` constructor which would coerce tz-aware and tz-naive :class:`Timestamp` to tz-aware (:issue:`13051`)\n- Bug in :class:`Index` with ``datetime64[ns, tz]`` dtype that did not localize integer data correctly (:issue:`20964`)\n- Bug in :class:`DatetimeIndex` where constructing with an integer and tz would not localize correctly (:issue:`12619`)\n- Fixed bug where :meth:`DataFrame.describe` and :meth:`Series.describe` on tz-aware datetimes did not show ``first`` and ``last`` result (:issue:`21328`)\n- Bug in :class:`DatetimeIndex` comparisons failing to raise ``TypeError`` when comparing timezone-aware ``DatetimeIndex`` against ``np.datetime64`` (:issue:`22074`)\n- Bug in ``DataFrame`` assignment with a timezone-aware scalar (:issue:`19843`)\n- Bug in :func:`DataFrame.asof` that raised a ``TypeError`` when attempting to compare tz-naive and tz-aware timestamps (:issue:`21194`)\n- Bug when constructing a :class:`DatetimeIndex` with :class:`Timestamp` constructed with the ``replace`` method across DST (:issue:`18785`)\n- Bug when setting a new value with :meth:`DataFrame.loc` with a :class:`DatetimeIndex` with a DST transition (:issue:`18308`, :issue:`20724`)\n- Bug in :meth:`Index.unique` that did not re-localize tz-aware dates correctly (:issue:`21737`)\n- Bug when indexing a :class:`Series` with a DST transition (:issue:`21846`)\n- Bug in :meth:`DataFrame.resample` and :meth:`Series.resample` where an ``AmbiguousTimeError`` or ``NonExistentTimeError`` would raise if a timezone aware timeseries ended on a DST transition (:issue:`19375`, :issue:`10117`)\n- Bug in :meth:`DataFrame.drop` and :meth:`Series.drop` when specifying a tz-aware Timestamp key to drop from a :class:`DatetimeIndex` with a DST transition (:issue:`21761`)\n- Bug in :class:`DatetimeIndex` constructor where ``NaT`` and ``dateutil.tz.tzlocal`` would raise an ``OutOfBoundsDatetime`` error (:issue:`23807`)\n- Bug in :meth:`DatetimeIndex.tz_localize` and :meth:`Timestamp.tz_localize` with ``dateutil.tz.tzlocal`` near a DST transition that would return an incorrectly localized datetime (:issue:`23807`)\n- Bug in :class:`Timestamp` constructor where a ``dateutil.tz.tzutc`` timezone passed with a ``datetime.datetime`` argument would be converted to a ``pytz.UTC`` timezone (:issue:`23807`)\n- Bug in :func:`to_datetime` where ``utc=True`` was not respected when specifying a ``unit`` and ``errors='ignore'`` (:issue:`23758`)\n- Bug in :func:`to_datetime` where ``utc=True`` was not respected when passing a :class:`Timestamp` (:issue:`24415`)\n- Bug in :meth:`DataFrame.any` returns wrong value when ``axis=1`` and the data is of datetimelike type (:issue:`23070`)\n- Bug in :meth:`DatetimeIndex.to_period` where a timezone aware index was converted to UTC first before creating :class:`PeriodIndex` (:issue:`22905`)\n- Bug in :meth:`DataFrame.tz_localize`, :meth:`DataFrame.tz_convert`, :meth:`Series.tz_localize`, and :meth:`Series.tz_convert` where ``copy=False`` would mutate the original argument inplace (:issue:`6326`)\n- Bug in :meth:`DataFrame.max` and :meth:`DataFrame.min` with ``axis=1`` where a :class:`Series` with ``NaN`` would be returned when all columns contained the same timezone (:issue:`10390`)\n\nOffsets\n^^^^^^^\n\n- Bug in :class:`FY5253` where date offsets could incorrectly raise an ``AssertionError`` in arithmetic operations (:issue:`14774`)\n- Bug in :class:`DateOffset` where keyword arguments ``week`` and ``milliseconds`` were accepted and ignored.  Passing these will now raise ``ValueError`` (:issue:`19398`)\n- Bug in adding :class:`DateOffset` with :class:`DataFrame` or :class:`PeriodIndex` incorrectly raising ``TypeError`` (:issue:`23215`)\n- Bug in comparing :class:`DateOffset` objects with non-DateOffset objects, particularly strings, raising ``ValueError`` instead of returning ``False`` for equality checks and ``True`` for not-equal checks (:issue:`23524`)\n\nNumeric\n^^^^^^^\n\n- Bug in :class:`Series` ``__rmatmul__`` doesn't support matrix vector multiplication (:issue:`21530`)\n- Bug in :func:`factorize` fails with read-only array (:issue:`12813`)\n- Fixed bug in :func:`unique` handled signed zeros inconsistently: for some inputs 0.0 and -0.0 were treated as equal and for some inputs as different. Now they are treated as equal for all inputs (:issue:`21866`)\n- Bug in :meth:`DataFrame.agg`, :meth:`DataFrame.transform` and :meth:`DataFrame.apply` where,\n  when supplied with a list of functions and ``axis=1`` (e.g. ``df.apply(['sum', 'mean'], axis=1)``),\n  a ``TypeError`` was wrongly raised. For all three methods such calculation are now done correctly. (:issue:`16679`).\n- Bug in :class:`Series` comparison against datetime-like scalars and arrays (:issue:`22074`)\n- Bug in :class:`DataFrame` multiplication between boolean dtype and integer returning ``object`` dtype instead of integer dtype (:issue:`22047`, :issue:`22163`)\n- Bug in :meth:`DataFrame.apply` where, when supplied with a string argument and additional positional or keyword arguments (e.g. ``df.apply('sum', min_count=1)``), a ``TypeError`` was wrongly raised (:issue:`22376`)\n- Bug in :meth:`DataFrame.astype` to extension dtype may raise ``AttributeError`` (:issue:`22578`)\n- Bug in :class:`DataFrame` with ``timedelta64[ns]`` dtype arithmetic operations with ``ndarray`` with integer dtype incorrectly treating the narray as ``timedelta64[ns]`` dtype (:issue:`23114`)\n- Bug in :meth:`Series.rpow` with object dtype ``NaN`` for ``1 ** NA`` instead of ``1`` (:issue:`22922`).\n- :meth:`Series.agg` can now handle numpy NaN-aware methods like :func:`numpy.nansum` (:issue:`19629`)\n- Bug in :meth:`Series.rank` and :meth:`DataFrame.rank` when ``pct=True`` and more than 2\\ :sup:`24` rows are present resulted in percentages greater than 1.0 (:issue:`18271`)\n- Calls such as :meth:`DataFrame.round` with a non-unique :meth:`CategoricalIndex` now return expected data. Previously, data would be improperly duplicated (:issue:`21809`).\n- Added ``log10``, ``floor`` and ``ceil`` to the list of supported functions in :meth:`DataFrame.eval` (:issue:`24139`, :issue:`24353`)\n- Logical operations ``&, |, ^`` between :class:`Series` and :class:`Index` will no longer raise ``ValueError`` (:issue:`22092`)\n- Checking PEP 3141 numbers in :func:`~pandas.api.types.is_scalar` function returns ``True`` (:issue:`22903`)\n- Reduction methods like :meth:`Series.sum` now accept the default value of ``keepdims=False`` when called from a NumPy ufunc, rather than raising a ``TypeError``. Full support for ``keepdims`` has not been implemented (:issue:`24356`).\n\nConversion\n^^^^^^^^^^\n\n- Bug in :meth:`DataFrame.combine_first` in which column types were unexpectedly converted to float (:issue:`20699`)\n- Bug in :meth:`DataFrame.clip` in which column types are not preserved and casted to float (:issue:`24162`)\n- Bug in :meth:`DataFrame.clip` when order of columns of dataframes doesn't match, result observed is wrong in numeric values (:issue:`20911`)\n- Bug in :meth:`DataFrame.astype` where converting to an extension dtype when duplicate column names are present causes a ``RecursionError`` (:issue:`24704`)\n\nStrings\n^^^^^^^\n\n- Bug in :meth:`Index.str.partition` was not nan-safe (:issue:`23558`).\n- Bug in :meth:`Index.str.split` was not nan-safe (:issue:`23677`).\n- Bug :func:`Series.str.contains` not respecting the ``na`` argument for a ``Categorical`` dtype ``Series`` (:issue:`22158`)\n- Bug in :meth:`Index.str.cat` when the result contained only ``NaN`` (:issue:`24044`)\n\nInterval\n^^^^^^^^\n\n- Bug in the :class:`IntervalIndex` constructor where the ``closed`` parameter did not always override the inferred ``closed`` (:issue:`19370`)\n- Bug in the ``IntervalIndex`` repr where a trailing comma was missing after the list of intervals (:issue:`20611`)\n- Bug in :class:`Interval` where scalar arithmetic operations did not retain the ``closed`` value (:issue:`22313`)\n- Bug in :class:`IntervalIndex` where indexing with datetime-like values raised a ``KeyError`` (:issue:`20636`)\n- Bug in ``IntervalTree`` where data containing ``NaN`` triggered a warning and resulted in incorrect indexing queries with :class:`IntervalIndex` (:issue:`23352`)\n\nIndexing\n^^^^^^^^\n\n- Bug in :meth:`DataFrame.ne` fails if columns contain column name \"dtype\" (:issue:`22383`)\n- The traceback from a ``KeyError`` when asking ``.loc`` for a single missing label is now shorter and more clear (:issue:`21557`)\n- :class:`PeriodIndex` now emits a ``KeyError`` when a malformed string is looked up, which is consistent with the behavior of :class:`DatetimeIndex` (:issue:`22803`)\n- When ``.ix`` is asked for a missing integer label in a :class:`MultiIndex` with a first level of integer type, it now raises a ``KeyError``, consistently with the case of a flat :class:`Int64Index`, rather than falling back to positional indexing (:issue:`21593`)\n- Bug in :meth:`Index.reindex` when reindexing a tz-naive and tz-aware :class:`DatetimeIndex` (:issue:`8306`)\n- Bug in :meth:`Series.reindex` when reindexing an empty series with a ``datetime64[ns, tz]`` dtype (:issue:`20869`)\n- Bug in :class:`DataFrame` when setting values with ``.loc`` and a timezone aware :class:`DatetimeIndex` (:issue:`11365`)\n- ``DataFrame.__getitem__`` now accepts dictionaries and dictionary keys as list-likes of labels, consistently with ``Series.__getitem__`` (:issue:`21294`)\n- Fixed ``DataFrame[np.nan]`` when columns are non-unique (:issue:`21428`)\n- Bug when indexing :class:`DatetimeIndex` with nanosecond resolution dates and timezones (:issue:`11679`)\n- Bug where indexing with a Numpy array containing negative values would mutate the indexer (:issue:`21867`)\n- Bug where mixed indexes wouldn't allow integers for ``.at`` (:issue:`19860`)\n- ``Float64Index.get_loc`` now raises ``KeyError`` when boolean key passed. (:issue:`19087`)\n- Bug in :meth:`DataFrame.loc` when indexing with an :class:`IntervalIndex` (:issue:`19977`)\n- :class:`Index` no longer mangles ``None``, ``NaN`` and ``NaT``, i.e. they are treated as three different keys. However, for numeric Index all three are still coerced to a ``NaN`` (:issue:`22332`)\n- Bug in ``scalar in Index`` if scalar is a float while the ``Index`` is of integer dtype (:issue:`22085`)\n- Bug in :func:`MultiIndex.set_levels` when levels value is not subscriptable (:issue:`23273`)\n- Bug where setting a timedelta column by ``Index`` causes it to be casted to double, and therefore lose precision (:issue:`23511`)\n- Bug in :func:`Index.union` and :func:`Index.intersection` where name of the ``Index`` of the result was not computed correctly for certain cases (:issue:`9943`, :issue:`9862`)\n- Bug in :class:`Index` slicing with boolean :class:`Index` may raise ``TypeError`` (:issue:`22533`)\n- Bug in ``PeriodArray.__setitem__`` when accepting slice and list-like value (:issue:`23978`)\n- Bug in :class:`DatetimeIndex`, :class:`TimedeltaIndex` where indexing with ``Ellipsis`` would lose their ``freq`` attribute (:issue:`21282`)\n- Bug in ``iat`` where using it to assign an incompatible value would create a new column (:issue:`23236`)\n\nMissing\n^^^^^^^\n\n- Bug in :func:`DataFrame.fillna` where a ``ValueError`` would raise when one column contained a ``datetime64[ns, tz]`` dtype (:issue:`15522`)\n- Bug in :func:`Series.hasnans` that could be incorrectly cached and return incorrect answers if null elements are introduced after an initial call (:issue:`19700`)\n- :func:`Series.isin` now treats all NaN-floats as equal also for ``np.object_``-dtype. This behavior is consistent with the behavior for float64 (:issue:`22119`)\n- :func:`unique` no longer mangles NaN-floats and the ``NaT``-object for ``np.object_``-dtype, i.e. ``NaT`` is no longer coerced to a NaN-value and is treated as a different entity. (:issue:`22295`)\n- :class:`DataFrame` and :class:`Series` now properly handle numpy masked arrays with hardened masks. Previously, constructing a DataFrame or Series from a masked array with a hard mask would create a pandas object containing the underlying value, rather than the expected NaN. (:issue:`24574`)\n- Bug in :class:`DataFrame` constructor where ``dtype`` argument was not honored when handling numpy masked record arrays. (:issue:`24874`)\n\nMultiIndex\n^^^^^^^^^^\n\n- Bug in :func:`io.formats.style.Styler.applymap` where ``subset=`` with :class:`MultiIndex` slice would reduce to :class:`Series` (:issue:`19861`)\n- Removed compatibility for :class:`MultiIndex` pickles prior to version 0.8.0; compatibility with :class:`MultiIndex` pickles from version 0.13 forward is maintained (:issue:`21654`)\n- :meth:`MultiIndex.get_loc_level` (and as a consequence, ``.loc`` on a ``Series`` or ``DataFrame`` with a :class:`MultiIndex` index) will now raise a ``KeyError``, rather than returning an empty ``slice``, if asked a label which is present in the ``levels`` but is unused (:issue:`22221`)\n- :class:`MultiIndex` has gained the :meth:`MultiIndex.from_frame`, it allows constructing a :class:`MultiIndex` object from a :class:`DataFrame` (:issue:`22420`)\n- Fix ``TypeError`` in Python 3 when creating :class:`MultiIndex` in which some levels have mixed types, e.g. when some labels are tuples (:issue:`15457`)\n\nIO\n^^\n\n- Bug in :func:`read_csv` in which a column specified with ``CategoricalDtype`` of boolean categories was not being correctly coerced from string values to booleans (:issue:`20498`)\n- Bug in :func:`read_csv` in which unicode column names were not being properly recognized with Python 2.x (:issue:`13253`)\n- Bug in :meth:`DataFrame.to_sql` when writing timezone aware data (``datetime64[ns, tz]`` dtype) would raise a ``TypeError`` (:issue:`9086`)\n- Bug in :meth:`DataFrame.to_sql` where a naive :class:`DatetimeIndex` would be written as ``TIMESTAMP WITH TIMEZONE`` type in supported databases, e.g. PostgreSQL (:issue:`23510`)\n- Bug in :meth:`read_excel()` when ``parse_cols`` is specified with an empty dataset (:issue:`9208`)\n- :func:`read_html()` no longer ignores all-whitespace ``<tr>`` within ``<thead>`` when considering the ``skiprows`` and ``header`` arguments. Previously, users had to decrease their ``header`` and ``skiprows`` values on such tables to work around the issue. (:issue:`21641`)\n- :func:`read_excel()` will correctly show the deprecation warning for previously deprecated ``sheetname`` (:issue:`17994`)\n- :func:`read_csv()` and :func:`read_table()` will throw ``UnicodeError`` and not coredump on badly encoded strings (:issue:`22748`)\n- :func:`read_csv()` will correctly parse timezone-aware datetimes (:issue:`22256`)\n- Bug in :func:`read_csv()` in which memory management was prematurely optimized for the C engine when the data was being read in chunks (:issue:`23509`)\n- Bug in :func:`read_csv()` in unnamed columns were being improperly identified when extracting a multi-index (:issue:`23687`)\n- :func:`read_sas()` will parse numbers in sas7bdat-files that have width less than 8 bytes correctly. (:issue:`21616`)\n- :func:`read_sas()` will correctly parse sas7bdat files with many columns (:issue:`22628`)\n- :func:`read_sas()` will correctly parse sas7bdat files with data page types having also bit 7 set (so page type is 128 + 256 = 384) (:issue:`16615`)\n- Bug in :func:`read_sas()` in which an incorrect error was raised on an invalid file format. (:issue:`24548`)\n- Bug in :meth:`detect_client_encoding` where potential ``IOError`` goes unhandled when importing in a mod_wsgi process due to restricted access to stdout. (:issue:`21552`)\n- Bug in :func:`DataFrame.to_html()` with ``index=False`` misses truncation indicators (...) on truncated DataFrame (:issue:`15019`, :issue:`22783`)\n- Bug in :func:`DataFrame.to_html()` with ``index=False`` when both columns and row index are ``MultiIndex`` (:issue:`22579`)\n- Bug in :func:`DataFrame.to_html()` with ``index_names=False`` displaying index name (:issue:`22747`)\n- Bug in :func:`DataFrame.to_html()` with ``header=False`` not displaying row index names (:issue:`23788`)\n- Bug in :func:`DataFrame.to_html()` with ``sparsify=False`` that caused it to raise ``TypeError`` (:issue:`22887`)\n- Bug in :func:`DataFrame.to_string()` that broke column alignment when ``index=False`` and width of first column's values is greater than the width of first column's header (:issue:`16839`, :issue:`13032`)\n- Bug in :func:`DataFrame.to_string()` that caused representations of :class:`DataFrame` to not take up the whole window (:issue:`22984`)\n- Bug in :func:`DataFrame.to_csv` where a single level MultiIndex incorrectly wrote a tuple. Now just the value of the index is written (:issue:`19589`).\n- :class:`HDFStore` will raise ``ValueError`` when the ``format`` kwarg is passed to the constructor (:issue:`13291`)\n- Bug in :meth:`HDFStore.append` when appending a :class:`DataFrame` with an empty string column and ``min_itemsize`` < 8 (:issue:`12242`)\n- Bug in :func:`read_csv()` in which memory leaks occurred in the C engine when parsing ``NaN`` values due to insufficient cleanup on completion or error (:issue:`21353`)\n- Bug in :func:`read_csv()` in which incorrect error messages were being raised when ``skipfooter`` was passed in along with ``nrows``, ``iterator``, or ``chunksize`` (:issue:`23711`)\n- Bug in :func:`read_csv()` in which :class:`MultiIndex` index names were being improperly handled in the cases when they were not provided (:issue:`23484`)\n- Bug in :func:`read_csv()` in which unnecessary warnings were being raised when the dialect's values conflicted with the default arguments (:issue:`23761`)\n- Bug in :func:`read_html()` in which the error message was not displaying the valid flavors when an invalid one was provided (:issue:`23549`)\n- Bug in :meth:`read_excel()` in which extraneous header names were extracted, even though none were specified (:issue:`11733`)\n- Bug in :meth:`read_excel()` in which column names were not being properly converted to string sometimes in Python 2.x (:issue:`23874`)\n- Bug in :meth:`read_excel()` in which ``index_col=None`` was not being respected and parsing index columns anyway (:issue:`18792`, :issue:`20480`)\n- Bug in :meth:`read_excel()` in which ``usecols`` was not being validated for proper column names when passed in as a string (:issue:`20480`)\n- Bug in :meth:`DataFrame.to_dict` when the resulting dict contains non-Python scalars in the case of numeric data (:issue:`23753`)\n- :func:`DataFrame.to_string()`, :func:`DataFrame.to_html()`, :func:`DataFrame.to_latex()` will correctly format output when a string is passed as the ``float_format`` argument (:issue:`21625`, :issue:`22270`)\n- Bug in :func:`read_csv` that caused it to raise ``OverflowError`` when trying to use 'inf' as ``na_value`` with integer index column (:issue:`17128`)\n- Bug in :func:`read_csv` that caused the C engine on Python 3.6+ on Windows to improperly read CSV filenames with accented or special characters (:issue:`15086`)\n- Bug in :func:`read_fwf` in which the compression type of a file was not being properly inferred (:issue:`22199`)\n- Bug in :func:`pandas.io.json.json_normalize` that caused it to raise ``TypeError`` when two consecutive elements of ``record_path`` are dicts (:issue:`22706`)\n- Bug in :meth:`DataFrame.to_stata`, :class:`pandas.io.stata.StataWriter` and :class:`pandas.io.stata.StataWriter117` where a exception would leave a partially written and invalid dta file (:issue:`23573`)\n- Bug in :meth:`DataFrame.to_stata` and :class:`pandas.io.stata.StataWriter117` that produced invalid files when using strLs with non-ASCII characters (:issue:`23573`)\n- Bug in :class:`HDFStore` that caused it to raise ``ValueError`` when reading a Dataframe in Python 3 from fixed format written in Python 2 (:issue:`24510`)\n- Bug in :func:`DataFrame.to_string()` and more generally in the floating ``repr`` formatter. Zeros were not trimmed if ``inf`` was present in a columns while it was the case with NA values. Zeros are now trimmed as in the presence of NA (:issue:`24861`).\n- Bug in the ``repr`` when truncating the number of columns and having a wide last column (:issue:`24849`).\n\nPlotting\n^^^^^^^^\n\n- Bug in :func:`DataFrame.plot.scatter` and :func:`DataFrame.plot.hexbin` caused x-axis label and ticklabels to disappear when colorbar was on in IPython inline backend (:issue:`10611`, :issue:`10678`, and :issue:`20455`)\n- Bug in plotting a Series with datetimes using :func:`matplotlib.axes.Axes.scatter` (:issue:`22039`)\n- Bug in :func:`DataFrame.plot.bar` caused bars to use multiple colors instead of a single one (:issue:`20585`)\n- Bug in validating color parameter caused extra color to be appended to the given color array. This happened to multiple plotting functions using matplotlib. (:issue:`20726`)\n\nGroupBy/resample/rolling\n^^^^^^^^^^^^^^^^^^^^^^^^\n\n- Bug in :func:`.Rolling.min` and :func:`.Rolling.max` with ``closed='left'``, a datetime-like index and only one entry in the series leading to segfault (:issue:`24718`)\n- Bug in :func:`.GroupBy.first` and :func:`.GroupBy.last` with ``as_index=False`` leading to the loss of timezone information (:issue:`15884`)\n- Bug in :meth:`DateFrame.resample` when downsampling across a DST boundary (:issue:`8531`)\n- Bug in date anchoring for :meth:`DateFrame.resample` with offset :class:`Day` when n > 1 (:issue:`24127`)\n- Bug where ``ValueError`` is wrongly raised when calling :func:`.SeriesGroupBy.count` method of a\n  ``SeriesGroupBy`` when the grouping variable only contains NaNs and numpy version < 1.13 (:issue:`21956`).\n- Multiple bugs in :func:`.Rolling.min` with ``closed='left'`` and a\n  datetime-like index leading to incorrect results and also segfault. (:issue:`21704`)\n- Bug in :meth:`.Resampler.apply` when passing positional arguments to applied func (:issue:`14615`).\n- Bug in :meth:`Series.resample` when passing ``numpy.timedelta64`` to ``loffset`` kwarg (:issue:`7687`).\n- Bug in :meth:`.Resampler.asfreq` when frequency of ``TimedeltaIndex`` is a subperiod of a new frequency (:issue:`13022`).\n- Bug in :meth:`.SeriesGroupBy.mean` when values were integral but could not fit inside of int64, overflowing instead. (:issue:`22487`)\n- :func:`.RollingGroupby.agg` and :func:`.ExpandingGroupby.agg` now support multiple aggregation functions as parameters (:issue:`15072`)\n- Bug in :meth:`DataFrame.resample` and :meth:`Series.resample` when resampling by a weekly offset (``'W'``) across a DST transition (:issue:`9119`, :issue:`21459`)\n- Bug in :meth:`DataFrame.expanding` in which the ``axis`` argument was not being respected during aggregations (:issue:`23372`)\n- Bug in :meth:`.GroupBy.transform` which caused missing values when the input function can accept a :class:`DataFrame` but renames it (:issue:`23455`).\n- Bug in :func:`.GroupBy.nth` where column order was not always preserved (:issue:`20760`)\n- Bug in :meth:`.GroupBy.rank` with ``method='dense'`` and ``pct=True`` when a group has only one member would raise a ``ZeroDivisionError`` (:issue:`23666`).\n- Calling :meth:`.GroupBy.rank` with empty groups and ``pct=True`` was raising a ``ZeroDivisionError`` (:issue:`22519`)\n- Bug in :meth:`DataFrame.resample` when resampling ``NaT`` in ``TimeDeltaIndex`` (:issue:`13223`).\n- Bug in :meth:`DataFrame.groupby` did not respect the ``observed`` argument when selecting a column and instead always used ``observed=False`` (:issue:`23970`)\n- Bug in :func:`.SeriesGroupBy.pct_change` or :func:`.DataFrameGroupBy.pct_change` would previously work across groups when calculating the percent change, where it now correctly works per group (:issue:`21200`, :issue:`21235`).\n- Bug preventing hash table creation with very large number (2^32) of rows (:issue:`22805`)\n- Bug in groupby when grouping on categorical causes ``ValueError`` and incorrect grouping if ``observed=True`` and ``nan`` is present in categorical column (:issue:`24740`, :issue:`21151`).\n\nReshaping\n^^^^^^^^^\n\n- Bug in :func:`pandas.concat` when joining resampled DataFrames with timezone aware index (:issue:`13783`)\n- Bug in :func:`pandas.concat` when joining only ``Series`` the ``names`` argument of ``concat`` is no longer ignored (:issue:`23490`)\n- Bug in :meth:`Series.combine_first` with ``datetime64[ns, tz]`` dtype which would return tz-naive result (:issue:`21469`)\n- Bug in :meth:`Series.where` and :meth:`DataFrame.where` with ``datetime64[ns, tz]`` dtype (:issue:`21546`)\n- Bug in :meth:`DataFrame.where` with an empty DataFrame and empty ``cond`` having non-bool dtype (:issue:`21947`)\n- Bug in :meth:`Series.mask` and :meth:`DataFrame.mask` with ``list`` conditionals (:issue:`21891`)\n- Bug in :meth:`DataFrame.replace` raises RecursionError when converting OutOfBounds ``datetime64[ns, tz]`` (:issue:`20380`)\n- :func:`.GroupBy.rank` now raises a ``ValueError`` when an invalid value is passed for argument ``na_option`` (:issue:`22124`)\n- Bug in :func:`get_dummies` with Unicode attributes in Python 2 (:issue:`22084`)\n- Bug in :meth:`DataFrame.replace` raises ``RecursionError`` when replacing empty lists (:issue:`22083`)\n- Bug in :meth:`Series.replace` and :meth:`DataFrame.replace` when dict is used as the ``to_replace`` value and one key in the dict is another key's value, the results were inconsistent between using integer key and using string key (:issue:`20656`)\n- Bug in :meth:`DataFrame.drop_duplicates` for empty ``DataFrame`` which incorrectly raises an error (:issue:`20516`)\n- Bug in :func:`pandas.wide_to_long` when a string is passed to the stubnames argument and a column name is a substring of that stubname (:issue:`22468`)\n- Bug in :func:`merge` when merging ``datetime64[ns, tz]`` data that contained a DST transition (:issue:`18885`)\n- Bug in :func:`merge_asof` when merging on float values within defined tolerance (:issue:`22981`)\n- Bug in :func:`pandas.concat` when concatenating a multicolumn DataFrame with tz-aware data against a DataFrame with a different number of columns (:issue:`22796`)\n- Bug in :func:`merge_asof` where confusing error message raised when attempting to merge with missing values (:issue:`23189`)\n- Bug in :meth:`DataFrame.nsmallest` and :meth:`DataFrame.nlargest` for dataframes that have a :class:`MultiIndex` for columns (:issue:`23033`).\n- Bug in :func:`pandas.melt` when passing column names that are not present in ``DataFrame`` (:issue:`23575`)\n- Bug in :meth:`DataFrame.append` with a :class:`Series` with a dateutil timezone would raise a ``TypeError`` (:issue:`23682`)\n- Bug in :class:`Series` construction when passing no data and ``dtype=str`` (:issue:`22477`)\n- Bug in :func:`cut` with ``bins`` as an overlapping ``IntervalIndex`` where multiple bins were returned per item instead of raising a ``ValueError`` (:issue:`23980`)\n- Bug in :func:`pandas.concat` when joining ``Series`` datetimetz with ``Series`` category would lose timezone (:issue:`23816`)\n- Bug in :meth:`DataFrame.join` when joining on partial MultiIndex would drop names (:issue:`20452`).\n- :meth:`DataFrame.nlargest` and :meth:`DataFrame.nsmallest` now returns the correct n values when keep != 'all' also when tied on the first columns (:issue:`22752`)\n- Constructing a DataFrame with an index argument that wasn't already an instance of :class:`.Index` was broken (:issue:`22227`).\n- Bug in :class:`DataFrame` prevented list subclasses to be used to construction (:issue:`21226`)\n- Bug in :func:`DataFrame.unstack` and :func:`DataFrame.pivot_table` returning a misleading error message when the resulting DataFrame has more elements than int32 can handle. Now, the error message is improved, pointing towards the actual problem (:issue:`20601`)\n- Bug in :func:`DataFrame.unstack` where a ``ValueError`` was raised when unstacking timezone aware values (:issue:`18338`)\n- Bug in :func:`DataFrame.stack` where timezone aware values were converted to timezone naive values (:issue:`19420`)\n- Bug in :func:`merge_asof` where a ``TypeError`` was raised when ``by_col`` were timezone aware values (:issue:`21184`)\n- Bug showing an incorrect shape when throwing error during ``DataFrame`` construction. (:issue:`20742`)\n\n.. _whatsnew_0240.bug_fixes.sparse:\n\nSparse\n^^^^^^\n\n- Updating a boolean, datetime, or timedelta column to be Sparse now works (:issue:`22367`)\n- Bug in :meth:`Series.to_sparse` with Series already holding sparse data not constructing properly (:issue:`22389`)\n- Providing a ``sparse_index`` to the SparseArray constructor no longer defaults the na-value to ``np.nan`` for all dtypes. The correct na_value for ``data.dtype`` is now used.\n- Bug in ``SparseArray.nbytes`` under-reporting its memory usage by not including the size of its sparse index.\n- Improved performance of :meth:`Series.shift` for non-NA ``fill_value``, as values are no longer converted to a dense array.\n- Bug in ``DataFrame.groupby`` not including ``fill_value`` in the groups for non-NA ``fill_value`` when grouping by a sparse column (:issue:`5078`)\n- Bug in unary inversion operator (``~``) on a ``SparseSeries`` with boolean values. The performance of this has also been improved (:issue:`22835`)\n- Bug in :meth:`SparseArary.unique` not returning the unique values (:issue:`19595`)\n- Bug in :meth:`SparseArray.nonzero` and :meth:`SparseDataFrame.dropna` returning shifted/incorrect results (:issue:`21172`)\n- Bug in :meth:`DataFrame.apply` where dtypes would lose sparseness (:issue:`23744`)\n- Bug in :func:`concat` when concatenating a list of :class:`Series` with all-sparse values changing the ``fill_value`` and converting to a dense Series (:issue:`24371`)\n\nStyle\n^^^^^\n\n- :meth:`~pandas.io.formats.style.Styler.background_gradient` now takes a ``text_color_threshold`` parameter to automatically lighten the text color based on the luminance of the background color. This improves readability with dark background colors without the need to limit the background colormap range. (:issue:`21258`)\n- :meth:`~pandas.io.formats.style.Styler.background_gradient` now also supports tablewise application (in addition to rowwise and columnwise) with ``axis=None`` (:issue:`15204`)\n- :meth:`~pandas.io.formats.style.Styler.bar` now also supports tablewise application (in addition to rowwise and columnwise) with ``axis=None`` and setting clipping range with ``vmin`` and ``vmax`` (:issue:`21548` and :issue:`21526`). ``NaN`` values are also handled properly.\n\nBuild changes\n^^^^^^^^^^^^^\n\n- Building pandas for development now requires ``cython >= 0.28.2`` (:issue:`21688`)\n- Testing pandas now requires ``hypothesis>=3.58``.  You can find `the Hypothesis docs here <https://hypothesis.readthedocs.io/en/latest/index.html>`_, and a pandas-specific introduction :ref:`in the contributing guide <using-hypothesis>`. (:issue:`22280`)\n- Building pandas on macOS now targets minimum macOS 10.9 if run on macOS 10.9 or above (:issue:`23424`)\n\nOther\n^^^^^\n\n- Bug where C variables were declared with external linkage causing import errors if certain other C libraries were imported before pandas. (:issue:`24113`)\n\n\n.. _whatsnew_0.24.0.contributors:\n\nContributors\n~~~~~~~~~~~~\n\n.. contributors:: v0.23.4..v0.24.0\n\n\n.. _whatsnew_131:\n\nWhat's new in 1.3.1 (July 25, 2021)\n-----------------------------------\n\nThese are the changes in pandas 1.3.1. See :ref:`release` for a full changelog\nincluding other versions of pandas.\n\n{{ header }}\n\n.. ---------------------------------------------------------------------------\n\n.. _whatsnew_131.regressions:\n\nFixed regressions\n~~~~~~~~~~~~~~~~~\n- Pandas could not be built on PyPy (:issue:`42355`)\n- :class:`DataFrame` constructed with an older version of pandas could not be unpickled (:issue:`42345`)\n- Performance regression in constructing a :class:`DataFrame` from a dictionary of dictionaries (:issue:`42248`)\n- Fixed regression in :meth:`DataFrame.agg` dropping values when the DataFrame had an Extension Array dtype, a duplicate index, and ``axis=1`` (:issue:`42380`)\n- Fixed regression in :meth:`DataFrame.astype` changing the order of noncontiguous data (:issue:`42396`)\n- Performance regression in :class:`DataFrame` in reduction operations requiring casting such as :meth:`DataFrame.mean` on integer data (:issue:`38592`)\n- Performance regression in :meth:`DataFrame.to_dict` and :meth:`Series.to_dict` when ``orient`` argument one of \"records\", \"dict\", or \"split\" (:issue:`42352`)\n- Fixed regression in indexing with a ``list`` subclass incorrectly raising ``TypeError`` (:issue:`42433`, :issue:`42461`)\n- Fixed regression in :meth:`DataFrame.isin` and :meth:`Series.isin` raising ``TypeError`` with nullable data containing at least one missing value (:issue:`42405`)\n- Regression in :func:`concat` between objects with bool dtype and integer dtype casting to object instead of to integer (:issue:`42092`)\n- Bug in :class:`Series` constructor not accepting a ``dask.Array`` (:issue:`38645`)\n- Fixed regression for ``SettingWithCopyWarning`` displaying incorrect stacklevel (:issue:`42570`)\n- Fixed regression for :func:`merge_asof` raising ``KeyError`` when one of the ``by`` columns is in the index (:issue:`34488`)\n- Fixed regression in :func:`to_datetime` returning pd.NaT for inputs that produce duplicated values, when ``cache=True`` (:issue:`42259`)\n- Fixed regression in :meth:`SeriesGroupBy.value_counts` that resulted in an ``IndexError`` when called on a Series with one row (:issue:`42618`)\n\n.. ---------------------------------------------------------------------------\n\n.. _whatsnew_131.bug_fixes:\n\nBug fixes\n~~~~~~~~~\n- Fixed bug in :meth:`DataFrame.transpose` dropping values when the DataFrame had an Extension Array dtype and a duplicate index (:issue:`42380`)\n- Fixed bug in :meth:`DataFrame.to_xml` raising ``KeyError`` when called with ``index=False`` and an offset index (:issue:`42458`)\n- Fixed bug in :meth:`.Styler.set_sticky` not handling index names correctly for single index columns case (:issue:`42537`)\n- Fixed bug in :meth:`DataFrame.copy` failing to consolidate blocks in the result (:issue:`42579`)\n\n.. ---------------------------------------------------------------------------\n\n.. _whatsnew_131.contributors:\n\nContributors\n~~~~~~~~~~~~\n\n.. contributors:: v1.3.0..v1.3.1\n\n\n.. _whatsnew_221:\n\nWhat's new in 2.2.1 (February 22, 2024)\n---------------------------------------\n\nThese are the changes in pandas 2.2.1. See :ref:`release` for a full changelog\nincluding other versions of pandas.\n\n{{ header }}\n\n.. ---------------------------------------------------------------------------\n.. _whatsnew_221.enhancements:\n\nEnhancements\n~~~~~~~~~~~~\n- Added ``pyarrow`` pip extra so users can install pandas and pyarrow with pip with ``pip install pandas[pyarrow]`` (:issue:`54466`)\n\n.. _whatsnew_221.regressions:\n\nFixed regressions\n~~~~~~~~~~~~~~~~~\n- Fixed memory leak in :func:`read_csv` (:issue:`57039`)\n- Fixed performance regression in :meth:`Series.combine_first` (:issue:`55845`)\n- Fixed regression causing overflow for near-minimum timestamps (:issue:`57150`)\n- Fixed regression in :func:`concat` changing long-standing behavior that always sorted the non-concatenation axis when the axis was a :class:`DatetimeIndex` (:issue:`57006`)\n- Fixed regression in :func:`merge_ordered` raising ``TypeError`` for ``fill_method=\"ffill\"`` and ``how=\"left\"`` (:issue:`57010`)\n- Fixed regression in :func:`pandas.testing.assert_series_equal` defaulting to ``check_exact=True`` when checking the :class:`Index` (:issue:`57067`)\n- Fixed regression in :func:`read_json` where an :class:`Index` would be returned instead of a :class:`RangeIndex` (:issue:`57429`)\n- Fixed regression in :func:`wide_to_long` raising an ``AttributeError`` for string columns (:issue:`57066`)\n- Fixed regression in :meth:`.DataFrameGroupBy.idxmin`, :meth:`.DataFrameGroupBy.idxmax`, :meth:`.SeriesGroupBy.idxmin`, :meth:`.SeriesGroupBy.idxmax` ignoring the ``skipna`` argument (:issue:`57040`)\n- Fixed regression in :meth:`.DataFrameGroupBy.idxmin`, :meth:`.DataFrameGroupBy.idxmax`, :meth:`.SeriesGroupBy.idxmin`, :meth:`.SeriesGroupBy.idxmax` where values containing the minimum or maximum value for the dtype could produce incorrect results (:issue:`57040`)\n- Fixed regression in :meth:`CategoricalIndex.difference` raising ``KeyError`` when other contains null values other than NaN (:issue:`57318`)\n- Fixed regression in :meth:`DataFrame.groupby` raising ``ValueError`` when grouping by a :class:`Series` in some cases (:issue:`57276`)\n- Fixed regression in :meth:`DataFrame.loc` raising ``IndexError`` for non-unique, masked dtype indexes where result has more than 10,000 rows (:issue:`57027`)\n- Fixed regression in :meth:`DataFrame.loc` which was unnecessarily throwing \"incompatible dtype warning\" when expanding with partial row indexer and multiple columns (see `PDEP6 <https://pandas.pydata.org/pdeps/0006-ban-upcasting.html>`_) (:issue:`56503`)\n- Fixed regression in :meth:`DataFrame.map` with ``na_action=\"ignore\"`` not being respected for NumPy nullable and :class:`ArrowDtypes` (:issue:`57316`)\n- Fixed regression in :meth:`DataFrame.merge` raising ``ValueError`` for certain types of 3rd-party extension arrays (:issue:`57316`)\n- Fixed regression in :meth:`DataFrame.query` with all ``NaT`` column with object dtype (:issue:`57068`)\n- Fixed regression in :meth:`DataFrame.shift` raising ``AssertionError`` for ``axis=1`` and empty :class:`DataFrame` (:issue:`57301`)\n- Fixed regression in :meth:`DataFrame.sort_index` not producing a stable sort for a index with duplicates (:issue:`57151`)\n- Fixed regression in :meth:`DataFrame.to_dict` with ``orient='list'`` and datetime or timedelta types returning integers (:issue:`54824`)\n- Fixed regression in :meth:`DataFrame.to_json` converting nullable integers to floats (:issue:`57224`)\n- Fixed regression in :meth:`DataFrame.to_sql` when ``method=\"multi\"`` is passed and the dialect type is not Oracle (:issue:`57310`)\n- Fixed regression in :meth:`DataFrame.transpose` with nullable extension dtypes not having F-contiguous data potentially causing exceptions when used (:issue:`57315`)\n- Fixed regression in :meth:`DataFrame.update` emitting incorrect warnings about downcasting (:issue:`57124`)\n- Fixed regression in :meth:`DataFrameGroupBy.idxmin`, :meth:`DataFrameGroupBy.idxmax`, :meth:`SeriesGroupBy.idxmin`, :meth:`SeriesGroupBy.idxmax` ignoring the ``skipna`` argument (:issue:`57040`)\n- Fixed regression in :meth:`DataFrameGroupBy.idxmin`, :meth:`DataFrameGroupBy.idxmax`, :meth:`SeriesGroupBy.idxmin`, :meth:`SeriesGroupBy.idxmax` where values containing the minimum or maximum value for the dtype could produce incorrect results (:issue:`57040`)\n- Fixed regression in :meth:`ExtensionArray.to_numpy` raising for non-numeric masked dtypes (:issue:`56991`)\n- Fixed regression in :meth:`Index.join` raising ``TypeError`` when joining an empty index to a non-empty index containing mixed dtype values (:issue:`57048`)\n- Fixed regression in :meth:`Series.astype` introducing decimals when converting from integer with missing values to string dtype (:issue:`57418`)\n- Fixed regression in :meth:`Series.pct_change` raising a ``ValueError`` for an empty :class:`Series` (:issue:`57056`)\n- Fixed regression in :meth:`Series.to_numpy` when dtype is given as float and the data contains NaNs (:issue:`57121`)\n- Fixed regression in addition or subtraction of :class:`DateOffset` objects with millisecond components to ``datetime64`` :class:`Index`, :class:`Series`, or :class:`DataFrame` (:issue:`57529`)\n\n.. ---------------------------------------------------------------------------\n.. _whatsnew_221.bug_fixes:\n\nBug fixes\n~~~~~~~~~\n- Fixed bug in :func:`pandas.api.interchange.from_dataframe` which was raising for Nullable integers (:issue:`55069`)\n- Fixed bug in :func:`pandas.api.interchange.from_dataframe` which was raising for empty inputs (:issue:`56700`)\n- Fixed bug in :func:`pandas.api.interchange.from_dataframe` which wasn't converting columns names to strings (:issue:`55069`)\n- Fixed bug in :meth:`DataFrame.__getitem__` for empty :class:`DataFrame` with Copy-on-Write enabled (:issue:`57130`)\n- Fixed bug in :meth:`PeriodIndex.asfreq` which was silently converting frequencies which are not supported as period frequencies instead of raising an error (:issue:`56945`)\n\n.. ---------------------------------------------------------------------------\n.. _whatsnew_221.other:\n\nOther\n~~~~~\n\n.. note::\n\n    The ``DeprecationWarning`` that was raised when pandas was imported without PyArrow being\n    installed has been removed. This decision was made because the warning was too noisy for too\n    many users and a lot of feedback was collected about the decision to make PyArrow a required\n    dependency. Pandas is currently considering the decision whether or not PyArrow should be added\n    as a hard dependency in 3.0. Interested users can follow the discussion\n    `here <https://github.com/pandas-dev/pandas/issues/57073>`_.\n\n- Added the argument ``skipna`` to :meth:`DataFrameGroupBy.first`, :meth:`DataFrameGroupBy.last`, :meth:`SeriesGroupBy.first`, and :meth:`SeriesGroupBy.last`; achieving ``skipna=False`` used to be available via :meth:`DataFrameGroupBy.nth`, but the behavior was changed in pandas 2.0.0 (:issue:`57019`)\n- Added the argument ``skipna`` to :meth:`Resampler.first`, :meth:`Resampler.last` (:issue:`57019`)\n\n.. ---------------------------------------------------------------------------\n.. _whatsnew_221.contributors:\n\nContributors\n~~~~~~~~~~~~\n\n.. contributors:: v2.2.0..v2.2.1\n\n\n\n.. _whatsnew_105:\n\nWhat's new in 1.0.5 (June 17, 2020)\n-----------------------------------\n\nThese are the changes in pandas 1.0.5. See :ref:`release` for a full changelog\nincluding other versions of pandas.\n\n{{ header }}\n\n.. ---------------------------------------------------------------------------\n\n.. _whatsnew_105.regressions:\n\nFixed regressions\n~~~~~~~~~~~~~~~~~\n\n- Fix regression in :meth:`read_parquet` when reading from file-like objects\n  (:issue:`34467`).\n- Fix regression in reading from public S3 buckets (:issue:`34626`).\n\nNote this disables the ability to read Parquet files from directories on S3\nagain (:issue:`26388`, :issue:`34632`), which was added in the 1.0.4 release,\nbut is now targeted for pandas 1.1.0.\n\n- Fixed regression in :meth:`~DataFrame.replace` raising an ``AssertionError`` when replacing values in an extension dtype with values of a different dtype (:issue:`34530`)\n\n.. _whatsnew_105.bug_fixes:\n\nBug fixes\n~~~~~~~~~\n\n- Fixed building from source with Python 3.8 fetching the wrong version of NumPy (:issue:`34666`)\n\nContributors\n~~~~~~~~~~~~\n\n.. contributors:: v1.0.4..v1.0.5|HEAD\n\n\n.. _whatsnew_132:\n\nWhat's new in 1.3.2 (August 15, 2021)\n-------------------------------------\n\nThese are the changes in pandas 1.3.2. See :ref:`release` for a full changelog\nincluding other versions of pandas.\n\n{{ header }}\n\n.. ---------------------------------------------------------------------------\n\n.. _whatsnew_132.regressions:\n\nFixed regressions\n~~~~~~~~~~~~~~~~~\n- Performance regression in :meth:`DataFrame.isin` and :meth:`Series.isin` for nullable data types (:issue:`42714`)\n- Regression in updating values of :class:`Series` using boolean index, created by using :meth:`DataFrame.pop` (:issue:`42530`)\n- Regression in :meth:`DataFrame.from_records` with empty records (:issue:`42456`)\n- Fixed regression in :meth:`DataFrame.shift` where ``TypeError`` occurred when shifting DataFrame created by concatenation of slices and fills with values (:issue:`42719`)\n- Regression in :meth:`DataFrame.agg` when the ``func`` argument returned lists and ``axis=1`` (:issue:`42727`)\n- Regression in :meth:`DataFrame.drop` does nothing if :class:`MultiIndex` has duplicates and indexer is a tuple or list of tuples (:issue:`42771`)\n- Fixed regression where :func:`read_csv` raised a ``ValueError`` when parameters ``names`` and ``prefix`` were both set to ``None`` (:issue:`42387`)\n- Fixed regression in comparisons between :class:`Timestamp` object and ``datetime64`` objects outside the implementation bounds for nanosecond ``datetime64`` (:issue:`42794`)\n- Fixed regression in :meth:`.Styler.highlight_min` and :meth:`.Styler.highlight_max` where ``pandas.NA`` was not successfully ignored (:issue:`42650`)\n- Fixed regression in :func:`concat` where ``copy=False`` was not honored in ``axis=1`` Series concatenation (:issue:`42501`)\n- Regression in :meth:`Series.nlargest` and :meth:`Series.nsmallest` with nullable integer or float dtype (:issue:`42816`)\n- Fixed regression in :meth:`Series.quantile` with :class:`Int64Dtype` (:issue:`42626`)\n- Fixed regression in :meth:`Series.groupby` and :meth:`DataFrame.groupby` where supplying the ``by`` argument with a Series named with a tuple would incorrectly raise (:issue:`42731`)\n\n.. ---------------------------------------------------------------------------\n\n.. _whatsnew_132.bug_fixes:\n\nBug fixes\n~~~~~~~~~\n- Bug in :func:`read_excel` modifies the dtypes dictionary when reading a file with duplicate columns (:issue:`42462`)\n- 1D slices over extension types turn into N-dimensional slices over ExtensionArrays (:issue:`42430`)\n- Fixed bug in :meth:`Series.rolling` and :meth:`DataFrame.rolling` not calculating window bounds correctly for the first row when ``center=True`` and ``window`` is an offset that covers all the rows (:issue:`42753`)\n- :meth:`.Styler.hide_columns` now hides the index name header row as well as column headers (:issue:`42101`)\n- :meth:`.Styler.set_sticky` has amended CSS to control the column/index names and ensure the correct sticky positions (:issue:`42537`)\n- Bug in de-serializing datetime indexes in PYTHONOPTIMIZED mode (:issue:`42866`)\n\n.. ---------------------------------------------------------------------------\n\n.. _whatsnew_132.contributors:\n\nContributors\n~~~~~~~~~~~~\n\n.. contributors:: v1.3.1..v1.3.2\n\n\n.. _whatsnew_213:\n\nWhat's new in 2.1.3 (November 10, 2023)\n---------------------------------------\n\nThese are the changes in pandas 2.1.3. See :ref:`release` for a full changelog\nincluding other versions of pandas.\n\n{{ header }}\n\n.. ---------------------------------------------------------------------------\n.. _whatsnew_213.regressions:\n\nFixed regressions\n~~~~~~~~~~~~~~~~~\n- Fixed infinite recursion from operations that return a new object on some DataFrame subclasses (:issue:`55763`)\n\n.. ---------------------------------------------------------------------------\n.. _whatsnew_213.bug_fixes:\n\nBug fixes\n~~~~~~~~~\n- Bug in :meth:`DatetimeIndex.diff` raising ``TypeError`` (:issue:`55080`)\n- Bug in :meth:`Index.isin` raising for Arrow backed string and ``None`` value (:issue:`55821`)\n- Fix :func:`read_parquet` and :func:`read_feather` for `CVE-2023-47248 <https://www.cve.org/CVERecord?id=CVE-2023-47248>`__ (:issue:`55894`)\n\n.. ---------------------------------------------------------------------------\n.. _whatsnew_213.contributors:\n\nContributors\n~~~~~~~~~~~~\n\n.. contributors:: v2.1.2..v2.1.3|HEAD\n\n\n.. _whatsnew_100:\n\nWhat's new in 1.0.0 (January 29, 2020)\n--------------------------------------\n\nThese are the changes in pandas 1.0.0. See :ref:`release` for a full changelog\nincluding other versions of pandas.\n\n.. note::\n\n    The pandas 1.0 release removed a lot of functionality that was deprecated\n    in previous releases (see :ref:`below <whatsnew_100.prior_deprecations>`\n    for an overview). It is recommended to first upgrade to pandas 0.25 and to\n    ensure your code is working without warnings, before upgrading to pandas\n    1.0.\n\n\nNew deprecation policy\n~~~~~~~~~~~~~~~~~~~~~~\n\nStarting with pandas 1.0.0, pandas will adopt a variant of `SemVer`_ to\nversion releases. Briefly,\n\n* Deprecations will be introduced in minor releases (e.g. 1.1.0, 1.2.0, 2.1.0, ...)\n* Deprecations will be enforced in major releases (e.g. 1.0.0, 2.0.0, 3.0.0, ...)\n* API-breaking changes will be made only in major releases (except for experimental features)\n\nSee :ref:`policies.version` for more.\n\n.. _2019 Pandas User Survey: https://pandas.pydata.org/community/blog/2019-user-survey.html\n.. _SemVer: https://semver.org\n\n{{ header }}\n\n.. ---------------------------------------------------------------------------\n\nEnhancements\n~~~~~~~~~~~~\n\n.. _whatsnew_100.numba_rolling_apply:\n\nUsing Numba in ``rolling.apply`` and ``expanding.apply``\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nWe've added an ``engine`` keyword to :meth:`~core.window.rolling.Rolling.apply` and :meth:`~core.window.expanding.Expanding.apply`\nthat allows the user to execute the routine using `Numba <https://numba.pydata.org/>`__ instead of Cython.\nUsing the Numba engine can yield significant performance gains if the apply function can operate on numpy arrays and\nthe data set is larger (1 million rows or greater). For more details, see\n:ref:`rolling apply documentation <window.numba_engine>` (:issue:`28987`, :issue:`30936`)\n\n.. _whatsnew_100.custom_window:\n\nDefining custom windows for rolling operations\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nWe've added a :func:`pandas.api.indexers.BaseIndexer` class that allows users to define how\nwindow bounds are created during ``rolling`` operations. Users can define their own ``get_window_bounds``\nmethod on a :func:`pandas.api.indexers.BaseIndexer` subclass that will generate the start and end\nindices used for each window during the rolling aggregation. For more details and example usage, see\nthe :ref:`custom window rolling documentation <window.custom_rolling_window>`\n\n.. _whatsnew_100.to_markdown:\n\nConverting to markdown\n^^^^^^^^^^^^^^^^^^^^^^\n\nWe've added :meth:`~DataFrame.to_markdown` for creating a markdown table (:issue:`11052`)\n\n.. ipython:: python\n\n   df = pd.DataFrame({\"A\": [1, 2, 3], \"B\": [1, 2, 3]}, index=['a', 'a', 'b'])\n   print(df.to_markdown())\n\nExperimental new features\n~~~~~~~~~~~~~~~~~~~~~~~~~\n\n.. _whatsnew_100.NA:\n\nExperimental ``NA`` scalar to denote missing values\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nA new ``pd.NA`` value (singleton) is introduced to represent scalar missing\nvalues. Up to now, pandas used several values to represent missing data: ``np.nan`` is used for this for float data, ``np.nan`` or\n``None`` for object-dtype data and ``pd.NaT`` for datetime-like data. The\ngoal of ``pd.NA`` is to provide a \"missing\" indicator that can be used\nconsistently across data types. ``pd.NA`` is currently used by the nullable integer and boolean\ndata types and the new string data type (:issue:`28095`).\n\n.. warning::\n\n   Experimental: the behaviour of ``pd.NA`` can still change without warning.\n\nFor example, creating a Series using the nullable integer dtype:\n\n.. ipython:: python\n\n    s = pd.Series([1, 2, None], dtype=\"Int64\")\n    s\n    s[2]\n\nCompared to ``np.nan``, ``pd.NA`` behaves differently in certain operations.\nIn addition to arithmetic operations, ``pd.NA`` also propagates as \"missing\"\nor \"unknown\" in comparison operations:\n\n.. ipython:: python\n\n    np.nan > 1\n    pd.NA > 1\n\nFor logical operations, ``pd.NA`` follows the rules of the\n`three-valued logic <https://en.wikipedia.org/wiki/Three-valued_logic>`__ (or\n*Kleene logic*). For example:\n\n.. ipython:: python\n\n    pd.NA | True\n\nFor more, see :ref:`NA section <missing_data.NA>` in the user guide on missing\ndata.\n\n\n.. _whatsnew_100.string:\n\nDedicated string data type\n^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nWe've added :class:`StringDtype`, an extension type dedicated to string data.\nPreviously, strings were typically stored in object-dtype NumPy arrays. (:issue:`29975`)\n\n.. warning::\n\n   ``StringDtype`` is currently considered experimental. The implementation\n   and parts of the API may change without warning.\n\nThe ``'string'`` extension type solves several issues with object-dtype NumPy arrays:\n\n1. You can accidentally store a *mixture* of strings and non-strings in an\n   ``object`` dtype array. A ``StringArray`` can only store strings.\n2. ``object`` dtype breaks dtype-specific operations like :meth:`DataFrame.select_dtypes`.\n   There isn't a clear way to select *just* text while excluding non-text,\n   but still object-dtype columns.\n3. When reading code, the contents of an ``object`` dtype array is less clear\n   than ``string``.\n\n\n.. ipython:: python\n\n   pd.Series(['abc', None, 'def'], dtype=pd.StringDtype())\n\nYou can use the alias ``\"string\"`` as well.\n\n.. ipython:: python\n\n   s = pd.Series(['abc', None, 'def'], dtype=\"string\")\n   s\n\nThe usual string accessor methods work. Where appropriate, the return type\nof the Series or columns of a DataFrame will also have string dtype.\n\n.. ipython:: python\n\n   s.str.upper()\n   s.str.split('b', expand=True).dtypes\n\nString accessor methods returning integers will return a value with :class:`Int64Dtype`\n\n.. ipython:: python\n\n   s.str.count(\"a\")\n\nWe recommend explicitly using the ``string`` data type when working with strings.\nSee :ref:`text.types` for more.\n\n.. _whatsnew_100.boolean:\n\nBoolean data type with missing values support\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nWe've added :class:`BooleanDtype` / :class:`~arrays.BooleanArray`, an extension\ntype dedicated to boolean data that can hold missing values. The default\n``bool`` data type based on a bool-dtype NumPy array, the column can only hold\n``True`` or ``False``, and not missing values. This new :class:`~arrays.BooleanArray`\ncan store missing values as well by keeping track of this in a separate mask.\n(:issue:`29555`, :issue:`30095`, :issue:`31131`)\n\n.. ipython:: python\n\n   pd.Series([True, False, None], dtype=pd.BooleanDtype())\n\nYou can use the alias ``\"boolean\"`` as well.\n\n.. ipython:: python\n\n   s = pd.Series([True, False, None], dtype=\"boolean\")\n   s\n\n.. _whatsnew_100.convert_dtypes:\n\nMethod ``convert_dtypes`` to ease use of supported extension dtypes\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nIn order to encourage use of the extension dtypes ``StringDtype``,\n``BooleanDtype``, ``Int64Dtype``, ``Int32Dtype``, etc., that support ``pd.NA``, the\nmethods :meth:`DataFrame.convert_dtypes` and :meth:`Series.convert_dtypes`\nhave been introduced. (:issue:`29752`) (:issue:`30929`)\n\nExample:\n\n.. ipython:: python\n\n   df = pd.DataFrame({'x': ['abc', None, 'def'],\n                      'y': [1, 2, np.nan],\n                      'z': [True, False, True]})\n   df\n   df.dtypes\n\n.. ipython:: python\n\n   converted = df.convert_dtypes()\n   converted\n   converted.dtypes\n\nThis is especially useful after reading in data using readers such as :func:`read_csv`\nand :func:`read_excel`.\nSee :ref:`here <missing_data.NA.conversion>` for a description.\n\n\n.. _whatsnew_100.enhancements.other:\n\nOther enhancements\n~~~~~~~~~~~~~~~~~~\n\n- :meth:`DataFrame.to_string` added the ``max_colwidth`` parameter to control when wide columns are truncated (:issue:`9784`)\n- Added the ``na_value`` argument to :meth:`Series.to_numpy`, :meth:`Index.to_numpy` and :meth:`DataFrame.to_numpy` to control the value used for missing data (:issue:`30322`)\n- :meth:`MultiIndex.from_product` infers level names from inputs if not explicitly provided (:issue:`27292`)\n- :meth:`DataFrame.to_latex` now accepts ``caption`` and ``label`` arguments (:issue:`25436`)\n- DataFrames with :ref:`nullable integer <integer_na>`, the :ref:`new string dtype <text.types>`\n  and period data type can now be converted to ``pyarrow`` (>=0.15.0), which means that it is\n  supported in writing to the Parquet file format when using the ``pyarrow`` engine (:issue:`28368`).\n  Full roundtrip to parquet (writing and reading back in with :meth:`~DataFrame.to_parquet` / :func:`read_parquet`)\n  is supported starting with pyarrow >= 0.16 (:issue:`20612`).\n- :func:`to_parquet` now appropriately handles the ``schema`` argument for user defined schemas in the pyarrow engine. (:issue:`30270`)\n- :meth:`DataFrame.to_json` now accepts an ``indent`` integer argument to enable pretty printing of JSON output (:issue:`12004`)\n- :meth:`read_stata` can read Stata 119 dta files. (:issue:`28250`)\n- Implemented :meth:`.Window.var` and :meth:`.Window.std` functions (:issue:`26597`)\n- Added ``encoding`` argument to :meth:`DataFrame.to_string` for non-ascii text (:issue:`28766`)\n- Added ``encoding`` argument to :func:`DataFrame.to_html` for non-ascii text (:issue:`28663`)\n- :meth:`Styler.background_gradient` now accepts ``vmin`` and ``vmax`` arguments (:issue:`12145`)\n- :meth:`Styler.format` added the ``na_rep`` parameter to help format the missing values (:issue:`21527`, :issue:`28358`)\n- :func:`read_excel` now can read binary Excel (``.xlsb``) files by passing ``engine='pyxlsb'``. For more details and example usage, see the :ref:`Binary Excel files documentation <io.xlsb>`. Closes :issue:`8540`.\n- The ``partition_cols`` argument in :meth:`DataFrame.to_parquet` now accepts a string (:issue:`27117`)\n- :func:`pandas.read_json` now parses ``NaN``, ``Infinity`` and ``-Infinity`` (:issue:`12213`)\n- DataFrame constructor preserve ``ExtensionArray`` dtype with ``ExtensionArray`` (:issue:`11363`)\n- :meth:`DataFrame.sort_values` and :meth:`Series.sort_values` have gained ``ignore_index`` keyword to be able to reset index after sorting (:issue:`30114`)\n- :meth:`DataFrame.sort_index` and :meth:`Series.sort_index` have gained ``ignore_index`` keyword to reset index (:issue:`30114`)\n- :meth:`DataFrame.drop_duplicates` has gained ``ignore_index`` keyword to reset index (:issue:`30114`)\n- Added new writer for exporting Stata dta files in versions 118 and 119, ``StataWriterUTF8``.  These files formats support exporting strings containing Unicode characters. Format 119 supports data sets with more than 32,767 variables (:issue:`23573`, :issue:`30959`)\n- :meth:`Series.map` now accepts ``collections.abc.Mapping`` subclasses as a mapper (:issue:`29733`)\n- Added an experimental :attr:`~DataFrame.attrs` for storing global metadata about a dataset (:issue:`29062`)\n- :meth:`Timestamp.fromisocalendar` is now compatible with python 3.8 and above (:issue:`28115`)\n- :meth:`DataFrame.to_pickle` and :func:`read_pickle` now accept URL (:issue:`30163`)\n\n\n\n.. ---------------------------------------------------------------------------\n\n.. _whatsnew_100.api_breaking:\n\nBackwards incompatible API changes\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\n.. _whatsnew_100.api_breaking.MultiIndex._names:\n\nAvoid using names from ``MultiIndex.levels``\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nAs part of a larger refactor to :class:`MultiIndex` the level names are now\nstored separately from the levels (:issue:`27242`). We recommend using\n:attr:`MultiIndex.names` to access the names, and :meth:`Index.set_names`\nto update the names.\n\nFor backwards compatibility, you can still *access* the names via the levels.\n\n.. ipython:: python\n\n   mi = pd.MultiIndex.from_product([[1, 2], ['a', 'b']], names=['x', 'y'])\n   mi.levels[0].name\n\nHowever, it is no longer possible to *update* the names of the ``MultiIndex``\nvia the level.\n\n.. ipython:: python\n   :okexcept:\n\n   mi.levels[0].name = \"new name\"\n   mi.names\n\nTo update, use ``MultiIndex.set_names``, which returns a new ``MultiIndex``.\n\n.. ipython:: python\n\n   mi2 = mi.set_names(\"new name\", level=0)\n   mi2.names\n\nNew repr for :class:`~pandas.arrays.IntervalArray`\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n:class:`pandas.arrays.IntervalArray` adopts a new ``__repr__`` in accordance with other array classes (:issue:`25022`)\n\n*pandas 0.25.x*\n\n.. code-block:: ipython\n\n   In [1]: pd.arrays.IntervalArray.from_tuples([(0, 1), (2, 3)])\n   Out[2]:\n   IntervalArray([(0, 1], (2, 3]],\n                 closed='right',\n                 dtype='interval[int64]')\n\n*pandas 1.0.0*\n\n.. ipython:: python\n\n   pd.arrays.IntervalArray.from_tuples([(0, 1), (2, 3)])\n\n``DataFrame.rename`` now only accepts one positional argument\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n:meth:`DataFrame.rename` would previously accept positional arguments that would lead\nto ambiguous or undefined behavior. From pandas 1.0, only the very first argument, which\nmaps labels to their new names along the default axis, is allowed to be passed by position\n(:issue:`29136`).\n\n.. ipython:: python\n   :suppress:\n\n   df = pd.DataFrame([[1]])\n\n*pandas 0.25.x*\n\n.. code-block:: ipython\n\n   In [1]: df = pd.DataFrame([[1]])\n   In [2]: df.rename({0: 1}, {0: 2})\n   Out[2]:\n   FutureWarning: ...Use named arguments to resolve ambiguity...\n      2\n   1  1\n\n*pandas 1.0.0*\n\n.. code-block:: ipython\n\n   In [3]: df.rename({0: 1}, {0: 2})\n   Traceback (most recent call last):\n   ...\n   TypeError: rename() takes from 1 to 2 positional arguments but 3 were given\n\nNote that errors will now be raised when conflicting or potentially ambiguous arguments are provided.\n\n*pandas 0.25.x*\n\n.. code-block:: ipython\n\n   In [4]: df.rename({0: 1}, index={0: 2})\n   Out[4]:\n      0\n   1  1\n\n   In [5]: df.rename(mapper={0: 1}, index={0: 2})\n   Out[5]:\n      0\n   2  1\n\n*pandas 1.0.0*\n\n.. code-block:: ipython\n\n   In [6]: df.rename({0: 1}, index={0: 2})\n   Traceback (most recent call last):\n   ...\n   TypeError: Cannot specify both 'mapper' and any of 'index' or 'columns'\n\n   In [7]: df.rename(mapper={0: 1}, index={0: 2})\n   Traceback (most recent call last):\n   ...\n   TypeError: Cannot specify both 'mapper' and any of 'index' or 'columns'\n\nYou can still change the axis along which the first positional argument is applied by\nsupplying the ``axis`` keyword argument.\n\n.. ipython:: python\n\n   df.rename({0: 1})\n   df.rename({0: 1}, axis=1)\n\nIf you would like to update both the index and column labels, be sure to use the respective\nkeywords.\n\n.. ipython:: python\n\n   df.rename(index={0: 1}, columns={0: 2})\n\nExtended verbose info output for :class:`~pandas.DataFrame`\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n:meth:`DataFrame.info` now shows line numbers for the columns summary (:issue:`17304`)\n\n*pandas 0.25.x*\n\n.. code-block:: ipython\n\n   In [1]: df = pd.DataFrame({\"int_col\": [1, 2, 3],\n   ...                    \"text_col\": [\"a\", \"b\", \"c\"],\n   ...                    \"float_col\": [0.0, 0.1, 0.2]})\n   In [2]: df.info(verbose=True)\n   <class 'pandas.core.frame.DataFrame'>\n   RangeIndex: 3 entries, 0 to 2\n   Data columns (total 3 columns):\n   int_col      3 non-null int64\n   text_col     3 non-null object\n   float_col    3 non-null float64\n   dtypes: float64(1), int64(1), object(1)\n   memory usage: 152.0+ bytes\n\n*pandas 1.0.0*\n\n.. ipython:: python\n\n   df = pd.DataFrame({\"int_col\": [1, 2, 3],\n                      \"text_col\": [\"a\", \"b\", \"c\"],\n                      \"float_col\": [0.0, 0.1, 0.2]})\n   df.info(verbose=True)\n\n:meth:`pandas.array` inference changes\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n:meth:`pandas.array` now infers pandas' new extension types in several cases (:issue:`29791`):\n\n1. String data (including missing values) now returns a :class:`arrays.StringArray`.\n2. Integer data (including missing values) now returns a :class:`arrays.IntegerArray`.\n3. Boolean data (including missing values) now returns the new :class:`arrays.BooleanArray`\n\n*pandas 0.25.x*\n\n.. code-block:: ipython\n\n   In [1]: pd.array([\"a\", None])\n   Out[1]:\n   <PandasArray>\n   ['a', None]\n   Length: 2, dtype: object\n\n   In [2]: pd.array([1, None])\n   Out[2]:\n   <PandasArray>\n   [1, None]\n   Length: 2, dtype: object\n\n\n*pandas 1.0.0*\n\n.. ipython:: python\n\n   pd.array([\"a\", None])\n   pd.array([1, None])\n\nAs a reminder, you can specify the ``dtype`` to disable all inference.\n\n:class:`arrays.IntegerArray` now uses :attr:`pandas.NA`\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n:class:`arrays.IntegerArray` now uses :attr:`pandas.NA` rather than\n:attr:`numpy.nan` as its missing value marker (:issue:`29964`).\n\n*pandas 0.25.x*\n\n.. code-block:: ipython\n\n   In [1]: a = pd.array([1, 2, None], dtype=\"Int64\")\n   In [2]: a\n   Out[2]:\n   <IntegerArray>\n   [1, 2, NaN]\n   Length: 3, dtype: Int64\n\n   In [3]: a[2]\n   Out[3]:\n   nan\n\n*pandas 1.0.0*\n\n.. ipython:: python\n\n   a = pd.array([1, 2, None], dtype=\"Int64\")\n   a\n   a[2]\n\nThis has a few API-breaking consequences.\n\n**Converting to a NumPy ndarray**\n\nWhen converting to a NumPy array missing values will be ``pd.NA``, which cannot\nbe converted to a float. So calling ``np.asarray(integer_array, dtype=\"float\")``\nwill now raise.\n\n*pandas 0.25.x*\n\n.. code-block:: ipython\n\n    In [1]: np.asarray(a, dtype=\"float\")\n    Out[1]:\n    array([ 1.,  2., nan])\n\n*pandas 1.0.0*\n\n.. ipython:: python\n   :okexcept:\n\n   np.asarray(a, dtype=\"float\")\n\nUse :meth:`arrays.IntegerArray.to_numpy` with an explicit ``na_value`` instead.\n\n.. ipython:: python\n\n   a.to_numpy(dtype=\"float\", na_value=np.nan)\n\n**Reductions can return** ``pd.NA``\n\nWhen performing a reduction such as a sum with ``skipna=False``, the result\nwill now be ``pd.NA`` instead of ``np.nan`` in presence of missing values\n(:issue:`30958`).\n\n*pandas 0.25.x*\n\n.. code-block:: ipython\n\n    In [1]: pd.Series(a).sum(skipna=False)\n    Out[1]:\n    nan\n\n*pandas 1.0.0*\n\n.. ipython:: python\n\n   pd.Series(a).sum(skipna=False)\n\n**value_counts returns a nullable integer dtype**\n\n:meth:`Series.value_counts` with a nullable integer dtype now returns a nullable\ninteger dtype for the values.\n\n*pandas 0.25.x*\n\n.. code-block:: ipython\n\n   In [1]: pd.Series([2, 1, 1, None], dtype=\"Int64\").value_counts().dtype\n   Out[1]:\n   dtype('int64')\n\n*pandas 1.0.0*\n\n.. ipython:: python\n\n   pd.Series([2, 1, 1, None], dtype=\"Int64\").value_counts().dtype\n\nSee :ref:`missing_data.NA` for more on the differences between :attr:`pandas.NA`\nand :attr:`numpy.nan`.\n\n:class:`arrays.IntegerArray` comparisons return :class:`arrays.BooleanArray`\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nComparison operations on a :class:`arrays.IntegerArray` now returns a\n:class:`arrays.BooleanArray` rather than a NumPy array (:issue:`29964`).\n\n*pandas 0.25.x*\n\n.. code-block:: ipython\n\n   In [1]: a = pd.array([1, 2, None], dtype=\"Int64\")\n   In [2]: a\n   Out[2]:\n   <IntegerArray>\n   [1, 2, NaN]\n   Length: 3, dtype: Int64\n\n   In [3]: a > 1\n   Out[3]:\n   array([False,  True, False])\n\n*pandas 1.0.0*\n\n.. ipython:: python\n\n   a = pd.array([1, 2, None], dtype=\"Int64\")\n   a > 1\n\nNote that missing values now propagate, rather than always comparing unequal\nlike :attr:`numpy.nan`. See :ref:`missing_data.NA` for more.\n\nBy default :meth:`Categorical.min` now returns the minimum instead of np.nan\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nWhen :class:`Categorical` contains ``np.nan``,\n:meth:`Categorical.min` no longer return ``np.nan`` by default (skipna=True) (:issue:`25303`)\n\n*pandas 0.25.x*\n\n.. code-block:: ipython\n\n   In [1]: pd.Categorical([1, 2, np.nan], ordered=True).min()\n   Out[1]: nan\n\n\n*pandas 1.0.0*\n\n.. ipython:: python\n\n   pd.Categorical([1, 2, np.nan], ordered=True).min()\n\n\nDefault dtype of empty :class:`pandas.Series`\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nInitialising an empty :class:`pandas.Series` without specifying a dtype will raise a ``DeprecationWarning`` now\n(:issue:`17261`). The default dtype will change from ``float64`` to ``object`` in future releases so that it is\nconsistent with the behaviour of :class:`DataFrame` and :class:`Index`.\n\n*pandas 1.0.0*\n\n.. code-block:: ipython\n\n   In [1]: pd.Series()\n   Out[2]:\n   DeprecationWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n   Series([], dtype: float64)\n\nResult dtype inference changes for resample operations\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nThe rules for the result dtype in :meth:`DataFrame.resample` aggregations have changed for extension types (:issue:`31359`).\nPreviously, pandas would attempt to convert the result back to the original dtype, falling back to the usual\ninference rules if that was not possible. Now, pandas will only return a result of the original dtype if the\nscalar values in the result are instances of the extension dtype's scalar type.\n\n.. ipython:: python\n\n   df = pd.DataFrame({\"A\": ['a', 'b']}, dtype='category',\n                     index=pd.date_range('2000', periods=2))\n   df\n\n\n*pandas 0.25.x*\n\n.. code-block:: ipython\n\n   In [1]> df.resample(\"2D\").agg(lambda x: 'a').A.dtype\n   Out[1]:\n   CategoricalDtype(categories=['a', 'b'], ordered=False)\n\n*pandas 1.0.0*\n\n.. ipython:: python\n\n   df.resample(\"2D\").agg(lambda x: 'a').A.dtype\n\nThis fixes an inconsistency between ``resample`` and ``groupby``.\nThis also fixes a potential bug, where the **values** of the result might change\ndepending on how the results are cast back to the original dtype.\n\n*pandas 0.25.x*\n\n.. code-block:: ipython\n\n   In [1] df.resample(\"2D\").agg(lambda x: 'c')\n   Out[1]:\n\n        A\n   0  NaN\n\n*pandas 1.0.0*\n\n.. ipython:: python\n\n   df.resample(\"2D\").agg(lambda x: 'c')\n\n\n.. _whatsnew_100.api_breaking.python:\n\nIncreased minimum version for Python\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\npandas 1.0.0 supports Python 3.6.1 and higher (:issue:`29212`).\n\n.. _whatsnew_100.api_breaking.deps:\n\nIncreased minimum versions for dependencies\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nSome minimum supported versions of dependencies were updated (:issue:`29766`, :issue:`29723`).\nIf installed, we now require:\n\n+-----------------+-----------------+----------+---------+\n| Package         | Minimum Version | Required | Changed |\n+=================+=================+==========+=========+\n| numpy           | 1.13.3          |    X     |         |\n+-----------------+-----------------+----------+---------+\n| pytz            | 2015.4          |    X     |         |\n+-----------------+-----------------+----------+---------+\n| python-dateutil | 2.6.1           |    X     |         |\n+-----------------+-----------------+----------+---------+\n| bottleneck      | 1.2.1           |          |         |\n+-----------------+-----------------+----------+---------+\n| numexpr         | 2.6.2           |          |         |\n+-----------------+-----------------+----------+---------+\n| pytest (dev)    | 4.0.2           |          |         |\n+-----------------+-----------------+----------+---------+\n\nFor `optional libraries <https://pandas.pydata.org/docs/getting_started/install.html>`_ the general recommendation is to use the latest version.\nThe following table lists the lowest version per library that is currently being tested throughout the development of pandas.\nOptional libraries below the lowest tested version may still work, but are not considered supported.\n\n+-----------------+-----------------+---------+\n| Package         | Minimum Version | Changed |\n+=================+=================+=========+\n| beautifulsoup4  | 4.6.0           |         |\n+-----------------+-----------------+---------+\n| fastparquet     | 0.3.2           |    X    |\n+-----------------+-----------------+---------+\n| gcsfs           | 0.2.2           |         |\n+-----------------+-----------------+---------+\n| lxml            | 3.8.0           |         |\n+-----------------+-----------------+---------+\n| matplotlib      | 2.2.2           |         |\n+-----------------+-----------------+---------+\n| numba           | 0.46.0          |    X    |\n+-----------------+-----------------+---------+\n| openpyxl        | 2.5.7           |    X    |\n+-----------------+-----------------+---------+\n| pyarrow         | 0.13.0          |    X    |\n+-----------------+-----------------+---------+\n| pymysql         | 0.7.1           |         |\n+-----------------+-----------------+---------+\n| pytables        | 3.4.2           |         |\n+-----------------+-----------------+---------+\n| s3fs            | 0.3.0           |    X    |\n+-----------------+-----------------+---------+\n| scipy           | 0.19.0          |         |\n+-----------------+-----------------+---------+\n| sqlalchemy      | 1.1.4           |         |\n+-----------------+-----------------+---------+\n| xarray          | 0.8.2           |         |\n+-----------------+-----------------+---------+\n| xlrd            | 1.1.0           |         |\n+-----------------+-----------------+---------+\n| xlsxwriter      | 0.9.8           |         |\n+-----------------+-----------------+---------+\n| xlwt            | 1.2.0           |         |\n+-----------------+-----------------+---------+\n\nSee :ref:`install.dependencies` and :ref:`install.optional_dependencies` for more.\n\nBuild changes\n^^^^^^^^^^^^^\n\npandas has added a `pyproject.toml <https://www.python.org/dev/peps/pep-0517/>`_ file and will no longer include\ncythonized files in the source distribution uploaded to PyPI (:issue:`28341`, :issue:`20775`). If you're installing\na built distribution (wheel) or via conda, this shouldn't have any effect on you. If you're building pandas from\nsource, you should no longer need to install Cython into your build environment before calling ``pip install pandas``.\n\n\n.. _whatsnew_100.api.other:\n\nOther API changes\n^^^^^^^^^^^^^^^^^\n\n- :meth:`.DataFrameGroupBy.transform` and :meth:`.SeriesGroupBy.transform` now raises on invalid operation names (:issue:`27489`)\n- :meth:`pandas.api.types.infer_dtype` will now return \"integer-na\" for integer and ``np.nan`` mix (:issue:`27283`)\n- :meth:`MultiIndex.from_arrays` will no longer infer names from arrays if ``names=None`` is explicitly provided (:issue:`27292`)\n- In order to improve tab-completion, pandas does not include most deprecated attributes when introspecting a pandas object using ``dir`` (e.g. ``dir(df)``).\n  To see which attributes are excluded, see an object's ``_deprecations`` attribute, for example ``pd.DataFrame._deprecations`` (:issue:`28805`).\n- The returned dtype of :func:`unique` now matches the input dtype. (:issue:`27874`)\n- Changed the default configuration value for ``options.matplotlib.register_converters`` from ``True`` to ``\"auto\"`` (:issue:`18720`).\n  Now, pandas custom formatters will only be applied to plots created by pandas, through :meth:`~DataFrame.plot`.\n  Previously, pandas' formatters would be applied to all plots created *after* a :meth:`~DataFrame.plot`.\n  See :ref:`units registration <whatsnew_100.matplotlib_units>` for more.\n- :meth:`Series.dropna` has dropped its ``**kwargs`` argument in favor of a single ``how`` parameter.\n  Supplying anything else than ``how`` to ``**kwargs`` raised a ``TypeError`` previously (:issue:`29388`)\n- When testing pandas, the new minimum required version of pytest is 5.0.1 (:issue:`29664`)\n- :meth:`Series.str.__iter__` was deprecated and will be removed in future releases (:issue:`28277`).\n- Added ``<NA>`` to the list of default NA values for :meth:`read_csv` (:issue:`30821`)\n\n.. _whatsnew_100.api.documentation:\n\nDocumentation improvements\n^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n- Added new section on :ref:`scale` (:issue:`28315`).\n- Added sub-section on :ref:`io.query_multi` for HDF5 datasets (:issue:`28791`).\n\n.. ---------------------------------------------------------------------------\n\n.. _whatsnew_100.deprecations:\n\nDeprecations\n~~~~~~~~~~~~\n\n- :meth:`Series.item` and :meth:`Index.item` have been _undeprecated_ (:issue:`29250`)\n- ``Index.set_value`` has been deprecated. For a given index ``idx``, array ``arr``,\n  value in ``idx`` of ``idx_val`` and a new value of ``val``, ``idx.set_value(arr, idx_val, val)``\n  is equivalent to ``arr[idx.get_loc(idx_val)] = val``, which should be used instead (:issue:`28621`).\n- :func:`is_extension_type` is deprecated, :func:`is_extension_array_dtype` should be used instead (:issue:`29457`)\n- :func:`eval` keyword argument \"truediv\" is deprecated and will be removed in a future version (:issue:`29812`)\n- :meth:`DateOffset.isAnchored` and :meth:`DatetOffset.onOffset` are deprecated and will be removed in a future version, use :meth:`DateOffset.is_anchored` and :meth:`DateOffset.is_on_offset` instead (:issue:`30340`)\n- ``pandas.tseries.frequencies.get_offset`` is deprecated and will be removed in a future version, use ``pandas.tseries.frequencies.to_offset`` instead (:issue:`4205`)\n- :meth:`Categorical.take_nd` and :meth:`CategoricalIndex.take_nd` are deprecated, use :meth:`Categorical.take` and :meth:`CategoricalIndex.take` instead (:issue:`27745`)\n- The parameter ``numeric_only`` of :meth:`Categorical.min` and :meth:`Categorical.max` is deprecated and replaced with ``skipna`` (:issue:`25303`)\n- The parameter ``label`` in :func:`lreshape` has been deprecated and will be removed in a future version (:issue:`29742`)\n- ``pandas.core.index`` has been deprecated and will be removed in a future version, the public classes are available in the top-level namespace (:issue:`19711`)\n- :func:`pandas.json_normalize` is now exposed in the top-level namespace.\n  Usage of ``json_normalize`` as ``pandas.io.json.json_normalize`` is now deprecated and\n  it is recommended to use ``json_normalize`` as :func:`pandas.json_normalize` instead (:issue:`27586`).\n- The ``numpy`` argument of :meth:`pandas.read_json` is deprecated (:issue:`28512`).\n- :meth:`DataFrame.to_stata`, :meth:`DataFrame.to_feather`, and :meth:`DataFrame.to_parquet` argument \"fname\" is deprecated, use \"path\" instead (:issue:`23574`)\n- The deprecated internal attributes ``_start``, ``_stop`` and ``_step`` of :class:`RangeIndex` now raise a ``FutureWarning`` instead of a ``DeprecationWarning`` (:issue:`26581`)\n- The ``pandas.util.testing`` module has been deprecated. Use the public API in ``pandas.testing`` documented at :ref:`api.general.testing` (:issue:`16232`).\n- ``pandas.SparseArray`` has been deprecated.  Use ``pandas.arrays.SparseArray`` (:class:`arrays.SparseArray`) instead. (:issue:`30642`)\n- The parameter ``is_copy`` of :meth:`Series.take` and :meth:`DataFrame.take` has been deprecated and will be removed in a future version. (:issue:`27357`)\n- Support for multi-dimensional indexing (e.g. ``index[:, None]``) on a :class:`Index` is deprecated and will be removed in a future version, convert to a numpy array before indexing instead (:issue:`30588`)\n- The ``pandas.np`` submodule is now deprecated. Import numpy directly instead (:issue:`30296`)\n- The ``pandas.datetime`` class is now deprecated. Import from ``datetime`` instead (:issue:`30610`)\n- :class:`~DataFrame.diff` will raise a ``TypeError`` rather than implicitly losing the dtype of extension types in the future. Convert to the correct dtype before calling ``diff`` instead (:issue:`31025`)\n\n**Selecting Columns from a Grouped DataFrame**\n\nWhen selecting columns from a :class:`DataFrameGroupBy` object, passing individual keys (or a tuple of keys) inside single brackets is deprecated,\na list of items should be used instead. (:issue:`23566`) For example:\n\n.. code-block:: ipython\n\n    df = pd.DataFrame({\n        \"A\": [\"foo\", \"bar\", \"foo\", \"bar\", \"foo\", \"bar\", \"foo\", \"foo\"],\n        \"B\": np.random.randn(8),\n        \"C\": np.random.randn(8),\n    })\n    g = df.groupby('A')\n\n     single key, returns SeriesGroupBy\n    g['B']\n\n     tuple of single key, returns SeriesGroupBy\n    g[('B',)]\n\n     tuple of multiple keys, returns DataFrameGroupBy, raises FutureWarning\n    g[('B', 'C')]\n\n     multiple keys passed directly, returns DataFrameGroupBy, raises FutureWarning\n     (implicitly converts the passed strings into a single tuple)\n    g['B', 'C']\n\n     proper way, returns DataFrameGroupBy\n    g[['B', 'C']]\n\n.. ---------------------------------------------------------------------------\n\n.. _whatsnew_100.prior_deprecations:\n\nRemoval of prior version deprecations/changes\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\n**Removed SparseSeries and SparseDataFrame**\n\n``SparseSeries``, ``SparseDataFrame`` and the ``DataFrame.to_sparse`` method\nhave been removed (:issue:`28425`). We recommend using a ``Series`` or\n``DataFrame`` with sparse values instead.\n\n.. _whatsnew_100.matplotlib_units:\n\n**Matplotlib unit registration**\n\nPreviously, pandas would register converters with matplotlib as a side effect of importing pandas (:issue:`18720`).\nThis changed the output of plots made via matplotlib plots after pandas was imported, even if you were using\nmatplotlib directly rather than :meth:`~DataFrame.plot`.\n\nTo use pandas formatters with a matplotlib plot, specify\n\n.. code-block:: ipython\n\n   In [1]: import pandas as pd\n   In [2]: pd.options.plotting.matplotlib.register_converters = True\n\nNote that plots created by :meth:`DataFrame.plot` and :meth:`Series.plot` *do* register the converters\nautomatically. The only behavior change is when plotting a date-like object via ``matplotlib.pyplot.plot``\nor ``matplotlib.Axes.plot``. See :ref:`plotting.formatters` for more.\n\n**Other removals**\n\n- Removed the previously deprecated keyword \"index\" from :func:`read_stata`, :class:`StataReader`, and :meth:`StataReader.read`, use \"index_col\" instead (:issue:`17328`)\n- Removed ``StataReader.data`` method, use :meth:`StataReader.read` instead (:issue:`9493`)\n- Removed ``pandas.plotting._matplotlib.tsplot``, use :meth:`Series.plot` instead (:issue:`19980`)\n- ``pandas.tseries.converter.register`` has been moved to :func:`pandas.plotting.register_matplotlib_converters` (:issue:`18307`)\n- :meth:`Series.plot` no longer accepts positional arguments, pass keyword arguments instead (:issue:`30003`)\n- :meth:`DataFrame.hist` and :meth:`Series.hist` no longer allows ``figsize=\"default\"``, specify figure size by passinig a tuple instead (:issue:`30003`)\n- Floordiv of integer-dtyped array by :class:`Timedelta` now raises ``TypeError`` (:issue:`21036`)\n- :class:`TimedeltaIndex` and :class:`DatetimeIndex` no longer accept non-nanosecond dtype strings like \"timedelta64\" or \"datetime64\", use \"timedelta64[ns]\" and \"datetime64[ns]\" instead (:issue:`24806`)\n- Changed the default \"skipna\" argument in :func:`pandas.api.types.infer_dtype` from ``False`` to ``True`` (:issue:`24050`)\n- Removed ``Series.ix`` and ``DataFrame.ix`` (:issue:`26438`)\n- Removed ``Index.summary`` (:issue:`18217`)\n- Removed the previously deprecated keyword \"fastpath\" from the :class:`Index` constructor (:issue:`23110`)\n- Removed ``Series.get_value``, ``Series.set_value``, ``DataFrame.get_value``, ``DataFrame.set_value`` (:issue:`17739`)\n- Removed ``Series.compound`` and ``DataFrame.compound`` (:issue:`26405`)\n- Changed the default \"inplace\" argument in :meth:`DataFrame.set_index` and :meth:`Series.set_axis` from ``None`` to ``False`` (:issue:`27600`)\n- Removed ``Series.cat.categorical``, ``Series.cat.index``, ``Series.cat.name`` (:issue:`24751`)\n- Removed the previously deprecated keyword \"box\" from :func:`to_datetime` and :func:`to_timedelta`; in addition these now always returns :class:`DatetimeIndex`, :class:`TimedeltaIndex`, :class:`Index`, :class:`Series`, or :class:`DataFrame` (:issue:`24486`)\n- :func:`to_timedelta`, :class:`Timedelta`, and :class:`TimedeltaIndex` no longer allow \"M\", \"y\", or \"Y\" for the \"unit\" argument (:issue:`23264`)\n- Removed the previously deprecated keyword \"time_rule\" from (non-public) ``offsets.generate_range``, which has been moved to :func:`core.arrays._ranges.generate_range` (:issue:`24157`)\n- :meth:`DataFrame.loc` or :meth:`Series.loc` with listlike indexers and missing labels will no longer reindex (:issue:`17295`)\n- :meth:`DataFrame.to_excel` and :meth:`Series.to_excel` with non-existent columns will no longer reindex (:issue:`17295`)\n- Removed the previously deprecated keyword \"join_axes\" from :func:`concat`; use ``reindex_like`` on the result instead (:issue:`22318`)\n- Removed the previously deprecated keyword \"by\" from :meth:`DataFrame.sort_index`, use :meth:`DataFrame.sort_values` instead (:issue:`10726`)\n- Removed support for nested renaming in :meth:`DataFrame.aggregate`, :meth:`Series.aggregate`, :meth:`core.groupby.DataFrameGroupBy.aggregate`, :meth:`core.groupby.SeriesGroupBy.aggregate`, :meth:`core.window.rolling.Rolling.aggregate` (:issue:`18529`)\n- Passing ``datetime64`` data to :class:`TimedeltaIndex` or ``timedelta64`` data to ``DatetimeIndex`` now raises ``TypeError`` (:issue:`23539`, :issue:`23937`)\n- Passing ``int64`` values to :class:`DatetimeIndex` and a timezone now interprets the values as nanosecond timestamps in UTC, not wall times in the given timezone (:issue:`24559`)\n- A tuple passed to :meth:`DataFrame.groupby` is now exclusively treated as a single key (:issue:`18314`)\n- Removed ``Index.contains``, use ``key in index`` instead (:issue:`30103`)\n- Addition and subtraction of ``int`` or integer-arrays is no longer allowed in :class:`Timestamp`, :class:`DatetimeIndex`, :class:`TimedeltaIndex`, use ``obj + n * obj.freq`` instead of ``obj + n`` (:issue:`22535`)\n- Removed ``Series.ptp`` (:issue:`21614`)\n- Removed ``Series.from_array`` (:issue:`18258`)\n- Removed ``DataFrame.from_items`` (:issue:`18458`)\n- Removed ``DataFrame.as_matrix``, ``Series.as_matrix`` (:issue:`18458`)\n- Removed ``Series.asobject`` (:issue:`18477`)\n- Removed ``DataFrame.as_blocks``, ``Series.as_blocks``, ``DataFrame.blocks``, ``Series.blocks`` (:issue:`17656`)\n- :meth:`pandas.Series.str.cat` now defaults to aligning ``others``, using ``join='left'`` (:issue:`27611`)\n- :meth:`pandas.Series.str.cat` does not accept list-likes *within* list-likes anymore (:issue:`27611`)\n- :meth:`Series.where` with ``Categorical`` dtype (or :meth:`DataFrame.where` with ``Categorical`` column) no longer allows setting new categories (:issue:`24114`)\n- Removed the previously deprecated keywords \"start\", \"end\", and \"periods\" from the :class:`DatetimeIndex`, :class:`TimedeltaIndex`, and :class:`PeriodIndex` constructors; use :func:`date_range`, :func:`timedelta_range`, and :func:`period_range` instead (:issue:`23919`)\n- Removed the previously deprecated keyword \"verify_integrity\" from the :class:`DatetimeIndex` and :class:`TimedeltaIndex` constructors (:issue:`23919`)\n- Removed the previously deprecated keyword \"fastpath\" from ``pandas.core.internals.blocks.make_block`` (:issue:`19265`)\n- Removed the previously deprecated keyword \"dtype\" from :meth:`Block.make_block_same_class` (:issue:`19434`)\n- Removed ``ExtensionArray._formatting_values``. Use :attr:`ExtensionArray._formatter` instead. (:issue:`23601`)\n- Removed ``MultiIndex.to_hierarchical`` (:issue:`21613`)\n- Removed ``MultiIndex.labels``, use :attr:`MultiIndex.codes` instead (:issue:`23752`)\n- Removed the previously deprecated keyword \"labels\" from the :class:`MultiIndex` constructor, use \"codes\" instead (:issue:`23752`)\n- Removed ``MultiIndex.set_labels``, use :meth:`MultiIndex.set_codes` instead (:issue:`23752`)\n- Removed the previously deprecated keyword \"labels\" from :meth:`MultiIndex.set_codes`, :meth:`MultiIndex.copy`, :meth:`MultiIndex.drop`, use \"codes\" instead (:issue:`23752`)\n- Removed support for legacy HDF5 formats (:issue:`29787`)\n- Passing a dtype alias (e.g. 'datetime64[ns, UTC]') to :class:`DatetimeTZDtype` is no longer allowed, use :meth:`DatetimeTZDtype.construct_from_string` instead (:issue:`23990`)\n- Removed the previously deprecated keyword \"skip_footer\" from :func:`read_excel`; use \"skipfooter\" instead (:issue:`18836`)\n- :func:`read_excel` no longer allows an integer value for the parameter ``usecols``, instead pass a list of integers from 0 to ``usecols`` inclusive (:issue:`23635`)\n- Removed the previously deprecated keyword \"convert_datetime64\" from :meth:`DataFrame.to_records` (:issue:`18902`)\n- Removed ``IntervalIndex.from_intervals`` in favor of the :class:`IntervalIndex` constructor (:issue:`19263`)\n- Changed the default \"keep_tz\" argument in :meth:`DatetimeIndex.to_series` from ``None`` to ``True`` (:issue:`23739`)\n- Removed ``api.types.is_period`` and ``api.types.is_datetimetz`` (:issue:`23917`)\n- Ability to read pickles containing :class:`Categorical` instances created with pre-0.16 version of pandas has been removed (:issue:`27538`)\n- Removed ``pandas.tseries.plotting.tsplot`` (:issue:`18627`)\n- Removed the previously deprecated keywords \"reduce\" and \"broadcast\" from :meth:`DataFrame.apply` (:issue:`18577`)\n- Removed the previously deprecated ``assert_raises_regex`` function in ``pandas._testing`` (:issue:`29174`)\n- Removed the previously deprecated ``FrozenNDArray`` class in ``pandas.core.indexes.frozen`` (:issue:`29335`)\n- Removed the previously deprecated keyword \"nthreads\" from :func:`read_feather`, use \"use_threads\" instead (:issue:`23053`)\n- Removed ``Index.is_lexsorted_for_tuple`` (:issue:`29305`)\n- Removed support for nested renaming in :meth:`DataFrame.aggregate`, :meth:`Series.aggregate`, :meth:`core.groupby.DataFrameGroupBy.aggregate`, :meth:`core.groupby.SeriesGroupBy.aggregate`, :meth:`core.window.rolling.Rolling.aggregate` (:issue:`29608`)\n- Removed ``Series.valid``; use :meth:`Series.dropna` instead (:issue:`18800`)\n- Removed ``DataFrame.is_copy``, ``Series.is_copy`` (:issue:`18812`)\n- Removed ``DataFrame.get_ftype_counts``, ``Series.get_ftype_counts`` (:issue:`18243`)\n- Removed ``DataFrame.ftypes``, ``Series.ftypes``, ``Series.ftype`` (:issue:`26744`)\n- Removed ``Index.get_duplicates``, use ``idx[idx.duplicated()].unique()`` instead (:issue:`20239`)\n- Removed ``Series.clip_upper``, ``Series.clip_lower``, ``DataFrame.clip_upper``, ``DataFrame.clip_lower`` (:issue:`24203`)\n- Removed the ability to alter :attr:`DatetimeIndex.freq`, :attr:`TimedeltaIndex.freq`, or :attr:`PeriodIndex.freq` (:issue:`20772`)\n- Removed ``DatetimeIndex.offset`` (:issue:`20730`)\n- Removed ``DatetimeIndex.asobject``, ``TimedeltaIndex.asobject``, ``PeriodIndex.asobject``, use ``astype(object)`` instead (:issue:`29801`)\n- Removed the previously deprecated keyword \"order\" from :func:`factorize` (:issue:`19751`)\n- Removed the previously deprecated keyword \"encoding\" from :func:`read_stata` and :meth:`DataFrame.to_stata` (:issue:`21400`)\n- Changed the default \"sort\" argument in :func:`concat` from ``None`` to ``False`` (:issue:`20613`)\n- Removed the previously deprecated keyword \"raise_conflict\" from :meth:`DataFrame.update`, use \"errors\" instead (:issue:`23585`)\n- Removed the previously deprecated keyword \"n\" from :meth:`DatetimeIndex.shift`, :meth:`TimedeltaIndex.shift`, :meth:`PeriodIndex.shift`, use \"periods\" instead (:issue:`22458`)\n- Removed the previously deprecated keywords \"how\", \"fill_method\", and \"limit\" from :meth:`DataFrame.resample` (:issue:`30139`)\n- Passing an integer to :meth:`Series.fillna` or :meth:`DataFrame.fillna` with ``timedelta64[ns]`` dtype now raises ``TypeError`` (:issue:`24694`)\n- Passing multiple axes to :meth:`DataFrame.dropna` is no longer supported (:issue:`20995`)\n- Removed ``Series.nonzero``, use ``to_numpy().nonzero()`` instead (:issue:`24048`)\n- Passing floating dtype ``codes`` to :meth:`Categorical.from_codes` is no longer supported, pass ``codes.astype(np.int64)`` instead (:issue:`21775`)\n- Removed the previously deprecated keyword \"pat\" from :meth:`Series.str.partition` and :meth:`Series.str.rpartition`, use \"sep\" instead (:issue:`23767`)\n- Removed ``Series.put`` (:issue:`27106`)\n- Removed ``Series.real``, ``Series.imag`` (:issue:`27106`)\n- Removed ``Series.to_dense``, ``DataFrame.to_dense`` (:issue:`26684`)\n- Removed ``Index.dtype_str``, use ``str(index.dtype)`` instead (:issue:`27106`)\n- :meth:`Categorical.ravel` returns a :class:`Categorical` instead of a ``ndarray`` (:issue:`27199`)\n- The 'outer' method on Numpy ufuncs, e.g. ``np.subtract.outer`` operating on :class:`Series` objects is no longer supported, and will raise ``NotImplementedError`` (:issue:`27198`)\n- Removed ``Series.get_dtype_counts`` and ``DataFrame.get_dtype_counts`` (:issue:`27145`)\n- Changed the default \"fill_value\" argument in :meth:`Categorical.take` from ``True`` to ``False`` (:issue:`20841`)\n- Changed the default value for the ``raw`` argument in :func:`Series.rolling().apply() <.Rolling.apply>`, :func:`DataFrame.rolling().apply() <.Rolling.apply>`, :func:`Series.expanding().apply() <.Expanding.apply>`, and :func:`DataFrame.expanding().apply() <.Expanding.apply>` from ``None`` to ``False`` (:issue:`20584`)\n- Removed deprecated behavior of :meth:`Series.argmin` and :meth:`Series.argmax`, use :meth:`Series.idxmin` and :meth:`Series.idxmax` for the old behavior (:issue:`16955`)\n- Passing a tz-aware ``datetime.datetime`` or :class:`Timestamp` into the :class:`Timestamp` constructor with the ``tz`` argument now raises a ``ValueError`` (:issue:`23621`)\n- Removed ``Series.base``, ``Index.base``, ``Categorical.base``, ``Series.flags``, ``Index.flags``, ``PeriodArray.flags``, ``Series.strides``, ``Index.strides``, ``Series.itemsize``, ``Index.itemsize``, ``Series.data``, ``Index.data`` (:issue:`20721`)\n- Changed :meth:`Timedelta.resolution` to match the behavior of the standard library ``datetime.timedelta.resolution``, for the old behavior, use :meth:`Timedelta.resolution_string` (:issue:`26839`)\n- Removed ``Timestamp.weekday_name``, ``DatetimeIndex.weekday_name``, and ``Series.dt.weekday_name`` (:issue:`18164`)\n- Removed the previously deprecated keyword \"errors\" in :meth:`Timestamp.tz_localize`, :meth:`DatetimeIndex.tz_localize`, and :meth:`Series.tz_localize` (:issue:`22644`)\n- Changed the default \"ordered\" argument in :class:`CategoricalDtype` from ``None`` to ``False`` (:issue:`26336`)\n- :meth:`Series.set_axis` and :meth:`DataFrame.set_axis` now require \"labels\" as the first argument and \"axis\" as an optional named parameter (:issue:`30089`)\n- Removed ``to_msgpack``, ``read_msgpack``, ``DataFrame.to_msgpack``, ``Series.to_msgpack`` (:issue:`27103`)\n- Removed ``Series.compress`` (:issue:`21930`)\n- Removed the previously deprecated keyword \"fill_value\" from :meth:`Categorical.fillna`, use \"value\" instead (:issue:`19269`)\n- Removed the previously deprecated keyword \"data\" from :func:`andrews_curves`, use \"frame\" instead (:issue:`6956`)\n- Removed the previously deprecated keyword \"data\" from :func:`parallel_coordinates`, use \"frame\" instead (:issue:`6956`)\n- Removed the previously deprecated keyword \"colors\" from :func:`parallel_coordinates`, use \"color\" instead (:issue:`6956`)\n- Removed the previously deprecated keywords \"verbose\" and \"private_key\" from :func:`read_gbq` (:issue:`30200`)\n- Calling ``np.array`` and ``np.asarray`` on tz-aware :class:`Series` and :class:`DatetimeIndex` will now return an object array of tz-aware :class:`Timestamp` (:issue:`24596`)\n-\n\n.. ---------------------------------------------------------------------------\n\n.. _whatsnew_100.performance:\n\nPerformance improvements\n~~~~~~~~~~~~~~~~~~~~~~~~\n\n- Performance improvement in :class:`DataFrame` arithmetic and comparison operations with scalars (:issue:`24990`, :issue:`29853`)\n- Performance improvement in indexing with a non-unique :class:`IntervalIndex` (:issue:`27489`)\n- Performance improvement in :attr:`MultiIndex.is_monotonic` (:issue:`27495`)\n- Performance improvement in :func:`cut` when ``bins`` is an :class:`IntervalIndex` (:issue:`27668`)\n- Performance improvement when initializing a :class:`DataFrame` using a ``range`` (:issue:`30171`)\n- Performance improvement in :meth:`DataFrame.corr` when ``method`` is ``\"spearman\"`` (:issue:`28139`)\n- Performance improvement in :meth:`DataFrame.replace` when provided a list of values to replace (:issue:`28099`)\n- Performance improvement in :meth:`DataFrame.select_dtypes` by using vectorization instead of iterating over a loop (:issue:`28317`)\n- Performance improvement in :meth:`Categorical.searchsorted` and  :meth:`CategoricalIndex.searchsorted` (:issue:`28795`)\n- Performance improvement when comparing a :class:`Categorical` with a scalar and the scalar is not found in the categories (:issue:`29750`)\n- Performance improvement when checking if values in a :class:`Categorical` are equal, equal or larger or larger than a given scalar.\n  The improvement is not present if checking if the :class:`Categorical` is less than or less than or equal than the scalar (:issue:`29820`)\n- Performance improvement in :meth:`Index.equals` and  :meth:`MultiIndex.equals` (:issue:`29134`)\n- Performance improvement in :func:`~pandas.api.types.infer_dtype` when ``skipna`` is ``True`` (:issue:`28814`)\n\n.. ---------------------------------------------------------------------------\n\n.. _whatsnew_100.bug_fixes:\n\nBug fixes\n~~~~~~~~~\n\n\nCategorical\n^^^^^^^^^^^\n\n- Added test to assert the :func:`fillna` raises the correct ``ValueError`` message when the value isn't a value from categories (:issue:`13628`)\n- Bug in :meth:`Categorical.astype` where ``NaN`` values were handled incorrectly when casting to int (:issue:`28406`)\n- :meth:`DataFrame.reindex` with a :class:`CategoricalIndex` would fail when the targets contained duplicates, and wouldn't fail if the source contained duplicates (:issue:`28107`)\n- Bug in :meth:`Categorical.astype` not allowing for casting to extension dtypes (:issue:`28668`)\n- Bug where :func:`merge` was unable to join on categorical and extension dtype columns (:issue:`28668`)\n- :meth:`Categorical.searchsorted` and :meth:`CategoricalIndex.searchsorted` now work on unordered categoricals also (:issue:`21667`)\n- Added test to assert roundtripping to parquet with :func:`DataFrame.to_parquet` or :func:`read_parquet` will preserve Categorical dtypes for string types (:issue:`27955`)\n- Changed the error message in :meth:`Categorical.remove_categories` to always show the invalid removals as a set (:issue:`28669`)\n- Using date accessors on a categorical dtyped :class:`Series` of datetimes was not returning an object of the\n  same type as if one used the :meth:`.str.` / :meth:`.dt.` on a :class:`Series` of that type. E.g. when accessing :meth:`Series.dt.tz_localize` on a\n  :class:`Categorical` with duplicate entries, the accessor was skipping duplicates (:issue:`27952`)\n- Bug in :meth:`DataFrame.replace` and :meth:`Series.replace` that would give incorrect results on categorical data (:issue:`26988`)\n- Bug where calling :meth:`Categorical.min` or :meth:`Categorical.max` on an empty Categorical would raise a numpy exception (:issue:`30227`)\n- The following methods now also correctly output values for unobserved categories when called through ``groupby(..., observed=False)`` (:issue:`17605`)\n  * :meth:`core.groupby.SeriesGroupBy.count`\n  * :meth:`core.groupby.SeriesGroupBy.size`\n  * :meth:`core.groupby.SeriesGroupBy.nunique`\n  * :meth:`core.groupby.SeriesGroupBy.nth`\n\n\nDatetimelike\n^^^^^^^^^^^^\n- Bug in :meth:`Series.__setitem__` incorrectly casting ``np.timedelta64(\"NaT\")`` to ``np.datetime64(\"NaT\")`` when inserting into a :class:`Series` with datetime64 dtype (:issue:`27311`)\n- Bug in :meth:`Series.dt` property lookups when the underlying data is read-only (:issue:`27529`)\n- Bug in ``HDFStore.__getitem__`` incorrectly reading tz attribute created in Python 2 (:issue:`26443`)\n- Bug in :func:`to_datetime` where passing arrays of malformed ``str`` with errors=\"coerce\" could incorrectly lead to raising ``ValueError`` (:issue:`28299`)\n- Bug in :meth:`core.groupby.SeriesGroupBy.nunique` where ``NaT`` values were interfering with the count of unique values (:issue:`27951`)\n- Bug in :class:`Timestamp` subtraction when subtracting a :class:`Timestamp` from a ``np.datetime64`` object incorrectly raising ``TypeError`` (:issue:`28286`)\n- Addition and subtraction of integer or integer-dtype arrays with :class:`Timestamp` will now raise ``NullFrequencyError`` instead of ``ValueError`` (:issue:`28268`)\n- Bug in :class:`Series` and :class:`DataFrame` with integer dtype failing to raise ``TypeError`` when adding or subtracting a ``np.datetime64`` object (:issue:`28080`)\n- Bug in :meth:`Series.astype`, :meth:`Index.astype`, and :meth:`DataFrame.astype` failing to handle ``NaT`` when casting to an integer dtype (:issue:`28492`)\n- Bug in :class:`Week` with ``weekday`` incorrectly raising ``AttributeError`` instead of ``TypeError`` when adding or subtracting an invalid type (:issue:`28530`)\n- Bug in :class:`DataFrame` arithmetic operations when operating with a :class:`Series` with dtype ``'timedelta64[ns]'`` (:issue:`28049`)\n- Bug in :func:`core.groupby.generic.SeriesGroupBy.apply` raising ``ValueError`` when a column in the original DataFrame is a datetime and the column labels are not standard integers (:issue:`28247`)\n- Bug in :func:`pandas._config.localization.get_locales` where the ``locales -a`` encodes the locales list as windows-1252 (:issue:`23638`, :issue:`24760`, :issue:`27368`)\n- Bug in :meth:`Series.var` failing to raise ``TypeError`` when called with ``timedelta64[ns]`` dtype (:issue:`28289`)\n- Bug in :meth:`DatetimeIndex.strftime` and :meth:`Series.dt.strftime` where ``NaT`` was converted to the string ``'NaT'`` instead of ``np.nan`` (:issue:`29578`)\n- Bug in masking datetime-like arrays with a boolean mask of an incorrect length not raising an ``IndexError`` (:issue:`30308`)\n- Bug in :attr:`Timestamp.resolution` being a property instead of a class attribute (:issue:`29910`)\n- Bug in :func:`pandas.to_datetime` when called with ``None`` raising ``TypeError`` instead of returning ``NaT`` (:issue:`30011`)\n- Bug in :func:`pandas.to_datetime` failing for ``deque`` objects when using ``cache=True`` (the default) (:issue:`29403`)\n- Bug in :meth:`Series.item` with ``datetime64`` or ``timedelta64`` dtype, :meth:`DatetimeIndex.item`, and :meth:`TimedeltaIndex.item` returning an integer instead of a :class:`Timestamp` or :class:`Timedelta` (:issue:`30175`)\n- Bug in :class:`DatetimeIndex` addition when adding a non-optimized :class:`DateOffset` incorrectly dropping timezone information (:issue:`30336`)\n- Bug in :meth:`DataFrame.drop` where attempting to drop non-existent values from a DatetimeIndex would yield a confusing error message (:issue:`30399`)\n- Bug in :meth:`DataFrame.append` would remove the timezone-awareness of new data (:issue:`30238`)\n- Bug in :meth:`Series.cummin` and :meth:`Series.cummax` with timezone-aware dtype incorrectly dropping its timezone (:issue:`15553`)\n- Bug in :class:`DatetimeArray`, :class:`TimedeltaArray`, and :class:`PeriodArray` where inplace addition and subtraction did not actually operate inplace (:issue:`24115`)\n- Bug in :func:`pandas.to_datetime` when called with ``Series`` storing ``IntegerArray`` raising ``TypeError`` instead of returning ``Series`` (:issue:`30050`)\n- Bug in :func:`date_range` with custom business hours as ``freq`` and given number of ``periods`` (:issue:`30593`)\n- Bug in :class:`PeriodIndex` comparisons with incorrectly casting integers to :class:`Period` objects, inconsistent with the :class:`Period` comparison behavior (:issue:`30722`)\n- Bug in :meth:`DatetimeIndex.insert` raising a ``ValueError`` instead of a ``TypeError`` when trying to insert a timezone-aware :class:`Timestamp` into a timezone-naive :class:`DatetimeIndex`, or vice-versa (:issue:`30806`)\n\nTimedelta\n^^^^^^^^^\n- Bug in subtracting a :class:`TimedeltaIndex` or :class:`TimedeltaArray` from a ``np.datetime64`` object (:issue:`29558`)\n-\n\nTimezones\n^^^^^^^^^\n\n-\n\n\nNumeric\n^^^^^^^\n- Bug in :meth:`DataFrame.quantile` with zero-column :class:`DataFrame` incorrectly raising (:issue:`23925`)\n- :class:`DataFrame` flex inequality comparisons methods (:meth:`DataFrame.lt`, :meth:`DataFrame.le`, :meth:`DataFrame.gt`, :meth:`DataFrame.ge`) with object-dtype and ``complex`` entries failing to raise ``TypeError`` like their :class:`Series` counterparts (:issue:`28079`)\n- Bug in :class:`DataFrame` logical operations (``&``, ``|``, ``^``) not matching :class:`Series` behavior by filling NA values (:issue:`28741`)\n- Bug in :meth:`DataFrame.interpolate` where specifying axis by name references variable before it is assigned (:issue:`29142`)\n- Bug in :meth:`Series.var` not computing the right value with a nullable integer dtype series not passing through ddof argument (:issue:`29128`)\n- Improved error message when using ``frac`` > 1 and ``replace`` = False (:issue:`27451`)\n- Bug in numeric indexes resulted in it being possible to instantiate an :class:`Int64Index`, :class:`UInt64Index`, or :class:`Float64Index` with an invalid dtype (e.g. datetime-like) (:issue:`29539`)\n- Bug in :class:`UInt64Index` precision loss while constructing from a list with values in the ``np.uint64`` range (:issue:`29526`)\n- Bug in :class:`NumericIndex` construction that caused indexing to fail when integers in the ``np.uint64`` range were used (:issue:`28023`)\n- Bug in :class:`NumericIndex` construction that caused :class:`UInt64Index` to be casted to :class:`Float64Index` when integers in the ``np.uint64`` range were used to index a :class:`DataFrame` (:issue:`28279`)\n- Bug in :meth:`Series.interpolate` when using method=`index` with an unsorted index, would previously return incorrect results. (:issue:`21037`)\n- Bug in :meth:`DataFrame.round` where a :class:`DataFrame` with a :class:`CategoricalIndex` of :class:`IntervalIndex` columns would incorrectly raise a ``TypeError`` (:issue:`30063`)\n- Bug in :meth:`Series.pct_change` and :meth:`DataFrame.pct_change` when there are duplicated indices (:issue:`30463`)\n- Bug in :class:`DataFrame` cumulative operations (e.g. cumsum, cummax) incorrect casting to object-dtype (:issue:`19296`)\n- Bug in :class:`~DataFrame.diff` losing the dtype for extension types (:issue:`30889`)\n- Bug in :class:`DataFrame.diff` raising an ``IndexError`` when one of the columns was a nullable integer dtype (:issue:`30967`)\n\nConversion\n^^^^^^^^^^\n\n-\n\nStrings\n^^^^^^^\n\n- Calling :meth:`Series.str.isalnum` (and other \"ismethods\") on an empty ``Series`` would return an ``object`` dtype instead of ``bool`` (:issue:`29624`)\n-\n\n\nInterval\n^^^^^^^^\n\n- Bug in :meth:`IntervalIndex.get_indexer` where a :class:`Categorical` or :class:`CategoricalIndex` ``target`` would incorrectly raise a ``TypeError`` (:issue:`30063`)\n- Bug in ``pandas.core.dtypes.cast.infer_dtype_from_scalar`` where passing ``pandas_dtype=True`` did not infer :class:`IntervalDtype` (:issue:`30337`)\n- Bug in :class:`Series` constructor where constructing a ``Series`` from a ``list`` of :class:`Interval` objects resulted in ``object`` dtype instead of :class:`IntervalDtype` (:issue:`23563`)\n- Bug in :class:`IntervalDtype` where the ``kind`` attribute was incorrectly set as ``None`` instead of ``\"O\"`` (:issue:`30568`)\n- Bug in :class:`IntervalIndex`, :class:`~arrays.IntervalArray`, and :class:`Series` with interval data where equality comparisons were incorrect (:issue:`24112`)\n\nIndexing\n^^^^^^^^\n\n- Bug in assignment using a reverse slicer (:issue:`26939`)\n- Bug in :meth:`DataFrame.explode` would duplicate frame in the presence of duplicates in the index (:issue:`28010`)\n- Bug in reindexing a :meth:`PeriodIndex` with another type of index that contained a ``Period`` (:issue:`28323`) (:issue:`28337`)\n- Fix assignment of column via ``.loc`` with numpy non-ns datetime type (:issue:`27395`)\n- Bug in :meth:`Float64Index.astype` where ``np.inf`` was not handled properly when casting to an integer dtype (:issue:`28475`)\n- :meth:`Index.union` could fail when the left contained duplicates (:issue:`28257`)\n- Bug when indexing with ``.loc`` where the index was a :class:`CategoricalIndex` with non-string categories didn't work (:issue:`17569`, :issue:`30225`)\n- :meth:`Index.get_indexer_non_unique` could fail with ``TypeError`` in some cases, such as when searching for ints in a string index (:issue:`28257`)\n- Bug in :meth:`Float64Index.get_loc` incorrectly raising ``TypeError`` instead of ``KeyError`` (:issue:`29189`)\n- Bug in :meth:`DataFrame.loc` with incorrect dtype when setting Categorical value in 1-row DataFrame (:issue:`25495`)\n- :meth:`MultiIndex.get_loc` can't find missing values when input includes missing values (:issue:`19132`)\n- Bug in :meth:`Series.__setitem__` incorrectly assigning values with boolean indexer when the length of new data matches the number of ``True`` values and new data is not a ``Series`` or an ``np.array`` (:issue:`30567`)\n- Bug in indexing with a :class:`PeriodIndex` incorrectly accepting integers representing years, use e.g. ``ser.loc[\"2007\"]`` instead of ``ser.loc[2007]`` (:issue:`30763`)\n\nMissing\n^^^^^^^\n\n-\n\nMultiIndex\n^^^^^^^^^^\n\n- Constructor for :class:`MultiIndex` verifies that the given ``sortorder`` is compatible with the actual ``lexsort_depth``  if ``verify_integrity`` parameter is ``True`` (the default) (:issue:`28735`)\n- Series and MultiIndex ``.drop`` with ``MultiIndex`` raise exception if labels not in given in level (:issue:`8594`)\n-\n\nIO\n^^\n\n- :meth:`read_csv` now accepts binary mode file buffers when using the Python csv engine (:issue:`23779`)\n- Bug in :meth:`DataFrame.to_json` where using a Tuple as a column or index value and using ``orient=\"columns\"`` or ``orient=\"index\"`` would produce invalid JSON (:issue:`20500`)\n- Improve infinity parsing. :meth:`read_csv` now interprets ``Infinity``, ``+Infinity``, ``-Infinity`` as floating point values (:issue:`10065`)\n- Bug in :meth:`DataFrame.to_csv` where values were truncated when the length of ``na_rep`` was shorter than the text input data. (:issue:`25099`)\n- Bug in :func:`DataFrame.to_string` where values were truncated using display options instead of outputting the full content (:issue:`9784`)\n- Bug in :meth:`DataFrame.to_json` where a datetime column label would not be written out in ISO format with ``orient=\"table\"`` (:issue:`28130`)\n- Bug in :func:`DataFrame.to_parquet` where writing to GCS would fail with ``engine='fastparquet'`` if the file did not already exist (:issue:`28326`)\n- Bug in :func:`read_hdf` closing stores that it didn't open when Exceptions are raised (:issue:`28699`)\n- Bug in :meth:`DataFrame.read_json` where using ``orient=\"index\"`` would not maintain the order (:issue:`28557`)\n- Bug in :meth:`DataFrame.to_html` where the length of the ``formatters`` argument was not verified (:issue:`28469`)\n- Bug in :meth:`DataFrame.read_excel` with ``engine='ods'`` when ``sheet_name`` argument references a non-existent sheet (:issue:`27676`)\n- Bug in :meth:`pandas.io.formats.style.Styler` formatting for floating values not displaying decimals correctly (:issue:`13257`)\n- Bug in :meth:`DataFrame.to_html` when using ``formatters=<list>`` and ``max_cols`` together. (:issue:`25955`)\n- Bug in :meth:`Styler.background_gradient` not able to work with dtype ``Int64`` (:issue:`28869`)\n- Bug in :meth:`DataFrame.to_clipboard` which did not work reliably in ipython (:issue:`22707`)\n- Bug in :func:`read_json` where default encoding was not set to ``utf-8`` (:issue:`29565`)\n- Bug in :class:`PythonParser` where str and bytes were being mixed when dealing with the decimal field (:issue:`29650`)\n- :meth:`read_gbq` now accepts ``progress_bar_type`` to display progress bar while the data downloads. (:issue:`29857`)\n- Bug in :func:`pandas.io.json.json_normalize` where a missing value in the location specified by ``record_path`` would raise a ``TypeError`` (:issue:`30148`)\n- :func:`read_excel` now accepts binary data (:issue:`15914`)\n- Bug in :meth:`read_csv` in which encoding handling was limited to just the string ``utf-16`` for the C engine (:issue:`24130`)\n\nPlotting\n^^^^^^^^\n\n- Bug in :meth:`Series.plot` not able to plot boolean values (:issue:`23719`)\n- Bug in :meth:`DataFrame.plot` not able to plot when no rows (:issue:`27758`)\n- Bug in :meth:`DataFrame.plot` producing incorrect legend markers when plotting multiple series on the same axis (:issue:`18222`)\n- Bug in :meth:`DataFrame.plot` when ``kind='box'`` and data contains datetime or timedelta data. These types are now automatically dropped (:issue:`22799`)\n- Bug in :meth:`DataFrame.plot.line` and :meth:`DataFrame.plot.area` produce wrong xlim in x-axis (:issue:`27686`, :issue:`25160`, :issue:`24784`)\n- Bug where :meth:`DataFrame.boxplot` would not accept a ``color`` parameter like :meth:`DataFrame.plot.box` (:issue:`26214`)\n- Bug in the ``xticks`` argument being ignored for :meth:`DataFrame.plot.bar` (:issue:`14119`)\n- :func:`set_option` now validates that the plot backend provided to ``'plotting.backend'`` implements the backend when the option is set, rather than when a plot is created (:issue:`28163`)\n- :meth:`DataFrame.plot` now allow a ``backend`` keyword argument to allow changing between backends in one session (:issue:`28619`).\n- Bug in color validation incorrectly raising for non-color styles (:issue:`29122`).\n- Allow :meth:`DataFrame.plot.scatter` to plot ``objects`` and ``datetime`` type data (:issue:`18755`, :issue:`30391`)\n- Bug in :meth:`DataFrame.hist`, ``xrot=0`` does not work with ``by`` and subplots (:issue:`30288`).\n\nGroupBy/resample/rolling\n^^^^^^^^^^^^^^^^^^^^^^^^\n\n- Bug in :meth:`core.groupby.DataFrameGroupBy.apply` only showing output from a single group when function returns an :class:`Index` (:issue:`28652`)\n- Bug in :meth:`DataFrame.groupby` with multiple groups where an ``IndexError`` would be raised if any group contained all NA values (:issue:`20519`)\n- Bug in :meth:`.Resampler.size` and :meth:`.Resampler.count` returning wrong dtype when used with an empty :class:`Series` or :class:`DataFrame` (:issue:`28427`)\n- Bug in :meth:`DataFrame.rolling` not allowing for rolling over datetimes when ``axis=1`` (:issue:`28192`)\n- Bug in :meth:`DataFrame.rolling` not allowing rolling over multi-index levels (:issue:`15584`).\n- Bug in :meth:`DataFrame.rolling` not allowing rolling on monotonic decreasing time indexes (:issue:`19248`).\n- Bug in :meth:`DataFrame.groupby` not offering selection by column name when ``axis=1`` (:issue:`27614`)\n- Bug in :meth:`core.groupby.DataFrameGroupby.agg` not able to use lambda function with named aggregation (:issue:`27519`)\n- Bug in :meth:`DataFrame.groupby` losing column name information when grouping by a categorical column (:issue:`28787`)\n- Remove error raised due to duplicated input functions in named aggregation in :meth:`DataFrame.groupby` and :meth:`Series.groupby`. Previously error will be raised if the same function is applied on the same column and now it is allowed if new assigned names are different. (:issue:`28426`)\n- :meth:`core.groupby.SeriesGroupBy.value_counts` will be able to handle the case even when the :class:`Grouper` makes empty groups (:issue:`28479`)\n- Bug in :meth:`core.window.rolling.Rolling.quantile` ignoring ``interpolation`` keyword argument when used within a groupby (:issue:`28779`)\n- Bug in :meth:`DataFrame.groupby` where ``any``, ``all``, ``nunique`` and transform functions would incorrectly handle duplicate column labels (:issue:`21668`)\n- Bug in :meth:`core.groupby.DataFrameGroupBy.agg` with timezone-aware datetime64 column incorrectly casting results to the original dtype (:issue:`29641`)\n- Bug in :meth:`DataFrame.groupby` when using axis=1 and having a single level columns index (:issue:`30208`)\n- Bug in :meth:`DataFrame.groupby` when using nunique on axis=1 (:issue:`30253`)\n- Bug in :meth:`.DataFrameGroupBy.quantile` and :meth:`.SeriesGroupBy.quantile` with multiple list-like q value and integer column names (:issue:`30289`)\n- Bug in :meth:`.DataFrameGroupBy.pct_change` and :meth:`.SeriesGroupBy.pct_change` causes ``TypeError`` when ``fill_method`` is ``None`` (:issue:`30463`)\n- Bug in :meth:`Rolling.count` and :meth:`Expanding.count` argument where ``min_periods`` was ignored (:issue:`26996`)\n\nReshaping\n^^^^^^^^^\n\n- Bug in :meth:`DataFrame.apply` that caused incorrect output with empty :class:`DataFrame` (:issue:`28202`, :issue:`21959`)\n- Bug in :meth:`DataFrame.stack` not handling non-unique indexes correctly when creating MultiIndex (:issue:`28301`)\n- Bug in :meth:`pivot_table` not returning correct type ``float`` when ``margins=True`` and ``aggfunc='mean'`` (:issue:`24893`)\n- Bug :func:`merge_asof` could not use :class:`datetime.timedelta` for ``tolerance`` kwarg (:issue:`28098`)\n- Bug in :func:`merge`, did not append suffixes correctly with MultiIndex (:issue:`28518`)\n- :func:`qcut` and :func:`cut` now handle boolean input (:issue:`20303`)\n- Fix to ensure all int dtypes can be used in :func:`merge_asof` when using a tolerance value. Previously every non-int64 type would raise an erroneous ``MergeError`` (:issue:`28870`).\n- Better error message in :func:`get_dummies` when ``columns`` isn't a list-like value (:issue:`28383`)\n- Bug in :meth:`Index.join` that caused infinite recursion error for mismatched ``MultiIndex`` name orders. (:issue:`25760`, :issue:`28956`)\n- Bug :meth:`Series.pct_change` where supplying an anchored frequency would throw a ``ValueError`` (:issue:`28664`)\n- Bug where :meth:`DataFrame.equals` returned True incorrectly in some cases when two DataFrames had the same columns in different orders (:issue:`28839`)\n- Bug in :meth:`DataFrame.replace` that caused non-numeric replacer's dtype not respected (:issue:`26632`)\n- Bug in :func:`melt` where supplying mixed strings and numeric values for ``id_vars`` or ``value_vars`` would incorrectly raise a ``ValueError`` (:issue:`29718`)\n- Dtypes are now preserved when transposing a ``DataFrame`` where each column is the same extension dtype (:issue:`30091`)\n- Bug in :func:`merge_asof` merging on a tz-aware ``left_index`` and ``right_on`` a tz-aware column (:issue:`29864`)\n- Improved error message and docstring in :func:`cut` and :func:`qcut` when ``labels=True`` (:issue:`13318`)\n- Bug in missing ``fill_na`` parameter to :meth:`DataFrame.unstack` with list of levels (:issue:`30740`)\n\nSparse\n^^^^^^\n- Bug in :class:`SparseDataFrame` arithmetic operations incorrectly casting inputs to float (:issue:`28107`)\n- Bug in ``DataFrame.sparse`` returning a ``Series`` when there was a column named ``sparse`` rather than the accessor (:issue:`30758`)\n- Fixed :meth:`operator.xor` with a boolean-dtype ``SparseArray``. Now returns a sparse result, rather than object dtype (:issue:`31025`)\n\nExtensionArray\n^^^^^^^^^^^^^^\n\n- Bug in :class:`arrays.PandasArray` when setting a scalar string (:issue:`28118`, :issue:`28150`).\n- Bug where nullable integers could not be compared to strings (:issue:`28930`)\n- Bug where :class:`DataFrame` constructor raised ``ValueError`` with list-like data and ``dtype`` specified (:issue:`30280`)\n\nOther\n^^^^^\n- Trying to set the ``display.precision``, ``display.max_rows`` or ``display.max_columns`` using :meth:`set_option` to anything but a ``None`` or a positive int will raise a ``ValueError`` (:issue:`23348`)\n- Using :meth:`DataFrame.replace` with overlapping keys in a nested dictionary will no longer raise, now matching the behavior of a flat dictionary (:issue:`27660`)\n- :meth:`DataFrame.to_csv` and :meth:`Series.to_csv` now support dicts as ``compression`` argument with key ``'method'`` being the compression method and others as additional compression options when the compression method is ``'zip'``. (:issue:`26023`)\n- Bug in :meth:`Series.diff` where a boolean series would incorrectly raise a ``TypeError`` (:issue:`17294`)\n- :meth:`Series.append` will no longer raise a ``TypeError`` when passed a tuple of ``Series`` (:issue:`28410`)\n- Fix corrupted error message when calling ``pandas.libs._json.encode()`` on a 0d array (:issue:`18878`)\n- Backtick quoting in :meth:`DataFrame.query` and :meth:`DataFrame.eval` can now also be used to use invalid identifiers like names that start with a digit, are python keywords, or are using single character operators. (:issue:`27017`)\n- Bug in ``pd.core.util.hashing.hash_pandas_object`` where arrays containing tuples were incorrectly treated as non-hashable (:issue:`28969`)\n- Bug in :meth:`DataFrame.append` that raised ``IndexError`` when appending with empty list (:issue:`28769`)\n- Fix :class:`AbstractHolidayCalendar` to return correct results for\n  years after 2030 (now goes up to 2200) (:issue:`27790`)\n- Fixed :class:`~arrays.IntegerArray` returning ``inf`` rather than ``NaN`` for operations dividing by ``0`` (:issue:`27398`)\n- Fixed ``pow`` operations for :class:`~arrays.IntegerArray` when the other value is ``0`` or ``1`` (:issue:`29997`)\n- Bug in :meth:`Series.count` raises if use_inf_as_na is enabled (:issue:`29478`)\n- Bug in :class:`Index` where a non-hashable name could be set without raising ``TypeError`` (:issue:`29069`)\n- Bug in :class:`DataFrame` constructor when passing a 2D ``ndarray`` and an extension dtype (:issue:`12513`)\n- Bug in :meth:`DataFrame.to_csv` when supplied a series with a ``dtype=\"string\"`` and a ``na_rep``, the ``na_rep`` was being truncated to 2 characters. (:issue:`29975`)\n- Bug where :meth:`DataFrame.itertuples` would incorrectly determine whether or not namedtuples could be used for dataframes of 255 columns (:issue:`28282`)\n- Handle nested NumPy ``object`` arrays in :func:`testing.assert_series_equal` for ExtensionArray implementations (:issue:`30841`)\n- Bug in :class:`Index` constructor incorrectly allowing 2-dimensional input arrays (:issue:`13601`, :issue:`27125`)\n\n.. ---------------------------------------------------------------------------\n\n.. _whatsnew_100.contributors:\n\nContributors\n~~~~~~~~~~~~\n\n.. contributors:: v0.25.3..v1.0.0\n\n\n.. _whatsnew_222:\n\nWhat's new in 2.2.2 (April 10, 2024)\n---------------------------------------\n\nThese are the changes in pandas 2.2.2. See :ref:`release` for a full changelog\nincluding other versions of pandas.\n\n{{ header }}\n\n.. ---------------------------------------------------------------------------\n\n.. _whatsnew_220.np2_compat:\n\nPandas 2.2.2 is now compatible with numpy 2.0\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\nPandas 2.2.2 is the first version of pandas that is generally compatible with the upcoming\nnumpy 2.0 release, and wheels for pandas 2.2.2 will work with both numpy 1.x and 2.x.\n\nOne major caveat is that arrays created with numpy 2.0's new ``StringDtype`` will convert\nto ``object`` dtyped arrays upon :class:`Series`/:class:`DataFrame` creation.\nFull support for numpy 2.0's StringDtype is expected to land in pandas 3.0.\n\nAs usual please report any bugs discovered to our `issue tracker <https://github.com/pandas-dev/pandas/issues/new/choose>`_\n\n.. _whatsnew_222.regressions:\n\nFixed regressions\n~~~~~~~~~~~~~~~~~\n- :meth:`DataFrame.__dataframe__` was producing incorrect data buffers when the a column's type was a pandas nullable on with missing values (:issue:`56702`)\n- :meth:`DataFrame.__dataframe__` was producing incorrect data buffers when the a column's type was a pyarrow nullable on with missing values (:issue:`57664`)\n- Avoid issuing a spurious ``DeprecationWarning`` when a custom :class:`DataFrame` or :class:`Series` subclass method is called (:issue:`57553`)\n- Fixed regression in precision of :func:`to_datetime` with string and ``unit`` input (:issue:`57051`)\n\n.. ---------------------------------------------------------------------------\n.. _whatsnew_222.bug_fixes:\n\nBug fixes\n~~~~~~~~~\n- :meth:`DataFrame.__dataframe__` was producing incorrect data buffers when the column's type was nullable boolean (:issue:`55332`)\n- :meth:`DataFrame.__dataframe__` was showing bytemask instead of bitmask for ``'string[pyarrow]'`` validity buffer (:issue:`57762`)\n- :meth:`DataFrame.__dataframe__` was showing non-null validity buffer (instead of ``None``) ``'string[pyarrow]'`` without missing values (:issue:`57761`)\n- :meth:`DataFrame.to_sql` was failing to find the right table when using the schema argument (:issue:`57539`)\n\n.. ---------------------------------------------------------------------------\n.. _whatsnew_222.other:\n\nOther\n~~~~~\n-\n\n.. ---------------------------------------------------------------------------\n.. _whatsnew_222.contributors:\n\nContributors\n~~~~~~~~~~~~\n\n.. contributors:: v2.2.1..v2.2.2|HEAD\n\n\n.. _whatsnew_0191:\n\nVersion 0.19.1 (November 3, 2016)\n---------------------------------\n\n{{ header }}\n\n.. ipython:: python\n   :suppress:\n\n   from pandas import *   noqa F401, F403\n\n\nThis is a minor bug-fix release from 0.19.0 and includes some small regression fixes,\nbug fixes and performance improvements.\nWe recommend that all users upgrade to this version.\n\n.. contents:: What's new in v0.19.1\n    :local:\n    :backlinks: none\n\n\n.. _whatsnew_0191.performance:\n\nPerformance improvements\n~~~~~~~~~~~~~~~~~~~~~~~~\n\n- Fixed performance regression in factorization of ``Period`` data (:issue:`14338`)\n- Fixed performance regression in ``Series.asof(where)`` when ``where`` is a scalar (:issue:`14461`)\n- Improved performance in ``DataFrame.asof(where)`` when ``where`` is a scalar (:issue:`14461`)\n- Improved performance in ``.to_json()`` when ``lines=True`` (:issue:`14408`)\n- Improved performance in certain types of ``loc`` indexing with a MultiIndex (:issue:`14551`).\n\n\n.. _whatsnew_0191.bug_fixes:\n\nBug fixes\n~~~~~~~~~\n\n- Source installs from PyPI will now again work without ``cython`` installed, as in previous versions (:issue:`14204`)\n- Compat with Cython 0.25 for building (:issue:`14496`)\n- Fixed regression where user-provided file handles were closed in ``read_csv`` (c engine) (:issue:`14418`).\n- Fixed regression in ``DataFrame.quantile`` when missing values where present in some columns (:issue:`14357`).\n- Fixed regression in ``Index.difference`` where the ``freq`` of a ``DatetimeIndex`` was incorrectly set (:issue:`14323`)\n- Added back ``pandas.core.common.array_equivalent`` with a deprecation warning (:issue:`14555`).\n- Bug in ``pd.read_csv`` for the C engine in which quotation marks were improperly parsed in skipped rows (:issue:`14459`)\n- Bug in ``pd.read_csv`` for Python 2.x in which Unicode quote characters were no longer being respected (:issue:`14477`)\n- Fixed regression in ``Index.append`` when categorical indices were appended (:issue:`14545`).\n- Fixed regression in ``pd.DataFrame`` where constructor fails when given dict with ``None`` value (:issue:`14381`)\n- Fixed regression in ``DatetimeIndex._maybe_cast_slice_bound`` when index is empty (:issue:`14354`).\n- Bug in localizing an ambiguous timezone when a boolean is passed (:issue:`14402`)\n- Bug in ``TimedeltaIndex`` addition with a Datetime-like object where addition overflow in the negative direction was not being caught (:issue:`14068`, :issue:`14453`)\n- Bug in string indexing against data with ``object`` ``Index`` may raise ``AttributeError`` (:issue:`14424`)\n- Correctly raise ``ValueError`` on empty input to ``pd.eval()`` and ``df.query()`` (:issue:`13139`)\n- Bug in ``RangeIndex.intersection`` when result is a empty set (:issue:`14364`).\n- Bug in groupby-transform broadcasting that could cause incorrect dtype coercion (:issue:`14457`)\n- Bug in ``Series.__setitem__`` which allowed mutating read-only arrays (:issue:`14359`).\n- Bug in ``DataFrame.insert`` where multiple calls with duplicate columns can fail (:issue:`14291`)\n- ``pd.merge()`` will raise ``ValueError`` with non-boolean parameters in passed boolean type arguments (:issue:`14434`)\n- Bug in ``Timestamp`` where dates very near the minimum (1677-09) could underflow on creation (:issue:`14415`)\n- Bug in ``pd.concat`` where names of the ``keys`` were not propagated to the resulting ``MultiIndex`` (:issue:`14252`)\n- Bug in ``pd.concat`` where ``axis`` cannot take string parameters ``'rows'`` or ``'columns'`` (:issue:`14369`)\n- Bug in ``pd.concat`` with dataframes heterogeneous in length and tuple ``keys`` (:issue:`14438`)\n- Bug in ``MultiIndex.set_levels`` where illegal level values were still set after raising an error (:issue:`13754`)\n- Bug in ``DataFrame.to_json`` where ``lines=True`` and a value contained a ``}`` character (:issue:`14391`)\n- Bug in ``df.groupby`` causing an ``AttributeError`` when grouping a single index frame by a column and the index level (:issue:`14327`)\n- Bug in ``df.groupby`` where ``TypeError`` raised when ``pd.Grouper(key=...)`` is passed in a list (:issue:`14334`)\n- Bug in ``pd.pivot_table`` may raise ``TypeError`` or ``ValueError`` when ``index`` or ``columns``\n  is not scalar and ``values`` is not specified (:issue:`14380`)\n\n\n.. _whatsnew_0.19.1.contributors:\n\nContributors\n~~~~~~~~~~~~\n\n.. contributors:: v0.19.0..v0.19.1\n\n\n.. _whatsnew_114:\n\nWhat's new in 1.1.4 (October 30, 2020)\n--------------------------------------\n\nThese are the changes in pandas 1.1.4. See :ref:`release` for a full changelog\nincluding other versions of pandas.\n\n{{ header }}\n\n.. ---------------------------------------------------------------------------\n\n.. _whatsnew_114.regressions:\n\nFixed regressions\n~~~~~~~~~~~~~~~~~\n- Fixed regression in :func:`read_csv` raising a ``ValueError`` when ``names`` was of type ``dict_keys`` (:issue:`36928`)\n- Fixed regression in :func:`read_csv` with more than 1M rows and specifying a ``index_col`` argument (:issue:`37094`)\n- Fixed regression where attempting to mutate a :class:`DateOffset` object would no longer raise an ``AttributeError`` (:issue:`36940`)\n- Fixed regression where :meth:`DataFrame.agg` would fail with :exc:`TypeError` when passed positional arguments to be passed on to the aggregation function (:issue:`36948`).\n- Fixed regression in :class:`RollingGroupby` with ``sort=False`` not being respected (:issue:`36889`)\n- Fixed regression in :meth:`Series.astype` converting ``None`` to ``\"nan\"`` when casting to string (:issue:`36904`)\n- Fixed regression in :meth:`Series.rank` method failing for read-only data (:issue:`37290`)\n- Fixed regression in :class:`RollingGroupby` causing a segmentation fault with Index of dtype object (:issue:`36727`)\n- Fixed regression in :meth:`DataFrame.resample(...).apply(...)` raised ``AttributeError`` when input was a :class:`DataFrame` and only a :class:`Series` was evaluated (:issue:`36951`)\n- Fixed regression in ``DataFrame.groupby(..).std()`` with nullable integer dtype (:issue:`37415`)\n- Fixed regression in :class:`PeriodDtype` comparing both equal and unequal to its string representation (:issue:`37265`)\n- Fixed regression where slicing :class:`DatetimeIndex` raised :exc:`AssertionError` on irregular time series with ``pd.NaT`` or on unsorted indices (:issue:`36953` and :issue:`35509`)\n- Fixed regression in certain offsets (:meth:`pd.offsets.Day() <pandas.tseries.offsets.Day>` and below) no longer being hashable (:issue:`37267`)\n- Fixed regression in :class:`StataReader` which required ``chunksize`` to be manually set when using an iterator to read a dataset (:issue:`37280`)\n- Fixed regression in setitem with :meth:`DataFrame.iloc` which raised error when trying to set a value while filtering with a boolean list (:issue:`36741`)\n- Fixed regression in setitem with a Series getting aligned before setting the values (:issue:`37427`)\n- Fixed regression in :attr:`MultiIndex.is_monotonic_increasing` returning wrong results with ``NaN`` in at least one of the levels (:issue:`37220`)\n- Fixed regression in inplace arithmetic operation (`+=`) on a Series not updating the parent DataFrame/Series (:issue:`36373`)\n\n.. ---------------------------------------------------------------------------\n\n.. _whatsnew_114.bug_fixes:\n\nBug fixes\n~~~~~~~~~\n- Bug causing ``groupby(...).sum()`` and similar to not preserve metadata (:issue:`29442`)\n- Bug in :meth:`Series.isin` and :meth:`DataFrame.isin` raising a ``ValueError`` when the target was read-only (:issue:`37174`)\n- Bug in :meth:`.DataFrameGroupBy.fillna` and :meth:`.SeriesGroupBy.fillna` that introduced a performance regression after 1.0.5 (:issue:`36757`)\n- Bug in :meth:`DataFrame.info` was raising a ``KeyError`` when the DataFrame has integer column names (:issue:`37245`)\n- Bug in :meth:`DataFrameGroupby.apply` would drop a :class:`CategoricalIndex` when grouped on (:issue:`35792`)\n\n.. ---------------------------------------------------------------------------\n\n.. _whatsnew_114.contributors:\n\nContributors\n~~~~~~~~~~~~\n\n.. contributors:: v1.1.3..v1.1.4\n\n\n.. _whatsnew_0170:\n\nVersion 0.17.0 (October 9, 2015)\n--------------------------------\n\n{{ header }}\n\n\nThis is a major release from 0.16.2 and includes a small number of API changes, several new features,\nenhancements, and performance improvements along with a large number of bug fixes. We recommend that all\nusers upgrade to this version.\n\n.. warning::\n\n   pandas >= 0.17.0 will no longer support compatibility with Python version 3.2 (:issue:`9118`)\n\n.. warning::\n\n   The ``pandas.io.data`` package is deprecated and will be replaced by the\n   `pandas-datareader package <https://github.com/pydata/pandas-datareader>`_.\n   This will allow the data modules to be independently updated to your pandas\n   installation. The API for ``pandas-datareader v0.1.1`` is exactly the same\n   as in ``pandas v0.17.0`` (:issue:`8961`, :issue:`10861`).\n\n   After installing pandas-datareader, you can easily change your imports:\n\n   .. code-block:: python\n\n     from pandas.io import data, wb\n\n   becomes\n\n   .. code-block:: python\n\n     from pandas_datareader import data, wb\n\nHighlights include:\n\n- Release the Global Interpreter Lock (GIL) on some cython operations, see :ref:`here <whatsnew_0170.gil>`\n- Plotting methods are now available as attributes of the ``.plot`` accessor, see :ref:`here <whatsnew_0170.plot>`\n- The sorting API has been revamped to remove some long-time inconsistencies, see :ref:`here <whatsnew_0170.api_breaking.sorting>`\n- Support for a ``datetime64[ns]`` with timezones as a first-class dtype, see :ref:`here <whatsnew_0170.tz>`\n- The default for ``to_datetime`` will now be to ``raise`` when presented with unparsable formats,\n  previously this would return the original input. Also, date parse\n  functions now return consistent results. See :ref:`here <whatsnew_0170.api_breaking.to_datetime>`\n- The default for ``dropna`` in ``HDFStore`` has changed to ``False``, to store by default all rows even\n  if they are all ``NaN``, see :ref:`here <whatsnew_0170.api_breaking.hdf_dropna>`\n- Datetime accessor (``dt``) now supports ``Series.dt.strftime`` to generate formatted strings for datetime-likes, and ``Series.dt.total_seconds`` to generate each duration of the timedelta in seconds. See :ref:`here <whatsnew_0170.strftime>`\n- ``Period`` and ``PeriodIndex`` can handle multiplied freq like ``3D``, which corresponding to 3 days span. See :ref:`here <whatsnew_0170.periodfreq>`\n- Development installed versions of pandas will now have ``PEP440`` compliant version strings (:issue:`9518`)\n- Development support for benchmarking with the `Air Speed Velocity library <https://github.com/spacetelescope/asv/>`_ (:issue:`8361`)\n- Support for reading SAS xport files, see :ref:`here <whatsnew_0170.enhancements.sas_xport>`\n- Documentation comparing SAS to *pandas*, see :ref:`here <compare_with_sas>`\n- Removal of the automatic TimeSeries broadcasting, deprecated since 0.8.0, see :ref:`here <whatsnew_0170.prior_deprecations>`\n- Display format with plain text can optionally align with Unicode East Asian Width, see :ref:`here <whatsnew_0170.east_asian_width>`\n- Compatibility with Python 3.5 (:issue:`11097`)\n- Compatibility with matplotlib 1.5.0 (:issue:`11111`)\n\nCheck the :ref:`API Changes <whatsnew_0170.api>` and :ref:`deprecations <whatsnew_0170.deprecations>` before updating.\n\n.. contents:: What's new in v0.17.0\n    :local:\n    :backlinks: none\n\n.. _whatsnew_0170.enhancements:\n\nNew features\n~~~~~~~~~~~~\n\n.. _whatsnew_0170.tz:\n\nDatetime with TZ\n^^^^^^^^^^^^^^^^\n\nWe are adding an implementation that natively supports datetime with timezones. A ``Series`` or a ``DataFrame`` column previously\n*could* be assigned a datetime with timezones, and would work as an ``object`` dtype. This had performance issues with a large\nnumber rows. See the :ref:`docs <timeseries.timezone_series>` for more details. (:issue:`8260`, :issue:`10763`, :issue:`11034`).\n\nThe new implementation allows for having a single-timezone across all rows, with operations in a performant manner.\n\n.. ipython:: python\n\n   df = pd.DataFrame(\n       {\n           \"A\": pd.date_range(\"20130101\", periods=3),\n           \"B\": pd.date_range(\"20130101\", periods=3, tz=\"US/Eastern\"),\n           \"C\": pd.date_range(\"20130101\", periods=3, tz=\"CET\"),\n       }\n   )\n   df\n   df.dtypes\n\n.. ipython:: python\n\n   df.B\n   df.B.dt.tz_localize(None)\n\nThis uses a new-dtype representation as well, that is very similar in look-and-feel to its numpy cousin ``datetime64[ns]``\n\n.. ipython:: python\n\n   df[\"B\"].dtype\n   type(df[\"B\"].dtype)\n\n.. note::\n\n   There is a slightly different string repr for the underlying ``DatetimeIndex`` as a result of the dtype changes, but\n   functionally these are the same.\n\n   Previous behavior:\n\n   .. code-block:: ipython\n\n      In [1]: pd.date_range('20130101', periods=3, tz='US/Eastern')\n      Out[1]: DatetimeIndex(['2013-01-01 00:00:00-05:00', '2013-01-02 00:00:00-05:00',\n                             '2013-01-03 00:00:00-05:00'],\n                            dtype='datetime64[ns]', freq='D', tz='US/Eastern')\n\n      In [2]: pd.date_range('20130101', periods=3, tz='US/Eastern').dtype\n      Out[2]: dtype('<M8[ns]')\n\n   New behavior:\n\n   .. ipython:: python\n\n      pd.date_range(\"20130101\", periods=3, tz=\"US/Eastern\")\n      pd.date_range(\"20130101\", periods=3, tz=\"US/Eastern\").dtype\n\n.. _whatsnew_0170.gil:\n\nReleasing the GIL\n^^^^^^^^^^^^^^^^^\n\nWe are releasing the global-interpreter-lock (GIL) on some cython operations.\nThis will allow other threads to run simultaneously during computation, potentially allowing performance improvements\nfrom multi-threading. Notably ``groupby``, ``nsmallest``, ``value_counts`` and some indexing operations benefit from this. (:issue:`8882`)\n\nFor example the groupby expression in the following code will have the GIL released during the factorization step, e.g. ``df.groupby('key')``\nas well as the ``.sum()`` operation.\n\n.. code-block:: python\n\n   N = 1000000\n   ngroups = 10\n   df = DataFrame(\n       {\"key\": np.random.randint(0, ngroups, size=N), \"data\": np.random.randn(N)}\n   )\n   df.groupby(\"key\")[\"data\"].sum()\n\nReleasing of the GIL could benefit an application that uses threads for user interactions (e.g. QT_), or performing multi-threaded computations. A nice example of a library that can handle these types of computation-in-parallel is the dask_ library.\n\n.. _dask: https://dask.readthedocs.io/en/latest/\n.. _QT: https://wiki.python.org/moin/PyQt\n\n.. _whatsnew_0170.plot:\n\nPlot submethods\n^^^^^^^^^^^^^^^\n\nThe Series and DataFrame ``.plot()`` method allows for customizing :ref:`plot types<visualization.other>` by supplying the ``kind`` keyword arguments. Unfortunately, many of these kinds of plots use different required and optional keyword arguments, which makes it difficult to discover what any given plot kind uses out of the dozens of possible arguments.\n\nTo alleviate this issue, we have added a new, optional plotting interface, which exposes each kind of plot as a method of the ``.plot`` attribute. Instead of writing ``series.plot(kind=<kind>, ...)``, you can now also use ``series.plot.<kind>(...)``:\n\n.. ipython::\n    :verbatim:\n\n    In [13]: df = pd.DataFrame(np.random.rand(10, 2), columns=['a', 'b'])\n\n    In [14]: df.plot.bar()\n\n.. image:: ../_static/whatsnew_plot_submethods.png\n\nAs a result of this change, these methods are now all discoverable via tab-completion:\n\n.. ipython::\n    :verbatim:\n\n    In [15]: df.plot.<TAB>   noqa: E225, E999\n    df.plot.area     df.plot.barh     df.plot.density  df.plot.hist     df.plot.line     df.plot.scatter\n    df.plot.bar      df.plot.box      df.plot.hexbin   df.plot.kde      df.plot.pie\n\nEach method signature only includes relevant arguments. Currently, these are limited to required arguments, but in the future these will include optional arguments, as well. For an overview, see the new :ref:`api.dataframe.plotting` API documentation.\n\n.. _whatsnew_0170.strftime:\n\nAdditional methods for ``dt`` accessor\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nSeries.dt.strftime\n\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\n\nWe are now supporting a ``Series.dt.strftime`` method for datetime-likes to generate a formatted string (:issue:`10110`). Examples:\n\n.. ipython:: python\n\n    DatetimeIndex\n   s = pd.Series(pd.date_range(\"20130101\", periods=4))\n   s\n   s.dt.strftime(\"%Y/%m/%d\")\n\n.. ipython:: python\n\n    PeriodIndex\n   s = pd.Series(pd.period_range(\"20130101\", periods=4))\n   s\n   s.dt.strftime(\"%Y/%m/%d\")\n\nThe string format is as the python standard library and details can be found `here <https://docs.python.org/2/library/datetime.html#strftime-and-strptime-behavior>`_\n\nSeries.dt.total_seconds\n\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\n\n``pd.Series`` of type ``timedelta64`` has new method ``.dt.total_seconds()`` returning the duration of the timedelta in seconds (:issue:`10817`)\n\n.. ipython:: python\n\n    TimedeltaIndex\n   s = pd.Series(pd.timedelta_range(\"1 minutes\", periods=4))\n   s\n   s.dt.total_seconds()\n\n.. _whatsnew_0170.periodfreq:\n\nPeriod frequency enhancement\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n``Period``, ``PeriodIndex`` and ``period_range`` can now accept multiplied freq. Also, ``Period.freq`` and ``PeriodIndex.freq`` are now stored as a ``DateOffset`` instance like ``DatetimeIndex``, and not as ``str`` (:issue:`7811`)\n\nA multiplied freq represents a span of corresponding length. The example below creates a period of 3 days. Addition and subtraction will shift the period by its span.\n\n.. ipython:: python\n\n   p = pd.Period(\"2015-08-01\", freq=\"3D\")\n   p\n   p + 1\n   p - 2\n   p.to_timestamp()\n   p.to_timestamp(how=\"E\")\n\nYou can use the multiplied freq in ``PeriodIndex`` and ``period_range``.\n\n.. ipython:: python\n\n   idx = pd.period_range(\"2015-08-01\", periods=4, freq=\"2D\")\n   idx\n   idx + 1\n\n.. _whatsnew_0170.enhancements.sas_xport:\n\nSupport for SAS XPORT files\n^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n:meth:`~pandas.io.read_sas` provides support for reading *SAS XPORT* format files. (:issue:`4052`).\n\n.. code-block:: python\n\n    df = pd.read_sas(\"sas_xport.xpt\")\n\nIt is also possible to obtain an iterator and read an XPORT file\nincrementally.\n\n.. code-block:: python\n\n    for df in pd.read_sas(\"sas_xport.xpt\", chunksize=10000):\n        do_something(df)\n\nSee the :ref:`docs <io.sas>` for more details.\n\n.. _whatsnew_0170.matheval:\n\nSupport for math functions in .eval()\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n:meth:`~pandas.eval` now supports calling math functions (:issue:`4893`)\n\n.. code-block:: python\n\n    df = pd.DataFrame({\"a\": np.random.randn(10)})\n    df.eval(\"b = sin(a)\")\n\nThe support math functions are ``sin``, ``cos``, ``exp``, ``log``, ``expm1``, ``log1p``,\n``sqrt``, ``sinh``, ``cosh``, ``tanh``, ``arcsin``, ``arccos``, ``arctan``, ``arccosh``,\n``arcsinh``, ``arctanh``, ``abs`` and ``arctan2``.\n\nThese functions map to the intrinsics for the ``NumExpr`` engine.  For the Python\nengine, they are mapped to ``NumPy`` calls.\n\nChanges to Excel with ``MultiIndex``\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nIn version 0.16.2 a ``DataFrame`` with ``MultiIndex`` columns could not be written to Excel via ``to_excel``.\nThat functionality has been added (:issue:`10564`), along with updating  ``read_excel`` so that the data can\nbe read back with, no loss of information, by specifying which columns/rows make up the ``MultiIndex``\nin the ``header`` and ``index_col`` parameters (:issue:`4679`)\n\nSee the :ref:`documentation <io.excel>` for more details.\n\n.. ipython:: python\n\n   df = pd.DataFrame(\n       [[1, 2, 3, 4], [5, 6, 7, 8]],\n       columns=pd.MultiIndex.from_product(\n           [[\"foo\", \"bar\"], [\"a\", \"b\"]], names=[\"col1\", \"col2\"]\n       ),\n       index=pd.MultiIndex.from_product([[\"j\"], [\"l\", \"k\"]], names=[\"i1\", \"i2\"]),\n   )\n\n   df\n   df.to_excel(\"test.xlsx\")\n\n   df = pd.read_excel(\"test.xlsx\", header=[0, 1], index_col=[0, 1])\n   df\n\n.. ipython:: python\n   :suppress:\n\n   import os\n\n   os.remove(\"test.xlsx\")\n\nPreviously, it was necessary to specify the ``has_index_names`` argument in ``read_excel``,\nif the serialized data had index names.  For version 0.17.0 the output format of ``to_excel``\nhas been changed to make this keyword unnecessary - the change is shown below.\n\n**Old**\n\n.. image:: ../_static/old-excel-index.png\n\n**New**\n\n.. image:: ../_static/new-excel-index.png\n\n.. warning::\n\n   Excel files saved in version 0.16.2 or prior that had index names will still able to be read in,\n   but the ``has_index_names`` argument must specified to ``True``.\n\n.. _whatsnew_0170.gbq:\n\nGoogle BigQuery enhancements\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n- Added ability to automatically create a table/dataset using the :func:`pandas.io.gbq.to_gbq` function if the destination table/dataset does not exist. (:issue:`8325`, :issue:`11121`).\n- Added ability to replace an existing table and schema when calling the :func:`pandas.io.gbq.to_gbq` function via the ``if_exists`` argument. See the `docs <https://pandas-gbq.readthedocs.io/en/latest/writing.html>`__ for more details (:issue:`8325`).\n- ``InvalidColumnOrder`` and ``InvalidPageToken`` in the gbq module will raise ``ValueError`` instead of ``IOError``.\n- The ``generate_bq_schema()`` function is now deprecated and will be removed in a future version (:issue:`11121`)\n- The gbq module will now support Python 3 (:issue:`11094`).\n\n.. _whatsnew_0170.east_asian_width:\n\nDisplay alignment with Unicode East Asian width\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n.. warning::\n\n   Enabling this option will affect the performance for printing of ``DataFrame`` and ``Series`` (about 2 times slower).\n   Use only when it is actually required.\n\nSome East Asian countries use Unicode characters its width is corresponding to 2 alphabets. If a ``DataFrame`` or ``Series`` contains these characters, the default output cannot be aligned properly. The following options are added to enable precise handling for these characters.\n\n- ``display.unicode.east_asian_width``: Whether to use the Unicode East Asian Width to calculate the display text width. (:issue:`2612`)\n- ``display.unicode.ambiguous_as_wide``: Whether to handle Unicode characters belong to Ambiguous as Wide. (:issue:`11102`)\n\n.. ipython:: python\n\n   df = pd.DataFrame({u\"\u00e5\u009b\u00bd\u00e7\u00b1\u008d\": [\"UK\", u\"\u00e6\u0097\u00a5\u00e6\u009c\u00ac\"], u\"\u00e5\u0090\u008d\u00e5\u0089\u008d\": [\"Alice\", u\"\u00e3\u0081\u0097\u00e3\u0081\u00ae\u00e3\u0081\u00b6\"]})\n   df\n\n.. ipython:: python\n\n   pd.set_option(\"display.unicode.east_asian_width\", True)\n   df\n\nFor further details, see :ref:`here <options.east_asian_width>`\n\n.. ipython:: python\n   :suppress:\n\n   pd.set_option(\"display.unicode.east_asian_width\", False)\n\n.. _whatsnew_0170.enhancements.other:\n\nOther enhancements\n^^^^^^^^^^^^^^^^^^\n\n- Support for ``openpyxl`` >= 2.2. The API for style support is now stable (:issue:`10125`)\n- ``merge`` now accepts the argument ``indicator`` which adds a Categorical-type column (by default called ``_merge``) to the output object that takes on the values (:issue:`8790`)\n\n  ===================================   ================\n  Observation Origin                    ``_merge`` value\n  ===================================   ================\n  Merge key only in ``'left'`` frame    ``left_only``\n  Merge key only in ``'right'`` frame   ``right_only``\n  Merge key in both frames              ``both``\n  ===================================   ================\n\n  .. ipython:: python\n\n    df1 = pd.DataFrame({\"col1\": [0, 1], \"col_left\": [\"a\", \"b\"]})\n    df2 = pd.DataFrame({\"col1\": [1, 2, 2], \"col_right\": [2, 2, 2]})\n    pd.merge(df1, df2, on=\"col1\", how=\"outer\", indicator=True)\n\n  For more, see the :ref:`updated docs <merging.indicator>`\n\n- ``pd.to_numeric`` is a new function to coerce strings to numbers (possibly with coercion) (:issue:`11133`)\n\n- ``pd.merge`` will now allow duplicate column names if they are not merged upon (:issue:`10639`).\n\n- ``pd.pivot`` will now allow passing index as ``None`` (:issue:`3962`).\n\n- ``pd.concat`` will now use existing Series names if provided (:issue:`10698`).\n\n  .. ipython:: python\n\n     foo = pd.Series([1, 2], name=\"foo\")\n     bar = pd.Series([1, 2])\n     baz = pd.Series([4, 5])\n\n  Previous behavior:\n\n  .. code-block:: ipython\n\n     In [1]: pd.concat([foo, bar, baz], axis=1)\n     Out[1]:\n           0  1  2\n        0  1  1  4\n        1  2  2  5\n\n  New behavior:\n\n  .. ipython:: python\n\n    pd.concat([foo, bar, baz], axis=1)\n\n- ``DataFrame`` has gained the ``nlargest`` and ``nsmallest`` methods (:issue:`10393`)\n\n- Add a ``limit_direction`` keyword argument that works with ``limit`` to enable ``interpolate`` to fill ``NaN`` values forward, backward, or both (:issue:`9218`, :issue:`10420`, :issue:`11115`)\n\n  .. ipython:: python\n\n     ser = pd.Series([np.nan, np.nan, 5, np.nan, np.nan, np.nan, 13])\n     ser.interpolate(limit=1, limit_direction=\"both\")\n\n- Added a ``DataFrame.round`` method to round the values to a variable number of decimal places (:issue:`10568`).\n\n  .. ipython:: python\n\n     df = pd.DataFrame(\n         np.random.random([3, 3]),\n         columns=[\"A\", \"B\", \"C\"],\n         index=[\"first\", \"second\", \"third\"],\n     )\n     df\n     df.round(2)\n     df.round({\"A\": 0, \"C\": 2})\n\n- ``drop_duplicates`` and ``duplicated`` now accept a ``keep`` keyword to target first, last, and all duplicates. The ``take_last`` keyword is deprecated, see :ref:`here <whatsnew_0170.deprecations>` (:issue:`6511`, :issue:`8505`)\n\n  .. ipython:: python\n\n     s = pd.Series([\"A\", \"B\", \"C\", \"A\", \"B\", \"D\"])\n     s.drop_duplicates()\n     s.drop_duplicates(keep=\"last\")\n     s.drop_duplicates(keep=False)\n\n- Reindex now has a ``tolerance`` argument that allows for finer control of :ref:`basics.limits_on_reindex_fill` (:issue:`10411`):\n\n  .. ipython:: python\n\n     df = pd.DataFrame({\"x\": range(5), \"t\": pd.date_range(\"2000-01-01\", periods=5)})\n     df.reindex([0.1, 1.9, 3.5], method=\"nearest\", tolerance=0.2)\n\n  When used on a ``DatetimeIndex``, ``TimedeltaIndex`` or ``PeriodIndex``, ``tolerance`` will coerced into a ``Timedelta`` if possible. This allows you to specify tolerance with a string:\n\n  .. ipython:: python\n\n     df = df.set_index(\"t\")\n     df.reindex(pd.to_datetime([\"1999-12-31\"]), method=\"nearest\", tolerance=\"1 day\")\n\n  ``tolerance`` is also exposed by the lower level ``Index.get_indexer`` and ``Index.get_loc`` methods.\n\n- Added functionality to use the ``base`` argument when resampling a ``TimeDeltaIndex`` (:issue:`10530`)\n\n- ``DatetimeIndex`` can be instantiated using strings contains ``NaT`` (:issue:`7599`)\n\n- ``to_datetime`` can now accept the ``yearfirst`` keyword (:issue:`7599`)\n\n- ``pandas.tseries.offsets`` larger than the ``Day`` offset can now be used with a ``Series`` for addition/subtraction (:issue:`10699`).  See the :ref:`docs <timeseries.offsetseries>` for more details.\n\n- ``pd.Timedelta.total_seconds()`` now returns Timedelta duration to ns precision (previously microsecond precision) (:issue:`10939`)\n\n- ``PeriodIndex`` now supports arithmetic with ``np.ndarray`` (:issue:`10638`)\n\n- Support pickling of ``Period`` objects (:issue:`10439`)\n\n- ``.as_blocks`` will now take a ``copy`` optional argument to return a copy of the data, default is to copy (no change in behavior from prior versions), (:issue:`9607`)\n\n- ``regex`` argument to ``DataFrame.filter`` now handles numeric column names instead of raising ``ValueError`` (:issue:`10384`).\n\n- Enable reading gzip compressed files via URL, either by explicitly setting the compression parameter or by inferring from the presence of the HTTP Content-Encoding header in the response (:issue:`8685`)\n\n- Enable writing Excel files in :ref:`memory <io.excel_writing_buffer>` using StringIO/BytesIO (:issue:`7074`)\n\n- Enable serialization of lists and dicts to strings in ``ExcelWriter`` (:issue:`8188`)\n\n- SQL io functions now accept a SQLAlchemy connectable. (:issue:`7877`)\n\n- ``pd.read_sql`` and ``to_sql`` can accept database URI as ``con`` parameter (:issue:`10214`)\n\n- ``read_sql_table`` will now allow reading from views (:issue:`10750`).\n\n- Enable writing complex values to ``HDFStores`` when using the ``table`` format (:issue:`10447`)\n\n- Enable ``pd.read_hdf`` to be used without specifying a key when the HDF file contains a single dataset (:issue:`10443`)\n\n- ``pd.read_stata`` will now read Stata 118 type files. (:issue:`9882`)\n\n- ``msgpack`` submodule has been updated to 0.4.6 with backward compatibility (:issue:`10581`)\n\n- ``DataFrame.to_dict`` now accepts ``orient='index'`` keyword argument (:issue:`10844`).\n\n- ``DataFrame.apply`` will return a Series of dicts if the passed function returns a dict and ``reduce=True`` (:issue:`8735`).\n\n- Allow passing ``kwargs`` to the interpolation methods (:issue:`10378`).\n\n- Improved error message when concatenating an empty iterable of ``Dataframe`` objects (:issue:`9157`)\n\n- ``pd.read_csv`` can now read bz2-compressed files incrementally, and the C parser can read bz2-compressed files from AWS S3 (:issue:`11070`, :issue:`11072`).\n\n- In ``pd.read_csv``, recognize ``s3n://`` and ``s3a://`` URLs as designating S3 file storage (:issue:`11070`, :issue:`11071`).\n\n- Read CSV files from AWS S3 incrementally, instead of first downloading the entire file. (Full file download still required for compressed files in Python 2.)  (:issue:`11070`, :issue:`11073`)\n\n- ``pd.read_csv`` is now able to infer compression type for files read from AWS S3 storage (:issue:`11070`, :issue:`11074`).\n\n\n.. _whatsnew_0170.api:\n\n.. _whatsnew_0170.api_breaking:\n\nBackwards incompatible API changes\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\n.. _whatsnew_0170.api_breaking.sorting:\n\nChanges to sorting API\n^^^^^^^^^^^^^^^^^^^^^^\n\nThe sorting API has had some longtime inconsistencies. (:issue:`9816`, :issue:`8239`).\n\nHere is a summary of the API **PRIOR** to 0.17.0:\n\n- ``Series.sort`` is **INPLACE** while ``DataFrame.sort`` returns a new object.\n- ``Series.order`` returns a new object\n- It was possible to use ``Series/DataFrame.sort_index`` to sort by **values** by passing the ``by`` keyword.\n- ``Series/DataFrame.sortlevel`` worked only on a ``MultiIndex`` for sorting by index.\n\nTo address these issues, we have revamped the API:\n\n- We have introduced a new method, :meth:`DataFrame.sort_values`, which is the merger of ``DataFrame.sort()``, ``Series.sort()``,\n  and ``Series.order()``, to handle sorting of **values**.\n- The existing methods ``Series.sort()``, ``Series.order()``, and ``DataFrame.sort()`` have been deprecated and will be removed in a\n  future version.\n- The ``by`` argument of ``DataFrame.sort_index()`` has been deprecated and will be removed in a future version.\n- The existing method ``.sort_index()`` will gain the ``level`` keyword to enable level sorting.\n\nWe now have two distinct and non-overlapping methods of sorting. A ``*`` marks items that\nwill show a ``FutureWarning``.\n\nTo sort by the **values**:\n\n==================================    ====================================\nPrevious                              Replacement\n==================================    ====================================\n\\* ``Series.order()``                 ``Series.sort_values()``\n\\* ``Series.sort()``                  ``Series.sort_values(inplace=True)``\n\\* ``DataFrame.sort(columns=...)``    ``DataFrame.sort_values(by=...)``\n==================================    ====================================\n\nTo sort by the **index**:\n\n==================================    ====================================\nPrevious                              Replacement\n==================================    ====================================\n``Series.sort_index()``               ``Series.sort_index()``\n``Series.sortlevel(level=...)``       ``Series.sort_index(level=...``)\n``DataFrame.sort_index()``            ``DataFrame.sort_index()``\n``DataFrame.sortlevel(level=...)``    ``DataFrame.sort_index(level=...)``\n\\* ``DataFrame.sort()``                 ``DataFrame.sort_index()``\n==================================    ====================================\n\nWe have also deprecated and changed similar methods in two Series-like classes, ``Index`` and ``Categorical``.\n\n==================================    ====================================\nPrevious                              Replacement\n==================================    ====================================\n\\* ``Index.order()``                  ``Index.sort_values()``\n\\* ``Categorical.order()``            ``Categorical.sort_values()``\n==================================    ====================================\n\n.. _whatsnew_0170.api_breaking.to_datetime:\n\nChanges to to_datetime and to_timedelta\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nError handling\n\"\"\"\"\"\"\"\"\"\"\"\"\"\"\n\nThe default for ``pd.to_datetime`` error handling has changed to ``errors='raise'``.\nIn prior versions it was ``errors='ignore'``. Furthermore, the ``coerce`` argument\nhas been deprecated in favor of ``errors='coerce'``. This means that invalid parsing\nwill raise rather that return the original input as in previous versions. (:issue:`10636`)\n\nPrevious behavior:\n\n.. code-block:: ipython\n\n   In [2]: pd.to_datetime(['2009-07-31', 'asd'])\n   Out[2]: array(['2009-07-31', 'asd'], dtype=object)\n\nNew behavior:\n\n.. code-block:: ipython\n\n   In [3]: pd.to_datetime(['2009-07-31', 'asd'])\n   ValueError: Unknown string format\n\nOf course you can coerce this as well.\n\n.. ipython:: python\n\n   pd.to_datetime([\"2009-07-31\", \"asd\"], errors=\"coerce\")\n\nTo keep the previous behavior, you can use ``errors='ignore'``:\n\n.. code-block:: ipython\n\n   In [4]: pd.to_datetime([\"2009-07-31\", \"asd\"], errors=\"ignore\")\n   Out[4]: Index(['2009-07-31', 'asd'], dtype='object')\n\nFurthermore, ``pd.to_timedelta`` has gained a similar API, of ``errors='raise'|'ignore'|'coerce'``, and the ``coerce`` keyword\nhas been deprecated in favor of ``errors='coerce'``.\n\nConsistent parsing\n\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\n\nThe string parsing of ``to_datetime``, ``Timestamp`` and ``DatetimeIndex`` has\nbeen made consistent. (:issue:`7599`)\n\nPrior to v0.17.0, ``Timestamp`` and ``to_datetime`` may parse year-only datetime-string incorrectly using today's date, otherwise ``DatetimeIndex``\nuses the beginning of the year. ``Timestamp`` and ``to_datetime`` may raise ``ValueError`` in some types of datetime-string which ``DatetimeIndex``\ncan parse, such as a quarterly string.\n\nPrevious behavior:\n\n.. code-block:: ipython\n\n   In [1]: pd.Timestamp('2012Q2')\n   Traceback\n      ...\n   ValueError: Unable to parse 2012Q2\n\n    Results in today's date.\n   In [2]: pd.Timestamp('2014')\n   Out [2]: 2014-08-12 00:00:00\n\nv0.17.0 can parse them as below. It works on ``DatetimeIndex`` also.\n\nNew behavior:\n\n.. ipython:: python\n\n   pd.Timestamp(\"2012Q2\")\n   pd.Timestamp(\"2014\")\n   pd.DatetimeIndex([\"2012Q2\", \"2014\"])\n\n.. note::\n\n   If you want to perform calculations based on today's date, use ``Timestamp.now()`` and ``pandas.tseries.offsets``.\n\n   .. ipython:: python\n\n      import pandas.tseries.offsets as offsets\n\n      pd.Timestamp.now()\n      pd.Timestamp.now() + offsets.DateOffset(years=1)\n\nChanges to Index comparisons\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nOperator equal on ``Index`` should behavior similarly to ``Series`` (:issue:`9947`, :issue:`10637`)\n\nStarting in v0.17.0, comparing ``Index`` objects of different lengths will raise\na ``ValueError``. This is to be consistent with the behavior of ``Series``.\n\nPrevious behavior:\n\n.. code-block:: ipython\n\n   In [2]: pd.Index([1, 2, 3]) == pd.Index([1, 4, 5])\n   Out[2]: array([ True, False, False], dtype=bool)\n\n   In [3]: pd.Index([1, 2, 3]) == pd.Index([2])\n   Out[3]: array([False,  True, False], dtype=bool)\n\n   In [4]: pd.Index([1, 2, 3]) == pd.Index([1, 2])\n   Out[4]: False\n\nNew behavior:\n\n.. code-block:: ipython\n\n   In [8]: pd.Index([1, 2, 3]) == pd.Index([1, 4, 5])\n   Out[8]: array([ True, False, False], dtype=bool)\n\n   In [9]: pd.Index([1, 2, 3]) == pd.Index([2])\n   ValueError: Lengths must match to compare\n\n   In [10]: pd.Index([1, 2, 3]) == pd.Index([1, 2])\n   ValueError: Lengths must match to compare\n\nNote that this is different from the ``numpy`` behavior where a comparison can\nbe broadcast:\n\n.. ipython:: python\n\n   np.array([1, 2, 3]) == np.array([1])\n\nor it can return False if broadcasting can not be done:\n\n.. code-block:: ipython\n\n   In [11]: np.array([1, 2, 3]) == np.array([1, 2])\n   Out[11]: False\n\nChanges to boolean comparisons vs. None\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nBoolean comparisons of a ``Series`` vs ``None`` will now be equivalent to comparing with ``np.nan``, rather than raise ``TypeError``. (:issue:`1079`).\n\n.. ipython:: python\n\n   s = pd.Series(range(3), dtype=\"float\")\n   s.iloc[1] = None\n   s\n\nPrevious behavior:\n\n.. code-block:: ipython\n\n   In [5]: s == None\n   TypeError: Could not compare <type 'NoneType'> type with Series\n\nNew behavior:\n\n.. ipython:: python\n\n   s == None\n\nUsually you simply want to know which values are null.\n\n.. ipython:: python\n\n   s.isnull()\n\n.. warning::\n\n   You generally will want to use ``isnull/notnull`` for these types of comparisons, as ``isnull/notnull`` tells you which elements are null. One has to be\n   mindful that ``nan's`` don't compare equal, but ``None's`` do. Note that pandas/numpy uses the fact that ``np.nan != np.nan``, and treats ``None`` like ``np.nan``.\n\n   .. ipython:: python\n\n      None == None\n      np.nan == np.nan\n\n.. _whatsnew_0170.api_breaking.hdf_dropna:\n\nHDFStore dropna behavior\n^^^^^^^^^^^^^^^^^^^^^^^^\n\nThe default behavior for HDFStore write functions with ``format='table'`` is now to keep rows that are all missing. Previously, the behavior was to drop rows that were all missing save the index. The previous behavior can be replicated using the ``dropna=True`` option. (:issue:`9382`)\n\nPrevious behavior:\n\n.. ipython:: python\n\n   df_with_missing = pd.DataFrame(\n       {\"col1\": [0, np.nan, 2], \"col2\": [1, np.nan, np.nan]}\n   )\n\n   df_with_missing\n\n\n.. code-block:: ipython\n\n   In [27]:\n   df_with_missing.to_hdf('file.h5',\n                          key='df_with_missing',\n                          format='table',\n                          mode='w')\n\n   In [28]: pd.read_hdf('file.h5', 'df_with_missing')\n\n   Out [28]:\n         col1  col2\n     0     0     1\n     2     2   NaN\n\n\nNew behavior:\n\n.. ipython:: python\n\n   df_with_missing.to_hdf(\"file.h5\", key=\"df_with_missing\", format=\"table\", mode=\"w\")\n\n   pd.read_hdf(\"file.h5\", \"df_with_missing\")\n\n.. ipython:: python\n   :suppress:\n\n   import os\n\n   os.remove(\"file.h5\")\n\nSee the :ref:`docs <io.hdf5>` for more details.\n\n.. _whatsnew_0170.api_breaking.display_precision:\n\nChanges to ``display.precision`` option\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nThe ``display.precision`` option has been clarified to refer to decimal places (:issue:`10451`).\n\nEarlier versions of pandas would format floating point numbers to have one less decimal place than the value in\n``display.precision``.\n\n.. code-block:: ipython\n\n  In [1]: pd.set_option('display.precision', 2)\n\n  In [2]: pd.DataFrame({'x': [123.456789]})\n  Out[2]:\n         x\n  0  123.5\n\nIf interpreting precision as \"significant figures\" this did work for scientific notation but that same interpretation\ndid not work for values with standard formatting. It was also out of step with how numpy handles formatting.\n\nGoing forward the value of ``display.precision`` will directly control the number of places after the decimal, for\nregular formatting as well as scientific notation, similar to how numpy's ``precision`` print option works.\n\n.. ipython:: python\n\n  pd.set_option(\"display.precision\", 2)\n  pd.DataFrame({\"x\": [123.456789]})\n\nTo preserve output behavior with prior versions the default value of ``display.precision`` has been reduced to ``6``\nfrom ``7``.\n\n.. ipython:: python\n  :suppress:\n\n  pd.set_option(\"display.precision\", 6)\n\n.. _whatsnew_0170.api_breaking.categorical_unique:\n\nChanges to ``Categorical.unique``\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n``Categorical.unique`` now returns new ``Categoricals`` with ``categories`` and ``codes`` that are unique, rather than returning ``np.array`` (:issue:`10508`)\n\n- unordered category: values and categories are sorted by appearance order.\n- ordered category: values are sorted by appearance order, categories keep existing order.\n\n.. ipython:: python\n\n   cat = pd.Categorical([\"C\", \"A\", \"B\", \"C\"], categories=[\"A\", \"B\", \"C\"], ordered=True)\n   cat\n   cat.unique()\n\n   cat = pd.Categorical([\"C\", \"A\", \"B\", \"C\"], categories=[\"A\", \"B\", \"C\"])\n   cat\n   cat.unique()\n\nChanges to ``bool`` passed as ``header`` in parsers\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nIn earlier versions of pandas, if a bool was passed the ``header`` argument of\n``read_csv``, ``read_excel``, or ``read_html`` it was implicitly converted to\nan integer, resulting in ``header=0`` for ``False`` and ``header=1`` for ``True``\n(:issue:`6113`)\n\nA ``bool`` input to ``header`` will now raise a ``TypeError``\n\n.. code-block:: ipython\n\n   In [29]: df = pd.read_csv('data.csv', header=False)\n   TypeError: Passing a bool to header is invalid. Use header=None for no header or\n   header=int or list-like of ints to specify the row(s) making up the column names\n\n\n.. _whatsnew_0170.api_breaking.other:\n\nOther API changes\n^^^^^^^^^^^^^^^^^\n\n- Line and kde plot with ``subplots=True`` now uses default colors, not all black. Specify ``color='k'`` to draw all lines in black (:issue:`9894`)\n- Calling the ``.value_counts()`` method on a Series with a ``categorical`` dtype now returns a Series with a ``CategoricalIndex`` (:issue:`10704`)\n- The metadata properties of subclasses of pandas objects will now be serialized (:issue:`10553`).\n- ``groupby`` using ``Categorical`` follows the same rule as ``Categorical.unique`` described above  (:issue:`10508`)\n- When constructing ``DataFrame`` with an array of ``complex64`` dtype previously meant the corresponding column\n  was automatically promoted to the ``complex128`` dtype. pandas will now preserve the itemsize of the input for complex data (:issue:`10952`)\n- some numeric reduction operators would return ``ValueError``, rather than ``TypeError`` on object types that includes strings and numbers (:issue:`11131`)\n- Passing currently unsupported ``chunksize`` argument to ``read_excel`` or ``ExcelFile.parse`` will now raise ``NotImplementedError`` (:issue:`8011`)\n- Allow an ``ExcelFile`` object to be passed into ``read_excel`` (:issue:`11198`)\n- ``DatetimeIndex.union`` does not infer ``freq`` if ``self`` and the input have ``None`` as ``freq`` (:issue:`11086`)\n- ``NaT``'s methods now either raise ``ValueError``, or return ``np.nan`` or ``NaT`` (:issue:`9513`)\n\n  ===============================     ===============================================================\n  Behavior                            Methods\n  ===============================     ===============================================================\n  return ``np.nan``                   ``weekday``, ``isoweekday``\n  return ``NaT``                      ``date``, ``now``, ``replace``, ``to_datetime``, ``today``\n  return ``np.datetime64('NaT')``     ``to_datetime64`` (unchanged)\n  raise ``ValueError``                All other public methods (names not beginning with underscores)\n  ===============================     ===============================================================\n\n.. _whatsnew_0170.deprecations:\n\nDeprecations\n^^^^^^^^^^^^\n\n- For ``Series`` the following indexing functions are deprecated (:issue:`10177`).\n\n  =====================  =================================\n  Deprecated Function    Replacement\n  =====================  =================================\n  ``.irow(i)``           ``.iloc[i]`` or ``.iat[i]``\n  ``.iget(i)``           ``.iloc[i]`` or ``.iat[i]``\n  ``.iget_value(i)``     ``.iloc[i]`` or ``.iat[i]``\n  =====================  =================================\n\n- For ``DataFrame`` the following indexing functions are deprecated (:issue:`10177`).\n\n  =====================  =================================\n  Deprecated Function    Replacement\n  =====================  =================================\n  ``.irow(i)``           ``.iloc[i]``\n  ``.iget_value(i, j)``  ``.iloc[i, j]`` or ``.iat[i, j]``\n  ``.icol(j)``           ``.iloc[:, j]``\n  =====================  =================================\n\n.. note:: These indexing function have been deprecated in the documentation since 0.11.0.\n\n- ``Categorical.name`` was deprecated to make ``Categorical`` more ``numpy.ndarray`` like. Use ``Series(cat, name=\"whatever\")`` instead (:issue:`10482`).\n- Setting missing values (NaN) in a ``Categorical``'s ``categories`` will issue a warning (:issue:`10748`). You can still have missing values in the ``values``.\n- ``drop_duplicates`` and ``duplicated``'s ``take_last`` keyword was deprecated in favor of ``keep``. (:issue:`6511`, :issue:`8505`)\n- ``Series.nsmallest`` and ``nlargest``'s ``take_last`` keyword was deprecated in favor of ``keep``. (:issue:`10792`)\n- ``DataFrame.combineAdd`` and ``DataFrame.combineMult`` are deprecated. They\n  can easily be replaced by using the ``add`` and ``mul`` methods:\n  ``DataFrame.add(other, fill_value=0)`` and ``DataFrame.mul(other, fill_value=1.)``\n  (:issue:`10735`).\n- ``TimeSeries`` deprecated in favor of ``Series`` (note that this has been an alias since 0.13.0), (:issue:`10890`)\n- ``SparsePanel`` deprecated and will be removed in a future version (:issue:`11157`).\n- ``Series.is_time_series`` deprecated in favor of ``Series.index.is_all_dates`` (:issue:`11135`)\n- Legacy offsets (like ``'AJAN'``) are deprecated (note that this has been alias since 0.8.0) (:issue:`10878`)\n- ``WidePanel`` deprecated in favor of ``Panel``, ``LongPanel`` in favor of ``DataFrame`` (note these have been aliases since < 0.11.0), (:issue:`10892`)\n- ``DataFrame.convert_objects`` has been deprecated in favor of type-specific functions ``pd.to_datetime``, ``pd.to_timestamp`` and ``pd.to_numeric`` (new in 0.17.0) (:issue:`11133`).\n\n.. _whatsnew_0170.prior_deprecations:\n\nRemoval of prior version deprecations/changes\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n- Removal of ``na_last`` parameters from ``Series.order()`` and ``Series.sort()``, in favor of ``na_position``. (:issue:`5231`)\n- Remove of ``percentile_width`` from ``.describe()``, in favor of ``percentiles``. (:issue:`7088`)\n- Removal of ``colSpace`` parameter from ``DataFrame.to_string()``, in favor of ``col_space``, circa 0.8.0 version.\n- Removal of automatic time-series broadcasting (:issue:`2304`)\n\n  .. ipython:: python\n\n     np.random.seed(1234)\n     df = pd.DataFrame(\n         np.random.randn(5, 2),\n         columns=list(\"AB\"),\n         index=pd.date_range(\"2013-01-01\", periods=5),\n     )\n     df\n\n  Previously\n\n  .. code-block:: ipython\n\n     In [3]: df + df.A\n     FutureWarning: TimeSeries broadcasting along DataFrame index by default is deprecated.\n     Please use DataFrame.<op> to explicitly broadcast arithmetic operations along the index\n\n     Out[3]:\n                         A         B\n     2013-01-01  0.942870 -0.719541\n     2013-01-02  2.865414  1.120055\n     2013-01-03 -1.441177  0.166574\n     2013-01-04  1.719177  0.223065\n     2013-01-05  0.031393 -2.226989\n\n  Current\n\n  .. ipython:: python\n\n     df.add(df.A, axis=\"index\")\n\n\n- Remove ``table`` keyword in ``HDFStore.put/append``, in favor of using ``format=`` (:issue:`4645`)\n- Remove ``kind`` in ``read_excel/ExcelFile`` as its unused (:issue:`4712`)\n- Remove ``infer_type`` keyword from ``pd.read_html`` as its unused (:issue:`4770`, :issue:`7032`)\n- Remove ``offset`` and ``timeRule`` keywords from ``Series.tshift/shift``, in favor of ``freq`` (:issue:`4853`, :issue:`4864`)\n- Remove ``pd.load/pd.save`` aliases in favor of ``pd.to_pickle/pd.read_pickle`` (:issue:`3787`)\n\n.. _whatsnew_0170.performance:\n\nPerformance improvements\n~~~~~~~~~~~~~~~~~~~~~~~~\n\n- Development support for benchmarking with the `Air Speed Velocity library <https://github.com/spacetelescope/asv/>`_ (:issue:`8361`)\n- Added vbench benchmarks for alternative ExcelWriter engines and reading Excel files (:issue:`7171`)\n- Performance improvements in ``Categorical.value_counts`` (:issue:`10804`)\n- Performance improvements in ``SeriesGroupBy.nunique`` and ``SeriesGroupBy.value_counts`` and ``SeriesGroupby.transform`` (:issue:`10820`, :issue:`11077`)\n- Performance improvements in ``DataFrame.drop_duplicates`` with integer dtypes (:issue:`10917`)\n- Performance improvements in ``DataFrame.duplicated`` with wide frames. (:issue:`10161`, :issue:`11180`)\n- 4x improvement in ``timedelta`` string parsing (:issue:`6755`, :issue:`10426`)\n- 8x improvement in ``timedelta64`` and ``datetime64`` ops (:issue:`6755`)\n- Significantly improved performance of indexing ``MultiIndex`` with slicers (:issue:`10287`)\n- 8x improvement in ``iloc`` using list-like input (:issue:`10791`)\n- Improved performance of ``Series.isin`` for datetimelike/integer Series (:issue:`10287`)\n- 20x improvement in ``concat`` of Categoricals when categories are identical (:issue:`10587`)\n- Improved performance of ``to_datetime`` when specified format string is ISO8601 (:issue:`10178`)\n- 2x improvement of ``Series.value_counts`` for float dtype (:issue:`10821`)\n- Enable ``infer_datetime_format`` in ``to_datetime`` when date components do not have 0 padding (:issue:`11142`)\n- Regression from 0.16.1 in constructing ``DataFrame`` from nested dictionary (:issue:`11084`)\n- Performance improvements in addition/subtraction operations for ``DateOffset`` with ``Series`` or ``DatetimeIndex``  (:issue:`10744`, :issue:`11205`)\n\n.. _whatsnew_0170.bug_fixes:\n\nBug fixes\n~~~~~~~~~\n\n- Bug in incorrect computation of ``.mean()`` on ``timedelta64[ns]`` because of overflow (:issue:`9442`)\n- Bug in  ``.isin`` on older numpies (:issue:`11232`)\n- Bug in ``DataFrame.to_html(index=False)`` renders unnecessary ``name`` row (:issue:`10344`)\n- Bug in ``DataFrame.to_latex()`` the ``column_format`` argument could not be passed (:issue:`9402`)\n- Bug in ``DatetimeIndex`` when localizing with ``NaT`` (:issue:`10477`)\n- Bug in ``Series.dt`` ops in preserving meta-data (:issue:`10477`)\n- Bug in preserving ``NaT`` when passed in an otherwise invalid ``to_datetime`` construction (:issue:`10477`)\n- Bug in ``DataFrame.apply`` when function returns categorical series. (:issue:`9573`)\n- Bug in ``to_datetime`` with invalid dates and formats supplied (:issue:`10154`)\n- Bug in ``Index.drop_duplicates`` dropping name(s) (:issue:`10115`)\n- Bug in ``Series.quantile`` dropping name (:issue:`10881`)\n- Bug in ``pd.Series`` when setting a value on an empty ``Series`` whose index has a frequency. (:issue:`10193`)\n- Bug in ``pd.Series.interpolate`` with invalid ``order`` keyword values. (:issue:`10633`)\n- Bug in ``DataFrame.plot`` raises ``ValueError`` when color name is specified by multiple characters (:issue:`10387`)\n- Bug in ``Index`` construction with a mixed list of tuples (:issue:`10697`)\n- Bug in ``DataFrame.reset_index`` when index contains ``NaT``. (:issue:`10388`)\n- Bug in ``ExcelReader`` when worksheet is empty (:issue:`6403`)\n- Bug in ``BinGrouper.group_info`` where returned values are not compatible with base class (:issue:`10914`)\n- Bug in clearing the cache on ``DataFrame.pop`` and a subsequent inplace op (:issue:`10912`)\n- Bug in indexing with a mixed-integer ``Index`` causing an ``ImportError`` (:issue:`10610`)\n- Bug in ``Series.count`` when index has nulls (:issue:`10946`)\n- Bug in pickling of a non-regular freq ``DatetimeIndex`` (:issue:`11002`)\n- Bug causing ``DataFrame.where`` to not respect the ``axis`` parameter when the frame has a symmetric shape. (:issue:`9736`)\n- Bug in ``Table.select_column`` where name is not preserved (:issue:`10392`)\n- Bug in ``offsets.generate_range`` where ``start`` and ``end`` have finer precision than ``offset`` (:issue:`9907`)\n- Bug in ``pd.rolling_*`` where ``Series.name`` would be lost in the output (:issue:`10565`)\n- Bug in ``stack`` when index or columns are not unique. (:issue:`10417`)\n- Bug in setting a ``Panel`` when an axis has a MultiIndex (:issue:`10360`)\n- Bug in ``USFederalHolidayCalendar`` where ``USMemorialDay`` and ``USMartinLutherKingJr`` were incorrect (:issue:`10278` and :issue:`9760` )\n- Bug in ``.sample()`` where returned object, if set, gives unnecessary ``SettingWithCopyWarning`` (:issue:`10738`)\n- Bug in ``.sample()`` where weights passed as ``Series`` were not aligned along axis before being treated positionally, potentially causing problems if weight indices were not aligned with sampled object. (:issue:`10738`)\n\n- Regression fixed in (:issue:`9311`, :issue:`6620`, :issue:`9345`), where groupby with a datetime-like converting to float with certain aggregators (:issue:`10979`)\n\n- Bug in ``DataFrame.interpolate`` with ``axis=1`` and ``inplace=True`` (:issue:`10395`)\n- Bug in ``io.sql.get_schema`` when specifying multiple columns as primary\n  key (:issue:`10385`).\n\n- Bug in ``groupby(sort=False)`` with datetime-like ``Categorical`` raises ``ValueError`` (:issue:`10505`)\n- Bug in ``groupby(axis=1)`` with ``filter()`` throws ``IndexError`` (:issue:`11041`)\n- Bug in ``test_categorical`` on big-endian builds (:issue:`10425`)\n- Bug in ``Series.shift`` and ``DataFrame.shift`` not supporting categorical data (:issue:`9416`)\n- Bug in ``Series.map`` using categorical ``Series`` raises ``AttributeError`` (:issue:`10324`)\n- Bug in ``MultiIndex.get_level_values`` including ``Categorical`` raises ``AttributeError`` (:issue:`10460`)\n- Bug in ``pd.get_dummies`` with ``sparse=True`` not returning ``SparseDataFrame`` (:issue:`10531`)\n- Bug in ``Index`` subtypes (such as ``PeriodIndex``) not returning their own type for ``.drop`` and ``.insert`` methods (:issue:`10620`)\n- Bug in ``algos.outer_join_indexer`` when ``right`` array is empty (:issue:`10618`)\n\n- Bug in ``filter`` (regression from 0.16.0) and ``transform`` when grouping on multiple keys, one of which is datetime-like (:issue:`10114`)\n\n\n- Bug in ``to_datetime`` and ``to_timedelta`` causing ``Index`` name to be lost (:issue:`10875`)\n- Bug in ``len(DataFrame.groupby)`` causing ``IndexError`` when there's a column containing only NaNs (:issue:`11016`)\n\n- Bug that caused segfault when resampling an empty Series (:issue:`10228`)\n- Bug in ``DatetimeIndex`` and ``PeriodIndex.value_counts`` resets name from its result, but retains in result's ``Index``. (:issue:`10150`)\n- Bug in ``pd.eval`` using ``numexpr`` engine coerces 1 element numpy array to scalar (:issue:`10546`)\n- Bug in ``pd.concat`` with ``axis=0`` when column is of dtype ``category`` (:issue:`10177`)\n- Bug in ``read_msgpack`` where input type is not always checked (:issue:`10369`, :issue:`10630`)\n- Bug in ``pd.read_csv`` with kwargs ``index_col=False``, ``index_col=['a', 'b']`` or ``dtype``\n  (:issue:`10413`, :issue:`10467`, :issue:`10577`)\n- Bug in ``Series.from_csv`` with ``header`` kwarg not setting the ``Series.name`` or the ``Series.index.name`` (:issue:`10483`)\n- Bug in ``groupby.var`` which caused variance to be inaccurate for small float values (:issue:`10448`)\n- Bug in ``Series.plot(kind='hist')`` Y Label not informative (:issue:`10485`)\n- Bug in ``read_csv`` when using a converter which generates a ``uint8`` type (:issue:`9266`)\n\n- Bug causes memory leak in time-series line and area plot (:issue:`9003`)\n\n- Bug when setting a ``Panel`` sliced along the major or minor axes when the right-hand side is a ``DataFrame`` (:issue:`11014`)\n- Bug that returns ``None`` and does not raise ``NotImplementedError`` when operator functions (e.g. ``.add``) of ``Panel`` are not implemented (:issue:`7692`)\n\n- Bug in line and kde plot cannot accept multiple colors when ``subplots=True`` (:issue:`9894`)\n- Bug in ``DataFrame.plot`` raises ``ValueError`` when color name is specified by multiple characters (:issue:`10387`)\n\n- Bug in left and right ``align`` of ``Series`` with ``MultiIndex`` may be inverted (:issue:`10665`)\n- Bug in left and right ``join`` of with ``MultiIndex`` may be inverted (:issue:`10741`)\n\n- Bug in ``read_stata`` when reading a file with a different order set in ``columns`` (:issue:`10757`)\n- Bug in ``Categorical`` may not representing properly when category contains ``tz`` or ``Period`` (:issue:`10713`)\n- Bug in ``Categorical.__iter__`` may not returning correct ``datetime`` and ``Period`` (:issue:`10713`)\n- Bug in indexing with a ``PeriodIndex`` on an object with a ``PeriodIndex`` (:issue:`4125`)\n- Bug in ``read_csv`` with ``engine='c'``: EOF preceded by a comment, blank line, etc. was not handled correctly (:issue:`10728`, :issue:`10548`)\n\n- Reading \"famafrench\" data via ``DataReader`` results in HTTP 404 error because of the website url is changed (:issue:`10591`).\n- Bug in ``read_msgpack`` where DataFrame to decode has duplicate column names (:issue:`9618`)\n- Bug in ``io.common.get_filepath_or_buffer`` which caused reading of valid S3 files to fail if the bucket also contained keys for which the user does not have read permission (:issue:`10604`)\n- Bug in vectorised setting of timestamp columns with python ``datetime.date`` and numpy ``datetime64`` (:issue:`10408`, :issue:`10412`)\n- Bug in ``Index.take`` may add unnecessary ``freq`` attribute (:issue:`10791`)\n- Bug in ``merge`` with empty ``DataFrame`` may raise ``IndexError`` (:issue:`10824`)\n- Bug in ``to_latex`` where unexpected keyword argument for some documented arguments (:issue:`10888`)\n- Bug in indexing of large ``DataFrame`` where ``IndexError`` is uncaught (:issue:`10645` and :issue:`10692`)\n- Bug in ``read_csv`` when using the ``nrows`` or ``chunksize`` parameters if file contains only a header line (:issue:`9535`)\n- Bug in serialization of ``category`` types in HDF5 in presence of alternate encodings. (:issue:`10366`)\n- Bug in ``pd.DataFrame`` when constructing an empty DataFrame with a string dtype (:issue:`9428`)\n- Bug in ``pd.DataFrame.diff`` when DataFrame is not consolidated (:issue:`10907`)\n- Bug in ``pd.unique`` for arrays with the ``datetime64`` or ``timedelta64`` dtype that meant an array with object dtype was returned instead the original dtype (:issue:`9431`)\n- Bug in ``Timedelta`` raising error when slicing from 0s (:issue:`10583`)\n- Bug in ``DatetimeIndex.take`` and ``TimedeltaIndex.take`` may not raise ``IndexError`` against invalid index (:issue:`10295`)\n- Bug in ``Series([np.nan]).astype('M8[ms]')``, which now returns ``Series([pd.NaT])`` (:issue:`10747`)\n- Bug in ``PeriodIndex.order`` reset freq (:issue:`10295`)\n- Bug in ``date_range`` when ``freq`` divides ``end`` as nanos (:issue:`10885`)\n- Bug in ``iloc`` allowing memory outside bounds of a Series to be accessed with negative integers (:issue:`10779`)\n- Bug in ``read_msgpack`` where encoding is not respected (:issue:`10581`)\n- Bug preventing access to the first index when using ``iloc`` with a list containing the appropriate negative integer (:issue:`10547`, :issue:`10779`)\n- Bug in ``TimedeltaIndex`` formatter causing error while trying to save ``DataFrame`` with ``TimedeltaIndex`` using ``to_csv`` (:issue:`10833`)\n- Bug in ``DataFrame.where`` when handling Series slicing (:issue:`10218`, :issue:`9558`)\n- Bug where ``pd.read_gbq`` throws ``ValueError`` when Bigquery returns zero rows (:issue:`10273`)\n- Bug in ``to_json`` which was causing segmentation fault when serializing 0-rank ndarray (:issue:`9576`)\n- Bug in plotting functions may raise ``IndexError`` when plotted on ``GridSpec`` (:issue:`10819`)\n- Bug in plot result may show unnecessary minor ticklabels (:issue:`10657`)\n- Bug in ``groupby`` incorrect computation for aggregation on ``DataFrame`` with ``NaT`` (E.g ``first``, ``last``, ``min``). (:issue:`10590`, :issue:`11010`)\n- Bug when constructing ``DataFrame`` where passing a dictionary with only scalar values and specifying columns did not raise an error (:issue:`10856`)\n- Bug in ``.var()`` causing roundoff errors for highly similar values (:issue:`10242`)\n- Bug in ``DataFrame.plot(subplots=True)`` with duplicated columns outputs incorrect result (:issue:`10962`)\n- Bug in ``Index`` arithmetic may result in incorrect class (:issue:`10638`)\n- Bug in ``date_range`` results in empty if freq is negative annually, quarterly and monthly (:issue:`11018`)\n- Bug in ``DatetimeIndex`` cannot infer negative freq (:issue:`11018`)\n- Remove use of some deprecated numpy comparison operations, mainly in tests. (:issue:`10569`)\n- Bug in ``Index`` dtype may not applied properly (:issue:`11017`)\n- Bug in ``io.gbq`` when testing for minimum google api client version (:issue:`10652`)\n- Bug in ``DataFrame`` construction from nested ``dict`` with ``timedelta`` keys (:issue:`11129`)\n- Bug in ``.fillna`` against may raise ``TypeError`` when data contains datetime dtype (:issue:`7095`, :issue:`11153`)\n- Bug in ``.groupby`` when number of keys to group by is same as length of index (:issue:`11185`)\n- Bug in ``convert_objects`` where converted values might not be returned if all null and ``coerce`` (:issue:`9589`)\n- Bug in ``convert_objects`` where ``copy`` keyword was not respected (:issue:`9589`)\n\n\n.. _whatsnew_0.17.0.contributors:\n\nContributors\n~~~~~~~~~~~~\n\n.. contributors:: v0.16.2..v0.17.0\n\n\n.. _whatsnew_120:\n\nWhat's new in 1.2.0 (December 26, 2020)\n---------------------------------------\n\nThese are the changes in pandas 1.2.0. See :ref:`release` for a full changelog\nincluding other versions of pandas.\n\n{{ header }}\n\n.. warning::\n\n   The `xlwt <https://xlwt.readthedocs.io/en/latest/>`_ package for writing old-style ``.xls``\n   excel files is no longer maintained.\n   The `xlrd <https://xlrd.readthedocs.io/en/latest/>`_ package is now only for reading\n   old-style ``.xls`` files.\n\n   Previously, the default argument ``engine=None`` to :func:`~pandas.read_excel`\n   would result in using the ``xlrd`` engine in many cases, including new\n   Excel 2007+ (``.xlsx``) files.\n   If `openpyxl <https://openpyxl.readthedocs.io/en/stable/>`_  is installed,\n   many of these cases will now default to using the ``openpyxl`` engine.\n   See the :func:`read_excel` documentation for more details.\n\n   Thus, it is strongly encouraged to install ``openpyxl`` to read Excel 2007+\n   (``.xlsx``) files.\n   **Please do not report issues when using ``xlrd`` to read ``.xlsx`` files.**\n   This is no longer supported, switch to using ``openpyxl`` instead.\n\n   Attempting to use the ``xlwt`` engine will raise a ``FutureWarning``\n   unless the option :attr:`io.excel.xls.writer` is set to ``\"xlwt\"``.\n   While this option is now deprecated and will also raise a ``FutureWarning``,\n   it can be globally set and the warning suppressed. Users are recommended to\n   write ``.xlsx`` files using the ``openpyxl`` engine instead.\n\n.. ---------------------------------------------------------------------------\n\nEnhancements\n~~~~~~~~~~~~\n\n.. _whatsnew_120.duplicate_labels:\n\nOptionally disallow duplicate labels\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n:class:`Series` and :class:`DataFrame` can now be created with ``allows_duplicate_labels=False`` flag to\ncontrol whether the index or columns can contain duplicate labels (:issue:`28394`). This can be used to\nprevent accidental introduction of duplicate labels, which can affect downstream operations.\n\nBy default, duplicates continue to be allowed.\n\n.. code-block:: ipython\n\n    In [1]: pd.Series([1, 2], index=['a', 'a'])\n    Out[1]:\n    a    1\n    a    2\n    Length: 2, dtype: int64\n\n    In [2]: pd.Series([1, 2], index=['a', 'a']).set_flags(allows_duplicate_labels=False)\n    ...\n    DuplicateLabelError: Index has duplicates.\n          positions\n    label\n    a        [0, 1]\n\npandas will propagate the ``allows_duplicate_labels`` property through many operations.\n\n.. code-block:: ipython\n\n    In [3]: a = (\n       ...:     pd.Series([1, 2], index=['a', 'b'])\n       ...:       .set_flags(allows_duplicate_labels=False)\n       ...: )\n\n    In [4]: a\n    Out[4]:\n    a    1\n    b    2\n    Length: 2, dtype: int64\n\n     An operation introducing duplicates\n    In [5]: a.reindex(['a', 'b', 'a'])\n    ...\n    DuplicateLabelError: Index has duplicates.\n          positions\n    label\n    a        [0, 2]\n\n    [1 rows x 1 columns]\n\n.. warning::\n\n   This is an experimental feature. Currently, many methods fail to\n   propagate the ``allows_duplicate_labels`` value. In future versions\n   it is expected that every method taking or returning one or more\n   DataFrame or Series objects will propagate ``allows_duplicate_labels``.\n\nSee :ref:`duplicates` for more.\n\nThe ``allows_duplicate_labels`` flag is stored in the new :attr:`DataFrame.flags`\nattribute. This stores global attributes that apply to the *pandas object*. This\ndiffers from :attr:`DataFrame.attrs`, which stores information that applies to\nthe dataset.\n\nPassing arguments to fsspec backends\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nMany read/write functions have acquired the ``storage_options`` optional argument,\nto pass a dictionary of parameters to the storage backend. This allows, for\nexample, for passing credentials to S3 and GCS storage. The details of what\nparameters can be passed to which backends can be found in the documentation\nof the individual storage backends (detailed from the fsspec docs for\n`builtin implementations`_ and linked to `external ones`_). See\nSection :ref:`io.remote`.\n\n:issue:`35655` added fsspec support (including ``storage_options``)\nfor reading excel files.\n\n.. _builtin implementations: https://filesystem-spec.readthedocs.io/en/latest/api.html#built-in-implementations\n.. _external ones: https://filesystem-spec.readthedocs.io/en/latest/api.html#other-known-implementations\n\n.. _whatsnew_120.binary_handle_to_csv:\n\nSupport for binary file handles in ``to_csv``\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n:meth:`to_csv` supports file handles in binary mode (:issue:`19827` and :issue:`35058`)\nwith ``encoding`` (:issue:`13068` and :issue:`23854`) and ``compression`` (:issue:`22555`).\nIf pandas does not automatically detect whether the file handle is opened in binary or text mode,\nit is necessary to provide ``mode=\"wb\"``.\n\nFor example:\n\n.. ipython:: python\n\n   import io\n\n   data = pd.DataFrame([0, 1, 2])\n   buffer = io.BytesIO()\n   data.to_csv(buffer, encoding=\"utf-8\", compression=\"gzip\")\n\nSupport for short caption and table position in ``to_latex``\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n:meth:`DataFrame.to_latex` now allows one to specify\na floating table position (:issue:`35281`)\nand a short caption (:issue:`36267`).\n\nThe keyword ``position`` has been added to set the position.\n\n.. ipython:: python\n   :okwarning:\n\n   data = pd.DataFrame({'a': [1, 2], 'b': [3, 4]})\n   table = data.to_latex(position='ht')\n   print(table)\n\nUsage of the keyword ``caption`` has been extended.\nBesides taking a single string as an argument,\none can optionally provide a tuple ``(full_caption, short_caption)``\nto add a short caption macro.\n\n.. ipython:: python\n   :okwarning:\n\n   data = pd.DataFrame({'a': [1, 2], 'b': [3, 4]})\n   table = data.to_latex(caption=('the full long caption', 'short caption'))\n   print(table)\n\n.. _whatsnew_120.read_csv_table_precision_default:\n\nChange in default floating precision for ``read_csv`` and ``read_table``\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nFor the C parsing engine, the methods :meth:`read_csv` and :meth:`read_table` previously defaulted to a parser that\ncould read floating point numbers slightly incorrectly with respect to the last bit in precision.\nThe option ``floating_precision=\"high\"`` has always been available to avoid this issue.\nBeginning with this version, the default is now to use the more accurate parser by making\n``floating_precision=None`` correspond to the high precision parser, and the new option\n``floating_precision=\"legacy\"`` to use the legacy parser. The change to using the higher precision\nparser by default should have no impact on performance. (:issue:`17154`)\n\n.. _whatsnew_120.floating:\n\nExperimental nullable data types for float data\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nWe've added :class:`Float32Dtype` / :class:`Float64Dtype` and :class:`~arrays.FloatingArray`.\nThese are extension data types dedicated to floating point data that can hold the\n``pd.NA`` missing value indicator (:issue:`32265`, :issue:`34307`).\n\nWhile the default float data type already supports missing values using ``np.nan``,\nthese new data types use ``pd.NA`` (and its corresponding behavior) as the missing\nvalue indicator, in line with the already existing nullable :ref:`integer <integer_na>`\nand :ref:`boolean <boolean>` data types.\n\nOne example where the behavior of ``np.nan`` and ``pd.NA`` is different is\ncomparison operations:\n\n.. ipython:: python\n\n   the default NumPy float64 dtype\n  s1 = pd.Series([1.5, None])\n  s1\n  s1 > 1\n\n.. ipython:: python\n\n   the new nullable float64 dtype\n  s2 = pd.Series([1.5, None], dtype=\"Float64\")\n  s2\n  s2 > 1\n\nSee the :ref:`missing_data.NA` doc section for more details on the behavior\nwhen using the ``pd.NA`` missing value indicator.\n\nAs shown above, the dtype can be specified using the \"Float64\" or \"Float32\"\nstring (capitalized to distinguish it from the default \"float64\" data type).\nAlternatively, you can also use the dtype object:\n\n.. ipython:: python\n\n   pd.Series([1.5, None], dtype=pd.Float32Dtype())\n\nOperations with the existing integer or boolean nullable data types that\ngive float results will now also use the nullable floating data types (:issue:`38178`).\n\n.. warning::\n\n   Experimental: the new floating data types are currently experimental, and their\n   behavior or API may still change without warning. Especially the behavior\n   regarding NaN (distinct from NA missing values) is subject to change.\n\n.. _whatsnew_120.index_name_preservation:\n\nIndex/column name preservation when aggregating\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nWhen aggregating using :meth:`concat` or the :class:`DataFrame` constructor, pandas\nwill now attempt to preserve index and column names whenever possible (:issue:`35847`).\nIn the case where all inputs share a common name, this name will be assigned to the\nresult. When the input names do not all agree, the result will be unnamed. Here is an\nexample where the index name is preserved:\n\n.. ipython:: python\n\n    idx = pd.Index(range(5), name='abc')\n    ser = pd.Series(range(5, 10), index=idx)\n    pd.concat({'x': ser[1:], 'y': ser[:-1]}, axis=1)\n\nThe same is true for :class:`MultiIndex`, but the logic is applied separately on a\nlevel-by-level basis.\n\n.. _whatsnew_120.groupby_ewm:\n\nGroupBy supports EWM operations directly\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n:class:`.DataFrameGroupBy` now supports exponentially weighted window operations directly (:issue:`16037`).\n\n.. ipython:: python\n\n    df = pd.DataFrame({'A': ['a', 'b', 'a', 'b'], 'B': range(4)})\n    df\n    df.groupby('A').ewm(com=1.0).mean()\n\nAdditionally ``mean`` supports execution via `Numba <https://numba.pydata.org/>`__ with\nthe  ``engine`` and ``engine_kwargs`` arguments. Numba must be installed as an optional dependency\nto use this feature.\n\n.. _whatsnew_120.enhancements.other:\n\nOther enhancements\n^^^^^^^^^^^^^^^^^^\n- Added ``day_of_week`` (compatibility alias ``dayofweek``) property to :class:`Timestamp`, :class:`.DatetimeIndex`, :class:`Period`, :class:`PeriodIndex` (:issue:`9605`)\n- Added ``day_of_year`` (compatibility alias ``dayofyear``) property to :class:`Timestamp`, :class:`.DatetimeIndex`, :class:`Period`, :class:`PeriodIndex` (:issue:`9605`)\n- Added :meth:`~DataFrame.set_flags` for setting table-wide flags on a Series or DataFrame (:issue:`28394`)\n- :meth:`DataFrame.applymap` now supports ``na_action`` (:issue:`23803`)\n- :class:`Index` with object dtype supports division and multiplication (:issue:`34160`)\n- :meth:`io.sql.get_schema` now supports a ``schema`` keyword argument that will add a schema into the create table statement (:issue:`28486`)\n- :meth:`DataFrame.explode` and :meth:`Series.explode` now support exploding of sets (:issue:`35614`)\n- :meth:`DataFrame.hist` now supports time series (datetime) data (:issue:`32590`)\n- :meth:`.Styler.set_table_styles` now allows the direct styling of rows and columns and can be chained (:issue:`35607`)\n- :class:`.Styler` now allows direct CSS class name addition to individual data cells (:issue:`36159`)\n- :meth:`.Rolling.mean` and :meth:`.Rolling.sum` use Kahan summation to calculate the mean to avoid numerical problems (:issue:`10319`, :issue:`11645`, :issue:`13254`, :issue:`32761`, :issue:`36031`)\n- :meth:`.DatetimeIndex.searchsorted`, :meth:`.TimedeltaIndex.searchsorted`, :meth:`PeriodIndex.searchsorted`, and :meth:`Series.searchsorted` with datetime-like dtypes will now try to cast string arguments (list-like and scalar) to the matching datetime-like type (:issue:`36346`)\n- Added methods :meth:`IntegerArray.prod`, :meth:`IntegerArray.min`, and :meth:`IntegerArray.max` (:issue:`33790`)\n- Calling a NumPy ufunc on a ``DataFrame`` with extension types now preserves the extension types when possible (:issue:`23743`)\n- Calling a binary-input NumPy ufunc on multiple ``DataFrame`` objects now aligns, matching the behavior of binary operations and ufuncs on ``Series`` (:issue:`23743`).\n  This change has been reverted in pandas 1.2.1, and the behaviour to not align DataFrames\n  is deprecated instead, see the :ref:`the 1.2.1 release notes <whatsnew_121.ufunc_deprecation>`.\n- Where possible :meth:`RangeIndex.difference` and :meth:`RangeIndex.symmetric_difference` will return :class:`RangeIndex` instead of :class:`Int64Index` (:issue:`36564`)\n- :meth:`DataFrame.to_parquet` now supports :class:`MultiIndex` for columns in parquet format (:issue:`34777`)\n- :func:`read_parquet` gained a ``use_nullable_dtypes=True`` option to use nullable dtypes that use ``pd.NA`` as missing value indicator where possible for the resulting DataFrame (default is ``False``, and only applicable for ``engine=\"pyarrow\"``) (:issue:`31242`)\n- Added :meth:`.Rolling.sem` and :meth:`Expanding.sem` to compute the standard error of the mean (:issue:`26476`)\n- :meth:`.Rolling.var` and :meth:`.Rolling.std` use Kahan summation and Welford's Method to avoid numerical issues (:issue:`37051`)\n- :meth:`DataFrame.corr` and :meth:`DataFrame.cov` use Welford's Method to avoid numerical issues (:issue:`37448`)\n- :meth:`DataFrame.plot` now recognizes ``xlabel`` and ``ylabel`` arguments for plots of type ``scatter`` and ``hexbin`` (:issue:`37001`)\n- :class:`DataFrame` now supports the ``divmod`` operation (:issue:`37165`)\n- :meth:`DataFrame.to_parquet` now returns a ``bytes`` object when no ``path`` argument is passed (:issue:`37105`)\n- :class:`.Rolling` now supports the ``closed`` argument for fixed windows (:issue:`34315`)\n- :class:`.DatetimeIndex` and :class:`Series` with ``datetime64`` or ``datetime64tz`` dtypes now support ``std`` (:issue:`37436`)\n- :class:`Window` now supports all Scipy window types in ``win_type`` with flexible keyword argument support (:issue:`34556`)\n- :meth:`testing.assert_index_equal` now has a ``check_order`` parameter that allows indexes to be checked in an order-insensitive manner (:issue:`37478`)\n- :func:`read_csv` supports memory-mapping for compressed files (:issue:`37621`)\n- Add support for ``min_count`` keyword for :meth:`DataFrame.groupby` and :meth:`DataFrame.resample` for functions ``min``, ``max``, ``first`` and ``last`` (:issue:`37821`, :issue:`37768`)\n- Improve error reporting for :meth:`DataFrame.merge` when invalid merge column definitions were given (:issue:`16228`)\n- Improve numerical stability for :meth:`.Rolling.skew`, :meth:`.Rolling.kurt`, :meth:`Expanding.skew` and :meth:`Expanding.kurt` through implementation of Kahan summation (:issue:`6929`)\n- Improved error reporting for subsetting columns of a :class:`.DataFrameGroupBy` with ``axis=1`` (:issue:`37725`)\n- Implement method ``cross`` for :meth:`DataFrame.merge` and :meth:`DataFrame.join` (:issue:`5401`)\n- When :func:`read_csv`, :func:`read_sas` and :func:`read_json` are called with ``chunksize``/``iterator`` they can be used in a ``with`` statement as they return context-managers (:issue:`38225`)\n- Augmented the list of named colors available for styling Excel exports, enabling all of CSS4 colors (:issue:`38247`)\n\n.. ---------------------------------------------------------------------------\n\n.. _whatsnew_120.notable_bug_fixes:\n\nNotable bug fixes\n~~~~~~~~~~~~~~~~~\n\nThese are bug fixes that might have notable behavior changes.\n\nConsistency of DataFrame Reductions\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n:meth:`DataFrame.any` and :meth:`DataFrame.all` with ``bool_only=True`` now\ndetermines whether to exclude object-dtype columns on a column-by-column basis,\ninstead of checking if *all* object-dtype columns can be considered boolean.\n\nThis prevents pathological behavior where applying the reduction on a subset\nof columns could result in a larger Series result. See (:issue:`37799`).\n\n.. ipython:: python\n\n    df = pd.DataFrame({\"A\": [\"foo\", \"bar\"], \"B\": [True, False]}, dtype=object)\n    df[\"C\"] = pd.Series([True, True])\n\n\n*Previous behavior*:\n\n.. code-block:: ipython\n\n    In [5]: df.all(bool_only=True)\n    Out[5]:\n    C    True\n    dtype: bool\n\n    In [6]: df[[\"B\", \"C\"]].all(bool_only=True)\n    Out[6]:\n    B    False\n    C    True\n    dtype: bool\n\n*New behavior*:\n\n.. ipython:: python\n   :okwarning:\n\n    In [5]: df.all(bool_only=True)\n\n    In [6]: df[[\"B\", \"C\"]].all(bool_only=True)\n\n\nOther DataFrame reductions with ``numeric_only=None`` will also avoid\nthis pathological behavior (:issue:`37827`):\n\n.. ipython:: python\n\n    df = pd.DataFrame({\"A\": [0, 1, 2], \"B\": [\"a\", \"b\", \"c\"]}, dtype=object)\n\n\n*Previous behavior*:\n\n.. code-block:: ipython\n\n    In [3]: df.mean()\n    Out[3]: Series([], dtype: float64)\n\n    In [4]: df[[\"A\"]].mean()\n    Out[4]:\n    A    1.0\n    dtype: float64\n\n*New behavior*:\n\n.. code-block:: ipython\n\n    In [3]: df.mean()\n    Out[3]:\n    A    1.0\n    dtype: float64\n\n    In [4]: df[[\"A\"]].mean()\n    Out[4]:\n    A    1.0\n    dtype: float64\n\nMoreover, DataFrame reductions with ``numeric_only=None`` will now be\nconsistent with their Series counterparts.  In particular, for\nreductions where the Series method raises ``TypeError``, the\nDataFrame reduction will now consider that column non-numeric\ninstead of casting to a NumPy array which may have different semantics (:issue:`36076`,\n:issue:`28949`, :issue:`21020`).\n\n.. ipython:: python\n   :okwarning:\n\n    ser = pd.Series([0, 1], dtype=\"category\", name=\"A\")\n    df = ser.to_frame()\n\n\n*Previous behavior*:\n\n.. code-block:: ipython\n\n    In [5]: df.any()\n    Out[5]:\n    A    True\n    dtype: bool\n\n*New behavior*:\n\n.. code-block:: ipython\n\n    In [5]: df.any()\n    Out[5]: Series([], dtype: bool)\n\n\n.. _whatsnew_120.api_breaking.python:\n\nIncreased minimum version for Python\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\npandas 1.2.0 supports Python 3.7.1 and higher (:issue:`35214`).\n\n.. _whatsnew_120.api_breaking.deps:\n\nIncreased minimum versions for dependencies\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nSome minimum supported versions of dependencies were updated (:issue:`35214`).\nIf installed, we now require:\n\n+-----------------+-----------------+----------+---------+\n| Package         | Minimum Version | Required | Changed |\n+=================+=================+==========+=========+\n| numpy           | 1.16.5          |    X     |    X    |\n+-----------------+-----------------+----------+---------+\n| pytz            | 2017.3          |    X     |    X    |\n+-----------------+-----------------+----------+---------+\n| python-dateutil | 2.7.3           |    X     |         |\n+-----------------+-----------------+----------+---------+\n| bottleneck      | 1.2.1           |          |         |\n+-----------------+-----------------+----------+---------+\n| numexpr         | 2.6.8           |          |    X    |\n+-----------------+-----------------+----------+---------+\n| pytest (dev)    | 5.0.1           |          |    X    |\n+-----------------+-----------------+----------+---------+\n| mypy (dev)      | 0.782           |          |    X    |\n+-----------------+-----------------+----------+---------+\n\nFor `optional libraries <https://pandas.pydata.org/docs/getting_started/install.html>`_ the general recommendation is to use the latest version.\nThe following table lists the lowest version per library that is currently being tested throughout the development of pandas.\nOptional libraries below the lowest tested version may still work, but are not considered supported.\n\n+-----------------+-----------------+---------+\n| Package         | Minimum Version | Changed |\n+=================+=================+=========+\n| beautifulsoup4  | 4.6.0           |         |\n+-----------------+-----------------+---------+\n| fastparquet     | 0.3.2           |         |\n+-----------------+-----------------+---------+\n| fsspec          | 0.7.4           |         |\n+-----------------+-----------------+---------+\n| gcsfs           | 0.6.0           |         |\n+-----------------+-----------------+---------+\n| lxml            | 4.3.0           |    X    |\n+-----------------+-----------------+---------+\n| matplotlib      | 2.2.3           |    X    |\n+-----------------+-----------------+---------+\n| numba           | 0.46.0          |         |\n+-----------------+-----------------+---------+\n| openpyxl        | 2.6.0           |    X    |\n+-----------------+-----------------+---------+\n| pyarrow         | 0.15.0          |    X    |\n+-----------------+-----------------+---------+\n| pymysql         | 0.7.11          |    X    |\n+-----------------+-----------------+---------+\n| pytables        | 3.5.1           |    X    |\n+-----------------+-----------------+---------+\n| s3fs            | 0.4.0           |         |\n+-----------------+-----------------+---------+\n| scipy           | 1.2.0           |         |\n+-----------------+-----------------+---------+\n| sqlalchemy      | 1.2.8           |    X    |\n+-----------------+-----------------+---------+\n| xarray          | 0.12.3          |    X    |\n+-----------------+-----------------+---------+\n| xlrd            | 1.2.0           |    X    |\n+-----------------+-----------------+---------+\n| xlsxwriter      | 1.0.2           |    X    |\n+-----------------+-----------------+---------+\n| xlwt            | 1.3.0           |    X    |\n+-----------------+-----------------+---------+\n| pandas-gbq      | 0.12.0          |         |\n+-----------------+-----------------+---------+\n\nSee :ref:`install.dependencies` and :ref:`install.optional_dependencies` for more.\n\n.. _whatsnew_120.api.other:\n\nOther API changes\n^^^^^^^^^^^^^^^^^\n\n- Sorting in descending order is now stable for :meth:`Series.sort_values` and :meth:`Index.sort_values` for Datetime-like :class:`Index` subclasses. This will affect sort order when sorting a DataFrame on multiple columns, sorting with a key function that produces duplicates, or requesting the sorting index when using :meth:`Index.sort_values`. When using :meth:`Series.value_counts`, the count of missing values is no longer necessarily last in the list of duplicate counts. Instead, its position corresponds to the position in the original Series. When using :meth:`Index.sort_values` for Datetime-like :class:`Index` subclasses, NaTs ignored the ``na_position`` argument and were sorted to the beginning. Now they respect ``na_position``, the default being ``last``, same as other :class:`Index` subclasses (:issue:`35992`)\n- Passing an invalid ``fill_value`` to :meth:`Categorical.take`, :meth:`.DatetimeArray.take`, :meth:`TimedeltaArray.take`, or :meth:`PeriodArray.take` now raises a ``TypeError`` instead of a ``ValueError`` (:issue:`37733`)\n- Passing an invalid ``fill_value`` to :meth:`Series.shift` with a ``CategoricalDtype`` now raises a ``TypeError`` instead of a ``ValueError`` (:issue:`37733`)\n- Passing an invalid value to :meth:`IntervalIndex.insert` or :meth:`CategoricalIndex.insert` now raises a ``TypeError`` instead of a ``ValueError`` (:issue:`37733`)\n- Attempting to reindex a Series with a :class:`CategoricalIndex` with an invalid ``fill_value`` now raises a ``TypeError`` instead of a ``ValueError`` (:issue:`37733`)\n- :meth:`CategoricalIndex.append` with an index that contains non-category values will now cast instead of raising ``TypeError`` (:issue:`38098`)\n\n.. ---------------------------------------------------------------------------\n\n.. _whatsnew_120.deprecations:\n\nDeprecations\n~~~~~~~~~~~~\n- Deprecated parameter ``inplace`` in :meth:`MultiIndex.set_codes` and :meth:`MultiIndex.set_levels` (:issue:`35626`)\n- Deprecated parameter ``dtype`` of method :meth:`~Index.copy` for all :class:`Index` subclasses. Use the :meth:`~Index.astype` method instead for changing dtype (:issue:`35853`)\n- Deprecated parameters ``levels`` and ``codes`` in :meth:`MultiIndex.copy`. Use the :meth:`~MultiIndex.set_levels` and :meth:`~MultiIndex.set_codes` methods instead (:issue:`36685`)\n- Date parser functions :func:`~pandas.io.date_converters.parse_date_time`, :func:`~pandas.io.date_converters.parse_date_fields`, :func:`~pandas.io.date_converters.parse_all_fields` and :func:`~pandas.io.date_converters.generic_parser` from ``pandas.io.date_converters`` are deprecated and will be removed in a future version; use :func:`to_datetime` instead (:issue:`35741`)\n- :meth:`DataFrame.lookup` is deprecated and will be removed in a future version, use :meth:`DataFrame.melt` and :meth:`DataFrame.loc` instead (:issue:`35224`)\n- The method :meth:`Index.to_native_types` is deprecated. Use ``.astype(str)`` instead (:issue:`28867`)\n- Deprecated indexing :class:`DataFrame` rows with a single datetime-like string as ``df[string]`` (given the ambiguity whether it is indexing the rows or selecting a column), use ``df.loc[string]`` instead (:issue:`36179`)\n- Deprecated :meth:`Index.is_all_dates` (:issue:`27744`)\n- The default value of ``regex`` for :meth:`Series.str.replace` will change from ``True`` to ``False`` in a future release. In addition, single character regular expressions will *not* be treated as literal strings when ``regex=True`` is set (:issue:`24804`)\n- Deprecated automatic alignment on comparison operations between :class:`DataFrame` and :class:`Series`, do ``frame, ser = frame.align(ser, axis=1, copy=False)`` before e.g. ``frame == ser`` (:issue:`28759`)\n- :meth:`Rolling.count` with ``min_periods=None`` will default to the size of the window in a future version (:issue:`31302`)\n- Using \"outer\" ufuncs on DataFrames to return 4d ndarray is now deprecated. Convert to an ndarray first (:issue:`23743`)\n- Deprecated slice-indexing on tz-aware :class:`DatetimeIndex` with naive ``datetime`` objects, to match scalar indexing behavior (:issue:`36148`)\n- :meth:`Index.ravel` returning a ``np.ndarray`` is deprecated, in the future this will return a view on the same index (:issue:`19956`)\n- Deprecate use of strings denoting units with 'M', 'Y' or 'y' in :func:`~pandas.to_timedelta` (:issue:`36666`)\n- :class:`Index` methods ``&``, ``|``, and ``^`` behaving as the set operations :meth:`Index.intersection`, :meth:`Index.union`, and :meth:`Index.symmetric_difference`, respectively, are deprecated and in the future will behave as pointwise boolean operations matching :class:`Series` behavior.  Use the named set methods instead (:issue:`36758`)\n- :meth:`Categorical.is_dtype_equal` and :meth:`CategoricalIndex.is_dtype_equal` are deprecated, will be removed in a future version (:issue:`37545`)\n- :meth:`Series.slice_shift` and :meth:`DataFrame.slice_shift` are deprecated, use :meth:`Series.shift` or :meth:`DataFrame.shift` instead (:issue:`37601`)\n- Partial slicing on unordered :class:`.DatetimeIndex` objects with keys that are not in the index is deprecated and will be removed in a future version (:issue:`18531`)\n- The ``how`` keyword in :meth:`PeriodIndex.astype` is deprecated and will be removed in a future version, use ``index.to_timestamp(how=how)`` instead (:issue:`37982`)\n- Deprecated :meth:`Index.asi8` for :class:`Index` subclasses other than :class:`.DatetimeIndex`, :class:`.TimedeltaIndex`, and :class:`PeriodIndex` (:issue:`37877`)\n- The ``inplace`` parameter of :meth:`Categorical.remove_unused_categories` is deprecated and will be removed in a future version (:issue:`37643`)\n- The ``null_counts`` parameter of :meth:`DataFrame.info` is deprecated and replaced by ``show_counts``. It will be removed in a future version (:issue:`37999`)\n\n**Calling NumPy ufuncs on non-aligned DataFrames**\n\nCalling NumPy ufuncs on non-aligned DataFrames changed behaviour in pandas\n1.2.0 (to align the inputs before calling the ufunc), but this change is\nreverted in pandas 1.2.1. The behaviour to not align is now deprecated instead,\nsee the :ref:`the 1.2.1 release notes <whatsnew_121.ufunc_deprecation>` for\nmore details.\n\n.. ---------------------------------------------------------------------------\n\n\n.. _whatsnew_120.performance:\n\nPerformance improvements\n~~~~~~~~~~~~~~~~~~~~~~~~\n\n- Performance improvements when creating DataFrame or Series with dtype ``str`` or :class:`StringDtype` from array with many string elements (:issue:`36304`, :issue:`36317`, :issue:`36325`, :issue:`36432`, :issue:`37371`)\n- Performance improvement in :meth:`.DataFrameGroupBy.agg` and :meth:`.SeriesGroupBy.agg` with the ``numba`` engine (:issue:`35759`)\n- Performance improvements when creating :meth:`Series.map` from a huge dictionary (:issue:`34717`)\n- Performance improvement in :meth:`.DataFrameGroupBy.transform` and :meth:`.SeriesGroupBy.transform` with the ``numba`` engine (:issue:`36240`)\n- :class:`.Styler` uuid method altered to compress data transmission over web whilst maintaining reasonably low table collision probability (:issue:`36345`)\n- Performance improvement in :func:`to_datetime` with non-ns time unit for ``float`` ``dtype`` columns (:issue:`20445`)\n- Performance improvement in setting values on an :class:`IntervalArray` (:issue:`36310`)\n- The internal index method :meth:`~Index._shallow_copy` now makes the new index and original index share cached attributes, avoiding creating these again, if created on either. This can speed up operations that depend on creating copies of existing indexes (:issue:`36840`)\n- Performance improvement in :meth:`.RollingGroupby.count` (:issue:`35625`)\n- Small performance decrease to :meth:`.Rolling.min` and :meth:`.Rolling.max` for fixed windows (:issue:`36567`)\n- Reduced peak memory usage in :meth:`DataFrame.to_pickle` when using ``protocol=5`` in python 3.8+ (:issue:`34244`)\n- Faster ``dir`` calls when the object has many index labels, e.g. ``dir(ser)`` (:issue:`37450`)\n- Performance improvement in :class:`ExpandingGroupby` (:issue:`37064`)\n- Performance improvement in :meth:`Series.astype` and :meth:`DataFrame.astype` for :class:`Categorical` (:issue:`8628`)\n- Performance improvement in :meth:`DataFrame.groupby` for ``float`` ``dtype`` (:issue:`28303`), changes of the underlying hash-function can lead to changes in float based indexes sort ordering for ties (e.g. :meth:`Index.value_counts`)\n- Performance improvement in :meth:`pd.isin` for inputs with more than 1e6 elements (:issue:`36611`)\n- Performance improvement for :meth:`DataFrame.__setitem__` with list-like indexers (:issue:`37954`)\n- :meth:`read_json` now avoids reading entire file into memory when chunksize is specified (:issue:`34548`)\n\n.. ---------------------------------------------------------------------------\n\n.. _whatsnew_120.bug_fixes:\n\nBug fixes\n~~~~~~~~~\n\nCategorical\n^^^^^^^^^^^\n- :meth:`Categorical.fillna` will always return a copy, validate a passed fill value regardless of whether there are any NAs to fill, and disallow an ``NaT`` as a fill value for numeric categories (:issue:`36530`)\n- Bug in :meth:`Categorical.__setitem__` that incorrectly raised when trying to set a tuple value (:issue:`20439`)\n- Bug in :meth:`CategoricalIndex.equals` incorrectly casting non-category entries to ``np.nan`` (:issue:`37667`)\n- Bug in :meth:`CategoricalIndex.where` incorrectly setting non-category entries to ``np.nan`` instead of raising ``TypeError`` (:issue:`37977`)\n- Bug in :meth:`Categorical.to_numpy` and ``np.array(categorical)`` with tz-aware ``datetime64`` categories incorrectly dropping the time zone information instead of casting to object dtype (:issue:`38136`)\n\nDatetime-like\n^^^^^^^^^^^^^\n- Bug in :meth:`DataFrame.combine_first` that would convert datetime-like column on other :class:`DataFrame` to integer when the column is not present in original :class:`DataFrame` (:issue:`28481`)\n- Bug in :attr:`.DatetimeArray.date` where a ``ValueError`` would be raised with a read-only backing array (:issue:`33530`)\n- Bug in ``NaT`` comparisons failing to raise ``TypeError`` on invalid inequality comparisons (:issue:`35046`)\n- Bug in :class:`.DateOffset` where attributes reconstructed from pickle files differ from original objects when input values exceed normal ranges (e.g. months=12) (:issue:`34511`)\n- Bug in :meth:`.DatetimeIndex.get_slice_bound` where ``datetime.date`` objects were not accepted or naive :class:`Timestamp` with a tz-aware :class:`.DatetimeIndex` (:issue:`35690`)\n- Bug in :meth:`.DatetimeIndex.slice_locs` where ``datetime.date`` objects were not accepted (:issue:`34077`)\n- Bug in :meth:`.DatetimeIndex.searchsorted`, :meth:`.TimedeltaIndex.searchsorted`, :meth:`PeriodIndex.searchsorted`, and :meth:`Series.searchsorted` with ``datetime64``, ``timedelta64`` or :class:`Period` dtype placement of ``NaT`` values being inconsistent with NumPy (:issue:`36176`, :issue:`36254`)\n- Inconsistency in :class:`.DatetimeArray`, :class:`.TimedeltaArray`, and :class:`.PeriodArray` method ``__setitem__`` casting arrays of strings to datetime-like scalars but not scalar strings (:issue:`36261`)\n- Bug in :meth:`.DatetimeArray.take` incorrectly allowing ``fill_value`` with a mismatched time zone (:issue:`37356`)\n- Bug in :class:`.DatetimeIndex.shift` incorrectly raising when shifting empty indexes (:issue:`14811`)\n- :class:`Timestamp` and :class:`.DatetimeIndex` comparisons between tz-aware and tz-naive objects now follow the standard library ``datetime`` behavior, returning ``True``/``False`` for ``!=``/``==`` and raising for inequality comparisons (:issue:`28507`)\n- Bug in :meth:`.DatetimeIndex.equals` and :meth:`.TimedeltaIndex.equals` incorrectly considering ``int64`` indexes as equal (:issue:`36744`)\n- :meth:`Series.to_json`, :meth:`DataFrame.to_json`, and :meth:`read_json` now implement time zone parsing when orient structure is ``table`` (:issue:`35973`)\n- :meth:`astype` now attempts to convert to ``datetime64[ns, tz]`` directly from ``object`` with inferred time zone from string (:issue:`35973`)\n- Bug in :meth:`.TimedeltaIndex.sum` and :meth:`Series.sum` with ``timedelta64`` dtype on an empty index or series returning ``NaT`` instead of ``Timedelta(0)`` (:issue:`31751`)\n- Bug in :meth:`.DatetimeArray.shift` incorrectly allowing ``fill_value`` with a mismatched time zone (:issue:`37299`)\n- Bug in adding a :class:`.BusinessDay` with nonzero ``offset`` to a non-scalar other (:issue:`37457`)\n- Bug in :func:`to_datetime` with a read-only array incorrectly raising (:issue:`34857`)\n- Bug in :meth:`Series.isin` with ``datetime64[ns]`` dtype and :meth:`.DatetimeIndex.isin` incorrectly casting integers to datetimes (:issue:`36621`)\n- Bug in :meth:`Series.isin` with ``datetime64[ns]`` dtype and :meth:`.DatetimeIndex.isin` failing to consider tz-aware and tz-naive datetimes as always different (:issue:`35728`)\n- Bug in :meth:`Series.isin` with ``PeriodDtype`` dtype and :meth:`PeriodIndex.isin` failing to consider arguments with different ``PeriodDtype`` as always different (:issue:`37528`)\n- Bug in :class:`Period` constructor now correctly handles nanoseconds in the ``value`` argument (:issue:`34621` and :issue:`17053`)\n\nTimedelta\n^^^^^^^^^\n- Bug in :class:`.TimedeltaIndex`, :class:`Series`, and :class:`DataFrame` floor-division with ``timedelta64`` dtypes and ``NaT`` in the denominator (:issue:`35529`)\n- Bug in parsing of ISO 8601 durations in :class:`Timedelta` and :func:`to_datetime` (:issue:`29773`, :issue:`36204`)\n- Bug in :func:`to_timedelta` with a read-only array incorrectly raising (:issue:`34857`)\n- Bug in :class:`Timedelta` incorrectly truncating to sub-second portion of a string input when it has precision higher than nanoseconds (:issue:`36738`)\n\nTimezones\n^^^^^^^^^\n\n- Bug in :func:`date_range` was raising ``AmbiguousTimeError`` for valid input with ``ambiguous=False`` (:issue:`35297`)\n- Bug in :meth:`Timestamp.replace` was losing fold information (:issue:`37610`)\n\n\nNumeric\n^^^^^^^\n- Bug in :func:`to_numeric` where float precision was incorrect (:issue:`31364`)\n- Bug in :meth:`DataFrame.any` with ``axis=1`` and ``bool_only=True`` ignoring the ``bool_only`` keyword (:issue:`32432`)\n- Bug in :meth:`Series.equals` where a ``ValueError`` was raised when NumPy arrays were compared to scalars (:issue:`35267`)\n- Bug in :class:`Series` where two Series each have a :class:`.DatetimeIndex` with different time zones having those indexes incorrectly changed when performing arithmetic operations (:issue:`33671`)\n- Bug in :mod:`pandas.testing` module functions when used with ``check_exact=False`` on complex numeric types (:issue:`28235`)\n- Bug in :meth:`DataFrame.__rmatmul__` error handling reporting transposed shapes (:issue:`21581`)\n- Bug in :class:`Series` flex arithmetic methods where the result when operating with a ``list``, ``tuple`` or ``np.ndarray`` would have an incorrect name (:issue:`36760`)\n- Bug in :class:`.IntegerArray` multiplication with ``timedelta`` and ``np.timedelta64`` objects (:issue:`36870`)\n- Bug in :class:`MultiIndex` comparison with tuple incorrectly treating tuple as array-like (:issue:`21517`)\n- Bug in :meth:`DataFrame.diff` with ``datetime64`` dtypes including ``NaT`` values failing to fill ``NaT`` results correctly (:issue:`32441`)\n- Bug in :class:`DataFrame` arithmetic ops incorrectly accepting keyword arguments (:issue:`36843`)\n- Bug in :class:`.IntervalArray` comparisons with :class:`Series` not returning Series (:issue:`36908`)\n- Bug in :class:`DataFrame` allowing arithmetic operations with list of array-likes with undefined results. Behavior changed to raising ``ValueError`` (:issue:`36702`)\n- Bug in :meth:`DataFrame.std` with ``timedelta64`` dtype and ``skipna=False`` (:issue:`37392`)\n- Bug in :meth:`DataFrame.min` and :meth:`DataFrame.max` with ``datetime64`` dtype and ``skipna=False`` (:issue:`36907`)\n- Bug in :meth:`DataFrame.idxmax` and :meth:`DataFrame.idxmin` with mixed dtypes incorrectly raising ``TypeError`` (:issue:`38195`)\n\nConversion\n^^^^^^^^^^\n\n- Bug in :meth:`DataFrame.to_dict` with ``orient='records'`` now returns python native datetime objects for datetime-like columns (:issue:`21256`)\n- Bug in :meth:`Series.astype` conversion from ``string`` to ``float`` raised in presence of ``pd.NA`` values (:issue:`37626`)\n\nStrings\n^^^^^^^\n- Bug in :meth:`Series.to_string`, :meth:`DataFrame.to_string`, and :meth:`DataFrame.to_latex` adding a leading space when ``index=False`` (:issue:`24980`)\n- Bug in :func:`to_numeric` raising a ``TypeError`` when attempting to convert a string dtype Series containing only numeric strings and ``NA`` (:issue:`37262`)\n\nInterval\n^^^^^^^^\n\n- Bug in :meth:`DataFrame.replace` and :meth:`Series.replace` where :class:`Interval` dtypes would be converted to object dtypes (:issue:`34871`)\n- Bug in :meth:`IntervalIndex.take` with negative indices and ``fill_value=None`` (:issue:`37330`)\n- Bug in :meth:`IntervalIndex.putmask` with datetime-like dtype incorrectly casting to object dtype (:issue:`37968`)\n- Bug in :meth:`IntervalArray.astype` incorrectly dropping dtype information with a :class:`CategoricalDtype` object (:issue:`37984`)\n\nIndexing\n^^^^^^^^\n\n- Bug in :meth:`PeriodIndex.get_loc` incorrectly raising ``ValueError`` on non-datelike strings instead of ``KeyError``, causing similar errors in :meth:`Series.__getitem__`, :meth:`Series.__contains__`, and :meth:`Series.loc.__getitem__` (:issue:`34240`)\n- Bug in :meth:`Index.sort_values` where, when empty values were passed, the method would break by trying to compare missing values instead of pushing them to the end of the sort order (:issue:`35584`)\n- Bug in :meth:`Index.get_indexer` and :meth:`Index.get_indexer_non_unique` where ``int64`` arrays are returned instead of ``intp`` (:issue:`36359`)\n- Bug in :meth:`DataFrame.sort_index` where parameter ascending passed as a list on a single level index gives wrong result (:issue:`32334`)\n- Bug in :meth:`DataFrame.reset_index` was incorrectly raising a ``ValueError`` for input with a :class:`MultiIndex` with missing values in a level with ``Categorical`` dtype (:issue:`24206`)\n- Bug in indexing with boolean masks on datetime-like values sometimes returning a view instead of a copy (:issue:`36210`)\n- Bug in :meth:`DataFrame.__getitem__` and :meth:`DataFrame.loc.__getitem__` with :class:`IntervalIndex` columns and a numeric indexer (:issue:`26490`)\n- Bug in :meth:`Series.loc.__getitem__` with a non-unique :class:`MultiIndex` and an empty-list indexer (:issue:`13691`)\n- Bug in indexing on a :class:`Series` or :class:`DataFrame` with a :class:`MultiIndex` and a level named ``\"0\"`` (:issue:`37194`)\n- Bug in :meth:`Series.__getitem__` when using an unsigned integer array as an indexer giving incorrect results or segfaulting instead of raising ``KeyError`` (:issue:`37218`)\n- Bug in :meth:`Index.where` incorrectly casting numeric values to strings (:issue:`37591`)\n- Bug in :meth:`DataFrame.loc` returning empty result when indexer is a slice with negative step size (:issue:`38071`)\n- Bug in :meth:`Series.loc` and :meth:`DataFrame.loc` raises when the index was of ``object`` dtype and the given numeric label was in the index (:issue:`26491`)\n- Bug in :meth:`DataFrame.loc` returned requested key plus missing values when ``loc`` was applied to single level from a :class:`MultiIndex` (:issue:`27104`)\n- Bug in indexing on a :class:`Series` or :class:`DataFrame` with a :class:`CategoricalIndex` using a list-like indexer containing NA values (:issue:`37722`)\n- Bug in :meth:`DataFrame.loc.__setitem__` expanding an empty :class:`DataFrame` with mixed dtypes (:issue:`37932`)\n- Bug in :meth:`DataFrame.xs` ignored ``droplevel=False`` for columns (:issue:`19056`)\n- Bug in :meth:`DataFrame.reindex` raising ``IndexingError`` wrongly for empty DataFrame with ``tolerance`` not ``None`` or ``method=\"nearest\"`` (:issue:`27315`)\n- Bug in indexing on a :class:`Series` or :class:`DataFrame` with a :class:`CategoricalIndex` using list-like indexer that contains elements that are in the index's ``categories`` but not in the index itself failing to raise ``KeyError`` (:issue:`37901`)\n- Bug on inserting a boolean label into a :class:`DataFrame` with a numeric :class:`Index` columns incorrectly casting to integer (:issue:`36319`)\n- Bug in :meth:`DataFrame.iloc` and :meth:`Series.iloc` aligning objects in ``__setitem__`` (:issue:`22046`)\n- Bug in :meth:`MultiIndex.drop` does not raise if labels are partially found (:issue:`37820`)\n- Bug in :meth:`DataFrame.loc` did not raise ``KeyError`` when missing combination was given with ``slice(None)`` for remaining levels (:issue:`19556`)\n- Bug in :meth:`DataFrame.loc` raising ``TypeError`` when non-integer slice was given to select values from :class:`MultiIndex` (:issue:`25165`, :issue:`24263`)\n- Bug in :meth:`Series.at` returning :class:`Series` with one element instead of scalar when index is a :class:`MultiIndex` with one level (:issue:`38053`)\n- Bug in :meth:`DataFrame.loc` returning and assigning elements in wrong order when indexer is differently ordered than the :class:`MultiIndex` to filter (:issue:`31330`, :issue:`34603`)\n- Bug in :meth:`DataFrame.loc` and :meth:`DataFrame.__getitem__`  raising ``KeyError`` when columns were :class:`MultiIndex` with only one level (:issue:`29749`)\n- Bug in :meth:`Series.__getitem__` and :meth:`DataFrame.__getitem__` raising blank ``KeyError`` without missing keys for :class:`IntervalIndex` (:issue:`27365`)\n- Bug in setting a new label on a :class:`DataFrame` or :class:`Series` with a :class:`CategoricalIndex` incorrectly raising ``TypeError`` when the new label is not among the index's categories (:issue:`38098`)\n- Bug in :meth:`Series.loc` and :meth:`Series.iloc` raising ``ValueError`` when inserting a list-like ``np.array``, ``list`` or ``tuple`` in an ``object`` Series of equal length (:issue:`37748`, :issue:`37486`)\n- Bug in :meth:`Series.loc` and :meth:`Series.iloc` setting all the values of an ``object`` Series with those of a list-like ``ExtensionArray`` instead of inserting it (:issue:`38271`)\n\nMissing\n^^^^^^^\n\n- Bug in :meth:`.SeriesGroupBy.transform` now correctly handles missing values for ``dropna=False`` (:issue:`35014`)\n- Bug in :meth:`Series.nunique` with ``dropna=True`` was returning incorrect results when both ``NA`` and ``None`` missing values were present (:issue:`37566`)\n- Bug in :meth:`Series.interpolate` where kwarg ``limit_area`` and ``limit_direction`` had no effect when using methods ``pad`` and ``backfill`` (:issue:`31048`)\n\nMultiIndex\n^^^^^^^^^^\n\n- Bug in :meth:`DataFrame.xs` when used with :class:`IndexSlice` raises ``TypeError`` with message ``\"Expected label or tuple of labels\"`` (:issue:`35301`)\n- Bug in :meth:`DataFrame.reset_index` with ``NaT`` values in index raises ``ValueError`` with message ``\"cannot convert float NaN to integer\"`` (:issue:`36541`)\n- Bug in :meth:`DataFrame.combine_first` when used with :class:`MultiIndex` containing string and ``NaN`` values raises ``TypeError`` (:issue:`36562`)\n- Bug in :meth:`MultiIndex.drop` dropped ``NaN`` values when non existing key was given as input (:issue:`18853`)\n- Bug in :meth:`MultiIndex.drop` dropping more values than expected when index has duplicates and is not sorted (:issue:`33494`)\n\nI/O\n^^^\n\n- :func:`read_sas` no longer leaks resources on failure (:issue:`35566`)\n- Bug in :meth:`DataFrame.to_csv` and :meth:`Series.to_csv` caused a ``ValueError`` when it was called with a filename in combination with ``mode`` containing a ``b`` (:issue:`35058`)\n- Bug in :meth:`read_csv` with ``float_precision='round_trip'`` did not handle ``decimal`` and ``thousands`` parameters (:issue:`35365`)\n- :meth:`to_pickle` and :meth:`read_pickle` were closing user-provided file objects (:issue:`35679`)\n- :meth:`to_csv` passes compression arguments for ``'gzip'`` always to ``gzip.GzipFile`` (:issue:`28103`)\n- :meth:`to_csv` did not support zip compression for binary file object not having a filename (:issue:`35058`)\n- :meth:`to_csv` and :meth:`read_csv` did not honor ``compression`` and ``encoding`` for path-like objects that are internally converted to file-like objects (:issue:`35677`, :issue:`26124`, :issue:`32392`)\n- :meth:`DataFrame.to_pickle`, :meth:`Series.to_pickle`, and :meth:`read_pickle` did not support compression for file-objects (:issue:`26237`, :issue:`29054`, :issue:`29570`)\n- Bug in :func:`LongTableBuilder.middle_separator` was duplicating LaTeX longtable entries in the List of Tables of a LaTeX document (:issue:`34360`)\n- Bug in :meth:`read_csv` with ``engine='python'`` truncating data if multiple items present in first row and first element started with BOM (:issue:`36343`)\n- Removed ``private_key`` and ``verbose`` from :func:`read_gbq` as they are no longer supported in ``pandas-gbq`` (:issue:`34654`, :issue:`30200`)\n- Bumped minimum pytables version to 3.5.1 to avoid a ``ValueError`` in :meth:`read_hdf` (:issue:`24839`)\n- Bug in :func:`read_table` and :func:`read_csv` when ``delim_whitespace=True`` and ``sep=default`` (:issue:`36583`)\n- Bug in :meth:`DataFrame.to_json` and :meth:`Series.to_json` when used with ``lines=True`` and ``orient='records'`` the last line of the record is not appended with 'new line character' (:issue:`36888`)\n- Bug in :meth:`read_parquet` with fixed offset time zones. String representation of time zones was not recognized (:issue:`35997`, :issue:`36004`)\n- Bug in :meth:`DataFrame.to_html`, :meth:`DataFrame.to_string`, and :meth:`DataFrame.to_latex` ignoring the ``na_rep`` argument when ``float_format`` was also specified (:issue:`9046`, :issue:`13828`)\n- Bug in output rendering of complex numbers showing too many trailing zeros (:issue:`36799`)\n- Bug in :class:`HDFStore` threw a ``TypeError`` when exporting an empty DataFrame with ``datetime64[ns, tz]`` dtypes with a fixed HDF5 store (:issue:`20594`)\n- Bug in :class:`HDFStore` was dropping time zone information when exporting a Series with ``datetime64[ns, tz]`` dtypes with a fixed HDF5 store (:issue:`20594`)\n- :func:`read_csv` was closing user-provided binary file handles when ``engine=\"c\"`` and an ``encoding`` was requested (:issue:`36980`)\n- Bug in :meth:`DataFrame.to_hdf` was not dropping missing rows with ``dropna=True`` (:issue:`35719`)\n- Bug in :func:`read_html` was raising a ``TypeError`` when supplying a ``pathlib.Path`` argument to the ``io`` parameter (:issue:`37705`)\n- :meth:`DataFrame.to_excel`, :meth:`Series.to_excel`, :meth:`DataFrame.to_markdown`, and :meth:`Series.to_markdown` now support writing to fsspec URLs such as S3 and Google Cloud Storage (:issue:`33987`)\n- Bug in :func:`read_fwf` with ``skip_blank_lines=True`` was not skipping blank lines (:issue:`37758`)\n- Parse missing values using :func:`read_json` with ``dtype=False`` to ``NaN`` instead of ``None`` (:issue:`28501`)\n- :meth:`read_fwf` was inferring compression with ``compression=None`` which was not consistent with the other ``read_*`` functions (:issue:`37909`)\n- :meth:`DataFrame.to_html` was ignoring ``formatters`` argument for ``ExtensionDtype`` columns (:issue:`36525`)\n- Bumped minimum xarray version to 0.12.3 to avoid reference to the removed ``Panel`` class (:issue:`27101`, :issue:`37983`)\n- :meth:`DataFrame.to_csv` was re-opening file-like handles that also implement ``os.PathLike`` (:issue:`38125`)\n- Bug in the conversion of a sliced ``pyarrow.Table`` with missing values to a DataFrame (:issue:`38525`)\n- Bug in :func:`read_sql_table` raising a ``sqlalchemy.exc.OperationalError`` when column names contained a percentage sign (:issue:`37517`)\n\nPeriod\n^^^^^^\n\n- Bug in :meth:`DataFrame.replace` and :meth:`Series.replace` where :class:`Period` dtypes would be converted to object dtypes (:issue:`34871`)\n\nPlotting\n^^^^^^^^\n\n- Bug in :meth:`DataFrame.plot` was rotating xticklabels when ``subplots=True``, even if the x-axis wasn't an irregular time series (:issue:`29460`)\n- Bug in :meth:`DataFrame.plot` where a marker letter in the ``style`` keyword sometimes caused a ``ValueError`` (:issue:`21003`)\n- Bug in :meth:`DataFrame.plot.bar` and :meth:`Series.plot.bar` where ticks positions were assigned by value order instead of using the actual value for numeric or a smart ordering for string (:issue:`26186`, :issue:`11465`). This fix has been reverted in pandas 1.2.1, see :doc:`v1.2.1`\n- Twinned axes were losing their tick labels which should only happen to all but the last row or column of 'externally' shared axes (:issue:`33819`)\n- Bug in :meth:`Series.plot` and :meth:`DataFrame.plot` was throwing a :exc:`ValueError` when the Series or DataFrame was\n  indexed by a :class:`.TimedeltaIndex` with a fixed frequency and the x-axis lower limit was greater than the upper limit (:issue:`37454`)\n- Bug in :meth:`.DataFrameGroupBy.boxplot` when ``subplots=False`` would raise a ``KeyError`` (:issue:`16748`)\n- Bug in :meth:`DataFrame.plot` and :meth:`Series.plot` was overwriting matplotlib's shared y axes behavior when no ``sharey`` parameter was passed (:issue:`37942`)\n- Bug in :meth:`DataFrame.plot` was raising a ``TypeError`` with ``ExtensionDtype`` columns (:issue:`32073`)\n\nStyler\n^^^^^^\n\n- Bug in :meth:`Styler.render` HTML was generated incorrectly because of formatting error in ``rowspan`` attribute, it now matches with w3 syntax (:issue:`38234`)\n\nGroupby/resample/rolling\n^^^^^^^^^^^^^^^^^^^^^^^^\n\n- Bug in :meth:`.DataFrameGroupBy.count` and :meth:`SeriesGroupBy.sum` returning ``NaN`` for missing categories when grouped on multiple ``Categoricals``. Now returning ``0`` (:issue:`35028`)\n- Bug in :meth:`.DataFrameGroupBy.apply` that would sometimes throw an erroneous ``ValueError`` if the grouping axis had duplicate entries (:issue:`16646`)\n- Bug in :meth:`DataFrame.resample` that would throw a ``ValueError`` when resampling from ``\"D\"`` to ``\"24H\"`` over a transition into daylight savings time (DST) (:issue:`35219`)\n- Bug when combining methods :meth:`DataFrame.groupby` with :meth:`DataFrame.resample` and :meth:`DataFrame.interpolate` raising a ``TypeError`` (:issue:`35325`)\n- Bug in :meth:`.DataFrameGroupBy.apply` where a non-nuisance grouping column would be dropped from the output columns if another groupby method was called before ``.apply`` (:issue:`34656`)\n- Bug when subsetting columns on a :class:`.DataFrameGroupBy` (e.g. ``df.groupby('a')[['b']])``) would reset the attributes ``axis``, ``dropna``, ``group_keys``, ``level``, ``mutated``, ``sort``, and ``squeeze`` to their default values (:issue:`9959`)\n- Bug in :meth:`.DataFrameGroupBy.tshift` failing to raise ``ValueError`` when a frequency cannot be inferred for the index of a group (:issue:`35937`)\n- Bug in :meth:`DataFrame.groupby` does not always maintain column index name for ``any``, ``all``, ``bfill``, ``ffill``, ``shift`` (:issue:`29764`)\n- Bug in :meth:`.DataFrameGroupBy.apply` raising error with ``np.nan`` group(s) when ``dropna=False`` (:issue:`35889`)\n- Bug in :meth:`.Rolling.sum` returned wrong values when dtypes where mixed between float and integer and ``axis=1`` (:issue:`20649`, :issue:`35596`)\n- Bug in :meth:`.Rolling.count` returned ``np.nan`` with :class:`~pandas.api.indexers.FixedForwardWindowIndexer` as window, ``min_periods=0`` and only missing values in the window (:issue:`35579`)\n- Bug where :class:`.Rolling` produces incorrect window sizes when using a ``PeriodIndex`` (:issue:`34225`)\n- Bug in :meth:`.DataFrameGroupBy.ffill` and :meth:`.DataFrameGroupBy.bfill` where a ``NaN`` group would return filled values instead of ``NaN`` when ``dropna=True`` (:issue:`34725`)\n- Bug in :meth:`.RollingGroupby.count` where a ``ValueError`` was raised when specifying the ``closed`` parameter (:issue:`35869`)\n- Bug in :meth:`.DataFrameGroupBy.rolling` returning wrong values with partial centered window (:issue:`36040`)\n- Bug in :meth:`.DataFrameGroupBy.rolling` returned wrong values with time aware window containing ``NaN``. Raises ``ValueError`` because windows are not monotonic now (:issue:`34617`)\n- Bug in :meth:`.Rolling.__iter__` where a ``ValueError`` was not raised when ``min_periods`` was larger than ``window`` (:issue:`37156`)\n- Using :meth:`.Rolling.var` instead of :meth:`.Rolling.std` avoids numerical issues for :meth:`.Rolling.corr` when :meth:`.Rolling.var` is still within floating point precision while :meth:`.Rolling.std` is not (:issue:`31286`)\n- Bug in :meth:`.DataFrameGroupBy.quantile` and :meth:`.Resampler.quantile` raised ``TypeError`` when values were of type ``Timedelta`` (:issue:`29485`)\n- Bug in :meth:`.Rolling.median` and :meth:`.Rolling.quantile` returned wrong values for :class:`.BaseIndexer` subclasses with non-monotonic starting or ending points for windows (:issue:`37153`)\n- Bug in :meth:`DataFrame.groupby` dropped ``nan`` groups from result with ``dropna=False`` when grouping over a single column (:issue:`35646`, :issue:`35542`)\n- Bug in :meth:`.DataFrameGroupBy.head`, :meth:`DataFrameGroupBy.tail`, :meth:`SeriesGroupBy.head`, and :meth:`SeriesGroupBy.tail` would raise when used with ``axis=1`` (:issue:`9772`)\n- Bug in :meth:`.DataFrameGroupBy.transform` would raise when used with ``axis=1`` and a transformation kernel (e.g. \"shift\") (:issue:`36308`)\n- Bug in :meth:`.DataFrameGroupBy.resample` using ``.agg`` with sum produced different result than just calling ``.sum`` (:issue:`33548`)\n- Bug in :meth:`.DataFrameGroupBy.apply` dropped values on ``nan`` group when returning the same axes with the original frame (:issue:`38227`)\n- Bug in :meth:`.DataFrameGroupBy.quantile` couldn't handle with arraylike ``q`` when grouping by columns (:issue:`33795`)\n- Bug in :meth:`DataFrameGroupBy.rank` with ``datetime64tz`` or period dtype incorrectly casting results to those dtypes instead of returning ``float64`` dtype (:issue:`38187`)\n\nReshaping\n^^^^^^^^^\n\n- Bug in :meth:`DataFrame.crosstab` was returning incorrect results on inputs with duplicate row names, duplicate column names or duplicate names between row and column labels (:issue:`22529`)\n- Bug in :meth:`DataFrame.pivot_table` with ``aggfunc='count'`` or ``aggfunc='sum'`` returning ``NaN`` for missing categories when pivoted on a ``Categorical``. Now returning ``0`` (:issue:`31422`)\n- Bug in :func:`concat` and :class:`DataFrame` constructor where input index names are not preserved in some cases (:issue:`13475`)\n- Bug in func :meth:`crosstab` when using multiple columns with ``margins=True`` and ``normalize=True`` (:issue:`35144`)\n- Bug in :meth:`DataFrame.stack` where an empty DataFrame.stack would raise an error (:issue:`36113`). Now returning an empty Series with empty MultiIndex.\n- Bug in :meth:`Series.unstack`. Now a Series with single level of Index trying to unstack would raise a ``ValueError`` (:issue:`36113`)\n- Bug in :meth:`DataFrame.agg` with ``func={'name':<FUNC>}`` incorrectly raising ``TypeError`` when ``DataFrame.columns==['Name']`` (:issue:`36212`)\n- Bug in :meth:`Series.transform` would give incorrect results or raise when the argument ``func`` was a dictionary (:issue:`35811`)\n- Bug in :meth:`DataFrame.pivot` did not preserve :class:`MultiIndex` level names for columns when rows and columns are both multiindexed (:issue:`36360`)\n- Bug in :meth:`DataFrame.pivot` modified ``index`` argument when ``columns`` was passed but ``values`` was not (:issue:`37635`)\n- Bug in :meth:`DataFrame.join` returned a non deterministic level-order for the resulting :class:`MultiIndex` (:issue:`36910`)\n- Bug in :meth:`DataFrame.combine_first` caused wrong alignment with dtype ``string`` and one level of ``MultiIndex`` containing only ``NA`` (:issue:`37591`)\n- Fixed regression in :func:`merge` on merging :class:`.DatetimeIndex` with empty DataFrame (:issue:`36895`)\n- Bug in :meth:`DataFrame.apply` not setting index of return value when ``func`` return type is ``dict`` (:issue:`37544`)\n- Bug in :meth:`DataFrame.merge` and :meth:`pandas.merge` returning inconsistent ordering in result for ``how=right`` and ``how=left`` (:issue:`35382`)\n- Bug in :func:`merge_ordered` couldn't handle list-like ``left_by`` or ``right_by`` (:issue:`35269`)\n- Bug in :func:`merge_ordered` returned wrong join result when length of ``left_by`` or ``right_by`` equals to the rows of ``left`` or ``right`` (:issue:`38166`)\n- Bug in :func:`merge_ordered` didn't raise when elements in ``left_by`` or ``right_by`` not exist in ``left`` columns or ``right`` columns (:issue:`38167`)\n- Bug in :func:`DataFrame.drop_duplicates` not validating bool dtype for ``ignore_index`` keyword (:issue:`38274`)\n\nExtensionArray\n^^^^^^^^^^^^^^\n\n- Fixed bug where :class:`DataFrame` column set to scalar extension type via a dict instantiation was considered an object type rather than the extension type (:issue:`35965`)\n- Fixed bug where ``astype()`` with equal dtype and ``copy=False`` would return a new object (:issue:`28488`)\n- Fixed bug when applying a NumPy ufunc with multiple outputs to an :class:`.IntegerArray` returning ``None`` (:issue:`36913`)\n- Fixed an inconsistency in :class:`.PeriodArray`'s ``__init__`` signature to those of :class:`.DatetimeArray` and :class:`.TimedeltaArray` (:issue:`37289`)\n- Reductions for :class:`.BooleanArray`, :class:`.Categorical`, :class:`.DatetimeArray`, :class:`.FloatingArray`, :class:`.IntegerArray`, :class:`.PeriodArray`, :class:`.TimedeltaArray`, and :class:`.PandasArray` are now keyword-only methods (:issue:`37541`)\n- Fixed a bug where a  ``TypeError`` was wrongly raised if a membership check was made on an ``ExtensionArray`` containing nan-like values (:issue:`37867`)\n\nOther\n^^^^^\n\n- Bug in :meth:`DataFrame.replace` and :meth:`Series.replace` incorrectly raising an ``AssertionError`` instead of a ``ValueError`` when invalid parameter combinations are passed (:issue:`36045`)\n- Bug in :meth:`DataFrame.replace` and :meth:`Series.replace` with numeric values and string ``to_replace`` (:issue:`34789`)\n- Fixed metadata propagation in :meth:`Series.abs` and ufuncs called on Series and DataFrames (:issue:`28283`)\n- Bug in :meth:`DataFrame.replace` and :meth:`Series.replace` incorrectly casting from ``PeriodDtype`` to object dtype (:issue:`34871`)\n- Fixed bug in metadata propagation incorrectly copying DataFrame columns as metadata when the column name overlaps with the metadata name (:issue:`37037`)\n- Fixed metadata propagation in the :class:`Series.dt`, :class:`Series.str` accessors, :class:`DataFrame.duplicated`, :class:`DataFrame.stack`, :class:`DataFrame.unstack`, :class:`DataFrame.pivot`, :class:`DataFrame.append`, :class:`DataFrame.diff`, :class:`DataFrame.applymap` and :class:`DataFrame.update` methods (:issue:`28283`, :issue:`37381`)\n- Fixed metadata propagation when selecting columns with ``DataFrame.__getitem__`` (:issue:`28283`)\n- Bug in :meth:`Index.intersection` with non-:class:`Index` failing to set the correct name on the returned :class:`Index` (:issue:`38111`)\n- Bug in :meth:`RangeIndex.intersection` failing to set the correct name on the returned :class:`Index` in some corner cases (:issue:`38197`)\n- Bug in :meth:`Index.difference` failing to set the correct name on the returned :class:`Index` in some corner cases (:issue:`38268`)\n- Bug in :meth:`Index.union` behaving differently depending on whether operand is an :class:`Index` or other list-like (:issue:`36384`)\n- Bug in :meth:`Index.intersection` with non-matching numeric dtypes casting to ``object`` dtype instead of minimal common dtype (:issue:`38122`)\n- Bug in :meth:`IntervalIndex.union` returning an incorrectly-typed :class:`Index` when empty (:issue:`38282`)\n- Passing an array with 2 or more dimensions to the :class:`Series` constructor now raises the more specific ``ValueError`` rather than a bare ``Exception`` (:issue:`35744`)\n- Bug in ``dir`` where ``dir(obj)`` wouldn't show attributes defined on the instance for pandas objects (:issue:`37173`)\n- Bug in :meth:`Index.drop` raising ``InvalidIndexError`` when index has duplicates (:issue:`38051`)\n- Bug in :meth:`RangeIndex.difference` returning :class:`Int64Index` in some cases where it should return :class:`RangeIndex` (:issue:`38028`)\n- Fixed bug in :func:`assert_series_equal` when comparing a datetime-like array with an equivalent non extension dtype array (:issue:`37609`)\n- Bug in :func:`.is_bool_dtype` would raise when passed a valid string such as ``\"boolean\"`` (:issue:`38386`)\n- Fixed regression in logical operators raising ``ValueError`` when columns of :class:`DataFrame` are a :class:`CategoricalIndex` with unused categories (:issue:`38367`)\n\n.. ---------------------------------------------------------------------------\n\n.. _whatsnew_120.contributors:\n\nContributors\n~~~~~~~~~~~~\n\n.. contributors:: v1.1.5..v1.2.0\n\n\n.. _whatsnew_0161:\n\nVersion 0.16.1 (May 11, 2015)\n-----------------------------\n\n{{ header }}\n\n\nThis is a minor bug-fix release from 0.16.0 and includes a large number of\nbug fixes along several new features, enhancements, and performance improvements.\nWe recommend that all users upgrade to this version.\n\nHighlights include:\n\n- Support for a ``CategoricalIndex``, a category based index, see :ref:`here <whatsnew_0161.enhancements.categoricalindex>`\n- New section on how-to-contribute to *pandas*, see :ref:`here <contributing>`\n- Revised \"Merge, join, and concatenate\" documentation, including graphical examples to make it easier to understand each operations, see :ref:`here <merging>`\n- New method ``sample`` for drawing random samples from Series, DataFrames and Panels. See :ref:`here <whatsnew_0161.enhancements.sample>`\n- The default ``Index`` printing has changed to a more uniform format, see :ref:`here <whatsnew_0161.index_repr>`\n- ``BusinessHour`` datetime-offset is now supported, see :ref:`here <timeseries.businesshour>`\n\n-  Further enhancement to the ``.str`` accessor to make string operations easier, see :ref:`here <whatsnew_0161.enhancements.string>`\n\n.. contents:: What's new in v0.16.1\n    :local:\n    :backlinks: none\n\n.. _whatsnew_0161.enhancements:\n\n.. warning::\n\n   In pandas 0.17.0, the sub-package ``pandas.io.data`` will be removed in favor of a separately installable package (:issue:`8961`).\n\nEnhancements\n~~~~~~~~~~~~\n\n.. _whatsnew_0161.enhancements.categoricalindex:\n\nCategoricalIndex\n^^^^^^^^^^^^^^^^\n\nWe introduce a ``CategoricalIndex``, a new type of index object that is useful for supporting\nindexing with duplicates. This is a container around a ``Categorical`` (introduced in v0.15.0)\nand allows efficient indexing and storage of an index with a large number of duplicated elements. Prior to 0.16.1,\nsetting the index of a ``DataFrame/Series`` with a ``category`` dtype would convert this to regular object-based ``Index``.\n\n.. code-block:: ipython\n\n    In [1]: df = pd.DataFrame({'A': np.arange(6),\n       ...:                    'B': pd.Series(list('aabbca'))\n       ...:                           .astype('category', categories=list('cab'))\n       ...:                    })\n       ...:\n\n    In [2]: df\n    Out[2]:\n       A  B\n    0  0  a\n    1  1  a\n    2  2  b\n    3  3  b\n    4  4  c\n    5  5  a\n\n    In [3]: df.dtypes\n    Out[3]:\n    A       int64\n    B    category\n    dtype: object\n\n    In [4]: df.B.cat.categories\n    Out[4]: Index(['c', 'a', 'b'], dtype='object')\n\n\nsetting the index, will create a ``CategoricalIndex``\n\n.. code-block:: ipython\n\n    In [5]: df2 = df.set_index('B')\n\n    In [6]: df2.index\n    Out[6]: CategoricalIndex(['a', 'a', 'b', 'b', 'c', 'a'], categories=['c', 'a', 'b'], ordered=False, name='B', dtype='category')\n\nindexing with ``__getitem__/.iloc/.loc/.ix`` works similarly to an Index with duplicates.\nThe indexers MUST be in the category or the operation will raise.\n\n.. code-block:: ipython\n\n    In [7]: df2.loc['a']\n    Out[7]:\n       A\n    B\n    a  0\n    a  1\n    a  5\n\nand preserves the ``CategoricalIndex``\n\n.. code-block:: ipython\n\n    In [8]: df2.loc['a'].index\n    Out[8]: CategoricalIndex(['a', 'a', 'a'], categories=['c', 'a', 'b'], ordered=False, name='B', dtype='category')\n\n\nsorting will order by the order of the categories\n\n.. code-block:: ipython\n\n    In [9]: df2.sort_index()\n    Out[9]:\n       A\n    B\n    c  4\n    a  0\n    a  1\n    a  5\n    b  2\n    b  3\n\ngroupby operations on the index will preserve the index nature as well\n\n.. code-block:: ipython\n\n    In [10]: df2.groupby(level=0).sum()\n    Out[10]:\n       A\n    B\n    c  4\n    a  6\n    b  5\n\n    In [11]: df2.groupby(level=0).sum().index\n    Out[11]: CategoricalIndex(['c', 'a', 'b'], categories=['c', 'a', 'b'], ordered=False, name='B', dtype='category')\n\n\nreindexing operations, will return a resulting index based on the type of the passed\nindexer, meaning that passing a list will return a plain-old-``Index``; indexing with\na ``Categorical`` will return a ``CategoricalIndex``, indexed according to the categories\nof the PASSED ``Categorical`` dtype. This allows one to arbitrarily index these even with\nvalues NOT in the categories, similarly to how you can reindex ANY pandas index.\n\n.. code-block:: ipython\n\n    In [12]: df2.reindex(['a', 'e'])\n    Out[12]:\n         A\n    B\n    a  0.0\n    a  1.0\n    a  5.0\n    e  NaN\n\n    In [13]: df2.reindex(['a', 'e']).index\n    Out[13]: pd.Index(['a', 'a', 'a', 'e'], dtype='object', name='B')\n\n    In [14]: df2.reindex(pd.Categorical(['a', 'e'], categories=list('abcde')))\n    Out[14]:\n         A\n    B\n    a  0.0\n    a  1.0\n    a  5.0\n    e  NaN\n\n    In [15]: df2.reindex(pd.Categorical(['a', 'e'], categories=list('abcde'))).index\n    Out[15]: pd.CategoricalIndex(['a', 'a', 'a', 'e'],\n                                 categories=['a', 'b', 'c', 'd', 'e'],\n                                 ordered=False, name='B',\n                                 dtype='category')\n\nSee the :ref:`documentation <advanced.categoricalindex>` for more. (:issue:`7629`, :issue:`10038`, :issue:`10039`)\n\n.. _whatsnew_0161.enhancements.sample:\n\nSample\n^^^^^^\n\nSeries, DataFrames, and Panels now have a new method: :meth:`~pandas.DataFrame.sample`.\nThe method accepts a specific number of rows or columns to return, or a fraction of the\ntotal number or rows or columns. It also has options for sampling with or without replacement,\nfor passing in a column for weights for non-uniform sampling, and for setting seed values to\nfacilitate replication. (:issue:`2419`)\n\n.. ipython:: python\n\n   example_series = pd.Series([0, 1, 2, 3, 4, 5])\n\n    When no arguments are passed, returns 1\n   example_series.sample()\n\n    One may specify either a number of rows:\n   example_series.sample(n=3)\n\n    Or a fraction of the rows:\n   example_series.sample(frac=0.5)\n\n    weights are accepted.\n   example_weights = [0, 0, 0.2, 0.2, 0.2, 0.4]\n   example_series.sample(n=3, weights=example_weights)\n\n    weights will also be normalized if they do not sum to one,\n    and missing values will be treated as zeros.\n   example_weights2 = [0.5, 0, 0, 0, None, np.nan]\n   example_series.sample(n=1, weights=example_weights2)\n\n\nWhen applied to a DataFrame, one may pass the name of a column to specify sampling weights\nwhen sampling from rows.\n\n.. ipython:: python\n\n   df = pd.DataFrame({\"col1\": [9, 8, 7, 6], \"weight_column\": [0.5, 0.4, 0.1, 0]})\n   df.sample(n=3, weights=\"weight_column\")\n\n\n.. _whatsnew_0161.enhancements.string:\n\nString methods enhancements\n^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n:ref:`Continuing from v0.16.0 <whatsnew_0160.enhancements.string>`, the following\nenhancements make string operations easier and more consistent with standard python string operations.\n\n\n- Added ``StringMethods`` (``.str`` accessor) to ``Index`` (:issue:`9068`)\n\n  The ``.str`` accessor is now available for both ``Series`` and ``Index``.\n\n  .. ipython:: python\n\n     idx = pd.Index([\" jack\", \"jill \", \" jesse \", \"frank\"])\n     idx.str.strip()\n\n  One special case for the ``.str`` accessor on ``Index`` is that if a string method returns ``bool``, the ``.str`` accessor\n  will return a ``np.array`` instead of a boolean ``Index`` (:issue:`8875`). This enables the following expression\n  to work naturally:\n\n  .. ipython:: python\n\n     idx = pd.Index([\"a1\", \"a2\", \"b1\", \"b2\"])\n     s = pd.Series(range(4), index=idx)\n     s\n     idx.str.startswith(\"a\")\n     s[s.index.str.startswith(\"a\")]\n\n- The following new methods are accessible via ``.str`` accessor to apply the function to each values. (:issue:`9766`, :issue:`9773`, :issue:`10031`, :issue:`10045`, :issue:`10052`)\n\n  ================  ===============  ===============  ===============  ================\n  ..                ..               Methods          ..               ..\n  ================  ===============  ===============  ===============  ================\n  ``capitalize()``  ``swapcase()``   ``normalize()``  ``partition()``  ``rpartition()``\n  ``index()``       ``rindex()``     ``translate()``\n  ================  ===============  ===============  ===============  ================\n\n- ``split`` now takes ``expand`` keyword to specify whether to expand dimensionality. ``return_type`` is deprecated. (:issue:`9847`)\n\n  .. ipython:: python\n\n     s = pd.Series([\"a,b\", \"a,c\", \"b,c\"])\n\n      return Series\n     s.str.split(\",\")\n\n      return DataFrame\n     s.str.split(\",\", expand=True)\n\n     idx = pd.Index([\"a,b\", \"a,c\", \"b,c\"])\n\n      return Index\n     idx.str.split(\",\")\n\n      return MultiIndex\n     idx.str.split(\",\", expand=True)\n\n\n- Improved ``extract`` and ``get_dummies`` methods for ``Index.str`` (:issue:`9980`)\n\n\n.. _whatsnew_0161.enhancements.other:\n\nOther enhancements\n^^^^^^^^^^^^^^^^^^\n\n- ``BusinessHour`` offset is now supported, which represents business hours starting from 09:00 - 17:00 on ``BusinessDay`` by default. See :ref:`Here <timeseries.businesshour>` for details. (:issue:`7905`)\n\n  .. ipython:: python\n\n     pd.Timestamp(\"2014-08-01 09:00\") + pd.tseries.offsets.BusinessHour()\n     pd.Timestamp(\"2014-08-01 07:00\") + pd.tseries.offsets.BusinessHour()\n     pd.Timestamp(\"2014-08-01 16:30\") + pd.tseries.offsets.BusinessHour()\n\n- ``DataFrame.diff`` now takes an ``axis`` parameter that determines the direction of differencing (:issue:`9727`)\n\n- Allow ``clip``, ``clip_lower``, and ``clip_upper`` to accept array-like arguments as thresholds (This is a regression from 0.11.0). These methods now have an ``axis`` parameter which determines how the Series or DataFrame will be aligned with the threshold(s). (:issue:`6966`)\n\n- ``DataFrame.mask()`` and ``Series.mask()`` now support same keywords as ``where`` (:issue:`8801`)\n\n- ``drop`` function can now accept ``errors`` keyword to suppress ``ValueError`` raised when any of label does not exist in the target data. (:issue:`6736`)\n\n  .. ipython:: python\n\n    df = pd.DataFrame(np.random.randn(3, 3), columns=[\"A\", \"B\", \"C\"])\n    df.drop([\"A\", \"X\"], axis=1, errors=\"ignore\")\n\n- Add support for separating years and quarters using dashes, for\n  example 2014-Q1.  (:issue:`9688`)\n\n- Allow conversion of values with dtype ``datetime64`` or ``timedelta64`` to strings using ``astype(str)`` (:issue:`9757`)\n- ``get_dummies`` function now accepts ``sparse`` keyword.  If set to ``True``, the return ``DataFrame`` is sparse, e.g. ``SparseDataFrame``. (:issue:`8823`)\n- ``Period`` now accepts ``datetime64`` as value input. (:issue:`9054`)\n\n- Allow timedelta string conversion when leading zero is missing from time definition, ie ``0:00:00`` vs ``00:00:00``. (:issue:`9570`)\n- Allow ``Panel.shift`` with ``axis='items'`` (:issue:`9890`)\n\n- Trying to write an excel file now raises ``NotImplementedError`` if the ``DataFrame`` has a ``MultiIndex`` instead of writing a broken Excel file. (:issue:`9794`)\n- Allow ``Categorical.add_categories`` to accept ``Series`` or ``np.array``. (:issue:`9927`)\n\n- Add/delete ``str/dt/cat`` accessors dynamically from ``__dir__``. (:issue:`9910`)\n- Add ``normalize`` as a ``dt`` accessor method. (:issue:`10047`)\n\n- ``DataFrame`` and ``Series`` now have ``_constructor_expanddim`` property as overridable constructor for one higher dimensionality data. This should be used only when it is really needed, see :ref:`here <extending.subclassing-pandas>`\n\n- ``pd.lib.infer_dtype`` now returns ``'bytes'`` in Python 3 where appropriate. (:issue:`10032`)\n\n\n.. _whatsnew_0161.api:\n\nAPI changes\n~~~~~~~~~~~\n\n- When passing in an ax to ``df.plot( ..., ax=ax)``, the ``sharex`` kwarg will now default to ``False``.\n  The result is that the visibility of xlabels and xticklabels will not anymore be changed. You\n  have to do that by yourself for the right axes in your figure or set ``sharex=True`` explicitly\n  (but this changes the visible for all axes in the figure, not only the one which is passed in!).\n  If pandas creates the subplots itself (e.g. no passed in ``ax`` kwarg), then the\n  default is still ``sharex=True`` and the visibility changes are applied.\n\n- :meth:`~pandas.DataFrame.assign` now inserts new columns in alphabetical order. Previously\n  the order was arbitrary. (:issue:`9777`)\n\n- By default, ``read_csv`` and ``read_table`` will now try to infer the compression type based on the file extension. Set ``compression=None`` to restore the previous behavior (no decompression). (:issue:`9770`)\n\n.. _whatsnew_0161.deprecations:\n\nDeprecations\n^^^^^^^^^^^^\n\n- ``Series.str.split``'s ``return_type`` keyword was removed in favor of ``expand`` (:issue:`9847`)\n\n\n.. _whatsnew_0161.index_repr:\n\nIndex representation\n~~~~~~~~~~~~~~~~~~~~\n\nThe string representation of ``Index`` and its sub-classes have now been unified. These will show a single-line display if there are few values; a wrapped multi-line display for a lot of values (but less than ``display.max_seq_items``; if lots of items (> ``display.max_seq_items``) will show a truncated display (the head and tail of the data). The formatting for ``MultiIndex`` is unchanged (a multi-line wrapped display). The display width responds to the option ``display.max_seq_items``, which is defaulted to 100. (:issue:`6482`)\n\nPrevious behavior\n\n.. code-block:: ipython\n\n   In [2]: pd.Index(range(4), name='foo')\n   Out[2]: Int64Index([0, 1, 2, 3], dtype='int64')\n\n   In [3]: pd.Index(range(104), name='foo')\n   Out[3]: Int64Index([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, ...], dtype='int64')\n\n   In [4]: pd.date_range('20130101', periods=4, name='foo', tz='US/Eastern')\n   Out[4]:\n   <class 'pandas.tseries.index.DatetimeIndex'>\n   [2013-01-01 00:00:00-05:00, ..., 2013-01-04 00:00:00-05:00]\n   Length: 4, Freq: D, Timezone: US/Eastern\n\n   In [5]: pd.date_range('20130101', periods=104, name='foo', tz='US/Eastern')\n   Out[5]:\n   <class 'pandas.tseries.index.DatetimeIndex'>\n   [2013-01-01 00:00:00-05:00, ..., 2013-04-14 00:00:00-04:00]\n   Length: 104, Freq: D, Timezone: US/Eastern\n\nNew behavior\n\n.. ipython:: python\n\n   pd.set_option(\"display.width\", 80)\n   pd.Index(range(4), name=\"foo\")\n   pd.Index(range(30), name=\"foo\")\n   pd.Index(range(104), name=\"foo\")\n   pd.CategoricalIndex([\"a\", \"bb\", \"ccc\", \"dddd\"], ordered=True, name=\"foobar\")\n   pd.CategoricalIndex([\"a\", \"bb\", \"ccc\", \"dddd\"] * 10, ordered=True, name=\"foobar\")\n   pd.CategoricalIndex([\"a\", \"bb\", \"ccc\", \"dddd\"] * 100, ordered=True, name=\"foobar\")\n   pd.date_range(\"20130101\", periods=4, name=\"foo\", tz=\"US/Eastern\")\n   pd.date_range(\"20130101\", periods=25, freq=\"D\")\n   pd.date_range(\"20130101\", periods=104, name=\"foo\", tz=\"US/Eastern\")\n\n\n.. _whatsnew_0161.performance:\n\nPerformance improvements\n~~~~~~~~~~~~~~~~~~~~~~~~\n\n- Improved csv write performance with mixed dtypes, including datetimes by up to 5x (:issue:`9940`)\n- Improved csv write performance generally by 2x (:issue:`9940`)\n- Improved the performance of ``pd.lib.max_len_string_array`` by 5-7x (:issue:`10024`)\n\n\n.. _whatsnew_0161.bug_fixes:\n\nBug fixes\n~~~~~~~~~\n\n- Bug where labels did not appear properly in the legend of ``DataFrame.plot()``, passing ``label=`` arguments works, and Series indices are no longer mutated. (:issue:`9542`)\n- Bug in json serialization causing a segfault when a frame had zero length. (:issue:`9805`)\n- Bug in ``read_csv`` where missing trailing delimiters would cause segfault. (:issue:`5664`)\n- Bug in retaining index name on appending (:issue:`9862`)\n- Bug in ``scatter_matrix`` draws unexpected axis ticklabels (:issue:`5662`)\n- Fixed bug in ``StataWriter`` resulting in changes to input ``DataFrame`` upon save (:issue:`9795`).\n- Bug in ``transform`` causing length mismatch when null entries were present and a fast aggregator was being used (:issue:`9697`)\n- Bug in ``equals`` causing false negatives when block order differed (:issue:`9330`)\n- Bug in grouping with multiple ``pd.Grouper`` where one is non-time based (:issue:`10063`)\n- Bug in ``read_sql_table`` error when reading postgres table with timezone (:issue:`7139`)\n- Bug in ``DataFrame`` slicing may not retain metadata (:issue:`9776`)\n- Bug where ``TimdeltaIndex`` were not properly serialized in fixed ``HDFStore`` (:issue:`9635`)\n- Bug with ``TimedeltaIndex`` constructor ignoring ``name`` when given another ``TimedeltaIndex`` as data (:issue:`10025`).\n- Bug in ``DataFrameFormatter._get_formatted_index`` with not applying ``max_colwidth`` to the ``DataFrame`` index (:issue:`7856`)\n- Bug in ``.loc`` with a read-only ndarray data source (:issue:`10043`)\n- Bug in ``groupby.apply()`` that would raise if a passed user defined function either returned only ``None`` (for all input). (:issue:`9685`)\n- Always use temporary files in pytables tests (:issue:`9992`)\n- Bug in plotting continuously using ``secondary_y`` may not show legend properly. (:issue:`9610`, :issue:`9779`)\n- Bug in ``DataFrame.plot(kind=\"hist\")`` results in ``TypeError`` when ``DataFrame`` contains non-numeric columns  (:issue:`9853`)\n- Bug where repeated plotting of ``DataFrame`` with a ``DatetimeIndex`` may raise ``TypeError`` (:issue:`9852`)\n- Bug in ``setup.py`` that would allow an incompat cython version to build (:issue:`9827`)\n- Bug in plotting ``secondary_y`` incorrectly attaches ``right_ax`` property to secondary axes specifying itself recursively. (:issue:`9861`)\n- Bug in ``Series.quantile`` on empty Series of type ``Datetime`` or ``Timedelta`` (:issue:`9675`)\n- Bug in ``where`` causing incorrect results when upcasting was required (:issue:`9731`)\n- Bug in ``FloatArrayFormatter`` where decision boundary for displaying \"small\" floats in decimal format is off by one order of magnitude for a given display.precision (:issue:`9764`)\n- Fixed bug where ``DataFrame.plot()`` raised an error when both ``color`` and ``style`` keywords were passed and there was no color symbol in the style strings (:issue:`9671`)\n- Not showing a ``DeprecationWarning`` on combining list-likes with an ``Index`` (:issue:`10083`)\n- Bug in ``read_csv`` and ``read_table`` when using ``skip_rows`` parameter if blank lines are present. (:issue:`9832`)\n- Bug in ``read_csv()`` interprets ``index_col=True`` as ``1`` (:issue:`9798`)\n- Bug in index equality comparisons using ``==`` failing on Index/MultiIndex type incompatibility (:issue:`9785`)\n- Bug in which ``SparseDataFrame`` could not take ``nan`` as a column name (:issue:`8822`)\n- Bug in ``to_msgpack`` and ``read_msgpack`` zlib and blosc compression support (:issue:`9783`)\n- Bug ``GroupBy.size`` doesn't attach index name properly if grouped by ``TimeGrouper`` (:issue:`9925`)\n- Bug causing an exception in slice assignments because ``length_of_indexer`` returns wrong results (:issue:`9995`)\n- Bug in csv parser causing lines with initial white space plus one non-space character to be skipped. (:issue:`9710`)\n- Bug in C csv parser causing spurious NaNs when data started with newline followed by white space. (:issue:`10022`)\n- Bug causing elements with a null group to spill into the final group when grouping by a ``Categorical`` (:issue:`9603`)\n- Bug where .iloc and .loc behavior is not consistent on empty dataframes (:issue:`9964`)\n- Bug in invalid attribute access on a ``TimedeltaIndex`` incorrectly raised ``ValueError`` instead of ``AttributeError`` (:issue:`9680`)\n- Bug in unequal comparisons between categorical data and a scalar, which was not in the categories (e.g. ``Series(Categorical(list(\"abc\"), ordered=True)) > \"d\"``. This returned ``False`` for all elements, but now raises a ``TypeError``. Equality comparisons also now return ``False`` for ``==`` and ``True`` for ``!=``. (:issue:`9848`)\n- Bug in DataFrame ``__setitem__`` when right hand side is a dictionary (:issue:`9874`)\n- Bug in ``where`` when dtype is ``datetime64/timedelta64``, but dtype of other is not (:issue:`9804`)\n- Bug in ``MultiIndex.sortlevel()`` results in unicode level name breaks (:issue:`9856`)\n- Bug in which ``groupby.transform`` incorrectly enforced output dtypes to match input dtypes. (:issue:`9807`)\n- Bug in ``DataFrame`` constructor when ``columns`` parameter is set, and ``data`` is an empty list (:issue:`9939`)\n- Bug in bar plot with ``log=True`` raises ``TypeError`` if all values are less than 1 (:issue:`9905`)\n- Bug in horizontal bar plot ignores ``log=True`` (:issue:`9905`)\n- Bug in PyTables queries that did not return proper results using the index (:issue:`8265`, :issue:`9676`)\n- Bug where dividing a dataframe containing values of type ``Decimal`` by another ``Decimal`` would raise. (:issue:`9787`)\n- Bug where using DataFrames asfreq would remove the name of the index. (:issue:`9885`)\n- Bug causing extra index point when resample BM/BQ (:issue:`9756`)\n- Changed caching in ``AbstractHolidayCalendar`` to be at the instance level rather than at the class level as the latter can result in unexpected behaviour. (:issue:`9552`)\n- Fixed latex output for MultiIndexed dataframes (:issue:`9778`)\n- Bug causing an exception when setting an empty range using ``DataFrame.loc`` (:issue:`9596`)\n- Bug in hiding ticklabels with subplots and shared axes when adding a new plot to an existing grid of axes (:issue:`9158`)\n- Bug in ``transform`` and ``filter`` when grouping on a categorical variable (:issue:`9921`)\n- Bug in ``transform`` when groups are equal in number and dtype to the input index (:issue:`9700`)\n- Google BigQuery connector now imports dependencies on a per-method basis.(:issue:`9713`)\n- Updated BigQuery connector to no longer use deprecated ``oauth2client.tools.run()`` (:issue:`8327`)\n- Bug in subclassed ``DataFrame``. It may not return the correct class, when slicing or subsetting it. (:issue:`9632`)\n- Bug in ``.median()`` where non-float null values are not handled correctly (:issue:`10040`)\n- Bug in Series.fillna() where it raises if a numerically convertible string is given (:issue:`10092`)\n\n\n.. _whatsnew_0.16.1.contributors:\n\nContributors\n~~~~~~~~~~~~\n\n.. contributors:: v0.16.0..v0.16.1\n"}